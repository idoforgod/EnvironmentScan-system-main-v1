# ğŸ—ï¸ arXiv Scanner ì˜êµ¬ í†µí•© ì„¤ê³„ ê³„íš

**ë‚ ì§œ**: 2026-01-30
**ëª©ì **: arXiv ìŠ¤ìºë„ˆë¥¼ ì‹œìŠ¤í…œì˜ ì˜êµ¬ì  í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ í†µí•©
**ìƒíƒœ**: ğŸ“‹ ì„¤ê³„ ê³„íš (êµ¬í˜„ ì „ ìŠ¹ì¸ í•„ìš”)

---

## ğŸ“‹ ëª©ì°¨

1. [í˜„ì¬ ìƒíƒœ ë¶„ì„](#í˜„ì¬-ìƒíƒœ-ë¶„ì„)
2. [í†µí•© ì•„í‚¤í…ì²˜ ì„¤ê³„](#í†µí•©-ì•„í‚¤í…ì²˜-ì„¤ê³„)
3. [êµ¬í˜„ ê³„íš](#êµ¬í˜„-ê³„íš)
4. [íŒŒì¼ êµ¬ì¡° ì¬í¸ì„±](#íŒŒì¼-êµ¬ì¡°-ì¬í¸ì„±)
5. [ì„¤ì • ê´€ë¦¬](#ì„¤ì •-ê´€ë¦¬)
6. [ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µì›ë ¥](#ì—ëŸ¬-ì²˜ë¦¬-ë°-ë³µì›ë ¥)
7. [í™•ì¥ì„± ê³ ë ¤ì‚¬í•­](#í™•ì¥ì„±-ê³ ë ¤ì‚¬í•­)
8. [í…ŒìŠ¤íŠ¸ ì „ëµ](#í…ŒìŠ¤íŠ¸-ì „ëµ)
9. [êµ¬í˜„ ìˆœì„œ](#êµ¬í˜„-ìˆœì„œ)

---

## í˜„ì¬ ìƒíƒœ ë¶„ì„

### âœ… ê²€ì¦ ì™„ë£Œëœ ê¸°ëŠ¥

```
scripts/arxiv_scanner.py (í˜„ì¬ ìœ„ì¹˜)
â”œâ”€ arXiv API í†µí•© âœ…
â”œâ”€ SSL ì²˜ë¦¬ âœ…
â”œâ”€ Rate limiting âœ…
â”œâ”€ STEEPs ì¹´í…Œê³ ë¦¬ ë§¤í•‘ âœ…
â”œâ”€ ì—ëŸ¬ ì²˜ë¦¬ âœ…
â””â”€ 90ê°œ ë…¼ë¬¸ ìˆ˜ì§‘ ì„±ê³µ (15ì´ˆ) âœ…

ê²€ì¦ ê²°ê³¼:
- ì„±ê³µë¥ : 100%
- ë°ì´í„° í’ˆì§ˆ: ì™„ì „í•œ ë©”íƒ€ë°ì´í„°
- ì„±ëŠ¥: 15ì´ˆ/90ê°œ ë…¼ë¬¸
- ì•ˆì •ì„±: í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ
```

### ğŸ”„ í˜„ì¬ ì œí•œì‚¬í•­

1. **ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸**: Workflowì™€ ë¶„ë¦¬ë˜ì–´ ìˆ˜ë™ ì‹¤í–‰
2. **í•˜ë“œì½”ë”©ëœ ì„¤ì •**: ì½”ë“œ ë‚´ë¶€ì— ì„¤ì •ê°’ í¬í•¨
3. **ë‹¨ì¼ ì†ŒìŠ¤**: arXivë§Œ ì§€ì› (í™•ì¥ ë¶ˆê°€)
4. **ìŠ¤ì¼€ì¤„ë§ ì—†ìŒ**: ìë™ ì‹¤í–‰ ë¯¸ì§€ì›
5. **ëª¨ë‹ˆí„°ë§ ë¶€ì¬**: ì‹¤íŒ¨ ì•Œë¦¼ ì‹œìŠ¤í…œ ì—†ìŒ

---

## í†µí•© ì•„í‚¤í…ì²˜ ì„¤ê³„

### ğŸ¯ ì„¤ê³„ ì›ì¹™

```
í•µì‹¬ ì›ì¹™:
1. ê¸°ì¡´ workflow ì² í•™ ì™„ë²½ ë³´ì¡´
2. Multi-source í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°
3. ì„¤ì • ê¸°ë°˜ ë™ì‘ (ì½”ë“œ ìˆ˜ì • ìµœì†Œí™”)
4. ì—ëŸ¬ ë³µì›ë ¥ (resilience)
5. ëª¨ë‹ˆí„°ë§ ë° ê´€ì°° ê°€ëŠ¥ì„± (observability)
```

### ğŸ“ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Orchestrator Agent                        â”‚
â”‚                   (env-scan-orchestrator)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”œâ”€ Phase 1: Data Collection
                      â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                   â”‚
    v                                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Archive Loader  â”‚           â”‚ Multi-Source     â”‚
â”‚   (Step 1.1)    â”‚           â”‚   Scanner        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  (Step 1.2)      â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚                  â”‚
                    v                  v                  v
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ arXiv Scanner   â”‚ â”‚ Google      â”‚ â”‚ Policy RSS       â”‚
           â”‚   (Core)        â”‚ â”‚ Scholar     â”‚ â”‚   Scanner        â”‚
           â”‚                 â”‚ â”‚ Scanner     â”‚ â”‚  (Future)        â”‚
           â”‚ - API í†µí•©      â”‚ â”‚ (Future)    â”‚ â”‚                  â”‚
           â”‚ - Rate limit    â”‚ â”‚             â”‚ â”‚                  â”‚
           â”‚ - STEEPs ë§¤í•‘   â”‚ â”‚             â”‚ â”‚                  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    v
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Unified Signal Format Converter    â”‚
           â”‚  (ëª¨ë“  ì†ŒìŠ¤ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    v
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   raw/daily-scan-{date}.json        â”‚
           â”‚   (í†µí•©ëœ ë©€í‹°ì†ŒìŠ¤ ê²°ê³¼)              â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”§ í†µí•© êµ¬ì¡°

#### Option A: Multi-Source Scanner Agent í™•ì¥ (ê¶Œì¥) âœ…

**ì¥ì **:
- ê¸°ì¡´ workflow êµ¬ì¡° ìœ ì§€
- Multi-source-scanner.md ëª…ì„¸ì™€ ì¼ì¹˜
- í™•ì¥ ìš©ì´ (Google Scholar, RSS ë“± ì¶”ê°€)
- Orchestrator ìˆ˜ì • ìµœì†Œí™”

**êµ¬ì¡°**:
```
.claude/agents/workers/multi-source-scanner.md
â”œâ”€ Role: "Scan multiple information sources..."
â”œâ”€ Input: config/sources.yaml
â”œâ”€ Output: raw/daily-scan-{date}.json
â””â”€ Processing Logic:
    â”œâ”€ load_configuration()
    â”œâ”€ scan_all_sources()
    â”‚   â”œâ”€ scan_academic_source() â† arXiv ì—¬ê¸° í†µí•©
    â”‚   â”œâ”€ scan_patent_source()
    â”‚   â”œâ”€ scan_policy_source()
    â”‚   â””â”€ scan_blog_source()
    â””â”€ write_raw_scan()

env-scanning/scanners/  (ìƒˆ ë””ë ‰í† ë¦¬)
â”œâ”€ __init__.py
â”œâ”€ base_scanner.py       â† ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”œâ”€ arxiv_scanner.py      â† í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë§ˆì´ê·¸ë ˆì´ì…˜
â”œâ”€ scholar_scanner.py    â† ë¯¸ë˜ í™•ì¥
â””â”€ rss_scanner.py        â† ë¯¸ë˜ í™•ì¥
```

#### Option B: ë…ë¦½ Subagentë¡œ ìœ ì§€ (ëŒ€ì•ˆ)

**ì¥ì **:
- ì™„ì „í•œ ë…ë¦½ì„±
- ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥

**ë‹¨ì **:
- Orchestrator ë³µì¡ë„ ì¦ê°€
- Multi-source í†µí•© ì–´ë ¤ì›€

**ê²°ë¡ **: **Option A ì„ íƒ** (Multi-Source Scanner í™•ì¥)

---

## êµ¬í˜„ ê³„íš

### Phase 1: ê¸°ë°˜ êµ¬ì¡° êµ¬ì¶• (1-2ì¼)

#### 1.1 Base Scanner ì¶”ìƒ í´ë˜ìŠ¤ ìƒì„±

**íŒŒì¼**: `env-scanning/scanners/base_scanner.py`

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any
from datetime import datetime, timedelta

class BaseScanner(ABC):
    """
    ëª¨ë“  ì†ŒìŠ¤ ìŠ¤ìºë„ˆì˜ ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤

    ê° ì†ŒìŠ¤ ìŠ¤ìºë„ˆëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ scan() ë©”ì„œë“œë¥¼ êµ¬í˜„
    """

    def __init__(self, config: Dict[str, Any]):
        """
        Args:
            config: sources.yamlì—ì„œ ë¡œë“œí•œ ì„¤ì •
        """
        self.config = config
        self.name = config['name']
        self.source_type = config['type']
        self.enabled = config.get('enabled', True)
        self.rate_limit = config.get('rate_limit', None)
        self.timeout = config.get('timeout', 30)

    @abstractmethod
    def scan(self,
             steeps_domains: Dict[str, List[str]],
             days_back: int = 7) -> List[Dict[str, Any]]:
        """
        ì†ŒìŠ¤ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì‹ í˜¸ ìˆ˜ì§‘

        Args:
            steeps_domains: STEEPs ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ
            days_back: ë©°ì¹  ì „ê¹Œì§€ ìŠ¤ìº”í• ì§€

        Returns:
            í‘œì¤€ ì‹ í˜¸ í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
        """
        pass

    def is_enabled(self) -> bool:
        """ìŠ¤ìºë„ˆ í™œì„±í™” ì—¬ë¶€"""
        return self.enabled

    def get_name(self) -> str:
        """ì†ŒìŠ¤ ì´ë¦„"""
        return self.name

    def validate_config(self) -> bool:
        """ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬"""
        required_fields = ['name', 'type']
        return all(field in self.config for field in required_fields)

    def to_standard_format(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì†ŒìŠ¤ë³„ ë°ì´í„°ë¥¼ í‘œì¤€ ì‹ í˜¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

        í‘œì¤€ í˜•ì‹:
        {
            "id": "arxiv-2601.12345",
            "title": "...",
            "source": {"name": "...", "type": "...", "url": "...", "published_date": "..."},
            "content": {"abstract": "...", "keywords": [...], "language": "en"},
            "preliminary_category": "T",
            "collected_at": "2026-01-30T09:00:00Z"
        }
        """
        return raw_data  # ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ
```

#### 1.2 arXiv Scanner ë¦¬íŒ©í† ë§

**íŒŒì¼**: `env-scanning/scanners/arxiv_scanner.py`

```python
from .base_scanner import BaseScanner
import urllib.request
import urllib.parse
import xml.etree.ElementTree as ET
import ssl
import time
from typing import List, Dict, Any
from datetime import datetime, timedelta

class ArXivScanner(BaseScanner):
    """
    arXiv í•™ìˆ  ë…¼ë¬¸ ìŠ¤ìºë„ˆ

    API: http://export.arxiv.org/api/query
    Rate Limit: 3ì´ˆë‹¹ 1íšŒ ìš”ì²­ (API ê°€ì´ë“œë¼ì¸)
    """

    BASE_URL = "http://export.arxiv.org/api/query"
    RATE_LIMIT_DELAY = 3  # seconds

    # STEEPs â†’ arXiv ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    CATEGORY_MAPPING = {
        'T_Technological': ['cs.AI', 'cs.RO', 'cs.CV', 'cs.CL', 'quant-ph'],
        'E_Economic': ['econ.EM', 'econ.GN', 'q-fin.EC', 'q-fin.TR'],
        'E_Environmental': ['physics.ao-ph', 'physics.geo-ph', 'q-bio.PE'],
        'S_Social': ['cs.CY', 'cs.HC', 'stat.AP'],
        'P_Political': ['cs.CY'],
        's_spiritual': ['cs.CY', 'physics.soc-ph']
    }

    def __init__(self, config: Dict[str, Any]):
        super().__init__(config)
        self.max_results_per_category = config.get('max_results', 20)
        self.last_request_time = 0

    def scan(self,
             steeps_domains: Dict[str, List[str]],
             days_back: int = 7) -> List[Dict[str, Any]]:
        """
        arXivì—ì„œ ë…¼ë¬¸ ìˆ˜ì§‘
        """
        all_papers = []

        # ê° STEEPs ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìŠ¤ìº”
        for steeps_category in self.CATEGORY_MAPPING.keys():
            papers = self._scan_category(steeps_category)
            all_papers.extend(papers)

        return all_papers

    def _respect_rate_limit(self):
        """Rate limit ì¤€ìˆ˜ (3ì´ˆ ëŒ€ê¸°)"""
        elapsed = time.time() - self.last_request_time
        if elapsed < self.RATE_LIMIT_DELAY:
            time.sleep(self.RATE_LIMIT_DELAY - elapsed)
        self.last_request_time = time.time()

    def _scan_category(self, steeps_category: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • STEEPs ì¹´í…Œê³ ë¦¬ ìŠ¤ìº”"""
        arxiv_cats = self.CATEGORY_MAPPING.get(steeps_category, [])
        if not arxiv_cats:
            return []

        # ì¿¼ë¦¬ ìƒì„±
        query = self._build_query(arxiv_cats)

        # API í˜¸ì¶œ
        papers = self._fetch_papers(query, self.max_results_per_category)

        # í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        return [self.to_standard_format(p, steeps_category) for p in papers]

    # ... (ê¸°ì¡´ _build_query, _fetch_papers, _parse_entry ë©”ì„œë“œë“¤)

    def to_standard_format(self, paper: Dict[str, Any], category: str) -> Dict[str, Any]:
        """arXiv ë…¼ë¬¸ì„ í‘œì¤€ ì‹ í˜¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        return {
            "id": f"arxiv-{paper['arxiv_id']}",
            "title": paper['title'],
            "source": {
                "name": "arXiv",
                "type": "academic",
                "url": paper['url'],
                "published_date": paper['published_date']
            },
            "content": {
                "abstract": paper['abstract'],
                "keywords": paper['categories'],
                "language": "en"
            },
            "metadata": {
                "arxiv_id": paper['arxiv_id'],
                "authors": paper['authors'],
                "arxiv_categories": paper['categories']
            },
            "preliminary_category": category[0],  # ì²« ê¸€ì (T, E, S, P, s)
            "collected_at": datetime.now().isoformat()
        }
```

#### 1.3 Scanner Factory ìƒì„±

**íŒŒì¼**: `env-scanning/scanners/scanner_factory.py`

```python
from typing import Dict, Any, List
from .base_scanner import BaseScanner
from .arxiv_scanner import ArXivScanner

class ScannerFactory:
    """
    ì„¤ì • ê¸°ë°˜ ìŠ¤ìºë„ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± íŒ©í† ë¦¬
    """

    # ì†ŒìŠ¤ íƒ€ì… â†’ ìŠ¤ìºë„ˆ í´ë˜ìŠ¤ ë§¤í•‘
    SCANNER_REGISTRY = {
        'academic': {
            'arXiv': ArXivScanner,
            # 'Google Scholar': GoogleScholarScanner,  # ë¯¸ë˜ í™•ì¥
        },
        # 'patent': {...},  # ë¯¸ë˜ í™•ì¥
        # 'policy': {...},  # ë¯¸ë˜ í™•ì¥
        # 'blog': {...},    # ë¯¸ë˜ í™•ì¥
    }

    @classmethod
    def create_scanner(cls, config: Dict[str, Any]) -> BaseScanner:
        """
        ì„¤ì •ì—ì„œ ì ì ˆí•œ ìŠ¤ìºë„ˆ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

        Args:
            config: sources.yamlì˜ ê°œë³„ ì†ŒìŠ¤ ì„¤ì •

        Returns:
            BaseScanner ì„œë¸Œí´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤

        Raises:
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ì¸ ê²½ìš°
        """
        source_type = config['type']
        source_name = config['name']

        # íƒ€ì…ë³„ ìŠ¤ìºë„ˆ ì°¾ê¸°
        if source_type not in cls.SCANNER_REGISTRY:
            raise ValueError(f"Unsupported source type: {source_type}")

        type_scanners = cls.SCANNER_REGISTRY[source_type]

        if source_name not in type_scanners:
            raise ValueError(f"Unsupported source: {source_name} ({source_type})")

        scanner_class = type_scanners[source_name]
        return scanner_class(config)

    @classmethod
    def create_all_scanners(cls, sources_config: List[Dict[str, Any]]) -> List[BaseScanner]:
        """
        sources.yamlì—ì„œ ëª¨ë“  í™œì„±í™”ëœ ìŠ¤ìºë„ˆ ìƒì„±

        Args:
            sources_config: sources.yamlì˜ 'sources' ë¦¬ìŠ¤íŠ¸

        Returns:
            í™œì„±í™”ëœ ìŠ¤ìºë„ˆ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        scanners = []

        for source_config in sources_config:
            # ë¹„í™œì„±í™”ëœ ì†ŒìŠ¤ëŠ” ê±´ë„ˆë›°ê¸°
            if not source_config.get('enabled', True):
                continue

            try:
                scanner = cls.create_scanner(source_config)

                # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
                if scanner.validate_config():
                    scanners.append(scanner)
                else:
                    print(f"[WARNING] Invalid config for {source_config['name']}")

            except ValueError as e:
                print(f"[WARNING] Skipping {source_config.get('name', 'unknown')}: {e}")
                continue

        return scanners
```

### Phase 2: Multi-Source Scanner í†µí•© (2-3ì¼)

#### 2.1 Multi-Source Scanner ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

**íŒŒì¼**: `env-scanning/scripts/run_multi_source_scan.py`

```python
#!/usr/bin/env python3
"""
Multi-Source Scanner Executor
Orchestratorì—ì„œ í˜¸ì¶œë˜ëŠ” ì‹¤ì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import os
import json
import yaml
from datetime import datetime
from typing import List, Dict, Any

# ìŠ¤ìºë„ˆ ëª¨ë“ˆ import
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from scanners.scanner_factory import ScannerFactory


def load_configuration():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open('config/sources.yaml', 'r') as f:
        sources_config = yaml.safe_load(f)

    with open('config/domains.yaml', 'r') as f:
        domains_config = yaml.safe_load(f)

    return sources_config, domains_config


def run_scan(days_back: int = 7) -> Dict[str, Any]:
    """
    ë©€í‹°ì†ŒìŠ¤ ìŠ¤ìº” ì‹¤í–‰

    Args:
        days_back: ë©°ì¹  ì „ê¹Œì§€ ìŠ¤ìº”í• ì§€

    Returns:
        scan_metadataì™€ itemsë¥¼ í¬í•¨í•œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("="*60)
    print("Multi-Source Scanner - Starting")
    print("="*60)

    start_time = datetime.now()

    # 1. ì„¤ì • ë¡œë“œ
    sources_config, domains_config = load_configuration()

    # 2. ìŠ¤ìºë„ˆ ìƒì„±
    scanners = ScannerFactory.create_all_scanners(sources_config['sources'])

    print(f"\n[INFO] Loaded {len(scanners)} active scanners")
    for scanner in scanners:
        print(f"  - {scanner.get_name()} ({scanner.source_type})")

    # 3. ê° ìŠ¤ìºë„ˆ ì‹¤í–‰
    all_items = []
    sources_scanned = 0

    for scanner in scanners:
        try:
            print(f"\n[SCANNING] {scanner.get_name()}...")

            items = scanner.scan(
                steeps_domains=domains_config['STEEPs'],
                days_back=days_back
            )

            all_items.extend(items)
            sources_scanned += 1

            print(f"[SUCCESS] {scanner.get_name()}: {len(items)} items collected")
            print(f"[PROGRESS] Total items: {len(all_items)}")

        except Exception as e:
            # ê°œë³„ ìŠ¤ìºë„ˆ ì‹¤íŒ¨ëŠ” ì „ì²´ ì‹¤íŒ¨ë¡œ ì´ì–´ì§€ì§€ ì•ŠìŒ
            print(f"[ERROR] {scanner.get_name()} failed: {e}")

            # Critical ì†ŒìŠ¤ì¸ ê²½ìš°ì—ë§Œ ì˜ˆì™¸ ë°œìƒ
            if scanner.config.get('critical', False):
                raise

            continue

    # 4. ê²°ê³¼ êµ¬ì„±
    execution_time = (datetime.now() - start_time).total_seconds()

    result = {
        "scan_metadata": {
            "date": datetime.now().strftime('%Y-%m-%d'),
            "sources_scanned": sources_scanned,
            "total_items": len(all_items),
            "execution_time": round(execution_time, 2),
            "mode": "multi_source",
            "days_back": days_back
        },
        "items": all_items
    }

    print("\n" + "="*60)
    print(f"[COMPLETE] Scan finished in {execution_time:.1f}s")
    print(f"[RESULT] {len(all_items)} items from {sources_scanned} sources")
    print("="*60)

    return result


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse

    parser = argparse.ArgumentParser(description='Multi-Source Scanner')
    parser.add_argument('--days-back', type=int, default=7,
                       help='How many days back to scan (default: 7)')
    parser.add_argument('--output', type=str, default=None,
                       help='Output file path (default: raw/daily-scan-{date}.json)')

    args = parser.parse_args()

    try:
        # ìŠ¤ìº” ì‹¤í–‰
        result = run_scan(days_back=args.days_back)

        # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        if args.output:
            output_path = args.output
        else:
            today = datetime.now().strftime('%Y-%m-%d')
            output_path = f"raw/daily-scan-{today}.json"

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        print(f"\n[SAVED] Output written to: {output_path}")

        return 0

    except Exception as e:
        print(f"\n[FATAL ERROR] {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

#### 2.2 Orchestrator í†µí•©

**íŒŒì¼**: `.claude/agents/env-scan-orchestrator.md` (ìˆ˜ì •)

```yaml
# Step 1.2: Multi-Source Scanner

invoke:
  tool: Task
  agent: general-purpose
  description: "Scan multiple sources for signals"

  prompt: |
    Execute the multi-source scanner to collect signals from configured sources.

    Command:
      cd env-scanning
      python3 scripts/run_multi_source_scan.py --days-back 7

    This will:
    1. Load sources.yaml and domains.yaml configurations
    2. Create scanner instances for all enabled sources (arXiv, etc.)
    3. Collect signals from each source
    4. Save unified results to raw/daily-scan-{date}.json

input:
  - config/sources.yaml (must exist)
  - config/domains.yaml (must exist)

output:
  - raw/daily-scan-{date}.json

verification:
  - File exists: raw/daily-scan-{date}.json
  - Contains: scan_metadata.total_items > 0
  - Contains: items array with at least 1 signal
  - Each signal has: id, title, source, preliminary_category

error_handling:
  - If critical source fails: halt workflow
  - If non-critical source fails: log warning, continue
  - Retry: 3 attempts with exponential backoff
```

### Phase 3: ì„¤ì • íŒŒì¼ ì—…ë°ì´íŠ¸ (1ì¼)

#### 3.1 sources.yaml í™•ì¥

**íŒŒì¼**: `env-scanning/config/sources.yaml`

```yaml
# Multi-Source Configuration
# Version: 2.0.0 (arXiv integration)
# Last Updated: 2026-01-30

sources:
  # ========================================
  # Academic Sources
  # ========================================

  - name: "arXiv"
    type: "academic"
    enabled: true  # âœ… ì˜êµ¬ í™œì„±í™”

    # arXiv API ì„¤ì •
    api_endpoint: "http://export.arxiv.org/api/query"
    rate_limit: 300  # per minute (ì‹¤ì œë¡œëŠ” 3ì´ˆë‹¹ 1íšŒ)
    timeout: 30

    # ì¤‘ìš”ë„ ì„¤ì •
    critical: true  # ì‹¤íŒ¨ì‹œ workflow ì¤‘ë‹¨

    # ìŠ¤ìº” ì„¤ì •
    date_filter: "last_7_days"
    max_results: 20  # STEEPs ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ ë…¼ë¬¸ ìˆ˜

    # í’ˆì§ˆ ì„¤ì •
    min_abstract_length: 100  # ìµœì†Œ ì´ˆë¡ ê¸¸ì´

    # ë©”íƒ€ë°ì´í„°
    description: "Open academic paper repository - no authentication required"
    reliability: "high"
    cost: "free"

  # ========================================
  # Future Academic Sources
  # ========================================

  - name: "Google Scholar"
    type: "academic"
    enabled: false  # ë¯¸ë˜ í™•ì¥
    api_endpoint: "https://serpapi.com/search"
    api_key_env: "SERPAPI_KEY"
    rate_limit: 100  # per hour
    timeout: 30
    critical: false
    max_results: 50

  - name: "SSRN"
    type: "academic"
    enabled: false  # ë¯¸ë˜ í™•ì¥
    rss_feed: "https://papers.ssrn.com/sol3/rss_feed.cfm"
    timeout: 15
    critical: false

# ========================================
# Global Settings
# ========================================

retry_policy:
  max_attempts: 3
  backoff_strategy: "exponential"  # 1s, 2s, 4s
  timeout_increase: true

error_handling:
  on_critical_failure: "halt_workflow"
  on_non_critical_failure: "skip_and_continue"
  log_errors: true
  notify_on_failure: false

# ========================================
# Monitoring
# ========================================

monitoring:
  track_performance: true
  track_success_rate: true
  alert_on_failures: false  # ë¯¸ë˜ í™•ì¥ (ì´ë©”ì¼/Slack)
```

---

## íŒŒì¼ êµ¬ì¡° ì¬í¸ì„±

### ìµœì¢… ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
env-scanning/
â”œâ”€ config/
â”‚  â”œâ”€ sources.yaml              â† arXiv ì˜êµ¬ ì„¤ì • í¬í•¨
â”‚  â”œâ”€ domains.yaml              â† STEEPs ì¹´í…Œê³ ë¦¬ ì •ì˜
â”‚  â””â”€ thresholds.yaml           â† ê¸°ì¡´
â”‚
â”œâ”€ scanners/                    â† ìƒˆë¡œ ìƒì„±
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ base_scanner.py           â† ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
â”‚  â”œâ”€ arxiv_scanner.py          â† arXiv í†µí•© (ë¦¬íŒ©í† ë§)
â”‚  â”œâ”€ scanner_factory.py        â† íŒ©í† ë¦¬ íŒ¨í„´
â”‚  â””â”€ README.md                 â† ìŠ¤ìºë„ˆ ì¶”ê°€ ê°€ì´ë“œ
â”‚
â”œâ”€ scripts/
â”‚  â”œâ”€ run_multi_source_scan.py  â† Orchestratorì—ì„œ í˜¸ì¶œ
â”‚  â”œâ”€ run_real_workflow.py      â† ê¸°ì¡´ (í…ŒìŠ¤íŠ¸ìš©)
â”‚  â””â”€ (arxiv_scanner.py ì‚­ì œ)   â† scanners/ë¡œ ì´ë™
â”‚
â”œâ”€ raw/                         â† ê¸°ì¡´
â”œâ”€ filtered/                    â† ê¸°ì¡´
â”œâ”€ structured/                  â† ê¸°ì¡´
â”œâ”€ analysis/                    â† ê¸°ì¡´
â”œâ”€ reports/                     â† ê¸°ì¡´
â””â”€ context/                     â† ê¸°ì¡´
```

### íŒŒì¼ ì´ë™ ê³„íš

```bash
# 1. ìƒˆ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p env-scanning/scanners

# 2. Base scanner ìƒì„±
# (ìƒˆ íŒŒì¼ë“¤ ìƒì„±)

# 3. arXiv scanner ë§ˆì´ê·¸ë ˆì´ì…˜
# scripts/arxiv_scanner.py â†’ scanners/arxiv_scanner.py
# (BaseScanner ìƒì† êµ¬ì¡°ë¡œ ë¦¬íŒ©í† ë§)

# 4. ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ì œê±°
# scripts/arxiv_scanner.py ì‚­ì œ (scanners/ë¡œ í†µí•©)
```

---

## ì„¤ì • ê´€ë¦¬

### í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬

**íŒŒì¼**: `env-scanning/.env.example`

```bash
# Multi-Source Scanner Environment Variables
# Copy this file to .env and fill in your values

# arXiv
# (No API key required - open access)

# Google Scholar (Future)
# SERPAPI_KEY=your_serpapi_key_here

# Monitoring (Future)
# SLACK_WEBHOOK_URL=your_slack_webhook
# EMAIL_SMTP_SERVER=smtp.gmail.com
# EMAIL_SMTP_PORT=587
# EMAIL_USERNAME=your_email
# EMAIL_PASSWORD=your_password
```

### ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬

**íŒŒì¼**: `env-scanning/scripts/validate_config.py`

```python
#!/usr/bin/env python3
"""
ì„¤ì • íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
"""

import yaml
import sys

def validate_sources_yaml():
    """sources.yaml ìœ íš¨ì„± ê²€ì‚¬"""
    with open('config/sources.yaml', 'r') as f:
        config = yaml.safe_load(f)

    # í•„ìˆ˜ í•„ë“œ ê²€ì‚¬
    assert 'sources' in config
    assert len(config['sources']) > 0

    # ìµœì†Œ 1ê°œ í™œì„±í™”ëœ ì†ŒìŠ¤ í•„ìš”
    enabled_sources = [s for s in config['sources'] if s.get('enabled', True)]
    assert len(enabled_sources) > 0, "No enabled sources found"

    # ê° ì†ŒìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
    for source in config['sources']:
        assert 'name' in source
        assert 'type' in source
        assert 'enabled' in source

    print(f"âœ… sources.yaml valid: {len(enabled_sources)} enabled sources")
    return True

def validate_domains_yaml():
    """domains.yaml ìœ íš¨ì„± ê²€ì‚¬"""
    with open('config/domains.yaml', 'r') as f:
        config = yaml.safe_load(f)

    # STEEPs ì¹´í…Œê³ ë¦¬ ì¡´ì¬ í™•ì¸
    assert 'STEEPs' in config

    required_categories = ['S_Social', 'T_Technological', 'E_Economic',
                          'E_Environmental', 'P_Political', 's_spiritual']

    for cat in required_categories:
        assert cat in config['STEEPs'], f"Missing category: {cat}"
        assert len(config['STEEPs'][cat]) > 0, f"Empty keywords for {cat}"

    print(f"âœ… domains.yaml valid: {len(config['STEEPs'])} categories")
    return True

if __name__ == "__main__":
    try:
        validate_sources_yaml()
        validate_domains_yaml()
        print("\nâœ… All configurations valid!")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Configuration error: {e}")
        sys.exit(1)
```

---

## ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µì›ë ¥

### ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

```python
# 1. Rate Limit ì—ëŸ¬
class RateLimitError(Exception):
    """API rate limit exceeded"""
    pass

def handle_rate_limit_error(scanner, retry_count):
    """
    Rate limit ì—ëŸ¬ ì²˜ë¦¬

    ì „ëµ:
    1. API ì‘ë‹µ í—¤ë”ì—ì„œ reset ì‹œê°„ í™•ì¸
    2. í•´ë‹¹ ì‹œê°„ë§Œí¼ ëŒ€ê¸°
    3. ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
    """
    wait_time = scanner.get_rate_limit_reset_time()
    print(f"[RATE_LIMIT] Waiting {wait_time}s before retry...")
    time.sleep(wait_time)

# 2. Timeout ì—ëŸ¬
def handle_timeout_error(scanner, retry_count):
    """
    Timeout ì—ëŸ¬ ì²˜ë¦¬

    ì „ëµ:
    1. ì²« ì‹œë„: 30s timeout
    2. ì¬ì‹œë„ 1: 60s timeout
    3. ì¬ì‹œë„ 2: 120s timeout
    """
    new_timeout = scanner.timeout * (2 ** retry_count)
    scanner.timeout = min(new_timeout, 300)  # ìµœëŒ€ 5ë¶„

# 3. ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬
def handle_network_error(scanner, retry_count):
    """
    ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ì²˜ë¦¬

    ì „ëµ: Exponential backoff (1s, 2s, 4s)
    """
    wait_time = 2 ** retry_count
    print(f"[NETWORK_ERROR] Retrying in {wait_time}s...")
    time.sleep(wait_time)
```

### Fallback ì „ëµ

```yaml
fallback_strategy:
  # Critical ì†ŒìŠ¤ ì‹¤íŒ¨ì‹œ
  critical_source_failure:
    action: "halt_workflow"
    notify: true
    log_level: "ERROR"

  # Non-critical ì†ŒìŠ¤ ì‹¤íŒ¨ì‹œ
  non_critical_source_failure:
    action: "skip_and_continue"
    notify: false
    log_level: "WARNING"

  # ëª¨ë“  ì†ŒìŠ¤ ì‹¤íŒ¨ì‹œ
  all_sources_failure:
    action: "use_cached_data"  # ì´ì „ ìŠ¤ìº” ê²°ê³¼ ì‚¬ìš©
    max_cache_age: "24_hours"
    notify: true
    log_level: "CRITICAL"
```

---

## í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

### ìƒˆ ì†ŒìŠ¤ ì¶”ê°€ í”„ë¡œì„¸ìŠ¤

**ì˜ˆì‹œ: Google Scholar ì¶”ê°€**

```python
# 1. Scanner í´ë˜ìŠ¤ ìƒì„±
# scanners/scholar_scanner.py

from .base_scanner import BaseScanner

class GoogleScholarScanner(BaseScanner):
    """Google Scholar via SerpAPI"""

    def scan(self, steeps_domains, days_back=7):
        # SerpAPI í˜¸ì¶œ ë¡œì§
        pass

    def to_standard_format(self, raw_data):
        # Scholar ë°ì´í„° â†’ í‘œì¤€ í˜•ì‹ ë³€í™˜
        pass

# 2. Factoryì— ë“±ë¡
# scanners/scanner_factory.py

SCANNER_REGISTRY = {
    'academic': {
        'arXiv': ArXivScanner,
        'Google Scholar': GoogleScholarScanner,  # â† ì¶”ê°€
    }
}

# 3. sources.yamlì— ì¶”ê°€
sources:
  - name: "Google Scholar"
    type: "academic"
    enabled: true  # â† í™œì„±í™”
    api_key_env: "SERPAPI_KEY"
    ...

# ì™„ë£Œ! ìë™ìœ¼ë¡œ ìŠ¤ìº”ì— í¬í•¨ë¨
```

### í™•ì¥ í¬ì¸íŠ¸

```python
# 1. ìƒˆ ì†ŒìŠ¤ íƒ€ì… ì¶”ê°€
class RSSScanner(BaseScanner):
    """Generic RSS feed scanner"""
    pass

# 2. ì»¤ìŠ¤í…€ í•„í„° ì¶”ê°€
class QualityFilter:
    """ìŠ¤ìº” ê²°ê³¼ í’ˆì§ˆ í•„í„°"""

    def filter(self, signals):
        # ë‚®ì€ í’ˆì§ˆ ì‹ í˜¸ ì œê±°
        return [s for s in signals if s.get('quality_score', 0) > 0.5]

# 3. ë°ì´í„° ì¦ê°• ì¶”ê°€
class SignalEnricher:
    """ìŠ¤ìº” ê²°ê³¼ ë°ì´í„° ì¦ê°•"""

    def enrich(self, signal):
        # ì™¸ë¶€ APIë¡œ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
        signal['citations'] = get_citation_count(signal['id'])
        return signal
```

---

## í…ŒìŠ¤íŠ¸ ì „ëµ

### Unit Tests

**íŒŒì¼**: `env-scanning/tests/test_arxiv_scanner.py`

```python
import pytest
from scanners.arxiv_scanner import ArXivScanner

def test_arxiv_scanner_initialization():
    """arXiv ìŠ¤ìºë„ˆ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
    config = {
        'name': 'arXiv',
        'type': 'academic',
        'enabled': True,
        'max_results': 20
    }

    scanner = ArXivScanner(config)

    assert scanner.get_name() == 'arXiv'
    assert scanner.is_enabled() == True
    assert scanner.validate_config() == True

def test_arxiv_category_mapping():
    """STEEPs â†’ arXiv ì¹´í…Œê³ ë¦¬ ë§¤í•‘ í…ŒìŠ¤íŠ¸"""
    scanner = ArXivScanner({'name': 'arXiv', 'type': 'academic'})

    assert 'cs.AI' in scanner.CATEGORY_MAPPING['T_Technological']
    assert 'econ.EM' in scanner.CATEGORY_MAPPING['E_Economic']

@pytest.mark.integration
def test_arxiv_real_scan():
    """ì‹¤ì œ arXiv ìŠ¤ìº” í†µí•© í…ŒìŠ¤íŠ¸ (slow)"""
    scanner = ArXivScanner({
        'name': 'arXiv',
        'type': 'academic',
        'max_results': 5  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ê°œë§Œ
    })

    domains = {'T_Technological': ['AI', 'machine learning']}
    results = scanner.scan(domains, days_back=7)

    assert len(results) > 0
    assert all('id' in r for r in results)
    assert all('title' in r for r in results)
```

### Integration Tests

**íŒŒì¼**: `env-scanning/tests/test_multi_source_integration.py`

```python
def test_multi_source_scan_execution():
    """ë©€í‹°ì†ŒìŠ¤ ìŠ¤ìº” í†µí•© í…ŒìŠ¤íŠ¸"""
    from scripts.run_multi_source_scan import run_scan

    result = run_scan(days_back=7)

    # ë©”íƒ€ë°ì´í„° ê²€ì¦
    assert 'scan_metadata' in result
    assert result['scan_metadata']['sources_scanned'] > 0
    assert result['scan_metadata']['total_items'] > 0

    # ì•„ì´í…œ ê²€ì¦
    assert 'items' in result
    assert len(result['items']) > 0

    # í‘œì¤€ í˜•ì‹ ê²€ì¦
    for item in result['items']:
        assert 'id' in item
        assert 'title' in item
        assert 'source' in item
        assert 'preliminary_category' in item
```

### Performance Tests

```python
def test_scan_performance():
    """ìŠ¤ìº” ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    import time

    start = time.time()
    result = run_scan(days_back=7)
    elapsed = time.time() - start

    # ì„±ëŠ¥ ëª©í‘œ: 100ê°œ ì‹ í˜¸ë¥¼ 30ì´ˆ ì´ë‚´ì— ìˆ˜ì§‘
    items_per_second = len(result['items']) / elapsed

    assert items_per_second > 3, "Performance target: >3 items/second"
    assert elapsed < 60, "Should complete within 60 seconds"
```

---

## êµ¬í˜„ ìˆœì„œ

### Week 1: ê¸°ë°˜ êµ¬ì¡° (ì¶”ì²œ ìˆœì„œ)

```
Day 1-2: ê¸°ë°˜ í´ë˜ìŠ¤ ë° ì•„í‚¤í…ì²˜
â”œâ”€ [ ] scanners/ ë””ë ‰í† ë¦¬ ìƒì„±
â”œâ”€ [ ] base_scanner.py ì‘ì„±
â”œâ”€ [ ] scanner_factory.py ì‘ì„±
â””â”€ [ ] Unit tests ì‘ì„±

Day 3-4: arXiv Scanner ë¦¬íŒ©í† ë§
â”œâ”€ [ ] arxiv_scanner.pyë¥¼ BaseScanner ìƒì† êµ¬ì¡°ë¡œ ë³€ê²½
â”œâ”€ [ ] to_standard_format() êµ¬í˜„
â”œâ”€ [ ] Integration tests ì‘ì„±
â””â”€ [ ] ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ì™€ ë¹„êµ ê²€ì¦

Day 5: Multi-Source Runner
â”œâ”€ [ ] run_multi_source_scan.py ì‘ì„±
â”œâ”€ [ ] CLI arguments ì§€ì›
â”œâ”€ [ ] ì—ëŸ¬ ì²˜ë¦¬ ì¶”ê°€
â””â”€ [ ] End-to-end test
```

### Week 2: Orchestrator í†µí•©

```
Day 6-7: Orchestrator ìˆ˜ì •
â”œâ”€ [ ] env-scan-orchestrator.md Step 1.2 ì—…ë°ì´íŠ¸
â”œâ”€ [ ] Task tool í˜¸ì¶œ êµ¬ì¡° ì •ì˜
â”œâ”€ [ ] ì…ì¶œë ¥ ê²€ì¦ ë¡œì§ ì¶”ê°€
â””â”€ [ ] í†µí•© í…ŒìŠ¤íŠ¸

Day 8-9: ì„¤ì • ê´€ë¦¬
â”œâ”€ [ ] sources.yaml ì—…ë°ì´íŠ¸ (arXiv ì˜êµ¬ ì„¤ì •)
â”œâ”€ [ ] .env.example ì‘ì„±
â”œâ”€ [ ] validate_config.py ì‘ì„±
â””â”€ [ ] ë¬¸ì„œí™”

Day 10: ìµœì¢… ê²€ì¦
â”œâ”€ [ ] ì „ì²´ workflow ì‹¤í–‰ (arXiv í¬í•¨)
â”œâ”€ [ ] ì„±ëŠ¥ ì¸¡ì •
â”œâ”€ [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸
â””â”€ [ ] ë°°í¬ ì¤€ë¹„
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### êµ¬í˜„ ì „ í™•ì¸ì‚¬í•­

- [ ] ê¸°ì¡´ workflow ì² í•™ ì´í•´
- [ ] Multi-source-scanner.md ëª…ì„¸ ìˆ™ì§€
- [ ] STEEPs í”„ë ˆì„ì›Œí¬ ì´í•´
- [ ] í˜„ì¬ íŒŒì¼ êµ¬ì¡° íŒŒì•…

### êµ¬í˜„ ì¤‘ í™•ì¸ì‚¬í•­

- [ ] BaseScanner ì¶”ìƒ í´ë˜ìŠ¤ ì˜¬ë°”ë¥´ê²Œ ì„¤ê³„
- [ ] Factory pattern ì ì ˆíˆ ì ìš©
- [ ] ì„¤ì • ê¸°ë°˜ ë™ì‘ (í•˜ë“œì½”ë”© ìµœì†Œí™”)
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ì™„ì „ì„±
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ

### êµ¬í˜„ í›„ í™•ì¸ì‚¬í•­

- [ ] ê¸°ì¡´ ê²€ì¦ ê²°ê³¼ì™€ ë™ì¼ (90ê°œ ë…¼ë¬¸ ìˆ˜ì§‘)
- [ ] ì„±ëŠ¥ ì €í•˜ ì—†ìŒ (15ì´ˆ ì´ë‚´)
- [ ] Orchestrator í†µí•© ì„±ê³µ
- [ ] ì „ì²´ workflow ì •ìƒ ë™ì‘
- [ ] ë¬¸ì„œí™” ì™„ë£Œ

---

## ì˜ˆìƒ ê²°ê³¼

### í†µí•© ì™„ë£Œ í›„

```bash
# 1. ìˆ˜ë™ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)
$ cd env-scanning
$ python3 scripts/run_multi_source_scan.py --days-back 7

# ì¶œë ¥:
# ============================================================
# Multi-Source Scanner - Starting
# ============================================================
#
# [INFO] Loaded 1 active scanners
#   - arXiv (academic)
#
# [SCANNING] arXiv...
# [SUCCESS] arXiv: 90 items collected
# [PROGRESS] Total items: 90
#
# ============================================================
# [COMPLETE] Scan finished in 15.1s
# [RESULT] 90 items from 1 sources
# ============================================================
#
# [SAVED] Output written to: raw/daily-scan-2026-01-30.json

# 2. Orchestrator ì‹¤í–‰ (í”„ë¡œë•ì…˜)
# Orchestratorê°€ ìë™ìœ¼ë¡œ Step 1.2ì—ì„œ ì‹¤í–‰

# 3. ê²°ê³¼ íŒŒì¼ êµ¬ì¡°
$ cat raw/daily-scan-2026-01-30.json
{
  "scan_metadata": {
    "date": "2026-01-30",
    "sources_scanned": 1,
    "total_items": 90,
    "execution_time": 15.06,
    "mode": "multi_source"
  },
  "items": [
    {
      "id": "arxiv-2601.20858",
      "title": "When Flores Bloomz Wrong...",
      "source": {...},
      "preliminary_category": "T",
      ...
    }
  ]
}
```

### ì‹œìŠ¤í…œ ìƒíƒœ

```
System Readiness: 95% â†’ 97% (arXiv ì˜êµ¬ í†µí•© ì™„ë£Œ)

ì™„ë£Œëœ ê¸°ëŠ¥:
  âœ… arXiv ì˜êµ¬ í†µí•©
  âœ… Multi-source ì•„í‚¤í…ì²˜
  âœ… ì„¤ì • ê¸°ë°˜ ë™ì‘
  âœ… í™•ì¥ ê°€ëŠ¥ êµ¬ì¡°
  âœ… ì—ëŸ¬ ë³µì›ë ¥

ë‹¤ìŒ ë‹¨ê³„:
  ğŸ”„ Google Scholar ì¶”ê°€ (ë¯¸ë˜)
  ğŸ”„ Policy RSS ì¶”ê°€ (ë¯¸ë˜)
  ğŸ”„ LLM ë¶„ë¥˜ í†µí•©
```

---

## ìŠ¹ì¸ í•„ìš” ì‚¬í•­

### ì„¤ê³„ ê²°ì • í™•ì¸

1. **ì•„í‚¤í…ì²˜ ì„ íƒ**: Multi-Source Scanner í™•ì¥ (Option A) âœ…
2. **íŒŒì¼ êµ¬ì¡°**: `scanners/` ë””ë ‰í† ë¦¬ ì‹ ê·œ ìƒì„± âœ…
3. **ì„¤ì • ê´€ë¦¬**: `sources.yaml`ì— arXiv ì˜êµ¬ ì„¤ì • âœ…
4. **ì—ëŸ¬ ì²˜ë¦¬**: Critical/Non-critical êµ¬ë¶„ ì „ëµ âœ…
5. **í™•ì¥ì„±**: Factory pattern + BaseScanner ìƒì† âœ…

### êµ¬í˜„ ë²”ìœ„ í™•ì¸

**Phase 1 (í•„ìˆ˜)**:
- Base scanner êµ¬ì¡°
- arXiv scanner ë¦¬íŒ©í† ë§
- Multi-source runner

**Phase 2 (ì„ íƒ)**:
- Google Scholar ì¶”ê°€ (ë¯¸ë˜ í™•ì¥)
- Monitoring ì‹œìŠ¤í…œ (ë¯¸ë˜ í™•ì¥)

### ì‚¬ìš©ì ìŠ¹ì¸ í•„ìš” ì§ˆë¬¸

1. **ì„¤ê³„ ë°©í–¥ì„± ìŠ¹ì¸**: ìœ„ ì„¤ê³„ì•ˆ ì „ì²´ ìŠ¹ì¸?
2. **êµ¬í˜„ ë²”ìœ„**: Phase 1ë§Œ ì§„í–‰? Phase 2ë„ í¬í•¨?
3. **íŒŒì¼ êµ¬ì¡°**: `scanners/` ë””ë ‰í† ë¦¬ êµ¬ì¡° ìŠ¹ì¸?
4. **ì„¤ì • ê´€ë¦¬**: `sources.yaml` í˜•ì‹ ìŠ¹ì¸?
5. **ê¸°íƒ€ ìš”êµ¬ì‚¬í•­**: ì¶”ê°€ ê¸°ëŠ¥ì´ë‚˜ ìˆ˜ì • í•„ìš”í•œ ë¶€ë¶„?

---

**ì„¤ê³„ ê³„íš ì‘ì„± ì™„ë£Œ**
**ë‹¤ìŒ ë‹¨ê³„**: ì‚¬ìš©ì ìŠ¹ì¸ í›„ êµ¬í˜„ ì‹œì‘
**ì˜ˆìƒ êµ¬í˜„ ê¸°ê°„**: 1-2ì£¼ (Phase 1 ê¸°ì¤€)
**ì‹œìŠ¤í…œ ì¤€ë¹„ë„**: 97% ì˜ˆìƒ (í†µí•© ì™„ë£Œ í›„)
