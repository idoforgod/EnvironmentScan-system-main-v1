# ================================================================
# WORKFLOW REGISTRY — Source of Truth (SOT)
# ================================================================
# Version: 2.2.1
# Last Updated: 2026-02-10
#
# This file is the SINGLE authoritative definition of the
# Quadruple Environmental Scanning System.
#
# RULES:
#   1. master-orchestrator MUST read this file at startup
#   2. validate_registry.py MUST pass before any workflow executes
#   3. Shared configs are referenced, NEVER duplicated
#   4. Adding/removing a workflow requires modifying this file FIRST
#   5. Agents do NOT hardcode paths — they receive paths from this registry
#   6. Validation failure with severity HALT stops the workflow entirely
#
# INDEPENDENCE GUARANTEE:
#   - WF1 does not know WF2, WF3, or WF4 exists
#   - WF2 does not know WF1, WF3, or WF4 exists
#   - WF3 does not know WF1, WF2, or WF4 exists
#   - WF4 does not know WF1, WF2, or WF3 exists
#   - Any workflow can be deleted without affecting the others
#   - No workflow reads or writes another's data during execution
#   - Each produces a complete, independently valid final report
# ================================================================

system:
  name: "Quadruple Environmental Scanning System"
  version: "2.5.0"
  created: "2026-02-03"

  # ── Execution Mode ──
  execution:
    mode: "sequential"  # wf1 completes → wf2 completes → wf3 completes → wf4 completes → merge
    master_orchestrator: ".claude/agents/master-orchestrator.md"
    protocol: ".claude/agents/protocols/orchestrator-protocol.md"

  # ── Temporal Consistency (v2.2.0, 2026-02-10) ──
  # 모든 일일 스캐닝의 시간적 범위를 제어하는 글로벌 설정.
  # 마스터 오케스트레이터가 T₀(실행 시작 시점)를 기록하고,
  # 모든 워크플로우에 동일한 기준점을 전달한다.
  temporal_consistency:
    enabled: true
    anchor: "master_start_time"        # T₀ = 마스터 오케스트레이터 실행 시작 시점
    window_calculation: "T0_minus_lookback"  # scan_start = T₀ - lookback_hours
    per_workflow_override: true         # 워크플로우별 lookback_hours 오버라이드 허용
    post_collection_filter: true       # 수집 후 프로그래매틱 필터링 강제
    default_lookback_hours: 24         # 기본 룩백: 24시간 (만 하루)
    default_tolerance_minutes: 30      # 기본 오차 허용: ±30분
    default_enforce: "strict"          # strict = 범위 외 시그널 제거, lenient = 경고만
    # ── Python 강제 모듈 (v2.2.1: 할루시네이션 원천봉쇄) ──
    # 이 스크립트들은 LLM 지시문을 대체하여 결정론적 연산을 보장한다.
    # T₀ 생성, 윈도우 산술, 파이프라인 게이트, 메타데이터 삽입 모두 Python이 수행.
    anchor_script: "env-scanning/core/temporal_anchor.py"
    gate_script: "env-scanning/core/temporal_gate.py"
    metadata_injector_script: "env-scanning/core/report_metadata_injector.py"
    statistics_engine_script: "env-scanning/core/report_statistics_engine.py"
    state_file_pattern: "{integration_output_root}/logs/scan-window-{date}.json"

  # ── Dedup Gate (v2.6.0→v2.9.0, 2026-02-24) ──
  # Cross-scan duplicate detection: deterministic Python pre-filter that catches
  # topic-level duplicates BEFORE the LLM dedup-filter agent processes signals.
  # 4-stage cascade: Stage A (URL) → Stage B (Topic Fingerprint) → Stage C
  # (Jaro-Winkler title similarity) → Stage D (entity overlap).
  # The LLM agent handles only uncertain signals.
  dedup_gate:
    enabled: true
    gate_script: "env-scanning/core/dedup_gate.py"
    previous_signals_source: "database_snapshot"  # "database_snapshot" = pre-update DB snapshot
    lookback_days: 30                    # How far back to compare previous signals (days)
    thresholds:
      url_exact: 1.0                     # Stage A: normalized URL exact match
      topic_fingerprint_definite: 0.60   # Stage B: ≥ this → definite_duplicate (removed)
      topic_fingerprint_uncertain: 0.30  # Stage B: ≥ this → uncertain (flagged for LLM)
      title_similarity_definite: 0.90    # Stage C: Jaro-Winkler ≥ this → definite_duplicate
      title_similarity_uncertain: 0.80   # Stage C: Jaro-Winkler ≥ this → uncertain
      entity_overlap_definite: 0.85      # Stage D: entity Jaccard ≥ this → definite_duplicate
      entity_overlap_uncertain: 0.70     # Stage D: entity Jaccard ≥ this → uncertain
    enforce: "strict"                    # strict = remove definite dupes; lenient = log only

  # ── Signal Evolution Tracking (v2.3.0, 2026-02-11) ──
  # Cross-day signal matching: tracks how signals evolve across daily scans.
  # Produces evolution states (NEW/RECURRING/STRENGTHENING/WEAKENING/FADED/TRANSFORMED)
  # and timeline metrics (velocity, direction, expansion).
  signal_evolution:
    enabled: true
    tracker_script: "env-scanning/core/signal_evolution_tracker.py"
    matching:
      title_similarity_threshold: 0.80     # Jaro-Winkler threshold for title matching
      semantic_similarity_threshold: 0.70  # Keyword similarity threshold
      high_confidence_threshold: 0.85      # Combined score for HIGH confidence
    lifecycle:
      fade_threshold_days: 3               # Days without appearance → FADED
      max_thread_age_days: 90              # Maximum thread tracking duration
      min_appearances_for_velocity: 2      # Minimum appearances to compute velocity
    state_detection:
      strengthening_psst_delta: 5          # pSST increase threshold for STRENGTHENING
      weakening_psst_delta: -5             # pSST decrease threshold for WEAKENING
    cross_workflow_correlation:
      enabled: true
      output_path: "integrated/analysis/evolution/"
      matching:
        title_similarity_threshold: 0.75     # Lower than intra-WF (0.80) — cross-WF expression differences
        semantic_similarity_threshold: 0.65  # Lower than intra-WF (0.70) — same reason
        high_confidence_threshold: 0.80      # Combined score for HIGH confidence (v1.3.0 L2 fix)
        category_filter_enabled: true        # Pre-filter by STEEPs category (v1.3.0 L2 fix)

    # ── Timeline Map Generation (v2.4.0, 2026-02-11) ──
    # Generates a Korean markdown timeline map showing signal evolution
    # across themes, pSST trajectories, and cross-WF correlations.
    timeline_map:
      enabled: true
      generator_script: "env-scanning/core/timeline_map_generator.py"
      output_filename_pattern: "timeline-map-{date}.md"
      lookback_days: 7          # Evolution history window (days)
      min_signals_for_theme: 2  # Minimum signals to include a theme cluster
      top_n_psst: 10            # Number of top-pSST signals to highlight

  # ── Bilingual System (v2.8.0, English-First Workflow) ──
  # All AI work is performed in English. Korean output is produced by
  # a deterministic translation sub-agent validated by Python.
  # "계산은 Python이, 판단은 LLM이" — Python handles structural integrity,
  # LLM handles semantic translation quality.
  bilingual:
    enabled: true
    internal_language: "en"   # AI processing language
    external_language: "ko"   # User-facing report language
    resolver_script: "env-scanning/core/bilingual_resolver.py"
    skeleton_mirror_script: "env-scanning/core/skeleton_mirror.py"
    translation_validator_script: "env-scanning/core/translation_validator.py"
    # English skeleton paths (generated by skeleton_mirror.py --all)
    skeletons_en:
      report_skeleton: ".claude/skills/env-scanner/references/report-skeleton-en.md"
      naver_report_skeleton: ".claude/skills/env-scanner/references/naver-report-skeleton-en.md"
      multiglobal_news_report_skeleton: ".claude/skills/env-scanner/references/multiglobal-news-report-skeleton-en.md"
      integrated_report_skeleton: ".claude/skills/env-scanner/references/integrated-report-skeleton-en.md"
      weekly_report_skeleton: ".claude/skills/env-scanner/references/weekly-report-skeleton-en.md"

  # ── Shared Invariants (read-only reference, never modified at runtime) ──
  # All workflows reference these same files to guarantee philosophical consistency.
  # These are methodology references, NOT runtime data dependencies.
  shared_invariants:
    steep_framework: ".claude/skills/env-scanner/references/steep-framework.md"
    report_format: ".claude/skills/env-scanner/references/report-format.md"
    report_skeleton: ".claude/skills/env-scanner/references/report-skeleton.md"
    signal_template: ".claude/skills/env-scanner/references/signal-template.md"
    core_invariants: "env-scanning/config/core-invariants.yaml"
    domains: "env-scanning/config/domains.yaml"
    thresholds: "env-scanning/config/thresholds.yaml"
    self_improvement_config: "env-scanning/config/self-improvement-config.yaml"

  # ── Shared Engine (Python modules used by all workflows) ──
  shared_engine:
    core_modules: "env-scanning/core/"
    scanners: "env-scanning/scanners/"
    validate_script: "env-scanning/scripts/validate_report.py"
    validate_registry_script: "env-scanning/scripts/validate_registry.py"

  # ── Shared Worker Agents (invoked by both orchestrators, unmodified) ──
  shared_workers:
    - ".claude/agents/workers/multi-source-scanner.md"
    - ".claude/agents/workers/deduplication-filter.md"
    - ".claude/agents/workers/signal-classifier.md"
    - ".claude/agents/workers/impact-analyzer.md"
    - ".claude/agents/workers/priority-ranker.md"
    - ".claude/agents/workers/report-generator.md"
    - ".claude/agents/workers/database-updater.md"
    - ".claude/agents/workers/archive-loader.md"
    - ".claude/agents/workers/archive-notifier.md"
    - ".claude/agents/workers/translation-agent.md"
    - ".claude/agents/workers/self-improvement-analyzer.md"
    - ".claude/agents/exploration-orchestrator.md"
    - ".claude/agents/workers/discovery-alpha.md"
    - ".claude/agents/workers/discovery-beta.md"
    - ".claude/agents/workers/discovery-evaluator.md"
    - ".claude/agents/workers/source-explorer.md"

  # ── SIE Policy ──
  sie_policy: "independent"
  # Each workflow runs its own SIE on its own metrics.
  # Shared configs (thresholds.yaml, domains.yaml) are NOT modifiable by SIE.
  # Modifying shared configs requires MAJOR change approval from user.

  # ── Total Human Checkpoints ──
  checkpoints_total: 9
  checkpoints_detail:
    wf1_analysis_review: "required"   # WF1 Step 2.5
    wf1_report_approval: "required"   # WF1 Step 3.4
    wf2_analysis_review: "required"   # WF2 Step 2.5
    wf2_report_approval: "required"   # WF2 Step 3.4
    wf3_analysis_review: "required"   # WF3 Step 2.5
    wf3_report_approval: "required"   # WF3 Step 3.4
    wf4_analysis_review: "required"   # WF4 Step 2.5
    wf4_report_approval: "required"   # WF4 Step 3.4
    integrated_approval: "required"   # Integrated report final approval

# ================================================================
# WORKFLOW DEFINITIONS
# ================================================================

workflows:

  # ────────────────────────────────────────────
  # WF1: General Environmental Scanning
  # ────────────────────────────────────────────
  wf1-general:
    name: "General Environmental Scanning"
    name_ko: "일반 환경스캐닝"
    description: "Multi-source environmental scanning (arXiv removed — transferred to WF2)"
    enabled: true
    execution_order: 1

    orchestrator: ".claude/agents/env-scan-orchestrator.md"
    sources_config: "env-scanning/config/sources.yaml"
    excluded_sources: ["arXiv"]  # Explicitly recorded: arXiv is disabled in sources.yaml

    data_root: "env-scanning/wf1-general"
    paths:
      raw: "raw/"
      structured: "structured/"
      filtered: "filtered/"
      analysis: "analysis/"
      signals_db: "signals/database.json"
      signals_snapshots: "signals/snapshots/"
      reports_daily: "reports/daily/"
      reports_archive: "reports/archive/"
      context: "context/"
      logs: "logs/"
      health: "health/"
      calibration: "calibration/"
      self_improvement: "self-improvement/"
      evolution_index: "signals/evolution-index.json"
      evolution_maps: "analysis/evolution/"
      exploration: "exploration/"
      exploration_candidates: "exploration/candidates/"
      exploration_history: "exploration/history/"

    parameters:
      marathon_mode: true
      base_only_flag: false

      # ── Source Exploration (v2.5.0) ──
      source_exploration:
        enabled: true
        enforcement: "mandatory"            # "mandatory" | "optional" — mandatory = validate_report.py CRITICAL, optional = ERROR
        exploration_method: "agent-team"    # "agent-team" | "single-agent"
        max_candidates_per_scan: 5          # Max candidate sources to test per scan
        max_test_signals_per_candidate: 10  # Max signals collected per candidate test
        time_budget_minutes: 40             # Stage C time upper bound (doubled from 20 on 2026-02-19)
        coverage_gap_threshold: 0.15        # STEEPs < 15% → "gap"
        min_signals_for_viable: 2           # Min 2 signals for viable source
        auto_promotion_scans: 5             # 5 consecutive successes → propose promotion
        candidate_retention_days: 30        # Keep undecided candidates for 30 days
        frontiers_config: "env-scanning/config/exploration-frontiers.yaml"
        gate_script: "env-scanning/core/exploration_gate.py"  # Programmatic enforcement (v2.5.1)
        frontier_selector_script: "env-scanning/core/frontier_selector.py"  # VP-5 depends on this (SOT-050)

      scan_window:
        lookback_hours: 24         # 만 24시간 — 일일 스캐닝의 절대 기준
        tolerance_minutes: 30      # 게시 시간 파싱 오차 허용 (±30분)
        enforce: "strict"          # strict = 범위 외 시그널 제거
        post_filter: true          # 수집 후 프로그래매틱 필터링 실행

    checkpoints:
      step_1_4: "optional"
      step_2_5: "required"
      step_3_4: "required"

    validate_profile: "standard"

  # ────────────────────────────────────────────
  # WF2: arXiv Academic Deep Scanning
  # ────────────────────────────────────────────
  wf2-arxiv:
    name: "arXiv Academic Deep Scanning"
    name_ko: "arXiv 학술 심층 스캐닝"
    description: "arXiv-only deep scanning with extended parameters"
    enabled: true
    execution_order: 2

    orchestrator: ".claude/agents/arxiv-scan-orchestrator.md"
    sources_config: "env-scanning/config/sources-arxiv.yaml"
    exclusive_sources: ["arXiv"]  # This workflow scans ONLY arXiv

    data_root: "env-scanning/wf2-arxiv"
    paths:
      raw: "raw/"
      structured: "structured/"
      filtered: "filtered/"
      analysis: "analysis/"
      signals_db: "signals/database.json"
      signals_snapshots: "signals/snapshots/"
      reports_daily: "reports/daily/"
      reports_archive: "reports/archive/"
      context: "context/"
      logs: "logs/"
      evolution_index: "signals/evolution-index.json"
      evolution_maps: "analysis/evolution/"

    parameters:
      days_back: 14  # DEPRECATED — use scan_window.lookback_hours instead
      max_results_per_category: 50
      arxiv_extended_categories: true
      marathon_mode: false  # Single source, marathon not needed
      scan_window:
        lookback_hours: 48         # arXiv: 48시간 (게시 지연 감안)
        tolerance_minutes: 60      # 학술 논문은 시간대 불명확
        enforce: "strict"          # strict = 범위 외 시그널 제거
        post_filter: true          # 수집 후 프로그래매틱 필터링 실행
        exception_reason: "arXiv batch posting delay (daily at ~20:00 EST, 1-2 day submission-to-posting lag)"

    checkpoints:
      step_1_4: "optional"
      step_2_5: "required"
      step_3_4: "required"

    validate_profile: "standard"

  # ────────────────────────────────────────────
  # WF3: Naver News Environmental Scanning
  # ────────────────────────────────────────────
  wf3-naver:
    name: "Naver News Environmental Scanning"
    name_ko: "네이버 뉴스 환경스캐닝"
    description: "Naver News crawling with FSSF classification, Three Horizons tagging, and Tipping Point detection"
    enabled: true
    execution_order: 3

    orchestrator: ".claude/agents/naver-scan-orchestrator.md"
    sources_config: "env-scanning/config/sources-naver.yaml"
    exclusive_sources: ["NaverNews"]  # This workflow scans ONLY Naver News

    data_root: "env-scanning/wf3-naver"
    paths:
      raw: "raw/"
      structured: "structured/"
      filtered: "filtered/"
      analysis: "analysis/"
      signals_db: "signals/database.json"
      signals_snapshots: "signals/snapshots/"
      reports_daily: "reports/daily/"
      reports_archive: "reports/archive/"
      context: "context/"
      logs: "logs/"
      health: "health/"
      evolution_index: "signals/evolution-index.json"
      evolution_maps: "analysis/evolution/"

    parameters:
      fssf_classification: true       # FSSF 8-type signal taxonomy
      three_horizons_tagging: true    # H1/H2/H3 time horizon classification
      tipping_point_detection: true   # Critical Slowing Down, Flickering detection
      anomaly_detection: true         # Statistical + Structural anomaly detection
      marathon_mode: false            # Single source, marathon not needed
      scan_window:
        lookback_hours: 24         # 만 24시간 — 일일 스캐닝의 절대 기준
        tolerance_minutes: 30      # 게시 시간 파싱 오차 허용 (±30분)
        enforce: "strict"          # strict = 범위 외 시그널 제거
        post_filter: true          # 수집 후 프로그래매틱 필터링 실행

    checkpoints:
      step_1_4: "optional"
      step_2_5: "required"
      step_3_4: "required"

    validate_profile: "naver"

  # ────────────────────────────────────────────
  # WF4: Multi&Global-News Environmental Scanning
  # ────────────────────────────────────────────
  wf4-multiglobal-news:
    name: "Multi&Global-News Environmental Scanning"
    name_ko: "멀티글로벌 뉴스 환경스캐닝"
    description: "Direct crawling of 43 global news sites with FSSF classification, Three Horizons tagging, Tipping Point detection, and multilingual translation"
    enabled: true
    execution_order: 4

    orchestrator: ".claude/agents/multiglobal-news-scan-orchestrator.md"
    sources_config: "env-scanning/config/sources-multiglobal-news.yaml"
    exclusive_sources: ["MultiGlobalNews"]  # This workflow scans ONLY the 43 direct news sites

    data_root: "env-scanning/wf4-multiglobal-news"
    paths:
      raw: "raw/"
      structured: "structured/"
      filtered: "filtered/"
      analysis: "analysis/"
      signals_db: "signals/database.json"
      signals_snapshots: "signals/snapshots/"
      reports_daily: "reports/daily/"
      reports_archive: "reports/archive/"
      context: "context/"
      logs: "logs/"
      health: "health/"
      evolution_index: "signals/evolution-index.json"
      evolution_maps: "analysis/evolution/"

    parameters:
      fssf_classification: true       # FSSF 8-type signal taxonomy
      three_horizons_tagging: true    # H1/H2/H3 time horizon classification
      tipping_point_detection: true   # Critical Slowing Down, Flickering detection
      anomaly_detection: true         # Statistical + Structural anomaly detection
      translation_enabled: true       # Multilingual→EN + EN→KO translation pipeline
      marathon_mode: false            # Single orchestrated crawl, marathon not needed
      scan_window:
        lookback_hours: 24         # 만 24시간 — 일일 스캐닝의 절대 기준
        tolerance_minutes: 30      # 게시 시간 파싱 오차 허용 (±30분)
        enforce: "strict"          # strict = 범위 외 시그널 제거
        post_filter: true          # 수집 후 프로그래매틱 필터링 실행

    checkpoints:
      step_1_4: "optional"
      step_2_5: "required"
      step_3_4: "required"

    validate_profile: "multiglobal-news"

# ================================================================
# INTEGRATION DEFINITION
# ================================================================

integration:
  enabled: true
  merger_agent: ".claude/agents/workers/report-merger.md"
  output_root: "env-scanning/integrated"

  paths:
    reports_daily: "reports/daily/"
    reports_archive: "reports/archive/"
    logs: "logs/"

  # Merge scope: reports only. Signal DBs remain independent.
  # No feedback loop — integrated output does NOT feed back into individual workflows.
  merge_scope: "reports_only"

  # ── Integration Method ──
  # "agent-team": Use Agent Teams for collaborative multi-perspective integration
  #               (5 teammates: WF1 analyst, WF2 analyst, WF3 analyst, WF4 analyst, synthesizer)
  #               Enables inter-agent discussion for deeper cross-workflow analysis.
  # "single-agent": Use traditional single report-merger subagent (legacy, fallback)
  #
  # If agent-team fails at runtime, master-orchestrator auto-falls back to single-agent.
  integration_method: "agent-team"

  merge_strategy:
    # No source overlap between WF1, WF2, and WF3, so no signal dedup needed at merge.
    # Merger combines signals from all three reports and re-ranks by pSST.
    signal_dedup: false
    ranking_method: "pSST_unified"
    integrated_top_signals: 20
    cross_workflow_analysis: true  # Analyze WF1↔WF2↔WF3↔WF4 signal interactions

  integrated_skeleton: ".claude/skills/env-scanner/references/integrated-report-skeleton.md"
  validate_profile: "integrated"

  checkpoints:
    final_approval: "required"

  # ────────────────────────────────────────────
  # Weekly Meta-Analysis Mode (v1.1.0, 2026-02-06)
  # ────────────────────────────────────────────
  # 주간 메타분석: 7일간 일일 스캔 결과를 거시적으로 재분석.
  # 새로운 소스 스캐닝 없음. 내부 축적 데이터 읽기 전용 접근.
  # 기존 일일 스캔(WF1→WF2→WF3→Merge)과 완전히 독립적으로 실행.
  weekly:
    enabled: true
    description: "주간 메타분석 - 7일간 일일 스캔 결과의 거시적 패턴 분석"

    # ── 트리거 조건 ──
    trigger:
      type: "manual"           # /env-scan:weekly로 수동 실행
      min_daily_scans: 5       # 최소 5일치 일일 스캔 필요
      lookback_days: 7         # 분석 대상: 최근 7일

    # ── 입력 (읽기 전용) ──
    inputs:
      wf1_reports: "wf1-general/reports/daily/"
      wf2_reports: "wf2-arxiv/reports/daily/"
      wf3_reports: "wf3-naver/reports/daily/"
      wf4_reports: "wf4-multiglobal-news/reports/daily/"
      integrated_reports: "integrated/reports/daily/"
      wf1_signals_db: "wf1-general/signals/database.json"
      wf2_signals_db: "wf2-arxiv/signals/database.json"
      wf3_signals_db: "wf3-naver/signals/database.json"
      wf4_signals_db: "wf4-multiglobal-news/signals/database.json"
      wf1_ranked: "wf1-general/analysis/"
      wf2_ranked: "wf2-arxiv/analysis/"
      wf3_ranked: "wf3-naver/analysis/"
      wf4_ranked: "wf4-multiglobal-news/analysis/"
      integrated_rankings: "integrated/"

    access_policy:
      wf1_data: "READ_ONLY"
      wf2_data: "READ_ONLY"
      wf3_data: "READ_ONLY"
      wf4_data: "READ_ONLY"
      integrated_daily: "READ_ONLY"
      weekly_output: "READ_WRITE"

    # ── 출력 ──
    output_root: "env-scanning/integrated/weekly"
    paths:
      reports: "reports/"
      reports_archive: "reports/archive/"
      analysis: "analysis/"
      logs: "logs/"

    # ── 스켈레톤 ──
    skeleton: ".claude/skills/env-scanner/references/weekly-report-skeleton.md"

    # ── 체크포인트 ──
    checkpoints:
      analysis_review: "required"    # Phase 2.5 분석 리뷰
      report_approval: "required"    # Phase 3.4 보고서 승인

    # ── 검증 프로파일 ──
    validate_profile: "weekly"

    # ── 주간 ID 체계 ──
    week_id_format: "ISO8601"  # {year}-W{week_number}, e.g., 2026-W06

    # ── TIS (추세 강도 점수) 가중치 ──
    tis_weights:
      n_sources: 0.30
      psst_delta: 0.30
      frequency: 0.20
      cross_domain: 0.20

    # ── 캘리브레이션 연동 ──
    calibration_integration:
      enabled: true
      source: "env-scanning/config/thresholds.yaml"
      section: "calibration"

# ================================================================
# STARTUP VALIDATION RULES
# ================================================================
# validate_registry.py executes these checks before any workflow runs.
# HALT = stop everything. CREATE = create missing directory. WARN = log and continue.

startup_validation:
  rules:
    - id: "SOT-001"
      check: "all_shared_invariants_exist"
      description: "All files in system.shared_invariants must exist"
      severity: "HALT"

    - id: "SOT-002"
      check: "all_orchestrators_exist"
      description: "All workflow orchestrator files must exist"
      severity: "HALT"

    - id: "SOT-003"
      check: "all_sources_configs_exist"
      description: "All workflow sources_config files must exist"
      severity: "HALT"

    - id: "SOT-004"
      check: "all_shared_workers_exist"
      description: "All shared worker agent files must exist"
      severity: "HALT"

    - id: "SOT-005"
      check: "all_data_roots_exist"
      description: "All workflow data_root directories exist (create subdirs if missing)"
      severity: "CREATE"

    - id: "SOT-006"
      check: "integration_output_root_exists"
      description: "Integration output_root directory exists (create if missing)"
      severity: "CREATE"

    - id: "SOT-007"
      check: "execution_order_unique_sequential"
      description: "Workflow execution_order values must be unique and sequential"
      severity: "HALT"

    - id: "SOT-008"
      check: "protocol_file_exists"
      description: "system.execution.protocol file must exist"
      severity: "HALT"

    - id: "SOT-009"
      check: "integrated_skeleton_exists"
      description: "integration.integrated_skeleton file must exist"
      severity: "HALT"

    - id: "SOT-010"
      check: "arxiv_disabled_in_wf1"
      description: "arXiv source must be enabled:false in WF1 sources_config"
      severity: "HALT"

    - id: "SOT-011"
      check: "arxiv_enabled_in_wf2"
      description: "arXiv source must be enabled:true in WF2 sources_config"
      severity: "HALT"

    - id: "SOT-012"
      check: "no_source_overlap"
      description: "No enabled source appears in both WF1 and WF2 sources_config"
      severity: "HALT"

    - id: "SOT-013"
      check: "merger_agent_exists"
      description: "integration.merger_agent file must exist"
      severity: "HALT"

    - id: "SOT-014"
      check: "execution_integrity_section_exists"
      description: "execution_integrity section must exist in registry"
      severity: "HALT"

    - id: "SOT-015"
      check: "scg_rules_valid"
      description: "All SCG rules have required fields (id, name, severity, checks)"
      severity: "HALT"

    - id: "SOT-016"
      check: "poe_schema_valid"
      description: "PoE schema has all required_fields defined"
      severity: "HALT"

    - id: "SOT-017"
      check: "weekly_skeleton_exists"
      description: "Weekly report skeleton file must exist if weekly enabled"
      severity: "HALT"
      condition: "integration.weekly.enabled == true"

    - id: "SOT-018"
      check: "weekly_output_root_exists"
      description: "Weekly output directories must exist (create if missing)"
      severity: "CREATE"
      condition: "integration.weekly.enabled == true"

    - id: "SOT-019"
      check: "weekly_validate_profile_defined"
      description: "Weekly validate_profile must be defined in integration.weekly"
      severity: "HALT"
      condition: "integration.weekly.enabled == true"

    - id: "SOT-020"
      check: "wf3_naver_source_exclusive"
      description: "NaverNews source must be enabled in WF3 sources config"
      severity: "HALT"
      condition: "workflows.wf3-naver.enabled == true"

    - id: "SOT-021"
      check: "wf3_orchestrator_exists"
      description: "WF3 orchestrator file must exist"
      severity: "HALT"
      condition: "workflows.wf3-naver.enabled == true"

    - id: "SOT-022"
      check: "wf3_data_root_exists"
      description: "WF3 data_root directory exists (create subdirs if missing)"
      severity: "CREATE"
      condition: "workflows.wf3-naver.enabled == true"

    - id: "SOT-023"
      check: "wf3_sources_config_exists"
      description: "WF3 sources_config file must exist"
      severity: "HALT"
      condition: "workflows.wf3-naver.enabled == true"

    # ── Cross-Platform System Prompt Validation ──
    - id: "SOT-024"
      check: "canonical_system_prompt_exists"
      description: "Canonical system prompt file (AGENTS.md) must exist"
      severity: "HALT"

    - id: "SOT-025"
      check: "agents_md_contains_required_references"
      description: "AGENTS.md must reference all required SOT files"
      severity: "HALT"

    - id: "SOT-026"
      check: "agents_md_contains_immutable_keywords"
      description: "AGENTS.md must contain all required immutable rule keywords"
      severity: "HALT"

    - id: "SOT-026b"
      check: "agents_md_tier1_values_match_core_invariants"
      description: "AGENTS.md Tier 1 values must match core-invariants.yaml structurally"
      severity: "HALT"

    - id: "SOT-027"
      check: "tool_specific_prompt_files_exist"
      description: "Tool-specific system prompt files (CLAUDE.md, GEMINI.md) should exist"
      severity: "WARN"

    - id: "SOT-028"
      check: "tool_specific_files_import_canonical"
      description: "Tool-specific files must @import the canonical file"
      severity: "WARN"

    - id: "SOT-029"
      check: "integration_method_valid"
      description: "integration.integration_method must be 'agent-team' or 'single-agent'"
      severity: "HALT"

    # ── Temporal Consistency Validation (v2.2.0) ──
    - id: "SOT-030"
      check: "scan_window_valid"
      description: "Each enabled workflow must have scan_window with valid lookback_hours [1,168] and enforce in {strict, lenient}"
      severity: "HALT"

    - id: "SOT-031"
      check: "temporal_consistency_section_exists"
      description: "system.temporal_consistency section must exist with required fields"
      severity: "HALT"

    - id: "SOT-032"
      check: "temporal_python_scripts_exist"
      description: "temporal_consistency Python enforcement scripts (anchor, gate, injector, statistics) must exist"
      severity: "HALT"

    # ── Signal Evolution Validation (v2.3.0) ──
    - id: "SOT-034"
      check: "signal_evolution_section_valid"
      description: "system.signal_evolution section exists with valid thresholds and tracker_script exists"
      severity: "HALT"
      condition: "system.signal_evolution.enabled == true"

    - id: "SOT-035"
      check: "evolution_paths_exist_in_enabled_workflows"
      description: "Each enabled workflow must have evolution_index and evolution_maps paths"
      severity: "CREATE"
      condition: "system.signal_evolution.enabled == true"

    # ── Timeline Map Validation (v2.4.0) ──
    - id: "SOT-036"
      check: "timeline_map_configuration_valid"
      description: "system.signal_evolution.timeline_map settings are valid (optional, supplementary output)"
      severity: "WARN"
      condition: "system.signal_evolution.timeline_map exists"

    # ── Source Exploration Validation (v2.5.0) ──
    - id: "SOT-037"
      check: "exploration_config_valid"
      description: "source_exploration parameters valid if enabled"
      severity: "HALT"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    - id: "SOT-038"
      check: "exploration_paths_exist"
      description: "WF1 exploration directories exist (create if missing)"
      severity: "CREATE"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    - id: "SOT-039"
      check: "exploration_agents_exist"
      description: "Exploration orchestrator and worker agent files must exist"
      severity: "HALT"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    - id: "SOT-040"
      check: "exploration_frontiers_config_exists"
      description: "exploration-frontiers.yaml must exist if exploration enabled"
      severity: "HALT"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    - id: "SOT-041"
      check: "exploration_gate_script_exists"
      description: "exploration gate_script Python file must exist if exploration enabled"
      severity: "HALT"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    # ── Dedup Index Freshness (v2.6.0) ──
    - id: "SOT-042"
      check: "dedup_index_freshness"
      description: "Dedup index (previous-signals.json) must be recent (<48h) for enabled workflows"
      severity: "WARN"

    # ── STEEPs Source Coverage (v2.7.0) ──
    - id: "SOT-043"
      check: "steeps_source_base_coverage"
      description: "All 6 STEEPs categories must have at least 1 enabled source with matching steeps_focus"
      severity: "WARN"

    # ── Dedup Gate Validation (v2.6.0→v2.9.0) ──
    - id: "SOT-044"
      check: "dedup_gate_section_valid"
      description: "system.dedup_gate section exists with required fields (enabled, gate_script, thresholds [A/B/C/D], lookback_days, enforce)"
      severity: "HALT"
    - id: "SOT-045"
      check: "dedup_gate_script_exists"
      description: "Dedup gate Python script referenced in SOT must exist on disk"
      severity: "HALT"

    # ── Bilingual System Validation (v2.8.0) ──
    - id: "SOT-046"
      check: "bilingual_section_valid"
      description: "system.bilingual section exists with required fields (enabled, internal_language, external_language)"
      severity: "HALT"
      condition: "system.bilingual.enabled == true"

    - id: "SOT-047"
      check: "bilingual_scripts_exist"
      description: "Bilingual Python scripts (skeleton_mirror, translation_validator) must exist"
      severity: "HALT"
      condition: "system.bilingual.enabled == true"

    - id: "SOT-048"
      check: "bilingual_en_skeletons_exist"
      description: "All English skeleton files referenced in system.bilingual.skeletons_en must exist"
      severity: "HALT"
      condition: "system.bilingual.enabled == true"

    - id: "SOT-049"
      check: "bilingual_en_profiles_implemented"
      description: "All EN validate_profiles derived by bilingual_resolver ({base}_en) must exist in validate_report.py PROFILES"
      severity: "HALT"
      condition: "system.bilingual.enabled == true and system.bilingual.internal_language == en"

    # ── Source Exploration Frontier Selector (v2.5.2) ──
    - id: "SOT-050"
      check: "frontier_selector_script_exists"
      description: "frontier_selector.py must exist — VP-5 (exploration_gate.py verify) depends on the file it creates"
      severity: "HALT"
      condition: "workflows.wf1-general.parameters.source_exploration.enabled == true"

    # ── WF4 Multi&Global-News Validation (v2.10.0) ──
    - id: "SOT-051"
      check: "wf4_multiglobal_source_exclusive"
      description: "MultiGlobalNews source must be enabled in WF4 sources config"
      severity: "HALT"
      condition: "workflows.wf4-multiglobal-news.enabled == true"

    - id: "SOT-052"
      check: "wf4_orchestrator_exists"
      description: "WF4 orchestrator file must exist"
      severity: "HALT"
      condition: "workflows.wf4-multiglobal-news.enabled == true"

    - id: "SOT-053"
      check: "wf4_data_root_exists"
      description: "WF4 data_root directory exists (create subdirs if missing)"
      severity: "CREATE"
      condition: "workflows.wf4-multiglobal-news.enabled == true"

    - id: "SOT-054"
      check: "wf4_sources_config_exists"
      description: "WF4 sources_config file must exist"
      severity: "HALT"
      condition: "workflows.wf4-multiglobal-news.enabled == true"

    # ── Profile Validity Validation (v2.2.1) ──
    - id: "SOT-033"
      check: "validate_profile_values_implemented"
      description: "All validate_profile values in enabled workflows must map to implemented profiles in validate_report.py"
      severity: "HALT"

# ================================================================
# EXECUTION INTEGRITY (v1.0.0)
# ================================================================
# 이 섹션은 워크플로우 실행의 무결성을 보장하기 위한
# 상태 관리, 실행 증명, 일관성 검증 규칙을 정의합니다.
#
# RULES:
#   1. validate_state_consistency.py MUST read this section at execution
#   2. 모든 상태 파일 경로는 이 섹션의 패턴을 따라야 함
#   3. 실행 증명(PoE)은 이 섹션의 스키마를 준수해야 함
#   4. SCG 검증은 이 섹션의 규칙을 따라야 함
# ================================================================

execution_integrity:
  version: "1.0.0"

  # ── 상태 파일 패턴 정의 ──
  # 모든 오케스트레이터는 이 패턴을 사용해야 함
  state_file_patterns:
    # 날짜별 상태 파일 (신규)
    workflow_status_dated: "{data_root}/logs/workflow-status-{date}.json"
    # 최신 상태 파일 (기존 호환)
    workflow_status_latest: "{data_root}/logs/workflow-status-latest.json"
    # 마스터 상태 파일 (날짜별)
    master_status_dated: "{integration_root}/logs/master-status-{date}.json"
    # 마스터 최신 상태 파일
    master_status_latest: "{integration_root}/logs/master-status-latest.json"
    # 주간 상태 파일 (v1.1.0)
    weekly_status: "{integration_root}/weekly/logs/weekly-status-{week_id}.json"

  # ── 실행 증명 (Proof of Execution) 스키마 ──
  proof_of_execution:
    enabled: true
    location: "scan_metadata.execution_proof"

    required_fields:
      - name: "execution_id"
        type: "string"
        format: "{workflow_id}-{date}-{time}-{random4}"
        example: "wf1-scan-2026-02-06-09-15-42-a3f2"

      - name: "started_at"
        type: "string"
        format: "ISO8601"

      - name: "completed_at"
        type: "string"
        format: "ISO8601"

      - name: "actual_api_calls"
        type: "object"
        required_keys: ["web_search", "arxiv_api"]

      - name: "actual_sources_scanned"
        type: "array"
        min_length: 1

      - name: "file_created_at"
        type: "string"
        format: "ISO8601"

    validation_rules:
      timestamp_tolerance_minutes: 5
      min_total_api_calls: 1
      validate_execution_id_format: true

  # ── 상태 일관성 검증 게이트 (SCG) ──
  state_consistency_gate:
    enabled: true
    execute_at:
      - "startup"
      - "phase_transition"
      - "completion"

    layers:
      - id: "SCG-L1"
        name: "SOT ↔ Master Status"
        description: "SOT와 마스터 상태 파일 간 일관성 검증"
        severity: "HALT"
        checks:
          - id: "SCG-L1-001"
            name: "registry_version_match"
            description: "SOT version과 master_status.registry_version 일치"
          - id: "SCG-L1-002"
            name: "workflow_list_match"
            description: "SOT workflows 목록과 master_status.workflow_results 키 일치"

      - id: "SCG-L2"
        name: "Master Status ↔ WF Status"
        description: "마스터 상태와 개별 워크플로우 상태 간 일관성 검증"
        severity: "HALT"
        checks:
          - id: "SCG-L2-001"
            name: "wf_status_match"
            description: "master.workflow_results[wf].status == wf_status.status"
          - id: "SCG-L2-002"
            name: "date_match"
            description: "모든 상태 파일의 날짜가 오늘 날짜와 일치"
          - id: "SCG-L2-003"
            name: "execution_id_prefix_match"
            description: "master.execution_id 접미사와 wf_status.execution_id 접미사 일치"

      - id: "SCG-L3"
        name: "WF Status ↔ Raw Data"
        description: "워크플로우 상태와 실제 데이터 파일 간 일관성 검증"
        severity: "HALT"
        checks:
          - id: "SCG-L3-001"
            name: "raw_file_exists"
            description: "wf_status.status=completed → raw 파일 존재"
          - id: "SCG-L3-002"
            name: "poe_valid"
            description: "raw 파일의 execution_proof가 스키마 준수"
          - id: "SCG-L3-003"
            name: "poe_execution_id_match"
            description: "wf_status.execution_id == raw.execution_proof.execution_id"
          - id: "SCG-L3-004"
            name: "poe_timestamp_valid"
            description: "파일 mtime과 poe.file_created_at 차이 < tolerance"
          - id: "SCG-L3-005"
            name: "poe_min_api_calls"
            description: "actual_api_calls 합계 >= min_total_api_calls"

      - id: "SCG-L5"
        name: "Weekly ↔ Daily Consistency"
        description: "주간 분석이 참조한 일일 데이터와의 일관성 검증"
        severity: "WARN"
        applies_to: "weekly"
        checks:
          - id: "SCG-L5-001"
            name: "weekly_daily_report_count_match"
            description: "주간 분석에서 참조한 일일 보고서 수 == 실제 존재하는 보고서 수"
          - id: "SCG-L5-002"
            name: "weekly_signal_count_consistency"
            description: "주간 통계의 총 신호 수 ≤ 일일 보고서들의 신호 수 합계"
          - id: "SCG-L5-003"
            name: "weekly_date_range_valid"
            description: "주간 분석 대상 날짜 범위가 lookback_days 이내"

      - id: "SCG-L4"
        name: "Raw Data ↔ Report"
        description: "데이터 파일과 보고서 간 일관성 검증"
        severity: "WARN"
        checks:
          - id: "SCG-L4-001"
            name: "signal_count_consistent"
            description: "raw.items.length >= report.signal_count"
          - id: "SCG-L4-002"
            name: "report_date_match"
            description: "report 파일명 날짜 == raw 파일 날짜"

    failure_actions:
      HALT: "워크플로우 즉시 중단, 사용자에게 불일치 보고, 수동 해결 요청"
      WARN: "경고 로그 기록, 사용자에게 알림, 워크플로우 계속 진행"

  # ── 사전 실행 검증 (Pre-Execution Check) ──
  pre_execution_check:
    enabled: true
    checks:
      - id: "PEC-001"
        name: "today_status_exists"
        description: "오늘 날짜 상태 파일 존재 여부 확인"
        on_exists:
          completed: "이미 완료됨. 재실행 확인 요청"
          in_progress: "진행 중. 이어서 실행 또는 재시작 확인 요청"
          failed: "실패 상태. 재시도 확인 요청"
        on_not_exists: "신규 실행 시작"

      - id: "PEC-002"
        name: "previous_day_completed"
        description: "전일 상태 확인 (경고용)"
        severity: "WARN"

      - id: "PEC-003"
        name: "weekly_data_sufficiency"
        description: "주간 분석에 필요한 최소 일일 스캔 수 확인"
        applies_to: "weekly"
        min_daily_scans: 5
        lookback_days: 7
        on_insufficient: "경고 표시 후 사용자 확인 요청"

# ================================================================
# CROSS-PLATFORM SYSTEM PROMPTS
# ================================================================
# This section defines the system prompt files that instruct AI CLI
# tools to follow this workflow's methodology. These files are part
# of the SOT ecosystem and are validated by validate_registry.py.
#
# Architecture:
#   AGENTS.md (canonical router) ← Tier 1 immutable rules inline
#       │                           + Tier 2 SOT file references
#       ├── CLAUDE.md (@import AGENTS.md + Claude Code specifics)
#       └── GEMINI.md (@import AGENTS.md + Gemini CLI specifics)
#
# AGENTS.md is read natively by: Codex CLI, GitHub Copilot, Cursor, Cline
# CLAUDE.md is read by: Claude Code
# GEMINI.md is read by: Gemini CLI
#
# RULES:
#   1. AGENTS.md MUST exist — it is the canonical methodology router
#   2. AGENTS.md MUST reference all required_references files
#   3. AGENTS.md MUST inline all required_inline_sections from core-invariants
#   4. Tool-specific files MUST @import AGENTS.md (not duplicate content)
#   5. Mutable parameters are NEVER copied into AGENTS.md — only referenced
# ================================================================

system_prompts:
  # ── Canonical Router Document ──
  canonical: "AGENTS.md"
  description: "Cross-platform methodology router read by all AI CLI tools"

  # ── Tool-Specific Wrappers ──
  tool_specific:
    claude_code:
      file: "CLAUDE.md"
      import_target: "AGENTS.md"
    gemini_cli:
      file: "GEMINI.md"
      import_target: "AGENTS.md"

  # ── Tier 1: Immutable Rules Source ──
  # These rules are inlined in AGENTS.md because they are immutable (never drift).
  # SOT-026 validates that AGENTS.md contains matching keywords.
  immutable_source: "env-scanning/config/core-invariants.yaml"
  required_inline_sections:
    - id: "steeps_categories"
      keywords: ["STEEPs", "Social", "Technological", "Economic", "Environmental", "Political", "spiritual"]
    - id: "workflow_phases"
      keywords: ["Phase 1", "Phase 2", "Phase 3", "Research", "Planning", "Implementation"]
    - id: "vev_protocol"
      keywords: ["VEV", "Verify-Execute-Verify", "PRE-VERIFY", "POST-VERIFY"]
    - id: "workflow_independence"
      keywords: ["WF1", "WF2", "WF3", "WF4", "independent"]
    - id: "bilingual_protocol"
      keywords: ["bilingual", "internal", "external", "en", "ko"]
    - id: "database_atomicity"
      keywords: ["atomic", "snapshot", "restore"]
    - id: "skeleton_fill"
      keywords: ["skeleton", "template"]
    - id: "quality_defense"
      keywords: ["4-Layer", "validate_report"]
    - id: "temporal_consistency"
      keywords: ["Temporal Consistency", "scan window", "lookback_hours", "T₀"]

  # ── Tier 2: Required References ──
  # AGENTS.md MUST contain these file paths as text (routing the AI to real SOT).
  # SOT-025 validates their presence.
  required_references:
    - "env-scanning/config/workflow-registry.yaml"
    - "env-scanning/config/core-invariants.yaml"
    - "env-scanning/scripts/validate_report.py"
    - "env-scanning/scripts/validate_registry.py"
