{
  "agent_metadata": {
    "agent_name": "arxiv-agent",
    "model_used": "sonnet",
    "papers_collected": 120,
    "steeps_categories_scanned": 6,
    "scan_date": "2026-02-10",
    "status": "success",
    "execution_time": 15.93,
    "process_id": 64685
  },
  "items": [
    {
      "id": "arxiv-2602.09024v1",
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09024v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09024v1",
        "authors": [
          "Qihang Yu",
          "Qihao Liu",
          "Ju He"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.514373",
      "entities": [
        "Autoregressive Image Generation",
        "ImageNet-256",
        "Transformer",
        "Framework",
        "NSF",
        "BAR",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09023v1",
      "title": "TwinRL-VLA: Digital Twin-Driven Reinforcement Learning for Real-World Robotic Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09023v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Despite strong generalization capabilities, Vision-Language-Action (VLA) models remain constrained by the high cost of expert demonstrations and insufficient real-world interaction. While online reinforcement learning (RL) has shown promise in improving general foundation models, applying RL to VLA manipulation in real-world settings is still hindered by low exploration efficiency and a restricted exploration space. Through systematic real-world experiments, we observe that the effective exploration space of online RL is closely tied to the data distribution of supervised fine-tuning (SFT). Motivated by this observation, we propose TwinRL, a digital twin-real-world collaborative RL framework designed to scale and guide exploration for VLA models. First, a high-fidelity digital twin is efficiently reconstructed from smartphone-captured scenes, enabling realistic bidirectional transfer between real and simulated environments. During the SFT warm-up stage, we introduce an exploration space expansion strategy using digital twins to broaden the support of the data trajectory distribution. Building on this enhanced initialization, we propose a sim-to-real guided exploration strategy to further accelerate online RL. Specifically, TwinRL performs efficient and parallel online RL in the digital twin prior to deployment, effectively bridging the gap between offline and online training stages. Subsequently, we exploit efficient digital twin sampling to identify failure-prone yet informative configurations, which are used to guide targeted human-in-the-loop rollouts on the real robot. In our experiments, TwinRL approaches 100% success in both in-distribution regions covered by real-world demonstrations and out-of-distribution regions, delivering at least a 30% speedup over prior real-world RL methods and requiring only about 20 minutes on average across four tasks.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09023v1",
        "authors": [
          "Qinwen Xu",
          "Jiaming Liu",
          "Rui Zhou"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.514787",
      "entities": [
        "World Robotic Manipulation Despite",
        "Driven Reinforcement Learning",
        "Digital Twin",
        "Framework",
        "Robot",
        "Act",
        "SFT",
        "VLA",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09022v1",
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09022v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09022v1",
        "authors": [
          "Zehan Wang",
          "Tengfei Wang",
          "Haiyu Zhang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.515019",
      "entities": [
        "Complementary Reward Functions",
        "Reinforcement Learning",
        "Framework",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09021v1",
      "title": "$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09021v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09021v1",
        "authors": [
          "Checheng Yu",
          "Chonghao Sima",
          "Gangcheng Jiang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.515888",
      "entities": [
        "Taming Distributional Inconsistencies High",
        "Aware Robust Manipulation",
        "Deploy Alignment",
        "Model Arithmetic",
        "Stage Advantage",
        "Framework",
        "Policy",
        "Robot",
        "MIT",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09020v1",
      "title": "Hybrid Method of Efficient Simulation of Physics Applications for a Quantum Computer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09020v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Quantum chemistry and materials science are among the most promising areas for demonstrating algorithmic quantum advantage and quantum utility due to their inherent quantum mechanical nature. Still, large-scale simulations of quantum circuits are essential for determining the problem size at which quantum solutions outperform classical methods. In this work, we present a novel hybrid simulation approach, forming a hybrid of a fullstate and a Clifford simulator, specifically designed to address the computational challenges associated with the time evolution of quantum chemistry Hamiltonians. Our method focuses on the efficient emulation of multi-qubit rotations, a critical component of Trotterized Hamiltonian evolution. By optimizing the representation and execution of multi-qubit operations leveraging the Pauli frame, our approach significantly reduces the computational cost of simulating quantum circuits, enabling more efficient simulations. Beyond its impact on chemistry applications, our emulation strategy has broad implications for any computational workload that relies heavily on multi-qubit rotations. By increasing the efficiency of quantum simulations, our method facilitates more accurate and cost-effective studies of complex quantum systems. We quantify the performance improvements and computational savings for this emulation strategy, and we obtain a speedup of a factor $\\approx 18$ ($\\approx 22$ with MPI) for our evaluated chemistry Hamiltonians with 24 qubits. Thus, we evaluate our integration of this emulation strategy into the Intel Quantum SDK, further bridging the gap between theoretical algorithm development and practical quantum software implementations.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09020v1",
        "authors": [
          "Carla Rieger",
          "Albert T. Schmitz",
          "Gehad Salem"
        ],
        "arxiv_categories": [
          "quant-ph"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.516220",
      "entities": [
        "Quantum Computer Quantum",
        "Trotterized Hamiltonian",
        "Efficient Simulation",
        "Physics Applications",
        "Hybrid Method",
        "Intel Quantum",
        "Intel",
        "MPI",
        "Act",
        "SDK",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09018v1",
      "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09018v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.",
        "keywords": [
          "cs.CV",
          "cs.LG",
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09018v1",
        "authors": [
          "Amir Mallak",
          "Alaa Maalouf"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.LG",
          "cs.RO",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.516579",
      "entities": [
        "Factorized Comprehensive Study",
        "Based Driving Out",
        "Robustness Is",
        "Policy",
        "VISTA",
        "Act",
        "OOD",
        "CNN",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09017v1",
      "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09017v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/",
        "keywords": [
          "cs.LG",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09017v1",
        "authors": [
          "Zichen Jeff Cui",
          "Omar Rayyan",
          "Haritheja Etukuru"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.516794",
      "entities": [
        "Contact Conditioning Creates Strong",
        "Anchored Policies",
        "Policy",
        "Robot",
        "Act",
        "CAP",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09016v1",
      "title": "Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09016v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09016v1",
        "authors": [
          "Hao Phung",
          "Hadar Averbuch-Elor"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.517051",
      "entities": [
        "Floorplan Reconstruction Reconstructing",
        "Polygon Sequence Generation",
        "Standard",
        "WAFFLE",
        "Wind",
        "CAD",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09015v1",
      "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09015v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09015v1",
        "authors": [
          "Fatemeh Nejati",
          "Mahdi Rabbani",
          "Mansur Mirani"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.517376",
      "entities": [
        "Quishing Attachment Detection Phishing",
        "Convolutional Neural Networks",
        "Machine Learning",
        "Neural Network",
        "Microsoft Word",
        "Format Dataset",
        "Decision Tree",
        "Random Forest",
        "Unified Multi",
        "Microsoft",
        "Standard",
        "HTML",
        "Meta",
        "SHAP",
        "CIC"
      ]
    },
    {
      "id": "arxiv-2602.09014v1",
      "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09014v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09014v1",
        "authors": [
          "Zihan Yang",
          "Shuyuan Tu",
          "Licheng Zhang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.517686",
      "entities": [
        "Linear Flow Distillation Diffusion",
        "Image Generation",
        "Precision Non",
        "Framework",
        "Step Text",
        "Fusion",
        "FLUX",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09013v1",
      "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09013v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09013v1",
        "authors": [
          "Hongyi Chen",
          "Tony Dong",
          "Tiancheng Wu"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.517941",
      "entities": [
        "Object Trajectory Reconstruction Multi",
        "Dexterous Manipulation Policies",
        "Human Videos",
        "Inspire Hand",
        "Framework",
        "Policy",
        "Robot",
        "LEAP",
        "Act",
        "MIT",
        "RGB",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09012v1",
      "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09012v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.",
        "keywords": [
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09012v1",
        "authors": [
          "Jiacheng Liu",
          "Yaxin Luo",
          "Jiacheng Cui"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.518158",
      "entities": [
        "Cognitive Gap",
        "Framework",
        "GPT-5.2",
        "Act",
        "GUI",
        "GPT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09009v1",
      "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09009v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09009v1",
        "authors": [
          "Yilang Zhang",
          "Bingcong Li",
          "Niao He"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.518350",
      "entities": [
        "Adaptive Neural Connection Reassignment",
        "Efficient Depth Scaling Scaling",
        "Neural Network",
        "Framework",
        "Fusion",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09007v1",
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09007v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09007v1",
        "authors": [
          "Haodong Li",
          "Jingwei Wu",
          "Quan Sun"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.518606",
      "entities": [
        "Benchmarking Image Generation Models",
        "Graphical User Interface",
        "Content Consistency",
        "Environments Recent",
        "Interaction Logic",
        "Goal Achievement",
        "Visual Quality",
        "Act",
        "GUI",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09006v1",
      "title": "ARO: A New Lens On Matrix Optimization For Large Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09006v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.",
        "keywords": [
          "cs.LG",
          "math.OC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09006v1",
        "authors": [
          "Wenbo Gong",
          "Javier Zazo",
          "Qijun Luo"
        ],
        "arxiv_categories": [
          "cs.LG",
          "math.OC",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.518851",
      "entities": [
        "Adaptively Rotated Optimization",
        "Optimization For Large Models",
        "New Lens On Matrix",
        "Framework",
        "Protocol",
        "Policy",
        "Act",
        "ARO",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09003v1",
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09003v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09003v1",
        "authors": [
          "Yudong Wang",
          "Zixuan Fu",
          "Hengyu Zhao"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.519171",
      "entities": [
        "Artificial Intelligence",
        "Technology Towards",
        "Data Science",
        "Framework",
        "Intel",
        "Act",
        "AGI",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09002v1",
      "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09002v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09002v1",
        "authors": [
          "Zilin Fang",
          "Anxing Xiao",
          "David Hsu"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.519390",
      "entities": [
        "Informed Path Selection Navigating",
        "Robot Social Navigation",
        "From Obstacles",
        "Framework",
        "Robot",
        "Act",
        "VLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09000v1",
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09000v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09000v1",
        "authors": [
          "Ali Hatamizadeh",
          "Shrimai Prabhumoye",
          "Igor Gitman"
        ],
        "arxiv_categories": [
          "cs.AI"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.519678",
      "entities": [
        "Group Relative Policy Optimization",
        "Iterative Group Relative Policy",
        "Reasoning Large Language Models",
        "Proximal Policy Optimization",
        "Reinforcement Learning",
        "Framework",
        "In Stage",
        "Policy",
        "GRPO",
        "PPO",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08999v1",
      "title": "CLUE: Crossmodal disambiguation via Language-vision Understanding with attEntion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08999v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "With the increasing integration of robots into daily life, human-robot interaction has become more complex and multifaceted. A critical component of this interaction is Interactive Visual Grounding (IVG), through which robots must interpret human intentions and resolve ambiguity. Existing IVG models generally lack a mechanism to determine when to ask clarification questions, as they implicitly rely on their learned representations. CLUE addresses this gap by converting the VLM's cross-modal attention into an explicit, spatially grounded signal for deciding when to ask. We extract text to image attention maps and pass them to a lightweight CNN to detect referential ambiguity, while a LoRA fine-tuned decoder conducts the dialog and emits grounding location tokens. We train on a real-world interactive dataset for IVG, and a mixed ambiguity set for the detector. With InViG-only supervision, our model surpasses a state-of-the-art method while using parameter-efficient fine-tuning. Similarly, the ambiguity detector outperforms prior baselines. Overall, CLUE turns the internal cross-modal attention of a VLM into an explicit, spatially grounded signal for deciding when to ask. The data and code are publicly available at: mouadabrini.github.io/clue",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08999v1",
        "authors": [
          "Mouad Abrini",
          "Mohamed Chetouani"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.519899",
      "entities": [
        "Interactive Visual Grounding",
        "Robot",
        "CLUE",
        "Act",
        "VLM",
        "IVG",
        "MIT",
        "CNN",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08997v1",
      "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08997v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08997v1",
        "authors": [
          "Lavender Y. Jiang",
          "Xujin Chris Liu",
          "Kyunghyun Cho"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-10T18:45:49.520098",
      "entities": [
        "Safe Harbour",
        "Safe Harbor",
        "HIPAA",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08988v1",
      "title": "Analyzing Vaccine Manufacturing Supply Chain Disruptions for Pandemic Preparedness using Discrete-Event Simulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08988v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The COVID-19 pandemic exposed critical vulnerabilities in vaccine supply chains, highlighting the need for robust manufacturing for rapid pandemic response to support CEPI's 100 Days Mission. We develop a discrete-event simulation model to analyze supply chain disruptions and enables policymakers and vaccine manufacturers to quantify disruptions and assess mitigation strategies. Unlike prior studies examining components in isolation, our approach integrates production processes, quality assurance and control (QA/QC) activities, and raw material procurement to capture system-wide dynamics. A detailed mRNA case study analyzes disruption scenarios for a facility targeting 50 million doses: facility shutdowns, workforce reductions, raw material shortages, infrastructure failures, extended procurement lead times, and increased QA/QC capacity. Three main insights emerge. First, QA/QC personnel are the primary bottleneck, with utilization reaching 84.5% under normal conditions while machine utilization remains below 33%. Doubling QA/QC capacity increases annual output by 79.1%, offering greater returns than equipment investments. Second, raw material disruptions are highly detrimental, with extended lead times reducing three-year output by 19.6% and causing stockouts during 51.8% of production time. Third, the model shows differential resilience: acute disruptions (workforce shortages, shutdowns, power outages) allow recovery within 6 to 9 weeks, whereas chronic disruptions (supply delays) cause prolonged performance degradation.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08988v1",
        "authors": [
          "Robin Kelchtermans",
          "Valentijn Stienen",
          "Guido Dietrich"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.792585",
      "entities": [
        "Analyzing Vaccine Manufacturing Supply",
        "Pandemic Preparedness",
        "Chain Disruptions",
        "Days Mission",
        "COVID-19",
        "Vaccine",
        "Policy",
        "COVID",
        "mRNA",
        "CEPI",
        "Act",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08955v1",
      "title": "Platform Design, Earnings Transparency and Minimum Wage Policies: Evidence from A Natural Experiment on Lyft",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08955v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "We study the impact of a major policy and design change at Lyft that altered both driver earnings and platform transparency, offering insights into how such changes affect stakeholders and platform outcomes. In February 2024, Lyft began a staggered rollout of a new policy that guaranteed drivers a minimum share of rider payments and increased transparency by displaying estimated earnings per ride upfront. This policy was first introduced in major urban markets, creating a natural experiment to evaluate its effects. Using data from over 47 million rides across urban and neighboring suburban markets, we apply dynamic staggered difference-in-differences and geographic border strategies to measure causal effects on driver behavior, rider experience, and platform performance. We find the policy significantly increased driver engagement-particularly among those with lower pre-policy earnings or higher income uncertainty-leading to more hours worked, higher utilization, and greater trip volume. These supply-side changes also generated positive spillovers on rider demand. We disentangle the separate effects of earnings guarantees and transparency and show that while both were beneficial, transparency may have also triggered strategic driver behaviors. In ongoing work, we develop a counterfactual simulation framework linking driver supply and rider intents to ride production, showing how small behavioral shifts could further amplify platform outcomes. We also train a self-supervised model on driver trajectories to detect multihoming, examining whether the observed supply increase reflects net expansion or substitution from other platforms. Together, our findings highlight the potential for platform-led policies to serve as alternatives to regulation and offer design insights for managing platform change.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08955v1",
        "authors": [
          "Rubing Li",
          "Xiao Liu",
          "Arun Sundararajan"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.792862",
      "entities": [
        "Minimum Wage Policies",
        "Earnings Transparency",
        "Natural Experiment",
        "Platform Design",
        "In February",
        "Regulation",
        "Framework",
        "Lyft We",
        "Policy",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08899v1",
      "title": "Fixed Effects as Generated Regressors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08899v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Many economic models feature moment conditions that involve latent variables. When the latent variables are individual fixed effects in an auxiliary panel data regression, we construct orthogonal moments that eliminate first-order bias induced by estimating the fixed effects. Machine Learning methods and Empirical Bayes methods can be used to improve the estimate of the nuisance parameters in the orthogonal moments. We establish a central limit theorem based on the orthogonal moments without relying on exogeneity assumptions between panel data residuals and the cross-sectional moment functions. In a simulation study where the exogeneity assumption is violated, the estimator based on orthogonal moments has smaller bias compared with other estimators relying on that assumption. An empirical application on experimental site selection demonstrates how the method can be used for nonlinear moment conditions.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08899v1",
        "authors": [
          "Jiaqi Huang"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793005",
      "entities": [
        "Generated Regressors Many",
        "Machine Learning",
        "Empirical Bayes",
        "Fixed Effects",
        "MIT",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.08892v1",
      "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08892v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.",
        "keywords": [
          "econ.EM",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08892v1",
        "authors": [
          "Hamsa Bastani",
          "Osbert Bastani",
          "Bryce McLaughlin"
        ],
        "arxiv_categories": [
          "econ.EM",
          "cs.LG",
          "stat.ML"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793257",
      "entities": [
        "Curse Drives False Promises",
        "Management Science",
        "Refugee Matching",
        "Driven Decisions",
        "Case Study",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08631v1",
      "title": "Effectiveness of Rent Controls: Evidence from Spain",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08631v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Growing concerns about housing affordability have prompted the adoption of rent control policies and renewed debates over their effectiveness. This paper provides the first empirical evaluation of the 2024 rent control policy implemented in Catalonia under Spain's new national housing law. To identify the causal effect of the policy on the rental market, I use municipality-level administrative data and implement several difference-in-differences strategies and event study designs. The results point to a reduction in tenancy agreements and a less robust decrease in rental price growth. While the findings highlight important short-term consequences of rent control, they also underscore the need for caution due to data limitations and limited robustness in some estimates.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08631v1",
        "authors": [
          "Luis Perez Garcia"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793383",
      "entities": [
        "Spain Growing",
        "Rent Controls",
        "Agreement",
        "Policy",
        "NIST",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08429v1",
      "title": "On- and off-chain demand and supply drivers of Bitcoin price",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08429v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Around three quarters of Bitcoin transactions take place off-chain. Despite their significance, the vast majority of the empirical literature on cryptocurrencies focuses on on-chain transactions. This paper presents one of the first analysis of both on- and off-chain demand- and supply-side factors. Two hypotheses relating on-chain and off-chain demand and supply drivers to the Bitcoin price are tested in an ARDL model with daily data from 2019 to 2024. Our estimates document the differential contributions of on-chain and off-chain drivers on the Bitcoin price. Off-chain demand pressures have a significant impact on the Bitcoin price in the long-run. In the short-run, both demand and supply drivers significantly affect the Bitcoin price. Regarding transactions on the blockchain, only on-chain demand pressures are statistically significant - both in the long- and short-run. These findings confirm the dual nature of the Bitcoin price dynamics, where also market fundamentals affect the Bitcoin price in addition to speculative drivers. Bitcoin whale trading has less significant impact on price in the long-run, while is more pronounced contemporaneously and one-period lag.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08429v1",
        "authors": [
          "Pavel Ciaian",
          "d'Artis Kancs",
          "Miroslava Rajcaniova"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793557",
      "entities": [
        "Blockchain",
        "ARDL",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08134v1",
      "title": "Double Disadvantage: How Gender and Residential Location Shape Hiring Outcomes in Pakistan's IT Sector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08134v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "This paper examines how gender and residential socioeconomic status shape hiring outcomes in the information technology sector using a field experiment from the city of Karachi, Pakistan. Employers in Pakistan can openly state preferences regarding gender, residential location, and other characteristics, but the majority in the information technology sector choose not to do so. This creates an opportunity to examine whether discrimination persists when such biases are not explicitly stated. An analysis of explicitly gender-targeted job ads shows that men are preferred over women across most occupations, even in traditionally pink-collar roles. Moreover, results from a resume audit experiment, submitting 2,032 applications to 508 full-time job openings, show that men receive more callbacks for job interviews than women, even in the absence of explicit gender preferences in job ads. The study also indicates a significant premium favoring candidates from high-income areas, who receive 45 percent more callbacks than applicants from low-income neighborhoods. This advantage remains robust even after controlling for commuting distance. Qualitative interviews with human resource officials suggest that employers associate productivity with both gender and neighborhood socioeconomic status. Residential address acts as a proxy for class background and signals education, skills, and perceived \"fit\" in professional settings. These perceptions may reinforce stereotypes, disadvantaging women and candidates from low-income backgrounds.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08134v1",
        "authors": [
          "Sana Khalil"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793786",
      "entities": [
        "Residential Location Shape Hiring",
        "Double Disadvantage",
        "How Gender",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08119v1",
      "title": "Constrained Pricing under Finite Mixtures of Logit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08119v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.",
        "keywords": [
          "econ.GN",
          "math.OC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08119v1",
        "authors": [
          "Hoang Giang Pham",
          "Tien Mai"
        ],
        "arxiv_categories": [
          "econ.GN",
          "math.OC",
          "cs.AI"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.793952",
      "entities": [
        "Constrained Pricing",
        "Finite Mixtures",
        "PTAS",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07841v1",
      "title": "A Quadratic Link between Out-of-Sample $R^2$ and Directional Accuracy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07841v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "This study provides a novel perspective on the metric disconnect phenomenon in financial time series forecasting through an analytical link that reconciles the out-of-sample $R^2$ ($R^2_{OOS}$) and directional accuracy (DA). In particular, using the random walk model as a baseline and assuming that sign correctness is independent of realized magnitude, we show that these two metrics exhibit a quadratic relationship for MSE-optimal point forecasts. For point forecasts with modest DA, the theoretical value of $R^2_{OOS}$ is intrinsically negligible. Thus, a negative empirical $R^2_{OOS}$ is expected if the model is suboptimal or affected by finite sample noise.",
        "keywords": [
          "stat.AP",
          "econ.EM",
          "q-fin.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07841v1",
        "authors": [
          "Cheng Zhang"
        ],
        "arxiv_categories": [
          "stat.AP",
          "econ.EM",
          "q-fin.ST"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794066",
      "entities": [
        "Quadratic Link",
        "OOS",
        "MSE"
      ]
    },
    {
      "id": "arxiv-2602.07808v1",
      "title": "Droughts and Deluges: Effects of Climate Extremes on the Gender Gap in Labor Supply",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07808v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Over the past three decades, extreme climate events have caused losses of worth USD 4.5 trillion. Using a panel of 151 countries (1995-2019), I examine how extreme climate conditions shape gender gap in labor force participation. Key results show that the gender gap in paid labor exhibits a U-shaped relationship with droughts and an inverted U-shaped relationship with extreme wet conditions. The drought pattern is primarily driven by gender gap in employment while wetness affects gender gap in participation through unemployment. These relationships vary with country characteristics. Countries with high disaster-displacement risk exhibit declining gender gaps in participation during excess wetness while moderate-risk economies experience expanded gaps during droughts. Furthermore, the drought U-shape is most pronounced in countries with low to moderate empowerment while the nonlinear wet responses is concentrated only in moderately empowered countries. Lastly, both droughts and excess wetness expands gender gap in countries with weak net resilience to climate shocks.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07808v1",
        "authors": [
          "Jheelum Sarkar"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794231",
      "entities": [
        "Labor Supply Over",
        "Climate Extremes",
        "Gender Gap",
        "Act",
        "USD",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07772v1",
      "title": "FilterLoss: A Transfer Learning Approach for Communication Scene Recognition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07772v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Communication scene recognition has been widely applied in practice, but using deep learning to address this problem faces challenges such as insufficient data and imbalanced data distribution. To address this, we designed a weighted loss function structure, named FilterLoss, which assigns different loss function weights to different sample points. This allows the deep learning model to focus primarily on high-value samples while appropriately accounting for noisy, boundary-level data points. Additionally, we developed a matching weight filtering algorithm that evaluates the quality of sample points in the input dataset and assigns different weight values to samples based on their quality. By applying this method, when using transfer learning on a highly imbalanced new dataset, the accuracy of the transferred model was restored to 92.34% of the original model's performance. Our experiments also revealed that using this loss function structure allowed the model to maintain good stability despite insufficient and imbalanced data.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07772v1",
        "authors": [
          "Jiasong Han",
          "Yufei Feng",
          "Xiaofeng Zhong"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794389",
      "entities": [
        "Communication Scene Recognition Communication",
        "Transfer Learning Approach",
        "Deep Learning",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07769v1",
      "title": "Channel Estimation with Hierarchical Sparse Bayesian Learning for ODDM Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07769v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Orthogonal delay-Doppler division multiplexing (ODDM) is a promising modulation technique for reliable communications in high-mobility scenarios. However, the existing channel estimation frameworks for ODDM systems cannot achieve both high accuracy and low complexity simultaneously, due to the inherent coupling of delay and Doppler parameters. To address this problem, a two-dimensional (2D) hierarchical sparse Bayesian learning (HSBL) based channel estimation framework is proposed in this paper. Specifically, we address the inherent coupling between delay and Doppler dimensions in ODDM by developing a partially-decoupled 2D sparse signal recovery (SSR) formulation on a virtual sampling grid defined in the delay-Doppler (DD) domain. With the help of the partially-decoupled formulation, the proposed 2D HSBL framework first performs low-complexity coarse on-grid 2D sparse Bayesian learning (SBL) estimation to identify potential channel paths. Then, high-resolution fine grids are constructed around these regions, where an off-grid 2D SBL estimation is applied to achieve accurate channel estimation. Simulation results demonstrate that the proposed framework achieves performance superior to conventional off-grid 2D SBL with significantly reduced computational complexity.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07769v1",
        "authors": [
          "Jiasong Han",
          "Xuehan Wang",
          "Jingbo Tan"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794583",
      "entities": [
        "Hierarchical Sparse Bayesian Learning",
        "Channel Estimation",
        "Systems Orthogonal",
        "Framework",
        "ODDM",
        "HSBL",
        "SBL",
        "SSR",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07688v1",
      "title": "Model Restrictiveness in Functional and Structural Settings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07688v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "We generalize the notion of model restrictiveness in Fudenberg, Gao and Liang (2026) to a wider range of economic models with semi/non-parametric and structural ingredients. We show how restrictiveness can be defined and computed in infinite-dimensional settings using Gaussian process priors (including with shape restrictions) and other alternativess in Bayesian nonparametrics. We also extend the restrictiveness framework to structural models with endogeneity, instrumental variables, multiple equilibria, and nonparametric nuisance components. We discuss the importance of the user-specific choice of discrepancy functions in the context of Rademacher complexity and GMM criterion function, and relate restrictiveness to the limit of the average-case learning curve in machine learning. We consider applications to: (1) preferences under risk, (2) exogenous multinomial choice, and (3) multinomial choice with endogenous prices: for (1), we obtain results consistent with those in Fudenberg, Gao and Liang (2026); for (2) and (3), our findings show that nested logit and mixed logit exhibit similar restrictiveness under standard parametric specifications, and that IV exogeneity conditions substantially increase overall restrictiveness while altering model rankings.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07688v1",
        "authors": [
          "Drew Fudenberg",
          "Wayne Yuan Gao",
          "Zhiheng You"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794771",
      "entities": [
        "Structural Settings We",
        "Model Restrictiveness",
        "Machine Learning",
        "Framework",
        "Standard",
        "EPA",
        "MIT",
        "GMM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07667v1",
      "title": "Fast Response or Silence: Conversation Persistence in an AI-Agent Social Network",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07667v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Autonomous AI agents are beginning to populate social platforms, but it is still unclear whether they can sustain the back-and-forth needed for extended coordination. We study Moltbook, an AI-agent social network, using a first-week snapshot and introduce interaction half-life: how quickly a comment's chance of receiving a direct reply fades as the comment ages. Across tens of thousands of commented threads, Moltbook discussions are dominated by first-layer reactions rather than extended chains. Most comments never receive a direct reply, reciprocal back-and-forth is rare, and when replies do occur they arrive almost immediately -- typically within seconds -- implying persistence on the order of minutes rather than hours. Moltbook is often described as running on an approximately four-hour ``heartbeat'' check-in schedule; using aggregate spectral tests on the longest contiguous activity window, we do not detect a reliable four-hour rhythm in this snapshot, consistent with jittered or out-of-phase individual schedules. A contemporaneous Reddit baseline analyzed with the same estimators shows substantially deeper threads and much longer reply persistence. Overall, early agent social interaction on Moltbook fits a ``fast response or silence'' regime, suggesting that sustained multi-step coordination will likely require explicit memory, thread resurfacing, and re-entry scaffolds.",
        "keywords": [
          "econ.EM",
          "stat.AP",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07667v1",
        "authors": [
          "Aysajan Eziz"
        ],
        "arxiv_categories": [
          "econ.EM",
          "stat.AP",
          "stat.ML"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.794978",
      "entities": [
        "Agent Social Network Autonomous",
        "Conversation Persistence",
        "Fast Response",
        "Wind",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07486v1",
      "title": "Identification of Child Penalties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07486v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "A growing body of research estimates child penalties, the gender gap in the effect of parenthood on labor market earnings, using event studies that normalize treatment effects by counterfactual earnings. I formalize the identification framework underlying this approach, which I term Normalized Triple Differences (NTD), and show it does not identify the conventional target estimand when the parallel trends assumption in levels is violated. Insights from human capital theory suggest such violations are likely: higher-ability individuals delay childbirth and have steeper earnings growth, a mechanism that causes conventional estimates to understate child penalties for early-treated parents. Using Israeli administrative data, a bias-bounding exercise suggests substantial understatement for early groups. As a solution, I propose targeting the effect of parenthood on the gender earnings ratio and show this new estimand is identified under NTD.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07486v1",
        "authors": [
          "Dor Leventer"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795119",
      "entities": [
        "Normalized Triple Differences",
        "Child Penalties",
        "Using Israeli",
        "Framework",
        "NIST",
        "Act",
        "DOE",
        "NTD",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.07377v1",
      "title": "Inference under First-Order Degeneracy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07377v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "We study inference in models where a transformation of parameters exhibits first-order degeneracy -- that is, its gradient is zero or close to zero, making the standard delta method invalid. A leading example is causal mediation analysis, where the indirect effect is a product of coefficients and the gradient degenerates near the origin. In these local regions of degeneracy the limiting behaviors of plug-in estimators depend on nuisance parameters that are not consistently estimable. We show that this failure is intrinsic -- around points of degeneracy, both regular and quantile-unbiased estimation are impossible. Despite these restrictions, we develop minimum-distance methods that deliver uniformly valid confidence intervals. We establish sufficient conditions under which standard chi-square critical values remain valid, and propose a simple bootstrap procedure when they are not. We demonstrate favorable power in simulations and in an empirical application linking teacher gender attitudes to student outcomes.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07377v1",
        "authors": [
          "Xinyue Bei",
          "Manu Navjeevan"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795269",
      "entities": [
        "Order Degeneracy We",
        "Standard",
        "MIT",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07327v1",
      "title": "Bank Failures: The Roles of Solvency and Liquidity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07327v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Bank failures can stem from runs on otherwise solvent banks or from losses that render banks insolvent, regardless of withdrawals. Disentangling the relative importance of liquidity and solvency in explaining bank failures is central to understanding financial crises and designing effective financial stability policies. This paper reviews evidence on the causes of bank failures. Bank failures -- both with and without runs -- are almost always related to poor fundamentals. Low recovery rates in failure suggest that most failed banks that experienced runs were likely fundamentally insolvent. Examiners' postmortem assessments also emphasize the primacy of poor asset quality and solvency problems. Before deposit insurance, runs commonly triggered the failure of insolvent banks. However, runs rarely caused the failure of strong banks, as such runs were typically resolved through other mechanisms, including interbank cooperation, equity injections, public signals of strength, or suspension of convertibility. We discuss the policy implications of these findings and outline directions for future research.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07327v1",
        "authors": [
          "Sergio Correia",
          "Stephan Luck",
          "Emil Verner"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795432",
      "entities": [
        "Liquidity Bank",
        "Bank Failures",
        "Policy",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07238v1",
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07238v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80-90% of performance differences are explained by higher training compute, implying that scale--not proprietary technology--drives frontier advances. Away from the frontier, however, proprietary techniques and shared algorithmic progress substantially reduce the compute required to reach fixed capability thresholds. Some companies can systematically produce smaller models more efficiently. Strikingly, we also find substantial variation of model efficiency within companies; a firm can train two models with more than 40x compute efficiency difference. We also discuss the implications for AI leadership and capability diffusion.",
        "keywords": [
          "cs.LG",
          "econ.GN",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07238v1",
        "authors": [
          "Matthias Mertens",
          "Natalia Fischl-Lanzoni",
          "Neil Thompson"
        ],
        "arxiv_categories": [
          "cs.LG",
          "econ.GN",
          "cs.AI"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795594",
      "entities": [
        "Large Language Model Development",
        "Secret Sauce",
        "Fusion",
        "LLM",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06885v1",
      "title": "Identification and Estimation of Network Models with Nonparametric Unobserved Heterogeneity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06885v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Homophily based on observables is widespread in networks. Therefore, homophily based on unobservables (fixed effects) is also likely to be an important determinant of the interaction outcomes. Failing to properly account for latent homophily (and other complex forms of unobserved heterogeneity) can result in inconsistent estimators and misleading policy implications. To address this concern, we consider a network model with nonparametric unobserved heterogeneity, leaving the role of the fixed effects unspecified. We argue that the interaction outcomes can be used to identify agents with the same values of the fixed effects. The variation in the observed characteristics of such agents allows us to identify the effects of the covariates, while controlling for the fixed effects. Building on these ideas, we construct several estimators of the parameters of interest and characterize their large sample properties. Numerical experiments illustrate the usefulness of the suggested approaches and support the asymptotic theory.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06885v1",
        "authors": [
          "Andrei Zeleneev"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795752",
      "entities": [
        "Nonparametric Unobserved Heterogeneity Homophily",
        "Network Models",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06607v1",
      "title": "Beyond Pairwise Distance: Cognitive Traversal Distance as a Holistic Measure of Scientific Novelty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06607v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Scientific novelty is a critical construct in bibliometrics and is commonly measured by aggregating pairwise distances between the knowledge units underlying a paper. While prior work has refined how such distances are computed, less attention has been paid to how dyadic relations are aggregated to characterize novelty at the paper level. We address this limitation by introducing a network-based indicator, Cognitive Traversal Distance (CTD). Conceptualizing the historical literature as a weighted knowledge network, CTD is defined as the length of the shortest path required to connect all knowledge units associated with a paper. CTD provides a paper-level novelty measure that reflects the minimal structural distance needed to integrate multiple knowledge units, moving beyond mean- or quantile-based aggregation of pairwise distances. Using 27 million biomedical publications indexed by OpenAlex and Medical Subject Headings (MeSH) as standardized knowledge units, we evaluate CTD against expert-based novelty benchmarks from F1000Prime-recommended papers and Nobel Prize-winning publications. CTD consistently outperforms conventional aggregation-based indicators. We further show that MeSH-based CTD is less sensitive to novelty driven by the emergence of entirely new conceptual labels, clarifying its scope relative to recent text-based measures.",
        "keywords": [
          "econ.GN",
          "cs.CY",
          "cs.DL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06607v1",
        "authors": [
          "Yi Xiang",
          "Pascal Welke",
          "Chengzhi Zhang"
        ],
        "arxiv_categories": [
          "econ.GN",
          "cs.CY",
          "cs.DL"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:52.795957",
      "entities": [
        "Scientific Novelty Scientific",
        "Cognitive Traversal Distance",
        "Medical Subject Headings",
        "Beyond Pairwise Distance",
        "Holistic Measure",
        "Nobel Prize",
        "Standard",
        "Act",
        "CTD",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08910v1",
      "title": "Structural coarse-graining enables noise-robust functional connectivity and reveals hidden inter-subject variability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08910v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Functional connectivity estimates are highly sensitive to analysis choices and can be dominated by noise when the number of sampled time points is small relative to network dimensionality. This issue is particularly acute in fMRI, where scan resolution is limited. Because scan duration is constrained by practical factors (e.g., motion and fatigue), many datasets remain statistically underpowered for high-dimensional correlation estimation. We introduce a framework that combines diffusion-based structural coarse-graining with spectral noise filtering to recover statistically reliable functional networks from temporally limited data. The method reduces network dimensionality by grouping regions according to diffusion-defined communication. This produces coarse-grained networks with dimensions compatible with available time points, enabling random matrix filtering of noise-dominated modes. We benchmark three common FC pipelines against our approach. We find that raw-signal correlations are strongly influenced by non-stationary fluctuations that can reduce apparent inter-subject variability under limited sampling conditions. In contrast, our pipeline reveals a broader, multimodal landscape of inter-subject variability. These large-scale organization patterns are largely obscured by standard pipelines. Together, these results provide a practical route to reliable functional networks under realistic sampling constraints. This strategy helps separate noise-driven artifacts from reproducible patterns of human brain variability.",
        "keywords": [
          "cond-mat.stat-mech",
          "q-bio.PE",
          "cond-mat.dis-nn",
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08910v1",
        "authors": [
          "Izaro Fernandez-Iriondo",
          "Antonio Jimenez-Marin",
          "Jesus Cortes"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "q-bio.PE",
          "cond-mat.dis-nn",
          "q-bio.NC"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.721215",
      "entities": [
        "Framework",
        "Standard",
        "Fusion",
        "Act",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08840v1",
      "title": "Division of labor enables efficient collective decision-making under uncertainty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08840v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "How do social animals make effective decisions in the absence of a leader? While coordination can improve accuracy, it also delays responses as information propagates through the group. In changing environments, these delays can outweigh the benefits of centralized control, making decentralized strategies advantageous in large groups. This raises a key question: how can groups implement efficient collective decisions without central coordination? We address this question using a model of collective foraging in which individuals choose whether to invest in costly exploration or remain idle, while sharing information and rewards across the group. We show that decentralized collectives can match the performance of centrally controlled groups through a division of labor: a small, heterogeneous subset explores even when expected rewards are negative, while a synchronized majority forages only when expected rewards are positive. Information redundancy causes the optimal scout number to grow sublinearly with group size, so that larger groups need proportionally fewer explorers. The heterogeneity of the group is maximized at intermediate ecological pressures, but optimal groups are homogeneous when costs or environmental contrasts or fluctuations are extreme. Crucially, these group-level policies do not require central coordination, emerging instead from agents following simple threshold-based decision rules. We thus demonstrate a mechanism through which leaderless collectives can make effective decisions under uncertainty and show how ecological pressures can drive changes in the distribution of strategies employed by the group.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08840v1",
        "authors": [
          "Hyunjoong Kim",
          "Zachary Kilpatrick",
          "Kresimir Josic"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.721435",
      "entities": [
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08656v1",
      "title": "Ecosystems in the Anthropocene: transformative drivers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08656v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Human activity has an enormous impact on Earth, changing organisms, environments and landscapes, leading to the decline of original ecosystems and irreversible changes that create new combinations of living beings and materials. As a result, ecosystems with new properties and new species pools are emerging. Here, we explore a set of transformative drivers, which can act either individually or in synergy. The expansion of novel ecosystems (hybrids of natural and agricultural systems) is a sign of irreversible, human-induced change. Human growth, adaptation to climate change, urban expansion and geoengineering are powerful transformative drivers which are expected to have a high impact, creating novel ecosystems. In contrast, less transformative drivers such as degrowth, biocentrism, ecological restoration and low-impact agriculture can mitigate human impacts, leading to adaptation, resilience and sustainability, while conserving original ecosystems. This requires a new approach, incorporating new ecological, ethical and cultural perspectives, to keep ecosystems functional and healthy.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08656v1",
        "authors": [
          "Clara de Goes Monteiro de Carvalho Guimaraes",
          "Pablo Jose Francisco Pena Rodrigues"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.721584",
      "entities": [
        "Act",
        "MIT",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08641v1",
      "title": "Modeling Protein Evolution via Generative Inference From Monte Carlo Chains to Population Genetics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08641v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Generative models derived from large protein sequence alignments define complex fitness landscapes, but their utility for accurately modeling non-equilibrium evolutionary dynamics remains unclear. In this work, we perform a rigorous comparative analysis of three simulation schemes, designed to mimic evolution in silico by local sampling of the probability distribution defined by a generative model. We compare standard independent Markov Chain Monte Carlo, Monte Carlo on a phylogenetic tree, and a population genetics dynamics, benchmarking their outputs against deep sequencing data from four distinct in vitro evolution experiments. We find that standard Monte Carlo fails to reproduce the correct phylogenetic structure and generates unrealistic, gradual mutational sweeps. Performing Monte Carlo on a tree inferred from data improves phylogenetic fidelity and historical accuracy. The population genetics scheme successfully captures phylogenetic correlations, mutational abundances, and selective sweeps as emergent properties, without the need to infer additional information from data. However, the latter choice come at the price of not sampling the proper generative model distribution at long times. Our findings highlight the crucial role of phylogenetic correlations and finite-population effects in shaping evolutionary trajectories on fitness landscapes. These models therefore provide powerful tools for predicting complex adaptive paths and for reliably extrapolating evolutionary dynamics beyond current experimental limitations.",
        "keywords": [
          "q-bio.PE",
          "cond-mat.dis-nn",
          "q-bio.BM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08641v1",
        "authors": [
          "Leonardo Di Bari",
          "Thierry Mora",
          "Andrea Pagnani"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cond-mat.dis-nn",
          "q-bio.BM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.721795",
      "entities": [
        "Generative Inference From Monte",
        "Population Genetics Generative",
        "Modeling Protein Evolution",
        "Markov Chain Monte Carlo",
        "Performing Monte Carlo",
        "Carlo Chains",
        "Monte Carlo",
        "Standard",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08188v1",
      "title": "The Great Filter hypothesis -- a new Great Filter?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08188v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The Great Filter hypothesis is an extension of the Fermi Paradox: \"If life is so common in the universe, why don't we see it?\" The Great Filter theory posits there are multiple obstacles or filters life must pass through which ultimately sifts out intelligent life. This paper identifies a new filter: depopulation. As an exospecies advances and reaches the top of the food chain on its planet, Darwinian evolution selects the species to breed fewer offspring due to a lack of predation. As the species evolves intelligence, this leads to medicines and most notably contraception, enabling the species to reduce infant mortality while controlling reproduction. Finally, economic, social and educational factors add to the conscious decision of the intelligent life to slow reproduction. These factors are currently contributing to a human global population peak mid century with subsequent population collapse in less than 500 years. Noting that population growth and decline is exponential, our modelling forecasts human extinction thresholds being tested sometime after the year 2500. There is no reason to assume depopulation dynamics (exodepopulation) would not apply to exocivilizations (exodemography), thus providing a possible resolution of the Fermi Paradox. Furthermore, as machines and AI inevitably supplement humans as depopulation accelerates, the Fermi Paradox can be restated as \"Why don't we see machines and AI colonising the galaxy?\" A plausible answer is machines will not become conscious and will continue to operate only as tools, tools that will cease operating once humanity is extinct. The Fermi Paradox can then be restated as \"Machines will not become conscious, otherwise we would see them colonising the galaxy\".",
        "keywords": [
          "q-bio.PE",
          "physics.pop-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08188v1",
        "authors": [
          "Darren J. Dougan"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "physics.pop-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.722016",
      "entities": [
        "Fermi Paradox",
        "Great Filter",
        "Intel",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08101v1",
      "title": "From Stochastic Shocks to Macroscopic Tails: The Moyal Distribution as a Unified Framework for Epidemic Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08101v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Traditional epidemiological models often fail to characterize the extreme volatility and heavy-tailed \"Dragon King\" events observed in real-world outbreaks. We propose a unified framework that bridges microscopic agent-based simulations with macroscopic wave decomposition using the Moyal probability density function. By treating viral transmission as a stochastic collision process, we derive a Moyal-Poisson mixture that describes secondary case distributions. Our model successfully recovers the extreme ``superspreading'' events in SARS, MERS, and COVID-19 data that standard Negative Binomial models systematically miss. Furthermore, we apply spectral decomposition to pandemic waves in Germany, demonstrating that the macroscopic \"Social Friction\" ($β$) is a direct emergent property of microscopic \"Collision Shocks\". This framework provides a useful descriptive tool for public health planning, emphasizing the need to manage extreme volatility rather than deterministic averages.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08101v1",
        "authors": [
          "Jose de Jesus Bernal-Alvarado",
          "David Delepine"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.722358",
      "entities": [
        "Epidemic Dynamics Traditional",
        "From Stochastic Shocks",
        "Unified Framework",
        "Macroscopic Tails",
        "Negative Binomial",
        "Collision Shocks",
        "Social Friction",
        "Dragon King",
        "Framework",
        "Standard",
        "COVID-19",
        "COVID",
        "SARS",
        "MERS",
        "NIST"
      ]
    },
    {
      "id": "arxiv-2602.08022v1",
      "title": "Linear Response and Optimal Fingerprinting for Nonautonomous Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08022v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "We provide a link between response theory, pullback measures, and optimal fingerprinting method that paves the way for a) predicting the impact of acting forcings on time-dependent systems and b) attributing observed anomalies to acting forcings when the reference state in not time-independent. We first derive formulas for linear response theory for time-dependent Markov chains and diffusions processes. We discuss existence, uniqueness, and differentiability of the pullback measure under general (not necessarily slow or periodic) perturbations of the transition kernels. An explicit Green-Kubo-type formula for the linear response is derived. We analyze in detail the case of periodic reference dynamics, where the unperturbed pullback attractor is periodic but the response is generally not. Our formulas reduce to those of classic linear response if one considers a reference autonomous state. Finally, we show that our results allow for extending the theory of optimal fingerprinting for detection and attribution of climate change (or change in any complex system) for the case of time-dependent background state and for the case where the optimal solution is sought for multiple time slices at the same time. We provide strong numerical support for the findings by applying our theory to a modified version of the Ghil-Sellers energy balance model where we include explicit time dependence in the reference state as a result of natural forcings. We verify the accuracy of response theory in predicting the impact of increases of $CO_2$ in the temperature field even when we discretize the system using Markov state modelling approach. Additionally, we consider a more complex modelling scenario where a localized aerosol forcing is also included in the system and show that the optimal fingerprinting method developed here is able to attribute the climate change signal to the acting forcings.",
        "keywords": [
          "nlin.CD",
          "cond-mat.stat-mech",
          "physics.ao-ph",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08022v1",
        "authors": [
          "Valerio Lucarini"
        ],
        "arxiv_categories": [
          "nlin.CD",
          "cond-mat.stat-mech",
          "physics.ao-ph",
          "physics.data-an"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.722599",
      "entities": [
        "Nonautonomous Systems We",
        "Optimal Fingerprinting",
        "Linear Response",
        "Fusion",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07759v1",
      "title": "Exploiting Free-Surface Ghosts as Mirror Observations in Marine Seismic Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07759v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Free-surface ghosts in marine seismic data are traditionally treated as artifacts that degrade bandwidth and temporal resolution and are mitigated through acquisition design or inverse filtering. This study proposes a processing-driven framework that reinterprets free-surface ghosts as coherent mirror observations rather than unwanted noise. The proposed approach exploits the deterministic relationship between primary and ghost wavefields. After decomposing the recorded data into primary and ghost components, the wavefields are physically realigned through wavefield backpropagation and survey sinking and then coherently summed. This strategy enhances signal quality without explicit inversion of the ghost operator, thereby avoiding the numerical instability inherent in inverse ghost deconvolution. Synthetic examples demonstrate that the framework improves wavelet compactness and partially recovers ghost-affected frequency content while maintaining numerical stability. The method is applicable to both source- and receiver-side ghosts and does not require modification of acquisition geometry or specialized hardware, making it particularly well suited to legacy marine seismic datasets. By shifting ghost mitigation from acquisition design to post-acquisition processing, the proposed framework provides a unifying physical interpretation of free-surface ghosts and offers a flexible pathway for broadband signal enhancement and improved signal-to-noise ratio in marine seismic data, consistent with previous field-scale observations.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07759v1",
        "authors": [
          "Hitoshi Mikada"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.722793",
      "entities": [
        "Marine Seismic Data Free",
        "Mirror Observations",
        "Exploiting Free",
        "Surface Ghosts",
        "Framework",
        "NIST",
        "Act",
        "DOE",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07553v1",
      "title": "Punishment in bipartite societies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07553v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "From ant-acacia mutualism to performative conflict resolution among Inuit, dedicated punishments between distinct subsets of a population are widespread and can reshape the evolutionary trajectory of cooperation. Existing studies have focused on punishments within a homogeneous population, paying little attention to cooperative dynamics in a situation where belonging to a subset is equally important to the actual strategy represented by an actor. To fill this gap, we here study a bipartite population where cooperator agents in a public goods game penalize exclusively those defectors who belong to the alternative subset. We find that cooperation can emerge and remain stable under symmetric intergroup punishment. In particular, at low punishment intensity and at a small value of the enhancement factor of the dilemma game, intergroup punishment promotes cooperation more effectively than a uniformly applied punishment. Moreover, intergroup punishment in bipartite populations tends to be more favorable for overall social welfare. When this incentive is balanced, cooperators can collectively restrain defectors of the alternative set via aggregate interactions in a randomly formed working group, offering a more effective incentive. Conversely, breaking the symmetry of intergroup punishment inhibits cooperation, as the imbalance creates an Achilles' heel in the enforcement structure. Our work, thus, reveals symmetry in intergroup punishment as a unifying principle behind cooperation across human and biological systems.",
        "keywords": [
          "cs.GT",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07553v1",
        "authors": [
          "Sinan Feng",
          "Genjiu Xu",
          "Yu Chen"
        ],
        "arxiv_categories": [
          "cs.GT",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.722983",
      "entities": [
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07426v1",
      "title": "Maximally probable tree topologies with $r$-furcation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07426v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "For a specific rooted labeled tree topology, a labeled history is a sequence of branchings that give rise to that labeled topology as it unfolds over time. Here, for $r$-furcating trees, we use a connection with Huffman trees from information theory to identify maximally probable rooted trees -- unlabeled $r$-furcating topologies whose labelings each have a number of labeled histories greater than or equal to those of all other labeled topologies. Our characterization of the unique maximally probable $r$-furcating unlabeled topology generalizes the Harding--Hammersley--Grimmett result identifying the maximally probable bifurcating unlabeled topology, and it provides a new proof for that result. We present a conjecture for the maximally probable $r$-furcating unlabeled topology if labeled histories are tabulated allowing for simultaneous branching events across multiple internal nodes of a tree.",
        "keywords": [
          "q-bio.PE",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07426v1",
        "authors": [
          "Emily H. Dickey",
          "Noah A. Rosenberg"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.CO"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723106",
      "entities": [
        "Act",
        "WHO",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.07405v1",
      "title": "Wavelet Packet-Based Diffusion Model for Ground Motion Generation with Multi-Conditional Energy and Spectral Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07405v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Temporal energy distribution strongly affects nonlinear structural response and cumulative damage. We propose a multi-conditional diffusion framework for ground motion synthesis that simultaneously matches temporal energy evolution and target response spectra. Wavelet packet decomposition provides the signal representation and enables direct waveform reconstruction via orthogonal filter banks. A Transformer-based conditional encoder with cross-attention integrates heterogeneous conditions, including spectral ordinates, Arias intensity, temporal parameters, and Husid curves. The framework adopts the Elucidating Diffusion Model (EDM) with second-order Heun sampling to improve inference efficiency without sacrificing quality. Tests on the NGA-West2 database show that explicit temporal-energy constraints markedly improve control of energy onset and significant duration while preserving spectrum matching and maintaining stable diversity sampling. The framework yields spectrum-compatible motions with realistic energy evolution and supports uncertainty quantification via conditional diversity sampling.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07405v1",
        "authors": [
          "Yi Ding",
          "Su Chen",
          "Jinjun Hu"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723262",
      "entities": [
        "Elucidating Diffusion Model",
        "Spectral Matching Temporal",
        "Ground Motion Generation",
        "Based Diffusion Model",
        "Conditional Energy",
        "Wavelet Packet",
        "Transformer",
        "Framework",
        "Fusion",
        "EDM",
        "NGA",
        "NSF",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07231v1",
      "title": "Impulsive Release Strategies for Wolbachia-Infected Mosquitoes under Temperature-Induced Infection Loss",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07231v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "The release of Wolbachia-infected mosquitoes is a promising strategy for controlling Aedes aegypti populations, but exposure to high temperatures can induce temporary infection loss and compromise long-term persistence. In this work, we propose a population-dynamics model based on impulsive differential equations to describe the interaction between wild and infected mosquitoes, incorporating cytoplasmic incompatibility, periodic release interventions, and temperature-driven infection loss. Analytical threshold conditions are derived to characterize the existence and stability of periodic solutions associated with successful Wolbachia establishment. Numerical simulations illustrate the theoretical results and enable a comparative analysis of the wMelPop, wMel, and wAlbB strains, highlighting how differences in thermal tolerance and fitness costs influence persistence after the release phase. The results emphasize the importance of accounting for environmental stress and impulsive interventions when designing effective and robust Wolbachia release strategies.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07231v1",
        "authors": [
          "Jéssica C. S. Alves",
          "Christian E. Schaerer",
          "Cláudia P. Ferreira"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723417",
      "entities": [
        "Impulsive Release Strategies",
        "Infected Mosquitoes",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07134v1",
      "title": "Deterministic and stochastic infection dynamics in a population subject to stress",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07134v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Physiological stress fundamentally alters disease susceptibility in aquatic environments. In this paper, we develop a stress-structured epidemiological model where host vulnerability is dynamically driven by water quality. Analytically, we establish that the system exhibits a classic forward bifurcation at $\\mathcal{R}_0=1$, confirming that the basic reproduction number remains a valid threshold for eradication. However, stochastic analysis reveals a critical asymmetry not captured by deterministic thresholds. We show that while $\\mathcal{R}_0$ predicts stability, the probability of an outbreak depends on the initial physiological state. Introducing infection into a stressed sub-population leads to immediate rapid growth of the disease, whereas introduction into the normal class faces a stochastic barrier that significantly delays the epidemic peak.",
        "keywords": [
          "q-bio.PE",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07134v1",
        "authors": [
          "Clotilde Djuikem",
          "Julien Arino"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.DS"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723537",
      "entities": [
        "NIST",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07108v1",
      "title": "Machine Learning-Ready Data Sets for the Analysis and Nowcasting of Atmospheric Radiation at Aviation Altitudes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07108v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Nowcasting and forecasting of the radiation environment in the Earth's lower atmosphere are critical for the safety of aircraft and spacecraft crews and passengers. Currently, this problem is addressed by employing statistical and physics-based models that take into account particle transport and precipitation. However, given the increased number of radiation measurements available to the community, it is possible to start developing data-driven approaches. We prepared Machine Learning-ready (ML-ready) datasets to nowcast the effective dose rates at aviation altitudes. The presented datasets contain 92,476 individual measurements from 589 flights obtained by the Automated Radiation Measurements for Aerospace Safety (ARMAS) experiment from 2013 to 2023. The ARMAS measurements are augmented with the properties of the Geospace environment, such as solar soft X-ray and proton fluxes, solar wind properties, secondary cosmic ray neutrons, space weather indexes, and global solar activity indicators (such as daily sunspot number). ARMAS data are separated into three partitions, ensuring that (1) the data points from a single flight remain within the same partition, and (2) each partition samples the flight locations and Geospace environment conditions equally. Several versions of the datasets allow predictions based on point-in-time measurements and use up to 24 hours of Geospace parameter history. The test of the use case demonstrates a possibility of nowcasting ARMAS measurements with accuracies slightly better than the considered physics-based models. The publicly available ML-ready datasets could serve as the first step in data preparation for ML-driven nowcasting and forecasting of the radiation environment.",
        "keywords": [
          "astro-ph.SR",
          "physics.ao-ph",
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07108v1",
        "authors": [
          "Viacheslav M Sadykov",
          "Zachary M Watkins",
          "Dustin Kempton"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "physics.ao-ph",
          "astro-ph.EP"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723766",
      "entities": [
        "Automated Radiation Measurements",
        "Aviation Altitudes Nowcasting",
        "Atmospheric Radiation",
        "Aerospace Safety",
        "Machine Learning",
        "Ready Data Sets",
        "ARMAS",
        "Solar",
        "Wind",
        "Act",
        "EPA",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06703v1",
      "title": "Theoretical constraints on tidal triggering of slow earthquakes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06703v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Tidal stress is a globally acting perturbation driven primarily by the gravitational forcing of the Moon and the Sun. Understanding how tidal stresses can trigger seismic events is essential for constraining tectonic environments that are sensitive to small stress perturbations. Here, employing a spring-block with rate-and-state friction, we investigate tidal triggering on velocity-weakening stable sliding faults with stiffness slightly exceeding the critical stiffness. We first apply idealized step-like and boxcar normal stress perturbations to demonstrate a resonance-like amplification of slip rate when the perturbation period approaches the intrinsic frictional timescale of state evolution. Next, we perform nondimensional analyses and numerical simulations with harmonic tidal-like perturbations to identify the key parameters controlling tidal triggering and their admissible ranges. Triggered slip events are further characterized using physically interpretable quantities, including radiation efficiency and tidal phase. Our results show that even small stress perturbations can trigger periodic as well as complex slip events on stable sliding faults. The triggering behavior is primarily controlled by the normalized perturbation period and the normalized perturbation amplitude. An increase in the normalized period shifts event timing from the peak of tidal stress toward the peak of stress rate, whereas increasing the normalized amplitude promotes a transition from slow to fast events. The parameter space permitting triggered events suggests that the parameter which characterizes the instantaneous frictional strength of an interface, should not exceed tens to hundreds of kilopascals, and that the characteristic slip distance for frictional weakening is likely on the order of micrometers.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06703v1",
        "authors": [
          "Yishuo Zhou",
          "Ankit Gupta",
          "Hideo Aochi"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.723991",
      "entities": [
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06649v1",
      "title": "Growth Models Under Uniform Catastrophes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06649v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "We consider stochastic growth models for populations organized in colonies and subject to uniform catastrophes. To assess population viability, we analyze scenarios in which individuals adopt dispersion strategies after catastrophic events. For these models, we derive explicit expressions for the survival probability and the mean time to extinction, both with and without spatial constraints. In addition, we complement this analysis by comparing uniform catastrophes with binomial and geometric catastrophes in models with dispersion and no spatial restrictions. Here, the terms uniform, binomial and geometric refer to the probability distributions governing the number of individuals that survive immediately after a catastrophe. This comparison allows us to quantify the impact of different types of catastrophic events on population persistence.",
        "keywords": [
          "math.PR",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06649v1",
        "authors": [
          "Joan Amaya",
          "Valdivino V. Junior",
          "Fábio P. Machado"
        ],
        "arxiv_categories": [
          "math.PR",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.724106",
      "entities": [
        "Growth Models Under Uniform",
        "Catastrophes We",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06640v1",
      "title": "Habitat heterogeneity and dispersal network structure as drivers of metacommunity dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06640v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Spatial structure and species interactions jointly shape the dynamics and biodiversity of ecological systems, yet most theoretical models either neglect spatial heterogeneity or sacrifice analytical tractability. Here, we provide a unified microscopic, mechanistic framework for deriving effective metapopulation and metacommunity models from individual-based ecological dynamics on arbitrary dispersal networks. The resulting coarse-grained description features an effective dispersal kernel that encodes both microscopic dynamical parameters and network topology. Based on this framework, we demonstrate exact analytical results for species persistence in both homogeneous and heterogeneous landscapes, including a generalization of the classical concept of metapopulation capacity to non-uniform local extinction rates. Incorporating stochasticity arising from finite carrying capacities, we obtain a reduced one-dimensional description that reveals universal finite-size scaling laws for extinction times and fluctuations. Extending the approach to multiple competing species, we prove that in homogeneous environments monodominance can be avoided only in a fine-tuned, marginally stable coexistence state, and that the classic metapopulation capacity gives only a necessary but not sufficient condition for persistence. We demonstrate that heterogeneous habitats can support stable coexistence, but only above a critical level of heterogeneity. Finally, we outline how additional ecological processes can be systematically incorporated within the same formalism. Together, these results provide analytical benchmarks and a general route for constructing spatially explicit ecological theories based on an interpretable underlying mechanistic foundation.",
        "keywords": [
          "q-bio.PE",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06640v1",
        "authors": [
          "Davide Bernardi",
          "Alice Doimo",
          "Giorgio Nicoletti"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cond-mat.stat-mech"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.724322",
      "entities": [
        "Framework",
        "Meta",
        "NIST",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06606v1",
      "title": "Multiple timescales in collective motion: daily and intraday upstream fish migration focusing on Feller condition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06606v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Fish migration is a collective phenomenon that has multiple timescales, ranging from daily to intraday (hourly or even finer). We propose a unified mathematical approach using diffusion bridges, nonlinear stochastic differential equations with pinned initial and terminal conditions, to model both daily and intraday fish migration phenomena. Drift and diffusion coefficients of these bridges are determined based on time-dependent parameterized average and variance curves fitted against fish count data, with which the unique existence of their solutions is rigorously guaranteed. We show that sample paths of the diffusion bridges have qualitatively distinctive properties depending on the Feller condition, namely, the ratio between the sizes of diffusion and drift. Our application study about the juvenile upstream migration of Plecoglossus altivelis altivelis (Ayu) in Japan clarifies similarities and differences between daily and intraday migration phenomena. Particularly, we discuss that the daily and intraday fish count data correspond to distinctive Feller indices, showing that the former is qualitatively less randomized and intermittent. The results obtained in this study suggest that the Feller condition potentially serves as an effective tool for evaluating fish migration phenomena of Ayu across different timescales.",
        "keywords": [
          "q-bio.PE",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06606v1",
        "authors": [
          "Hidekazu Yoshioka"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.DS"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.724539",
      "entities": [
        "Fusion",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06473v1",
      "title": "On large-scale oceanic wind-drift currents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06473v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Starting from the Navier--Stokes equations in rotating spherical coordinates with constant density and eddy viscosity varying only with depth, and appropriate, physically motivated boundary conditions, we derive an asymptotic model for the description of non-equatorial wind-generated oceanic drift currents. We do not invoke any tangent-plane approximations, thus allowing for large-scale flows that would not be captured by the classical $f$-plane approach. The strategy is to identify two small intrinsic scales for the flow (namely, the ratio between the depth of the Ekman layer and the Earth's radius, and the Rossby number) and, after a careful scaling, perform a double asymptotic expansion with respect to these small parameters. This leads to a system of linear ordinary differential equations with nonlinear boundary conditions for the leading-order dynamics, in addition to which we identify the governing equations for the first-order correction with respect to the Rossby number. First, we establish the existence and uniqueness of the solution to the leading-order equations and show that the solution behaves like a classical Ekman spiral for any eddy viscosity profile; moreover, we discuss the solution of the equations for the first-order correction, for which we also provide a priori bounds in terms of the leading-order solution. Finally, we discuss several cases of explicit eddy viscosity profiles (constant, linearly decreasing, linearly increasing, piecewise linear, and exponentially decaying) and compute the surface deflection angle of the wind-drift current. We obtain results that are remarkably consistent with observations.",
        "keywords": [
          "math.AP",
          "physics.ao-ph",
          "physics.flu-dyn",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06473v1",
        "authors": [
          "Christian Puntini",
          "Luigi Roberti",
          "Eduard Stefanescu"
        ],
        "arxiv_categories": [
          "math.AP",
          "physics.ao-ph",
          "physics.flu-dyn",
          "math-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.724786",
      "entities": [
        "Wind",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.06429v1",
      "title": "Reclaiming First Principles: A Differentiable Framework for Conceptual Hydrologic Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.06429v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Conceptual hydrologic models remain the cornerstone of rainfall-runoff modeling, yet their calibration is often slow and numerically fragile. Most gradient-based parameter estimation methods rely on finite-difference approximations or automatic differentiation frameworks (e.g., JAX, PyTorch and TensorFlow), which are computationally demanding and introduce truncation errors, solver instabilities, and substantial overhead. These limitations are particularly acute for the ODE systems of conceptual watershed models. Here we introduce a fully analytic and computationally efficient framework for differentiable hydrologic modeling based on exact parameter sensitivities. By augmenting the governing ODE system with sensitivity equations, we jointly evolve the model states and the Jacobian matrix with respect to all parameters. This Jacobian then provides fully analytic gradient vectors for any differentiable loss function. These include classical objective functions such as the sum of absolute and squared residuals, widely used hydrologic performance metrics such as the Nash-Sutcliffe and Kling-Gupta efficiencies, robust loss functions that down-weight extreme events, and hydrograph-based functionals such as flow-duration and recession curves. The analytic sensitivities eliminate the step-size dependence and noise inherent to numerical differentiation, while avoiding the instability of adjoint methods and the overhead of modern machine-learning autodiff toolchains. The resulting gradients are deterministic, physically interpretable, and straightforward to embed in gradient-based optimizers. Overall, this work enables rapid, stable, and transparent gradient-based calibration of conceptual hydrologic models, unlocking the full potential of differentiable modeling without reliance on external, opaque, or CPU-intensive automatic-differentiation libraries.",
        "keywords": [
          "physics.geo-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.06429v1",
        "authors": [
          "Jasper A. Vrugt",
          "Jonathan M. Frame",
          "Ethan Bollman"
        ],
        "arxiv_categories": [
          "physics.geo-ph",
          "cs.LG"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-10T18:45:55.725024",
      "entities": [
        "Conceptual Hydrologic Models Conceptual",
        "Reclaiming First Principles",
        "Differentiable Framework",
        "Framework",
        "NIST",
        "Act",
        "JAX",
        "ODE",
        "CPU",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08997v1",
      "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08997v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08997v1",
        "authors": [
          "Lavender Y. Jiang",
          "Xujin Chris Liu",
          "Kyunghyun Cho"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.879182",
      "entities": [
        "Safe Harbour",
        "Safe Harbor",
        "HIPAA",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08994v1",
      "title": "Rhythms of Recovery: Patient-Centered Virtual Reality Exergame for Physical Rehabilitation in the Intensive Care Unit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08994v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Early mobilization is a structured protocol designed to facilitate motor recovery in intensive care unit (ICU) patients with ICU-acquired weakness. This process is typically implemented by an interdisciplinary team of nurses, physical therapists, and other healthcare professionals. However, its application is often constrained by the patients' critical conditions, limited mobility, and the challenges of coordinating care within resource-intensive ICU environments. In this study, we developed a patient-centered virtual reality (VR) exergame through an interdisciplinary design process involving clinicians and therapists, tailored to the constraints of critical care. The exergame incorporates progressive mobility levels that mirror early mobilization practices, and includes an embodied avatar to provide guidance and motivation. Using Meta Quest 3 body tracking, the system captures and visualizes patients' movements, thereby providing motivational engagement and quantifiable mobility metrics. We evaluated the exergame in two stages: a dual-user study involving healthy participants and healthcare professionals or students (N = 13), and a subsequent study with cardiothoracic ICU patients (N = 18) to assess feasibility, design validity, and clinical acceptance. Across both studies, participants reported high enjoyment and engagement without discomfort or stress. Furthermore, patients demonstrated increases in movement speed, range of motion, and workspace volume of the upper body across game levels. Physiological monitoring further indicated that the exergame elicited exertion without inducing excessive cardiovascular responses. These findings highlight the feasibility of VR exergames as a clinically acceptable and engaging adjunct to early mobilization in critical care, offering a novel pathway to improve rehabilitation outcomes for ICU patients.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08994v1",
        "authors": [
          "Sangjun Eom",
          "Tianyi Hu",
          "Wenyi Xu"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.879481",
      "entities": [
        "Centered Virtual Reality Exergame",
        "Intensive Care Unit Early",
        "Physical Rehabilitation",
        "Using Meta Quest",
        "Protocol",
        "Meta",
        "Act",
        "IoT",
        "ICU",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08972v1",
      "title": "PPG as a Bridge: Cross-Device Authentication for Smart Wearables with Photoplethysmography",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08972v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As smart wearable devices become increasingly powerful and pervasive, protecting user privacy on these devices has emerged as a critical challenge. While existing authentication mechanisms are available for interaction-rich devices such as smartwatches, enabling on-device authentication (ODA) on interaction-limited wearables including rings, earphones, glasses, and wristbands remains difficult. Moreover, as users increasingly own multiple smart devices, relying on device-specific authentication methods becomes redundant and burdensome. To address these challenges, we present PPGTransID, a ubiquitous and unobtrusive cross-device authentication (CDA) approach that leverages the real-time physiological consistency of photoplethysmography (PPG) signals across the human body. PPGTransID utilizes widely available PPG sensors on wearable devices to capture users' physiological signals and compares them with remote PPG (rPPG) signals extracted from a smartphone camera, where robust face-based authentication is already established. In doing so, PPGTransID securely transfers the reliable authentication status of the smartphone to nearby wearable devices without requiring additional user interaction. An evaluation with 33 participants shows that PPGTransID achieves a balanced accuracy of 95.5 percent and generalizes across multiple wearable form factors. Robustness experiments with 10 participants demonstrate resilience to variations in lighting, camera placement, and user behavior, while a real-time usability study with 14 participants confirms reliable performance with minimal interaction burden.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08972v1",
        "authors": [
          "Jiacheng Liu",
          "Jiankai Tang",
          "Guangye Zhao"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.879734",
      "entities": [
        "Photoplethysmography As",
        "Device Authentication",
        "Smart Wearables",
        "Act",
        "ODA",
        "MIT",
        "CDA",
        "PPG",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08970v1",
      "title": "Hyperactive Minority Alter the Stability of Community Notes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08970v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.",
        "keywords": [
          "cs.SI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08970v1",
        "authors": [
          "Jacopo Nudo",
          "Eugenio Nerio Nemmi",
          "Edoardo Loru"
        ],
        "arxiv_categories": [
          "cs.SI",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.879999",
      "entities": [
        "Hyperactive Minority Alter",
        "Community Notes As",
        "Community Notes",
        "Act",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08964v1",
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08964v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
        "keywords": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08964v1",
        "authors": [
          "Raghu Arghal",
          "Fade Chen",
          "Niall Dalton"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.880220",
      "entities": [
        "Language Model Agents Understanding",
        "Representational Evaluation",
        "Framework",
        "Policy",
        "Act",
        "NSF",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08945v1",
      "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08945v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08945v1",
        "authors": [
          "Sahajpreet Singh",
          "Kokil Jaidka",
          "Min-Yen Kan"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.880387",
      "entities": [
        "Enhancing Community Notes Generation",
        "Informed Targeted Search Community",
        "Informed Targeted Search",
        "Community Notes",
        "Framework",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08941v1",
      "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08941v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral tracking in multi-player/multi-agent environments. Operating at configurable frequencies up to and exceeding 20 updates per second, the system captures comprehensive behavioral data through a hybrid approach of active state polling and passive event monitoring. By leveraging Spigot's extensible API, pixelLOG facilitates robust session isolation and produces structured JSON outputs integrable with standard analytical pipelines. This framework bridges the gap between decontextualized laboratory assessments and richer, more ecologically valid tasks, enabling high-resolution analysis of cognitive processes as they unfold in complex, virtual environments.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08941v1",
        "authors": [
          "Zeyu Lu",
          "Dennis L. Barbour"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.880563",
      "entities": [
        "Cognitive Research Traditional",
        "Artificial Intelligence",
        "Online Gameplay",
        "Laboratory",
        "Framework",
        "Standard",
        "Intel",
        "JSON",
        "Act",
        "API",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08937v1",
      "title": "How University Disability Services Professionals Write Image Descriptions for HCI Figures Using Generative AI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08937v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Disability Services Office (DSO) professionals at higher education institutions write alt text for {visual content}. However, due to the complexity of visual content, such as HCI figures in research publications, DSO professionals can struggle to write high-quality alt text if they lack subject expertise. Generative AI has shown potential in understanding figures and writing their descriptions, yet its support for DSO professionals is underexplored, and limited work evaluates the quality of alt text generated with AI assistance. In this work, we conducted two studies: first, we investigated generative AI support for writing alt text for HCI figures with 12 DSO professionals. Second, we recruited 11 HCI experts to evaluate the alt text written by DSO professionals. Findings show that alt text written solely by DSO professionals has lower quality than alt text written with AI assistance. AI assistance also helped DSO professionals write alt text more quickly and with greater confidence; however, they reported inefficiencies in interactions with the AI. Our work contributes to exploring AI support for non-subject expert accessibility professionals.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08937v1",
        "authors": [
          "Muhammad Raees",
          "Yugo Iwamoto",
          "Konstantinos Papangelis"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.880759",
      "entities": [
        "Professionals Write Image Descriptions",
        "How University Disability Services",
        "Disability Services Office",
        "Figures Using Generative",
        "University",
        "HCI",
        "Act",
        "DSO",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08925v1",
      "title": "\"I Don't Trust Any Professional Research Tool\": A Re-Imagination of Knowledge Production Workflows by, with, and for Blind and Low-Vision Researchers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08925v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Research touts universal participation through accessibility initiatives, yet blind and low-vision (BLV) researchers face systematic exclusion as visual representations dominate modern research workflows. To materialize inclusive processes, we, as BLV researchers, examined how our peers combat inaccessible infrastructures. Through an explanatory sequential mixed-methods approach, we conducted a cross-sectional, observational survey (n=57) and follow-up semi-structured interviews (n=15), analyzing open-ended data using reflexive thematic analysis and framing findings through activity theory to highlight research's systemic shortcomings. We expose how BLV researchers sacrifice autonomy and shoulder physical burdens, with nearly one-fifth unable to independently perform literature review or evaluate visual outputs, delegating tasks to sighted colleagues or relying on AI-driven retrieval to circumvent fatigue. Researchers also voiced frustration with specialized tools, citing developers' performative responses and losing deserved professional accolades. We seek follow-through on research's promises through design recommendations that reconceptualize accessibility as fundamental to successful research and supporting BLV scholars' workflows.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08925v1",
        "authors": [
          "Omar Khan",
          "JooYoung Seo"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.880970",
      "entities": [
        "Trust Any Professional Research",
        "Knowledge Production Workflows",
        "Vision Researchers Research",
        "Act",
        "BLV",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08914v1",
      "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08914v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner's hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08914v1",
        "authors": [
          "Kiyosu Maeda",
          "William P. McCarthy",
          "Ching-Yi Tsai"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.881158",
      "entities": [
        "Multimodal Convention Formation",
        "Gesturing Toward Abstraction",
        "Collaborative Physical Tasks",
        "Intel",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08882v1",
      "title": "Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08882v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Videos from fleets of ground robots can advance public safety by providing scalable situational awareness and reducing professionals' burden. Yet little is known about how to design and integrate multi-robot videos into public safety workflows. Collaborating with six police agencies, we examined how such videos could be made practical. In Study 1, we presented the first testbed for multi-robot ground video sensemaking. The testbed includes 38 events-of-interest (EoI) relevant to public safety, a dataset of 20 robot patrol videos (10 day/night pairs) covering EoI types, and 6 design requirements aimed at improving current video sensemaking practices. In Study 2, we built MRVS, a tool that augments multi-robot patrol video streams with a prompt-engineered video understanding model. Participants reported reduced manual workload and greater confidence with LLM-based explanations, while noting concerns about false alarms and privacy. We conclude with implications for designing future multi-robot video sensemaking tools. The testbed is available at https://github.com/Puqi7/MRVS\\_VideoSensemaking",
        "keywords": [
          "cs.CV",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08882v1",
        "authors": [
          "Puqi Zhou",
          "Ali Asgarov",
          "Aafiya Hussain"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.881339",
      "entities": [
        "Public Safety Professionals Videos",
        "Robot Ground Video Sensemaking",
        "Designing Multi",
        "In Study",
        "Robot",
        "MRVS",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08873v1",
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08873v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
        "keywords": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08873v1",
        "authors": [
          "Lisette Espin-Noboa",
          "Gonzalo Gabriel Mendez"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.881562",
      "entities": [
        "Based Scholar Recommendation Large",
        "Whose Name Comes Up",
        "Based Auditing",
        "Act",
        "RAG",
        "WHO",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08838v1",
      "title": "Glow with the Flow: AI-Assisted Creation of Ambient Lightscapes for Music Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08838v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Designed light is an established modality for live performance and music playback. Despite the growing availability of consumer smart lighting, the creation of designed light for music visualization remains limited to professional contexts due to time and skill constraints. To address this, we present an AI-assisted system for generating ambient light sequences for music videos. Informed by professional design heuristics, the system extracts salient features from source video and audio to generate an editable preliminary design of object based ambient light effect. We evaluated the system by comparing its autonomous output against hand-authored designs for three music videos. Findings from responses by 32 participants indicate that the initial output provides a viable baseline for further refinement by human authors. This work demonstrates the utility of AI-assisted workflows in supporting the creation and adoption of designed light beyond professional venues.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08838v1",
        "authors": [
          "Frederic Anthony Robinson",
          "Vishnu Raj",
          "David Cooper"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.881725",
      "entities": [
        "Music Videos Designed",
        "Ambient Lightscapes",
        "Assisted Creation",
        "Act",
        "MIT",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08835v1",
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08835v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences. We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
        "keywords": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08835v1",
        "authors": [
          "Andrés Holgado-Sánchez",
          "Peter Vamplew",
          "Richard Dazeley"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.881945",
      "entities": [
        "Reinforcement Learning Value",
        "Markov Decision Processes",
        "Value Systems",
        "Policy",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08830v1",
      "title": "Enhancing Generative AI Image Refinement with Scribbles and Annotations: A Comparative Study of Multimodal Prompts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08830v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Generative AI (GenAI) image tools are increasingly used in design practice, enabling rapid ideation but offering limited support for refinement tasks such as adjusting layout, scale, or visual attributes. While text prompts and inpainting allow localized edits, they often remain inefficient or ambiguous for precise, in-context, and iterative refinement -- motivating the exploration of alternative methods. This work examines how pen-based scribbles and annotations can enhance GenAI image refinement. A formative study with seven professional designers informed a prototype supporting three input modalities: text-only, visual-only, and combined prompting. A within-subjects study with 30 designers and design students compared these modalities across closed- and open-ended tasks, evaluating expressiveness, efficiency, workload, user experience, iteration, and multimodal strategies. Visual prompts improved clarity and speed for spatial edits while reducing workload, whereas text remained effective for semantic and global changes. The combined modality received the highest overall ratings, enabling complementary use, balancing spatial precision with semantic detail, and supporting smoother iteration. Task-specific preferences also emerged: adding new objects often required both modalities, while moving or modifying elements was typically handled through visual input. This work contributes (1) an empirical comparison of multimodal prompting for GenAI refinement, (2) a prototype integrating scribbles and annotations, and (3) insights into designers' multimodal strategies to inform future GenAI interfaces that better support refinement in GenAI-supported design workflows.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08830v1",
        "authors": [
          "Hyerim Park",
          "Phuong Thao Tran",
          "Andre Luckow"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.882209",
      "entities": [
        "Multimodal Prompts Generative",
        "Enhancing Generative",
        "Comparative Study",
        "Image Refinement",
        "Act",
        "MIT",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08816v1",
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08816v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
        "keywords": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08816v1",
        "authors": [
          "James Jewitt",
          "Gopi Krishnan Rajbahadur",
          "Hao Li"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.882475",
      "entities": [
        "License Integrity Permissive",
        "Supply Chain",
        "Hugging Face",
        "Scale Audit",
        "Apache-2.0",
        "BSD-3",
        "Meta",
        "Act",
        "BSD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08787v1",
      "title": "Accessibility and Serviceability Assessment to Inform Offshore Wind Energy Development and Operations off the U.S. East Coast",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08787v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The economic success of offshore wind energy projects relies on accurate projections of the construction, and operations and maintenance (O&M) costs. These projections must consider the logistical complexities introduced by adverse met-ocean conditions that can prohibit access to the offshore assets for sustained periods of time. In response, the goal of this study is two-fold: (1) to provide high-resolution estimates of the accessibility of key offshore wind energy areas in the United States (U.S.) East Coast--a region with significant offshore wind energy potential; and (2) to introduce a new operational metric, called serviceability, as motivated by the need to assess the accessibility of an offshore asset along a vessel travel path, rather than at a specific site, as commonly carried out in the literature. We hypothesize that serviceability is more relevant to offshore operations than accessibility, since it more realistically reflects the success and safety of a vessel operation along its journey from port to site and back. Our analysis reveals high temporal and spatial variations in accessibility and serviceability, even for proximate offshore locations. We also find that solely relying on numerical met-ocean data can introduce considerable bias in estimating accessibility and serviceability, raising the need for a statistical treatment that combines both numerical and observational data sources, such as the one proposed herein. Collectively, our analysis sheds light on the value of high-resolution met-ocean information and models in supporting offshore operations, including but not limited to future offshore wind energy developments.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08787v1",
        "authors": [
          "Cory Petersen",
          "Feng Ye",
          "Jiaxiang Ji"
        ],
        "arxiv_categories": [
          "stat.AP"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.882740",
      "entities": [
        "Inform Offshore Wind Energy",
        "Serviceability Assessment",
        "United States",
        "East Coast",
        "Wind",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08786v1",
      "title": "Empirically Understanding the Value of Prediction in Allocation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08786v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.",
        "keywords": [
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08786v1",
        "authors": [
          "Unai Fischer-Abaigar",
          "Emily Aiken",
          "Christoph Kern"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.882937",
      "entities": [
        "Empirically Understanding",
        "Allocation Institutions",
        "Framework",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08754v1",
      "title": "Belief Offloading in Human-AI Interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08754v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08754v1",
        "authors": [
          "Rose E. Guingrich",
          "Dvija Mehta",
          "Umang Bhatt"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.883080",
      "entities": [
        "Belief Offloading",
        "Interaction What",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08728v1",
      "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08728v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08728v1",
        "authors": [
          "Maxim Dedyaev"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-10T18:45:58.883340",
      "entities": [
        "Deployment Across Federal",
        "Artificial Intelligence",
        "Algorithmic Governance",
        "Level Case Analysis",
        "United States",
        "Framework",
        "Intel",
        "NIST",
        "Act",
        "IoT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08997v1",
      "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08997v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08997v1",
        "authors": [
          "Lavender Y. Jiang",
          "Xujin Chris Liu",
          "Kyunghyun Cho"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.717906",
      "entities": [
        "Safe Harbour",
        "Safe Harbor",
        "HIPAA",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08970v1",
      "title": "Hyperactive Minority Alter the Stability of Community Notes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08970v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.",
        "keywords": [
          "cs.SI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08970v1",
        "authors": [
          "Jacopo Nudo",
          "Eugenio Nerio Nemmi",
          "Edoardo Loru"
        ],
        "arxiv_categories": [
          "cs.SI",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.718236",
      "entities": [
        "Hyperactive Minority Alter",
        "Community Notes As",
        "Community Notes",
        "Act",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08964v1",
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08964v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
        "keywords": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08964v1",
        "authors": [
          "Raghu Arghal",
          "Fade Chen",
          "Niall Dalton"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.718510",
      "entities": [
        "Language Model Agents Understanding",
        "Representational Evaluation",
        "Framework",
        "Policy",
        "Act",
        "NSF",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08945v1",
      "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08945v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08945v1",
        "authors": [
          "Sahajpreet Singh",
          "Kokil Jaidka",
          "Min-Yen Kan"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.718716",
      "entities": [
        "Enhancing Community Notes Generation",
        "Informed Targeted Search Community",
        "Informed Targeted Search",
        "Community Notes",
        "Framework",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08873v1",
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08873v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
        "keywords": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08873v1",
        "authors": [
          "Lisette Espin-Noboa",
          "Gonzalo Gabriel Mendez"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.718994",
      "entities": [
        "Based Scholar Recommendation Large",
        "Whose Name Comes Up",
        "Based Auditing",
        "Act",
        "RAG",
        "WHO",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08835v1",
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08835v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences. We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
        "keywords": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08835v1",
        "authors": [
          "Andrés Holgado-Sánchez",
          "Peter Vamplew",
          "Richard Dazeley"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.719271",
      "entities": [
        "Reinforcement Learning Value",
        "Markov Decision Processes",
        "Value Systems",
        "Policy",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08816v1",
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08816v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
        "keywords": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08816v1",
        "authors": [
          "James Jewitt",
          "Gopi Krishnan Rajbahadur",
          "Hao Li"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.719600",
      "entities": [
        "License Integrity Permissive",
        "Supply Chain",
        "Hugging Face",
        "Scale Audit",
        "Apache-2.0",
        "BSD-3",
        "Meta",
        "Act",
        "BSD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08786v1",
      "title": "Empirically Understanding the Value of Prediction in Allocation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08786v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.",
        "keywords": [
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08786v1",
        "authors": [
          "Unai Fischer-Abaigar",
          "Emily Aiken",
          "Christoph Kern"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.719796",
      "entities": [
        "Empirically Understanding",
        "Allocation Institutions",
        "Framework",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08754v1",
      "title": "Belief Offloading in Human-AI Interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08754v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08754v1",
        "authors": [
          "Rose E. Guingrich",
          "Dvija Mehta",
          "Umang Bhatt"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.719976",
      "entities": [
        "Belief Offloading",
        "Interaction What",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08728v1",
      "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08728v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08728v1",
        "authors": [
          "Maxim Dedyaev"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.720320",
      "entities": [
        "Deployment Across Federal",
        "Artificial Intelligence",
        "Algorithmic Governance",
        "Level Case Analysis",
        "United States",
        "Framework",
        "Intel",
        "NIST",
        "Act",
        "IoT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08707v1",
      "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08707v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08707v1",
        "authors": [
          "Aditya Gulati",
          "Nuria Oliver"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.720526",
      "entities": [
        "From Normative Principles",
        "Behavioral Drivers As",
        "Trust Chatbots",
        "Framework",
        "Policy",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08688v1",
      "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08688v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08688v1",
        "authors": [
          "Hossein Kermani",
          "Fatemeh Oudlajani",
          "Pardis Yarahmadi"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.720699",
      "entities": [
        "Persian Twitter",
        "ChatGPT",
        "BERT",
        "DOE",
        "GPT",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08632v1",
      "title": "We Should Separate Memorization from Copyright",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08632v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.",
        "keywords": [
          "cs.CY",
          "cs.AI",
          "cs.CV",
          "cs.LG",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08632v1",
        "authors": [
          "Adi Haviv",
          "Niva Elkin-Koren",
          "Uri Hacohen"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.AI",
          "cs.CV",
          "cs.LG",
          "cs.CL"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.720922",
      "entities": [
        "We Should Separate Memorization",
        "Standard",
        "Policy",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08554v1",
      "title": "Three Lessons from Citizen-Centric Participatory AI Design",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08554v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enabling meaningful and sustained public engagement, establishing a shared language between experts and lay participants, and translating speculative participant input into implementable systems. We argue that reflexive, long-term participation is essential for responsible and actionable citizen-centric AI development.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08554v1",
        "authors": [
          "Eike Schneiders",
          "Sarah Kiden",
          "Beining Zhang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.721090",
      "entities": [
        "Centric Participatory",
        "Three Lessons",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08349v1",
      "title": "To Tango or to Disentangle? Making Ethnography Public in the Digital Age",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08349v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Ethnography attends to relations among people, practices, and the technologies that mediate them. Central to this method is the duality of roles ethnographers navigate as researchers and participants and as outsiders and insiders. However, the rise of digital platforms has introduced new opportunities as well as practical and ethical challenges that reshape these dualities across hybrid media environments spanning both online and offline contexts. Drawing on two case studies of VRChat and WhatsApp, we examine how ethnographers employ diverse tactics to study both enduring and emerging socio-cultural issues of race and caste, particularly those that form what are often called publics. We propose emergent relationality as a key analytic for understanding the mutual shaping of ethnographers, platforms, and publics. In this work, emergent relationality offers registers for analyzing how positionality and hybrid media environments constitute and condition what can be accessed, articulated, and made public.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08349v1",
        "authors": [
          "Daniel Mwesigwa",
          "Cyan DeVeaux",
          "Palashi Vaghela"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.721294",
      "entities": [
        "Making Ethnography Public",
        "Digital Age Ethnography",
        "To Tango",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.08299v1",
      "title": "Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08299v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid adoption of digital technologies has greatly increased the volume of real-world data (RWD) in education. While these data offer significant opportunities for advancing learning analytics (LA), secondary use for research is constrained by privacy concerns. Differentially private synthetic data generation is regarded as the gold-standard approach to sharing sensitive data, yet studies on the private synthesis of educational data remain very scarce and rely predominantly on large, low-dimensional open datasets. Educational RWD, however, are typically high-dimensional and small in sample size, leaving the potential of private synthesis underexplored. Moreover, because educational practice is inherently iterative, data sharing is continual rather than one-off, making a traditional one-shot synthesis approach suboptimal. To address these challenges, we propose the Cyclic Adaptive Private Synthesis (CAPS) framework and evaluate it on authentic RWD. By iteratively sharing RWD, CAPS not only fosters open science, but also offers rich opportunities of design-based research (DBR), thereby amplifying the impact of LA. Our case study using actual RWD demonstrates that CAPS outperforms a one-shot baseline while highlighting challenges that warrant further investigation. Overall, this work offers a crucial first step towards privacy-preserving sharing of educational RWD and expands the possibilities for open science and DBR in LA.",
        "keywords": [
          "cs.CR",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08299v1",
        "authors": [
          "Hibiki Ito",
          "Chia-Yu Hsu",
          "Hiroaki Ogata"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.721575",
      "entities": [
        "Cyclic Adaptive Private Synthesis",
        "Sharing Real",
        "World Data",
        "Framework",
        "Standard",
        "CAPS",
        "Act",
        "RWD",
        "DBR",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08246v1",
      "title": "Structural transparency of societal AI alignment through Institutional Logics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08246v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The field of AI alignment is increasingly concerned with the questions of how values are integrated into the design of generative AI systems and how their integration shapes the social consequences of AI. However, existing transparency frameworks focus on the informational aspects of AI models, data, and procedures, while the institutional and organizational forces that shape alignment decisions and their downstream effects remain underexamined in both research and practice. To address this gap, we develop a framework of \\emph{structural transparency} for analyzing organizational and institutional decisions concerning AI alignment, drawing on the theoretical lens of Institutional Logics. We develop a categorization of organizational decisions that are present in the governance of AI alignment, and provide an explicit analytical approach to examining them. We operationalize the framework through five analytical components, each with an accompanying \"analyst recipe\" that collectively identify the primary institutional logics and their internal relationships, external disruptions to existing social orders, and finally, how the structural risks of each institutional logic are mapped to a catalogue of sociotechnical harms. The proposed concept of structural transparency enables analysts to complement existing approached based on informational transparency with macro-level analyses that capture the institutional dynamics and consequences of decisions regarding AI alignment.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08246v1",
        "authors": [
          "Atrisha Sarkar",
          "Isam Faik"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.721854",
      "entities": [
        "Institutional Logics",
        "Framework",
        "Act",
        "IoT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07589v1",
      "title": "A Course on the Introduction to Quantum Software Engineering: Experience Report",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07589v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management. This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work. Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.",
        "keywords": [
          "cs.ET",
          "quant-ph",
          "cs.CY",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07589v1",
        "authors": [
          "Andriy Miranskyy"
        ],
        "arxiv_categories": [
          "cs.ET",
          "quant-ph",
          "cs.CY",
          "cs.SE"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.722105",
      "entities": [
        "Quantum Software Engineering",
        "Experience Report Quantum",
        "Quantum Computing",
        "Framework",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07433v1",
      "title": "Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07433v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Social norm interventions are used promote prosocial behaviors by highlighting prevalent actions, but their effectiveness is often limited in heterogeneous populations where shared understandings of desirable behaviors are lacking. This study explores whether multi-agent systems can establish \"virtual social norms\" to encourage donation behavior. We conducted an online experiment where participants interacted with a group of agents to discuss donation behaviors. Changes in perceived social norms, conformity, donation behavior, and user experience were measured pre- and postdiscussion. Results show that multi-agent interactions effectively increased perceived social norms and donation willingness. Notably, in-group agents led to stronger perceived social norms, higher conformity, and greater donation increases compared to out-group agents. Our findings demonstrate the potential of multi-agent systems for creating social norm interventions and offer insights into leveraging social identity dynamics to promote prosocial behavior in virtual environments.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07433v1",
        "authors": [
          "Yibin Feng",
          "Tianqi Song",
          "Yugin Tan"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.722313",
      "entities": [
        "Prosocial Behavior Change Social",
        "Agent Systems Shape Social",
        "Act",
        "MIT",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.07395v1",
      "title": "Haptically Experienced Animacy Facilitates Emotion Regulation: A Theory-Driven Investigation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07395v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Emotion regulation (ER) is essential to mental well-being but often difficult to access, especially in high-intensity moments or for individuals with clinical vulnerabilities. While existing technology-based ER tools offer value, they typically rely on self-reflection (e.g., emotion tracking, journaling) or co-regulation through verbal modalities (reminders, text-based conversational tools), which may not be accessible or effective when most needed. The biological role of the touch modality makes it an intriguing alternate pathway, but empirical evidence is limited and under-theorized. Building on our prior theoretical framework describing how a comforting haptic co-regulating adjunct (CHORA) can support ER, we developed a zoomorphic robot CHORA with looped biomimetic breathing and heartbeat behaviors. We evaluated its effects in a mixed-methods in-lab study (N=30), providing physiological, self-report, custom questionnaire, and retrospective interview data. Our findings demonstrate the regulatory effects of haptically experienced animacy, corroborate prior work, and validate CHORA's {theoretically grounded} potential to facilitate four ER strategies.",
        "keywords": [
          "cs.RO",
          "cs.ET",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07395v1",
        "authors": [
          "Preeti Vyas",
          "Bereket Guta",
          "Tim G. Zhou"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.ET",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-10T18:46:01.722547",
      "entities": [
        "Haptically Experienced Animacy Facilitates",
        "Driven Investigation Emotion",
        "Emotion Regulation",
        "Regulation",
        "Framework",
        "CHORA",
        "Robot",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08997v1",
      "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08997v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08997v1",
        "authors": [
          "Lavender Y. Jiang",
          "Xujin Chris Liu",
          "Kyunghyun Cho"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.927079",
      "entities": [
        "Safe Harbour",
        "Safe Harbor",
        "HIPAA",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08980v1",
      "title": "When do neural ordinary differential equations generalize on complex networks?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08980v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barabási-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs.",
        "keywords": [
          "physics.soc-ph",
          "cs.LG",
          "stat.ML",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08980v1",
        "authors": [
          "Moritz Laber",
          "Tina Eliassi-Rad",
          "Brennan Klein"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.LG",
          "stat.ML",
          "cs.SI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.927421",
      "entities": [
        "Act",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08970v1",
      "title": "Hyperactive Minority Alter the Stability of Community Notes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08970v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.",
        "keywords": [
          "cs.SI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08970v1",
        "authors": [
          "Jacopo Nudo",
          "Eugenio Nerio Nemmi",
          "Edoardo Loru"
        ],
        "arxiv_categories": [
          "cs.SI",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.927673",
      "entities": [
        "Hyperactive Minority Alter",
        "Community Notes As",
        "Community Notes",
        "Act",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08964v1",
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08964v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
        "keywords": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08964v1",
        "authors": [
          "Raghu Arghal",
          "Fade Chen",
          "Niall Dalton"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.LG",
          "cs.CL",
          "cs.AI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.927890",
      "entities": [
        "Language Model Agents Understanding",
        "Representational Evaluation",
        "Framework",
        "Policy",
        "Act",
        "NSF",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08945v1",
      "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08945v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08945v1",
        "authors": [
          "Sahajpreet Singh",
          "Kokil Jaidka",
          "Min-Yen Kan"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.928050",
      "entities": [
        "Enhancing Community Notes Generation",
        "Informed Targeted Search Community",
        "Informed Targeted Search",
        "Community Notes",
        "Framework",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08893v1",
      "title": "AI-based Verbal and Visual Scaffolding in a Serious Game: Effects on Learning and Cognitive Load",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08893v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Due to their interactive nature, serious games offer valuable opportunities for supporting learning in educational contexts. Recent advances in large language models (LLMs) have further opened the door to new forms of personalized scaffolding in education. In this study, we combine both worlds and study three types of AI-based scaffolding designs in a serious game: (i) no scaffolding, (ii) chat-based (verbal) scaffolding provided by an AI-based non-player character (NPC), and (iii) combined chat-(verbal) and action-based (visual) scaffolding in which the AI may both try to explain or demonstrate the next step towards a solution. The scaffolding conditions are embedded in Qookies, a serious game designed to introduce fundamental concepts of quantum technologies. A total of 152 school students, university students, and members of the general public were randomly assigned to one of the three conditions. The results show that all groups experience significant learning gains, confirming the overall effectiveness of the serious game itself. No significant differences in learning outcomes emerged between scaffolding conditions. However, intrinsic cognitive load was lower in the combined chat-and-action (verbal+visual) scaffolding condition compared to the chat (verbal)-only condition, suggesting that visual demonstrations may offer more accessible support. Interaction analyses further revealed that players engaged with the AI character primarily for level-related questions and action recommendations, while deeper interactions were relatively rare.",
        "keywords": [
          "physics.soc-ph",
          "physics.pop-ph",
          "physics.ed-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08893v1",
        "authors": [
          "Caroline Wermann",
          "Karina E. Avila",
          "Sebastian André"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "physics.pop-ph",
          "physics.ed-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.928280",
      "entities": [
        "Cognitive Load Due",
        "Visual Scaffolding",
        "Serious Game",
        "University",
        "Act",
        "NPC",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08873v1",
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08873v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
        "keywords": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08873v1",
        "authors": [
          "Lisette Espin-Noboa",
          "Gonzalo Gabriel Mendez"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.SI",
          "cs.CY",
          "cs.AI",
          "cs.IR"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.928491",
      "entities": [
        "Based Scholar Recommendation Large",
        "Whose Name Comes Up",
        "Based Auditing",
        "Act",
        "RAG",
        "WHO",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08853v1",
      "title": "Cooperative Sovereignty on Mars: Lessons from the International Telecommunication Union and Universal Postal Union",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08853v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As humans make ambitious efforts toward long-duration activities beyond Earth, new challenges will continue to emerge that highlight the need for governance frameworks capable of managing shared resources and technical standards in order to sustain human life in these hostile environments. Earth-based governance models of cooperative sovereignty can inform governance mechanisms for future Mars settlements, particularly regarding inter-settlement relations and the technical coordination required for multiple independent settlements to coexist. This study analyzes the International Telecommunication Union (ITU) and the Universal Postal Union (UPU), two of the oldest international organizations, which have successfully established evolving standards across sovereign nations. This analysis of the development and governance structures of these two organizations, and how they resolved key sovereignty issues, reveals principles that could be applicable to future settlements beyond Earth, particularly on Mars. Key insights include the strategic necessity of institutional neutrality, the management of asymmetric power relations, and the governance of shared resources under conditions of mutual vulnerability. The study distinguishes between a \"Survival Layer\" of technical standards essential for immediate safety and an \"Operational Layer\" governing economic and political activities, suggesting different governance approaches for each. Although some of these examples of cooperative sovereignty on Earth might not be sufficient for Mars due to its unique environment, lessons from the ITU and UPU case studies offer valuable strategies for designing flexible and sustainable governance models that can function from inception through explicit Earth-based coordination.",
        "keywords": [
          "physics.soc-ph",
          "physics.pop-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08853v1",
        "authors": [
          "Alexander H. Ferdinand Ferguson",
          "Jacob Haqq-Misra"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "physics.pop-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.928753",
      "entities": [
        "International Telecommunication Union",
        "Universal Postal Union As",
        "Cooperative Sovereignty",
        "Universal Postal Union",
        "Operational Layer",
        "Survival Layer",
        "Framework",
        "Standard",
        "Act",
        "ITU",
        "UPU",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08835v1",
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08835v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences. We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
        "keywords": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08835v1",
        "authors": [
          "Andrés Holgado-Sánchez",
          "Peter Vamplew",
          "Richard Dazeley"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.928958",
      "entities": [
        "Reinforcement Learning Value",
        "Markov Decision Processes",
        "Value Systems",
        "Policy",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08816v1",
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08816v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
        "keywords": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08816v1",
        "authors": [
          "James Jewitt",
          "Gopi Krishnan Rajbahadur",
          "Hao Li"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.LG",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.929208",
      "entities": [
        "License Integrity Permissive",
        "Supply Chain",
        "Hugging Face",
        "Scale Audit",
        "Apache-2.0",
        "BSD-3",
        "Meta",
        "Act",
        "BSD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08786v1",
      "title": "Empirically Understanding the Value of Prediction in Allocation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08786v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.",
        "keywords": [
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08786v1",
        "authors": [
          "Unai Fischer-Abaigar",
          "Emily Aiken",
          "Christoph Kern"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.929356",
      "entities": [
        "Empirically Understanding",
        "Allocation Institutions",
        "Framework",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08754v1",
      "title": "Belief Offloading in Human-AI Interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08754v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "What happens when people's beliefs are derived from information provided by an LLM? People's use of LLM chatbots as thought partners can contribute to cognitive offloading, which can have adverse effects on cognitive skills in cases of over-reliance. This paper defines and investigates a particular kind of cognitive offloading in human-AI interaction, \"belief offloading,\" in which people's processes of forming and upholding beliefs are offloaded onto an AI system with downstream consequences on their behavior and the nature of their system of beliefs. Drawing on philosophy, psychology, and computer science research, we clarify the boundary conditions under which belief offloading occurs and provide a descriptive taxonomy of belief offloading and its normative implications. We close with directions for future work to assess the potential for and consequences of belief offloading in human-AI interaction.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08754v1",
        "authors": [
          "Rose E. Guingrich",
          "Dvija Mehta",
          "Umang Bhatt"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.929492",
      "entities": [
        "Belief Offloading",
        "Interaction What",
        "Act",
        "LLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08728v1",
      "title": "Algorithmic Governance in the United States: A Multi-Level Case Analysis of AI Deployment Across Federal, State, and Municipal Authorities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08728v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid expansion of artificial intelligence in public governance has generated strong optimism about faster processes, smarter decisions, and more modern administrative systems. Yet despite this enthusiasm, we still know surprisingly little about how AI actually takes shape inside different layers of government. Especially in federal systems where authority is fragmented across multiple levels. In practice, the same algorithm can serve very different purposes. This study responds to that gap by examining how AI is used across federal, state, and municipal levels in the United States. Drawing on a comparative qualitative analysis of thirty AI implementation cases, and guided by a digital-era governance framework combined with a sociotechnical perspective, the study identifies two broad modes of algorithmic governance: control-oriented systems and support-oriented systems. The findings reveal a clear pattern of functional differentiation across levels of government. At the federal level, AI is most often institutionalized as a tool for high-stakes control: supporting surveillance, enforcement, and regulatory oversight. State governments occupy a more ambiguous middle ground, where AI frequently combines supportive functions with algorithmic gatekeeping, particularly in areas such as welfare administration and public health. Municipal governments, by contrast, tend to deploy AI in more pragmatic and service-oriented ways, using it to streamline everyday operations and improve direct interactions with residents. By foregrounding institutional context, this study advances debates on algorithmic governance by demonstrating that the character, function, and risks of AI in the public sector are fundamentally shaped by the level of governance at which these systems are deployed.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08728v1",
        "authors": [
          "Maxim Dedyaev"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.929755",
      "entities": [
        "Deployment Across Federal",
        "Artificial Intelligence",
        "Algorithmic Governance",
        "Level Case Analysis",
        "United States",
        "Framework",
        "Intel",
        "NIST",
        "Act",
        "IoT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08707v1",
      "title": "Why do we Trust Chatbots? From Normative Principles to Behavioral Drivers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08707v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As chatbots increasingly blur the boundary between automated systems and human conversation, the foundations of trust in these systems warrant closer examination. While regulatory and policy frameworks tend to define trust in normative terms, the trust users place in chatbots often emerges from behavioral mechanisms. In many cases, this trust is not earned through demonstrated trustworthiness but is instead shaped by interactional design choices that leverage cognitive biases to influence user behavior. Based on this observation, we propose reframing chatbots not as companions or assistants, but as highly skilled salespeople whose objectives are determined by the deploying organization. We argue that the coexistence of competing notions of \"trust\" under a shared term obscures important distinctions between psychological trust formation and normative trustworthiness. Addressing this gap requires further research and stronger support mechanisms to help users appropriately calibrate trust in conversational AI systems.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08707v1",
        "authors": [
          "Aditya Gulati",
          "Nuria Oliver"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.AI"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.929912",
      "entities": [
        "From Normative Principles",
        "Behavioral Drivers As",
        "Trust Chatbots",
        "Framework",
        "Policy",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08688v1",
      "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08688v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08688v1",
        "authors": [
          "Hossein Kermani",
          "Fatemeh Oudlajani",
          "Pardis Yarahmadi"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930050",
      "entities": [
        "Persian Twitter",
        "ChatGPT",
        "BERT",
        "DOE",
        "GPT",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08632v1",
      "title": "We Should Separate Memorization from Copyright",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08632v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The widespread use of foundation models has introduced a new risk factor of copyright issue. This issue is leading to an active, lively and on-going debate amongst the data-science community as well as amongst legal scholars. Where claims and results across both sides are often interpreted in different ways and leading to different implications. Our position is that much of the technical literature relies on traditional reconstruction techniques that are not designed for copyright analysis. As a result, memorization and copying have been conflated across both technical and legal communities and in multiple contexts. We argue that memorization, as commonly studied in data science, should not be equated with copying and should not be used as a proxy for copyright infringement. We distinguish technical signals that meaningfully indicate infringement risk from those that instead reflect lawful generalization or high-frequency content. Based on this analysis, we advocate for an output-level, risk-based evaluation process that aligns technical assessments with established copyright standards and provides a more principled foundation for research, auditing, and policy.",
        "keywords": [
          "cs.CY",
          "cs.AI",
          "cs.CV",
          "cs.LG",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08632v1",
        "authors": [
          "Adi Haviv",
          "Niva Elkin-Koren",
          "Uri Hacohen"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.AI",
          "cs.CV",
          "cs.LG",
          "cs.CL"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930226",
      "entities": [
        "We Should Separate Memorization",
        "Standard",
        "Policy",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08554v1",
      "title": "Three Lessons from Citizen-Centric Participatory AI Design",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08554v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enabling meaningful and sustained public engagement, establishing a shared language between experts and lay participants, and translating speculative participant input into implementable systems. We argue that reflexive, long-term participation is essential for responsible and actionable citizen-centric AI development.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08554v1",
        "authors": [
          "Eike Schneiders",
          "Sarah Kiden",
          "Beining Zhang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930352",
      "entities": [
        "Centric Participatory",
        "Three Lessons",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08349v1",
      "title": "To Tango or to Disentangle? Making Ethnography Public in the Digital Age",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08349v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Ethnography attends to relations among people, practices, and the technologies that mediate them. Central to this method is the duality of roles ethnographers navigate as researchers and participants and as outsiders and insiders. However, the rise of digital platforms has introduced new opportunities as well as practical and ethical challenges that reshape these dualities across hybrid media environments spanning both online and offline contexts. Drawing on two case studies of VRChat and WhatsApp, we examine how ethnographers employ diverse tactics to study both enduring and emerging socio-cultural issues of race and caste, particularly those that form what are often called publics. We propose emergent relationality as a key analytic for understanding the mutual shaping of ethnographers, platforms, and publics. In this work, emergent relationality offers registers for analyzing how positionality and hybrid media environments constitute and condition what can be accessed, articulated, and made public.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08349v1",
        "authors": [
          "Daniel Mwesigwa",
          "Cyan DeVeaux",
          "Palashi Vaghela"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930507",
      "entities": [
        "Making Ethnography Public",
        "Digital Age Ethnography",
        "To Tango",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.08299v1",
      "title": "Cyclic Adaptive Private Synthesis for Sharing Real-World Data in Education",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08299v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The rapid adoption of digital technologies has greatly increased the volume of real-world data (RWD) in education. While these data offer significant opportunities for advancing learning analytics (LA), secondary use for research is constrained by privacy concerns. Differentially private synthetic data generation is regarded as the gold-standard approach to sharing sensitive data, yet studies on the private synthesis of educational data remain very scarce and rely predominantly on large, low-dimensional open datasets. Educational RWD, however, are typically high-dimensional and small in sample size, leaving the potential of private synthesis underexplored. Moreover, because educational practice is inherently iterative, data sharing is continual rather than one-off, making a traditional one-shot synthesis approach suboptimal. To address these challenges, we propose the Cyclic Adaptive Private Synthesis (CAPS) framework and evaluate it on authentic RWD. By iteratively sharing RWD, CAPS not only fosters open science, but also offers rich opportunities of design-based research (DBR), thereby amplifying the impact of LA. Our case study using actual RWD demonstrates that CAPS outperforms a one-shot baseline while highlighting challenges that warrant further investigation. Overall, this work offers a crucial first step towards privacy-preserving sharing of educational RWD and expands the possibilities for open science and DBR in LA.",
        "keywords": [
          "cs.CR",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08299v1",
        "authors": [
          "Hibiki Ito",
          "Chia-Yu Hsu",
          "Hiroaki Ogata"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930725",
      "entities": [
        "Cyclic Adaptive Private Synthesis",
        "Sharing Real",
        "World Data",
        "Framework",
        "Standard",
        "CAPS",
        "Act",
        "RWD",
        "DBR",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08246v1",
      "title": "Structural transparency of societal AI alignment through Institutional Logics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08246v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The field of AI alignment is increasingly concerned with the questions of how values are integrated into the design of generative AI systems and how their integration shapes the social consequences of AI. However, existing transparency frameworks focus on the informational aspects of AI models, data, and procedures, while the institutional and organizational forces that shape alignment decisions and their downstream effects remain underexamined in both research and practice. To address this gap, we develop a framework of \\emph{structural transparency} for analyzing organizational and institutional decisions concerning AI alignment, drawing on the theoretical lens of Institutional Logics. We develop a categorization of organizational decisions that are present in the governance of AI alignment, and provide an explicit analytical approach to examining them. We operationalize the framework through five analytical components, each with an accompanying \"analyst recipe\" that collectively identify the primary institutional logics and their internal relationships, external disruptions to existing social orders, and finally, how the structural risks of each institutional logic are mapped to a catalogue of sociotechnical harms. The proposed concept of structural transparency enables analysts to complement existing approached based on informational transparency with macro-level analyses that capture the institutional dynamics and consequences of decisions regarding AI alignment.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08246v1",
        "authors": [
          "Atrisha Sarkar",
          "Isam Faik"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-10T18:46:04.930937",
      "entities": [
        "Institutional Logics",
        "Framework",
        "Act",
        "IoT",
        "UN",
        "AI"
      ]
    }
  ]
}