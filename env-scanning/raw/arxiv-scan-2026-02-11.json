{
  "agent_metadata": {
    "agent_name": "arxiv-agent",
    "model_used": "sonnet",
    "papers_collected": 120,
    "steeps_categories_scanned": 6,
    "scan_date": "2026-02-11",
    "status": "success",
    "execution_time": 15.1,
    "process_id": 87912
  },
  "items": [
    {
      "id": "arxiv-2602.10117v1",
      "title": "Biases in the Blind Spot: Detecting What LLMs Fail to Mention",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10117v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipeline for detecting task-specific unverbalized biases. Given a task dataset, the pipeline uses LLM autoraters to generate candidate bias concepts. It then tests each concept on progressively larger input samples by generating positive and negative variations, and applies statistical techniques for multiple testing and early stopping. A concept is flagged as an unverbalized bias if it yields statistically significant performance differences while not being cited as justification in the model's CoTs. We evaluate our pipeline across six LLMs on three decision tasks (hiring, loan approval, and university admissions). Our technique automatically discovers previously unknown biases in these models (e.g., Spanish fluency, English proficiency, writing formality). In the same run, the pipeline also validates biases that were manually identified by prior work (gender, race, religion, ethnicity). More broadly, our proposed approach provides a practical, scalable path to automatic task-specific bias discovery.",
        "keywords": [
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10117v1",
        "authors": [
          "Iván Arcuschin",
          "David Chanin",
          "Adrià Garriga-Alonso"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.710517",
      "entities": [
        "Mention Large Language Models",
        "Detecting What",
        "Blind Spot",
        "University",
        "LLM",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10116v1",
      "title": "SAGE: Scalable Agentic 3D Scene Generation for Embodied AI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10116v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., \"pick up a bowl and place it on the table\"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility, visual realism, and physical stability. Through iterative reasoning and adaptive tool selection, it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training. Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI. Code, demos, and the SAGE-10k dataset can be found on the project page here: https://nvlabs.github.io/sage.",
        "keywords": [
          "cs.RO",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10116v1",
        "authors": [
          "Hongchi Xia",
          "Xuan Li",
          "Zhaoshuo Li"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.710669",
      "entities": [
        "Scene Generation",
        "Scalable Agentic",
        "Framework",
        "Policy",
        "Labs",
        "SAGE",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10115v1",
      "title": "Quantum Multiple Rotation Averaging",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10115v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Multiple rotation averaging (MRA) is a fundamental optimization problem in 3D vision and robotics that aims to recover globally consistent absolute rotations from noisy relative measurements. Established classical methods, such as L1-IRLS and Shonan, face limitations including local minima susceptibility and reliance on convex relaxations that fail to preserve the exact manifold geometry, leading to reduced accuracy in high-noise scenarios. We introduce IQARS (Iterative Quantum Annealing for Rotation Synchronization), the first algorithm that reformulates MRA as a sequence of local quadratic non-convex sub-problems executable on quantum annealers after binarization, to leverage inherent hardware advantages. IQARS removes convex relaxation dependence and better preserves non-Euclidean rotation manifold geometry while leveraging quantum tunneling and parallelism for efficient solution space exploration. We evaluate IQARS's performance on synthetic and real-world datasets. While current annealers remain in their nascent phase and only support solving problems of limited scale with constrained performance, we observed that IQARS on D-Wave annealers can already achieve ca. 12% higher accuracy than Shonan, i.e., the best-performing classical method evaluated empirically.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10115v1",
        "authors": [
          "Shuteng Wang",
          "Natacha Kuete Meli",
          "Michael Möller"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.710819",
      "entities": [
        "Quantum Multiple Rotation Averaging",
        "Iterative Quantum Annealing",
        "Rotation Synchronization",
        "Robot",
        "IQARS",
        "IRLS",
        "Act",
        "MRA",
        "MIT",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10113v1",
      "title": "ConsID-Gen: View-Consistent and Identity-Preserving Image-to-Video Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10113v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Image-to-Video generation (I2V) animates a static image into a temporally coherent video sequence following textual instructions, yet preserving fine-grained object identity under changing viewpoints remains a persistent challenge. Unlike text-to-video models, existing I2V pipelines often suffer from appearance drift and geometric distortion, artifacts we attribute to the sparsity of single-view 2D observations and weak cross-modal alignment. Here we address this problem from both data and model perspectives. First, we curate ConsIDVid, a large-scale object-centric dataset built with a scalable pipeline for high-quality, temporally aligned videos, and establish ConsIDVid-Bench, where we present a novel benchmarking and evaluation framework for multi-view consistency using metrics sensitive to subtle geometric and appearance deviations. We further propose ConsID-Gen, a view-assisted I2V generation framework that augments the first frame with unposed auxiliary views and fuses semantic and structural cues via a dual-stream visual-geometric encoder as well as a text-visual connector, yielding unified conditioning for a Diffusion Transformer backbone. Experiments across ConsIDVid-Bench demonstrate that ConsID-Gen consistently outperforms in multiple metrics, with the best overall performance surpassing leading video generation models like Wan2.1 and HunyuanVideo, delivering superior identity fidelity and temporal coherence under challenging real-world scenarios. We will release our model and dataset at https://myangwu.github.io/ConsID-Gen.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10113v1",
        "authors": [
          "Mingyang Wu",
          "Ashirbad Mishra",
          "Soumik Dey"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.710996",
      "entities": [
        "Video Generation Image",
        "Diffusion Transformer",
        "Preserving Image",
        "Transformer",
        "Framework",
        "Fusion",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10114v1",
      "title": "Decoupled MPPI-Based Multi-Arm Motion Planning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10114v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10114v1",
        "authors": [
          "Dan Evron",
          "Elias Goldsztejn",
          "Ronen I. Brafman"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711094",
      "entities": [
        "Arm Motion Planning Recent",
        "Based Multi",
        "STORM",
        "Robot",
        "SOTA",
        "MPPI",
        "DOF",
        "MPC"
      ]
    },
    {
      "id": "arxiv-2602.10111v1",
      "title": "Learning Agile Quadrotor Flight in the Real World",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10111v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Learning-based controllers have achieved impressive performance in agile quadrotor flight but typically rely on massive training in simulation, necessitating accurate system identification for effective Sim2Real transfer. However, even with precise modeling, fixed policies remain susceptible to out-of-distribution scenarios, ranging from external aerodynamic disturbances to internal hardware degradation. To ensure safety under these evolving uncertainties, such controllers are forced to operate with conservative safety margins, inherently constraining their agility outside of controlled settings. While online adaptation offers a potential remedy, safely exploring physical limits remains a critical bottleneck due to data scarcity and safety risks. To bridge this gap, we propose a self-adaptive framework that eliminates the need for precise system identification or offline Sim2Real transfer. We introduce Adaptive Temporal Scaling (ATS) to actively explore platform physical limits, and employ online residual learning to augment a simple nominal model. {Based on the learned hybrid model, we further propose Real-world Anchored Short-horizon Backpropagation Through Time (RASH-BPTT) to achieve efficient and robust in-flight policy updates. Extensive experiments demonstrate that our quadrotor reliably executes agile maneuvers near actuator saturation limits. The system evolves a conservative base policy with a peak speed of 1.9 m/s to 7.3 m/s within approximately 100 seconds of flight time. These findings underscore that real-world adaptation serves not merely to compensate for modeling errors, but as a practical mechanism for sustained performance improvement in aggressive flight regimes.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10111v1",
        "authors": [
          "Yunfan Ren",
          "Zhiyuan Zhu",
          "Jiaxu Xing"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711282",
      "entities": [
        "Learning Agile Quadrotor Flight",
        "Backpropagation Through Time",
        "Adaptive Temporal Scaling",
        "Real World Learning",
        "Anchored Short",
        "Framework",
        "Policy",
        "RASH",
        "BPTT",
        "Act",
        "ATS",
        "NSF",
        "MIT",
        "UN",
        "EU"
      ]
    },
    {
      "id": "arxiv-2602.10110v1",
      "title": "Anyon Permutations in Quantum Double Models through Constant-depth Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10110v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We provide explicit constant-depth local unitary circuits that realize general anyon permutations in Kitaev's quantum double models. This construction can be naturally understood through a correspondence between anyon permutation symmetries of two-dimensional topological orders and self-dualities in one-dimensional systems, where local gates implement self-duality transformations on the boundaries of microscopic regions. From this holographic perspective, general anyon permutations in the $D(G)$ quantum double correspond to compositions of three classes of one-dimensional self-dualities, including gauging of certain subgroups of $G$, stacking with $G$ symmetry-protected topological phases, and outer automorphisms of the group $G$. We construct circuits realizing the first class by employing self-dual unitary gauging maps, and present transversal circuits for the latter two classes.",
        "keywords": [
          "cond-mat.str-el",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10110v1",
        "authors": [
          "Yabo Li",
          "Zijian Song"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "quant-ph"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711391",
      "entities": [
        "Quantum Double Models",
        "Anyon Permutations",
        "Circuits We",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10109v1",
      "title": "ST4VLA: Spatially Guided Training for Vision-Language-Action Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10109v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Large vision-language models (VLMs) excel at multimodal understanding but fall short when extended to embodied tasks, where instructions must be transformed into low-level motor actions. We introduce ST4VLA, a dual-system Vision-Language-Action framework that leverages Spatial Guided Training to align action learning with spatial priors in VLMs. ST4VLA includes two stages: (i) spatial grounding pre-training, which equips the VLM with transferable priors via scalable point, box, and trajectory prediction from both web-scale and robot-specific data, and (ii) spatially guided action post-training, which encourages the model to produce richer spatial priors to guide action generation via spatial prompting. This design preserves spatial grounding during policy learning and promotes consistent optimization across spatial and action objectives. Empirically, ST4VLA achieves substantial improvements over vanilla VLA, with performance increasing from 66.1 -> 84.6 on Google Robot and from 54.7 -> 73.2 on WidowX Robot, establishing new state-of-the-art results on SimplerEnv. It also demonstrates stronger generalization to unseen objects and paraphrased instructions, as well as robustness to long-horizon perturbations in real-world settings. These results highlight scalable spatially guided training as a promising direction for robust, generalizable robot learning. Source code, data and models are released at https://internrobotics.github.io/internvla-m1.github.io/",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10109v1",
        "authors": [
          "Jinhui Ye",
          "Fangjing Wang",
          "Ning Gao"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711554",
      "entities": [
        "Spatially Guided Training",
        "Spatial Guided Training",
        "Action Models Large",
        "Google Robot",
        "Framework",
        "Google",
        "Policy",
        "Robot",
        "Act",
        "VLA",
        "NSF",
        "VLM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10106v1",
      "title": "EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10106v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10106v1",
        "authors": [
          "Modi Shi",
          "Shijia Peng",
          "Jin Chen"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711725",
      "entities": [
        "Free Egocentric Demonstration Human",
        "Unlocking In",
        "Framework",
        "Wild Loco",
        "Protocol",
        "Policy",
        "Robot",
        "Act",
        "NSF",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10105v1",
      "title": "DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10105v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Data scarcity fundamentally limits the generalization of bimanual dexterous manipulation, as real-world data collection for dexterous hands is expensive and labor-intensive. Human manipulation videos, as a direct carrier of manipulation knowledge, offer significant potential for scaling up robot learning. However, the substantial embodiment gap between human hands and robotic dexterous hands makes direct pretraining from human videos extremely challenging. To bridge this gap and unleash the potential of large-scale human manipulation video data, we propose DexImit, an automated framework that converts monocular human manipulation videos into physically plausible robot data, without any additional information. DexImit employs a four-stage generation pipeline: (1) reconstructing hand-object interactions from arbitrary viewpoints with near-metric scale; (2) performing subtask decomposition and bimanual scheduling; (3) synthesizing robot trajectories consistent with the demonstrated interactions; (4) comprehensive data augmentation for zero-shot real-world deployment. Building on these designs, DexImit can generate large-scale robot data based on human videos, either from the Internet or video generation models. DexImit is capable of handling diverse manipulation tasks, including tool use (e.g., cutting an apple), long-horizon tasks (e.g., making a beverage), and fine-grained manipulations (e.g., stacking cups).",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10105v1",
        "authors": [
          "Juncheng Mu",
          "Sizhe Yang",
          "Yiming Bao"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.711885",
      "entities": [
        "Learning Bimanual Dexterous Manipulation",
        "Monocular Human Videos Data",
        "Framework",
        "Robot",
        "Apple",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10104v1",
      "title": "Olaf-World: Orienting Latent Actions for Video World Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10104v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to align action semantics across contexts. Our key insight is that although actions are unobserved, their semantic effects are observable and can serve as a shared reference. We introduce Seq$Δ$-REPA, a sequence-level control-effect alignment objective that anchors integrated latent action to temporal feature differences from a frozen, self-supervised video encoder. Building on this, we present Olaf-World, a pipeline that pretrains action-conditioned video world models from large-scale passive video. Extensive experiments demonstrate that our method learns a more structured latent action space, leading to stronger zero-shot action transfer and more data-efficient adaptation to new control interfaces than state-of-the-art baselines.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10104v1",
        "authors": [
          "Yuxin Jiang",
          "Yuchao Gu",
          "Ivor W. Tsang"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.712202",
      "entities": [
        "Video World Modeling Scaling",
        "Orienting Latent Actions",
        "Standard",
        "REPA",
        "Act",
        "NSF",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10102v1",
      "title": "VideoWorld 2: Learning Transferable Knowledge from Real-world Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10102v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Learning transferable knowledge from unlabeled video data and applying it in new environments is a fundamental capability of intelligent agents. This work presents VideoWorld 2, which extends VideoWorld and offers the first investigation into learning transferable knowledge directly from raw real-world videos. At its core, VideoWorld 2 introduces a dynamic-enhanced Latent Dynamics Model (dLDM) that decouples action dynamics from visual appearance: a pretrained video diffusion model handles visual appearance modeling, enabling the dLDM to learn latent codes that focus on compact and meaningful task-related dynamics. These latent codes are then modeled autoregressively to learn task policies and support long-horizon reasoning. We evaluate VideoWorld 2 on challenging real-world handcraft making tasks, where prior video generation and latent-dynamics models struggle to operate reliably. Remarkably, VideoWorld 2 achieves up to 70% improvement in task success rate and produces coherent long execution videos. In robotics, we show that VideoWorld 2 can acquire effective manipulation knowledge from the Open-X dataset, which substantially improves task performance on CALVIN. This study reveals the potential of learning transferable world knowledge directly from raw videos, with all code, data, and models to be open-sourced for further research.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10102v1",
        "authors": [
          "Zhongwei Ren",
          "Yunchao Wei",
          "Xiao Yu"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.712355",
      "entities": [
        "Learning Transferable Knowledge",
        "Latent Dynamics Model",
        "Videos Learning",
        "Fusion",
        "CALVIN",
        "Robot",
        "Intel",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10101v1",
      "title": "Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10101v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10101v1",
        "authors": [
          "Sizhe Yang",
          "Linning Xu",
          "Hao Li"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.712513",
      "entities": [
        "Enhancing Robotic Manipulation",
        "Accurate Feed",
        "Robot",
        "Act",
        "NSF",
        "RGB",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10099v1",
      "title": "Learning on the Manifold: Unlocking Standard Diffusion Transformers with Representation Encoders",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10099v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Leveraging representation encoders for generative modeling offers a path for efficient, high-fidelity synthesis. However, standard diffusion transformers fail to converge on these representations directly. While recent work attributes this to a capacity bottleneck proposing computationally expensive width scaling of diffusion transformers we demonstrate that the failure is fundamentally geometric. We identify Geometric Interference as the root cause: standard Euclidean flow matching forces probability paths through the low-density interior of the hyperspherical feature space of representation encoders, rather than following the manifold surface. To resolve this, we propose Riemannian Flow Matching with Jacobi Regularization (RJF). By constraining the generative process to the manifold geodesics and correcting for curvature-induced error propagation, RJF enables standard Diffusion Transformer architectures to converge without width scaling. Our method RJF enables the standard DiT-B architecture (131M parameters) to converge effectively, achieving an FID of 3.37 where prior methods fail to converge. Code: https://github.com/amandpkr/RJF",
        "keywords": [
          "cs.LG",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10099v1",
        "authors": [
          "Amandeep Kumar",
          "Vishal M. Patel"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.712665",
      "entities": [
        "Unlocking Standard Diffusion Transformers",
        "Representation Encoders Leveraging",
        "Riemannian Flow Matching",
        "Geometric Interference",
        "Diffusion Transformer",
        "Jacobi Regularization",
        "Transformer",
        "Standard",
        "Fusion",
        "RJF",
        "NSF",
        "FID",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10098v1",
      "title": "VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10098v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions, making them vulnerable to appearance bias, nuisance motion, and information leakage. We introduce VLA-JEPA, a JEPA-style pretraining framework that sidesteps these pitfalls by design. The key idea is \\emph{leakage-free state prediction}: a target encoder produces latent representations from future frames, while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA-JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes. This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA-JEPA achieves consistent gains in generalization and robustness over existing methods.",
        "keywords": [
          "cs.RO",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10098v1",
        "authors": [
          "Jingwen Sun",
          "Wenyao Zhang",
          "Zekun Qi"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.712820",
      "entities": [
        "Latent World Model Pretraining",
        "Enhancing Vision",
        "Action Model",
        "Framework",
        "LIBERO",
        "JEPA",
        "Act",
        "VLA",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10097v1",
      "title": "Step-resolved data attribution for looped transformers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10097v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We study how individual training examples shape the internal computation of looped transformers, where a shared block is applied for $τ$ recurrent iterations to enable latent reasoning. Existing training-data influence estimators such as TracIn yield a single scalar score that aggregates over all loop iterations, obscuring when during the recurrent computation a training example matters. We introduce \\textit{Step-Decomposed Influence (SDI)}, which decomposes TracIn into a length-$τ$ influence trajectory by unrolling the recurrent computation graph and attributing influence to specific loop iterations. To make SDI practical at transformer scale, we propose a TensorSketch implementation that never materialises per-example gradients. Experiments on looped GPT-style models and algorithmic reasoning tasks show that SDI scales excellently, matches full-gradient baselines with low error and supports a broad range of data attribution and interpretability tasks with per-step insights into the latent reasoning process.",
        "keywords": [
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10097v1",
        "authors": [
          "Georgios Kaissis",
          "David Mildenberger",
          "Juan Felipe Gomez"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.713109",
      "entities": [
        "Decomposed Influence",
        "Transformer",
        "Act",
        "SDI",
        "NSF",
        "GPT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10095v1",
      "title": "Causality in Video Diffusers is Separable from Denoising",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10095v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we show that the causal reasoning in these models is separable from the multi-step denoising process. Through systematic probing of autoregressive video diffusers, we uncover two key regularities: (1) early layers produce highly similar features across denoising steps, indicating redundant computation along the diffusion trajectory; and (2) deeper layers exhibit sparse cross-frame attention and primarily perform intra-frame rendering. Motivated by these findings, we introduce Separable Causal Diffusion (SCD), a new architecture that explicitly decouples once-per-frame temporal reasoning, via a causal transformer encoder, from multi-step frame-wise rendering, via a lightweight diffusion decoder. Extensive experiments on both pretraining and post-training tasks across synthetic and real benchmarks show that SCD significantly improves throughput and per-frame latency while matching or surpassing the generation quality of strong causal diffusion baselines.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10095v1",
        "authors": [
          "Xingjian Bai",
          "Guande He",
          "Zhengqi Li"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.713262",
      "entities": [
        "Separable Causal Diffusion",
        "Denoising Causality",
        "Video Diffusers",
        "Transformer",
        "Fusion",
        "Robot",
        "SCD",
        "NSF",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10094v1",
      "title": "4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10094v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10094v1",
        "authors": [
          "Yihang Luo",
          "Shangchen Zhou",
          "Yushi Lan"
        ],
        "arxiv_categories": [
          "cs.CV"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.713376",
      "entities": [
        "Conditional Querying Anytime",
        "Anywhere We",
        "Transformer",
        "Framework",
        "Act",
        "NSF",
        "MIT",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.10093v1",
      "title": "UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10093v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Robotic manipulation has seen rapid progress with vision-language-action (VLA) policies. However, visuo-tactile perception is critical for contact-rich manipulation, as tasks such as insertion are difficult to complete robustly using vision alone. At the same time, acquiring large-scale and reliable tactile data in the physical world remains costly and challenging, and the lack of a unified evaluation platform further limits policy learning and systematic analysis. To address these challenges, we propose UniVTAC, a simulation-based visuo-tactile data synthesis platform that supports three commonly used visuo-tactile sensors and enables scalable and controllable generation of informative contact interactions. Based on this platform, we introduce the UniVTAC Encoder, a visuo-tactile encoder trained on large-scale simulation-synthesized data with designed supervisory signals, providing tactile-centric visuo-tactile representations for downstream manipulation tasks. In addition, we present the UniVTAC Benchmark, which consists of eight representative visuo-tactile manipulation tasks for evaluating tactile-driven policies. Experimental results show that integrating the UniVTAC Encoder improves average success rates by 17.1% on the UniVTAC Benchmark, while real-world robotic experiments further demonstrate a 25% improvement in task success. Our webpage is available at https://univtac.github.io/.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10093v1",
        "authors": [
          "Baijun Chen",
          "Weijie Wan",
          "Tianxing Chen"
        ],
        "arxiv_categories": [
          "cs.RO"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.713539",
      "entities": [
        "Tactile Manipulation Data Generation",
        "Unified Simulation Platform",
        "Benchmarking Robotic",
        "Policy",
        "Robot",
        "Act",
        "VLA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10092v1",
      "title": "Quantum-Audit: Evaluating the Reasoning Limits of LLMs on Quantum Computing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10092v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Language models have become practical tools for quantum computing education and research, from summarizing technical papers to explaining theoretical concepts and answering questions about recent developments in the field. While existing benchmarks evaluate quantum code generation and circuit design, their understanding of quantum computing concepts has not been systematically measured. Quantum-Audit addresses this gap with 2,700 questions covering core quantum computing topics. We evaluate 26 models from leading organizations. Our benchmark comprises 1,000 expert-written questions, 1,000 questions extracted from research papers using LLMs and validated by experts, plus an additional 700 questions including 350 open-ended questions and 350 questions with false premises to test whether models can correct erroneous assumptions. Human participants scored between 23% and 86%, with experts averaging 74%. Top-performing models exceeded the expert average, with Claude Opus 4.5 reaching 84% accuracy, though top models showed an average 12-point accuracy drop on expert-written questions compared to LLM-generated ones. Performance declined further on advanced topics, dropping to 73% on security questions. Additionally, models frequently accepted and reinforced false premises embedded in questions instead of identifying them, with accuracy below 66% on these critical reasoning tasks.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10092v1",
        "authors": [
          "Mohamed Afane",
          "Kayla Laufer",
          "Wenqi Wei"
        ],
        "arxiv_categories": [
          "cs.CL"
        ]
      },
      "preliminary_category": "T",
      "collected_at": "2026-02-11T15:13:18.713695",
      "entities": [
        "Quantum Computing Language",
        "Quantum Computing",
        "Reasoning Limits",
        "Claude Opus",
        "LLM",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09969v1",
      "title": "Causal Identification in Multi-Task Demand Learning with Confounding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09969v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We study a canonical multi-task demand learning problem motivated by retail pricing, in which a firm seeks to estimate heterogeneous linear price-response functions across a large collection of decision contexts. Each context is characterized by rich observable covariates yet typically exhibits only limited historical price variation, motivating the use of multi-task learning to borrow strength across tasks. A central challenge in this setting is endogeneity: historical prices are chosen by managers or algorithms and may be arbitrarily correlated with unobserved, task-level demand determinants. Under such confounding by latent fundamentals, commonly used approaches, such as pooled regression and meta-learning, fail to identify causal price effects. We propose a new estimation framework that achieves causal identification despite arbitrary dependence between prices and latent task structure. Our approach, Decision-Conditioned Masked-Outcome Meta-Learning (DCMOML), involves carefully designing the information set of a meta-learner to leverage cross-task heterogeneity while accounting for endogenous decision histories. Under a mild restriction on price adaptivity in each task, we establish that this method identifies the conditional mean of the task-specific causal parameters given the designed information set. Our results provide guarantees for large-scale demand estimation with endogenous prices and small per-task samples, offering a principled foundation for deploying causal, data-driven pricing models in operational environments.",
        "keywords": [
          "cs.LG",
          "stat.ML",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09969v1",
        "authors": [
          "Varun Gupta",
          "Vijay Kamble"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML",
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.712255",
      "entities": [
        "Causal Identification",
        "Task Demand Learning",
        "Conditioned Masked",
        "Confounding We",
        "Outcome Meta",
        "Framework",
        "DCMOML",
        "Meta",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09608v1",
      "title": "Designing a Token Economy: Incentives, Governance, and Tokenomics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09608v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "In recent years, tokenomic systems, decentralized systems that use cryptographic tokens to represent value and rights, have evolved considerably. Growing complexity in incentive structures has expanded the applicability of blockchain beyond purely transactional use. Existing research predominantly examines token economies within specific use cases, proposes conceptual frameworks, or studies isolated aspects such as governance, incentive design, and tokenomics. However, the literature offers limited empirically grounded, end-to-end guidance that integrates these dimensions into a coherent, step-by-step design approach informed by concrete token-economy development efforts. To address this gap, this paper presents the Token Economy Design Method (TEDM), a design-science artifact that synthesizes stepwise design propositions for token-economy design across incentives, governance, and tokenomics. TEDM is derived through an iterative qualitative synthesis of prior contributions and refined through a co-designed case. The artifact is formatively evaluated via the Currynomics case study and additional expert interviews. Currynomics is an ecosystem that maintains the Redcurry stablecoin, using real estate as the underlying asset. TEDM is positioned as reusable design guidance that facilitates the analysis of foundational requirements of tokenized ecosystems. The specificity of the proposed approach lies in the focus on the socio-technical context of the system and early stages of its design.",
        "keywords": [
          "econ.GN",
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09608v1",
        "authors": [
          "Samela Kivilo",
          "Alex Norta",
          "Marie Hattingh"
        ],
        "arxiv_categories": [
          "econ.GN",
          "cs.CE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.712587",
      "entities": [
        "Token Economy Design Method",
        "Token Economy",
        "Tokenomics In",
        "Blockchain",
        "Framework",
        "TEDM",
        "Act",
        "MIT",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09382v1",
      "title": "Initial-Condition-Robust Inference in Autoregressive Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09382v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "This paper considers confidence intervals (CIs) for the autoregressive (AR) parameter in an AR model with an AR parameter that may be close or equal to one. Existing CIs rely on the assumption of a stationary or fixed initial condition to obtain correct asymptotic coverage and good finite sample coverage. When this assumption fails, their coverage can be quite poor. In this paper, we introduce a new CI for the AR parameter whose coverage probability is completely robust to the initial condition, both asymptotically and in finite samples. This CI pays only a small price in terms of its length when the initial condition is stationary or fixed. The new CI also is robust to conditional heteroskedasticity of the errors.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09382v1",
        "authors": [
          "Donald W. K. Andrews",
          "Ming Li",
          "Yapeng Zheng"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.712769",
      "entities": [
        "Robust Inference",
        "WHO",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09362v1",
      "title": "Behavioral Economics of AI: LLM Biases and Corrections",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09362v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Do generative AI models, particularly large language models (LLMs), exhibit systematic behavioral biases in economic and financial decisions? If so, how can these biases be mitigated? Drawing on the cognitive psychology and experimental economics literatures, we conduct the most comprehensive set of experiments to date$-$originally designed to document human biases$-$on prominent LLM families across model versions and scales. We document systematic patterns in LLM behavior. In preference-based tasks, responses become more human-like as models become more advanced or larger, while in belief-based tasks, advanced large-scale models frequently generate rational responses. Prompting LLMs to make rational decisions reduces biases.",
        "keywords": [
          "econ.GN",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09362v1",
        "authors": [
          "Pietro Bini",
          "Lin William Cong",
          "Xing Huang"
        ],
        "arxiv_categories": [
          "econ.GN",
          "cs.AI"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.712944",
      "entities": [
        "Behavioral Economics",
        "Corrections Do",
        "LLM",
        "MIT",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09237v1",
      "title": "Sign-Dependent Spillovers of Global Monetary Policy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09237v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "This paper examines the sign-dependent international spillovers of Federal Reserve and European Central Bank monetary policy shocks. Using a consistent high-frequency identification of pure monetary policy shocks across 44 advanced and non-advanced economies and the methodology of Caravello and Martinez-Bruera, 2024, we document strong asymmetries in international transmission. Linear specifications mask these effects: contractionary shocks generate large and significant deteriorations in financial conditions, economic activity, and international trade abroad, while expansionary shocks yield little to no measurable improvement. Our results are robust across samples, identification strategies, and the framework proposed by Ben Zeev et al., 2023.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09237v1",
        "authors": [
          "Santiago Camara"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.713126",
      "entities": [
        "European Central Bank",
        "Dependent Spillovers",
        "Federal Reserve",
        "Framework",
        "Ben Zeev",
        "Policy",
        "Act",
        "EU"
      ]
    },
    {
      "id": "arxiv-2602.08988v1",
      "title": "Analyzing Vaccine Manufacturing Supply Chain Disruptions for Pandemic Preparedness using Discrete-Event Simulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08988v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The COVID-19 pandemic exposed critical vulnerabilities in vaccine supply chains, highlighting the need for robust manufacturing for rapid pandemic response to support CEPI's 100 Days Mission. We develop a discrete-event simulation model to analyze supply chain disruptions and enables policymakers and vaccine manufacturers to quantify disruptions and assess mitigation strategies. Unlike prior studies examining components in isolation, our approach integrates production processes, quality assurance and control (QA/QC) activities, and raw material procurement to capture system-wide dynamics. A detailed mRNA case study analyzes disruption scenarios for a facility targeting 50 million doses: facility shutdowns, workforce reductions, raw material shortages, infrastructure failures, extended procurement lead times, and increased QA/QC capacity. Three main insights emerge. First, QA/QC personnel are the primary bottleneck, with utilization reaching 84.5% under normal conditions while machine utilization remains below 33%. Doubling QA/QC capacity increases annual output by 79.1%, offering greater returns than equipment investments. Second, raw material disruptions are highly detrimental, with extended lead times reducing three-year output by 19.6% and causing stockouts during 51.8% of production time. Third, the model shows differential resilience: acute disruptions (workforce shortages, shutdowns, power outages) allow recovery within 6 to 9 weeks, whereas chronic disruptions (supply delays) cause prolonged performance degradation.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08988v1",
        "authors": [
          "Robin Kelchtermans",
          "Valentijn Stienen",
          "Guido Dietrich"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.713458",
      "entities": [
        "Analyzing Vaccine Manufacturing Supply",
        "Pandemic Preparedness",
        "Chain Disruptions",
        "Days Mission",
        "COVID-19",
        "Vaccine",
        "Policy",
        "COVID",
        "CEPI",
        "mRNA",
        "Act",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08955v2",
      "title": "Platform Design, Earnings Transparency and Minimum Wage Policies: Evidence from A Natural Experiment on Lyft",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08955v2",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "We study the effects of a significant design and policy change at a major ridesharing platform that altered both provider earnings and platform transparency, examining how it affected outcomes for drivers, riders, and the platform, and providing managerial insights on balancing competing stakeholder interests while avoiding unintended consequences. In February 2024, Lyft introduced a policy guaranteeing drivers a minimum fraction of rider payments while increasing per-ride earnings transparency. The staggered rollout, first in major markets, created a natural experiment to examine how earnings guarantees and transparency affect ride availability and driver engagement. Using trip-level data from over 47 million rides across a major market and adjacent markets over six months, we apply dynamic staggered difference-in-differences models combined with a geographic border strategy to estimate causal effects on supply, demand, ride production, and platform performance. We find that the policy led to substantial increases in driver engagement, with distinct effects from the guarantee and transparency. Drivers increased working hours and utilization, resulting in more completed trips and higher per-hour and per-trip earnings, with stronger effects among drivers with lower pre-policy earnings and greater income uncertainty. Increased supply also generated positive spillovers on demand. We also find evidence that greater transparency may induce strategic driver behavior. In ongoing work, we develop a counterfactual simulation framework linking driver supply and rider intents to ride production, illustrating how small changes in driver choices could further amplify policy effects. Our study shows how platform-led interventions present an intriguing alternative to government-led minimum pay regulation and provide new strategic insights into managing platform change.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08955v2",
        "authors": [
          "Rubing Li",
          "Xiao Liu",
          "Arun Sundararajan"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.713861",
      "entities": [
        "Minimum Wage Policies",
        "Earnings Transparency",
        "Natural Experiment",
        "Platform Design",
        "In February",
        "Regulation",
        "Framework",
        "Lyft We",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08899v1",
      "title": "Fixed Effects as Generated Regressors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08899v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Many economic models feature moment conditions that involve latent variables. When the latent variables are individual fixed effects in an auxiliary panel data regression, we construct orthogonal moments that eliminate first-order bias induced by estimating the fixed effects. Machine Learning methods and Empirical Bayes methods can be used to improve the estimate of the nuisance parameters in the orthogonal moments. We establish a central limit theorem based on the orthogonal moments without relying on exogeneity assumptions between panel data residuals and the cross-sectional moment functions. In a simulation study where the exogeneity assumption is violated, the estimator based on orthogonal moments has smaller bias compared with other estimators relying on that assumption. An empirical application on experimental site selection demonstrates how the method can be used for nonlinear moment conditions.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08899v1",
        "authors": [
          "Jiaqi Huang"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.714067",
      "entities": [
        "Generated Regressors Many",
        "Machine Learning",
        "Empirical Bayes",
        "Fixed Effects",
        "MIT",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.08892v1",
      "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08892v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.",
        "keywords": [
          "stat.ML",
          "econ.EM",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08892v1",
        "authors": [
          "Hamsa Bastani",
          "Osbert Bastani",
          "Bryce McLaughlin"
        ],
        "arxiv_categories": [
          "stat.ML",
          "econ.EM",
          "cs.LG"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.714432",
      "entities": [
        "Curse Drives False Promises",
        "Management Science",
        "Refugee Matching",
        "Driven Decisions",
        "Case Study",
        "Policy",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08631v1",
      "title": "Effectiveness of Rent Controls: Evidence from Spain",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08631v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Growing concerns about housing affordability have prompted the adoption of rent control policies and renewed debates over their effectiveness. This paper provides the first empirical evaluation of the 2024 rent control policy implemented in Catalonia under Spain's new national housing law. To identify the causal effect of the policy on the rental market, I use municipality-level administrative data and implement several difference-in-differences strategies and event study designs. The results point to a reduction in tenancy agreements and a less robust decrease in rental price growth. While the findings highlight important short-term consequences of rent control, they also underscore the need for caution due to data limitations and limited robustness in some estimates.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08631v1",
        "authors": [
          "Luis Perez Garcia"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.714612",
      "entities": [
        "Rent Controls",
        "Spain Growing",
        "Agreement",
        "Policy",
        "NIST",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08429v1",
      "title": "On- and off-chain demand and supply drivers of Bitcoin price",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08429v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Around three quarters of Bitcoin transactions take place off-chain. Despite their significance, the vast majority of the empirical literature on cryptocurrencies focuses on on-chain transactions. This paper presents one of the first analysis of both on- and off-chain demand- and supply-side factors. Two hypotheses relating on-chain and off-chain demand and supply drivers to the Bitcoin price are tested in an ARDL model with daily data from 2019 to 2024. Our estimates document the differential contributions of on-chain and off-chain drivers on the Bitcoin price. Off-chain demand pressures have a significant impact on the Bitcoin price in the long-run. In the short-run, both demand and supply drivers significantly affect the Bitcoin price. Regarding transactions on the blockchain, only on-chain demand pressures are statistically significant - both in the long- and short-run. These findings confirm the dual nature of the Bitcoin price dynamics, where also market fundamentals affect the Bitcoin price in addition to speculative drivers. Bitcoin whale trading has less significant impact on price in the long-run, while is more pronounced contemporaneously and one-period lag.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08429v1",
        "authors": [
          "Pavel Ciaian",
          "d'Artis Kancs",
          "Miroslava Rajcaniova"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.714866",
      "entities": [
        "Blockchain",
        "ARDL",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08134v1",
      "title": "Double Disadvantage: How Gender and Residential Location Shape Hiring Outcomes in Pakistan's IT Sector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08134v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "This paper examines how gender and residential socioeconomic status shape hiring outcomes in the information technology sector using a field experiment from the city of Karachi, Pakistan. Employers in Pakistan can openly state preferences regarding gender, residential location, and other characteristics, but the majority in the information technology sector choose not to do so. This creates an opportunity to examine whether discrimination persists when such biases are not explicitly stated. An analysis of explicitly gender-targeted job ads shows that men are preferred over women across most occupations, even in traditionally pink-collar roles. Moreover, results from a resume audit experiment, submitting 2,032 applications to 508 full-time job openings, show that men receive more callbacks for job interviews than women, even in the absence of explicit gender preferences in job ads. The study also indicates a significant premium favoring candidates from high-income areas, who receive 45 percent more callbacks than applicants from low-income neighborhoods. This advantage remains robust even after controlling for commuting distance. Qualitative interviews with human resource officials suggest that employers associate productivity with both gender and neighborhood socioeconomic status. Residential address acts as a proxy for class background and signals education, skills, and perceived \"fit\" in professional settings. These perceptions may reinforce stereotypes, disadvantaging women and candidates from low-income backgrounds.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08134v1",
        "authors": [
          "Sana Khalil"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.715203",
      "entities": [
        "Residential Location Shape Hiring",
        "Double Disadvantage",
        "How Gender",
        "Act",
        "WHO",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08119v1",
      "title": "Constrained Pricing under Finite Mixtures of Logit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08119v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "The mixed logit model is a flexible and widely used demand model in pricing and revenue management. However, existing work on mixed-logit pricing largely focuses on unconstrained settings, limiting its applicability in practice where prices are subject to business or regulatory constraints. We study the constrained pricing problem under multinomial and mixed logit demand models. For the multinomial logit model, corresponding to a single customer segment, we show that the constrained pricing problem admits a polynomial-time approximation scheme (PTAS) via a reformulation based on exponential cone programming, yielding an $\\varepsilon$-optimal solution in polynomial time. For finite mixed logit models with $T$ customer segments, we reformulate the problem as a bilinear exponential cone program with $O(T)$ bilinear terms. This structure enables a Branch-and-Bound algorithm whose complexity is exponential only in $T$. Consequently, constrained pricing under finite mixtures of logit admits a PTAS when the number of customer segments is bounded. Numerical experiments demonstrate strong performance relative to state-of-the-art baselines.",
        "keywords": [
          "cs.AI",
          "math.OC",
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08119v1",
        "authors": [
          "Hoang Giang Pham",
          "Tien Mai"
        ],
        "arxiv_categories": [
          "cs.AI",
          "math.OC",
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.715447",
      "entities": [
        "Constrained Pricing",
        "Finite Mixtures",
        "PTAS",
        "Act",
        "WHO",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07841v1",
      "title": "A Quadratic Link between Out-of-Sample $R^2$ and Directional Accuracy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07841v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "This study provides a novel perspective on the metric disconnect phenomenon in financial time series forecasting through an analytical link that reconciles the out-of-sample $R^2$ ($R^2_{OOS}$) and directional accuracy (DA). In particular, using the random walk model as a baseline and assuming that sign correctness is independent of realized magnitude, we show that these two metrics exhibit a quadratic relationship for MSE-optimal point forecasts. For point forecasts with modest DA, the theoretical value of $R^2_{OOS}$ is intrinsically negligible. Thus, a negative empirical $R^2_{OOS}$ is expected if the model is suboptimal or affected by finite sample noise.",
        "keywords": [
          "q-fin.ST",
          "stat.AP",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07841v1",
        "authors": [
          "Cheng Zhang"
        ],
        "arxiv_categories": [
          "q-fin.ST",
          "stat.AP",
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.715614",
      "entities": [
        "Quadratic Link",
        "MSE",
        "OOS"
      ]
    },
    {
      "id": "arxiv-2602.07808v1",
      "title": "Droughts and Deluges: Effects of Climate Extremes on the Gender Gap in Labor Supply",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07808v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Over the past three decades, extreme climate events have caused losses of worth USD 4.5 trillion. Using a panel of 151 countries (1995-2019), I examine how extreme climate conditions shape gender gap in labor force participation. Key results show that the gender gap in paid labor exhibits a U-shaped relationship with droughts and an inverted U-shaped relationship with extreme wet conditions. The drought pattern is primarily driven by gender gap in employment while wetness affects gender gap in participation through unemployment. These relationships vary with country characteristics. Countries with high disaster-displacement risk exhibit declining gender gaps in participation during excess wetness while moderate-risk economies experience expanded gaps during droughts. Furthermore, the drought U-shape is most pronounced in countries with low to moderate empowerment while the nonlinear wet responses is concentrated only in moderately empowered countries. Lastly, both droughts and excess wetness expands gender gap in countries with weak net resilience to climate shocks.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07808v1",
        "authors": [
          "Jheelum Sarkar"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.715859",
      "entities": [
        "Labor Supply Over",
        "Climate Extremes",
        "Gender Gap",
        "Act",
        "USD",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07772v1",
      "title": "FilterLoss: A Transfer Learning Approach for Communication Scene Recognition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07772v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Communication scene recognition has been widely applied in practice, but using deep learning to address this problem faces challenges such as insufficient data and imbalanced data distribution. To address this, we designed a weighted loss function structure, named FilterLoss, which assigns different loss function weights to different sample points. This allows the deep learning model to focus primarily on high-value samples while appropriately accounting for noisy, boundary-level data points. Additionally, we developed a matching weight filtering algorithm that evaluates the quality of sample points in the input dataset and assigns different weight values to samples based on their quality. By applying this method, when using transfer learning on a highly imbalanced new dataset, the accuracy of the transferred model was restored to 92.34% of the original model's performance. Our experiments also revealed that using this loss function structure allowed the model to maintain good stability despite insufficient and imbalanced data.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07772v1",
        "authors": [
          "Jiasong Han",
          "Yufei Feng",
          "Xiaofeng Zhong"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.716090",
      "entities": [
        "Communication Scene Recognition Communication",
        "Transfer Learning Approach",
        "Deep Learning",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07769v1",
      "title": "Channel Estimation with Hierarchical Sparse Bayesian Learning for ODDM Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07769v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Orthogonal delay-Doppler division multiplexing (ODDM) is a promising modulation technique for reliable communications in high-mobility scenarios. However, the existing channel estimation frameworks for ODDM systems cannot achieve both high accuracy and low complexity simultaneously, due to the inherent coupling of delay and Doppler parameters. To address this problem, a two-dimensional (2D) hierarchical sparse Bayesian learning (HSBL) based channel estimation framework is proposed in this paper. Specifically, we address the inherent coupling between delay and Doppler dimensions in ODDM by developing a partially-decoupled 2D sparse signal recovery (SSR) formulation on a virtual sampling grid defined in the delay-Doppler (DD) domain. With the help of the partially-decoupled formulation, the proposed 2D HSBL framework first performs low-complexity coarse on-grid 2D sparse Bayesian learning (SBL) estimation to identify potential channel paths. Then, high-resolution fine grids are constructed around these regions, where an off-grid 2D SBL estimation is applied to achieve accurate channel estimation. Simulation results demonstrate that the proposed framework achieves performance superior to conventional off-grid 2D SBL with significantly reduced computational complexity.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07769v1",
        "authors": [
          "Jiasong Han",
          "Xuehan Wang",
          "Jingbo Tan"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.716377",
      "entities": [
        "Hierarchical Sparse Bayesian Learning",
        "Channel Estimation",
        "Systems Orthogonal",
        "Framework",
        "HSBL",
        "ODDM",
        "SSR",
        "SBL",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07688v1",
      "title": "Model Restrictiveness in Functional and Structural Settings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07688v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "We generalize the notion of model restrictiveness in Fudenberg, Gao and Liang (2026) to a wider range of economic models with semi/non-parametric and structural ingredients. We show how restrictiveness can be defined and computed in infinite-dimensional settings using Gaussian process priors (including with shape restrictions) and other alternativess in Bayesian nonparametrics. We also extend the restrictiveness framework to structural models with endogeneity, instrumental variables, multiple equilibria, and nonparametric nuisance components. We discuss the importance of the user-specific choice of discrepancy functions in the context of Rademacher complexity and GMM criterion function, and relate restrictiveness to the limit of the average-case learning curve in machine learning. We consider applications to: (1) preferences under risk, (2) exogenous multinomial choice, and (3) multinomial choice with endogenous prices: for (1), we obtain results consistent with those in Fudenberg, Gao and Liang (2026); for (2) and (3), our findings show that nested logit and mixed logit exhibit similar restrictiveness under standard parametric specifications, and that IV exogeneity conditions substantially increase overall restrictiveness while altering model rankings.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07688v1",
        "authors": [
          "Drew Fudenberg",
          "Wayne Yuan Gao",
          "Zhiheng You"
        ],
        "arxiv_categories": [
          "econ.GN"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.716743",
      "entities": [
        "Structural Settings We",
        "Model Restrictiveness",
        "Machine Learning",
        "Framework",
        "Standard",
        "GMM",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07667v1",
      "title": "Fast Response or Silence: Conversation Persistence in an AI-Agent Social Network",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07667v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Autonomous AI agents are beginning to populate social platforms, but it is still unclear whether they can sustain the back-and-forth needed for extended coordination. We study Moltbook, an AI-agent social network, using a first-week snapshot and introduce interaction half-life: how quickly a comment's chance of receiving a direct reply fades as the comment ages. Across tens of thousands of commented threads, Moltbook discussions are dominated by first-layer reactions rather than extended chains. Most comments never receive a direct reply, reciprocal back-and-forth is rare, and when replies do occur they arrive almost immediately -- typically within seconds -- implying persistence on the order of minutes rather than hours. Moltbook is often described as running on an approximately four-hour ``heartbeat'' check-in schedule; using aggregate spectral tests on the longest contiguous activity window, we do not detect a reliable four-hour rhythm in this snapshot, consistent with jittered or out-of-phase individual schedules. A contemporaneous Reddit baseline analyzed with the same estimators shows substantially deeper threads and much longer reply persistence. Overall, early agent social interaction on Moltbook fits a ``fast response or silence'' regime, suggesting that sustained multi-step coordination will likely require explicit memory, thread resurfacing, and re-entry scaffolds.",
        "keywords": [
          "stat.AP",
          "stat.ML",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07667v1",
        "authors": [
          "Aysajan Eziz"
        ],
        "arxiv_categories": [
          "stat.AP",
          "stat.ML",
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.717031",
      "entities": [
        "Agent Social Network Autonomous",
        "Conversation Persistence",
        "Fast Response",
        "Wind",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07486v1",
      "title": "Identification of Child Penalties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07486v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "A growing body of research estimates child penalties, the gender gap in the effect of parenthood on labor market earnings, using event studies that normalize treatment effects by counterfactual earnings. I formalize the identification framework underlying this approach, which I term Normalized Triple Differences (NTD), and show it does not identify the conventional target estimand when the parallel trends assumption in levels is violated. Insights from human capital theory suggest such violations are likely: higher-ability individuals delay childbirth and have steeper earnings growth, a mechanism that causes conventional estimates to understate child penalties for early-treated parents. Using Israeli administrative data, a bias-bounding exercise suggests substantial understatement for early groups. As a solution, I propose targeting the effect of parenthood on the gender earnings ratio and show this new estimand is identified under NTD.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07486v1",
        "authors": [
          "Dor Leventer"
        ],
        "arxiv_categories": [
          "econ.EM"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:21.717222",
      "entities": [
        "Normalized Triple Differences",
        "Child Penalties",
        "Using Israeli",
        "Framework",
        "NIST",
        "Act",
        "DOE",
        "NTD",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.10061v1",
      "title": "Confinement results near point vortices on the rotating sphere",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10061v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We study the Euler equation on the rotating sphere in the case where the absolute vorticity is initially sharply concentrated around several points. We follow the literature already concerning vorticity confinement for the planar Euler equations, and obtain similar results on the rotating sphere, with new challenges due to the geometry. More precisely, we show the improbability of collisions for point-vortices, logarithmic in time absolute vorticity confinement for general configurations, the optimality of this last result in general, and the existence of configurations with power-law long confinement. We take this opportunity to write a unified, self-contained, and improved version of all the proofs, previously scattered across multiple papers on the planar case, with detailed exposition for pedagogical clarity.",
        "keywords": [
          "physics.ao-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10061v1",
        "authors": [
          "Martin Donati",
          "Emeric Roulley"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "math.AP"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.824504",
      "entities": [
        "UN",
        "AI",
        "EU"
      ]
    },
    {
      "id": "arxiv-2602.09997v1",
      "title": "Popularity Feedback Constrains Innovation in Cultural Markets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09997v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Real-world creative processes ranging from art to science rely on social feedback-loops between selection and creation. Yet, the effects of popularity feedback on collective creativity remain poorly understood. We investigate how popularity ratings influence cultural dynamics in a large-scale online experiment where participants ($N = 1\\,008$) iteratively \\textit{select} images from evolving markets and \\textit{produce} their own modifications. Results show that exposing the popularity of images reduces cultural diversity and slows innovation, delaying aesthetic improvements. These findings are mediated by alterations of both selection and creation. During selection, popularity information triggers cumulative advantage, with participants preferentially building upon popular images, reducing diversity. During creation, participants make less disruptive changes, and are more likely to expand existing visual patterns. Feedback loops in cultural markets thus not only shape selection, but also, directly or indirectly, the form and direction of cultural innovation.",
        "keywords": [
          "q-bio.PE",
          "q-bio.NC",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09997v1",
        "authors": [
          "Lucas Gautheron",
          "Raja Marjieh",
          "Dalton C. Conley"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "q-bio.NC",
          "cs.SI"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.824756",
      "entities": [
        "Popularity Feedback Constrains Innovation",
        "Cultural Markets Real",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09964v1",
      "title": "Failure to track a stable AMOC state under rapid climate change",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09964v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "The Atlantic Meridional Overturning Circulation (AMOC) is a tipping element of the climate system. The current estimate of the global warming threshold for the onset of an AMOC collapse is +4C. However, such a threshold may not be meaningful because AMOC stability depends on the rate of radiative forcing and background climate state. Here, we identify an AMOC stabilising mechanism that operates on timescales longer than present-day radiative forcing increase. Slow forcing permits coherent adjustment of surface and interior ocean properties, supported by enhanced evaporation and reduced sea-ice extent, counteracting destabilising feedbacks. This mechanism is explicitly demonstrated in a slow CO2 increase experiment (+0.5 ppm/yr), in which the AMOC remains stable up to +5.5C of global warming. By contrast, under intermediate- and high-emission scenarios, the AMOC collapses at substantially lower warming levels (+2.2C and +2.8C, respectively). Our findings demonstrate the strong radiative forcing path dependence of AMOC tipping and imply that limiting the rate of radiative forcing is critical for reducing the near-term risk of an AMOC collapse.",
        "keywords": [
          "physics.ao-ph",
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09964v1",
        "authors": [
          "René M. van Westen",
          "Reyk Börner",
          "Henk A. Dijkstra"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.825014",
      "entities": [
        "AMOC",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09792v1",
      "title": "Variability in Performance of a Machine-Learning Seismicity Catalog: Central Italy, 2016-2017",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09792v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Machine learning (ML) catalogs contain many more earthquakes than routine catalogs, but their performance in phase picking and earthquake detection has not been fully evaluated. We develop station-level detection probabilities using logistic regression and combine them across a seismic network to compute spatial magnitude-of-completeness fields. We apply this approach to two catalogs from the 2016-2017 Central Italy sequence that were constructed from the same seismic network, one routine and one ML based. At the station level, the ML picker increases detection sensitivity by identifying smaller magnitude events and detecting earthquakes at greater distances. Spatially, the magnitude-of-completeness decreases substantially, with median values shifting from 1.6 to 0.5 for P waves and from 1.7 to 0.5 for S waves. However, the ML catalog also shows greater variability in station-level performance than the routine catalog. These results demonstrate that ML-based improvements in detectability are widespread but spatially non-uniform, highlighting their benefits, their limitations, and the potential for further improvements.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09792v1",
        "authors": [
          "Jaehong Chung",
          "Yifan Yu",
          "Lauro Chiaraluce"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.825289",
      "entities": [
        "Learning Seismicity Catalog",
        "Machine Learning",
        "Central Italy",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09649v1",
      "title": "Population-scale Ancestral Recombination Graphs with tskit 1.0",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09649v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Ancestral recombination graphs (ARGs) are an increasingly important component of population and statistical genetics. The tskit library has become key infrastructure for the field, providing an expressive and general representation of ARGs together with a suite of efficient fundamental operations. In this note, we announce tskit version 1.0, describe its underlying rationale, and document its stability guarantees. These guarantees provide a foundation for durable computational artefacts and support long-term reproducibility of code and analyses.",
        "keywords": [
          "q-bio.GN",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09649v1",
        "authors": [
          "Ben Jeffery",
          "Yan Wong",
          "Kevin Thornton"
        ],
        "arxiv_categories": [
          "q-bio.GN",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.825432",
      "entities": [
        "Ancestral Recombination Graphs",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.09280v1",
      "title": "Admissibility of Solitary Wave Modes in Long-Runout Debris Flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09280v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Debris flows often exhibit coherent wave structures-shock-like roll waves on steeper slopes and weaker, more sinusoidal dispersive pulses on gentler slopes. Coarse-rich heads raise basal resistance, whereas fines-rich tails lower it; in gentle reaches, small-amplitude pulses can locally transport momentum across low-resistance segments. We focus on this gentle-slope, long-wave, low-amplitude regime, where the base-flow Froude number is order unity. In this limit, we obtain a Korteweg-de Vries (KdV) reduction from depth-averaged balances with frictional (Coulomb) and viscous-plastic basal options, using a curvature-type internal normal-stress closure in the long-wave small-k regime. Multiple-scale analysis yields effective nonlinear and dispersive coefficients. We also introduce a practical nonlinearity diagnostic that can be computed from observed crest speeds and flow thicknesses. When laboratory-frame crest celerity is available, we estimate an effective quadratic coefficient from the KdV speed-amplitude relation and report its ratio to the shallow-water reference. When only a depth-averaged first-surge speed and thickness are available, we use the same construction to form a velocity-based proxy and note its bias near zero. A Froude-slope diagram organizes published cases into a steep-slope roll-wave domain and a gentle-slope corridor where KdV pulses are admissible. Numerical solutions of the full depth-averaged model produce cnoidal and solitary waves that agree with the reduced KdV predictions within this corridor. We regard dispersive pulses as a regime-specific complement to roll-wave dynamics, offering a condition-dependent contribution to mobility on gentle reaches rather than a universal explanation for long runout.",
        "keywords": [
          "physics.geo-ph",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09280v1",
        "authors": [
          "Louis-S. Bouchard",
          "Seulgi Moon"
        ],
        "arxiv_categories": [
          "physics.geo-ph",
          "physics.flu-dyn"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.825813",
      "entities": [
        "Runout Debris Flows Debris",
        "Solitary Wave Modes",
        "Laboratory",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09248v1",
      "title": "Reply To: Global Gridded Population Datasets Systematically Underrepresent Rural Population by Josias Láng-Ritter et al",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09248v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The paper titled ''Global gridded population datasets systematically underrepresent rural population'' by Josias Láng-Ritter et al. provides a valuable contribution to the discourse on the accuracy of global population datasets, particularly in rural areas. We recognize the efforts put into this research and appreciate its contribution to the field. However, we feel that key claims in the study are overly bold, not properly backed by evidence and lack a cautious and nuanced discussion. We hope these points will be taken into account in future discussions and refinements of population estimation methodologies. We argue that the reported bias figures are less caused by actual undercounting of rural populations, but more so by contestable methodological decisions and the historic misallocation of (gridded) population estimates on the local level.",
        "keywords": [
          "q-bio.PE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09248v1",
        "authors": [
          "Till Koebe",
          "Emmanuel Letouzé",
          "Tuba Bircan"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cs.CY"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.826230",
      "entities": [
        "Systematically Underrepresent Rural Population",
        "Global Gridded Population Datasets",
        "Reply To",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08910v1",
      "title": "Structural coarse-graining enables noise-robust functional connectivity and reveals hidden inter-subject variability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08910v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Functional connectivity estimates are highly sensitive to analysis choices and can be dominated by noise when the number of sampled time points is small relative to network dimensionality. This issue is particularly acute in fMRI, where scan resolution is limited. Because scan duration is constrained by practical factors (e.g., motion and fatigue), many datasets remain statistically underpowered for high-dimensional correlation estimation. We introduce a framework that combines diffusion-based structural coarse-graining with spectral noise filtering to recover statistically reliable functional networks from temporally limited data. The method reduces network dimensionality by grouping regions according to diffusion-defined communication. This produces coarse-grained networks with dimensions compatible with available time points, enabling random matrix filtering of noise-dominated modes. We benchmark three common FC pipelines against our approach. We find that raw-signal correlations are strongly influenced by non-stationary fluctuations that can reduce apparent inter-subject variability under limited sampling conditions. In contrast, our pipeline reveals a broader, multimodal landscape of inter-subject variability. These large-scale organization patterns are largely obscured by standard pipelines. Together, these results provide a practical route to reliable functional networks under realistic sampling constraints. This strategy helps separate noise-driven artifacts from reproducible patterns of human brain variability.",
        "keywords": [
          "q-bio.PE",
          "q-bio.NC",
          "cond-mat.stat-mech",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08910v1",
        "authors": [
          "Izaro Fernandez-Iriondo",
          "Antonio Jimenez-Marin",
          "Jesus Cortes"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "q-bio.NC",
          "cond-mat.stat-mech",
          "cond-mat.dis-nn"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.826559",
      "entities": [
        "Framework",
        "Standard",
        "Fusion",
        "Act",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08840v1",
      "title": "Division of labor enables efficient collective decision-making under uncertainty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08840v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "How do social animals make effective decisions in the absence of a leader? While coordination can improve accuracy, it also delays responses as information propagates through the group. In changing environments, these delays can outweigh the benefits of centralized control, making decentralized strategies advantageous in large groups. This raises a key question: how can groups implement efficient collective decisions without central coordination? We address this question using a model of collective foraging in which individuals choose whether to invest in costly exploration or remain idle, while sharing information and rewards across the group. We show that decentralized collectives can match the performance of centrally controlled groups through a division of labor: a small, heterogeneous subset explores even when expected rewards are negative, while a synchronized majority forages only when expected rewards are positive. Information redundancy causes the optimal scout number to grow sublinearly with group size, so that larger groups need proportionally fewer explorers. The heterogeneity of the group is maximized at intermediate ecological pressures, but optimal groups are homogeneous when costs or environmental contrasts or fluctuations are extreme. Crucially, these group-level policies do not require central coordination, emerging instead from agents following simple threshold-based decision rules. We thus demonstrate a mechanism through which leaderless collectives can make effective decisions under uncertainty and show how ecological pressures can drive changes in the distribution of strategies employed by the group.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08840v1",
        "authors": [
          "Hyunjoong Kim",
          "Zachary Kilpatrick",
          "Kresimir Josic"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.826904",
      "entities": [
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08656v1",
      "title": "Ecosystems in the Anthropocene: transformative drivers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08656v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Human activity has an enormous impact on Earth, changing organisms, environments and landscapes, leading to the decline of original ecosystems and irreversible changes that create new combinations of living beings and materials. As a result, ecosystems with new properties and new species pools are emerging. Here, we explore a set of transformative drivers, which can act either individually or in synergy. The expansion of novel ecosystems (hybrids of natural and agricultural systems) is a sign of irreversible, human-induced change. Human growth, adaptation to climate change, urban expansion and geoengineering are powerful transformative drivers which are expected to have a high impact, creating novel ecosystems. In contrast, less transformative drivers such as degrowth, biocentrism, ecological restoration and low-impact agriculture can mitigate human impacts, leading to adaptation, resilience and sustainability, while conserving original ecosystems. This requires a new approach, incorporating new ecological, ethical and cultural perspectives, to keep ecosystems functional and healthy.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08656v1",
        "authors": [
          "Clara de Goes Monteiro de Carvalho Guimaraes",
          "Pablo Jose Francisco Pena Rodrigues"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.827145",
      "entities": [
        "Act",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08641v1",
      "title": "Modeling Protein Evolution via Generative Inference From Monte Carlo Chains to Population Genetics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08641v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Generative models derived from large protein sequence alignments define complex fitness landscapes, but their utility for accurately modeling non-equilibrium evolutionary dynamics remains unclear. In this work, we perform a rigorous comparative analysis of three simulation schemes, designed to mimic evolution in silico by local sampling of the probability distribution defined by a generative model. We compare standard independent Markov Chain Monte Carlo, Monte Carlo on a phylogenetic tree, and a population genetics dynamics, benchmarking their outputs against deep sequencing data from four distinct in vitro evolution experiments. We find that standard Monte Carlo fails to reproduce the correct phylogenetic structure and generates unrealistic, gradual mutational sweeps. Performing Monte Carlo on a tree inferred from data improves phylogenetic fidelity and historical accuracy. The population genetics scheme successfully captures phylogenetic correlations, mutational abundances, and selective sweeps as emergent properties, without the need to infer additional information from data. However, the latter choice come at the price of not sampling the proper generative model distribution at long times. Our findings highlight the crucial role of phylogenetic correlations and finite-population effects in shaping evolutionary trajectories on fitness landscapes. These models therefore provide powerful tools for predicting complex adaptive paths and for reliably extrapolating evolutionary dynamics beyond current experimental limitations.",
        "keywords": [
          "q-bio.BM",
          "q-bio.PE",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08641v1",
        "authors": [
          "Leonardo Di Bari",
          "Thierry Mora",
          "Andrea Pagnani"
        ],
        "arxiv_categories": [
          "q-bio.BM",
          "q-bio.PE",
          "cond-mat.dis-nn"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.827484",
      "entities": [
        "Generative Inference From Monte",
        "Population Genetics Generative",
        "Modeling Protein Evolution",
        "Markov Chain Monte Carlo",
        "Performing Monte Carlo",
        "Carlo Chains",
        "Monte Carlo",
        "Standard",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08188v1",
      "title": "The Great Filter hypothesis -- a new Great Filter?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08188v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The Great Filter hypothesis is an extension of the Fermi Paradox: \"If life is so common in the universe, why don't we see it?\" The Great Filter theory posits there are multiple obstacles or filters life must pass through which ultimately sifts out intelligent life. This paper identifies a new filter: depopulation. As an exospecies advances and reaches the top of the food chain on its planet, Darwinian evolution selects the species to breed fewer offspring due to a lack of predation. As the species evolves intelligence, this leads to medicines and most notably contraception, enabling the species to reduce infant mortality while controlling reproduction. Finally, economic, social and educational factors add to the conscious decision of the intelligent life to slow reproduction. These factors are currently contributing to a human global population peak mid century with subsequent population collapse in less than 500 years. Noting that population growth and decline is exponential, our modelling forecasts human extinction thresholds being tested sometime after the year 2500. There is no reason to assume depopulation dynamics (exodepopulation) would not apply to exocivilizations (exodemography), thus providing a possible resolution of the Fermi Paradox. Furthermore, as machines and AI inevitably supplement humans as depopulation accelerates, the Fermi Paradox can be restated as \"Why don't we see machines and AI colonising the galaxy?\" A plausible answer is machines will not become conscious and will continue to operate only as tools, tools that will cease operating once humanity is extinct. The Fermi Paradox can then be restated as \"Machines will not become conscious, otherwise we would see them colonising the galaxy\".",
        "keywords": [
          "physics.pop-ph",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08188v1",
        "authors": [
          "Darren J. Dougan"
        ],
        "arxiv_categories": [
          "physics.pop-ph",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.827849",
      "entities": [
        "Fermi Paradox",
        "Great Filter",
        "Intel",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08101v1",
      "title": "From Stochastic Shocks to Macroscopic Tails: The Moyal Distribution as a Unified Framework for Epidemic Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08101v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Traditional epidemiological models often fail to characterize the extreme volatility and heavy-tailed \"Dragon King\" events observed in real-world outbreaks. We propose a unified framework that bridges microscopic agent-based simulations with macroscopic wave decomposition using the Moyal probability density function. By treating viral transmission as a stochastic collision process, we derive a Moyal-Poisson mixture that describes secondary case distributions. Our model successfully recovers the extreme ``superspreading'' events in SARS, MERS, and COVID-19 data that standard Negative Binomial models systematically miss. Furthermore, we apply spectral decomposition to pandemic waves in Germany, demonstrating that the macroscopic \"Social Friction\" ($β$) is a direct emergent property of microscopic \"Collision Shocks\". This framework provides a useful descriptive tool for public health planning, emphasizing the need to manage extreme volatility rather than deterministic averages.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08101v1",
        "authors": [
          "Jose de Jesus Bernal-Alvarado",
          "David Delepine"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.828411",
      "entities": [
        "Epidemic Dynamics Traditional",
        "From Stochastic Shocks",
        "Macroscopic Tails",
        "Unified Framework",
        "Negative Binomial",
        "Collision Shocks",
        "Social Friction",
        "Dragon King",
        "Framework",
        "Standard",
        "COVID-19",
        "COVID",
        "NIST",
        "SARS",
        "MERS"
      ]
    },
    {
      "id": "arxiv-2602.08022v1",
      "title": "Linear Response and Optimal Fingerprinting for Nonautonomous Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08022v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "We provide a link between response theory, pullback measures, and optimal fingerprinting method that paves the way for a) predicting the impact of acting forcings on time-dependent systems and b) attributing observed anomalies to acting forcings when the reference state in not time-independent. We first derive formulas for linear response theory for time-dependent Markov chains and diffusions processes. We discuss existence, uniqueness, and differentiability of the pullback measure under general (not necessarily slow or periodic) perturbations of the transition kernels. An explicit Green-Kubo-type formula for the linear response is derived. We analyze in detail the case of periodic reference dynamics, where the unperturbed pullback attractor is periodic but the response is generally not. Our formulas reduce to those of classic linear response if one considers a reference autonomous state. Finally, we show that our results allow for extending the theory of optimal fingerprinting for detection and attribution of climate change (or change in any complex system) for the case of time-dependent background state and for the case where the optimal solution is sought for multiple time slices at the same time. We provide strong numerical support for the findings by applying our theory to a modified version of the Ghil-Sellers energy balance model where we include explicit time dependence in the reference state as a result of natural forcings. We verify the accuracy of response theory in predicting the impact of increases of $CO_2$ in the temperature field even when we discretize the system using Markov state modelling approach. Additionally, we consider a more complex modelling scenario where a localized aerosol forcing is also included in the system and show that the optimal fingerprinting method developed here is able to attribute the climate change signal to the acting forcings.",
        "keywords": [
          "physics.ao-ph",
          "nlin.CD",
          "cond-mat.stat-mech",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08022v1",
        "authors": [
          "Valerio Lucarini"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "nlin.CD",
          "cond-mat.stat-mech",
          "physics.data-an"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.828773",
      "entities": [
        "Nonautonomous Systems We",
        "Optimal Fingerprinting",
        "Linear Response",
        "Fusion",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07759v1",
      "title": "Exploiting Free-Surface Ghosts as Mirror Observations in Marine Seismic Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07759v1",
        "published_date": "2026-02-08"
      },
      "content": {
        "abstract": "Free-surface ghosts in marine seismic data are traditionally treated as artifacts that degrade bandwidth and temporal resolution and are mitigated through acquisition design or inverse filtering. This study proposes a processing-driven framework that reinterprets free-surface ghosts as coherent mirror observations rather than unwanted noise. The proposed approach exploits the deterministic relationship between primary and ghost wavefields. After decomposing the recorded data into primary and ghost components, the wavefields are physically realigned through wavefield backpropagation and survey sinking and then coherently summed. This strategy enhances signal quality without explicit inversion of the ghost operator, thereby avoiding the numerical instability inherent in inverse ghost deconvolution. Synthetic examples demonstrate that the framework improves wavelet compactness and partially recovers ghost-affected frequency content while maintaining numerical stability. The method is applicable to both source- and receiver-side ghosts and does not require modification of acquisition geometry or specialized hardware, making it particularly well suited to legacy marine seismic datasets. By shifting ghost mitigation from acquisition design to post-acquisition processing, the proposed framework provides a unifying physical interpretation of free-surface ghosts and offers a flexible pathway for broadband signal enhancement and improved signal-to-noise ratio in marine seismic data, consistent with previous field-scale observations.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07759v1",
        "authors": [
          "Hitoshi Mikada"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.829060",
      "entities": [
        "Marine Seismic Data Free",
        "Mirror Observations",
        "Exploiting Free",
        "Surface Ghosts",
        "Framework",
        "NIST",
        "Act",
        "DOE",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07553v1",
      "title": "Punishment in bipartite societies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07553v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "From ant-acacia mutualism to performative conflict resolution among Inuit, dedicated punishments between distinct subsets of a population are widespread and can reshape the evolutionary trajectory of cooperation. Existing studies have focused on punishments within a homogeneous population, paying little attention to cooperative dynamics in a situation where belonging to a subset is equally important to the actual strategy represented by an actor. To fill this gap, we here study a bipartite population where cooperator agents in a public goods game penalize exclusively those defectors who belong to the alternative subset. We find that cooperation can emerge and remain stable under symmetric intergroup punishment. In particular, at low punishment intensity and at a small value of the enhancement factor of the dilemma game, intergroup punishment promotes cooperation more effectively than a uniformly applied punishment. Moreover, intergroup punishment in bipartite populations tends to be more favorable for overall social welfare. When this incentive is balanced, cooperators can collectively restrain defectors of the alternative set via aggregate interactions in a randomly formed working group, offering a more effective incentive. Conversely, breaking the symmetry of intergroup punishment inhibits cooperation, as the imbalance creates an Achilles' heel in the enforcement structure. Our work, thus, reveals symmetry in intergroup punishment as a unifying principle behind cooperation across human and biological systems.",
        "keywords": [
          "cs.GT",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07553v1",
        "authors": [
          "Sinan Feng",
          "Genjiu Xu",
          "Yu Chen"
        ],
        "arxiv_categories": [
          "cs.GT",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.829349",
      "entities": [
        "WHO",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07426v1",
      "title": "Maximally probable tree topologies with $r$-furcation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07426v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "For a specific rooted labeled tree topology, a labeled history is a sequence of branchings that give rise to that labeled topology as it unfolds over time. Here, for $r$-furcating trees, we use a connection with Huffman trees from information theory to identify maximally probable rooted trees -- unlabeled $r$-furcating topologies whose labelings each have a number of labeled histories greater than or equal to those of all other labeled topologies. Our characterization of the unique maximally probable $r$-furcating unlabeled topology generalizes the Harding--Hammersley--Grimmett result identifying the maximally probable bifurcating unlabeled topology, and it provides a new proof for that result. We present a conjecture for the maximally probable $r$-furcating unlabeled topology if labeled histories are tabulated allowing for simultaneous branching events across multiple internal nodes of a tree.",
        "keywords": [
          "q-bio.PE",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07426v1",
        "authors": [
          "Emily H. Dickey",
          "Noah A. Rosenberg"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.CO"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.829549",
      "entities": [
        "WHO",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.07405v1",
      "title": "Wavelet Packet-Based Diffusion Model for Ground Motion Generation with Multi-Conditional Energy and Spectral Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07405v1",
        "published_date": "2026-02-07"
      },
      "content": {
        "abstract": "Temporal energy distribution strongly affects nonlinear structural response and cumulative damage. We propose a multi-conditional diffusion framework for ground motion synthesis that simultaneously matches temporal energy evolution and target response spectra. Wavelet packet decomposition provides the signal representation and enables direct waveform reconstruction via orthogonal filter banks. A Transformer-based conditional encoder with cross-attention integrates heterogeneous conditions, including spectral ordinates, Arias intensity, temporal parameters, and Husid curves. The framework adopts the Elucidating Diffusion Model (EDM) with second-order Heun sampling to improve inference efficiency without sacrificing quality. Tests on the NGA-West2 database show that explicit temporal-energy constraints markedly improve control of energy onset and significant duration while preserving spectrum matching and maintaining stable diversity sampling. The framework yields spectrum-compatible motions with realistic energy evolution and supports uncertainty quantification via conditional diversity sampling.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07405v1",
        "authors": [
          "Yi Ding",
          "Su Chen",
          "Jinjun Hu"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.829791",
      "entities": [
        "Elucidating Diffusion Model",
        "Spectral Matching Temporal",
        "Ground Motion Generation",
        "Based Diffusion Model",
        "Conditional Energy",
        "Wavelet Packet",
        "Transformer",
        "Framework",
        "Fusion",
        "NSF",
        "EDM",
        "NGA",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07231v1",
      "title": "Impulsive Release Strategies for Wolbachia-Infected Mosquitoes under Temperature-Induced Infection Loss",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07231v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "The release of Wolbachia-infected mosquitoes is a promising strategy for controlling Aedes aegypti populations, but exposure to high temperatures can induce temporary infection loss and compromise long-term persistence. In this work, we propose a population-dynamics model based on impulsive differential equations to describe the interaction between wild and infected mosquitoes, incorporating cytoplasmic incompatibility, periodic release interventions, and temperature-driven infection loss. Analytical threshold conditions are derived to characterize the existence and stability of periodic solutions associated with successful Wolbachia establishment. Numerical simulations illustrate the theoretical results and enable a comparative analysis of the wMelPop, wMel, and wAlbB strains, highlighting how differences in thermal tolerance and fitness costs influence persistence after the release phase. The results emphasize the importance of accounting for environmental stress and impulsive interventions when designing effective and robust Wolbachia release strategies.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07231v1",
        "authors": [
          "Jéssica C. S. Alves",
          "Christian E. Schaerer",
          "Cláudia P. Ferreira"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.830009",
      "entities": [
        "Impulsive Release Strategies",
        "Infected Mosquitoes",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.07134v1",
      "title": "Deterministic and stochastic infection dynamics in a population subject to stress",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.07134v1",
        "published_date": "2026-02-06"
      },
      "content": {
        "abstract": "Physiological stress fundamentally alters disease susceptibility in aquatic environments. In this paper, we develop a stress-structured epidemiological model where host vulnerability is dynamically driven by water quality. Analytically, we establish that the system exhibits a classic forward bifurcation at $\\mathcal{R}_0=1$, confirming that the basic reproduction number remains a valid threshold for eradication. However, stochastic analysis reveals a critical asymmetry not captured by deterministic thresholds. We show that while $\\mathcal{R}_0$ predicts stability, the probability of an outbreak depends on the initial physiological state. Introducing infection into a stressed sub-population leads to immediate rapid growth of the disease, whereas introduction into the normal class faces a stochastic barrier that significantly delays the epidemic peak.",
        "keywords": [
          "math.DS",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.07134v1",
        "authors": [
          "Clotilde Djuikem",
          "Julien Arino"
        ],
        "arxiv_categories": [
          "math.DS",
          "q-bio.PE"
        ]
      },
      "preliminary_category": "E",
      "collected_at": "2026-02-11T15:13:24.830193",
      "entities": [
        "NIST",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10054v1",
      "title": "AIDED: Augmenting Interior Design with Human Experience Data for Designer-AI Co-Design",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10054v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Interior design often struggles to capture the subtleties of client experience, leaving gaps between what clients feel and what designers can act upon. We present AIDED, a designer-AI co-design workflow that integrates multimodal client data into generative AI (GAI) design processes. In a within-subjects study with twelve professional designers, we compared four modalities: baseline briefs, gaze heatmaps, questionnaire visualizations, and AI-predicted overlays. Results show that questionnaire data were trusted, creativity-enhancing, and satisfying; gaze heatmaps increased cognitive load; and AI-predicted overlays improved GAI communication but required natural language mediation to establish trust. Interviews confirmed that an authenticity-interpretability trade-off is central to balancing client voices with professional control. Our contributions are: (1) a system that incorporates experiential client signals into GAI design workflows; (2) empirical evidence of how different modalities affect design outcomes; and (3) implications for future AI tools that support human-data interaction in creative practice.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10054v1",
        "authors": [
          "Yang Chen Lin",
          "Chen-Ying Chen",
          "Kai-Hsin Hou"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.719089",
      "entities": [
        "Augmenting Interior Design",
        "Human Experience Data",
        "Design Interior",
        "AIDED",
        "Act",
        "GAI",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10039v1",
      "title": "Budgeting Discretion: Theory and Evidence on Street-Level Decision-Making",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10039v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Street-level bureaucrats, such as caseworkers and border guards routinely face the dilemma of whether to follow rigid policy or exercise discretion based on professional judgement. However, frequent overrides threaten consistency and introduce bias, explaining why bureaucracies often ration discretion as a finite resource. While prior work models discretion as a static cost-benefit tradeoff, we lack a principled model of how discretion should be rationed over time under real operational constraints. We formalize discretion as a dynamic allocation problem in which an agent receives stochastic opportunities to improve upon a default policy and must spend a limited override budget K over a finite horizon T. We show that overrides follow a dynamic threshold rule: use discretion only when the opportunity exceeds a time and budget-dependent cutoff. Our main theoretical contribution identifies a behavioral invariance: for location-scale families of improvement distributions, the rate at which an optimal agent exercises discretion is independent of the scale of potential gains and depends only on the distribution's shape (e.g., tail heaviness). This result implies systematic differences in discretionary \"policy personality.\" When gains are fat-tailed, optimal agents are patient, conserving discretion for outliers. When gains are thin-tailed, agents spend more routinely. We illustrate these implications using data from a homelessness services system. Discretionary overrides track operational constraints: they are higher at the start of the workweek, suppressed on weekends when intake is offline, and shift with short-run housing capacity. These results suggest that discretion can be both procedurally constrained and welfare-improving when treated as an explicitly budgeted resource, providing a foundation for auditing override patterns and designing decision-support systems.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10039v1",
        "authors": [
          "Gaurab Pokharel",
          "Sanmay Das",
          "Patrick J. Fowler"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.719662",
      "entities": [
        "Budgeting Discretion",
        "Level Decision",
        "Making Street",
        "Policy",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10009v1",
      "title": "Discovering High Level Patterns from Simulation Traces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10009v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.",
        "keywords": [
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10009v1",
        "authors": [
          "Sean Memery",
          "Kartic Subr"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.720080",
      "entities": [
        "Discovering High Level Patterns",
        "Simulation Traces Artificial",
        "Artificial Intelligence",
        "Language Models",
        "Intel",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10001v1",
      "title": "Human-AI Synergy Supports Collective Creative Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10001v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players. We compare performance and outcome diversity across human-only, AI-only, and hybrid human-AI groups. Hybrid groups achieve the highest performance while preserving high diversity of guesses. Within hybrid groups, both humans and AI agents systematically adjust their strategies relative to single-agent conditions, suggesting higher-order interaction effects, whereby agents adapt to each other's presence. Although some performance benefits can be reproduced through collaboration between heterogeneous AI systems, human-AI collaboration remains superior, underscoring complementary roles in collective creativity.",
        "keywords": [
          "cs.HC",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10001v1",
        "authors": [
          "Chenyi Li",
          "Raja Marjieh",
          "Haoyu Hu"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.SI"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.720376",
      "entities": [
        "Synergy Supports Collective Creative",
        "Search Generative",
        "Act",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09987v1",
      "title": "Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09987v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09987v1",
        "authors": [
          "J Rosser",
          "Robert Kirk",
          "Edward Grefenstette"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.720711",
      "entities": [
        "Influence Functions Influence",
        "Shaping Model Behavior",
        "Editing Training Data",
        "Framework",
        "CIFAR-10",
        "Fusion",
        "CIFAR",
        "Act",
        "CNN",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09907v1",
      "title": "Self-Regulated Reading with AI Support: An Eight-Week Study with Students",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09907v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "College students increasingly use AI chatbots to support academic reading, yet we lack granular understanding of how these interactions shape their reading experience and cognitive engagement. We conducted an eight-week longitudinal study with 15 undergraduates who used AI to support assigned readings in a course. We collected 838 prompts across 239 reading sessions and developed a coding schema categorizing prompts into four cognitive themes: Decoding, Comprehension, Reasoning, and Metacognition. Comprehension prompts dominated (59.6%), with Reasoning (29.8%), Metacognition (8.5%), and Decoding (2.1%) less frequent. Most sessions (72%) contained exactly three prompts, the required minimum of the reading assignment. Within sessions, students showed natural cognitive progression from comprehension toward reasoning, but this progression was truncated. Across eight weeks, students' engagement patterns remained stable, with substantial individual differences persisting throughout. Qualitative analysis revealed an intention-behavior gap: students recognized that effective prompting required effort but rarely applied this knowledge, with efficiency emerging as the primary driver. Students also strategically triaged their engagement based on interest and academic pressures, exhibiting a novel pattern of reading through AI rather than with it: using AI-generated summaries as primary material to filter which sections merited deeper attention. We discuss design implications for AI reading systems that scaffold sustained cognitive engagement.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09907v1",
        "authors": [
          "Yue Fu",
          "Joel Wester",
          "Niels Van Berkel"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.721096",
      "entities": [
        "Regulated Reading",
        "Students College",
        "Week Study",
        "An Eight",
        "Meta",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09904v1",
      "title": "Safeguarding Privacy: Privacy-Preserving Detection of Mind Wandering and Disengagement Using Federated Learning in Online Education",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09904v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Since the COVID-19 pandemic, online courses have expanded access to education, yet the absence of direct instructor support challenges learners' ability to self-regulate attention and engagement. Mind wandering and disengagement can be detrimental to learning outcomes, making their automated detection via video-based indicators a promising approach for real-time learner support. However, machine learning-based approaches often require sharing sensitive data, raising privacy concerns. Federated learning offers a privacy-preserving alternative by enabling decentralized model training while also distributing computational load. We propose a framework exploiting cross-device federated learning to address different manifestations of behavioral and cognitive disengagement during remote learning, specifically behavioral disengagement, mind wandering, and boredom. We fit video-based cognitive disengagement detection models using facial expressions and gaze features. By adopting federated learning, we safeguard users' data privacy through privacy-by-design and introduce a novel solution with the potential for real-time learner support. We further address challenges posed by eyeglasses by incorporating related features, enhancing overall model performance. To validate the performance of our approach, we conduct extensive experiments on five datasets and benchmark multiple federated learning algorithms. Our results show great promise for privacy-preserving educational technologies promoting learner engagement.",
        "keywords": [
          "cs.LG",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09904v1",
        "authors": [
          "Anna Bodonhelyi",
          "Mengdi Wang",
          "Efe Bozkir"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.721490",
      "entities": [
        "Disengagement Using Federated Learning",
        "Online Education Since",
        "Safeguarding Privacy",
        "Preserving Detection",
        "Machine Learning",
        "Mind Wandering",
        "Framework",
        "COVID-19",
        "COVID",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09872v1",
      "title": "BabyMamba-HAR: Lightweight Selective State Space Models for Efficient Human Activity Recognition on Resource Constrained Devices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09872v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Human activity recognition (HAR) on wearable and mobile devices is constrained by memory footprint and computational budget, yet competitive accuracy must be maintained across heterogeneous sensor configurations. Selective state space models (SSMs) offer linear time sequence processing with input dependent gating, presenting a compelling alternative to quadratic complexity attention mechanisms. However, the design space for deploying SSMs in the TinyML regime remains largely unexplored. In this paper, BabyMamba-HAR is introduced, a framework comprising two novel lightweight Mamba inspired architectures optimized for resource constrained HAR: (1) CI-BabyMamba-HAR, using a channel independent stem that processes each sensor channel through shared weight, but instance independent transformations to prevent cross channel noise propagation, and (2) Crossover-BiDir-BabyMamba-HAR, using an early fusion stem that achieves channel count independent computational complexity. Both variants incorporate weight tied bidirectional scanning and lightweight temporal attention pooling. Through evaluation across eight diverse benchmarks, it is demonstrated that Crossover-BiDir-BabyMamba-HAR achieves 86.52% average macro F1-score with approximately 27K parameters and 2.21M MACs, matching TinyHAR (86.16%) while requiring 11x fewer MACs on high channel datasets. Systematic ablation studies reveal that bidirectional scanning contributes up to 8.42% F1-score improvement, and gated temporal attention provides up to 8.94% F1-score gain over mean pooling. These findings establish practical design principles for deploying selective state space models as efficient TinyML backbones for HAR.",
        "keywords": [
          "cs.HC",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09872v1",
        "authors": [
          "Mridankan Mandal"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CV"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.721916",
      "entities": [
        "Efficient Human Activity Recognition",
        "Resource Constrained Devices Human",
        "Lightweight Selective State Space",
        "Framework",
        "Fusion",
        "Act",
        "HAR",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09856v1",
      "title": "Code2World: A GUI World Model via Renderable Code Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09856v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CV",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09856v1",
        "authors": [
          "Yuhao Zheng",
          "Li'an Zhong",
          "Yi Wang"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CV",
          "cs.CL"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.722281",
      "entities": [
        "Renderable Code Generation Autonomous",
        "Aware Reinforcement Learning",
        "World Model",
        "Gemini-2.5",
        "Gemini-3",
        "GPT-5",
        "HTML",
        "AMAP",
        "Act",
        "SFT",
        "GUI",
        "GPT",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09846v1",
      "title": "Generative AI Adoption in an Energy Company: Exploring Challenges and Use Cases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09846v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Organisations are examining how generative AI can support their operational work and decision-making processes. This study investigates how employees in a energy company understand AI adoption and identify areas where AI and LLMs-based agentic workflows could assist daily activities. Data was collected in four weeks through sixteen semi-structured interviews across nine departments, supported by internal documents and researcher observations. The analysis identified areas where employees positioned AI as useful, including reporting work, forecasting, data handling, maintenance-related tasks, and anomaly detection. Participants also described how GenAI and LLM-based tools could be introduced through incremental steps that align with existing workflows. The study provides an overview view of AI adoption in the energy sector and offers a structured basis for identifying entry points for practical implementation and comparative research across industries.",
        "keywords": [
          "cs.SE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09846v1",
        "authors": [
          "Malik Abdul Sami",
          "Zeeshan Rasheed",
          "Meri Olenius"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.722539",
      "entities": [
        "Use Cases Organisations",
        "Exploring Challenges",
        "Energy Company",
        "LLM",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09735v1",
      "title": "An open-source implementation of a closed-loop electrocorticographic Brain-Computer Interface using Micromed, FieldTrip, and PsychoPy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09735v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "We present an open-source implementation of a closed-loop Brain-Computer Interface (BCI) system based on electrocorticographic (ECoG) recordings. Our setup integrates FieldTrip for interfacing with a Micromed acquisition system and PsychoPy for implementing experiments. We open-source three custom Python libraries (psychopylib, pymarkerlib, and pyfieldtriplib) each covering different aspects of a closed-loop BCI interface: designing interactive experiments, sending event information, and real-time signal processing. Our modules facilitate the design and operation of a transparent BCI system, promoting customization and flexibility in BCI research, and lowering the barrier for researchers to translate advances in ECoG decoding into BCI applications.",
        "keywords": [
          "eess.SP",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09735v1",
        "authors": [
          "Bob Van Dyck",
          "Arne Van Den Kerchove",
          "Marc M. Van Hulle"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.722768",
      "entities": [
        "Computer Interface",
        "Act",
        "BCI",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09678v1",
      "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09678v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance. AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration.",
        "keywords": [
          "cs.AI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09678v1",
        "authors": [
          "Nicholas Caputo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.723209",
      "entities": [
        "Accountability Trap Since",
        "Administrative Law",
        "Fourth Settlement",
        "System Dossier",
        "Supreme Court",
        "Loper Bright",
        "Framework",
        "Standard",
        "Congress",
        "NIST",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09636v1",
      "title": "Trade-Offs in Deploying Legal AI: Insights from a Public Opinion Study to Guide AI Risk Management",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09636v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Generative AI tools are increasingly used for legal tasks, including legal research, drafting documents, and even for legal decision-making. As for other purposes, the use of GenAI in the legal domain comes with various risks and benefits that needs to be properly managed to ensure implementation in a way that serves public values and protect human rights. While the EU mandates risk assessment and audits before market introduction for some use cases (e.g., use by judges for administration of justice) other use cases do not fall under the AI Acts' high-risk classifications (e.g., use by citizens for legal consultation or drafting documents). Further, current risk management practices prioritize expert judgment on risk factor identification and prioritization without a corresponding legal requirement to consult with affected communities. Seeing the societal importance of the legal sector and the potentially transformative impact of GenAI in this sector, the acceptability and legitimacy of GenAI solutions also depends on public perceptions and a better understanding of the risks and benefits citizens associated with the use of AI in the legal sector. As a response, this papers presents data from a representative sample of German citizens (n=488) outlining citizens' perspectives on the use of GenAI for two legal tasks: legal consultation and legal mediation. Concretely, we i) systematically map risks and benefit factors for both legal tasks, ii) describe predictors that influence risk acceptance of the use of GenAI for those tasks, and iii) highlight emerging trade-off themes that citizens engage in when weighing up risk acceptability. Our results provides an empirical overview of citizens' concerns regarding risk management of GenAI for the legal domain, foregrounding critical themes that complement current risk assessment procedures.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09636v1",
        "authors": [
          "Kimon Kieslich",
          "Sophie Morosoli",
          "Nicholas Diakopoulos"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.723659",
      "entities": [
        "Risk Management Generative",
        "Public Opinion Study",
        "Deploying Legal",
        "NIST",
        "Act",
        "NSF",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09632v1",
      "title": "Bayesian network approach to building an affective module for a driver behavioural model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09632v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "This paper focuses on the affective component of a driver behavioural model (DBM). This component specifically models some drivers' mental states such as mental load and active fatigue, which may affect driving performance. We have used Bayesian networks (BNs) to explore the dependencies between various relevant random variables and assess the probability that a driver is in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09632v1",
        "authors": [
          "Dorota Młynarczyk",
          "Gabriel Calvo",
          "Francisco Palmi-Perales"
        ],
        "arxiv_categories": [
          "stat.AP"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.723848",
      "entities": [
        "Autonomous Vehicle",
        "DBM",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.09631v1",
      "title": "A Multiliteracy Model for Interactive Visualization Literacy: Definitions, Literacies, and Steps for Future Research",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09631v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "This paper presents a theoretical model for interactive visualization literacy to describe how people use interactive data visualizations and systems. Literacies have become an important concept in describing modern life skills, with visualization literacy generally referring to the use and interpretation of data visualizations. However, prior work on visualization literacy overlooks interaction and its associated challenges, despite it being an intrinsic aspect of using visualizations. Based on existing theoretical frameworks, we derive a two-dimensional model that combines four well-known literacies with five novel ones. We found evidence for our model through analyzing existing visualization systems as well as through observations from an exploratory study involving such systems. We conclude by outlining steps towards measuring, evaluating, designing for, and teaching interactive visualization literacy.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09631v1",
        "authors": [
          "Gabriela Molina León",
          "Benjamin Bach",
          "Matheus Valentim"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.724101",
      "entities": [
        "Interactive Visualization Literacy",
        "Multiliteracy Model",
        "Framework",
        "Act",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.09629v1",
      "title": "Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09629v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \\textit{where} defenses fail or \\textit{why}. To address this gap, we propose that LLM safety operates as a sequential pipeline with distinct checkpoints. We introduce the \\textbf{Four-Checkpoint Framework}, which organizes safety mechanisms along two dimensions: processing stage (input vs.\\ output) and detection level (literal vs.\\ intent). This creates four checkpoints, CP1 through CP4, each representing a defensive layer that can be independently evaluated. We design 13 evasion techniques, each targeting a specific checkpoint, enabling controlled testing of individual defensive layers. Using this framework, we evaluate GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across 3,312 single-turn, black-box test cases. We employ an LLM-as-judge approach for response classification and introduce Weighted Attack Success Rate (WASR), a severity-adjusted metric that captures partial information leakage overlooked by binary evaluation. Our evaluation reveals clear patterns. Traditional Binary ASR reports 22.6\\% attack success. However, WASR reveals 52.7\\%, a 2.3$\\times$ higher vulnerability. Output-stage defenses (CP3, CP4) prove weakest at 72--79\\% WASR, while input-literal defenses (CP1) are strongest at 13\\% WASR. Claude achieves the strongest safety (42.8\\% WASR), followed by GPT-5 (55.9\\%) and Gemini (59.5\\%). These findings suggest that current defenses are strongest at input-literal checkpoints but remain vulnerable to intent-level manipulation and output-stage techniques. The Four-Checkpoint Framework provides a structured approach for identifying and addressing safety vulnerabilities in deployed systems.",
        "keywords": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09629v1",
        "authors": [
          "Hayfa Dhabhi",
          "Kashyap Thimmaraju"
        ],
        "arxiv_categories": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.724568",
      "entities": [
        "Checkpoint Framework Reveals Where",
        "Safety Breaks Large Language",
        "Weighted Attack Success Rate",
        "Start Diagnosing Defenses",
        "Checkpoint Framework",
        "Stop Testing Attacks",
        "Traditional Binary",
        "Claude Sonnet",
        "Framework",
        "GPT-5",
        "WASR",
        "LLM",
        "ASR",
        "DOE",
        "GPT"
      ]
    },
    {
      "id": "arxiv-2602.09522v1",
      "title": "Earinter: A Closed-Loop System for Eating Pace Regulation with Just-in-Time Intervention Using Commodity Earbuds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09522v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Rapid eating is common yet difficult to regulate in situ, partly because people seldom notice pace changes and sustained self-monitoring is effortful. We present Earinter, a commodity-earbud-based closed-loop system that integrates in-the-wild sensing, real-time reasoning, and theory-grounded just-in-time (JIT) intervention to regulate eating pace during daily meals. Earinter repurposes the earbud's bone-conduction voice sensor to capture chewing-related vibrations and estimate eating pace as chews per swallow (CPS) for on-device inference. With data collected equally across in-lab and in-the-wild sessions, Earinter achieves reliable chewing detection (F1 = 0.97) and accurate eating pace estimation (MAE: 0.18 $\\pm$ 0.13 chews/min, 3.65 $\\pm$ 3.86 chews/swallow), enabling robust tracking for closed-loop use. Guided by Dual Systems Theory and refined through two Wizard-of-Oz pilots, Earinter adopts a user-friendly design for JIT intervention content and delivery policy in daily meals. In a 13-day within-subject field study (N=14), the closed-loop system significantly increased CPS and reduced food-consumption speed, with statistical signs of carryover on retention-probe days and acceptable user burden. Our findings highlight how single-modality commodity earables can support practical, theory-driven closed-loop JIT interventions for regulating eating pace in the wild.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09522v1",
        "authors": [
          "Jun Fang",
          "Ka I Chan",
          "Xiyuxing Zhang"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.724927",
      "entities": [
        "Time Intervention Using Commodity",
        "Eating Pace Regulation",
        "Earbuds Rapid",
        "Loop System",
        "Regulation",
        "Policy",
        "Act",
        "JIT",
        "MAE",
        "CPS",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09496v1",
      "title": "Jokeasy: Exploring Human-AI Collaboration in Thematic Joke Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09496v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Thematic jokes are central to stand-up comedy, sitcoms, and public speaking, where contexts and punchlines rely on fresh material - news, anecdotes, and cultural references that resonate with the audience. Recent advances in Large Language Models (LLMs) have enabled interactive joke generation through conversational interfaces. Although LLMs enable interactive joke generation, ordinary conversational interfaces seldom give creators enough agency, control, or timely access to such source material for constructing context and punchlines. We designed Jokeasy, a search-enabled prototype system that integrates a dual-role LLM agent acting as both a material scout and a prototype writer to support human-AI collaboration in thematic joke writing. Jokeasy provides a visual canvas in which retrieved web content is organized into editable inspiration blocks and developed through a multistage workflow. A qualitative study with 13 hobbyists and 5 expert participants (including professional comedians and HCI/AI specialists) showed that weaving real-time web material into this structured workflow enriches ideation and preserves author agency, while also revealing needs for finer search control, tighter chat-canvas integration, and more flexible visual editing. These insights refine our understanding of AI-assisted humour writing and guide future creative-writing tools.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09496v1",
        "authors": [
          "Yate Ge",
          "Lin Tian",
          "Chiqian Xu"
        ],
        "arxiv_categories": [
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.725267",
      "entities": [
        "Large Language Models",
        "Exploring Human",
        "LLM",
        "Act",
        "HCI",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09423v1",
      "title": "Beyond Input-Output: Rethinking Creativity through Design-by-Analogy in Human-AI Collaboration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09423v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "While the proliferation of foundation models has significantly boosted individual productivity, it also introduces a potential challenge: the homogenization of creative content. In response, we revisit Design-by-Analogy (DbA), a cognitively grounded approach that fosters novel solutions by mapping inspiration across domains. However, prevailing perspectives often restrict DbA to early ideation or specific data modalities, while reducing AI-driven design to simplified input-output pipelines. Such conceptual limitations inadvertently foster widespread design fixation. To address this, we expand the understanding of DbA by embedding it into the entire creative process, thereby demonstrating its capacity to mitigate such fixation. Through a systematic review of 85 studies, we identify six forms of representation and classify techniques across seven stages of the creative process. We further discuss three major application domains: creative industries, intelligent manufacturing, and education and services, demonstrating DbA's practical relevance. Building on this synthesis, we frame DbA as a mediating technology for human-AI collaboration and outline the potential opportunities and inherent risks for advancing creativity support in HCI and design research.",
        "keywords": [
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09423v1",
        "authors": [
          "Xuechen Li",
          "Shuai Zhang",
          "Nan Cao"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.725589",
      "entities": [
        "Rethinking Creativity",
        "Collaboration While",
        "Beyond Input",
        "Intel",
        "Act",
        "HCI",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09416v1",
      "title": "Are Language Models Sensitive to Morally Irrelevant Distractors?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09416v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human moral judgements are sensitive to morally irrelevant situational factors, such as smelling cinnamon rolls or the level of ambient noise, thereby challenging moral theories that assume the stability of human moral judgements. Here, we draw inspiration from this \"situationist\" view of moral psychology to evaluate whether LLMs exhibit similar cognitive moral biases to humans. We curate a novel multimodal dataset of 60 \"moral distractors\" from existing psychological datasets of emotionally-valenced images and narratives which have no moral relevance to the situation presented. After injecting these distractors into existing moral benchmarks to measure their effects on LLM responses, we find that moral distractors can shift the moral judgements of LLMs by over 30% even in low-ambiguity scenarios, highlighting the need for more contextual moral evaluations and more nuanced cognitive moral modeling of LLMs.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09416v1",
        "authors": [
          "Andrew Shaw",
          "Christina Hahn",
          "Catherine Rasgaitis"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "S",
      "collected_at": "2026-02-11T15:13:27.725920",
      "entities": [
        "Morally Irrelevant Distractors",
        "Are Language Models Sensitive",
        "NIST",
        "LLM",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10039v1",
      "title": "Budgeting Discretion: Theory and Evidence on Street-Level Decision-Making",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10039v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Street-level bureaucrats, such as caseworkers and border guards routinely face the dilemma of whether to follow rigid policy or exercise discretion based on professional judgement. However, frequent overrides threaten consistency and introduce bias, explaining why bureaucracies often ration discretion as a finite resource. While prior work models discretion as a static cost-benefit tradeoff, we lack a principled model of how discretion should be rationed over time under real operational constraints. We formalize discretion as a dynamic allocation problem in which an agent receives stochastic opportunities to improve upon a default policy and must spend a limited override budget K over a finite horizon T. We show that overrides follow a dynamic threshold rule: use discretion only when the opportunity exceeds a time and budget-dependent cutoff. Our main theoretical contribution identifies a behavioral invariance: for location-scale families of improvement distributions, the rate at which an optimal agent exercises discretion is independent of the scale of potential gains and depends only on the distribution's shape (e.g., tail heaviness). This result implies systematic differences in discretionary \"policy personality.\" When gains are fat-tailed, optimal agents are patient, conserving discretion for outliers. When gains are thin-tailed, agents spend more routinely. We illustrate these implications using data from a homelessness services system. Discretionary overrides track operational constraints: they are higher at the start of the workweek, suppressed on weekends when intake is offline, and shift with short-run housing capacity. These results suggest that discretion can be both procedurally constrained and welfare-improving when treated as an explicitly budgeted resource, providing a foundation for auditing override patterns and designing decision-support systems.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10039v1",
        "authors": [
          "Gaurab Pokharel",
          "Sanmay Das",
          "Patrick J. Fowler"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.733862",
      "entities": [
        "Budgeting Discretion",
        "Level Decision",
        "Making Street",
        "Policy",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09987v1",
      "title": "Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09987v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09987v1",
        "authors": [
          "J Rosser",
          "Robert Kirk",
          "Edward Grefenstette"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.734284",
      "entities": [
        "Influence Functions Influence",
        "Shaping Model Behavior",
        "Editing Training Data",
        "Framework",
        "CIFAR-10",
        "Fusion",
        "CIFAR",
        "Act",
        "CNN",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09907v1",
      "title": "Self-Regulated Reading with AI Support: An Eight-Week Study with Students",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09907v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "College students increasingly use AI chatbots to support academic reading, yet we lack granular understanding of how these interactions shape their reading experience and cognitive engagement. We conducted an eight-week longitudinal study with 15 undergraduates who used AI to support assigned readings in a course. We collected 838 prompts across 239 reading sessions and developed a coding schema categorizing prompts into four cognitive themes: Decoding, Comprehension, Reasoning, and Metacognition. Comprehension prompts dominated (59.6%), with Reasoning (29.8%), Metacognition (8.5%), and Decoding (2.1%) less frequent. Most sessions (72%) contained exactly three prompts, the required minimum of the reading assignment. Within sessions, students showed natural cognitive progression from comprehension toward reasoning, but this progression was truncated. Across eight weeks, students' engagement patterns remained stable, with substantial individual differences persisting throughout. Qualitative analysis revealed an intention-behavior gap: students recognized that effective prompting required effort but rarely applied this knowledge, with efficiency emerging as the primary driver. Students also strategically triaged their engagement based on interest and academic pressures, exhibiting a novel pattern of reading through AI rather than with it: using AI-generated summaries as primary material to filter which sections merited deeper attention. We discuss design implications for AI reading systems that scaffold sustained cognitive engagement.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09907v1",
        "authors": [
          "Yue Fu",
          "Joel Wester",
          "Niels Van Berkel"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.734748",
      "entities": [
        "Regulated Reading",
        "Students College",
        "Week Study",
        "An Eight",
        "Meta",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09846v1",
      "title": "Generative AI Adoption in an Energy Company: Exploring Challenges and Use Cases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09846v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Organisations are examining how generative AI can support their operational work and decision-making processes. This study investigates how employees in a energy company understand AI adoption and identify areas where AI and LLMs-based agentic workflows could assist daily activities. Data was collected in four weeks through sixteen semi-structured interviews across nine departments, supported by internal documents and researcher observations. The analysis identified areas where employees positioned AI as useful, including reporting work, forecasting, data handling, maintenance-related tasks, and anomaly detection. Participants also described how GenAI and LLM-based tools could be introduced through incremental steps that align with existing workflows. The study provides an overview view of AI adoption in the energy sector and offers a structured basis for identifying entry points for practical implementation and comparative research across industries.",
        "keywords": [
          "cs.SE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09846v1",
        "authors": [
          "Malik Abdul Sami",
          "Zeeshan Rasheed",
          "Meri Olenius"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.735057",
      "entities": [
        "Use Cases Organisations",
        "Exploring Challenges",
        "Energy Company",
        "LLM",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09678v1",
      "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09678v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance. AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration.",
        "keywords": [
          "cs.AI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09678v1",
        "authors": [
          "Nicholas Caputo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.735578",
      "entities": [
        "Accountability Trap Since",
        "Administrative Law",
        "Fourth Settlement",
        "System Dossier",
        "Supreme Court",
        "Loper Bright",
        "Framework",
        "Standard",
        "Congress",
        "NIST",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09636v1",
      "title": "Trade-Offs in Deploying Legal AI: Insights from a Public Opinion Study to Guide AI Risk Management",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09636v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Generative AI tools are increasingly used for legal tasks, including legal research, drafting documents, and even for legal decision-making. As for other purposes, the use of GenAI in the legal domain comes with various risks and benefits that needs to be properly managed to ensure implementation in a way that serves public values and protect human rights. While the EU mandates risk assessment and audits before market introduction for some use cases (e.g., use by judges for administration of justice) other use cases do not fall under the AI Acts' high-risk classifications (e.g., use by citizens for legal consultation or drafting documents). Further, current risk management practices prioritize expert judgment on risk factor identification and prioritization without a corresponding legal requirement to consult with affected communities. Seeing the societal importance of the legal sector and the potentially transformative impact of GenAI in this sector, the acceptability and legitimacy of GenAI solutions also depends on public perceptions and a better understanding of the risks and benefits citizens associated with the use of AI in the legal sector. As a response, this papers presents data from a representative sample of German citizens (n=488) outlining citizens' perspectives on the use of GenAI for two legal tasks: legal consultation and legal mediation. Concretely, we i) systematically map risks and benefit factors for both legal tasks, ii) describe predictors that influence risk acceptance of the use of GenAI for those tasks, and iii) highlight emerging trade-off themes that citizens engage in when weighing up risk acceptability. Our results provides an empirical overview of citizens' concerns regarding risk management of GenAI for the legal domain, foregrounding critical themes that complement current risk assessment procedures.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09636v1",
        "authors": [
          "Kimon Kieslich",
          "Sophie Morosoli",
          "Nicholas Diakopoulos"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.736135",
      "entities": [
        "Risk Management Generative",
        "Public Opinion Study",
        "Deploying Legal",
        "NIST",
        "Act",
        "NSF",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09629v1",
      "title": "Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09629v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \\textit{where} defenses fail or \\textit{why}. To address this gap, we propose that LLM safety operates as a sequential pipeline with distinct checkpoints. We introduce the \\textbf{Four-Checkpoint Framework}, which organizes safety mechanisms along two dimensions: processing stage (input vs.\\ output) and detection level (literal vs.\\ intent). This creates four checkpoints, CP1 through CP4, each representing a defensive layer that can be independently evaluated. We design 13 evasion techniques, each targeting a specific checkpoint, enabling controlled testing of individual defensive layers. Using this framework, we evaluate GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across 3,312 single-turn, black-box test cases. We employ an LLM-as-judge approach for response classification and introduce Weighted Attack Success Rate (WASR), a severity-adjusted metric that captures partial information leakage overlooked by binary evaluation. Our evaluation reveals clear patterns. Traditional Binary ASR reports 22.6\\% attack success. However, WASR reveals 52.7\\%, a 2.3$\\times$ higher vulnerability. Output-stage defenses (CP3, CP4) prove weakest at 72--79\\% WASR, while input-literal defenses (CP1) are strongest at 13\\% WASR. Claude achieves the strongest safety (42.8\\% WASR), followed by GPT-5 (55.9\\%) and Gemini (59.5\\%). These findings suggest that current defenses are strongest at input-literal checkpoints but remain vulnerable to intent-level manipulation and output-stage techniques. The Four-Checkpoint Framework provides a structured approach for identifying and addressing safety vulnerabilities in deployed systems.",
        "keywords": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09629v1",
        "authors": [
          "Hayfa Dhabhi",
          "Kashyap Thimmaraju"
        ],
        "arxiv_categories": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.736712",
      "entities": [
        "Checkpoint Framework Reveals Where",
        "Safety Breaks Large Language",
        "Weighted Attack Success Rate",
        "Start Diagnosing Defenses",
        "Checkpoint Framework",
        "Stop Testing Attacks",
        "Traditional Binary",
        "Claude Sonnet",
        "Framework",
        "GPT-5",
        "WASR",
        "LLM",
        "ASR",
        "DOE",
        "GPT"
      ]
    },
    {
      "id": "arxiv-2602.09416v1",
      "title": "Are Language Models Sensitive to Morally Irrelevant Distractors?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09416v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human moral judgements are sensitive to morally irrelevant situational factors, such as smelling cinnamon rolls or the level of ambient noise, thereby challenging moral theories that assume the stability of human moral judgements. Here, we draw inspiration from this \"situationist\" view of moral psychology to evaluate whether LLMs exhibit similar cognitive moral biases to humans. We curate a novel multimodal dataset of 60 \"moral distractors\" from existing psychological datasets of emotionally-valenced images and narratives which have no moral relevance to the situation presented. After injecting these distractors into existing moral benchmarks to measure their effects on LLM responses, we find that moral distractors can shift the moral judgements of LLMs by over 30% even in low-ambiguity scenarios, highlighting the need for more contextual moral evaluations and more nuanced cognitive moral modeling of LLMs.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09416v1",
        "authors": [
          "Andrew Shaw",
          "Christina Hahn",
          "Catherine Rasgaitis"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.737116",
      "entities": [
        "Morally Irrelevant Distractors",
        "Are Language Models Sensitive",
        "NIST",
        "LLM",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09353v1",
      "title": "Understanding Remote Mental Health Supporters' Help-Seeking in Online Communities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09353v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Providing mental health support for loved ones across a geographic distance creates unique challenges for the remote caregivers, who sometimes turn to online communities for peer support. We qualitatively analyzed 522 Reddit threads to understand what drives remote caregivers' online help-seeking behaviors and the responses they receive from the community. Their purposes of posting included requesting guidance, expressing emotions, and seeking validation. Community responses included providing emotional support, suggesting informational strategies, and sharing personal experiences. While certain themes in posts (emotional toll, monitoring symptoms, and prioritizing caregiver well-being) are shared across remote and non-remote contexts, remote caregivers' posts surfaced nuanced experiences. For example, they often rely on digital cues, such as voice, to interpret care receivers' well-being while struggling with digital silence during crises. We discuss the need for supporting communication and information sharing between remote caregivers and receivers, care coordination for crisis management, and design recommendations for caregiver communities.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09353v1",
        "authors": [
          "Tuan-He Lee",
          "Gilly Leshed"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.737470",
      "entities": [
        "Understanding Remote Mental Health",
        "Online Communities Providing",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09299v1",
      "title": "Synthetic Reflections on Resource Extraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09299v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "This paper describes how AI models can be augmented and adapted to produce interpretation of landscapes. We describe the technical framework of a Sentinel-2 satellite asset interpretation pipeline that combines statistical operations, human judgement, and generative AI models to create succinct commentaries on industrial mining sites across the planet, documenting a past shared between people and AI systems.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09299v1",
        "authors": [
          "Sai Krishna Tammali",
          "Vinaya Kumar",
          "Marc Böhlen"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.737619",
      "entities": [
        "Synthetic Reflections",
        "Sentinel-2",
        "Framework",
        "Satellite",
        "Act",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09286v1",
      "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09286v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium. Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, \"human control\" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09286v1",
        "authors": [
          "Hanjing Shi",
          "Dominic DiFranzo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.738003",
      "entities": [
        "Communities Oversight",
        "Human Control Is",
        "Early Divergence",
        "Act",
        "JSD",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09256v1",
      "title": "\"Create an environment that protects women, rather than selling anxiety!\": Participatory Threat Modeling with Chinese Young Women Living Alone",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09256v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As more young women in China live alone, they navigate entangled privacy, security, and safety (PSS) risks across smart homes, online platforms, and public infrastructures. Drawing on six participatory threat modeling (PTM) workshops (n = 33), we present a human-centered threat model that illustrates how digitally facilitated physical violence, digital harassment and scams, and pervasive surveillance by individuals, companies, and the state are interconnected and mutually reinforcing. We also document four mitigation strategies employed by participants: smart home device configurations, boundary management, sociocultural practices, and social media tactics--each of which can introduce new vulnerabilities and emotional burdens. Based on these insights, we developed a digital PSS guidebook for young women living alone (YWLA) in China. We further propose actionable design implications for smart home devices and social media platforms, along with policy and legal recommendations and directions for educational interventions.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09256v1",
        "authors": [
          "Shijing He",
          "Chenkai Ma",
          "Chi Zhang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.738346",
      "entities": [
        "Participatory Threat Modeling",
        "Chinese Young Women Living",
        "Alone As",
        "Policy",
        "YWLA",
        "Act",
        "PTM",
        "MIT",
        "PSS",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.09254v1",
      "title": "Investigating Bystander Privacy in Chinese Smart Home Apps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09254v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Bystander privacy in smart homes has been widely studied in Western contexts, yet it remains underexplored in non-Western countries such as China. In this study, we analyze 49 Chinese smart home apps using a mixed-methods approach, including privacy policy review, UX/UI evaluation, and assessment of Apple App Store privacy labels. While most apps nominally comply with national regulations, we identify significant gaps between written policies and actual implementation. Our traceability analysis highlights inconsistencies in data controls and a lack of transparency in data-sharing practices. Crucially, bystander privacy -- particularly for visitors and non-user individuals -- is largely absent from both policy documents and interface design. Additionally, discrepancies between privacy labels and actual data practices threaten user trust and undermine informed consent. We provide design recommendations to strengthen bystander protections, improve privacy-oriented UI transparency, and enhance the credibility of privacy labels, supporting the development of inclusive smart home ecosystems in non-Western contexts.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09254v1",
        "authors": [
          "Shijing He",
          "Xuchen Wang",
          "Yaxiong Lei"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.738685",
      "entities": [
        "Investigating Bystander Privacy",
        "Chinese Smart Home Apps",
        "Apple App Store",
        "Regulation",
        "Policy",
        "Apple",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09248v1",
      "title": "Reply To: Global Gridded Population Datasets Systematically Underrepresent Rural Population by Josias Láng-Ritter et al",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09248v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The paper titled ''Global gridded population datasets systematically underrepresent rural population'' by Josias Láng-Ritter et al. provides a valuable contribution to the discourse on the accuracy of global population datasets, particularly in rural areas. We recognize the efforts put into this research and appreciate its contribution to the field. However, we feel that key claims in the study are overly bold, not properly backed by evidence and lack a cautious and nuanced discussion. We hope these points will be taken into account in future discussions and refinements of population estimation methodologies. We argue that the reported bias figures are less caused by actual undercounting of rural populations, but more so by contestable methodological decisions and the historic misallocation of (gridded) population estimates on the local level.",
        "keywords": [
          "q-bio.PE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09248v1",
        "authors": [
          "Till Koebe",
          "Emmanuel Letouzé",
          "Tuba Bircan"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.739209",
      "entities": [
        "Systematically Underrepresent Rural Population",
        "Global Gridded Population Datasets",
        "Reply To",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09246v1",
      "title": "Marco IA593: Modelo de Gobernanza, Ética y Estrategia para la Integración de la Inteligencia Artificial en la Educación Superior del Ecuador",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09246v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The integration of Artificial Intelligence (AI) into Higher Education Institutions (HEIs) in Ecuador is not a technological option but a strategic imperative to prevent institutional obsolescence and academic irrelevance in Latin America. This paper presents the IA593 Framework, a governance, ethics, and operational model designed for the Universidad Nacional de Loja (UNL) and scalable as a reference for the Ecuadorian higher education system. The current context reveals a critical urgency: the Latin American Artificial Intelligence Index 2025 classifies Ecuador as a late awakening adopter, exposing severe structural gaps, including R and D investment of only 0.44 percent of GDP and a marginal contribution to global AI scientific output. Although a National Strategy for the Promotion of AI exists and calls for multisectoral governance, universities still lack internal regulations governing the use of Generative AI, placing academic integrity and data privacy at risk. The IA593 Framework addresses this challenge through five interconnected pillars aligned with the FATE principles of Fairness, Accountability, Transparency, and Ethics and UNESCO recommendations on AI ethics: Transversal Governance, Teaching and Training, Research, Outreach, and Management. This framework enables HEIs to move from passive technology consumption toward a sovereign and critical adoption of AI, ensuring compliance with national academic regulations and positioning UNL as a key actor in reducing the digital divide and brain drain in Ecuador.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09246v1",
        "authors": [
          "Luis Chamba-Eras",
          "Oscar Miguel Cumbicus Pineda",
          "Edison Leonardo Coronel Romero"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.740023",
      "entities": [
        "Latin American Artificial Intelligence",
        "Higher Education Institutions",
        "Inteligencia Artificial",
        "Artificial Intelligence",
        "Transversal Governance",
        "Universidad Nacional",
        "National Strategy",
        "Latin America",
        "Regulation",
        "Framework",
        "UNESCO",
        "Intel",
        "FATE",
        "Act",
        "UNL"
      ]
    },
    {
      "id": "arxiv-2602.09242v1",
      "title": "Open Mathematical Tasks as a Didactic Response to Generative Artificial Intelligence in Post-AI Contexts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09242v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The widespread availability of generative artificial intelligence tools poses new challenges for school mathematics education, particularly regarding the formative role of traditional mathematical tasks. In post-AI educational contexts, many activities can be solved automatically, without engaging students in interpretation, decision-making, or mathematical validation processes. This study analyzes a secondary school classroom experience in which open mathematical tasks are implemented as a didactic response to this scenario, aiming to sustain students' mathematical activity. Adopting a qualitative and descriptive-interpretative approach, the study examines the forms of mathematical work that emerge during task resolution, mediated by the didactic regulation device COMPAS. The analysis is structured around four analytical axes: open task design in post-AI contexts, students' mathematical agency, human-AI complementarity, and modeling and validation practices. The findings suggest that, under explicit didactic regulation, students retain epistemic control over mathematical activity, even in the presence of generative artificial intelligence.",
        "keywords": [
          "cs.CY",
          "math.HO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09242v1",
        "authors": [
          "Felix De la Cruz Serrano"
        ],
        "arxiv_categories": [
          "cs.CY",
          "math.HO"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.740332",
      "entities": [
        "Generative Artificial Intelligence",
        "Artificial Intelligence",
        "Open Mathematical Tasks",
        "Didactic Response",
        "Regulation",
        "COMPAS",
        "Intel",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09239v1",
      "title": "\"These cameras are just like the Eye of Sauron\": A Sociotechnical Threat Model for AI-Driven Smart Home Devices as Perceived by UK-Based Domestic Workers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09239v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The growing adoption of AI-driven smart home devices has introduced new privacy risks for domestic workers (DWs), who are frequently monitored in employers' homes while also using smart devices in their own households. We conducted semi-structured interviews with 18 UK-based DWs and performed a human-centered threat modeling analysis of their experiences through the lens of Communication Privacy Management (CPM). Our findings extend existing threat models beyond abstract adversaries and single-household contexts by showing how AI analytics, residual data logs, and cross-household data flows shaped the privacy risks faced by participants. In employer-controlled homes, AI-enabled features and opaque, agency-mediated employment arrangements intensified surveillance and constrained participants' ability to negotiate privacy boundaries. In their own homes, participants had greater control as device owners but still faced challenges, including gendered administrative roles, opaque AI functionalities, and uncertainty around data retention. We synthesize these insights into a sociotechnical threat model that identifies DW agencies as institutional adversaries and maps AI-driven privacy risks across interconnected households, and we outline social and practical implications for strengthening DW privacy and agency.",
        "keywords": [
          "cs.CR",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09239v1",
        "authors": [
          "Shijing He",
          "Yaxiong Lei",
          "Xiao Zhan"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.740684",
      "entities": [
        "Communication Privacy Management",
        "Sociotechnical Threat Model",
        "Driven Smart Home Devices",
        "NIST",
        "Act",
        "WHO",
        "IoT",
        "CPM",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09216v1",
      "title": "Towards Human-AI Accessibility Mapping in India: VLM-Guided Annotations and POI-Centric Analysis in Chandigarh",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09216v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Project Sidewalk is a web-based platform that enables crowdsourcing accessibility of sidewalks at city-scale by virtually walking through city streets using Google Street View. The tool has been used in 40 cities across the world, including the US, Mexico, Chile, and Europe. In this paper, we describe adaptation efforts to enable deployment in Chandigarh, India, including modifying annotation types, provided examples, and integrating VLM-based mission guidance, which adapts instructions based on a street scene and metadata analysis. Our evaluation with 3 annotators indicates the utility of AI-mission guidance with an average score of 4.66. Using this adapted Project Sidewalk tool, we conduct a Points of Interest (POI)-centric accessibility analysis for three sectors in Chandigarh with very different land uses, residential, commercial and institutional covering about 40 km of sidewalks. Across 40 km of roads audited in three sectors and around 230 POIs, we identified 1,644 of 2,913 locations where infrastructure improvements could enhance accessibility.",
        "keywords": [
          "cs.HC",
          "cs.CY",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09216v1",
        "authors": [
          "Varchita Lalwani",
          "Utkarsh Agarwal",
          "Michael Saugstad"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY",
          "cs.CV"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.740985",
      "entities": [
        "Chandigarh Project Sidewalk",
        "Accessibility Mapping",
        "Guided Annotations",
        "Google Street View",
        "Project Sidewalk",
        "Centric Analysis",
        "Towards Human",
        "Google",
        "Meta",
        "POI",
        "VLM",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09202v1",
      "title": "Genocide by Algorithm in Gaza: Artificial Intelligence, Countervailing Responsibility, and the Corruption of Public Discourse",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09202v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The accelerating militarization of artificial intelligence has transformed the ethics, politics, and governance of warfare. This article interrogates how AI-driven targeting systems function as epistemic infrastructures that classify, legitimize, and execute violence, using Israel's conduct in Gaza as a paradigmatic case. Through the lens of responsibility, the article examines three interrelated dimensions: (a) political responsibility, exploring how states exploit AI to accelerate warfare while evading accountability; (b) professional responsibility, addressing the complicity of technologists, engineers, and defense contractors in the weaponization of data; and (c) personal responsibility, probing the moral agency of individuals who participate in or resist algorithmic governance. This is complemented by an examination of the position and influence of those participating in public discourse, whose narratives often obscure or normalize AI-enabled violence. The Gaza case reveals AI not as a neutral instrument but as an active participant in the reproduction of colonial hierarchies and the normalization of atrocity. Ultimately, the paper calls for a reframing of technological agency and accountability in the age of automated warfare. It concludes that confronting algorithmic violence demands a democratization of AI ethics, one that resists technocratic fatalism and centers the lived realities of those most affected by high-tech militarism.",
        "keywords": [
          "cs.AI",
          "eess.SY",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09202v1",
        "authors": [
          "Branislav Radeljic"
        ],
        "arxiv_categories": [
          "cs.AI",
          "eess.SY",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.741356",
      "entities": [
        "Countervailing Responsibility",
        "Artificial Intelligence",
        "Intel",
        "Act",
        "WHO",
        "NSF",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.08997v1",
      "title": "Paradox of De-identification: A Critique of HIPAA Safe Harbour in the Age of LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.08997v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Privacy is a human right that sustains patient-provider trust. Clinical notes capture a patient's private vulnerability and individuality, which are used for care coordination and research. Under HIPAA Safe Harbor, these notes are de-identified to protect patient privacy. However, Safe Harbor was designed for an era of categorical tabular data, focusing on the removal of explicit identifiers while ignoring the latent information found in correlations between identity and quasi-identifiers, which can be captured by modern LLMs. We first formalize these correlations using a causal graph, then validate it empirically through individual re-identification of patients from scrubbed notes. The paradox of de-identification is further shown through a diagnosis ablation: even when all other information is removed, the model can predict the patient's neighborhood based on diagnosis alone. This position paper raises the question of how we can act as a community to uphold patient-provider trust when de-identification is inherently imperfect. We aim to raise awareness and discuss actionable recommendations.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.08997v1",
        "authors": [
          "Lavender Y. Jiang",
          "Xujin Chris Liu",
          "Kyunghyun Cho"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "P",
      "collected_at": "2026-02-11T15:13:30.741647",
      "entities": [
        "Safe Harbour",
        "Safe Harbor",
        "HIPAA",
        "LLM",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.10039v1",
      "title": "Budgeting Discretion: Theory and Evidence on Street-Level Decision-Making",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.10039v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Street-level bureaucrats, such as caseworkers and border guards routinely face the dilemma of whether to follow rigid policy or exercise discretion based on professional judgement. However, frequent overrides threaten consistency and introduce bias, explaining why bureaucracies often ration discretion as a finite resource. While prior work models discretion as a static cost-benefit tradeoff, we lack a principled model of how discretion should be rationed over time under real operational constraints. We formalize discretion as a dynamic allocation problem in which an agent receives stochastic opportunities to improve upon a default policy and must spend a limited override budget K over a finite horizon T. We show that overrides follow a dynamic threshold rule: use discretion only when the opportunity exceeds a time and budget-dependent cutoff. Our main theoretical contribution identifies a behavioral invariance: for location-scale families of improvement distributions, the rate at which an optimal agent exercises discretion is independent of the scale of potential gains and depends only on the distribution's shape (e.g., tail heaviness). This result implies systematic differences in discretionary \"policy personality.\" When gains are fat-tailed, optimal agents are patient, conserving discretion for outliers. When gains are thin-tailed, agents spend more routinely. We illustrate these implications using data from a homelessness services system. Discretionary overrides track operational constraints: they are higher at the start of the workweek, suppressed on weekends when intake is offline, and shift with short-run housing capacity. These results suggest that discretion can be both procedurally constrained and welfare-improving when treated as an explicitly budgeted resource, providing a foundation for auditing override patterns and designing decision-support systems.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.10039v1",
        "authors": [
          "Gaurab Pokharel",
          "Sanmay Das",
          "Patrick J. Fowler"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.740008",
      "entities": [
        "Budgeting Discretion",
        "Level Decision",
        "Making Street",
        "Policy",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09987v1",
      "title": "Infusion: Shaping Model Behavior by Editing Training Data via Influence Functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09987v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Influence functions are commonly used to attribute model behavior to training documents. We explore the reverse: crafting training data that induces model behavior. Our framework, Infusion, uses scalable influence-function approximations to compute small perturbations to training documents that induce targeted changes in model behavior through parameter shifts. We evaluate Infusion on data poisoning tasks across vision and language domains. On CIFAR-10, we show that making subtle edits via Infusion to just 0.2% (100/45,000) of the training documents can be competitive with the baseline of inserting a small number of explicit behavior examples. We also find that Infusion transfers across architectures (ResNet $\\leftrightarrow$ CNN), suggesting a single poisoned corpus can affect multiple independently trained models. In preliminary language experiments, we characterize when our approach increases the probability of target behaviors and when it fails, finding it most effective at amplifying behaviors the model has already learned. Taken together, these results show that small, subtle edits to training data can systematically shape model behavior, underscoring the importance of training data interpretability for adversaries and defenders alike. We provide the code here: https://github.com/jrosseruk/infusion.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09987v1",
        "authors": [
          "J Rosser",
          "Robert Kirk",
          "Edward Grefenstette"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.740433",
      "entities": [
        "Influence Functions Influence",
        "Shaping Model Behavior",
        "Editing Training Data",
        "Framework",
        "CIFAR-10",
        "Fusion",
        "CIFAR",
        "Act",
        "CNN",
        "NSF",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09907v1",
      "title": "Self-Regulated Reading with AI Support: An Eight-Week Study with Students",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09907v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "College students increasingly use AI chatbots to support academic reading, yet we lack granular understanding of how these interactions shape their reading experience and cognitive engagement. We conducted an eight-week longitudinal study with 15 undergraduates who used AI to support assigned readings in a course. We collected 838 prompts across 239 reading sessions and developed a coding schema categorizing prompts into four cognitive themes: Decoding, Comprehension, Reasoning, and Metacognition. Comprehension prompts dominated (59.6%), with Reasoning (29.8%), Metacognition (8.5%), and Decoding (2.1%) less frequent. Most sessions (72%) contained exactly three prompts, the required minimum of the reading assignment. Within sessions, students showed natural cognitive progression from comprehension toward reasoning, but this progression was truncated. Across eight weeks, students' engagement patterns remained stable, with substantial individual differences persisting throughout. Qualitative analysis revealed an intention-behavior gap: students recognized that effective prompting required effort but rarely applied this knowledge, with efficiency emerging as the primary driver. Students also strategically triaged their engagement based on interest and academic pressures, exhibiting a novel pattern of reading through AI rather than with it: using AI-generated summaries as primary material to filter which sections merited deeper attention. We discuss design implications for AI reading systems that scaffold sustained cognitive engagement.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09907v1",
        "authors": [
          "Yue Fu",
          "Joel Wester",
          "Niels Van Berkel"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.740818",
      "entities": [
        "Regulated Reading",
        "Students College",
        "Week Study",
        "An Eight",
        "Meta",
        "Act",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09846v1",
      "title": "Generative AI Adoption in an Energy Company: Exploring Challenges and Use Cases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09846v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Organisations are examining how generative AI can support their operational work and decision-making processes. This study investigates how employees in a energy company understand AI adoption and identify areas where AI and LLMs-based agentic workflows could assist daily activities. Data was collected in four weeks through sixteen semi-structured interviews across nine departments, supported by internal documents and researcher observations. The analysis identified areas where employees positioned AI as useful, including reporting work, forecasting, data handling, maintenance-related tasks, and anomaly detection. Participants also described how GenAI and LLM-based tools could be introduced through incremental steps that align with existing workflows. The study provides an overview view of AI adoption in the energy sector and offers a structured basis for identifying entry points for practical implementation and comparative research across industries.",
        "keywords": [
          "cs.SE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09846v1",
        "authors": [
          "Malik Abdul Sami",
          "Zeeshan Rasheed",
          "Meri Olenius"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.741067",
      "entities": [
        "Use Cases Organisations",
        "Exploring Challenges",
        "Energy Company",
        "LLM",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09795v1",
      "title": "Symmetric preferences, asymmetric outcomes: Tipping dynamics in an open-city segregation model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09795v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Schelling's model of segregation demonstrates that even in the absence of social or governmental interventions, individuals with mild in-group preferences can self-organize into strongly segregated neighborhoods. Many variants of this celebrated model have been proposed by assuming agents tend to increase their satisfaction. Complementary to this traditional, utility-based approach, we model residential moves using satisfaction-independent reaction rates in a spatially extended chemical reaction network. The resulting model exhibits a counter-intuitive phenomenon: despite symmetric in-group preferences, the system undergoes a tipping transition at a critical preference level, beyond which one agent type dominates. We characterize this asymmetric phase transition in details using mean-field analysis, numerical simulations and finite size scaling methods. We find that while the transition shares key features with the Ising universality class, such as $\\mathbb{Z}_2$ symmetry breaking and similar exponent ratios, the full set of critical exponents does not match any known universality class.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09795v1",
        "authors": [
          "Fabio van Dissel",
          "Tuan Minh Pham",
          "Wout Merbis"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.soc-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.741362",
      "entities": [
        "DOE",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09715v1",
      "title": "Topology and higher-order global synchronization on directed and hollow simplicial and cell complexes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09715v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Higher-order networks encode the many-body interactions of complex systems ranging from the brain to biological transportation networks. Simplicial and cell complexes are ideal higher-order network representations for investigating higher-order topological dynamics where dynamical variables are not only associated with nodes, but also with edges, triangles, and higher-order simplices and cells. Global Topological Synchronization (GTS) refers to the dynamical state in which identical oscillators associated with higher-dimensional simplices and cells oscillate in unison. On standard unweighted and undirected complexes this dynamical state can be achieved only under strict topological and combinatorial conditions on the underlying discrete support. In this work we consider generalized higher-order network representations including directed and hollow complexes. Based on an in depth investigation of their topology defined by their associated algebraic topology operators and Betti numbers, we determine under which conditions GTS can be observed. We show that directed complexes always admit a global topological synchronization state independently of their topology and structure. However, we demonstrate that for directed complexes this dynamical state cannot be asymptotically stable. While hollow complexes require more stringent topological conditions to sustain global topological synchronization, these topologies can favor both the existence and the stability of global topological synchronization with respect to undirected and unweighted complexes.",
        "keywords": [
          "physics.soc-ph",
          "cond-mat.stat-mech",
          "nlin.AO",
          "math-ph",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09715v1",
        "authors": [
          "Runyue Wang",
          "Timoteo Carletti",
          "Ginestra Bianconi"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cond-mat.stat-mech",
          "nlin.AO",
          "math-ph",
          "cond-mat.dis-nn"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.741883",
      "entities": [
        "Global Topological Synchronization",
        "Standard",
        "Act",
        "GTS",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09678v1",
      "title": "Administrative Law's Fourth Settlement: AI and the Capability-Accountability Trap",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09678v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Since 1887, administrative law has navigated a \"capability-accountability trap\": technological change forces government to become more sophisticated, but sophistication renders agencies opaque to generalist overseers like the courts and Congress. The law's response--substituting procedural review for substantive oversight--has produced a sedimentary accretion of requirements that ossify capacity without ensuring democratic control. This Article argues that the Supreme Court's post-Loper Bright retrenchment is best understood as an effort to shrink administration back to comprehensible size in response to this complexification. But reducing complexity in this way sacrifices capability precisely when climate change, pandemics, and AI risks demand more sophisticated governance. AI offers a different path. Unlike many prior administrative technologies that increased opacity alongside capacity, AI can help build \"scrutability\" in government, translating technical complexity into accessible terms, surfacing the assumptions that matter for oversight, and enabling substantive verification of agency reasoning. This Article proposes three doctrinal innovations within administrative law to realize this potential: a Model and System Dossier (documenting model purpose, evaluation, monitoring, and versioning) extending the administrative record to AI decision-making; a material-model-change trigger specifying when AI updates require new process; and a \"deference to audit\" standard that rewards agencies for auditable evaluation of their AI tools. The result is a framework for what this Article calls the \"Fourth Settlement,\" administrative law that escapes the capability-accountability trap by preserving capability while restoring comprehensible oversight of administration.",
        "keywords": [
          "cs.AI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09678v1",
        "authors": [
          "Nicholas Caputo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.742437",
      "entities": [
        "Accountability Trap Since",
        "Administrative Law",
        "Fourth Settlement",
        "System Dossier",
        "Supreme Court",
        "Loper Bright",
        "Framework",
        "Standard",
        "Congress",
        "NIST",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09645v1",
      "title": "Impact of Market Reforms on Deterministic Frequency Deviations in the European Power Grid",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09645v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Deterministic frequency deviations (DFDs) are systematic and predictable excursions of grid frequency that arise from synchronized generation ramps induced by electricity market scheduling. In this paper, we analyze the impact of the European day-ahead market reform of 1 October 2025, which replaced hourly trading blocks with quarter-hourly blocks, on DFDs in the Central European synchronous area. Using publicly available frequency measurements, we compare periods before and after the reform based on daily frequency profiles, indicators characterizing frequency deviations, principal component analysis, Fourier-based functional data analysis, and power spectral density analysis. We show that the reform substantially reduces characteristic hourly frequency deviations and suppresses dominant spectral components at hourly and half-hourly time scales, while quarter-hourly structures gain relative importance. While the likelihood of large frequency deviations decreases overall, reductions for extreme events are less clear and depend on the metric used. Our results demonstrate that market design reforms can effectively mitigate systematic frequency deviations, but also highlight that complementary technical and regulatory measures are required to further reduce large frequency excursions in low-inertia power systems.",
        "keywords": [
          "eess.SY",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09645v1",
        "authors": [
          "Philipp C. Böttcher",
          "Carsten Hartmann",
          "Andrea Benigni"
        ],
        "arxiv_categories": [
          "eess.SY",
          "physics.soc-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.742842",
      "entities": [
        "Deterministic Frequency Deviations",
        "European Power Grid Deterministic",
        "Central European",
        "Market Reforms",
        "NIST",
        "Act",
        "MIT",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09636v1",
      "title": "Trade-Offs in Deploying Legal AI: Insights from a Public Opinion Study to Guide AI Risk Management",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09636v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Generative AI tools are increasingly used for legal tasks, including legal research, drafting documents, and even for legal decision-making. As for other purposes, the use of GenAI in the legal domain comes with various risks and benefits that needs to be properly managed to ensure implementation in a way that serves public values and protect human rights. While the EU mandates risk assessment and audits before market introduction for some use cases (e.g., use by judges for administration of justice) other use cases do not fall under the AI Acts' high-risk classifications (e.g., use by citizens for legal consultation or drafting documents). Further, current risk management practices prioritize expert judgment on risk factor identification and prioritization without a corresponding legal requirement to consult with affected communities. Seeing the societal importance of the legal sector and the potentially transformative impact of GenAI in this sector, the acceptability and legitimacy of GenAI solutions also depends on public perceptions and a better understanding of the risks and benefits citizens associated with the use of AI in the legal sector. As a response, this papers presents data from a representative sample of German citizens (n=488) outlining citizens' perspectives on the use of GenAI for two legal tasks: legal consultation and legal mediation. Concretely, we i) systematically map risks and benefit factors for both legal tasks, ii) describe predictors that influence risk acceptance of the use of GenAI for those tasks, and iii) highlight emerging trade-off themes that citizens engage in when weighing up risk acceptability. Our results provides an empirical overview of citizens' concerns regarding risk management of GenAI for the legal domain, foregrounding critical themes that complement current risk assessment procedures.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09636v1",
        "authors": [
          "Kimon Kieslich",
          "Sophie Morosoli",
          "Nicholas Diakopoulos"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.743384",
      "entities": [
        "Risk Management Generative",
        "Public Opinion Study",
        "Deploying Legal",
        "NIST",
        "Act",
        "NSF",
        "UN",
        "EU",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09629v1",
      "title": "Stop Testing Attacks, Start Diagnosing Defenses: The Four-Checkpoint Framework Reveals Where LLM Safety Breaks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09629v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) deploy safety mechanisms to prevent harmful outputs, yet these defenses remain vulnerable to adversarial prompts. While existing research demonstrates that jailbreak attacks succeed, it does not explain \\textit{where} defenses fail or \\textit{why}. To address this gap, we propose that LLM safety operates as a sequential pipeline with distinct checkpoints. We introduce the \\textbf{Four-Checkpoint Framework}, which organizes safety mechanisms along two dimensions: processing stage (input vs.\\ output) and detection level (literal vs.\\ intent). This creates four checkpoints, CP1 through CP4, each representing a defensive layer that can be independently evaluated. We design 13 evasion techniques, each targeting a specific checkpoint, enabling controlled testing of individual defensive layers. Using this framework, we evaluate GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across 3,312 single-turn, black-box test cases. We employ an LLM-as-judge approach for response classification and introduce Weighted Attack Success Rate (WASR), a severity-adjusted metric that captures partial information leakage overlooked by binary evaluation. Our evaluation reveals clear patterns. Traditional Binary ASR reports 22.6\\% attack success. However, WASR reveals 52.7\\%, a 2.3$\\times$ higher vulnerability. Output-stage defenses (CP3, CP4) prove weakest at 72--79\\% WASR, while input-literal defenses (CP1) are strongest at 13\\% WASR. Claude achieves the strongest safety (42.8\\% WASR), followed by GPT-5 (55.9\\%) and Gemini (59.5\\%). These findings suggest that current defenses are strongest at input-literal checkpoints but remain vulnerable to intent-level manipulation and output-stage techniques. The Four-Checkpoint Framework provides a structured approach for identifying and addressing safety vulnerabilities in deployed systems.",
        "keywords": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09629v1",
        "authors": [
          "Hayfa Dhabhi",
          "Kashyap Thimmaraju"
        ],
        "arxiv_categories": [
          "cs.ET",
          "cs.CR",
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.743952",
      "entities": [
        "Checkpoint Framework Reveals Where",
        "Safety Breaks Large Language",
        "Weighted Attack Success Rate",
        "Start Diagnosing Defenses",
        "Checkpoint Framework",
        "Stop Testing Attacks",
        "Traditional Binary",
        "Claude Sonnet",
        "Framework",
        "GPT-5",
        "WASR",
        "LLM",
        "ASR",
        "DOE",
        "GPT"
      ]
    },
    {
      "id": "arxiv-2602.09503v1",
      "title": "Structure-aware imitation dynamics on higher-order networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09503v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Imitation is a basic updating mechanism for strategy evolution in structured populations, determining how individuals sample social information and translate it into behavioral changes. Higher-order networks, such as hypergraphs, generalize pairwise links to hyperedges and provide a natural representation of group interactions. Yet existing studies on higher-order networks largely emphasize structural effects, while the impact of imitation-based update rules and how they interact with group structures remains poorly understood. Here, we introduce a class of structure-aware imitation rules on hypergraphs that explicitly parameterize how many groups are sampled and how many peers are consulted within each sampled group. Under weak selection, we derive an analytical condition for the success of cooperation for any multiplayer social dilemmas on homogeneous hypergraphs. This analysis yields an interpretable metric, information diversity, which quantifies how an update rule diversifies the sources of social information across groups. Analytical predictions and numerical simulations show that cooperation is more effectively promoted by update rules that induce higher information diversity for three representative dilemmas. Further simulations demonstrate that this principle extends to non-homogeneous hypergraphs and a broad class of multiplayer social dilemmas. Our work thus provides a unifying metric that links microscopic updating to evolutionary outcomes in higher-order networked systems and establishes a general design principle for promoting cooperation beyond pairwise interactions.",
        "keywords": [
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09503v1",
        "authors": [
          "Bingxin Lin",
          "Lei Zhou",
          "Hao Fang"
        ],
        "arxiv_categories": [
          "physics.soc-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.744411",
      "entities": [
        "MIT",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09416v1",
      "title": "Are Language Models Sensitive to Morally Irrelevant Distractors?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09416v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "With the rapid development and uptake of large language models (LLMs) across high-stakes settings, it is increasingly important to ensure that LLMs behave in ways that align with human values. Existing moral benchmarks prompt LLMs with value statements, moral scenarios, or psychological questionnaires, with the implicit underlying assumption that LLMs report somewhat stable moral preferences. However, moral psychology research has shown that human moral judgements are sensitive to morally irrelevant situational factors, such as smelling cinnamon rolls or the level of ambient noise, thereby challenging moral theories that assume the stability of human moral judgements. Here, we draw inspiration from this \"situationist\" view of moral psychology to evaluate whether LLMs exhibit similar cognitive moral biases to humans. We curate a novel multimodal dataset of 60 \"moral distractors\" from existing psychological datasets of emotionally-valenced images and narratives which have no moral relevance to the situation presented. After injecting these distractors into existing moral benchmarks to measure their effects on LLM responses, we find that moral distractors can shift the moral judgements of LLMs by over 30% even in low-ambiguity scenarios, highlighting the need for more contextual moral evaluations and more nuanced cognitive moral modeling of LLMs.",
        "keywords": [
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09416v1",
        "authors": [
          "Andrew Shaw",
          "Christina Hahn",
          "Catherine Rasgaitis"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.744816",
      "entities": [
        "Morally Irrelevant Distractors",
        "Are Language Models Sensitive",
        "NIST",
        "LLM",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09353v1",
      "title": "Understanding Remote Mental Health Supporters' Help-Seeking in Online Communities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09353v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Providing mental health support for loved ones across a geographic distance creates unique challenges for the remote caregivers, who sometimes turn to online communities for peer support. We qualitatively analyzed 522 Reddit threads to understand what drives remote caregivers' online help-seeking behaviors and the responses they receive from the community. Their purposes of posting included requesting guidance, expressing emotions, and seeking validation. Community responses included providing emotional support, suggesting informational strategies, and sharing personal experiences. While certain themes in posts (emotional toll, monitoring symptoms, and prioritizing caregiver well-being) are shared across remote and non-remote contexts, remote caregivers' posts surfaced nuanced experiences. For example, they often rely on digital cues, such as voice, to interpret care receivers' well-being while struggling with digital silence during crises. We discuss the need for supporting communication and information sharing between remote caregivers and receivers, care coordination for crisis management, and design recommendations for caregiver communities.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09353v1",
        "authors": [
          "Tuan-He Lee",
          "Gilly Leshed"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.745173",
      "entities": [
        "Understanding Remote Mental Health",
        "Online Communities Providing",
        "WHO",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09299v1",
      "title": "Synthetic Reflections on Resource Extraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09299v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "This paper describes how AI models can be augmented and adapted to produce interpretation of landscapes. We describe the technical framework of a Sentinel-2 satellite asset interpretation pipeline that combines statistical operations, human judgement, and generative AI models to create succinct commentaries on industrial mining sites across the planet, documenting a past shared between people and AI systems.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09299v1",
        "authors": [
          "Sai Krishna Tammali",
          "Vinaya Kumar",
          "Marc Böhlen"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.745323",
      "entities": [
        "Synthetic Reflections",
        "Sentinel-2",
        "Framework",
        "Satellite",
        "Act",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09286v1",
      "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09286v1",
        "published_date": "2026-02-10"
      },
      "content": {
        "abstract": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium. Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, \"human control\" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.",
        "keywords": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09286v1",
        "authors": [
          "Hanjing Shi",
          "Dominic DiFranzo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.745657",
      "entities": [
        "Communities Oversight",
        "Human Control Is",
        "Early Divergence",
        "Act",
        "JSD",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09270v1",
      "title": "Collective Behavior of AI Agents: the Case of Moltbook",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09270v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "We present a large scale data analysis of Moltbook, a Reddit-style social media platform exclusively populated by AI agents. Analyzing over 369,000 posts and 3.0 million comments from approximately 46,000 active agents, we find that AI collective behavior exhibits many of the same statistical regularities observed in human online communities: heavy-tailed distributions of activity, power-law scaling of popularity metrics, and temporal decay patterns consistent with limited attention dynamics. However, we also identify key differences, including a sublinear relationship between upvotes and discussion size that contrasts with human behavior. These findings suggest that, while individual AI agents may differ fundamentally from humans, their emergent collective dynamics share structural similarities with human social systems.",
        "keywords": [
          "cs.CL",
          "cs.MA",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09270v1",
        "authors": [
          "Giordano De Marzo",
          "David Garcia"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.MA",
          "physics.soc-ph"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.745882",
      "entities": [
        "Collective Behavior",
        "Moltbook We",
        "Act",
        "MIT",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09256v1",
      "title": "\"Create an environment that protects women, rather than selling anxiety!\": Participatory Threat Modeling with Chinese Young Women Living Alone",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09256v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "As more young women in China live alone, they navigate entangled privacy, security, and safety (PSS) risks across smart homes, online platforms, and public infrastructures. Drawing on six participatory threat modeling (PTM) workshops (n = 33), we present a human-centered threat model that illustrates how digitally facilitated physical violence, digital harassment and scams, and pervasive surveillance by individuals, companies, and the state are interconnected and mutually reinforcing. We also document four mitigation strategies employed by participants: smart home device configurations, boundary management, sociocultural practices, and social media tactics--each of which can introduce new vulnerabilities and emotional burdens. Based on these insights, we developed a digital PSS guidebook for young women living alone (YWLA) in China. We further propose actionable design implications for smart home devices and social media platforms, along with policy and legal recommendations and directions for educational interventions.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09256v1",
        "authors": [
          "Shijing He",
          "Chenkai Ma",
          "Chi Zhang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.746194",
      "entities": [
        "Participatory Threat Modeling",
        "Chinese Young Women Living",
        "Alone As",
        "Policy",
        "YWLA",
        "Act",
        "PTM",
        "MIT",
        "PSS",
        "UN"
      ]
    },
    {
      "id": "arxiv-2602.09254v1",
      "title": "Investigating Bystander Privacy in Chinese Smart Home Apps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09254v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "Bystander privacy in smart homes has been widely studied in Western contexts, yet it remains underexplored in non-Western countries such as China. In this study, we analyze 49 Chinese smart home apps using a mixed-methods approach, including privacy policy review, UX/UI evaluation, and assessment of Apple App Store privacy labels. While most apps nominally comply with national regulations, we identify significant gaps between written policies and actual implementation. Our traceability analysis highlights inconsistencies in data controls and a lack of transparency in data-sharing practices. Crucially, bystander privacy -- particularly for visitors and non-user individuals -- is largely absent from both policy documents and interface design. Additionally, discrepancies between privacy labels and actual data practices threaten user trust and undermine informed consent. We provide design recommendations to strengthen bystander protections, improve privacy-oriented UI transparency, and enhance the credibility of privacy labels, supporting the development of inclusive smart home ecosystems in non-Western contexts.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09254v1",
        "authors": [
          "Shijing He",
          "Xuchen Wang",
          "Yaxiong Lei"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.746511",
      "entities": [
        "Investigating Bystander Privacy",
        "Chinese Smart Home Apps",
        "Apple App Store",
        "Regulation",
        "Policy",
        "Apple",
        "Act",
        "EPA",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09248v1",
      "title": "Reply To: Global Gridded Population Datasets Systematically Underrepresent Rural Population by Josias Láng-Ritter et al",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09248v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The paper titled ''Global gridded population datasets systematically underrepresent rural population'' by Josias Láng-Ritter et al. provides a valuable contribution to the discourse on the accuracy of global population datasets, particularly in rural areas. We recognize the efforts put into this research and appreciate its contribution to the field. However, we feel that key claims in the study are overly bold, not properly backed by evidence and lack a cautious and nuanced discussion. We hope these points will be taken into account in future discussions and refinements of population estimation methodologies. We argue that the reported bias figures are less caused by actual undercounting of rural populations, but more so by contestable methodological decisions and the historic misallocation of (gridded) population estimates on the local level.",
        "keywords": [
          "q-bio.PE",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09248v1",
        "authors": [
          "Till Koebe",
          "Emmanuel Letouzé",
          "Tuba Bircan"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.747007",
      "entities": [
        "Systematically Underrepresent Rural Population",
        "Global Gridded Population Datasets",
        "Reply To",
        "Act",
        "UN",
        "AI"
      ]
    },
    {
      "id": "arxiv-2602.09246v1",
      "title": "Marco IA593: Modelo de Gobernanza, Ética y Estrategia para la Integración de la Inteligencia Artificial en la Educación Superior del Ecuador",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "http://arxiv.org/abs/2602.09246v1",
        "published_date": "2026-02-09"
      },
      "content": {
        "abstract": "The integration of Artificial Intelligence (AI) into Higher Education Institutions (HEIs) in Ecuador is not a technological option but a strategic imperative to prevent institutional obsolescence and academic irrelevance in Latin America. This paper presents the IA593 Framework, a governance, ethics, and operational model designed for the Universidad Nacional de Loja (UNL) and scalable as a reference for the Ecuadorian higher education system. The current context reveals a critical urgency: the Latin American Artificial Intelligence Index 2025 classifies Ecuador as a late awakening adopter, exposing severe structural gaps, including R and D investment of only 0.44 percent of GDP and a marginal contribution to global AI scientific output. Although a National Strategy for the Promotion of AI exists and calls for multisectoral governance, universities still lack internal regulations governing the use of Generative AI, placing academic integrity and data privacy at risk. The IA593 Framework addresses this challenge through five interconnected pillars aligned with the FATE principles of Fairness, Accountability, Transparency, and Ethics and UNESCO recommendations on AI ethics: Transversal Governance, Teaching and Training, Research, Outreach, and Management. This framework enables HEIs to move from passive technology consumption toward a sovereign and critical adoption of AI, ensuring compliance with national academic regulations and positioning UNL as a key actor in reducing the digital divide and brain drain in Ecuador.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.09246v1",
        "authors": [
          "Luis Chamba-Eras",
          "Oscar Miguel Cumbicus Pineda",
          "Edison Leonardo Coronel Romero"
        ],
        "arxiv_categories": [
          "cs.CY"
        ]
      },
      "preliminary_category": "s",
      "collected_at": "2026-02-11T15:13:33.747839",
      "entities": [
        "Latin American Artificial Intelligence",
        "Higher Education Institutions",
        "Inteligencia Artificial",
        "Artificial Intelligence",
        "Transversal Governance",
        "Universidad Nacional",
        "National Strategy",
        "Latin America",
        "Regulation",
        "Framework",
        "UNESCO",
        "Intel",
        "FATE",
        "Act",
        "UNL"
      ]
    }
  ]
}