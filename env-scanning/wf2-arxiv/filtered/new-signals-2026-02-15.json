{
  "metadata": {
    "workflow": "wf2-arxiv",
    "filter_date": "2026-02-15",
    "raw_count": 583,
    "dedup_removed": 0,
    "new_signal_count": 583,
    "dedup_rate": 0.0,
    "previous_db_size": 110,
    "temporal_gate_override": "Weekend freeze: all papers have published_date=2026-02-12 but were posted Feb 13-14 by arXiv batch system",
    "override_approved_by": "human (user approval at Step 1.4 checkpoint)"
  },
  "items": [
    {
      "id": "arxiv-2602.12281v1",
      "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12281v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12281v1",
        "authors": [
          "Jacky Kwok",
          "Xilun Zhang",
          "Mengdi Xu",
          "Yuejiang Liu",
          "Azalia Mirhoseini"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scaling Verification Can Be",
        "Scaling Policy Learning",
        "More Effective",
        "Framework",
        "Policy",
        "Robot",
        "Act",
        "VLM",
        "VLA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.010035"
    },
    {
      "id": "arxiv-2602.12280v1",
      "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12280v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12280v1",
        "authors": [
          "Huai-Hsun Cheng",
          "Siang-Ling Zhang",
          "Yu-Lun Liu"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Progressive Semantic Illusions",
        "Score Distillation Sampling",
        "Vector Sketching Visual",
        "Overlay Loss",
        "Framework",
        "NSF",
        "SDS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.010427"
    },
    {
      "id": "arxiv-2602.12279v1",
      "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12279v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12279v1",
        "authors": [
          "Leon Liangyu Chen",
          "Haoyu Ma",
          "Zhipeng Fan",
          "Ziqi Huang",
          "Animesh Sinha"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Multimodal Chain",
        "Scaling Unified",
        "Thought Test",
        "Framework",
        "Act",
        "TTS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.010827"
    },
    {
      "id": "arxiv-2602.12278v1",
      "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12278v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12278v1",
        "authors": [
          "David Jiahao Fu",
          "Lam Thanh Do",
          "Jiayu Li",
          "Kevin Chen-Chuan Chang"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Secretly Long Document Retrievers",
        "Large Language Models",
        "Attention Layers",
        "RAG",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.011071"
    },
    {
      "id": "arxiv-2602.12276v1",
      "title": "Agentic Test-Time Scaling for WebAgents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12276v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12276v1",
        "authors": [
          "Nicholas Lee",
          "Lutfi Eren Erdogan",
          "Chris Joseph John",
          "Surya Krishnapillai",
          "Michael W. Mahoney"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "Agentic Test",
        "Time Scaling",
        "Aware Test",
        "Standard",
        "CATTS",
        "Act",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.011424"
    },
    {
      "id": "arxiv-2602.12275v1",
      "title": "On-Policy Context Distillation for Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12275v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Context distillation enables language models to internalize in-context knowledge into their parameters. In our work, we propose On-Policy Context Distillation (OPCD), a framework that bridges on-policy distillation with context distillation by training a student model on its own generated trajectories while minimizing reverse Kullback-Leibler divergence against a context-conditioned teacher. We demonstrate the effectiveness of OPCD on two important applications: experiential knowledge distillation, where models extract and consolidate transferable knowledge from their historical solution traces, and system prompt distillation, where models internalize beneficial behaviors encoded in optimized prompts. Across mathematical reasoning, text-based games, and domain-specific tasks, OPCD consistently outperforms baseline methods, achieving higher task accuracy while better preserving out-of-distribution capabilities. We further show that OPCD enables effective cross-size distillation, where smaller student models can internalize experiential knowledge from larger teachers.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12275v1",
        "authors": [
          "Tianzhu Ye",
          "Li Dong",
          "Xun Wu",
          "Shaohan Huang",
          "Furu Wei"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Policy Context Distillation",
        "Language Models Context",
        "Framework",
        "Policy",
        "OPCD",
        "Act",
        "NSF",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.011703"
    },
    {
      "id": "arxiv-2602.12274v1",
      "title": "Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12274v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a Local Neural Operator (LNO) surrogate to provide physics-consistent guidance for cross-field conditioning on the dynamics field. This decoupling allows the diffusion prior to robustly recover missing information in parameter space, while the surrogate provides efficient gradient-based guidance for data assimilation. We demonstrate Fun-DDPS on synthetic CCS modeling datasets, achieving two key results: (1) For forward modeling with only 25% observations, Fun-DDPS achieves 7.7% relative error compared to 86.9% for standard surrogates (an 11x improvement), proving its capability to handle extreme data sparsity where deterministic methods fail. (2) We provide the first rigorous validation of diffusion-based inverse solvers against asymptotically exact Rejection Sampling (RS) posteriors. Both Fun-DDPS and the joint-state baseline (Fun-DPS) achieve Jensen-Shannon divergence less than 0.06 against the ground truth. Crucially, Fun-DDPS produces physically consistent realizations free from the high-frequency artifacts observed in joint-state baselines, achieving this with 4x improved sample efficiency compared to rejection sampling.",
        "keywords": [
          "cs.LG",
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12274v1",
        "authors": [
          "Xin Ju",
          "Jiachen Yao",
          "Anima Anandkumar",
          "Sally M. Benson",
          "Gege Wen"
        ],
        "arxiv_categories": [
          "cs.LG",
          "physics.geo-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Space Decoupled Diffusion",
        "Local Neural Operator",
        "Rejection Sampling",
        "Inverse Modeling",
        "Storage Accurate",
        "Carbon Capture",
        "Framework",
        "Standard",
        "Both Fun",
        "Fusion",
        "NIST",
        "DDPS",
        "Act",
        "LNO",
        "CCS"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.012105"
    },
    {
      "id": "arxiv-2602.12273v1",
      "title": "Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12273v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.",
        "keywords": [
          "math.OC",
          "cs.LG",
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12273v1",
        "authors": [
          "Yongcun Song",
          "Xiaoming Yuan",
          "Hangrui Yue",
          "Tianyou Zeng"
        ],
        "arxiv_categories": [
          "math.OC",
          "cs.LG",
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonsmooth Optimal Control",
        "Neural Network",
        "Deep Learning",
        "Framework",
        "Act",
        "PDE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.012377"
    },
    {
      "id": "arxiv-2602.12271v1",
      "title": "MonarchRT: Efficient Attention for Real-Time Video Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12271v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.",
        "keywords": [
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12271v1",
        "authors": [
          "Krish Agarwal",
          "Zhuoming Chen",
          "Cheng Luo",
          "Yongqi Chen",
          "Haizhong Zheng"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Video Generation Real",
        "Diffusion Transformers",
        "Efficient Attention",
        "FlashAttention-2",
        "FlashAttention-4",
        "FlashAttention-3",
        "Transformer",
        "Oracle",
        "NVIDIA",
        "Fusion",
        "Act",
        "NSF",
        "RTX",
        "FPS",
        "IoT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.012828"
    },
    {
      "id": "arxiv-2602.12270v1",
      "title": "Creative Ownership in the Age of AI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12270v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Copyright law focuses on whether a new work is \"substantially similar\" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \\emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.",
        "keywords": [
          "econ.TH",
          "cs.AI",
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12270v1",
        "authors": [
          "Annie Liang",
          "Jay Lu"
        ],
        "arxiv_categories": [
          "econ.TH",
          "cs.AI",
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Creative Ownership",
        "Regulation",
        "Act",
        "MIT",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:07.013099"
    },
    {
      "id": "arxiv-2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12268v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12268v1",
        "authors": [
          "Zhen Zhang",
          "Kaiqiang Song",
          "Xun Wang",
          "Yebowen Hu",
          "Weixiang Yan"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcement Learning",
        "Step Agentic Tool Use",
        "Checklist Rewards",
        "Framework",
        "Meta",
        "RLCR",
        "BFCL",
        "Act",
        "MIT",
        "LLM",
        "SFT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.013522"
    },
    {
      "id": "arxiv-2602.12267v1",
      "title": "Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12267v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12267v1",
        "authors": [
          "Duy Nguyen",
          "Jiachen Yao",
          "Jiayun Wang",
          "Julius Berner",
          "Animashree Anandkumar"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guided Neural Operator",
        "Time Fourier Transform",
        "Supervised Learning",
        "Series Data Self",
        "Framework",
        "DREAMT",
        "AUROC",
        "FGNO",
        "RMSE",
        "Act",
        "NSF",
        "SSL",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.013939"
    },
    {
      "id": "arxiv-2602.12262v1",
      "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12262v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.",
        "keywords": [
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12262v1",
        "authors": [
          "Tunyu Zhang",
          "Xinxi Zhang",
          "Ligong Han",
          "Haizhou Shi",
          "Xiaoxiao He"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Direct Discriminative Optimization Diffusion",
        "Direct Discriminative Optimization",
        "Step Diffusion Language Models",
        "Trajectory Self",
        "Framework",
        "Standard",
        "Fusion",
        "DDO",
        "Act",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.014235"
    },
    {
      "id": "arxiv-2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12259v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
        "keywords": [
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12259v1",
        "authors": [
          "Jianke Yang",
          "Ohm Venkatachalam",
          "Mohammad Kianezhad",
          "Sharvaree Vadgama",
          "Rose Yu"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Equation Discovery Explaining",
        "Framework",
        "Act",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.014493"
    },
    {
      "id": "arxiv-2602.12257v1",
      "title": "On the implicit regularization of Langevin dynamics with projected noise",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12257v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.",
        "keywords": [
          "math.PR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12257v1",
        "authors": [
          "Govind Menon",
          "Austin J. Stromme",
          "Adrien Vacher"
        ],
        "arxiv_categories": [
          "math.PR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.014697"
    },
    {
      "id": "arxiv-2602.12253v1",
      "title": "Is Online Linear Optimization Sufficient for Strategic Robustness?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12253v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids. In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\\sqrt{T \\log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\\sqrt{T (\\log K+\\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].",
        "keywords": [
          "cs.GT",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12253v1",
        "authors": [
          "Yang Cai",
          "Haipeng Luo",
          "Chen-Yu Wei",
          "Weiqiang Zheng"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.LG"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Is Online Linear Optimization",
        "Strategic Robustness",
        "OLO",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:07.015443"
    },
    {
      "id": "arxiv-2602.12251v1",
      "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12251v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12251v1",
        "authors": [
          "Ralph Krüger"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multilingual Communication",
        "Artificial Intelligence",
        "Neural Network",
        "Transformer",
        "Institute",
        "Intel",
        "Act",
        "NSF",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.015711"
    },
    {
      "id": "arxiv-2602.12250v1",
      "title": "Community Concealment from Unsupervised Graph Learning-Based Clustering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12250v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.",
        "keywords": [
          "cs.LG",
          "cs.CR",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12250v1",
        "authors": [
          "Dalyapraz Manatova",
          "Pablo Moriano",
          "L. Jean Camp"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CR",
          "cs.SI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unsupervised Graph Learning",
        "Based Clustering Graph",
        "Community Concealment",
        "Neural Network",
        "Intel",
        "DICE",
        "Act",
        "MIT",
        "GNN",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.016042"
    },
    {
      "id": "arxiv-2602.12249v1",
      "title": "\"Sorry, I Didn't Catch That\": How Speech Models Miss What Matters Most",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12249v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.",
        "keywords": [
          "cs.AI",
          "cs.CL",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12249v1",
        "authors": [
          "Kaitlyn Zhou",
          "Martijn Bartelds",
          "Federico Bianchi",
          "James Zou"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL",
          "cs.CY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "What Matters Most Despite",
        "How Speech Models Miss",
        "Microsoft",
        "Standard",
        "Google",
        "OpenAI",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.016331"
    },
    {
      "id": "arxiv-2602.12247v1",
      "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12247v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12247v1",
        "authors": [
          "Nick Ferguson",
          "Josh Pennington",
          "Narek Beghian",
          "Aravind Mohan",
          "Douwe Kiela"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Complex Structured Extraction Unstructured",
        "Evaluation Methodology",
        "Framework",
        "Standard",
        "Gemini-3",
        "GPT-5",
        "JSON",
        "Act",
        "PDF",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.016674"
    },
    {
      "id": "arxiv-2602.12245v1",
      "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12245v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12245v1",
        "authors": [
          "Anthony Kobanda",
          "Waris Radji"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Architectures Induce Quasimetric Spaces",
        "Quasimetric Reinforcement Learning",
        "Embedding Predictive Architectures",
        "Energy Joint Embedding Predictive",
        "JEPA",
        "Act",
        "EPA",
        "MIT",
        "QRL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.016938"
    },
    {
      "id": "arxiv-2602.12241v1",
      "title": "Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12241v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent \"encode-the-whole-utterance\" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.",
        "keywords": [
          "cs.CL",
          "cs.LG",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12241v1",
        "authors": [
          "Manjunath Kudlur",
          "Evan King",
          "James Wang",
          "Pete Warden"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.LG",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Critical Speech Applications Latency",
        "Ergodic Streaming Encoder",
        "Transformer",
        "Standard",
        "Wind",
        "TTFT",
        "Act",
        "NSF",
        "WHO",
        "MIT",
        "ASR",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.017261"
    },
    {
      "id": "arxiv-2602.12237v1",
      "title": "Olmix: A Framework for Data Mixing Throughout LM Development",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12237v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges. First, the configuration space for developing a mixing method is not well understood -- design choices across existing methods lack justification or consensus and overlook practical issues like data constraints. We conduct a comprehensive empirical study of this space, identifying which design choices lead to a strong mixing method. Second, in practice, the domain set evolves throughout LM development as datasets are added, removed, partitioned, and revised -- a problem setting largely unaddressed by existing works, which assume fixed domains. We study how to efficiently recompute the mixture after the domain set is updated, leveraging information from past mixtures. We introduce mixture reuse, a mechanism that reuses existing ratios and recomputes ratios only for domains affected by the update. Over a sequence of five domain-set updates mirroring real-world LM development, mixture reuse matches the performance of fully recomputing the mix after each update with 74% less compute and improves over training without mixing by 11.6% on downstream tasks.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12237v1",
        "authors": [
          "Mayee F. Chen",
          "Tyler Murray",
          "David Heineman",
          "Matt Jordan",
          "Hannaneh Hajishirzi"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Data Mixing Throughout",
        "Development Data",
        "Framework",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.017567"
    },
    {
      "id": "arxiv-2602.12236v1",
      "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12236v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.",
        "keywords": [
          "cs.NE",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12236v1",
        "authors": [
          "Anika Tabassum Meem",
          "Muntasir Hossain Nadid",
          "Md Zesun Ahmed Mia"
        ],
        "arxiv_categories": [
          "cs.NE",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neuromorphic Vision Neuromorphic",
        "Spiking Neural Networks",
        "Aware Spike Budgeting",
        "Continual Learning",
        "Neural Network",
        "Framework",
        "CIFAR-10",
        "MNIST",
        "CIFAR",
        "NIST",
        "Act",
        "SNN",
        "MIT",
        "DVS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.017949"
    },
    {
      "id": "arxiv-2602.12235v1",
      "title": "Detecting Overflow in Compressed Token Representations for Retrieval-Augmented Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12235v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient long-context processing remains a crucial challenge for contemporary large language models (LLMs), especially in resource-constrained environments. Soft compression architectures promise to extend effective context length by replacing long token sequences with smaller sets of learned compressed tokens. Yet, the limits of compressibility -- and when compression begins to erase task-relevant content -- remain underexplored. In this paper, we define \\emph{token overflow} as a regime in which compressed representations no longer contain sufficient information to answer a given query, and propose a methodology to characterize and detect it. In the xRAG soft-compression setting, we find that query-agnostic saturation statistics reliably separate compressed from uncompressed token representations, providing a practical tool for identifying compressed tokens but showing limited overflow detection capability. Lightweight probing classifiers over both query and context xRAG representations detect overflow with 0.72 AUC-ROC on average on HotpotQA, SQuADv2, and TriviaQA datasets, demonstrating that incorporating query information improves detection performance. These results advance from query-independent diagnostics to query-aware detectors, enabling low-cost pre-LLM gating to mitigate compression-induced errors.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12235v1",
        "authors": [
          "Julia Belikova",
          "Danila Rozhevskii",
          "Dennis Svirin",
          "Konstantin Polev",
          "Alexander Panchenko"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Compressed Token Representations",
        "Augmented Generation Efficient",
        "Detecting Overflow",
        "Act",
        "EPA",
        "ROC",
        "MIT",
        "LLM",
        "AUC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.018305"
    },
    {
      "id": "arxiv-2602.12233v1",
      "title": "Categorical Flow Maps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12233v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12233v1",
        "authors": [
          "Daan Roos",
          "Oscar Davis",
          "Floor Eijkelboom",
          "Michael Bronstein",
          "Max Welling"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Categorical Flow Maps We",
        "Categorical Flow Maps",
        "Fusion",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.018576"
    },
    {
      "id": "arxiv-2602.12229v1",
      "title": "Diffusion Alignment Beyond KL: Variance Minimisation as Effective Policy Optimiser",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12229v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Diffusion alignment adapts pretrained diffusion models to sample from reward-tilted distributions along the denoising trajectory. This process naturally admits a Sequential Monte Carlo (SMC) interpretation, where the denoising model acts as a proposal and reward guidance induces importance weights. Motivated by this view, we introduce Variance Minimisation Policy Optimisation (VMPO), which formulates diffusion alignment as minimising the variance of log importance weights rather than directly optimising a Kullback-Leibler (KL) based objective. We prove that the variance objective is minimised by the reward-tilted target distribution and that, under on-policy sampling, its gradient coincides with that of standard KL-based alignment. This perspective offers a common lens for understanding diffusion alignment. Under different choices of potential functions and variance minimisation strategies, VMPO recovers various existing methods, while also suggesting new design directions beyond KL.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12229v1",
        "authors": [
          "Zijing Ou",
          "Jacob Si",
          "Junyi Zhu",
          "Ondrej Bohdal",
          "Mete Ozay"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variance Minimisation Policy Optimisation",
        "Effective Policy Optimiser Diffusion",
        "Diffusion Alignment Beyond",
        "Sequential Monte Carlo",
        "Variance Minimisation",
        "Standard",
        "Policy",
        "Fusion",
        "VMPO",
        "Act",
        "MIT",
        "SMC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.018837"
    },
    {
      "id": "arxiv-2602.12224v1",
      "title": "Bandit Learning in Matching Markets with Interviews",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12224v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.",
        "keywords": [
          "cs.GT",
          "cs.AI",
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12224v1",
        "authors": [
          "Amirmahdi Mirfakhar",
          "Xuchuang Wang",
          "Mengfan Xu",
          "Hedyeh Beyhaghi",
          "Mohammad Hajiesmaili"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.AI",
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Matching Markets",
        "Bandit Learning",
        "Interviews Two",
        "Framework",
        "Act",
        "EPA",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:07.019125"
    },
    {
      "id": "arxiv-2602.12222v1",
      "title": "Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12222v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \\textbf{\\textit{Distribution Discriminant Theory (DDT)}}, which explains and quantifies the alignment between data and the model-induced distribution. Leveraging DDT, we introduce two complementary techniques: (i) \\textbf{\\textit{In-Distribution Finetuning (IDFT)}}, a loss-level method to enhance generalization ability of SFT, and (ii) \\textbf{\\textit{Hinted Decoding}}, a data-level technique that can re-align the training corpus to the model's distribution. Extensive experiments demonstrate that our framework achieves generalization performance on par with prominent offline RL algorithms, including DPO and SimPO, while maintaining the efficiency of an SFT pipeline. The proposed framework thus offers a practical alternative in domains where RL is infeasible. We open-source the code here: https://github.com/zhangmiaosen2000/Towards-On-Policy-SFT",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12222v1",
        "authors": [
          "Miaosen Zhang",
          "Yishan Liu",
          "Shuxia Lin",
          "Xu Yang",
          "Qi Dai"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distribution Finetuning",
        "Training Supervised",
        "Hinted Decoding",
        "Towards On",
        "Framework",
        "Policy",
        "IDFT",
        "Act",
        "DDT",
        "DPO",
        "LLM",
        "SFT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.019381"
    },
    {
      "id": "arxiv-2602.12221v1",
      "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12221v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12221v1",
        "authors": [
          "Onkar Susladkar",
          "Tushar Prakash",
          "Gayatri Deshmukh",
          "Kiet A. Nguyen",
          "Jiaxun Zhang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Discrete Flow Matching",
        "Multimodal Reasoning",
        "Both Worlds",
        "Framework",
        "SOTA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.019564"
    },
    {
      "id": "arxiv-2602.12218v1",
      "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12218v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12218v1",
        "authors": [
          "Christian Internò",
          "Jumpei Yamaguchi",
          "Loren Amdahl-Culleton",
          "Markus Olhofer",
          "David Klindt"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Invasive Adaptation Corrupts Latent",
        "Physics Determining",
        "World Models",
        "Standard",
        "Protocol",
        "WTO",
        "SSL",
        "OOD",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.020111"
    },
    {
      "id": "arxiv-2602.12207v1",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12207v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.",
        "keywords": [
          "cs.HC",
          "cs.AI",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12207v1",
        "authors": [
          "Emma Hoes",
          "K. Jonathan Klueser",
          "Fabrizio Gilardi"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI",
          "cs.SI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Democratic Innovation Digital",
        "Virtual Arena",
        "University",
        "VIRENA",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:07.020411"
    },
    {
      "id": "arxiv-2602.12205v1",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12205v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12205v1",
        "authors": [
          "Dianyi Wang",
          "Ruihang Li",
          "Feng Han",
          "Chaofan Ma",
          "Wei Song"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lightweight Unified Multimodal Model",
        "Advancing Image Generation",
        "Stacked Channel Bridging",
        "Reinforcement Learning",
        "Joint Supervised Fine",
        "Editing Current",
        "Alignment Pre",
        "Framework",
        "WISE",
        "GRPO",
        "Act",
        "VLM",
        "SCB",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.020768"
    },
    {
      "id": "arxiv-2602.12204v1",
      "title": "Learning to Forget Attention: Memory Consolidation for Adaptive Compute Reduction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12204v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Hybrid architectures combining state-space models with attention have achieved strong efficiency-quality tradeoffs, yet existing approaches either apply attention uniformly or learn static sparse patterns. This misses a key opportunity: \\emph{attention demand should decrease over time as recurring patterns become familiar}. We present a surprising finding from analyzing GPT-2 models: \\textbf{88\\%} of attention operations retrieve information already predictable from the model's hidden state, and this redundancy does \\emph{not} decrease during training. Motivated by this observation, we introduce \\textbf{\\ours{}} (\\textbf{C}onsolidation-based \\textbf{R}outing for \\textbf{A}daptive \\textbf{M}emory), a biologically inspired memory consolidation mechanism that gradually distills episodic retrievals into parametric semantic memory. Unlike prior sparse attention methods, \\ours{} exhibits \\emph{decreasing attention utilization} over training, achieving a \\textbf{37.8$\\times$} reduction through a sharp phase transition at approximately 3K steps. We prove that this capability is \\emph{impossible} without consolidation: any static routing scheme requires $Ω(f \\cdot n)$ attention for tasks with recurring patterns of frequency $f$. On our proposed SRCD benchmark, \\ours{} achieves \\textbf{100\\% retrieval accuracy} at 1.6\\% attention compute (vs.\\ 68\\% for baselines), and consolidated patterns transfer to unseen tasks with \\textbf{48--52\\%} attention reduction without retraining. Remarkably, the learned consolidation dynamics quantitatively match human episodic-to-semantic memory transition curves from cognitive psychology ($γ= 0.43$ vs.\\ $γ_{\\text{human}} \\approx 0.4$--$0.5$). Code and benchmarks are available at [anonymized].",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12204v1",
        "authors": [
          "Ibne Farabi Shihab",
          "Sanjeda Akter",
          "Anuj Sharma"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adaptive Compute Reduction Hybrid",
        "Memory Consolidation",
        "Forget Attention",
        "GPT-2",
        "SRCD",
        "NSF",
        "DOE",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.021545"
    },
    {
      "id": "arxiv-2602.12203v1",
      "title": "ExStrucTiny: A Benchmark for Schema-Variable Structured Information Extraction from Document Images",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12203v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Enterprise documents, such as forms and reports, embed critical information for downstream applications like data archiving, automated workflows, and analytics. Although generalist Vision Language Models (VLMs) perform well on established document understanding benchmarks, their ability to conduct holistic, fine-grained structured extraction across diverse document types and flexible schemas is not well studied. Existing Key Entity Extraction (KEE), Relation Extraction (RE), and Visual Question Answering (VQA) datasets are limited by narrow entity ontologies, simple queries, or homogeneous document types, often overlooking the need for adaptable and structured extraction. To address these gaps, we introduce ExStrucTiny, a new benchmark dataset for structured Information Extraction (IE) from document images, unifying aspects of KEE, RE, and VQA. Built through a novel pipeline combining manual and synthetic human-validated samples, ExStrucTiny covers more varied document types and extraction scenarios. We analyze open and closed VLMs on this benchmark, highlighting challenges such as schema adaptation, query under-specification, and answer localization. We hope our work provides a bedrock for improving generalist models for structured IE in documents.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12203v1",
        "authors": [
          "Mathieu Sibue",
          "Andres Muñoz Garza",
          "Samuel Mensah",
          "Pranav Shetty",
          "Zhiqiang Ma"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variable Structured Information Extraction",
        "Existing Key Entity Extraction",
        "Document Images Enterprise",
        "Visual Question Answering",
        "Vision Language Models",
        "Information Extraction",
        "Relation Extraction",
        "Act",
        "KEE",
        "MIT",
        "VQA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.021814"
    },
    {
      "id": "arxiv-2602.12196v1",
      "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12196v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12196v1",
        "authors": [
          "Mohamed Huti",
          "Alasdair Mackintosh",
          "Amy Waldock",
          "Dominic Andrews",
          "Maxime Lelièvre"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Large Language Models",
        "Visual Reasoning Benchmark",
        "Authentic Visual Problems",
        "Evaluating Multimodal",
        "Primary Education",
        "VRB",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.022118"
    },
    {
      "id": "arxiv-2602.12192v1",
      "title": "Query-focused and Memory-aware Reranker for Long Context Processing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12192v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12192v1",
        "authors": [
          "Yuqing Li",
          "Jiangnan Li",
          "Mo Yu",
          "Guoxuan Ding",
          "Zheng Lin"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Long Context Processing Built",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.022382"
    },
    {
      "id": "arxiv-2602.12189v1",
      "title": "WaveFormer: Wavelet Embedding Transformer for Biomedical Signals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12189v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Biomedical signal classification presents unique challenges due to long sequences, complex temporal dynamics, and multi-scale frequency patterns that are poorly captured by standard transformer architectures. We propose WaveFormer, a transformer architecture that integrates wavelet decomposition at two critical stages: embedding construction, where multi-channel Discrete Wavelet Transform (DWT) extracts frequency features to create tokens containing both time-domain and frequency-domain information, and positional encoding, where Dynamic Wavelet Positional Encoding (DyWPE) adapts position embeddings to signal-specific temporal structure through mono-channel DWT analysis. We evaluate WaveFormer on eight diverse datasets spanning human activity recognition and brain signal analysis, with sequence lengths ranging from 50 to 3000 timesteps and channel counts from 1 to 144. Experimental results demonstrate that WaveFormer achieves competitive performance through comprehensive frequency-aware processing. Our approach provides a principled framework for incorporating frequency-domain knowledge into transformer-based time series classification.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12189v1",
        "authors": [
          "Habib Irani",
          "Bikram De",
          "Vangelis Metsis"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Wavelet Positional Encoding",
        "Wavelet Embedding Transformer",
        "Biomedical Signals Biomedical",
        "Discrete Wavelet Transform",
        "Transformer",
        "Framework",
        "Standard",
        "Act",
        "NSF",
        "DWT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.022614"
    },
    {
      "id": "arxiv-2602.12187v1",
      "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12187v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12187v1",
        "authors": [
          "Sunghwan Kim",
          "Wooseok Jeong",
          "Serin Kim",
          "Sangam Lee",
          "Dongha Lee"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Augmented Generative Engine Optimization",
        "Augmented Generative Engines",
        "Realistic Environment",
        "Evaluating Search",
        "SAGEO",
        "SAGE",
        "Act",
        "MIT",
        "GEO",
        "SEO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.022963"
    },
    {
      "id": "arxiv-2602.12181v1",
      "title": "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12181v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.",
        "keywords": [
          "cs.GT",
          "cs.LG",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12181v1",
        "authors": [
          "Anas Barakat",
          "Ioannis Panageas",
          "Antonios Varvitsiotis"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.LG",
          "cs.MA"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Nash Equilibria Convex Markov",
        "General Utility Markov Games",
        "Convex Markov Games",
        "Learning Algorithms",
        "New Proof",
        "Policy",
        "Act",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:07.023257"
    },
    {
      "id": "arxiv-2602.12180v1",
      "title": "How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12180v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.",
        "keywords": [
          "cs.LG",
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12180v1",
        "authors": [
          "Yurong Chen",
          "Yu He",
          "Michael I. Jordan",
          "Fan Yao"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Identity Preference Optimization",
        "Direct Preference Optimization",
        "Iterative Dynamics Standard",
        "How Sampling Shapes",
        "Shot Optima",
        "Framework",
        "Standard",
        "From One",
        "Policy",
        "Act",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.023502"
    },
    {
      "id": "arxiv-2602.12177v1",
      "title": "EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12177v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12177v1",
        "authors": [
          "Nils Lehmann",
          "Yi Wang",
          "Zhitong Xiong",
          "Xiaoxiang Zhu"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Earth Observation Data State",
        "EPA",
        "VAE",
        "RGB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.023698"
    },
    {
      "id": "arxiv-2602.12173v1",
      "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12173v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12173v1",
        "authors": [
          "Chengxi Zeng",
          "Yuxuan Jiang",
          "Ge Gao",
          "Shuai Wang",
          "Duolikun Danier"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Language Segmentation Vision",
        "An Anatomical Study",
        "Efficient Vision",
        "Text Encoder",
        "Framework",
        "Wind",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.023974"
    },
    {
      "id": "arxiv-2602.12172v1",
      "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12172v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12172v1",
        "authors": [
          "Bowei He",
          "Yankai Chen",
          "Xiaokun Zhang",
          "Linghe Kong",
          "Philip S. Yu"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Language Model Knowledge Distillation",
        "Mastery Learning Principles",
        "Inspired Data Synthesis",
        "Large Language Models",
        "Knowledge Identifier",
        "Proximal Development",
        "Framework",
        "LLaMA-3.1",
        "MATH",
        "NSF",
        "IOA",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.024286"
    },
    {
      "id": "arxiv-2602.12170v1",
      "title": "Statistical Parsing for Logical Information Retrieval",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12170v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language. This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers. We argue this reconciles formal semantics with Sutton's \"bitter lesson\" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12170v1",
        "authors": [
          "Greg Coppola"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantified Boolean Bayesian Network",
        "Logical Information Retrieval In",
        "Statistical Parsing",
        "NIST",
        "QBBN",
        "Act",
        "NEG",
        "UAS",
        "NLP",
        "LLM"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.024584"
    },
    {
      "id": "arxiv-2602.12164v1",
      "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12164v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12164v1",
        "authors": [
          "Xiaohan He",
          "Shiyang Feng",
          "Songtao Huang",
          "Lei Bai",
          "Bin Wang"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sparse Supervision Large",
        "Scientific Reasoning",
        "Geometric Consensus",
        "Framework",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.024830"
    },
    {
      "id": "arxiv-2602.12162v1",
      "title": "Amortized Molecular Optimization via Group Relative Policy Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12162v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as \"Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12162v1",
        "authors": [
          "Muhammad bin Javaid",
          "Hasham Hussain",
          "Ashima Khanna",
          "Berke Kisin",
          "Jonathan Pirnay"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Group Relative Policy Optimization",
        "Amortized Molecular Optimization",
        "Instance Optimizers",
        "Graph Transformer",
        "Transformer",
        "Oracle",
        "Policy",
        "GRPO",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.025071"
    },
    {
      "id": "arxiv-2602.12160v1",
      "title": "DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12160v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12160v1",
        "authors": [
          "Xu Guo",
          "Fulong Ye",
          "Qichao Sun",
          "Liyang Chen",
          "Bingchuan Li"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Symmetric Conditional Diffusion Transformer",
        "Task Progressive Training",
        "Video Generation Recent",
        "Level Disentanglement",
        "Structured Captions",
        "Controllable Human",
        "Unified Framework",
        "Centric Audio",
        "Transformer",
        "Framework",
        "Fusion",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.025395"
    },
    {
      "id": "arxiv-2602.12159v1",
      "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12159v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12159v1",
        "authors": [
          "Wancai Zheng",
          "Hao Chen",
          "Xianlong Lu",
          "Linlin Ou",
          "Xinyi Yu"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Splatting Object",
        "Language Model Reasoning",
        "Gaussian Splatting",
        "Object Navigation",
        "Enhancing Vision",
        "Framework",
        "Robot",
        "Intel",
        "ZSON",
        "Act",
        "VLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.025682"
    },
    {
      "id": "arxiv-2602.12158v1",
      "title": "SafeNeuron: Neuron-Level Safety Alignment for Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12158v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods operate at the behavioral level, offering limited control over the model's internal safety mechanisms. In this work, we propose SafeNeuron, a neuron-level safety alignment framework that improves robustness by redistributing safety representations across the network. SafeNeuron first identifies safety-related neurons, then freezes these neurons during preference optimization to prevent reliance on sparse safety pathways and force the model to construct redundant safety representations. Extensive experiments across models and modalities demonstrate that SafeNeuron significantly improves robustness against neuron pruning attacks, reduces the risk of open-source models being repurposed as red-team generators, and preserves general capabilities. Furthermore, our layer-wise analysis reveals that safety behaviors are governed by stable and shared internal representations. Overall, SafeNeuron provides an interpretable and robust perspective for model alignment.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12158v1",
        "authors": [
          "Zhaoxin Wang",
          "Jiaming Liang",
          "Fengbin Zhu",
          "Weixiang Zhao",
          "Junfeng Fang"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models Large",
        "Level Safety Alignment",
        "Framework",
        "MIT",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.025947"
    },
    {
      "id": "arxiv-2602.12157v1",
      "title": "TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12157v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.",
        "keywords": [
          "cs.CV",
          "cs.GR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12157v1",
        "authors": [
          "Ziteng Lu",
          "Yushuang Wu",
          "Chongjie Ye",
          "Yuda Qiu",
          "Jing Shao"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.GR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Point Latent Representation High",
        "Texture Enhancement",
        "Each Texlet",
        "Transformer",
        "Framework",
        "Fusion",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.026224"
    },
    {
      "id": "arxiv-2602.12155v1",
      "title": "FAIL: Flow Matching Adversarial Imitation Learning for Image Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12155v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12155v1",
        "authors": [
          "Yeyao Ma",
          "Chen Li",
          "Xiaosong Zhang",
          "Han Hu",
          "Weidi Xie"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Flow Matching Adversarial Imitation",
        "Image Generation Post",
        "While Supervised Fine",
        "Nano Banana",
        "Framework",
        "Policy",
        "FLUX",
        "FAIL",
        "ODE",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.026468"
    },
    {
      "id": "arxiv-2602.12153v1",
      "title": "dVoting: Fast Voting for dLLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12153v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12153v1",
        "authors": [
          "Sicheng Feng",
          "Zigeng Chen",
          "Xinyin Ma",
          "Gongfan Fang",
          "Xinchao Wang"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Diffusion Large Language Models",
        "Fast Voting",
        "Fusion",
        "MMLU",
        "ARC",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.026732"
    },
    {
      "id": "arxiv-2602.12150v1",
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12150v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
        "keywords": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12150v1",
        "authors": [
          "John Muchovej",
          "Amanda Royka",
          "Shane Lee",
          "Julian Jara-Ettinger"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mind Do Large Language",
        "Lacks Core Features",
        "Framework",
        "Act",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.026947"
    },
    {
      "id": "arxiv-2602.12147v1",
      "title": "It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12147v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Time series foundation models (TSFMs) are revolutionizing the forecasting landscape from specific dataset modeling to generalizable task evaluation. However, we contend that existing benchmarks exhibit common limitations in four dimensions: constrained data composition dominated by reused legacy sources, compromised data integrity lacking rigorous quality assurance, misaligned task formulations detached from real-world contexts, and rigid analysis perspectives that obscure generalizable insights. To bridge these gaps, we introduce TIME, a next-generation task-centric benchmark comprising 50 fresh datasets and 98 forecasting tasks, tailored for strict zero-shot TSFM evaluation free from data leakage. Integrating large language models and human expertise, we establish a rigorous human-in-the-loop benchmark construction pipeline to ensure high data integrity and redefine task formulation by aligning forecasting configurations with real-world operational requirements and variate predictability. Furthermore, we propose a novel pattern-level evaluation perspective that moves beyond traditional dataset-level evaluations based on static meta labels. By leveraging structural time series features to characterize intrinsic temporal properties, this approach offers generalizable insights into model capabilities across diverse patterns. We evaluate 12 representative TSFMs and establish a multi-granular leaderboard to facilitate in-depth analysis and visualized inspection. The leaderboard is available at https://huggingface.co/spaces/Real-TSF/TIME-leaderboard.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12147v1",
        "authors": [
          "Zhongzheng Qiao",
          "Sheng Pan",
          "Anni Wang",
          "Viktoriya Zhukova",
          "Yong Liu"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Series Forecasting Benchmarks",
        "Next Generation",
        "TIME",
        "Meta",
        "TSFM",
        "Act",
        "MIT",
        "TSF",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.027254"
    },
    {
      "id": "arxiv-2602.12146v1",
      "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12146v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.",
        "keywords": [
          "cs.AI",
          "cs.CL",
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12146v1",
        "authors": [
          "Mahdi Khodabandeh",
          "Ghazal Shabani",
          "Arash Yousefi Jordehi",
          "Seyed Abolghasem Mirroshandel"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL",
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcement Learning Efficient",
        "Discrete Latent Transformers",
        "Lossless Data Compression",
        "Reinforcement Learning",
        "Deep Learning",
        "Transformer",
        "Policy",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.027566"
    },
    {
      "id": "arxiv-2602.12144v1",
      "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12144v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12144v1",
        "authors": [
          "Muhammad Ahmad Khan",
          "Hasnain Ali",
          "Muneeb Rana",
          "Muhammad Saqib Ilyas",
          "Abdul Ali Bangash"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Coding Agents",
        "Act",
        "OSS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.027806"
    },
    {
      "id": "arxiv-2602.12143v1",
      "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12143v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.",
        "keywords": [
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12143v1",
        "authors": [
          "Xiaoxiao Wang",
          "Chunxiao Li",
          "Junying Wang",
          "Yijin Guo",
          "Zijian Chen"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constrained Probabilistic Matrix Factorization",
        "Large Model Performance Prediction",
        "Bridging Statistical",
        "Agentic Reasoning",
        "Framework",
        "CPMF",
        "STAR",
        "Act",
        "MIT",
        "LLM",
        "EVT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.028039"
    },
    {
      "id": "arxiv-2602.12139v1",
      "title": "Oscillators Are All You Need: Irregular Time Series Modelling via Damped Harmonic Oscillators with Closed-Form Solutions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12139v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Transformers excel at time series modelling through attention mechanisms that capture long-term temporal patterns. However, they assume uniform time intervals and therefore struggle with irregular time series. Neural Ordinary Differential Equations (NODEs) effectively handle irregular time series by modelling hidden states as continuously evolving trajectories. ContiFormers arxiv:2402.10635 combine NODEs with Transformers, but inherit the computational bottleneck of the former by using heavy numerical solvers. This bottleneck can be removed by using a closed-form solution for the given dynamical system - but this is known to be intractable in general! We obviate this by replacing NODEs with a novel linear damped harmonic oscillator analogy - which has a known closed-form solution. We model keys and values as damped, driven oscillators and expand the query in a sinusoidal basis up to a suitable number of modes. This analogy naturally captures the query-key coupling that is fundamental to any transformer architecture by modelling attention as a resonance phenomenon. Our closed-form solution eliminates the computational overhead of numerical ODE solvers while preserving expressivity. We prove that this oscillator-based parameterisation maintains the universal approximation property of continuous-time attention; specifically, any discrete attention matrix realisable by ContiFormer's continuous keys can be approximated arbitrarily well by our fixed oscillator modes. Our approach delivers both theoretical guarantees and scalability, achieving state-of-the-art performance on irregular time series benchmarks while being orders of magnitude faster.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12139v1",
        "authors": [
          "Yashas Shende",
          "Aritra Das",
          "Reva Laxmi Chauhan",
          "Arghya Pathak",
          "Debayan Gupta"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Ordinary Differential Equations",
        "Irregular Time Series Modelling",
        "Damped Harmonic Oscillators",
        "Form Solutions Transformers",
        "Oscillators Are All You",
        "Transformer",
        "Act",
        "NSF",
        "ODE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.028356"
    },
    {
      "id": "arxiv-2602.12137v1",
      "title": "CitiLink-Minutes: A Multilayer Annotated Dataset of Municipal Meeting Minutes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12137v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "City councils play a crucial role in local governance, directly influencing citizens' daily lives through decisions made during municipal meetings. These deliberations are formally documented in meeting minutes, which serve as official records of discussions, decisions, and voting outcomes. Despite their importance, municipal meeting records have received little attention in Information Retrieval (IR) and Natural Language Processing (NLP), largely due to the lack of annotated datasets, which ultimately limit the development of computational models. To address this gap, we introduce CitiLink-Minutes, a multilayer dataset of 120 European Portuguese municipal meeting minutes from six municipalities. Unlike prior annotated datasets of parliamentary or video records, CitiLink-Minutes provides multilayer annotations and structured linkage of official written minutes. The dataset contains over one million tokens, with all personal identifiers de-identified. Each minute was manually annotated by two trained annotators and curated by an experienced linguist across three complementary dimensions: (1) metadata, (2) subjects of discussion, and (3) voting outcomes, totaling over 38,000 individual annotations. Released under FAIR principles and accompanied by baseline results on metadata extraction, topic classification, and vote labeling, CitiLink-Minutes demonstrates its potential for downstream NLP and IR tasks, while promoting transparent access to municipal decisions.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12137v1",
        "authors": [
          "Ricardo Campos",
          "Ana Filipa Pacheco",
          "Ana Luísa Fernandes",
          "Inês Cantante",
          "Rute Rebouças"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Municipal Meeting Minutes City",
        "Multilayer Annotated Dataset",
        "Natural Language Processing",
        "Information Retrieval",
        "European Portuguese",
        "FAIR",
        "Meta",
        "Act",
        "MIT",
        "NLP",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.028648"
    },
    {
      "id": "arxiv-2602.12135v1",
      "title": "WavBench: Benchmarking Reasoning, Colloquialism, and Paralinguistics for End-to-End Spoken Dialogue Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12135v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "With the rapid integration of advanced reasoning capabilities into spoken dialogue models, the field urgently demands benchmarks that transcend simple interactions to address real-world complexity. However, current evaluations predominantly adhere to text-generation standards, overlooking the unique audio-centric characteristics of paralinguistics and colloquialisms, alongside the cognitive depth required by modern agents. To bridge this gap, we introduce WavBench, a comprehensive benchmark designed to evaluate realistic conversational abilities where prior works fall short. Uniquely, WavBench establishes a tripartite framework: 1) Pro subset, designed to rigorously challenge reasoning-enhanced models with significantly increased difficulty; 2) Basic subset, defining a novel standard for spoken colloquialism that prioritizes \"listenability\" through natural vocabulary, linguistic fluency, and interactive rapport, rather than rigid written accuracy; and 3) Acoustic subset, covering explicit understanding, generation, and implicit dialogue to rigorously evaluate comprehensive paralinguistic capabilities within authentic real-world scenarios. Through evaluating five state-of-the-art models, WavBench offers critical insights into the intersection of complex problem-solving, colloquial delivery, and paralinguistic fidelity, guiding the evolution of robust spoken dialogue models. The benchmark dataset and evaluation toolkit are available at https://naruto-2024.github.io/wavbench.github.io/.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12135v1",
        "authors": [
          "Yangzhuo Li",
          "Shengpeng Ji",
          "Yifu Chen",
          "Tianle Liang",
          "Haorong Ying"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "End Spoken Dialogue Models",
        "Benchmarking Reasoning",
        "Framework",
        "Standard",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.028939"
    },
    {
      "id": "arxiv-2602.12134v1",
      "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12134v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.",
        "keywords": [
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12134v1",
        "authors": [
          "Jiajun Chen",
          "Hua Shen"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Measuring Value Trade",
        "Value Alignment Tax",
        "Alignment Existing",
        "Framework",
        "Act",
        "VAT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.029127"
    },
    {
      "id": "arxiv-2602.12133v1",
      "title": "Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12133v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong \"default white\" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.",
        "keywords": [
          "cs.AI",
          "cs.CL",
          "cs.CY",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12133v1",
        "authors": [
          "Roberto Balestri"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL",
          "cs.CY",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantifying Gender",
        "Neutral Prompts",
        "Neutral People",
        "Gemini Flash",
        "Tone Bias",
        "Framework",
        "PERLA",
        "MST",
        "GPT",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.029380"
    },
    {
      "id": "arxiv-2602.12132v1",
      "title": "A Rule-based Computational Model for Gaidhlig Morphology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12132v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Language models and software tools are essential to support the continuing vitality of lesser-used languages; however, currently popular neural models require considerable data for training, which normally is not available for such low-resource languages. This paper describes work-in-progress to construct a rule-based model of Gaidhlig morphology using data from Wiktionary, arguing that rule-based systems effectively leverage limited sample data, support greater interpretability, and provide insights useful in the design of teaching materials. The use of SQL for querying the occurrence of different lexical patterns is investigated, and a declarative rule-base is presented that allows Python utilities to derive inflected forms of Gaidhlig words. This functionality could be used to support educational tools that teach or explain language patterns, for example, or to support higher level tools such as rule-based dependency parsers. This approach adds value to the data already present in Wiktionary by adapting it to new use-cases.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12132v1",
        "authors": [
          "Peter J Barclay"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaidhlig Morphology Language",
        "Computational Model",
        "SQL",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.029596"
    },
    {
      "id": "arxiv-2602.12129v1",
      "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12129v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph. To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset",
        "keywords": [
          "cs.IR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12129v1",
        "authors": [
          "Rahin Arefin Ahmed",
          "Md. Anik Chowdhury",
          "Sakil Ahmed Sheikh Reza",
          "Devnil Bhattacharjee",
          "Muhammad Abdullah Adnan"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Towards Personalized Bangla Book",
        "Entity Book Graph Dataset",
        "Neural Network",
        "Scale Multi",
        "NDCG",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.029881"
    },
    {
      "id": "arxiv-2602.12128v1",
      "title": "HLA: Hadamard Linear Attention",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12128v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax. We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12128v1",
        "authors": [
          "Hanno Ackermann",
          "Hong Cai",
          "Mohsen Ghafoorian",
          "Amirhossein Habibian"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hadamard Linear Attention",
        "Transformer",
        "Standard",
        "Fusion",
        "HLA",
        "NSF",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.030122"
    },
    {
      "id": "arxiv-2602.12127v1",
      "title": "PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12127v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12127v1",
        "authors": [
          "Sixiang Chen",
          "Jianyu Lai",
          "Jialin Gao",
          "Hengyu Shi",
          "Zhongying Liu"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalized Artistic Poster Creation",
        "Unified Reward Feedback Image",
        "Task Distillation",
        "Reward Feedback",
        "Framework",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.030439"
    },
    {
      "id": "arxiv-2602.12125v1",
      "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12125v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12125v1",
        "authors": [
          "Wenkai Yang",
          "Weijie Liu",
          "Ruobing Xie",
          "Kai Yang",
          "Saiyong Yang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reward Extrapolation On",
        "Policy Distillation",
        "Generalized On",
        "Framework",
        "Standard",
        "Policy",
        "OPD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.030782"
    },
    {
      "id": "arxiv-2602.12124v1",
      "title": "Capability-Oriented Training Induced Alignment Risk",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12124v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "While most AI alignment research focuses on preventing models from generating explicitly harmful content, a more subtle risk is emerging: capability-oriented training induced exploitation. We investigate whether language models, when trained with reinforcement learning (RL) in environments with implicit loopholes, will spontaneously learn to exploit these flaws to maximize their reward, even without any malicious intent in their training. To test this, we design a suite of four diverse \"vulnerability games\", each presenting a unique, exploitable flaw related to context-conditional compliance, proxy metrics, reward tampering, and self-evaluation. Our experiments show that models consistently learn to exploit these vulnerabilities, discovering opportunistic strategies that significantly increase their reward at the expense of task correctness or safety. More critically, we find that these exploitative strategies are not narrow \"tricks\" but generalizable skills; they can be transferred to new tasks and even \"distilled\" from a capable teacher model to other student models through data alone. Our findings reveal that capability-oriented training induced risks pose a fundamental challenge to current alignment approaches, suggesting that future AI safety work must extend beyond content moderation to rigorously auditing and securing the training environments and reward mechanisms themselves. Code is available at https://github.com/YujunZhou/Capability_Oriented_Alignment_Risk.",
        "keywords": [
          "cs.LG",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12124v1",
        "authors": [
          "Yujun Zhou",
          "Yue Huang",
          "Han Bao",
          "Kehan Guo",
          "Zhenwen Liang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oriented Training Induced Alignment",
        "Risk While",
        "NIST",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.031058"
    },
    {
      "id": "arxiv-2602.12123v1",
      "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12123v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data. Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights. Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12123v1",
        "authors": [
          "Xubin Wang",
          "Weijia Jia"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Demonstration Selection",
        "Learning Demonstration",
        "Context Learning",
        "Supervised Meta",
        "Agreement",
        "NIST",
        "Meta",
        "Act",
        "ICL",
        "IDF",
        "MIT",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.031349"
    },
    {
      "id": "arxiv-2602.12120v1",
      "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12120v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12120v1",
        "authors": [
          "Jittarin Jetwiriyanon",
          "Teo Susnjak",
          "Surangika Ranathunga"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Institutional Operating Conditions Index",
        "Student Enrolment Forecasting Under",
        "Time Series Foundation Models",
        "Google Trends",
        "Data Sparsity",
        "Google",
        "Wind",
        "TSFM",
        "IOCI",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.031576"
    },
    {
      "id": "arxiv-2602.12117v1",
      "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12117v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12117v1",
        "authors": [
          "Jiakang Shen",
          "Qinghui Chen",
          "Runtong Wang",
          "Chenrui Xu",
          "Jinglin Zhang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meteorological Satellite Tropical",
        "Parameterized Lightweight Physics",
        "Feature Interaction Framework",
        "Tropical Cyclone Estimation",
        "For Maximum Sustained Wind",
        "Arnold Network",
        "Qingyun-1000",
        "Framework",
        "Satellite",
        "Wind",
        "FY-4",
        "Act",
        "MSW",
        "FIF",
        "MLP"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.031855"
    },
    {
      "id": "arxiv-2602.12116v1",
      "title": "P-GenRM: Personalized Generative Reward Model with Test-time User-based Scaling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12116v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Personalized alignment of large language models seeks to adapt responses to individual user preferences, typically via reinforcement learning. A key challenge is obtaining accurate, user-specific reward signals in open-ended scenarios. Existing personalized reward models face two persistent limitations: (1) oversimplifying diverse, scenario-specific preferences into a small, fixed set of evaluation principles, and (2) struggling with generalization to new users with limited feedback. To this end, we propose P-GenRM, the first Personalized Generative Reward Model with test-time user-based scaling. P-GenRM transforms preference signals into structured evaluation chains that derive adaptive personas and scoring rubrics across various scenarios. It further clusters users into User Prototypes and introduces a dual-granularity scaling mechanism: at the individual level, it adaptively scales and aggregates each user's scoring scheme; at the prototype level, it incorporates preferences from similar users. This design mitigates noise in inferred preferences and enhances generalization to unseen users through prototype-based transfer. Empirical results show that P-GenRM achieves state-of-the-art results on widely-used personalized reward model benchmarks, with an average improvement of 2.31%, and demonstrates strong generalization on an out-of-distribution dataset. Notably, Test-time User-based scaling provides an additional 3% boost, demonstrating stronger personalized alignment with test-time scalability.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12116v1",
        "authors": [
          "Pinyi Zhang",
          "Ting-En Lin",
          "Yuchuan Wu",
          "Jingyang Chen",
          "Zongqi Wang"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Personalized Generative Reward Model",
        "Scaling Personalized",
        "User Prototypes",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.032122"
    },
    {
      "id": "arxiv-2602.12113v1",
      "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12113v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12113v1",
        "authors": [
          "Zewei Yu",
          "Lirong Gao",
          "Yuke Zhu",
          "Bo Zheng",
          "Sheng Guo"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Length Coordinated Penalty Large",
        "Stop Unnecessary Reflection",
        "Length Coordinated Penalty",
        "Adaptive Reflection",
        "Efficient Reasoning",
        "Reasoning Models",
        "Framework",
        "Qwen-1",
        "ARLCP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.032421"
    },
    {
      "id": "arxiv-2602.12112v1",
      "title": "Few-Shot Design Optimization by Exploiting Auxiliary Information",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12112v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to real-world experimental setups, where experiments often generate a wealth of useful information. We introduce a new setting where an experiment generates high-dimensional auxiliary information $h(x)$ along with the performance measure $f(x)$; moreover, a history of previously solved tasks from the same task family is available for accelerating optimization. A key challenge of our setting is learning how to represent and utilize $h(x)$ for efficiently solving new optimization tasks beyond the task history. We develop a novel approach for this setting based on a neural model which predicts $f(x)$ for unseen designs given a few-shot context containing observations of $h(x)$. We evaluate our method on two challenging domains, robotic hardware design and neural network hyperparameter tuning, and introduce a novel design problem and large-scale benchmark for the former. On both domains, our method utilizes auxiliary feedback effectively to achieve more accurate few-shot prediction and faster optimization of design tasks, significantly outperforming several methods for multi-task optimization.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12112v1",
        "authors": [
          "Arjun Mani",
          "Carl Vondrick",
          "Richard Zemel"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Exploiting Auxiliary Information Many",
        "Shot Design Optimization",
        "Bayesian Optimization",
        "Neural Network",
        "Framework",
        "Robot",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.032658"
    },
    {
      "id": "arxiv-2602.12108v1",
      "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12108v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12108v1",
        "authors": [
          "Xiaoyuan Liu",
          "Tian Liang",
          "Dongyang Ma",
          "Deyu Zhou",
          "Haitao Mi"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stateful Language Models Mastering",
        "Harry Potter",
        "Standard",
        "Wind",
        "Act",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.032924"
    },
    {
      "id": "arxiv-2602.12107v1",
      "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12107v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\" We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches. Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12107v1",
        "authors": [
          "Haolin Liu",
          "Braham Snyder",
          "Chen-Yu Wei"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Offline Reinforcement Learning",
        "Partial Coverage We",
        "Framework",
        "Act",
        "DEC",
        "CQL",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.033662"
    },
    {
      "id": "arxiv-2602.12105v1",
      "title": "Iskra: A System for Inverse Geometry Processing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12105v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.",
        "keywords": [
          "cs.GR",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12105v1",
        "authors": [
          "Ana Dodik",
          "Ahmed H. Mahmoud",
          "Justin Solomon"
        ],
        "arxiv_categories": [
          "cs.GR",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inverse Geometry Processing We",
        "Machine Learning",
        "Framework",
        "ADMM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.033867"
    },
    {
      "id": "arxiv-2602.12100v1",
      "title": "AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12100v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12100v1",
        "authors": [
          "Lingting Zhu",
          "Shengju Qian",
          "Haidi Fan",
          "Jiayu Dong",
          "Zhenchao Jin"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Assets Generation",
        "Transformer",
        "Framework",
        "NSF",
        "MIT",
        "UGC",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.034062"
    },
    {
      "id": "arxiv-2602.12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12099v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12099v1",
        "authors": [
          " GigaBrain Team",
          "Boyuan Wang",
          "Chaojun Ni",
          "Guan Huang",
          "Guosheng Zhao"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Reinforcement Learning Vision",
        "Espresso Preparation",
        "Laundry Folding",
        "GigaBrain-0.5",
        "Box Packing",
        "GigaBrain-0",
        "Policy",
        "RECAP",
        "Robot",
        "RAMP",
        "Act",
        "WHO",
        "EPA",
        "MIT",
        "VLA"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.034344"
    },
    {
      "id": "arxiv-2602.12096v1",
      "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12096v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12096v1",
        "authors": [
          "Itamar Mishani",
          "Maxim Likhachev"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Robot Motion Planning",
        "Multi Graph Search",
        "Graph Search",
        "Robot",
        "MGS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.034546"
    },
    {
      "id": "arxiv-2602.12092v1",
      "title": "DeepSight: An All-in-One LM Safety Toolkit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12092v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.CR",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12092v1",
        "authors": [
          "Bo Zhang",
          "Jiaxuan Guo",
          "Lijun Li",
          "Dongrui Liu",
          "Sujin Chen"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.CR",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Large Language Models",
        "Large Language Models",
        "Safety Toolkit As",
        "Large Models",
        "Protocol",
        "An All",
        "Act",
        "NSF",
        "EPA",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.034794"
    },
    {
      "id": "arxiv-2602.12089v1",
      "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12089v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.",
        "keywords": [
          "cs.GT",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12089v1",
        "authors": [
          "Kehang Zhu",
          "Lithium Thain",
          "Vivian Tsai",
          "James Wexler",
          "Crystal Qian"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Party Negotiation As",
        "Choose Your Agent",
        "Act",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:07.035097"
    },
    {
      "id": "arxiv-2602.12087v1",
      "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12087v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12087v1",
        "authors": [
          "Alfredo Reichlin",
          "Adriano Pacciarelli",
          "Danica Kragic",
          "Miguel Vasco"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal State Estimation",
        "Learning Metric Spaces",
        "Fusion",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.035344"
    },
    {
      "id": "arxiv-2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12083v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone. We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
        "keywords": [
          "cs.AI",
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12083v1",
        "authors": [
          "Antonin Sulc"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Modal Logical Neural Networks",
        "Differentiable Modal Logic",
        "Communication As",
        "Agent Diagnosis",
        "Neural Network",
        "Framework",
        "Act",
        "WHO",
        "MIT",
        "DML",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.035614"
    },
    {
      "id": "arxiv-2602.12082v1",
      "title": "Empirical Gaussian Processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12082v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Gaussian processes (GPs) are powerful and widely used probabilistic regression models, but their effectiveness in practice is often limited by the choice of kernel function. This kernel function is typically handcrafted from a small set of standard functions, a process that requires expert knowledge, results in limited adaptivity to data, and imposes strong assumptions on the hypothesis space. We study Empirical GPs, a principled framework for constructing flexible, data-driven GP priors that overcome these limitations. Rather than relying on standard parametric kernels, we estimate the mean and covariance functions empirically from a corpus of historical observations, enabling the prior to reflect rich, non-trivial covariance structures present in the data. Theoretically, we show that the resulting model converges to the GP that is closest (in KL-divergence sense) to the real data generating process. Practically, we formulate the problem of learning the GP prior from independent datasets as likelihood estimation and derive an Expectation-Maximization algorithm with closed-form updates, allowing the model handle heterogeneous observation locations across datasets. We demonstrate that Empirical GPs achieve competitive performance on learning curve extrapolation and time series forecasting benchmarks.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12082v1",
        "authors": [
          "Jihao Andreas Lin",
          "Sebastian Ament",
          "Louis C. Tiao",
          "David Eriksson",
          "Maximilian Balandat"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Empirical Gaussian Processes Gaussian",
        "Framework",
        "Standard",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.035846"
    },
    {
      "id": "arxiv-2602.12080v1",
      "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12080v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12080v1",
        "authors": [
          "Hyunsung Kim",
          "Kunhee Lee",
          "Sangwoo Seo",
          "Sang-Ki Ko",
          "Jinsung Yoon"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Free Soccer Event Detection",
        "Player Trajectories Despite",
        "Possession Path Inference",
        "Conditional Random Field",
        "Set Attention",
        "Framework",
        "Act",
        "MIT",
        "CRF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.036122"
    },
    {
      "id": "arxiv-2602.12078v1",
      "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12078v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12078v1",
        "authors": [
          "Wenlong Wang",
          "Fergal Reid"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tiny Recursive Reasoning",
        "Attention Hybrid Recent",
        "Transformer",
        "Mamba-2",
        "AGI-1",
        "Act",
        "NSF",
        "ARC",
        "SSM",
        "MIT",
        "TRM",
        "DOE",
        "AGI",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.036345"
    },
    {
      "id": "arxiv-2602.12058v1",
      "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12058v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.",
        "keywords": [
          "cs.SE",
          "cs.AI",
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12058v1",
        "authors": [
          "Zhiyong Chen",
          "Jialun Cao",
          "Chang Xu",
          "Shing-Chi Cheung"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI",
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "An Integrated Toolkit",
        "Model Visualization",
        "Graph Optimization",
        "Model Repair",
        "Model Digest",
        "Repair Model",
        "Act",
        "EPA",
        "TLA",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.036612"
    },
    {
      "id": "arxiv-2602.12056v1",
      "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12056v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12056v1",
        "authors": [
          "Xinyu Yang",
          "Chenlong Deng",
          "Tongyu Wen",
          "Binyu Xie",
          "Zhicheng Dou"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Environments Legal",
        "Deep Research Legal Agent",
        "EVAL",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.036812"
    },
    {
      "id": "arxiv-2602.12055v1",
      "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12055v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
        "keywords": [
          "cs.AI",
          "cs.MA",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12055v1",
        "authors": [
          "Amath Sow",
          "Mauricio Rodriguez Cesen",
          "Fabiola Martins Campos de Oliveira",
          "Mariusz Wzorek",
          "Daniel de Leng"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.MA",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Aware Prioritized Planning",
        "Iterative Conflict Resolution",
        "Unmanned Traffic Management",
        "Dynamic Airspace Preflight",
        "Safe Flight Interval Path",
        "Large Neighborhood Search",
        "Unmanned Aerial Vehicle",
        "Temporal Constraints",
        "Preflight Planning",
        "Agent Path Finding",
        "Enhanced Conflict",
        "Based Search",
        "While Multi",
        "Framework",
        "Fly Zones"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.037089"
    },
    {
      "id": "arxiv-2602.12049v1",
      "title": "Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12049v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12049v1",
        "authors": [
          "Ryo Mikasa",
          "Shun-ichiro Hayashi",
          "Daichi Mukunoki",
          "Tetsuya Hoshino",
          "Takahiro Katagiri"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Group Relative Policy Optimization",
        "Machine Benchmark Rewards Large",
        "Online Reinforcement Learning",
        "Code Generation Capability",
        "Staged Quality",
        "Policy",
        "GFLOPS",
        "GRPO",
        "HPC",
        "MIT",
        "SQD",
        "GPU",
        "CPU",
        "LLM",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.037285"
    },
    {
      "id": "arxiv-2602.12047v1",
      "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12047v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.",
        "keywords": [
          "cs.RO",
          "cs.LG",
          "eess.SY",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12047v1",
        "authors": [
          "Anutam Srinivasan",
          "Antoine Leeman",
          "Glen Chou"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.LG",
          "eess.SY",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Conformalized System Level Synthesis",
        "Safety Beyond",
        "Training Data",
        "Robust Out",
        "Framework",
        "Act",
        "SLS",
        "MPC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.037475"
    },
    {
      "id": "arxiv-2602.12045v1",
      "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12045v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12045v1",
        "authors": [
          "Jed A. Duersch",
          "Elohan Veillon",
          "Astrid Klipfel",
          "Adlane Sayede",
          "Zied Bouraoui"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Latent Crystallographic Diffusion",
        "Fourier Transformers",
        "Transformer",
        "Fusion",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.037679"
    },
    {
      "id": "arxiv-2602.12044v1",
      "title": "A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12044v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12044v1",
        "authors": [
          "Banglei Guan",
          "Jing Tao",
          "Liang Xu",
          "Dongcai Tan",
          "Pengju Sun"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Adaptive Modulation Method",
        "High Dynamic Range Imaging",
        "Framework",
        "Meta",
        "CMOS",
        "Act",
        "DMD",
        "MIT",
        "CCD",
        "HDR",
        "DIC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.037939"
    },
    {
      "id": "arxiv-2602.12039v1",
      "title": "The Implicit Bias of Logit Regularization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12039v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12039v1",
        "authors": [
          "Alon Beck",
          "Yohai Bar Sinai",
          "Noam Levi"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Logit Regularization Logit",
        "Linear Discriminant",
        "For Gaussian",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.038126"
    },
    {
      "id": "arxiv-2602.12038v1",
      "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12038v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12038v1",
        "authors": [
          "Yuejun Guo",
          "Qiang Hu",
          "Qiang Tang",
          "Yves Le Traon"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Software Vulnerability Detection Vulnerability",
        "An Empirical Study",
        "Imbalance Issue",
        "Deep Learning",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.038355"
    },
    {
      "id": "arxiv-2602.12036v1",
      "title": "Composition-RL: Compose Your Verifiable Prompts for Reinforcement Learning of Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12036v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large-scale verifiable prompts underpin the success of Reinforcement Learning with Verifiable Rewards (RLVR), but they contain many uninformative examples and are costly to expand further. Recent studies focus on better exploiting limited training data by prioritizing hard prompts whose rollout pass rate is 0. However, easy prompts with a pass rate of 1 also become increasingly prevalent as training progresses, thereby reducing the effective data size. To mitigate this, we propose Composition-RL, a simple yet useful approach for better utilizing limited verifiable prompts targeting pass-rate-1 prompts. More specifically, Composition-RL automatically composes multiple problems into a new verifiable question and uses these compositional prompts for RL training. Extensive experiments across model sizes from 4B to 30B show that Composition-RL consistently improves reasoning capability over RL trained on the original dataset. Performance can be further boosted with a curriculum variant of Composition-RL that gradually increases compositional depth over training. Additionally, Composition-RL enables more effective cross-domain RL by composing prompts drawn from different domains. Codes, datasets, and models are available at https://github.com/XinXU-USTC/Composition-RL.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12036v1",
        "authors": [
          "Xin Xu",
          "Clive Bai",
          "Kai Yang",
          "Tianhao Chen",
          "Yangkun Chen"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Compose Your Verifiable Prompts",
        "Large Language Models Large",
        "Reinforcement Learning",
        "Verifiable Rewards",
        "RLVR",
        "USTC",
        "WHO",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.038585"
    },
    {
      "id": "arxiv-2602.12029v1",
      "title": "PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12029v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.",
        "keywords": [
          "cs.LG",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12029v1",
        "authors": [
          "Sunghyeon Woo",
          "Hoseung Kim",
          "Sunghwan Shim",
          "Minjung Jo",
          "Hyunjoon Jeong"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Disaggregated Serving Multi",
        "Shared Prefill Module",
        "Act",
        "EPA",
        "DOE",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.038837"
    },
    {
      "id": "arxiv-2602.12026v1",
      "title": "Protein Circuit Tracing via Cross-layer Transcoders",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12026v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.",
        "keywords": [
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12026v1",
        "authors": [
          "Darin Tsui",
          "Kunal Talreja",
          "Daniel Saeedi",
          "Amirali Aghazadeh"
        ],
        "arxiv_categories": [
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protein Circuit Tracing",
        "Transcoders Protein",
        "Framework",
        "NIST",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:07.039049"
    },
    {
      "id": "arxiv-2602.12264v1",
      "title": "Transmit or Idle: Efficient AoI Optimal Transmission Policy for Gossiping Receivers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12264v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the optimal transmission and scheduling policy for a transmitter (source) communicating with two gossiping receivers aiming at tracking the source's status over time using the age of information (AoI) metric. Gossiping enables local information exchange in a decentralized manner without relying solely on the transmitter's direct communication, which we assume incurs a transmission cost. On the other hand, gossiping may be communicating stale information, necessitating the transmitter's intervention. With communication links having specific success probabilities, we formulate an average-cost Markov Decision Process (MDP) to jointly minimize the sum AoI and transmission cost for such a system in a time-slotted setting. We employ the Relative Value Iteration (RVI) algorithm to evaluate the optimal policy for the transmitter and then prove several structural properties showing that it has an age-difference threshold structure with minimum age activation in the case where gossiping is relatively more reliable. Specifically, direct transmission is optimal only if the minimum AoI of the receivers is large enough and their age difference is below a certain threshold. Otherwise, the transmitter idles to effectively take advantage of gossiping and reduce direct transmission costs. Numerical evaluations demonstrate the significance of our optimal policy compared to multiple baselines. Our result is a first step towards characterizing optimal freshness and transmission cost trade-offs in gossiping networks.",
        "keywords": [
          "cs.IT",
          "cs.NI",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12264v1",
        "authors": [
          "Irtiza Hasan",
          "Ahmed Arafa"
        ],
        "arxiv_categories": [
          "cs.IT",
          "cs.NI",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optimal Transmission Policy",
        "Relative Value Iteration",
        "Markov Decision Process",
        "Gossiping Receivers We",
        "Policy",
        "Act",
        "MIT",
        "MDP",
        "RVI",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.188865"
    },
    {
      "id": "arxiv-2602.12260v1",
      "title": "Legitimate Overrides in Decentralized Protocols",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12260v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Decentralized protocols claim immutable, rule-based execution, yet many embed emergency mechanisms such as chain-level freezes, protocol pauses, and account quarantines. These overrides are crucial for responding to exploits and systemic failures, but they expose a core tension: when does intervention preserve trust and when is it perceived as illegitimate discretion? With approximately $10$ billion in technical exploit losses potentially addressable by onchain intervention (2016--2026), the design of these mechanisms has high practical stakes, but current approaches remain ad hoc and ideologically charged. We address this gap by developing a Scope $\\times$ Authority taxonomy that maps the design space of emergency architectures along two dimensions: the precision of the intervention and the concentration of trigger authority. We formalize the resulting tradeoffs of a standing centralization cost versus containment speed and collateral disruption as a stochastic cost-minimization problem; and derive three testable predictions. Assessing these predictions against 705 documented exploit incidents, we find that containment time varies systematically by authority type; that losses follow a heavy-tailed distribution ($α\\approx 1.33$) concentrating risk in rare catastrophic events; and that community sentiment measurably modulates the effective cost of maintaining intervention capability. The analysis yields concrete design principles that move emergency governance from ideological debate towards quantitative engineering.",
        "keywords": [
          "cs.CR",
          "cs.CY",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12260v1",
        "authors": [
          "Oghenekaro Elem",
          "Nimrod Talmon"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CY",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Decentralized Protocols Decentralized",
        "Legitimate Overrides",
        "Protocol",
        "Bill",
        "Act",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.189486"
    },
    {
      "id": "arxiv-2602.12246v1",
      "title": "6G Empowering Future Robotics: A Vision for Next-Generation Autonomous Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12246v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The convergence of robotics and next-generation communication is a critical driver of technological advancement. As the world transitions from 5G to 6G, the foundational capabilities of wireless networks are evolving to support increasingly complex and autonomous robotic systems. This paper examines the transformative impact of 6G on enhancing key robotics functionalities. It provides a systematic mapping of IMT-2030 key performance indicators to robotic functional blocks including sensing, perception, cognition, actuation and self-learning. Building upon this mapping, we propose a high-level architectural framework integrating robotic, intelligent, and network service planes, underscoring the need for a holistic approach. As an example use case, we present a real-time, dynamic safety framework enabled by IMT-2030 capabilities for safe and efficient human-robot collaboration in shared spaces.",
        "keywords": [
          "cs.NI",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12246v1",
        "authors": [
          "Mona Ghassemian",
          "Andrés Meseguer Valenzuela",
          "Ana Garcia Armada",
          "Dejan Vukobratovic",
          "Periklis Chatzimisios"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Empowering Future Robotics",
        "Framework",
        "IMT-2030",
        "Robot",
        "Intel",
        "Act",
        "NSF",
        "IMT",
        "5G",
        "6G",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.189673"
    },
    {
      "id": "arxiv-2602.12244v1",
      "title": "Any House Any Task: Scalable Long-Horizon Planning for Abstract Human Tasks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12244v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Open world language conditioned task planning is crucial for robots operating in large-scale household environments. While many recent works attempt to address this problem using Large Language Models (LLMs) via prompting or training, a key challenge remains scalability. Performance often degrades rapidly with increasing environment size, plan length, instruction ambiguity, and constraint complexity. In this work, we propose Any House Any Task (AHAT), a household task planner optimized for long-horizon planning in large environments given ambiguous human instructions. At its core, AHAT utilizes an LLM trained to map task instructions and textual scene graphs into grounded subgoals defined in the Planning Domain Definition Language (PDDL). These subgoals are subsequently solved to generate feasible and optimal long-horizon plans through explicit symbolic reasoning. To enhance the model's ability to decompose complex and ambiguous intentions, we introduce TGPO, a novel reinforcement learning algorithm that integrates external correction of intermediate reasoning traces into Group Relative Policy Optimization (GRPO). Experiments demonstrate that AHAT achieves significant performance gains over state-of-the-art prompting, planning, and learning methods, particularly in human-style household tasks characterized by brief instructions but requiring complex execution plans.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12244v1",
        "authors": [
          "Zhihong Liu",
          "Yang Li",
          "Rengming Huang",
          "Cewu Lu",
          "Panpan Cai"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Planning Domain Definition Language",
        "Group Relative Policy Optimization",
        "Abstract Human Tasks Open",
        "Large Language Models",
        "Any House Any Task",
        "Horizon Planning",
        "Scalable Long",
        "Policy",
        "Robot",
        "AHAT",
        "PDDL",
        "TGPO",
        "GRPO",
        "Act",
        "LLM"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.189917"
    },
    {
      "id": "arxiv-2602.12215v1",
      "title": "LDA-1B: Scaling Latent Dynamics Action Model via Universal Embodied Data Ingestion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12215v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent robot foundation models largely rely on large-scale behavior cloning, which imitates expert actions but discards transferable dynamics knowledge embedded in heterogeneous embodied data. While the Unified World Model (UWM) formulation has the potential to leverage such diverse data, existing instantiations struggle to scale to foundation-level due to coarse data usage and fragmented datasets. We introduce LDA-1B, a robot foundation model that scales through universal embodied data ingestion by jointly learning dynamics, policy, and visual forecasting, assigning distinct roles to data of varying quality. To support this regime at scale, we assemble and standardize EI-30k, an embodied interaction dataset comprising over 30k hours of human and robot trajectories in a unified format. Scalable dynamics learning over such heterogeneous data is enabled by prediction in a structured DINO latent space, which avoids redundant pixel-space appearance modeling. Complementing this representation, LDA-1B employs a multi-modal diffusion transformer to handle asynchronous vision and action streams, enabling stable training at the 1B-parameter scale. Experiments in simulation and the real world show LDA-1B outperforms prior methods (e.g., $π_{0.5}$) by up to 21\\%, 48\\%, and 23\\% on contact-rich, dexterous, and long-horizon tasks, respectively. Notably, LDA-1B enables data-efficient fine-tuning, gaining 10\\% by leveraging 30\\% low-quality trajectories typically harmful and discarded.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12215v1",
        "authors": [
          "Jiangran Lyu",
          "Kai Liu",
          "Xuheng Zhang",
          "Haoran Liao",
          "Yusen Feng"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universal Embodied Data Ingestion",
        "Scaling Latent Dynamics Action",
        "Unified World Model",
        "Transformer",
        "Standard",
        "Policy",
        "Fusion",
        "Robot",
        "DINO",
        "Act",
        "NSF",
        "LDA",
        "MIT",
        "UWM",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.190535"
    },
    {
      "id": "arxiv-2602.12199v1",
      "title": "Sub--Riemannian boundary value problems for Optimal Geometric Locomotion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12199v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.",
        "keywords": [
          "cs.RO",
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12199v1",
        "authors": [
          "Oliver Gross",
          "Florine Hartwig",
          "Martin Rumpf",
          "Peter Schröder"
        ],
        "arxiv_categories": [
          "cs.RO",
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optimal Geometric Locomotion We",
        "Framework",
        "Robot",
        "Meta",
        "Act",
        "WHO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.190781"
    },
    {
      "id": "arxiv-2602.12151v1",
      "title": "OServe: Accelerating LLM Serving via Spatial-Temporal Workload Orchestration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12151v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Serving Large Language Models (LLMs) can benefit immensely from parallelizing both the model and input requests across multiple devices, but incoming workloads exhibit substantial spatial and temporal heterogeneity. Spatially, workloads comprise heterogeneous requests with varying compute and memory demands. Temporally, workload composition varies over time. Nevertheless, existing systems typically assume spatially uniform and temporally stable workloads, employing a homogeneous, static model deployment. This mismatch between the assumption and real-world spatial-temporal heterogeneity results in suboptimal performance. We present OServe, an LLM serving system with heterogeneous and flexible model deployment that addresses both spatial and temporal heterogeneity. First, OServe introduces a novel workload-aware scheduling algorithm that optimizes heterogeneous model deployments according to real-time workload characteristics. Second, OServe proposes an efficient workload-adaptive switching method that migrates model deployments in response to predicted workload changes. Experiments on real-world traces show that OServe improves performance by up to 2$\\times$ (average: 1.5$\\times$) compared to state-of-the-art serving systems.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12151v1",
        "authors": [
          "Youhe Jiang",
          "Fangcheng Fu",
          "Taiyi Wang",
          "Guoliang He",
          "Eiko Yoneki"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Temporal Workload Orchestration Serving",
        "Large Language Models",
        "Act",
        "LLM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.191033"
    },
    {
      "id": "arxiv-2602.12095v1",
      "title": "Pack it in: Packing into Partially Filled Containers Through Contact",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12095v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The automation of warehouse operations is crucial for improving productivity and reducing human exposure to hazardous environments. One operation frequently performed in warehouses is bin-packing where items need to be placed into containers, either for delivery to a customer, or for temporary storage in the warehouse. Whilst prior bin-packing works have largely been focused on packing items into empty containers and have adopted collision-free strategies, it is often the case that containers will already be partially filled with items, often in suboptimal arrangements due to transportation about a warehouse. This paper presents a contact-aware packing approach that exploits purposeful interactions with previously placed objects to create free space and enable successful placement of new items. This is achieved by using a contact-based multi-object trajectory optimizer within a model predictive controller, integrated with a physics-aware perception system that estimates object poses even during inevitable occlusions, and a method that suggests physically-feasible locations to place the object inside the container.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12095v1",
        "authors": [
          "David Russell",
          "Zisong Xu",
          "Maximo A. Roa",
          "Mehmet Dogar"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Partially Filled Containers Through",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.191261"
    },
    {
      "id": "arxiv-2602.12074v1",
      "title": "RF-Modulated Adaptive Communication Improves Multi-Agent Robotic Exploration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12074v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Reliable coordination and efficient communication are critical challenges for multi-agent robotic exploration of environments where communication is limited. This work introduces Adaptive-RF Transmission (ART), a novel communication-aware planning algorithm that dynamically modulates transmission location based on signal strength and data payload size, enabling heterogeneous robot teams to share information efficiently without unnecessary backtracking. We further explore an extension to this approach called ART-SST, which enforces signal strength thresholds for high-fidelity data delivery. Through over 480 simulations across three cave-inspired environments, ART consistently outperforms existing strategies, including full rendezvous and minimum-signal heuristic approaches, achieving up to a 58% reduction in distance traveled and up to 52% faster exploration times compared to baseline methods. These results demonstrate that adaptive, payload-aware communication significantly improves coverage efficiency and mission speed in complex, communication-constrained environments, offering a promising foundation for future planetary exploration and search-and-rescue missions.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12074v1",
        "authors": [
          "Lorin Achey",
          "Breanne Crockett",
          "Christoffer Heckman",
          "Bradley Hayes"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Modulated Adaptive Communication Improves",
        "Agent Robotic Exploration Reliable",
        "Robot",
        "SST",
        "MIT",
        "ART",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.191468"
    },
    {
      "id": "arxiv-2602.12070v1",
      "title": "Contention Resolution, With and Without a Global Clock",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12070v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the Contention Resolution problem $n$ parties each wish to have exclusive use of a shared resource for one unit of time. The problem has been studied since the early 1970s, under a variety of assumptions on feedback given to the parties, how the parties wake up, knowledge of $n$, and so on. The most consistent assumption is that parties do not have access to a global clock, only their local time since wake-up. This is surprising because the assumption of a global clock is both technologically realistic and algorithmically interesting. It enriches the problem, and opens the door to entirely new techniques. Our primary results are: [1] We design a new Contention Resolution protocol that guarantees latency $$O\\left(\\left(n\\log\\log n\\log^{(3)} n\\log^{(4)} n\\cdots \\log^{(\\log^* n)} n\\right)\\cdot 2^{\\log^* n}\\right) \\le n(\\log\\log n)^{1+o(1)}$$ in expectation and with high probability. This already establishes at least a roughly $\\log n$ complexity gap between randomized protocols in GlobalClock and LocalClock. [2] Prior analyses of randomized ContentionResolution protocols in LocalClock guaranteed a certain latency with high probability, i.e., with probability $1-1/\\text{poly}(n)$. We observe that it is just as natural to measure expected latency, and prove a $\\log n$-factor complexity gap between the two objectives for memoryless protocols. The In-Expectation complexity is $Θ(n \\log n/\\log\\log n)$ whereas the With-High-Probability latency is $Θ(n\\log^2 n/\\log\\log n)$. Three of these four upper and lower bounds are new. [3] Given the complexity separation above, one would naturally want a ContentionResolution protocol that is optimal under both the In-Expectation and With-High-Probability metrics. This is impossible! It is even impossible to achieve In-Expectation latency $o(n\\log^2 n/(\\log\\log n)^2)$ and With-High-Probability latency $n\\log^{O(1)} n$ simultaneously.",
        "keywords": [
          "cs.DC",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12070v1",
        "authors": [
          "Zixi Cai",
          "Kuowen Chen",
          "Shengquan Du",
          "Tsvi Kopelowitz",
          "Seth Pettie"
        ],
        "arxiv_categories": [
          "cs.DC",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Contention Resolution",
        "Global Clock In",
        "Protocol",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.192200"
    },
    {
      "id": "arxiv-2602.12065v1",
      "title": "Affordance-Graphed Task Worlds: Self-Evolving Task Generation for Scalable Embodied Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12065v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Training robotic policies directly in the real world is expensive and unscalable. Although generative simulation enables large-scale data synthesis, current approaches often fail to generate logically coherent long-horizon tasks and struggle with dynamic physical uncertainties due to open-loop execution. To address these challenges, we propose Affordance-Graphed Task Worlds (AGT-World), a unified framework that autonomously constructs interactive simulated environments and corresponding robot task policies based on real-world observations. Unlike methods relying on random proposals or static replication, AGT-World formalizes the task space as a structured graph, enabling the precise, hierarchical decomposition of complex goals into theoretically grounded atomic primitives. Furthermore, we introduce a Self-Evolution mechanism with hybrid feedback to autonomously refine policies, combining Vision-Language Model reasoning and geometric verification. Extensive experiments demonstrate that our method significantly outperforms in success rates and generalization, achieving a self-improving cycle of proposal, execution, and correction for scalable robot learning.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12065v1",
        "authors": [
          "Xiang Liu",
          "Sen Cui",
          "Guocai Yao",
          "Zhong Cao",
          "Jingheng Ma"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Embodied Learning Training",
        "Evolving Task Generation",
        "Graphed Task Worlds",
        "Language Model",
        "Framework",
        "Robot",
        "Act",
        "MIT",
        "AGT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.192482"
    },
    {
      "id": "arxiv-2602.12063v1",
      "title": "VLAW: Iterative Co-Improvement of Vision-Language-Action Policy and World Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12063v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The goal of this paper is to improve the performance and reliability of vision-language-action (VLA) models through iterative online interaction. Since collecting policy rollouts in the real world is expensive, we investigate whether a learned simulator-specifically, an action-conditioned video generation model-can be used to generate additional rollout data. Unfortunately, existing world models lack the physical fidelity necessary for policy improvement: they are predominantly trained on demonstration datasets that lack coverage of many different physical interactions (particularly failure cases) and struggle to accurately model small yet critical physical details in contact-rich object manipulation. We propose a simple iterative improvement algorithm that uses real-world roll-out data to improve the fidelity of the world model, which can then, in turn, be used to generate supplemental synthetic data for improving the VLA model. In our experiments on a real robot, we use this approach to improve the performance of a state-of-the-art VLA model on multiple downstream tasks. We achieve a 39.2% absolute success rate improvement over the base policy and 11.6% improvement from training with the generated synthetic rollouts. Videos can be found at this anonymous website: https://sites.google.com/view/vla-w",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12063v1",
        "authors": [
          "Yanjiang Guo",
          "Tony Lee",
          "Lucy Xiaoyang Shi",
          "Jianyu Chen",
          "Percy Liang"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Action Policy",
        "Iterative Co",
        "Google",
        "Policy",
        "Robot",
        "VLAW",
        "Act",
        "VLA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.192724"
    },
    {
      "id": "arxiv-2602.12062v1",
      "title": "HoloBrain-0 Technical Report",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12062v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this work, we introduce HoloBrain-0, a comprehensive Vision-Language-Action (VLA) framework that bridges the gap between foundation model research and reliable real-world robot deployment. The core of our system is a novel VLA architecture that explicitly incorporates robot embodiment priors, including multi-view camera parameters and kinematic descriptions (URDF), to enhance 3D spatial reasoning and support diverse embodiments. We validate this design through a scalable ``pre-train then post-train\" paradigm, achieving state-of-the-art results on simulation benchmarks such as RoboTwin 2.0, LIBERO, and GenieSim, as well as strong results on challenging long-horizon real-world manipulation tasks. Notably, our efficient 0.2B-parameter variant rivals significantly larger baselines, enabling low-latency on-device deployment. To further accelerate research and practical adoption, we fully open-source the entire HoloBrain ecosystem, which includes: (1) powerful pre-trained VLA foundations; (2) post-trained checkpoints for multiple simulation suites and real-world tasks; and (3) RoboOrchard, a full-stack VLA infrastructure for data curation, model training and deployment. Together with standardized data collection protocols, this release provides the community with a complete, reproducible path toward high-performance robotic manipulation.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12062v1",
        "authors": [
          "Xuewu Lin",
          "Tianwei Lin",
          "Yun Du",
          "Hongyu Xie",
          "Yiwei Jin"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Technical Report In",
        "HoloBrain-0",
        "Framework",
        "Standard",
        "Protocol",
        "LIBERO",
        "Robot",
        "URDF",
        "Act",
        "VLA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.192968"
    },
    {
      "id": "arxiv-2602.12059v1",
      "title": "Evaluation of Security-Induced Latency on 5G RAN Interfaces and User Plane Communication",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12059v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "5G promises enhanced performance-not only in bandwidth and capacity, but also latency and security. Its ultra-reliable low-latency configuration targets round-trip times below 1 ms, while optional security controls extend protection across all interfaces, making 5G attractive for mission-critical applications. A key enabler of low latency is the disaggregation of network components, including the RAN, allowing user-plane functions to be deployed nearer to end users. However, this split introduces additional interfaces, whose protection increases latency overhead. In this paper, guided by discussions with a network operator and a 5G manufacturer, we evaluate the latency overhead of enabling optional 5G security controls across internal RAN interfaces and the 5G user plane. To this end, we deploy the first testbed implementing a disaggregated RAN with standardized optional security mechanisms. Our results show that disaggregated RAN deployments retain a latency advantage over monolithic designs, even with security enabled. However, achieving sub-1 ms round-trip times remains challenging, as cryptographic overhead alone can already exceed this target.",
        "keywords": [
          "cs.CR",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12059v1",
        "authors": [
          "Sotiris Michaelides",
          "Jakub Lapawa",
          "Daniel Eguiguren Chavez",
          "Martin Henze"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "User Plane Communication",
        "Induced Latency",
        "Standard",
        "Act",
        "WHO",
        "RAN",
        "5G",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.193184"
    },
    {
      "id": "arxiv-2602.12032v1",
      "title": "When would Vision-Proprioception Policies Fail in Robotic Manipulation?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12032v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Proprioceptive information is critical for precise servo control by providing real-time robotic states. Its collaboration with vision is highly expected to enhance performances of the manipulation policy in complex tasks. However, recent studies have reported inconsistent observations on the generalization of vision-proprioception policies. In this work, we investigate this by conducting temporally controlled experiments. We found that during task sub-phases that robot's motion transitions, which require target localization, the vision modality of the vision-proprioception policy plays a limited role. Further analysis reveals that the policy naturally gravitates toward concise proprioceptive signals that offer faster loss reduction when training, thereby dominating the optimization and suppressing the learning of the visual modality during motion-transition phases. To alleviate this, we propose the Gradient Adjustment with Phase-guidance (GAP) algorithm that adaptively modulates the optimization of proprioception, enabling dynamic collaboration within the vision-proprioception policy. Specifically, we leverage proprioception to capture robotic states and estimate the probability of each timestep in the trajectory belonging to motion-transition phases. During policy learning, we apply fine-grained adjustment that reduces the magnitude of proprioception's gradient based on estimated probabilities, leading to robust and generalizable vision-proprioception policies. The comprehensive experiments demonstrate GAP is applicable in both simulated and real-world environments, across one-arm and dual-arm setups, and compatible with both conventional and Vision-Language-Action models. We believe this work can offer valuable insights into the development of vision-proprioception policies in robotic manipulation.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12032v1",
        "authors": [
          "Jingxian Lu",
          "Wenke Xia",
          "Yuxuan Wu",
          "Zhiwu Lu",
          "Di Hu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Proprioception Policies Fail",
        "Robotic Manipulation",
        "Gradient Adjustment",
        "Policy",
        "Robot",
        "Act",
        "MIT",
        "GAP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.193546"
    },
    {
      "id": "arxiv-2602.12024v1",
      "title": "Adaptive-Horizon Conflict-Based Search for Closed-Loop Multi-Agent Path Finding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12024v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "MAPF is a core coordination problem for large robot fleets in automated warehouses and logistics. Existing approaches are typically either open-loop planners, which generate fixed trajectories and struggle to handle disturbances, or closed-loop heuristics without reliable performance guarantees, limiting their use in safety-critical deployments. This paper presents ACCBS, a closed-loop algorithm built on a finite-horizon variant of CBS with a horizon-changing mechanism inspired by iterative deepening in MPC. ACCBS dynamically adjusts the planning horizon based on the available computational budget, and reuses a single constraint tree to enable seamless transitions between horizons. As a result, it produces high-quality feasible solutions quickly while being asymptotically optimal as the budget increases, exhibiting anytime behavior. Extensive case studies demonstrate that ACCBS combines flexibility to disturbances with strong performance guarantees, effectively bridging the gap between theoretical optimality and practical robustness for large-scale robot deployment.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12024v1",
        "authors": [
          "Jiarui Li",
          "Federico Pecora",
          "Runyu Zhang",
          "Gioele Zardini"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Path Finding",
        "Horizon Conflict",
        "Based Search",
        "Loop Multi",
        "ACCBS",
        "Robot",
        "MAPF",
        "Act",
        "MIT",
        "CBS",
        "MPC",
        "AI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.193789"
    },
    {
      "id": "arxiv-2602.12012v1",
      "title": "Decentralized Multi-Robot Obstacle Detection and Tracking in a Maritime Scenario",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12012v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Autonomous aerial-surface robot teams are promising for maritime monitoring. Robust deployment requires reliable perception over reflective water and scalable coordination under limited communication. We present a decentralized multi-robot framework for detecting and tracking floating containers using multiple UAVs cooperating with an autonomous surface vessel. Each UAV performs YOLOv8 and stereo-disparity-based visual detection, then tracks targets with per-object EKFs using uncertainty-aware data association. Compact track summaries are exchanged and fused conservatively via covariance intersection, ensuring consistency under unknown correlations. An information-driven assignment module allocates targets and selects UAV hover viewpoints by trading expected uncertainty reduction against travel effort and safety separation. Simulation results in a maritime scenario demonstrate improved coverage, localization accuracy, and tracking consistency while maintaining modest communication requirements.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12012v1",
        "authors": [
          "Muhammad Farhan Ahmed",
          "Vincent Frémont"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Maritime Scenario Autonomous",
        "Robot Obstacle Detection",
        "Decentralized Multi",
        "Framework",
        "Robot",
        "Act",
        "EPA",
        "MIT",
        "UAV",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.193970"
    },
    {
      "id": "arxiv-2602.11998v1",
      "title": "An Auction-Based Mechanism for Optimal Task Allocation and Resource Aware Containerization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11998v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Distributed computing has enabled cooperation between multiple computing devices for the simultaneous execution of resource-hungry tasks. Such execution also plays a pivotal role in the parallel execution of numerous tasks in the Internet of Things (IoT) environment. Leveraging the computing resources of multiple devices, the offloading and processing of computationintensive tasks can be carried out more efficiently. However, managing resources and optimizing costs remain challenging for successfully executing tasks in cloud-based containerization for IoT. This paper proposes AUC-RAC, an auction-based mechanism for efficient offloading of computation tasks among multiple local servers in the context of IoT devices. The approach leverages the concept of Docker swarm, which connects multiple local servers in the form of Manager Node (MN) and Worker Nodes (WNs). It uses Docker containerization to execute tasks simultaneously. In this system, IoT devices send tasks to the MN, which then sends the task details to all its WNs to participate in the auction-based bidding process. The auctionbased bidding process optimizes the allocation of computation tasks among multiple systems, considering their resource sufficiency. The experimental analysis establishes that the approach offers improved offloading and computation-intensive services for IoT devices by enabling cooperation between local servers.",
        "keywords": [
          "cs.DC",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11998v1",
        "authors": [
          "Ramakant kumar"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Resource Aware Containerization Distributed",
        "Optimal Task Allocation",
        "Internet of Things",
        "Based Mechanism",
        "Worker Nodes",
        "Manager Node",
        "An Auction",
        "AUC",
        "RAC",
        "IoT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.194211"
    },
    {
      "id": "arxiv-2602.11978v1",
      "title": "Accelerating Robotic Reinforcement Learning with Agent Guidance",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11978v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Reinforcement Learning (RL) offers a powerful paradigm for autonomous robots to master generalist manipulation skills through trial-and-error. However, its real-world application is stifled by severe sample inefficiency. Recent Human-in-the-Loop (HIL) methods accelerate training by using human corrections, yet this approach faces a scalability barrier. Reliance on human supervisors imposes a 1:1 supervision ratio that limits fleet expansion, suffers from operator fatigue over extended sessions, and introduces high variance due to inconsistent human proficiency. We present Agent-guided Policy Search (AGPS), a framework that automates the training pipeline by replacing human supervisors with a multimodal agent. Our key insight is that the agent can be viewed as a semantic world model, injecting intrinsic value priors to structure physical exploration. By using executable tools, the agent provides precise guidance via corrective waypoints and spatial constraints for exploration pruning. We validate our approach on two tasks, ranging from precision insertion to deformable object manipulation. Results demonstrate that AGPS outperforms HIL methods in sample efficiency. This automates the supervision pipeline, unlocking the path to labor-free and scalable robot learning. Project website: https://agps-rl.github.io/agps.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11978v1",
        "authors": [
          "Haojun Chen",
          "Zili Zou",
          "Chengdong Ma",
          "Yaoxiang Pu",
          "Haotong Zhang"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Accelerating Robotic Reinforcement Learning",
        "Agent Guidance Reinforcement Learning",
        "Policy Search",
        "Recent Human",
        "Framework",
        "Policy",
        "Robot",
        "AGPS",
        "HIL",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.194453"
    },
    {
      "id": "arxiv-2602.11966v1",
      "title": "MING: An Automated CNN-to-Edge MLIR HLS framework",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11966v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Driven by the increasing demand for low-latency and real-time processing, machine learning applications are steadily migrating toward edge computing platforms, where Field-Programmable Gate Arrays (FPGAs) are widely adopted for their energy efficiency compared to CPUs and GPUs. To generate high-performance and low-power FPGA designs, several frameworks built upon High Level Synthesis (HLS) vendor tools have been proposed, among which MLIR-based frameworks are gaining significant traction due to their extensibility and ease of use. However, existing state-of-the-art frameworks often overlook the stringent resource constraints of edge devices. To address this limitation, we propose MING, an Multi-Level Intermediate Representation (MLIR)-based framework that abstracts and automates the HLS design process. Within this framework, we adopt a streaming architecture with carefully managed buffers, specifically designed to handle resource constraints while ensuring low-latency. In comparison with recent frameworks, our approach achieves on average 15x speedup for standard Convolutional Neural Network (CNN) kernels with up to four layers, and up to 200x for single-layer kernels. For kernels with larger input sizes, MING is capable of generating efficient designs that respect hardware resource constraints, whereas state-of-the-art frameworks struggle to meet.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11966v1",
        "authors": [
          "Jiahong Bi",
          "Lars Schütze",
          "Jeronimo Castrillon"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Intermediate Representation",
        "Convolutional Neural Network",
        "Programmable Gate Arrays",
        "High Level Synthesis",
        "Machine Learning",
        "Edge Computing",
        "Neural Network",
        "An Automated",
        "Framework",
        "Standard",
        "MING",
        "FPGA",
        "MLIR",
        "Act",
        "HLS"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.194687"
    },
    {
      "id": "arxiv-2602.11934v1",
      "title": "Robot-DIFT: Distilling Diffusion Features for Geometrically Consistent Visuomotor Control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11934v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We hypothesize that a key bottleneck in generalizable robot manipulation is not solely data scale or policy capacity, but a structural mismatch between current visual backbones and the physical requirements of closed-loop control. While state-of-the-art vision encoders (including those used in VLAs) optimize for semantic invariance to stabilize classification, manipulation typically demands geometric sensitivity the ability to map millimeter-level pose shifts to predictable feature changes. Their discriminative objective creates a \"blind spot\" for fine-grained control, whereas generative diffusion models inherently encode geometric dependencies within their latent manifolds, encouraging the preservation of dense multi-scale spatial structure. However, directly deploying stochastic diffusion features for control is hindered by stochastic instability, inference latency, and representation drift during fine-tuning. To bridge this gap, we propose Robot-DIFT, a framework that decouples the source of geometric information from the process of inference via Manifold Distillation. By distilling a frozen diffusion teacher into a deterministic Spatial-Semantic Feature Pyramid Network (S2-FPN), we retain the rich geometric priors of the generative model while ensuring temporal stability, real-time execution, and robustness against drift. Pretrained on the large-scale DROID dataset, Robot-DIFT demonstrates superior geometric consistency and control performance compared to leading discriminative baselines, supporting the view that how a model learns to see dictates how well it can learn to act.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11934v1",
        "authors": [
          "Yu Deng",
          "Yufeng Jin",
          "Xiaogang Jia",
          "Jiahong Xue",
          "Gerhard Neumann"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Geometrically Consistent Visuomotor Control",
        "Semantic Feature Pyramid Network",
        "Distilling Diffusion Features",
        "Manifold Distillation",
        "Framework",
        "Policy",
        "Fusion",
        "DROID",
        "Robot",
        "NIST",
        "DIFT",
        "Act",
        "FPN",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.194948"
    },
    {
      "id": "arxiv-2602.11929v1",
      "title": "General Humanoid Whole-Body Control via Pretraining and Fast Adaptation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11929v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Learning a general whole-body controller for humanoid robots remains challenging due to the diversity of motion distributions, the difficulty of fast adaptation, and the need for robust balance in high-dynamic scenarios. Existing approaches often require task-specific training or suffer from performance degradation when adapting to new motions. In this paper, we present FAST, a general humanoid whole-body control framework that enables Fast Adaptation and Stable Motion Tracking. FAST introduces Parseval-Guided Residual Policy Adaptation, which learns a lightweight delta action policy under orthogonality and KL constraints, enabling efficient adaptation to out-of-distribution motions while mitigating catastrophic forgetting. To further improve physical robustness, we propose Center-of-Mass-Aware Control, which incorporates CoM-related observations and objectives to enhance balance when tracking challenging reference motions. Extensive experiments in simulation and real-world deployment demonstrate that FAST consistently outperforms state-of-the-art baselines in robustness, adaptation efficiency, and generalization.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11929v1",
        "authors": [
          "Zepeng Wang",
          "Jiangxing Wang",
          "Shiqing Yao",
          "Yu Zhang",
          "Ziluo Ding"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guided Residual Policy Adaptation",
        "Fast Adaptation Learning",
        "Stable Motion Tracking",
        "General Humanoid Whole",
        "Fast Adaptation",
        "Aware Control",
        "Body Control",
        "Framework",
        "Policy",
        "Robot",
        "FAST",
        "Act",
        "WHO",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.195150"
    },
    {
      "id": "arxiv-2602.11890v1",
      "title": "Data-Driven Trajectory Imputation for Vessel Mobility Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11890v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Modeling vessel activity at sea is critical for a wide range of applications, including route planning, transportation logistics, maritime safety, and environmental monitoring. Over the past two decades, the Automatic Identification System (AIS) has enabled real-time monitoring of hundreds of thousands of vessels, generating huge amounts of data daily. One major challenge in using AIS data is the presence of large gaps in vessel trajectories, often caused by coverage limitations or intentional transmission interruptions. These gaps can significantly degrade data quality, resulting in inaccurate or incomplete analysis. State-of-the-art imputation approaches have mainly been devised to tackle gaps in vehicle trajectories, even when the underlying road network is not considered. But the motion patterns of sailing vessels differ substantially, e.g., smooth turns, maneuvering near ports, or navigating in adverse weather conditions. In this application paper, we propose HABIT, a lightweight, configurable H3 Aggregation-Based Imputation framework for vessel Trajectories. This data-driven framework provides a valuable means to impute missing trajectory segments by extracting, analyzing, and indexing motion patterns from historical AIS data. Our empirical study over AIS data across various timeframes, densities, and vessel types reveals that HABIT produces maritime trajectory imputations performing comparably to baseline methods in terms of accuracy, while performing better in terms of latency while accounting for vessel characteristics and their motion patterns.",
        "keywords": [
          "cs.DB",
          "cs.CG",
          "cs.RO",
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11890v1",
        "authors": [
          "Giannis Spiliopoulos",
          "Alexandros Troupiotis-Kapeliaris",
          "Kostas Patroumpas",
          "Nikolaos Liapis",
          "Dimitrios Skoutas"
        ],
        "arxiv_categories": [
          "cs.DB",
          "cs.CG",
          "cs.RO",
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vessel Mobility Analysis Modeling",
        "Automatic Identification System",
        "Driven Trajectory Imputation",
        "Based Imputation",
        "Framework",
        "HABIT",
        "Act",
        "MIT",
        "AIS",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.195404"
    },
    {
      "id": "arxiv-2602.11885v1",
      "title": "Learning to Manipulate Anything: Revealing Data Scaling Laws in Bounding-Box Guided Policies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11885v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Diffusion-based policies show limited generalization in semantic manipulation, posing a key obstacle to the deployment of real-world robots. This limitation arises because relying solely on text instructions is inadequate to direct the policy's attention toward the target object in complex and dynamic environments. To solve this problem, we propose leveraging bounding-box instruction to directly specify target object, and further investigate whether data scaling laws exist in semantic manipulation tasks. Specifically, we design a handheld segmentation device with an automated annotation pipeline, Label-UMI, which enables the efficient collection of demonstration data with semantic labels. We further propose a semantic-motion-decoupled framework that integrates object detection and bounding-box guided diffusion policy to improve generalization and adaptability in semantic manipulation. Throughout extensive real-world experiments on large-scale datasets, we validate the effectiveness of the approach, and reveal a power-law relationship between generalization performance and the number of bounding-box objects. Finally, we summarize an effective data collection strategy for semantic manipulation, which can achieve 85\\% success rates across four tasks on both seen and unseen objects. All datasets and code will be released to the community.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11885v1",
        "authors": [
          "Yihao Wu",
          "Jinming Ma",
          "Junbo Tan",
          "Yanzhao Yu",
          "Shoujie Li"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Box Guided Policies Diffusion",
        "Revealing Data Scaling Laws",
        "Manipulate Anything",
        "Framework",
        "Policy",
        "Fusion",
        "Robot",
        "MIT",
        "UMI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.195630"
    },
    {
      "id": "arxiv-2602.11882v1",
      "title": "Where Bits Matter in World Model Planning: A Paired Mixed-Bit Study for Efficient Spatial Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11882v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient spatial reasoning requires world models that remain reliable under tight precision budgets. We study whether low-bit planning behavior is determined mostly by total bitwidth or by where bits are allocated across modules. Using DINO-WM on the Wall planning task, we run a paired-goal mixed-bit evaluation across uniform, mixed, asymmetric, and layerwise variants under two planner budgets. We observe a consistent three-regime pattern: 8-bit and 6-bit settings remain close to FP16, 3-bit settings collapse, and 4-bit settings are allocation-sensitive. In that transition region, preserving encoder precision improves planning relative to uniform quantization, and near-size asymmetric variants show the same encoder-side direction. In a later strict 22-cell replication with smaller per-cell episode count, the mixed-versus-uniform INT4 sign becomes budget-conditioned, which further highlights the sensitivity of this transition regime. These findings motivate module-aware, budget-aware quantization policies as a broader research direction for efficient spatial reasoning. Code and run artifacts are available at https://github.com/suraj-ranganath/DINO-MBQuant.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11882v1",
        "authors": [
          "Suraj Ranganath",
          "Anish Patnaik",
          "Vaishak Menon"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Spatial Reasoning Efficient",
        "World Model Planning",
        "Where Bits Matter",
        "Paired Mixed",
        "Bit Study",
        "DINO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.195834"
    },
    {
      "id": "arxiv-2602.11875v1",
      "title": "DiffPlace: Street View Generation via Place-Controllable Diffusion Model Enhancing Place Recognition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11875v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Generative models have advanced significantly in realistic image synthesis, with diffusion models excelling in quality and stability. Recent multi-view diffusion models improve 3D-aware street view generation, but they struggle to produce place-aware and background-consistent urban scenes from text, BEV maps, and object bounding boxes. This limits their effectiveness in generating realistic samples for place recognition tasks. To address these challenges, we propose DiffPlace, a novel framework that introduces a place-ID controller to enable place-controllable multi-view image generation. The place-ID controller employs linear projection, perceiver transformer, and contrastive learning to map place-ID embeddings into a fixed CLIP space, allowing the model to synthesize images with consistent background buildings while flexibly modifying foreground objects and weather conditions. Extensive experiments, including quantitative comparisons and augmented training evaluations, demonstrate that DiffPlace outperforms existing methods in both generation quality and training support for visual place recognition. Our results highlight the potential of generative models in enhancing scene-level and place-aware synthesis, providing a valuable approach for improving place recognition in autonomous driving",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11875v1",
        "authors": [
          "Ji Li",
          "Zhiwei Li",
          "Shihao Li",
          "Zhenjiang Yu",
          "Boyang Wang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Controllable Diffusion Model Enhancing",
        "Place Recognition Generative",
        "Street View Generation",
        "Transformer",
        "Framework",
        "Fusion",
        "CLIP",
        "NSF",
        "MIT",
        "BEV",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.196053"
    },
    {
      "id": "arxiv-2602.11862v1",
      "title": "LAMP: Implicit Language Map for Robot Navigation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11862v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent advances in vision-language models have made zero-shot navigation feasible, enabling robots to follow natural language instructions without requiring labeling. However, existing methods that explicitly store language vectors in grid or node-based maps struggle to scale to large environments due to excessive memory requirements and limited resolution for fine-grained planning. We introduce LAMP (Language Map), a novel neural language field-based navigation framework that learns a continuous, language-driven map and directly leverages it for fine-grained path generation. Unlike prior approaches, our method encodes language features as an implicit neural field rather than storing them explicitly at every location. By combining this implicit representation with a sparse graph, LAMP supports efficient coarse path planning and then performs gradient-based optimization in the learned field to refine poses near the goal. This coarse-to-fine pipeline, language-driven, gradient-guided optimization is the first application of an implicit language map for precise path generation. This refinement is particularly effective at selecting goal regions not directly observed by leveraging semantic similarities in the learned feature space. To further enhance robustness, we adopt a Bayesian framework that models embedding uncertainty via the von Mises-Fisher distribution, thereby improving generalization to unobserved regions. To scale to large environments, LAMP employs a graph sampling strategy that prioritizes spatial coverage and embedding confidence, retaining only the most informative nodes and substantially reducing computational overhead. Our experimental results, both in NVIDIA Isaac Sim and on a real multi-floor building, demonstrate that LAMP outperforms existing explicit methods in both memory efficiency and fine-grained goal-reaching accuracy.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11862v1",
        "authors": [
          "Sibaek Lee",
          "Hyeonwoo Yu",
          "Giseop Kim",
          "Sunwook Choi"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robot Navigation Recent",
        "Implicit Language Map",
        "Language Map",
        "Isaac Sim",
        "Framework",
        "NVIDIA",
        "Robot",
        "LAMP",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.196338"
    },
    {
      "id": "arxiv-2602.11832v1",
      "title": "JEPA-VLA: Video Predictive Embedding is Needed for VLA Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11832v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent vision-language-action (VLA) models built upon pretrained vision-language models (VLMs) have achieved significant improvements in robotic manipulation. However, current VLAs still suffer from low sample efficiency and limited generalization. This paper argues that these limitations are closely tied to an overlooked component, pretrained visual representation, which offers insufficient knowledge on both aspects of environment understanding and policy prior. Through an in-depth analysis, we find that commonly used visual representations in VLAs, whether pretrained via language-image contrastive learning or image-based self-supervised learning, remain inadequate at capturing crucial, task-relevant environment information and at inducing effective policy priors, i.e., anticipatory knowledge of how the environment evolves under successful task execution. In contrast, we discover that predictive embeddings pretrained on videos, in particular V-JEPA 2, are adept at flexibly discarding unpredictable environment factors and encoding task-relevant temporal dynamics, thereby effectively compensating for key shortcomings of existing visual representations in VLAs. Building on these observations, we introduce JEPA-VLA, a simple yet effective approach that adaptively integrates predictive embeddings into existing VLAs. Our experiments demonstrate that JEPA-VLA yields substantial performance gains across a range of benchmarks, including LIBERO, LIBERO-plus, RoboTwin2.0, and real-robot tasks.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11832v1",
        "authors": [
          "Shangchen Miao",
          "Ningya Feng",
          "Jialong Wu",
          "Ye Lin",
          "Xu He"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Video Predictive Embedding",
        "Models Recent",
        "Policy",
        "LIBERO",
        "Robot",
        "JEPA",
        "Act",
        "EPA",
        "MIT",
        "VLA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.196577"
    },
    {
      "id": "arxiv-2602.11798v1",
      "title": "Real-World Asset Integration in Next-Generation Communication Networks: Fundamental, Framework, and Case Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11798v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Next-generation communication networks are characterized by integrated ultra-high reliability, ultra-low latency, massive connectivity, and ubiquitous coverage. However, this paradigm faces significant structural challenges of liquidity and security. Liquidity issues arise from prohibitive upfront costs of network resources, which strain the limited capital and financial flexibility. This also limits the deployment of the resource- and investment-intensive security solutions, bringing security issues. Security vulnerabilities arise from the decentralized architecture as well, particularly threats posed by Byzantine nodes. To address these dual challenges, we propose a novel framework utilizing Real-World Asset (RWA) tokenization for tokenizing network resources. RWA tokenization uses blockchain to convert ownership rights of real-world assets into digital tokens that can be programmed, divided, and traded. We then analyze the criteria for identifying suitable assets. Through a case study on dynamic spectrum allocation, we demonstrate the superior performance of this RWA approach. Particularly under conditions of resource scarcity, it can exhibit strong resilience against collusion and default attacks. Finally, we delineate fruitful avenues for future research in this nascent field.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11798v1",
        "authors": [
          "Tingxuan Su",
          "Haoxiang Luo",
          "Ruichen Zhang",
          "Yinqiu Liu",
          "Gang Sun"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generation Communication Networks",
        "World Asset Integration",
        "Case Study Next",
        "World Asset",
        "Blockchain",
        "Framework",
        "Act",
        "MIT",
        "RWA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.196799"
    },
    {
      "id": "arxiv-2602.11776v1",
      "title": "MUSE: Multi-Tenant Model Serving With Seamless Model Updates",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11776v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In binary classification systems, decision thresholds translate model scores into actions. Choosing suitable thresholds relies on the specific distribution of the underlying model scores but also on the specific business decisions of each client using that model. However, retraining models inevitably shifts score distributions, invalidating existing thresholds. In multi-tenant Score-as-a-Service environments, where decision boundaries reside in client-managed infrastructure, this creates a severe bottleneck: recalibration requires coordinating threshold updates across hundreds of clients, consuming excessive human hours and leading to model stagnation. We introduce MUSE, a model serving framework that enables seamless model updates by decoupling model scores from client decision boundaries. Designed for multi-tenancy, MUSE optimizes infrastructure re-use by sharing models via dynamic intent-based routing, combined with a two-level score transformation that maps model outputs to a stable, reference distribution. Deployed at scale by Feedzai, MUSE processes over a thousand events per second, and over 55 billion events in the last 12 months, across several dozens of tenants, while maintaining high-availability and low-latency guarantees. By reducing model lead time from weeks to minutes, MUSE promotes model resilience against shifting attacks, saving millions of dollars in fraud losses and operational costs.",
        "keywords": [
          "cs.LG",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11776v1",
        "authors": [
          "Cláudio Correia",
          "Alberto E. A. Ferreira",
          "Lucas Martins",
          "Miguel P. Bento",
          "Sofia Guerreiro"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Seamless Model Updates In",
        "Tenant Model Serving With",
        "Framework",
        "MUSE",
        "Bill",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.197051"
    },
    {
      "id": "arxiv-2602.11764v1",
      "title": "Reliable and Private Anonymous Routing for Satellite Constellations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11764v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Shared, dynamic network infrastructures, such as dual-use LEO satellite constellations, pose critical threats to metadata privacy, particularly for state actors operating in mixed-trust environments. This work proposes an enhanced anonymity architecture, evolving the Loopix mix-network, to provide robust security and reliability in these volatile topologies. We introduce three primary contributions: (1) A multi-path transport protocol utilizing $(n, k)$ erasure codes, which is demonstrated to counteract the high link volatility and intermittent connectivity that renders standard mix-networks unreliable. (2) The integration of a computationally efficient Private Information Retrieval (PIR) protocol during route discovery. (3) The introduction of adaptive, centrality-based delay strategies that efficiently mitigate the inherent topological bias of LEO networks, providing a superior anonymity-to-latency trade-off. This mechanism provably prevents metadata leakage at the user-provider directory, mitigating profiling and correlation attacks. We validate this architecture via high-fidelity, packet-level simulations of a LEO constellation. Empirical results show our multi-path transport achieves near-zero message loss, establishing a quantifiable trade-off between reliability and bandwidth overhead. Furthermore, microbenchmarks of the PIR protocol quantify its computational and latency overheads, confirming its feasibility for practical deployment. This work provides a validated blueprint for deployable high-anonymity communication systems, demonstrating the viability of securely multiplexing sensitive operations within large-scale commercial network infrastructures.",
        "keywords": [
          "cs.CR",
          "cs.ET",
          "cs.IR",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11764v1",
        "authors": [
          "Nilesh Vyas",
          "Fabien Geyer",
          "Svetoslav Duhovnikov"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.ET",
          "cs.IR",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite Constellations Shared",
        "Private Information Retrieval",
        "Private Anonymous Routing",
        "Satellite",
        "Standard",
        "Protocol",
        "Meta",
        "Act",
        "PIR",
        "MIT",
        "LEO",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.197316"
    },
    {
      "id": "arxiv-2602.11758v1",
      "title": "HAIC: Humanoid Agile Object Interaction Control via Dynamics-Aware World Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11758v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Humanoid robots show promise for complex whole-body tasks in unstructured environments. Although Human-Object Interaction (HOI) has advanced, most methods focus on fully actuated objects rigidly coupled to the robot, ignoring underactuated objects with independent dynamics and non-holonomic constraints. These introduce control challenges from coupling forces and occlusions. We present HAIC, a unified framework for robust interaction across diverse object dynamics without external state estimation. Our key contribution is a dynamics predictor that estimates high-order object states (velocity, acceleration) solely from proprioceptive history. These predictions are projected onto static geometric priors to form a spatially grounded dynamic occupancy map, enabling the policy to infer collision boundaries and contact affordances in blind spots. We use asymmetric fine-tuning, where a world model continuously adapts to the student policy's exploration, ensuring robust state estimation under distribution shifts. Experiments on a humanoid robot show HAIC achieves high success rates in agile tasks (skateboarding, cart pushing/pulling under various loads) by proactively compensating for inertial perturbations, and also masters multi-object long-horizon tasks like carrying a box across varied terrain by predicting the dynamics of multiple objects.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11758v1",
        "authors": [
          "Dongting Li",
          "Xingyu Chen",
          "Qianyang Wu",
          "Bo Chen",
          "Sikai Wu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Humanoid Agile Object Interaction",
        "Aware World Model Humanoid",
        "Object Interaction",
        "Although Human",
        "Framework",
        "Policy",
        "Robot",
        "HAIC",
        "Act",
        "WHO",
        "HOI",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.197545"
    },
    {
      "id": "arxiv-2602.11741v1",
      "title": "Designing Scalable Rate Limiting Systems: Algorithms, Architecture, and Distributed Solutions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11741v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Designing a rate limiter that is simultaneously accurate, available, and scalable presents a fundamental challenge in distributed systems, primarily due to the trade-offs between algorithmic precision, availability, consistency, and partition tolerance. This article presents a concrete architecture for a distributed rate limiting system in a production-grade environment. Our design chooses the in-memory cache database, the Redis, along with its Sorted Set data structure, which provides $O(log (N))$ time complexity operation for the key-value pair dataset with efficiency and low latency, and maintains precision. The core contribution is quantifying the accuracy and memory cost trade-off of the chosen Rolling Window as the implemented rate limiting algorithm against the Token Bucket and Fixed Window algorithms. In addition, we explain how server-side Lua scripting is critical to bundling cleanup, counting, and insertion into a single atomic operation, thereby eliminating race conditions in concurrent environments. In the system architecture, we propose a three-layer architecture that manages the storage and updating of the limit rules. Through script load by hashing the rule parameters, rules can be changed without modifying the cached scripts. Furthermore, we analyze the deployment of this architecture on a Redis Cluster, which provides the availability and scalability by data sharding and replication. We explain the acceptance of AP (Availability and Partition Tolerance) from the CAP theorem as the pragmatic engineering trade-off for this use case.",
        "keywords": [
          "cs.DC",
          "cs.DB",
          "cs.PF",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11741v1",
        "authors": [
          "Bo Guan"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.DB",
          "cs.PF",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Designing Scalable Rate Limiting",
        "Distributed Solutions Designing",
        "Partition Tolerance",
        "Rolling Window",
        "Redis Cluster",
        "Fixed Window",
        "Token Bucket",
        "Sorted Set",
        "Wind",
        "MIT",
        "CAP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.197803"
    },
    {
      "id": "arxiv-2602.11740v1",
      "title": "Counterfactual Conditional Likelihood Rewards for Multiagent Exploration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11740v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient exploration is critical for multiagent systems to discover coordinated strategies, particularly in open-ended domains such as search and rescue or planetary surveying. However, when exploration is encouraged only at the individual agent level, it often leads to redundancy, as agents act without awareness of how their teammates are exploring. In this work, we introduce Counterfactual Conditional Likelihood (CCL) rewards, which score each agent's exploration by isolating its unique contribution to team exploration. Unlike prior methods that reward agents solely for the novelty of their individual observations, CCL emphasizes observations that are informative with respect to the joint exploration of the team. Experiments in continuous multiagent domains show that CCL rewards accelerate learning for domains with sparse team rewards, where most joint actions yield zero rewards, and are particularly effective in tasks that require tight coordination among agents.",
        "keywords": [
          "cs.MA",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11740v1",
        "authors": [
          "Ayhan Alp Aydeniz",
          "Robert Loftin",
          "Kagan Tumer"
        ],
        "arxiv_categories": [
          "cs.MA",
          "cs.RO"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Counterfactual Conditional Likelihood Rewards",
        "Counterfactual Conditional Likelihood",
        "Multiagent Exploration Efficient",
        "Act",
        "CCL",
        "AI",
        "UN"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-15T13:53:11.197977"
    },
    {
      "id": "arxiv-2602.11735v1",
      "title": "AC-MASAC: An Attentive Curriculum Learning Framework for Heterogeneous UAV Swarm Coordination",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11735v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Cooperative path planning for heterogeneous UAV swarms poses significant challenges for Multi-Agent Reinforcement Learning (MARL), particularly in handling asymmetric inter-agent dependencies and addressing the risks of sparse rewards and catastrophic forgetting during training. To address these issues, this paper proposes an attentive curriculum learning framework (AC-MASAC). The framework introduces a role-aware heterogeneous attention mechanism to explicitly model asymmetric dependencies. Moreover, a structured curriculum strategy is designed, integrating hierarchical knowledge transfer and stage-proportional experience replay to address the issues of sparse rewards and catastrophic forgetting. The proposed framework is validated on a custom multi-agent simulation platform, and the results show that our method has significant advantages over other advanced methods in terms of Success Rate, Formation Keeping Rate, and Success-weighted Mission Time. The code is available at \\textcolor{red}{https://github.com/Wanhao-Liu/AC-MASAC}.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11735v1",
        "authors": [
          "Wanhao Liu",
          "Junhong Dai",
          "Yixuan Zhang",
          "Shengyun Yin",
          "Panshuo Li"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "An Attentive Curriculum Learning",
        "Swarm Coordination Cooperative",
        "Agent Reinforcement Learning",
        "Formation Keeping Rate",
        "Success Rate",
        "Mission Time",
        "Framework",
        "MASAC",
        "MARL",
        "NSF",
        "UAV",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.198171"
    },
    {
      "id": "arxiv-2602.11714v1",
      "title": "GSO-SLAM: Bidirectionally Coupled Gaussian Splatting and Direct Visual Odometry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11714v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose GSO-SLAM, a real-time monocular dense SLAM system that leverages Gaussian scene representation. Unlike existing methods that couple tracking and mapping with a unified scene, incurring computational costs, or loosely integrate them with well-structured tracking frameworks, introducing redundancies, our method bidirectionally couples Visual Odometry (VO) and Gaussian Splatting (GS). Specifically, our approach formulates joint optimization within an Expectation-Maximization (EM) framework, enabling the simultaneous refinement of VO-derived semi-dense depth estimates and the GS representation without additional computational overhead. Moreover, we present Gaussian Splat Initialization, which utilizes image information, keyframe poses, and pixel associations from VO to produce close approximations to the final Gaussian scene, thereby eliminating the need for heuristic methods. Through extensive experiments, we validate the effectiveness of our method, showing that it not only operates in real time but also achieves state-of-the-art geometric/photometric fidelity of the reconstructed scene and tracking accuracy.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11714v1",
        "authors": [
          "Jiung Yeon",
          "Seongbo Ha",
          "Hyeonwoo Yu"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bidirectionally Coupled Gaussian Splatting",
        "Gaussian Splat Initialization",
        "Direct Visual Odometry We",
        "Gaussian Splatting",
        "Visual Odometry",
        "Framework",
        "SLAM",
        "GSO",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.198371"
    },
    {
      "id": "arxiv-2602.11710v1",
      "title": "Mapping the Landscape of Affective Extended Reality: A Scoping Review of Biodata-Driven Systems for Understanding and Sharing Emotions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11710v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper introduces the notion of affective extended reality (XR) to characterise XR systems that use biodata to enable understanding of emotions. The HCI literature contains many such systems, but they have not yet been mapped into a coherent whole. To address this, we conducted a scoping review of 82 papers that explore the nexus of biodata, emotions, and XR. We analyse the technologies used in these systems, the interaction techniques employed, and the methods used to evaluate their effectiveness. Through our analysis, we contribute a mapping of the current landscape of affective XR, revealing diversity in the goals for enabling emotion sharing. We demonstrate how HCI researchers have explored the design of the interaction flows in XR biofeedback systems, highlighting key design dimensions and challenges in understanding emotions. We discuss underused approaches for emotion sharing and highlight opportunities for future research on affective XR.",
        "keywords": [
          "cs.HC",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11710v1",
        "authors": [
          "Zhidian Lin",
          "Allison Jing",
          "Ziyuan Qu",
          "Fabio Zambetta",
          "Ryan M. Kelly"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.ET"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Affective Extended Reality",
        "Scoping Review",
        "Driven Systems",
        "Act",
        "WHO",
        "HCI",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:11.198558"
    },
    {
      "id": "arxiv-2602.11706v1",
      "title": "LLM-Driven 3D Scene Generation of Agricultural Simulation Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11706v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Procedural generation techniques in 3D rendering engines have revolutionized the creation of complex environments, reducing reliance on manual design. Recent approaches using Large Language Models (LLMs) for 3D scene generation show promise but often lack domain-specific reasoning, verification mechanisms, and modular design. These limitations lead to reduced control and poor scalability. This paper investigates the use of LLMs to generate agricultural synthetic simulation environments from natural language prompts, specifically to address the limitations of lacking domain-specific reasoning, verification mechanisms, and modular design. A modular multi-LLM pipeline was developed, integrating 3D asset retrieval, domain knowledge injection, and code generation for the Unreal rendering engine using its API. This results in a 3D environment with realistic planting layouts and environmental context, all based on the input prompt and the domain knowledge. To enhance accuracy and scalability, the system employs a hybrid strategy combining LLM optimization techniques such as few-shot prompting, Retrieval-Augmented Generation (RAG), finetuning, and validation. Unlike monolithic models, the modular architecture enables structured data handling, intermediate verification, and flexible expansion. The system was evaluated using structured prompts and semantic accuracy metrics. A user study assessed realism and familiarity against real-world images, while an expert comparison demonstrated significant time savings over manual scene design. The results confirm the effectiveness of multi-LLM pipelines in automating domain-specific 3D scene generation with improved reliability and precision. Future work will explore expanding the asset hierarchy, incorporating real-time generation, and adapting the pipeline to other simulation domains beyond agriculture.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11706v1",
        "authors": [
          "Arafa Yoncalik",
          "Wouter Jansen",
          "Nico Huebel",
          "Mohammad Hasan Rahmani",
          "Jan Steckel"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agricultural Simulation Environments Procedural",
        "Large Language Models",
        "Augmented Generation",
        "Scene Generation",
        "API",
        "RAG",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.198852"
    },
    {
      "id": "arxiv-2602.11688v1",
      "title": "GORGO: Maximizing KV-Cache Reuse While Minimizing Network Latency in Cross-Region LLM Load Balancing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11688v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Distributing LLM inference across geographical regions can improve Time-to-First-Token (TTFT) by regionalizing service deployments. While existing multi-region load balancers save prefill computation by prioritizing Key--Value (KV) Cache hit rate, they ignore cluster networking latency, a critical factor in routing decisions. We introduce GORGO, a method for minimizing TTFT by optimizing a total serving cost as a function of available compute, network latency, and prefix caching. Using extensive profiling on custom infrastructure, we analyze component-level latency bottlenecks and benchmark GORGO against three baselines: (1) naive least-load routing, which ignores prefix-cache overlap; (2) prefix-similarity routing, which selectively pushes requests to the replica with the highest cached-prefix overlap; and (3) a centralized HTTP proxy that runs the GORGO policy while tracking requests across all nodes. We demonstrate that GORGO reduces P99 TTFT through network-aware routing and improves average TTFT by preventing pathological cross-region forwarding. Additionally, we find that GORGO-proxy overcomes synchronization overhead in previous methods and is 2.5x faster on median TTFT, demonstrating the success of a centralized router.",
        "keywords": [
          "cs.NI",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11688v1",
        "authors": [
          "Alessio Ricci Toniolo",
          "Abinaya Dinesh",
          "Rome Thorstenson"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cache Reuse While Minimizing",
        "Load Balancing Distributing",
        "Network Latency",
        "Policy",
        "GORGO",
        "HTTP",
        "TTFT",
        "Act",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.199064"
    },
    {
      "id": "arxiv-2602.11686v1",
      "title": "LAER-MoE: Load-Adaptive Expert Re-layout for Efficient Mixture-of-Experts Training",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11686v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Expert parallelism is vital for effectively training Mixture-of-Experts (MoE) models, enabling different devices to host distinct experts, with each device processing different input data. However, during expert parallel training, dynamic routing results in significant load imbalance among experts: a handful of overloaded experts hinder overall iteration, emerging as a training bottleneck. In this paper, we introduce LAER-MoE, an efficient MoE training framework. The core of LAER-MoE is a novel parallel paradigm, Fully Sharded Expert Parallel (FSEP), which fully partitions each expert parameter by the number of devices and restores partial experts at expert granularity through All-to-All communication during training. This allows for flexible re-layout of expert parameters during training to enhance load balancing. In particular, we perform fine-grained scheduling of communication operations to minimize communication overhead. Additionally, we develop a load balancing planner to formulate re-layout strategies of experts and routing schemes for tokens during training. We perform experiments on an A100 cluster, and the results indicate that our system achieves up to 1.69x acceleration compared to the current state-of-the-art training systems. Source code available at https://github.com/PKU-DAIR/Hetu-Galvatron/tree/laer-moe.",
        "keywords": [
          "cs.DC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11686v1",
        "authors": [
          "Xinyi Liu",
          "Yujie Wang",
          "Fangcheng Fu",
          "Xuefeng Xiao",
          "Huixia Li"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fully Sharded Expert Parallel",
        "Experts Training Expert",
        "Adaptive Expert Re",
        "Efficient Mixture",
        "Framework",
        "FSEP",
        "LAER",
        "DAIR",
        "PKU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.199285"
    },
    {
      "id": "arxiv-2602.11660v1",
      "title": "Clutt3R-Seg: Sparse-view 3D Instance Segmentation for Language-grounded Grasping in Cluttered Scenes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11660v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Reliable 3D instance segmentation is fundamental to language-grounded robotic manipulation. Its critical application lies in cluttered environments, where occlusions, limited viewpoints, and noisy masks degrade perception. To address these challenges, we present Clutt3R-Seg, a zero-shot pipeline for robust 3D instance segmentation for language-grounded grasping in cluttered scenes. Our key idea is to introduce a hierarchical instance tree of semantic cues. Unlike prior approaches that attempt to refine noisy masks, our method leverages them as informative cues: through cross-view grouping and conditional substitution, the tree suppresses over- and under-segmentation, yielding view-consistent masks and robust 3D instances. Each instance is enriched with open-vocabulary semantic embeddings, enabling accurate target selection from natural language instructions. To handle scene changes during multi-stage tasks, we further introduce a consistency-aware update that preserves instance correspondences from only a single post-interaction image, allowing efficient adaptation without rescanning. Clutt3R-Seg is evaluated on both synthetic and real-world datasets, and validated on a real robot. Across all settings, it consistently outperforms state-of-the-art baselines in cluttered and sparse-view scenarios. Even on the most challenging heavy-clutter sequences, Clutt3R-Seg achieves an AP@25 of 61.66, over 2.2x higher than baselines, and with only four input views it surpasses MaskClustering with eight views by more than 2x. The code is available at: https://github.com/jeonghonoh/clutt3r-seg.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11660v1",
        "authors": [
          "Jeongho Noh",
          "Tai Hyoung Rhee",
          "Eunho Lee",
          "Jeongyun Kim",
          "Sunwoo Lee"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cluttered Scenes Reliable",
        "Instance Segmentation",
        "Robot",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.199535"
    },
    {
      "id": "arxiv-2602.11656v1",
      "title": "SToRM: Supervised Token Reduction for Multi-modal LLMs toward efficient end-to-end autonomous driving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11656v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In autonomous driving, end-to-end (E2E) driving systems that predict control commands directly from sensor data have achieved significant advancements. For safe driving in unexpected scenarios, these systems may additionally rely on human interventions such as natural language instructions. Using a multi-modal large language model (MLLM) facilitates human-vehicle interaction and can improve performance in such scenarios. However, this approach requires substantial computational resources due to its reliance on an LLM and numerous visual tokens from sensor inputs, which are limited in autonomous vehicles. Many MLLM studies have explored reducing visual tokens, but often suffer end-task performance degradation compared to using all tokens. To enable efficient E2E driving while maintaining performance comparable to using all tokens, this paper proposes the first Supervised Token Reduction framework for multi-modal LLMs (SToRM). The proposed framework consists of three key elements. First, a lightweight importance predictor with short-term sliding windows estimates token importance scores. Second, a supervised training approach uses an auxiliary path to obtain pseudo-supervision signals from an all-token LLM pass. Third, an anchor-context merging module partitions tokens into anchors and context tokens, and merges context tokens into relevant anchors to reduce redundancy while minimizing information loss. Experiments on the LangAuto benchmark show that SToRM outperforms state-of-the-art E2E driving MLLMs under the same reduced-token budget, maintaining all-token performance while reducing computational cost by up to 30x.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11656v1",
        "authors": [
          "Seo Hyun Kim",
          "Jin Bok Park",
          "Do Yeon Koo",
          "Ho Gun Park",
          "Il Yong Chun"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Supervised Token Reduction",
        "Autonomous Vehicle",
        "Framework",
        "Wind",
        "MLLM",
        "Act",
        "MIT",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.199785"
    },
    {
      "id": "arxiv-2602.11655v1",
      "title": "LoRA-based Parameter-Efficient LLMs for Continuous Learning in Edge-based Malware Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11655v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The proliferation of edge devices has created an urgent need for security solutions capable of detecting malware in real time while operating under strict computational and memory constraints. Recently, Large Language Models (LLMs) have demonstrated remarkable capabilities in recognizing complex patterns, yet their deployment on edge devices remains impractical due to their resource demands. However, in edge malware detection, static or centrally retrained models degrade under evolving threats and heterogeneous traffic; locally trained models become siloed and fail to transfer across domains. To overcome these limitations, in this paper, we present a continuous learning architecture for edge-based malware detection that combines local adaptation on each device with global knowledge sharing through parameter-efficient LoRA adapters. Lightweight transformer models (DistilBERT, DistilGPT-2, TinyT5) run on edge nodes and are incrementally fine-tuned on device-specific traffic; only the resulting LoRA modules are aggregated by a lightweight coordinator and redistributed, enabling cross-device generalization without exchanging raw data. We evaluate on two public IoT security datasets, Edge-IIoTset and TON-IoT, under multi-round learning to simulate evolving threats. Compared to isolated fine-tuning, the LoRA-based exchange yields up to 20-25% accuracy gains when models encounter previously unseen attacks from another domain, while maintaining stable loss and F1 across rounds. LoRA adds less than 1% to model size (~0.6-1.8 MB), making updates practical for constrained edge hardware.",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11655v1",
        "authors": [
          "Christian Rondanini",
          "Barbara Carminati",
          "Elena Ferrari",
          "Niccolò Lardo",
          "Ashish Kundu"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models",
        "Continuous Learning",
        "DistilGPT-2",
        "Transformer",
        "BERT",
        "Act",
        "NSF",
        "MIT",
        "IoT",
        "TON",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.200031"
    },
    {
      "id": "arxiv-2602.11648v1",
      "title": "Human-Like Gaze Behavior in Social Robots: A Deep Learning Approach Integrating Human and Non-Human Stimuli",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11648v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Nonverbal behaviors, particularly gaze direction, play a crucial role in enhancing effective communication in social interactions. As social robots increasingly participate in these interactions, they must adapt their gaze based on human activities and remain receptive to all cues, whether human-generated or not, to ensure seamless and effective communication. This study aims to increase the similarity between robot and human gaze behavior across various social situations, including both human and non-human stimuli (e.g., conversations, pointing, door openings, and object drops). A key innovation in this study, is the investigation of gaze responses to non-human stimuli, a critical yet underexplored area in prior research. These scenarios, were simulated in the Unity software as a 3D animation and a 360-degree real-world video. Data on gaze directions from 41 participants were collected via virtual reality (VR) glasses. Preprocessed data, trained two neural networks-LSTM and Transformer-to build predictive models based on individuals' gaze patterns. In the animated scenario, the LSTM and Transformer models achieved prediction accuracies of 67.6% and 70.4%, respectively; In the real-world scenario, the LSTM and Transformer models achieved accuracies of 72% and 71.6%, respectively. Despite the gaze pattern differences among individuals, our models outperform existing approaches in accuracy while uniquely considering non-human stimuli, offering a significant advantage over previous literature. Furthermore, deployed on the NAO robot, the system was evaluated by 275 participants via a comprehensive questionnaire, with results demonstrating high satisfaction during interactions. This work advances social robotics by enabling robots to dynamically mimic human gaze behavior in complex social contexts.",
        "keywords": [
          "cs.RO",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11648v1",
        "authors": [
          "Faezeh Vahedi",
          "Morteza Memari",
          "Ramtin Tabatabaei",
          "Alireza Taheri"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deep Learning Approach Integrating",
        "Human Stimuli Nonverbal",
        "Like Gaze Behavior",
        "Neural Network",
        "Social Robots",
        "Deep Learning",
        "Transformer",
        "Robot",
        "LSTM",
        "Act",
        "NSF",
        "NAO",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.200311"
    },
    {
      "id": "arxiv-2602.11643v1",
      "title": "ViTaS: Visual Tactile Soft Fusion Contrastive Learning for Visuomotor Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11643v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Tactile information plays a crucial role in human manipulation tasks and has recently garnered increasing attention in robotic manipulation. However, existing approaches mostly focus on the alignment of visual and tactile features and the integration mechanism tends to be direct concatenation. Consequently, they struggle to effectively cope with occluded scenarios due to neglecting the inherent complementary nature of both modalities and the alignment may not be exploited enough, limiting the potential of their real-world deployment. In this paper, we present ViTaS, a simple yet effective framework that incorporates both visual and tactile information to guide the behavior of an agent. We introduce Soft Fusion Contrastive Learning, an advanced version of conventional contrastive learning method and a CVAE module to utilize the alignment and complementarity within visuo-tactile representations. We demonstrate the effectiveness of our method in 12 simulated and 3 real-world environments, and our experiments show that ViTaS significantly outperforms existing baselines. Project page: https://skyrainwind.github.io/ViTaS/index.html.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11643v1",
        "authors": [
          "Yufeng Tian",
          "Shuiqi Cheng",
          "Tianming Wei",
          "Tianxing Zhou",
          "Yuanhang Zhang"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Soft Fusion Contrastive Learning",
        "Visuomotor Learning Tactile",
        "Visual Tactile Soft Fusion",
        "Contrastive Learning",
        "Framework",
        "Fusion",
        "Robot",
        "Wind",
        "CVAE",
        "Act",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.200503"
    },
    {
      "id": "arxiv-2602.11632v1",
      "title": "CL API: Real-Time Closed-Loop Interactions with Biological Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11632v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Biological neural networks (BNNs) are increasingly explored for their rich dynamics, parallelism, and adaptive behavior. Beyond understanding their function as a scientific endeavour, a key focus has been using these biological systems as a novel computing substrate. However, BNNs can only function as reliable information-processing systems if inputs are delivered in a temporally and structurally consistent manner. In practice, this requires stimulation with precisely controlled structure, microsecond-scale timing, multi-channel synchronization, and the ability to observe and respond to neural activity in real-time. Existing approaches to interacting with BNNs face a fundamental trade-off: they either depend on low-level hardware mechanisms, imposing prohibitive complexity for rapid iteration, or they sacrifice temporal and structural control, undermining consistency and reproducibility - particularly in closed-loop experiments. The Cortical Labs Application Programming Interface (CL API) enables real-time, sub-millisecond closed-loop interactions with BNNs. Taking a contract-based API design approach, the CL API provides users with precise stimulation semantics, transactional admission, deterministic ordering, and explicit synchronization guarantees. This contract is presented through a declarative Python interface, enabling non-expert programmers to express complex stimulation and closed-loop behavior without managing low-level scheduling or hardware details. Ultimately, the CL API provides an accessible and reproducible foundation for real-time experimentation with BNNs, supporting both fundamental biological research and emerging neurocomputing applications.",
        "keywords": [
          "q-bio.NC",
          "cs.ET",
          "cs.NE",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11632v1",
        "authors": [
          "David Hogan",
          "Andrew Doherty",
          "Boon Kien Khoo",
          "Johnson Zhou",
          "Richard Salib"
        ],
        "arxiv_categories": [
          "q-bio.NC",
          "cs.ET",
          "cs.NE",
          "eess.SY"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Biological Neural Networks Biological",
        "Programming Interface",
        "Loop Interactions",
        "Neural Network",
        "Time Closed",
        "NIST",
        "Labs",
        "Act",
        "API",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-15T13:53:11.200762"
    },
    {
      "id": "arxiv-2602.11614v1",
      "title": "Device-Circuit Co-Design of Variation-Resilient Read and Write Drivers for Antiferromagnetic Tunnel Junction (AFMTJ) Memories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11614v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Antiferromagnetic Tunnel Junctions (AFMTJs) offer picosecond switching and high integration density for in-memory computing, but their ultrafast dynamics and low tunnel magnetoresistance (TMR) make state-of-the-art MRAM interfaces unreliable. This work develops a device-circuit co-designed read/write interface optimized for AFMTJ behavior. Using a calibrated SPICE AFMTJ model as a baseline, we identify the limitations of conventional drivers and propose an asymmetric pulse driver (PD) for deterministic picosecond switching and a self-timed sense amplifier (STSA) with dynamic trip-point tuning for low-TMR sensing. Our experiments using SPICE and Monte Carlo evaluations demonstrate that the proposed circuits preserve AFMTJ latency and energy benefits while achieving robust read/write yield under realistic PVT and 3D integration parasitics, outperforming standard MRAM front-ends under the same conditions.",
        "keywords": [
          "cs.AR",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11614v1",
        "authors": [
          "Yousuf Choudhary",
          "Tosiron Adegbija"
        ],
        "arxiv_categories": [
          "cs.AR",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Memories Antiferromagnetic Tunnel Junctions",
        "Antiferromagnetic Tunnel Junction",
        "Resilient Read",
        "Write Drivers",
        "Monte Carlo",
        "Circuit Co",
        "Standard",
        "AFMTJ",
        "SPICE",
        "NIST",
        "MRAM",
        "STSA",
        "MIT",
        "PVT",
        "TMR"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.200932"
    },
    {
      "id": "arxiv-2602.11598v1",
      "title": "ABot-N0: Technical Report on the VLA Foundation Model for Versatile Embodied Navigation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11598v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Embodied navigation has long been fragmented by task-specific architectures. We introduce ABot-N0, a unified Vision-Language-Action (VLA) foundation model that achieves a ``Grand Unification'' across 5 core tasks: Point-Goal, Object-Goal, Instruction-Following, POI-Goal, and Person-Following. ABot-N0 utilizes a hierarchical ``Brain-Action'' architecture, pairing an LLM-based Cognitive Brain for semantic reasoning with a Flow Matching-based Action Expert for precise, continuous trajectory generation. To support large-scale learning, we developed the ABot-N0 Data Engine, curating 16.9M expert trajectories and 5.0M reasoning samples across 7,802 high-fidelity 3D scenes (10.7 $\\text{km}^2$). ABot-N0 achieves new SOTA performance across 7 benchmarks, significantly outperforming specialized models. Furthermore, our Agentic Navigation System integrates a planner with hierarchical topological memory, enabling robust, long-horizon missions in dynamic real-world environments.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11598v1",
        "authors": [
          "Zedong Chu",
          "Shichao Xie",
          "Xiaolong Wu",
          "Yanfen Shen",
          "Minghua Luo"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Versatile Embodied Navigation Embodied",
        "Agentic Navigation System",
        "Grand Unification",
        "Technical Report",
        "Foundation Model",
        "Cognitive Brain",
        "Flow Matching",
        "Action Expert",
        "Data Engine",
        "SOTA",
        "Act",
        "POI",
        "VLA",
        "LLM",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.201152"
    },
    {
      "id": "arxiv-2602.11585v1",
      "title": "C-POD: An AWS Cloud Framework for Edge Pod Automation and Remote Wireless Testbed Sharing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11585v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents C-POD, a cloud-native framework that automates the deployment and management of edge pods for seamless remote access and sharing of wireless testbeds. C-POD leverages public cloud resources and edge pods to lower the barrier to over-the-air (OTA) experimentation, enabling researchers to share and access distributed testbeds without extensive local infrastructure. A supporting toolkit has been developed for C-POD to enable flexible and scalable experimental workflows, including containerized edge environments, persistent Secure Shell (SSH) tunnels, and stable graphical interfaces. We prototype and deploy C-POD on the Amazon Web Services (AWS) public cloud to demonstrate its key features, including cloud-assisted edge pod deployment automation, elastic computing resource management, and experiment observability, by integrating two wireless testbeds that focus on RF signal generation and 5G(B) communications, respectively.",
        "keywords": [
          "eess.SP",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11585v1",
        "authors": [
          "Annoy Dey",
          "Vineet Sreeram",
          "Gokkul Eraivan Arutkani Aiyanathan",
          "Maxwell McManus",
          "Yuqing Cui"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Remote Wireless Testbed Sharing",
        "Edge Pod Automation",
        "Amazon Web Services",
        "Cloud Framework",
        "Secure Shell",
        "Framework",
        "Amazon",
        "OTA",
        "AWS",
        "SSH",
        "POD",
        "5G",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.201326"
    },
    {
      "id": "arxiv-2602.11580v1",
      "title": "Benchmarking for Single Feature Attribution with Microarchitecture Cliffs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11580v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Architectural simulators play a critical role in early microarchitectural exploration due to their flexibility and high productivity. However, their effectiveness is often constrained by fidelity: simulators may deviate from the behavior of the final RTL, leading to unreliable performance estimates. Consequently, model calibration, which aligns simulator behavior with the RTL as the ground-truth microarchitecture, becomes essential for achieving accurate performance modeling. To facilitate model calibration accuracy, we propose Microarchitecture Cliffs, a benchmark generation methodology designed to expose mismatches in microarchitectural behavior between the simulator and RTL. After identifying the key architectural components that require calibration, the Cliff methodology enables precise attribution of microarchitectural differences to a single microarchitectural feature through a set of benchmarks. In addition, we develop a set of automated tools to improve the efficiency of the Cliff workflow. We apply the Cliff methodology to calibrate the XiangShan version of gem5 (XS-GEM5) against the XiangShan open-source CPU (XS-RTL). We reduce the performance error of XS-GEM5 from 59.2% to just 1.4% on the Cliff benchmarks. Meanwhile, the calibration guided by Cliffs effectively reduces the relative error of a representative tightly coupled microarchitectural feature by 48.03%. It also substantially lowers the absolute performance error, with reductions of 15.1% and 21.0% on SPECint2017 and SPECfp2017, respectively.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11580v1",
        "authors": [
          "Hao Zhen",
          "Qingxuan Kang",
          "Yungang Bao",
          "Trevor E. Carlson"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Microarchitecture Cliffs Architectural",
        "Single Feature Attribution",
        "Microarchitecture Cliffs",
        "CPU",
        "RTL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.201572"
    },
    {
      "id": "arxiv-2602.11575v1",
      "title": "ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11575v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simulation using 3D Gaussian Splatting (GS) can mitigate this gap, prior works have assumed only static scenes or unrealistic dynamic obstacles, despite the importance of safe navigation in dynamic environments. To address these issues, we propose ReaDy-Go, a novel real-to-sim simulation pipeline that synthesizes photorealistic dynamic scenarios for target environments. ReaDy-Go generates photorealistic navigation datasets for dynamic environments by combining a reconstructed static GS scene with dynamic human GS obstacles, and trains policies robust to both the sim-to-real gap and moving obstacles. The pipeline consists of three components: (1) a dynamic GS simulator that integrates scene GS with a human animation module, enabling the insertion of animatable human GS avatars and the synthesis of plausible human motions from 2D trajectories, (2) navigation dataset generation for dynamic environments that leverages the simulator, a robot expert planner designed for dynamic GS representations, and a human planner, and (3) policy learning using the generated datasets. ReaDy-Go outperforms baselines across target environments in both simulation and real-world experiments, demonstrating improved navigation performance even after sim-to-real transfer and in the presence of moving obstacles. Moreover, zero-shot sim-to-real deployment in an unseen environment indicates its generalization potential. Project page: https://syeon-yoo.github.io/ready-go-site/.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11575v1",
        "authors": [
          "Seungyeon Yoo",
          "Youngseok Jang",
          "Dabin Kim",
          "Youngsoo Han",
          "Seungwoo Jung"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Splatting Simulation",
        "Specific Visual Navigation",
        "Moving Obstacles Visual",
        "Gaussian Splatting",
        "Sim Dynamic",
        "Policy",
        "Robot",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.201844"
    },
    {
      "id": "arxiv-2602.11554v1",
      "title": "HyperDet: 3D Object Detection with Hyper 4D Radar Point Clouds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11554v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "4D mmWave radar provides weather-robust, velocity-aware measurements and is more cost-effective than LiDAR. However, radar-only 3D detection still trails LiDAR-based systems because radar point clouds are sparse, irregular, and often corrupted by multipath noise, yielding weak and unstable geometry. We present HyperDet, a detector-agnostic radar-only 3D detection framework that constructs a task-aware hyper 4D radar point cloud for standard LiDAR-oriented detectors. HyperDet aggregates returns from multiple surround-view 4D radars over consecutive frames to improve coverage and density, then applies geometry-aware cross-sensor consensus validation with a lightweight self-consistency check outside overlap regions to suppress inconsistent returns. It further integrates a foreground-focused diffusion module with training-time mixed radar-LiDAR supervision to densify object structures while lifting radar attributes (e.g., Doppler, RCS); the model is distilled into a consistency model for single-step inference. On MAN TruckScenes, HyperDet consistently improves over raw radar inputs with VoxelNeXt and CenterPoint, partially narrowing the radar-LiDAR gap. These results show that input-level refinement enables radar to better leverage LiDAR-oriented detectors without architectural modifications.",
        "keywords": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11554v1",
        "authors": [
          "Yichun Xiao",
          "Runwei Guan",
          "Fangqiang Ding"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Radar Point Clouds",
        "Object Detection",
        "Framework",
        "Standard",
        "Fusion",
        "MAN",
        "RCS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.202049"
    },
    {
      "id": "arxiv-2602.11544v1",
      "title": "Differentially Private Perturbed Push-Sum Protocol and Its Application in Non-Convex Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11544v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In decentralized networks, nodes cannot ensure that their shared information will be securely preserved by their neighbors, making privacy vulnerable to inference by curious nodes. Adding calibrated random noise before communication to satisfy differential privacy offers a proven defense; however, most existing methods are tailored to specific downstream tasks and lack a general, protocol-level privacy-preserving solution. To bridge this gap, we propose Differentially Private Perturbed Push-Sum (DPPS), a lightweight differential privacy protocol for decentralized communication. Since protocol-level differential privacy introduces the unique challenge of obtaining the sensitivity for each communication round, DPPS introduces a novel sensitivity estimation mechanism that requires each node to compute and broadcast only one scalar per round, enabling rigorous differential privacy guarantees. This design allows DPPS to serve as a plug-and-play, low-cost privacy-preserving solution for downstream applications built on it. To provide a concrete instantiation of DPPS and better balance the privacy-utility trade-off, we design PartPSP, a privacy-preserving decentralized algorithm for non-convex optimization that integrates a partial communication mechanism. By partitioning model parameters into local and shared components and applying DPPS only to the shared parameters, PartPSP reduces the dimensionality of consensus data, thereby lowering the magnitude of injected noise and improving optimization performance. We theoretically prove that PartPSP converges under non-convex objectives and, with partial communication, achieves better optimization performance under the same privacy budget. Experimental results validate the effectiveness of DPPS's privacy-preserving and demonstrate that PartPSP outperforms existing privacy-preserving decentralized optimization algorithms.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11544v1",
        "authors": [
          "Yiming Zhou",
          "Kaiping Xue",
          "Enhong Chen"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Differentially Private Perturbed Push",
        "Convex Optimization In",
        "Its Application",
        "Sum Protocol",
        "Protocol",
        "DPPS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.202328"
    },
    {
      "id": "arxiv-2602.11530v1",
      "title": "PASCAL: A Phase-Aware Scheduling Algorithm for Serving Reasoning-based Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11530v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The emergence of reasoning-based LLMs leveraging Chain-of-Thought (CoT) inference introduces new serving challenges, as their extended reasoning phases delay user-visible output and inflate Time-To-First-Token (TTFT). Existing LLM serving frameworks fail to distinguish between reasoning and answering phases, leading to performance degradation under GPU memory constraints. We present PASCAL, a phase-aware scheduling algorithm that prioritizes reasoning to reduce TTFT while using controlled preemption and token pacing during answering to preserve Quality-of-Experience (QoE). Our hierarchical scheduler combines instance-level placement with intra-instance execution and enables dynamic migration at phase boundaries to balance load and reduce interference. Across benchmarks using DeepSeek-R1-Distill-Qwen-32B, PASCAL reduces tail TTFT by up to 72% while maintaining answering phase SLO attainment, demonstrating the importance of phase-aware scheduling for reasoning-based LLM deployment.",
        "keywords": [
          "cs.LG",
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11530v1",
        "authors": [
          "Eunyeong Cho",
          "Jehyeon Bang",
          "Ranggi Hwang",
          "Minsoo Rhu"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Scheduling Algorithm",
        "Serving Reasoning",
        "Framework",
        "PASCAL",
        "TTFT",
        "GPU",
        "LLM",
        "SLO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:11.202500"
    },
    {
      "id": "arxiv-2602.12256v1",
      "title": "Automated Test Suite Enhancement Using Large Language Models with Few-shot Prompting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12256v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Unit testing is essential for verifying the functional correctness of code modules (e.g., classes, methods), but manually writing unit tests is often labor-intensive and time-consuming. Unit tests generated by tools that employ traditional approaches, such as search-based software testing (SBST), lack readability, naturalness, and practical usability. LLMs have recently provided promising results and become integral to developers' daily practices. Consequently, software repositories now include a mix of human-written tests, LLM-generated tests, and those from tools employing traditional approaches such as SBST. While LLMs' zero-shot capabilities have been widely studied, their few-shot learning potential for unit test generation remains underexplored. Few-shot prompting enables LLMs to learn from examples in the prompt, and automatically retrieving such examples could enhance test suites. This paper empirically investigates how few-shot prompting with different test artifact sources, comprising human, SBST, or LLM, affects the quality of LLM-generated unit tests as program comprehension artifacts and their contribution to improving existing test suites by evaluating not only correctness and coverage but also readability, cognitive complexity, and maintainability in hybrid human-AI codebases. We conducted experiments on HumanEval and ClassEval datasets using GPT-4o, which is integrated into GitHub Copilot and widely used among developers. We also assessed retrieval-based methods for selecting relevant examples. Our results show that LLMs can generate high-quality tests via few-shot prompting, with human-written examples producing the best coverage and correctness. Additionally, selecting examples based on the combined similarity of problem description and code consistently yields the most effective few-shot prompts.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12256v1",
        "authors": [
          "Alex Chudic",
          "Gül Çalıklı"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Automated Test Suite Enhancement",
        "Using Large Language Models",
        "Prompting Unit",
        "SBST",
        "Act",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.379339"
    },
    {
      "id": "arxiv-2602.12209v1",
      "title": "Keeping a Secret Requires a Good Memory: Space Lower-Bounds for Private Algorithms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12209v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the computational cost of differential privacy in terms of memory efficiency. While the trade-off between accuracy and differential privacy is well-understood, the inherent cost of privacy regarding memory use remains largely unexplored. This paper establishes for the first time an unconditional space lower bound for user-level differential privacy by introducing a novel proof technique based on a multi-player communication game. Central to our approach, this game formally links the hardness of low-memory private algorithms to the necessity of ``contribution capping'' -- tracking and limiting the users who disproportionately impact the dataset. We demonstrate that winning this communication game requires transmitting information proportional to the number of over-active users, which translates directly to memory lower bounds. We apply this framework, as an example, to the fundamental problem of estimating the number of distinct elements in a stream and we prove that any private algorithm requires almost $\\widetildeΩ(T^{1/3})$ space to achieve certain error rates in a promise variant of the problem. This resolves an open problem in the literature (by Jain et al. NeurIPS 2023 and Cummings et al. ICML 2025) and establishes the first exponential separation between the space complexity of private algorithms and their non-private $\\widetilde{O}(1)$ counterparts for a natural statistical estimation task. Furthermore, we show that this communication-theoretic technique generalizes to broad classes of problems, yielding lower bounds for private medians, quantiles, and max-select.",
        "keywords": [
          "cs.CR",
          "cs.CC",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12209v1",
        "authors": [
          "Alessandro Epasto",
          "Xin Lyu",
          "Pasin Manurangsi"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CC",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Private Algorithms We",
        "Secret Requires",
        "Good Memory",
        "Space Lower",
        "Framework",
        "ICML",
        "Act",
        "WHO",
        "EPA",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.380865"
    },
    {
      "id": "arxiv-2602.12194v1",
      "title": "MalTool: Malicious Tool Attacks on LLM Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12194v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In a malicious tool attack, an attacker uploads a malicious tool to a distribution platform; once a user installs the tool and the LLM agent selects it during task execution, the tool can compromise the user's security and privacy. Prior work primarily focuses on manipulating tool names and descriptions to increase the likelihood of installation by users and selection by LLM agents. However, a successful attack also requires embedding malicious behaviors in the tool's code implementation, which remains largely unexplored. In this work, we bridge this gap by presenting the first systematic study of malicious tool code implementations. We first propose a taxonomy of malicious tool behaviors based on the confidentiality-integrity-availability triad, tailored to LLM-agent settings. To investigate the severity of the risks posed by attackers exploiting coding LLMs to automatically generate malicious tools, we develop MalTool, a coding-LLM-based framework that synthesizes tools exhibiting specified malicious behaviors, either as standalone tools or embedded within otherwise benign implementations. To ensure functional correctness and structural diversity, MalTool leverages an automated verifier that validates whether generated tools exhibit the intended malicious behaviors and differ sufficiently from prior instances, iteratively refining generations until success. Our evaluation demonstrates that MalTool is highly effective even when coding LLMs are safety-aligned. Using MalTool, we construct two datasets of malicious tools: 1,200 standalone malicious tools and 5,287 real-world tools with embedded malicious behaviors. We further show that existing detection methods, including commercial malware detection approaches such as VirusTotal and methods tailored to the LLM-agent setting, exhibit limited effectiveness at detecting the malicious tools, highlighting an urgent need for new defenses.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12194v1",
        "authors": [
          "Yuepeng Hu",
          "Yuqi Jia",
          "Mengyuan Li",
          "Dawn Song",
          "Neil Gong"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Malicious Tool Attacks",
        "Agents In",
        "Framework",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.381563"
    },
    {
      "id": "arxiv-2602.12183v1",
      "title": "Unknown Attack Detection in IoT Networks using Large Language Models: A Robust, Data-efficient Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12183v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The rapid evolution of cyberattacks continues to drive the emergence of unknown (zero-day) threats, posing significant challenges for network intrusion detection systems in Internet of Things (IoT) networks. Existing machine learning and deep learning approaches typically rely on large labeled datasets, payload inspection, or closed-set classification, limiting their effectiveness under data scarcity, encrypted traffic, and distribution shifts. Consequently, detecting unknown attacks in realistic IoT deployments remains difficult. To address these limitations, we propose SiamXBERT, a robust and data-efficient Siamese meta-learning framework empowered by a transformer-based language model for unknown attack detection. The proposed approach constructs a dual-modality feature representation by integrating flow-level and packet-level information, enabling richer behavioral modeling while remaining compatible with encrypted traffic. Through meta-learning, the model rapidly adapts to new attack types using only a small number of labeled samples and generalizes to previously unseen behaviors. Extensive experiments on representative IoT intrusion datasets demonstrate that SiamXBERT consistently outperforms state-of-the-art baselines under both within-dataset and cross-dataset settings while requiring significantly less training data, achieving up to \\num{78.8}\\% improvement in unknown F1-score. These results highlight the practicality of SiamXBERT for robust unknown attack detection in real-world IoT environments.",
        "keywords": [
          "cs.CR",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12183v1",
        "authors": [
          "Shan Ali",
          "Feifei Niu",
          "Paria Shirani",
          "Lionel C. Briand"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unknown Attack Detection",
        "Large Language Models",
        "Internet of Things",
        "Machine Learning",
        "Deep Learning",
        "Transformer",
        "Framework",
        "Meta",
        "BERT",
        "Act",
        "NSF",
        "MIT",
        "IoT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.382137"
    },
    {
      "id": "arxiv-2602.12138v1",
      "title": "BlackCATT: Black-box Collusion Aware Traitor Tracing in Federated Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12138v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Federated Learning has been popularized in recent years for applications involving personal or sensitive data, as it allows the collaborative training of machine learning models through local updates at the data-owners' premises, which does not require the sharing of the data itself. Considering the risk of leakage or misuse by any of the data-owners, many works attempt to protect their copyright, or even trace the origin of a potential leak through unique watermarks identifying each participant's model copy. Realistic accusation scenarios impose a black-box setting, where watermarks are typically embedded as a set of sample-label pairs. The threat of collusion, however, where multiple bad actors conspire together to produce an untraceable model, has been rarely addressed, and previous works have been limited to shallow networks and near-linearly separable main tasks. To the best of our knowledge, this work is the first to present a general collusion-resistant embedding method for black-box traitor tracing in Federated Learning: BlackCATT, which introduces a novel collusion-aware embedding loss term and, instead of using a fixed trigger set, iteratively optimizes the triggers to aid convergence and traitor tracing performance. Experimental results confirm the efficacy of the proposed scheme across different architectures and datasets. Furthermore, for models that would otherwise suffer from update incompatibility on the main task after learning different watermarks (e.g., architectures including batch normalization layers), our proposed BlackCATT+FR incorporates functional regularization through a set of auxiliary examples at the aggregator, promoting a shared feature space among model copies without compromising traitor tracing performance.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12138v1",
        "authors": [
          "Elena Rodríguez-Lois",
          "Fabio Brau",
          "Maura Pintor",
          "Battista Biggio",
          "Fernando Pérez-González"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Federated Learning Federated Learning",
        "Collusion Aware Traitor Tracing",
        "Federated Learning",
        "Machine Learning",
        "Act",
        "EPA",
        "MIT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.382854"
    },
    {
      "id": "arxiv-2602.12106v1",
      "title": "MedExChain: Enabling Secure and Efffcient PHR Sharing Across Heterogeneous Blockchains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12106v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "With the proliferation of intelligent healthcare systems, patients' Personal Health Records (PHR) generated by the Internet of Medical Things (IoMT) in real-time play a vital role in disease diagnosis. The integration of emerging blockchain technologies signiffcantly enhanced the data security inside intelligent medical systems. However, data sharing across different systems based on varied blockchain architectures is still constrained by the unsolved performance and security challenges. This paper constructs a cross-chain data sharing scheme, termed MedExChain, which aims to securely share PHR across heterogeneous blockchain systems. The MedExChain scheme ensures that PHR can be shared across chains even under the performance limitations of IoMT devices. Additionally, the scheme incorporates Cryptographic Reverse Firewall (CRF) and a blockchain audit mechanism to defend against both internal and external security threats. The robustness of our scheme is validated through BAN logic, Scyther tool, Chosen Plaintext Attack (CPA) and Algorithm Substitution Attack (ASA) security analysis veriffcation. Extensive evaluations demonstrate that MedExChain signiffcantly minimizes computation and communication overhead, making it suitable for IoMT devices and fostering the efffcient circulation of PHR across diverse blockchain systems.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12106v1",
        "authors": [
          "Yongyang Lv",
          "Xiaohong Li",
          "Kui Chen",
          "Zhe Hou",
          "Guangdong Bai"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sharing Across Heterogeneous Blockchains",
        "Cryptographic Reverse Firewall",
        "Algorithm Substitution Attack",
        "Personal Health Records",
        "Chosen Plaintext Attack",
        "Enabling Secure",
        "Medical Things",
        "Blockchain",
        "Intel",
        "PHR",
        "BAN",
        "MIT",
        "CPA",
        "CRF",
        "ASA"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.383388"
    },
    {
      "id": "arxiv-2602.12084v1",
      "title": "Computing Distinguishing Formulae for Threshold-Based Behavioural Distances",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12084v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Behavioural distances generally offer more fine-grained means of comparing quantitative systems than two-valued behavioural equivalences. They often relate to quantitative modalities, which generate quantitative modal logics that characterize a given behavioural distance in terms of the induced logical distance. We develop a unified framework for behavioural distances and logics induced by a special type of modalities that lift two-valued predicates to quantitative predicates. A typical example is the probability operator, which maps a two-valued predicate $A$ to a quantitative predicate on probability distributions assigning to each distribution the respective probability of $A$. Correspondingly, the prototypical example of our framework is $ε$-bisimulation distance of Markov chains, which has recently been shown to coincide with the behavioural distance induced by the popular Lévy-Prokhorov distance on distributions. Other examples include behavioural distance on metric transition systems and Hausdorff behavioural distance on fuzzy transition systems. Our main generic results concern the polynomial-time extraction of distinguishing formulae in two characteristic modal logics: A two-valued logic with a notion of satisfaction up to $ε$, and a quantitative modal logic. These results instantiate to new results in many of the mentioned examples. Notably, we obtain polynomial-time extraction of distinguishing formulae for $ε$-bisimulation distance of Markov chains in a quantitative logic featuring a `generally' modality used in probabilistic knowledge representation.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12084v1",
        "authors": [
          "Jonas Forster",
          "Lutz Schröder",
          "Paul Wild",
          "Barbara König",
          "Pedro Nora"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Behavioural Distances Behavioural",
        "Computing Distinguishing Formulae",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.384820"
    },
    {
      "id": "arxiv-2602.12081v1",
      "title": "PPTAM$η$: Energy Aware CI/CD Pipeline for Container Based Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12081v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Modern container-based microservices evolve through rapid deployment cycles, but CI/CD pipelines still rarely measure energy consumption, even though prior work shows that design patterns, code smells and refactorings affect energy efficiency. We present PPTAM$η$, an automated pipeline that integrates power and energy measurement into GitLab CI for containerised API systems, coordinating load generation, container monitoring and hardware power probes to collect comparable metrics at each commit. The pipeline makes energy visible to developers, supports version comparison for test engineers and enables trend analysis for researchers. We evaluate PPTAM$η$ on a JWT-authenticated API across four commits, collecting performance and energy metrics and summarising the architecture, measurement methodology and validation.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12081v1",
        "authors": [
          "Alessandro Aneggi",
          "Xiaozhou Li",
          "Andrea Janes"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Container Based Applications Modern",
        "Energy Aware",
        "PPTAM",
        "Act",
        "API",
        "MIT",
        "JWT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.385691"
    },
    {
      "id": "arxiv-2602.12079v1",
      "title": "Performance Antipatterns: Angel or Devil for Power Consumption?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12079v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Performance antipatterns are known to degrade the responsiveness of microservice-based systems, but their impact on energy consumption remains largely unexplored. This paper empirically investigates whether widely studied performance antipatterns defined by Smith and Williams also negatively influence power usage. We implement ten antipatterns as isolated microservices and evaluate them under controlled load conditions, collecting synchronized measurements of performance, CPU and DRAM power consumption, and resource utilization across 30 repeated runs per antipattern. The results show that while all antipatterns degrade performance as expected, only a subset exhibit a statistically significant relationship between response time and increased power consumption. Specifically, several antipatterns reach CPU saturation, capping power draw regardless of rising response time, whereas others (\\eg Unnecessary Processing, The Ramp) demonstrate energy-performance coupling indicative of inefficiency. Our results show that, while all injected performance antipatterns increase response time as expected, only a subset also behaves as clear energy antipatterns, with several cases reaching a nearly constant CPU power level where additional slowdowns mainly translate into longer execution time rather than higher instantaneous power consumption. The study provides a systematic foundation for identifying performance antipatterns that also behave as energy antipatterns and offers actionable insights for designing more energy-efficient microservices architectures.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12079v1",
        "authors": [
          "Alessandro Aneggi",
          "Vincenzo Stoico",
          "Andrea Janes"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Performance Antipatterns",
        "Unnecessary Processing",
        "Power Consumption",
        "DRAM",
        "Act",
        "MIT",
        "CPU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.386266"
    },
    {
      "id": "arxiv-2602.12054v1",
      "title": "Unravelling Abstract Cyclic Proofs into Proofs by Induction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12054v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Cyclic proof theory breaks tradition by allowing certain infinite proofs: those that can be represented by a finite graph, while satisfying a soundness condition. We reconcile cyclic proofs with traditional finite proofs: we extend abstract cyclic proof systems with a well-founded induction principle, and transform any cyclic proof into a finite proof in the extended system. Moreover, this transformation preserves the structure of the cyclic proof. Our results leverage an annotated representation of cyclic proofs, which allows us to extract induction hypotheses and to determine their introduction order. The representation is essentially a reset proof with one key modification: names must be covered in a uniform way before a reset. This innovation allows us to handle cyclic proofs where the underlying inductive sort is non-linear. Our framework is general enough to cover recursive functions satisfying the size-change termination principle, which are viewed as cyclic proofs under the Curry-Howard correspondence.",
        "keywords": [
          "cs.LO",
          "math.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12054v1",
        "authors": [
          "Lide Grotenhuis",
          "Daniël Otten"
        ],
        "arxiv_categories": [
          "cs.LO",
          "math.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unravelling Abstract Cyclic Proofs",
        "Induction Cyclic",
        "Framework",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.386827"
    },
    {
      "id": "arxiv-2602.11988v1",
      "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11988v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files. Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11988v1",
        "authors": [
          "Thibaud Gloaguen",
          "Niels Mündler",
          "Mark Müller",
          "Veselin Raychev",
          "Martin Vechev"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Context Files Helpful",
        "Are Repository",
        "Coding Agents",
        "AGENTS",
        "Act",
        "MIT",
        "SWE",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.387401"
    },
    {
      "id": "arxiv-2602.11954v1",
      "title": "PAC to the Future: Zero-Knowledge Proofs of PAC Private Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11954v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Privacy concerns in machine learning systems have grown significantly with the increasing reliance on sensitive user data for training large-scale models. This paper introduces a novel framework combining Probably Approximately Correct (PAC) Privacy with zero-knowledge proofs (ZKPs) to provide verifiable privacy guarantees in trustless computing environments. Our approach addresses the limitations of traditional privacy-preserving techniques by enabling users to verify both the correctness of computations and the proper application of privacy-preserving noise, particularly in cloud-based systems. We leverage non-interactive ZKP schemes to generate proofs that attest to the correct implementation of PAC privacy mechanisms while maintaining the confidentiality of proprietary systems. Our results demonstrate the feasibility of achieving verifiable PAC privacy in outsourced computation, offering a practical solution for maintaining trust in privacy-preserving machine learning and database systems while ensuring computational integrity.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11954v1",
        "authors": [
          "Guilhem Repetto",
          "Nojan Sheybani",
          "Gabrielle De Micheli",
          "Farinaz Koushanfar"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Probably Approximately Correct",
        "Private Systems Privacy",
        "Knowledge Proofs",
        "Machine Learning",
        "Framework",
        "Act",
        "PAC",
        "MIT",
        "ZKP",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.387809"
    },
    {
      "id": "arxiv-2602.11949v1",
      "title": "Designing and Comparing RPQ Semantics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11949v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Modern property graph database query languages such as Cypher, PGQL, GSQL, and the standard GQL draw inspiration from the formalism of regular path queries (RPQs). In order to output walks explicitly, they depart from the classical and well-studied homomorphism semantics. However, it then becomes difficult to present results to users because RPQs may match infinitely many walks. The aforementioned languages use ad-hoc criteria to select a finite subset of those matches. For instance, Cypher uses trail semantics, discarding walks with repeated edges; PGQL and GSQL use shortest walk semantics, retaining only the walks of minimal length among all matched walks; and GQL allows users to choose from several semantics. Even though there is academic research on these semantics, it focuses almost exclusively on evaluation efficiency. In an attempt to better understand, choose and design RPQ semantics, we present a framework to categorize and compare them according to other criteria. We formalize several possible properties, pertaining to the study of RPQ semantics seen as mathematical functions mapping a database and a query to a finite set of walks. We show that some properties are mutually exclusive, or cannot be met. We also give several new RPQ semantics as examples. Some of them may provide ideas for the design of new semantics for future graph database query languages.",
        "keywords": [
          "cs.DB",
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11949v1",
        "authors": [
          "Victor Marsault",
          "Antoine Meyer"
        ],
        "arxiv_categories": [
          "cs.DB",
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Semantics Modern",
        "Framework",
        "Standard",
        "PGQL",
        "GSQL",
        "EPA",
        "RPQ",
        "GQL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.388246"
    },
    {
      "id": "arxiv-2602.11925v1",
      "title": "Studying Quality Improvements Recommended via Manual and Automated Code Review",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11925v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Several Deep Learning (DL)-based techniques have been proposed to automate code review. Still, it is unclear the extent to which these approaches can recommend quality improvements as a human reviewer. We study the similarities and differences between code reviews performed by humans and those automatically generated by DL models, using ChatGPT-4 as representative of the latter. In particular, we run a mining-based study in which we collect and manually inspect 739 comments posted by human reviewers to suggest code changes in 240 PRs. The manual inspection aims at classifying the type of quality improvement recommended by human reviewers (e.g., rename variable/constant). Then, we ask ChatGPT to perform a code review on the same PRs and we compare the quality improvements it recommends against those suggested by the human reviewers. We show that while, on average, ChatGPT tends to recommend a higher number of code changes as compared to human reviewers (~2.4x more), it can only spot 10% of the quality issues reported by humans. However, ~40% of the additional comments generated by the LLM point to meaningful quality issues. In short, our findings show the complementarity of manual and AI-based code review. This finding suggests that, in its current state, DL-based code review can be used as a further quality check on top of the one performed by humans, but should not be considered as a valid alternative to them nor as a mean to save code review time, since human reviewers would still need to perform their manual inspection while also validating the quality issues reported by the DL-based technique.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11925v1",
        "authors": [
          "Giuseppe Crupi",
          "Rosalia Tufano",
          "Gabriele Bavota"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Studying Quality Improvements Recommended",
        "Automated Code Review Several",
        "Deep Learning",
        "ChatGPT-4",
        "ChatGPT",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.388756"
    },
    {
      "id": "arxiv-2602.11911v1",
      "title": "Improving Code Generation via Small Language Model-as-a-judge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11911v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large language models (LLMs) have shown remarkable capabilities in automated code generation. While effective for mainstream languages, they may underperform on less common or domain-specific languages, prompting companies to develop in-house code generators. While open-source models can be trained for this, only LLMs with tens of billions of parameters match the performance of commercial tools, demanding costly training and deployment. Recent work proposed supporting code generation with smaller models (SLMs) by generating multiple candidate solutions and using another SLM to select the most likely correct one. The most recent work in this area is the one by Sun et al. [29] presenting RankEF, a T5 model trained to rank code solutions using both execution-based and non-execution-based information. However, Sun et al. do not assess the T5 ranker's classification accuracy, that is, how often it misjudges correct implementations as incorrect or vice versa, leaving open questions about the reliability of LMs as code correctness judges for other tasks (e.g., automated code review). Moreover, their experiments involve relatively old models, making it unclear the extent to which such a methodology would still help companies in cheaply training their own code generators with performance comparable to those of massive LLMs. We present a study addressing these limitations. We train several state-of-the-art SLMs as code correctness judges and assess their ability to discriminate between correct and wrong implementations. We show that modern SLMs outperform RankEF, even without exploiting execution-based information. When used as code rankers, they achieve higher performance gains than RankEF and perform competitively with LLMs 5-25x larger, at a fraction of the cost.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11911v1",
        "authors": [
          "Giuseppe Crupi",
          "Rosalia Tufano",
          "Gabriele Bavota"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Improving Code Generation",
        "Small Language Model",
        "Bill",
        "Act",
        "SLM",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.389297"
    },
    {
      "id": "arxiv-2602.11907v1",
      "title": "A Unified Treatment of Substitution for Presheaves, Nominal Sets, Renaming Sets, and so on",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11907v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Presheaves and nominal sets provide alternative abstract models of sets of syntactic objects with free and bound variables, such as lambda-terms. One distinguishing feature of the presheaf-based perspective is its elegant syntax-free characterization of substitution using a closed monoidal structure. In this paper, we introduce a corresponding closed monoidal structure on nominal sets, modeling substitution in the spirit of Fiore et al.'s substitution tensor for presheaves over finite sets. To this end, we present a general method to derive a closed monoidal structure on a category from a given action of a monoidal category on that category. We demonstrate that this method not only uniformly recovers known substitution tensors for various kinds of presheaf categories, but also yields novel notions of substitution tensor for nominal sets and their relatives, such as renaming sets. In doing so, we shed new light on different incarnations of nominal sets and (pre-)sheaf categories and establish a number of novel correspondences between them.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11907v1",
        "authors": [
          "Fabian Lenke",
          "Stefan Milius",
          "Henning Urbat"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Treatment",
        "Renaming Sets",
        "Nominal Sets",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.389660"
    },
    {
      "id": "arxiv-2602.11904v1",
      "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs: A Systematic Evaluation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11904v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Software languages evolve over time for reasons such as feature additions. When grammars evolve, textual instances that originally conformed to them may become outdated. While model-driven engineering provides many techniques for co-evolving models with metamodel changes, these approaches are not designed for textual DSLs and may lose human-relevant information such as layout and comments. This study systematically evaluates the potential of large language models (LLMs) for co-evolving grammars and instances of textual DSLs. Using Claude Sonnet 4.5 and GPT-5.2 across ten case languages with ten runs each, we assess both correctness and preservation of human-oriented information. Results show strong performance on small-scale cases ($\\geq$94% precision and recall for instances requiring fewer than 20 modified lines), but performance degraded with scale: Claude maintains 85% recall at 40 lines, while GPT fails on the largest instances. Response time increases substantially with instance size, and grammar evolution complexity and deletion granularity affect performance more than change type. These findings clarify when LLM-based co-evolution is effective and where current limitations remain.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11904v1",
        "authors": [
          "Weixing Zhang",
          "Bowen Jiang",
          "Yuhong Fu",
          "Anne Koziolek",
          "Regina Hebig"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Systematic Evaluation Software",
        "Using Claude Sonnet",
        "GPT-5.2",
        "Meta",
        "MIT",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.390073"
    },
    {
      "id": "arxiv-2602.11897v1",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11897v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity orchestration should be reconceptualized as an agentic, multi-agent cognitive system, rather than a linear sequence of detection and response components. We introduce a conceptual architectural framework in which heterogeneous AI agents responsible for detection, hypothesis formation, contextual interpretation, explanation, and governance are coordinated through an explicit meta-cognitive judgement function. This function governs decision readiness and dynamically calibrates system autonomy when evidence is incomplete, conflicting, or operationally risky. By synthesizing distributed cognition theory, multi-agent systems research, and responsible AI governance frameworks, we demonstrate that modern security operations already function as distributed cognitive systems, albeit without an explicit organizing principle. Our contribution is to make this cognitive structure architecturally explicit and governable by embedding meta-cognitive judgement as a first-class system function. We discuss implications for security operations centers, accountable autonomy, and the design of next-generation AI-enabled cyber defence architectures. The proposed framework shifts the focus of AI in cybersecurity from optimizing isolated predictions to governing autonomy under uncertainty.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11897v1",
        "authors": [
          "Andrei Kojukhov",
          "Arkady Bovshover"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Governable Autonomy Contemporary",
        "Cognitive Architecture",
        "Framework",
        "Meta",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.390603"
    },
    {
      "id": "arxiv-2602.11887v1",
      "title": "Verifiable Provenance of Software Artifacts with Zero-Knowledge Compilation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11887v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Verifying that a compiled binary originates from its claimed source code is a fundamental security requirement, called source code provenance. Achieving verifiable source code provenance in practice remains challenging. The most popular technique, called reproducible builds, requires difficult matching and reexecution of build toolchains and environments. We propose a novel approach to verifiable provenance based on compiling software with zero-knowledge virtual machines (zkVMs). By executing a compiler within a zkVM, our system produces both the compiled output and a cryptographic proof attesting that the compilation was performed on the claimed source code with the claimed compiler. We implement a proof-of-concept implementation using the RISC Zero zkVM and the ChibiCC C compiler, and evaluate it on 200 synthetic programs as well as 31 OpenSSL and 21 libsodium source files. Our results show that zk-compilation is applicable to real-world software and provides strong security guarantees: all adversarial tests targeting compiler substitution, source tampering, output manipulation, and replay attacks are successfully blocked.",
        "keywords": [
          "cs.SE",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11887v1",
        "authors": [
          "Javier Ron",
          "Martin Monperrus"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Knowledge Compilation Verifying",
        "Verifiable Provenance",
        "Software Artifacts",
        "RISC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.390972"
    },
    {
      "id": "arxiv-2602.11851v1",
      "title": "Resource-Aware Deployment Optimization for Collaborative Intrusion Detection in Layered Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11851v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Collaborative Intrusion Detection Systems (CIDS) are increasingly adopted to counter cyberattacks, as their collaborative nature enables them to adapt to diverse scenarios across heterogeneous environments. As distributed critical infrastructure operates in rapidly evolving environments, such as drones in both civil and military domains, there is a growing need for CIDS architectures that can flexibly accommodate these dynamic changes. In this study, we propose a novel CIDS framework designed for easy deployment across diverse distributed environments. The framework dynamically optimizes detector allocation per node based on available resources and data types, enabling rapid adaptation to new operational scenarios with minimal computational overhead. We first conducted a comprehensive literature review to identify key characteristics of existing CIDS architectures. Based on these insights and real-world use cases, we developed our CIDS framework, which we evaluated using several distributed datasets that feature different attack chains and network topologies. Notably, we introduce a public dataset based on a realistic cyberattack targeting a ground drone aimed at sabotaging critical infrastructure. Experimental results demonstrate that the proposed CIDS framework can achieve adaptive, efficient intrusion detection in distributed settings, automatically reconfiguring detectors to maintain an optimal configuration, without requiring heavy computation, since all experiments were conducted on edge devices.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11851v1",
        "authors": [
          "André García Gómez",
          "Ines Rieger",
          "Wolfgang Hotwagner",
          "Max Landauer",
          "Markus Wurzenberger"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Layered Networks Collaborative Intrusion",
        "Collaborative Intrusion Detection",
        "Aware Deployment Optimization",
        "Detection Systems",
        "Framework",
        "Drone",
        "CIDS",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.391465"
    },
    {
      "id": "arxiv-2602.11820v1",
      "title": "Solving the Post-Quantum Control Plane Bottleneck: Energy-Aware Cryptographic Scheduling in Open RAN",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11820v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Open Radio Access Network (O-RAN) offers flexibility and innovation but introduces unique security vulnerabilities, particularly from cryptographically relevant quantum computers. While Post-Quantum Cryptography (PQC) is the primary scalable defence, its computationally intensive handshakes create a significant bottleneck for the RAN control plane, posing sustainability challenges. This paper proposes an energy-aware framework to solve this PQC bottleneck, ensuring quantum resilience without sacrificing operational energy efficiency. The system employs an O-RAN aligned split: a Crypto Policy rApp residing in the Non-Real-Time (Non-RT) RIC defines the strategic security envelope (including PQC suites), while a Security Operations Scheduling (SOS) xApp in the Near-RT RIC converts these into tactical timing and placement intents. Cryptographic enforcement remains at standards-compliant endpoints: the Open Fronthaul utilizes Media Access Control Security (MACsec) at the O-DU/O-RU, while the xhaul (midhaul and backhaul) utilizes IP Security (IPsec) at tunnel terminators. The SOS xApp reduces PQC overhead by batching non-urgent handshakes, prioritizing session resumption, and selecting parameters that meet slice SLAs while minimizing joules per secure connection. We evaluate the architecture via a Discrete-Event Simulation (DES) using 3GPP-aligned traffic profiles and verified hardware benchmarks from literature. Results show that intelligent scheduling can reduce per-handshake energy by approximately 60 percent without violating slice latency targets.",
        "keywords": [
          "cs.CR",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11820v1",
        "authors": [
          "Neha Gupta",
          "Hamed Alimohammadi",
          "Mohammad Shojafar",
          "De Mi",
          "Muhammad N. M. Bhutta"
        ],
        "arxiv_categories": [
          "cs.CR",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Control Plane Bottleneck",
        "Security Operations Scheduling",
        "Aware Cryptographic Scheduling",
        "Media Access Control Security",
        "Quantum Cryptography",
        "Event Simulation",
        "Open Fronthaul",
        "Crypto Policy",
        "While Post",
        "Framework",
        "Standard",
        "Policy",
        "Intel",
        "Act",
        "SOS"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.391979"
    },
    {
      "id": "arxiv-2602.11793v1",
      "title": "More Haste, Less Speed: Weaker Single-Layer Watermark Improves Distortion-Free Watermark Ensembles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11793v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Watermarking has emerged as a crucial technique for detecting and attributing content generated by large language models. While recent advancements have utilized watermark ensembles to enhance robustness, prevailing methods typically prioritize maximizing the strength of the watermark at every individual layer. In this work, we identify a critical limitation in this \"stronger-is-better\" approach: strong watermarks significantly reduce the entropy of the token distribution, which paradoxically weakens the effectiveness of watermarking in subsequent layers. We theoretically and empirically show that detectability is bounded by entropy and that watermark ensembles induce a monotonic decrease in both entropy and the expected green-list ratio across layers. To address this inherent trade-off, we propose a general framework that utilizes weaker single-layer watermarks to preserve the entropy required for effective multi-layer ensembling. Empirical evaluations demonstrate that this counter-intuitive strategy mitigates signal decay and consistently outperforms strong baselines in both detectability and robustness.",
        "keywords": [
          "cs.CR",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11793v1",
        "authors": [
          "Ruibo Chen",
          "Yihan Wu",
          "Xuehao Cui",
          "Jingqi Zhang",
          "Heng Huang"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Free Watermark Ensembles Watermarking",
        "Layer Watermark Improves Distortion",
        "Weaker Single",
        "More Haste",
        "Less Speed",
        "Framework",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.392322"
    },
    {
      "id": "arxiv-2602.11782v1",
      "title": "FlowMind: Execute-Summarize for Structured Workflow Generation from LLM Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11782v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "LLMs can solve complex tasks through reasoning and tool use, but accurately translating these solutions into structured workflows remains challenging. We model workflows as sequences of tool use and reformulate the problem as designing a mechanism that can both solve tasks and reliably construct workflows. Prior approaches that build workflows during execution often suffer from inaccuracies due to interference between the two processes. We propose an Execute-Summarize(ES) framework that decouples task execution from workflow construction: the model first completes the task using available tools, then independently reconstructs a structured workflow from execution traces. This separation improves workflow accuracy and robustness. We introduce FlowBench and show through extensive experiments that our approach outperforms existing methods, providing a reliable paradigm for grounding free-form LLM reasoning into structured workflows.",
        "keywords": [
          "cs.AI",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11782v1",
        "authors": [
          "Yihao Liu",
          "Ziyun Zhang",
          "Zile He",
          "Huaqian Cai"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structured Workflow Generation",
        "Framework",
        "EPA",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.392606"
    },
    {
      "id": "arxiv-2602.11775v1",
      "title": "V-SHiNE: A Virtual Smart Home Framework for Explainability Evaluation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11775v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Explanations are essential for helping users interpret and trust autonomous smart-home decisions, yet evaluating their quality and impact remains methodologically difficult in this domain. V-SHiNE addresses this gap: a browser-based smarthome simulation framework for scalable and realistic assessment of explanations. It allows researchers to configure environments, simulate behaviors, and plug in custom explanation engines, with flexible delivery modes and rich interaction logging. A study with 159 participants demonstrates its feasibility. V-SHiNE provides a lightweight, reproducible platform for advancing user-centered evaluation of explainable intelligent systems",
        "keywords": [
          "cs.HC",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11775v1",
        "authors": [
          "Mersedeh Sadeghi",
          "Simon Scholz",
          "Max Unterbusch",
          "Andreas Vogelsang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.SE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Explainability Evaluation Explanations",
        "Virtual Smart Home Framework",
        "Framework",
        "Intel",
        "Act",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:15.392828"
    },
    {
      "id": "arxiv-2602.11750v1",
      "title": "AmbiBench: Benchmarking Mobile GUI Agents Beyond One-Shot Instructions in the Wild",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11750v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Benchmarks are paramount for gauging progress in the domain of Mobile GUI Agents. In practical scenarios, users frequently fail to articulate precise directives containing full task details at the onset, and their expressions are typically ambiguous. Consequently, agents are required to converge on the user's true intent via active clarification and interaction during execution. However, existing benchmarks predominantly operate under the idealized assumption that user-issued instructions are complete and unequivocal. This paradigm focuses exclusively on assessing single-turn execution while overlooking the alignment capability of the agent. To address this limitation, we introduce AmbiBench, the first benchmark incorporating a taxonomy of instruction clarity to shift evaluation from unidirectional instruction following to bidirectional intent alignment. Grounded in Cognitive Gap theory, we propose a taxonomy of four clarity levels: Detailed, Standard, Incomplete, and Ambiguous. We construct a rigorous dataset of 240 ecologically valid tasks across 25 applications, subject to strict review protocols. Furthermore, targeting evaluation in dynamic environments, we develop MUSE (Mobile User Satisfaction Evaluator), an automated framework utilizing an MLLM-as-a-judge multi-agent architecture. MUSE performs fine-grained auditing across three dimensions: Outcome Effectiveness, Execution Quality, and Interaction Quality. Empirical results on AmbiBench reveal the performance boundaries of SoTA agents across different clarity levels, quantify the gains derived from active interaction, and validate the strong correlation between MUSE and human judgment. This work redefines evaluation standards, laying the foundation for next-generation agents capable of truly understanding user intent.",
        "keywords": [
          "cs.SE",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11750v1",
        "authors": [
          "Jiazheng Sun",
          "Mingxuan Li",
          "Yingying Zhang",
          "Jiayang Niu",
          "Yachen Wu"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mobile User Satisfaction Evaluator",
        "Outcome Effectiveness",
        "Interaction Quality",
        "Benchmarking Mobile",
        "Agents Beyond One",
        "Shot Instructions",
        "Execution Quality",
        "Wild Benchmarks",
        "Cognitive Gap",
        "Framework",
        "Directive",
        "Standard",
        "Protocol",
        "MUSE",
        "MLLM"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.393388"
    },
    {
      "id": "arxiv-2602.11746v1",
      "title": "Leveraging Language Models to Discover Evidence-Based Actions for OSS Sustainability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11746v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "When successful, Open Source Software (OSS) projects create enormous value, but most never reach a sustainable state. Recent work has produced accurate models that forecast OSS sustainability, yet these models rarely tell maintainers what to do: their features are often high-level socio-technical signals that are not directly actionable. Decades of empirical software engineering research have accumulated a large but underused body of evidence on concrete practices that improve project health. We close this gap by using LLMs as evidence miners over the SE literature. We design a RAG-pipeline and a two-layer prompting strategy that extract researched actionables (ReACTs): concise, evidence-linked recommendations mapping to specific OSS practices. In the first layer, we systematically explore open LLMs and prompting techniques, selecting the best-performing combination to derive candidate ReACTs from 829 ICSE and FSE papers. In the second layer, we apply follow-up prompting to filter hallucinations, extract impact and evidence, and assess soundness and precision. Our pipeline yields 1,922 ReACTs, of which 1,312 pass strict quality criteria and are organized into practice-oriented categories connectable to project signals from tools like APEX. The result is a reproducible, scalable approach turning scattered research findings into structured, evidence-based actions guiding OSS projects toward sustainability.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11746v1",
        "authors": [
          "Nafiz Imtiaz Khan",
          "Vladimir Filkov"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Leveraging Language Models",
        "Open Source Software",
        "Sustainability When",
        "Discover Evidence",
        "Based Actions",
        "ICSE",
        "APEX",
        "Act",
        "OSS",
        "RAG",
        "FSE",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.393780"
    },
    {
      "id": "arxiv-2602.11729v1",
      "title": "Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11729v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Model diffing, the process of comparing models' internal representations to identify their differences, is a promising approach for uncovering safety-critical behaviors in new models. However, its application has so far been primarily focused on comparing a base model with its finetune. Since new LLM releases are often novel architectures, cross-architecture methods are essential to make model diffing widely applicable. Crosscoders are one solution capable of cross-architecture model diffing but have only ever been applied to base vs finetune comparisons. We provide the first application of crosscoders to cross-architecture model diffing and introduce Dedicated Feature Crosscoders (DFCs), an architectural modification designed to better isolate features unique to one model. Using this technique, we find in an unsupervised fashion features including Chinese Communist Party alignment in Qwen3-8B and Deepseek-R1-0528-Qwen3-8B, American exceptionalism in Llama3.1-8B-Instruct, and a copyright refusal mechanism in GPT-OSS-20B. Together, our results work towards establishing cross-architecture crosscoder model diffing as an effective method for identifying meaningful behavioral differences between AI models.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11729v1",
        "authors": [
          "Thomas Jiralerspong",
          "Trenton Bricken"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dedicated Feature Crosscoders",
        "Architecture Model Diffing",
        "Chinese Communist Party",
        "Unsupervised Discovery",
        "Differences Between",
        "R1-0528",
        "NIST",
        "OSS",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.394192"
    },
    {
      "id": "arxiv-2602.11724v1",
      "title": "WebTestPilot: Agentic End-to-End Web Testing against Natural Language Specification by Inferring Oracles with Symbolized GUI Elements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11724v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Visual language model (VLM) agents show great promise in automating end-to-end (E2E) web testing against requirements in natural language. However, the probabilistic nature of language models can have inherent hallucinations. Therefore, given a detected inconsistency between the requirement and the web application, it is hard to distinguish whether it stems from the hallucination or a real application bug. Addressing this issue presents two core technical challenges: the implicit oracle inference challenge, where the agent must act as its own oracle to implicitly decide if the application's behavior is correct without guidance, and the probabilistic inference challenge, where an LLM's inconsistent reasoning undermines its trustworthiness as an oracle. Existing LLM-based approaches fail to capture such implicit oracles, either by treating any page navigation that doesn't crash as a success, or by checking each state in isolation, thus missing bugs dependent on context from prior steps. We introduce WebTestPilot, an LLM-based agent designed to address these challenges. WebTestPilot uses (1) a symbolization layer which detects and symbolizes critical GUI elements on the web application into symbols (i.e., variables) and (2) translates natural language specification into a sequence of steps, each of which is equipped with inferred pre- and post-conditions over the symbols as an oracle. This oracle captures data, temporal, and causal dependencies, enabling the validation of implicit requirements. To advance research in this area, we build a benchmark of bug-injected web apps for evaluating NL-to-E2E testing. The results show that WebTestPilot achieves a task completion rate of 99%, with 96% precision and 96% recall in bug detection, outperforming the best baseline (+70 precision, +27 recall). The agent generalizes across diverse natural language inputs and model scales.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11724v1",
        "authors": [
          "Xiwen Teoh",
          "Yun Lin",
          "Duc-Minh Nguyen",
          "Ruofei Ren",
          "Wenjie Zhang"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Natural Language Specification",
        "Inferring Oracles",
        "End Web Testing",
        "Elements Visual",
        "Agentic End",
        "Oracle",
        "Act",
        "VLM",
        "DOE",
        "LLM",
        "GUI",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.394707"
    },
    {
      "id": "arxiv-2602.11692v1",
      "title": "Beyond Code: Empirical Insights into How Team Dynamics Influence OSS Project Selection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11692v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Open-source software (OSS) development relies on effective collaboration among distributed contributors. Yet, current OSS project recommendation systems primarily emphasize technical attributes, overlooking the collaboration and community aspects that influence contributors' decisions to join and remain in projects. This study investigates how team dynamics within OSS communities influence project selection and how these preferences vary across contributors' motivations. We conducted an online survey with 198 OSS practitioners, combining quantitative and qualitative analyses to capture contributors' perceptions of team dynamics. The results reveal that communication-related team dynamics such as responsiveness, tone, and clarity of replies are consistently prioritized across practitioners. However, the relative importance of these team dynamics differs according to contributors' motivations. For instance, practitioners motivated by gaining reputation or networking preferred inclusive project communities that encouraged diverse participation. These findings highlight that understanding how team dynamics align with contributors' motivations provides valuable insights into practitioners' project selection behaviour. Those insights can inform the design of future human-aware project recommendation systems that better account for social collaboration quality and motivational fit.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11692v1",
        "authors": [
          "Shashiwadana Nirmani",
          "Hourieh Khalajzadeh",
          "Mojtaba Shahin",
          "Xiao Liu"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "How Team Dynamics Influence",
        "Project Selection Open",
        "Empirical Insights",
        "Beyond Code",
        "Act",
        "OSS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.395085"
    },
    {
      "id": "arxiv-2602.11671v1",
      "title": "Do Not Treat Code as Natural Language: Implications for Repository-Level Code Generation and Beyond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11671v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large language models for code (CodeLLMs) have demonstrated remarkable success in standalone code completion and generation, sometimes even surpassing human performance, yet their effectiveness diminishes in repository-level settings where cross-file dependencies and structural context are essential. Existing Retrieval-Augmented Generation (RAG) approaches often borrow strategies from NLP, relying on chunking-based indexing and similarity-based retrieval. Chunking results in the loss of coherence between code units and overlooks structural relationships, while similarity-driven methods frequently miss functionally relevant dependencies such as helper functions, classes, or global variables. To address these limitations, we present Hydra, a repository-level code generation framework that treats code as structured code rather than natural language. Our approach introduces (i) a structure-aware indexing strategy that represents repositories as hierarchical trees of functions, classes, and variables, preserving code structure and dependencies, (ii) a lightweight dependency-aware retriever (DAR) that explicitly identifies and retrieves the true dependencies required by a target function, and (iii) a hybrid retrieval mechanism that combines DAR with similarity-based retrieval to provide both essential building blocks and practical usage examples. Extensive experiments on the challenging DevEval and RepoExec benchmarks, both requiring function implementation from real-world repositories with complex large repository context, show that Hydra achieves state-of-the-art performance across open- and closed-source CodeLLMs. Notably, our method establishes a new state of the art in repository-level code generation, surpassing strongest baseline by over 5% in Pass@1 and even enabling smaller models to match or exceed the performance of much larger ones that rely on existing retrievers.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11671v1",
        "authors": [
          "Minh Le-Anh",
          "Huyen Nguyen",
          "Khanh An Tran",
          "Nam Le Hai",
          "Linh Ngo Van"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Code Generation",
        "Augmented Generation",
        "Existing Retrieval",
        "Do Not Treat Code",
        "Natural Language",
        "Beyond Large",
        "Framework",
        "Act",
        "DAR",
        "MIT",
        "NLP",
        "LLM",
        "RAG",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.395603"
    },
    {
      "id": "arxiv-2602.11651v1",
      "title": "DMind-3: A Sovereign Edge--Local--Cloud AI System with Controlled Deliberation and Correction-Based Tuning for Safe, Low-Latency Transaction Execution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11651v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper introduces DMind-3, a sovereign Edge-Local-Cloud intelligence stack designed to secure irreversible financial execution in Web3 environments against adversarial risks and strict latency constraints. While existing cloud-centric assistants compromise privacy and fail under network congestion, and purely local solutions lack global ecosystem context, DMind-3 resolves these tensions by decomposing capability into three cooperating layers: a deterministic signing-time intent firewall at the edge, a private high-fidelity reasoning engine on user hardware, and a policy-governed global context synthesizer in the cloud. We propose policy-driven selective offloading to route computation based on privacy sensitivity and uncertainty, supported by two novel training objectives: Hierarchical Predictive Synthesis (HPS) for fusing time-varying macro signals, and Contrastive Chain-of-Correction Supervised Fine-Tuning (C$^3$-SFT) to enhance local verification reliability. Extensive evaluations demonstrate that DMind-3 achieves a 93.7% multi-turn success rate in protocol-constrained tasks and superior domain reasoning compared to general-purpose baselines, providing a scalable framework where safety is bound to the edge execution primitive while maintaining sovereignty over sensitive user intent.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11651v1",
        "authors": [
          "Enhao Huang",
          "Frank Li",
          "Tony Lin",
          "Lowes Yang"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hierarchical Predictive Synthesis",
        "Correction Supervised Fine",
        "Controlled Deliberation",
        "Contrastive Chain",
        "Sovereign Edge",
        "Based Tuning",
        "Framework",
        "Protocol",
        "DMind-3",
        "Policy",
        "Intel",
        "NIST",
        "Act",
        "HPS",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.396045"
    },
    {
      "id": "arxiv-2602.11606v1",
      "title": "QDBFT: A Dynamic Consensus Algorithm for Quantum-Secured Blockchain",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11606v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The security foundation of blockchain system relies primarily on classical cryptographic methods and consensus algorithms. However, the advent of quantum computing poses a significant threat to conventional public-key cryptosystems based on computational hardness assumptions. In particular, Shor's algorithm can efficiently solve discrete logarithm and integer factorization problems in polynomial time, thereby undermining the immutability and security guarantees of existing systems. Moreover, current Practical Byzantine Fault Tolerance (PBFT) protocols, widely adopted in consortium blockchains, suffer from high communication overhead and limited efficiency when coping with dynamic node reconfigurations, while offering no intrinsic protection against quantum adversaries. To address these challenges, we propose QDBFT, a quantum-secured dynamic consensus algorithm, with two main contributions: first,we design a primary node automatic rotation mechanism based on a consistent hash ring to enable consensus under dynamic membership changes, ensuring equitable authority distribution; second, we integrate Quantum Key Distribution (QKD) networks to provide message authentication for inter-node communication, thereby achieving information-theoretic security in the consensus process. Experimental evaluations demonstrate that QDBFT achieves performance comparable to traditional PBFT while delivering strong resilience against quantum attacks, making it a promising solution for future quantum-secure decentralized infrastructures.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11606v1",
        "authors": [
          "Fei Xu",
          "Cheng Ye",
          "Jie OuYang",
          "Ziqiang Wu",
          "Haoze Chen"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Practical Byzantine Fault Tolerance",
        "Dynamic Consensus Algorithm",
        "Quantum Key Distribution",
        "Quantum Computing",
        "Blockchain",
        "Protocol",
        "QDBFT",
        "PBFT",
        "Act",
        "QKD",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.396468"
    },
    {
      "id": "arxiv-2602.11528v1",
      "title": "Stop Tracking Me! Proactive Defense Against Attribute Inference Attack in LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11528v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent studies have shown that large language models (LLMs) can infer private user attributes (e.g., age, location, gender) from user-generated text shared online, enabling rapid and large-scale privacy breaches. Existing anonymization-based defenses are coarse-grained, lacking word-level precision in anonymizing privacy-leaking elements. Moreover, they are inherently limited as altering user text to hide sensitive cues still allows attribute inference to occur through models' reasoning capabilities. To address these limitations, we propose a unified defense framework that combines fine-grained anonymization (TRACE) with inference-preventing optimization (RPS). TRACE leverages attention mechanisms and inference chain generation to identify and anonymize privacy-leaking textual elements, while RPS employs a lightweight two-stage optimization strategy to induce model rejection behaviors, thereby preventing attribute inference. Evaluations across diverse LLMs show that TRACE-RPS reduces attribute inference accuracy from around 50\\% to below 5\\% on open-source models. In addition, our approach offers strong cross-model generalization, prompt-variation robustness, and utility-privacy tradeoffs. Our code is available at https://github.com/Jasper-Yan/TRACE-RPS.",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11528v1",
        "authors": [
          "Dong Yan",
          "Jian Liang",
          "Ran He",
          "Tieniu Tan"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Proactive Defense Against Attribute",
        "Inference Attack",
        "Stop Tracking Me",
        "Framework",
        "TRACE",
        "Act",
        "RPS",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.396821"
    },
    {
      "id": "arxiv-2602.11514v1",
      "title": "How Smart Is Your GUI Agent? A Framework for the Future of Software Interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11514v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "GUI agents are rapidly becoming a new interaction to software, allowing people to navigate web, desktop and mobile rather than execute them click by click. Yet ``agent'' is described with radically different degrees of autonomy, obscuring capability, responsibility and risk. We call for conceptual clarity through GUI Agent Autonomy Levels (GAL), a six-level framework that makes autonomy explicit and helps benchmark progress toward trustworthy software interaction.",
        "keywords": [
          "cs.SE",
          "cs.AI",
          "cs.CV",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11514v1",
        "authors": [
          "Sidong Feng",
          "Chunyang Chen"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI",
          "cs.CV",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Autonomy Levels",
        "Software Interaction",
        "How Smart Is Your",
        "Framework",
        "Act",
        "GAL",
        "GUI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.396998"
    },
    {
      "id": "arxiv-2602.11513v1",
      "title": "Differentially Private and Communication Efficient Large Language Model Split Inference via Stochastic Quantization and Soft Prompt",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11513v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) have achieved remarkable performance and received significant research interest. The enormous computational demands, however, hinder the local deployment on devices with limited resources. The current prevalent LLM inference paradigms require users to send queries to the service providers for processing, which raises critical privacy concerns. Existing approaches propose to allow the users to obfuscate the token embeddings before transmission and utilize local models for denoising. Nonetheless, transmitting the token embeddings and deploying local models may result in excessive communication and computation overhead, preventing practical implementation. In this work, we propose \\textbf{DEL}, a framework for \\textbf{D}ifferentially private and communication \\textbf{E}fficient \\textbf{L}LM split inference. More specifically, an embedding projection module and a differentially private stochastic quantization mechanism are proposed to reduce the communication overhead in a privacy-preserving manner. To eliminate the need for local models, we adapt soft prompt at the server side to compensate for the utility degradation caused by privacy. To the best of our knowledge, this is the first work that utilizes soft prompt to improve the trade-off between privacy and utility in LLM inference, and extensive experiments on text generation and natural language understanding benchmarks demonstrate the effectiveness of the proposed method.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11513v1",
        "authors": [
          "Yujie Gu",
          "Richeng Jin",
          "Xiaoyu Ji",
          "Yier Jin",
          "Wenyuan Xu"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Communication Efficient Large Language",
        "Soft Prompt Large Language",
        "Stochastic Quantization",
        "Differentially Private",
        "Model Split Inference",
        "Framework",
        "Act",
        "DEL",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.397407"
    },
    {
      "id": "arxiv-2602.11495v1",
      "title": "Jailbreaking Leaves a Trace: Understanding and Detecting Jailbreak Attacks from Internal Representations of Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11495v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Jailbreaking large language models (LLMs) has emerged as a critical security challenge with the widespread deployment of conversational AI systems. Adversarial users exploit these models through carefully crafted prompts to elicit restricted or unsafe outputs, a phenomenon commonly referred to as Jailbreaking. Despite numerous proposed defense mechanisms, attackers continue to develop adaptive prompting strategies, and existing models remain vulnerable. This motivates approaches that examine the internal behavior of LLMs rather than relying solely on prompt-level defenses. In this work, we study jailbreaking from both security and interpretability perspectives by analyzing how internal representations differ between jailbreak and benign prompts. We conduct a systematic layer-wise analysis across multiple open-source models, including GPT-J, LLaMA, Mistral, and the state-space model Mamba, and identify consistent latent-space patterns associated with harmful inputs. We then propose a tensor-based latent representation framework that captures structure in hidden activations and enables lightweight jailbreak detection without model fine-tuning or auxiliary LLM-based detectors. We further demonstrate that the latent signals can be used to actively disrupt jailbreak execution at inference time. On an abliterated LLaMA-3.1-8B model, selectively bypassing high-susceptibility layers blocks 78% of jailbreak attempts while preserving benign behavior on 94% of benign prompts. This intervention operates entirely at inference time and introduces minimal overhead, providing a scalable foundation for achieving stronger coverage by incorporating additional attack distributions or more refined susceptibility thresholds. Our results provide evidence that jailbreak behavior is rooted in identifiable internal structures and suggest a complementary, architecture-agnostic direction for improving LLM security.",
        "keywords": [
          "cs.CR",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11495v1",
        "authors": [
          "Sri Durga Sai Sowmya Kadali",
          "Evangelos E. Papalexakis"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models Jailbreaking",
        "Detecting Jailbreak Attacks",
        "Internal Representations",
        "Jailbreaking Leaves",
        "LLaMA-3.1",
        "Framework",
        "Act",
        "LLM",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.397910"
    },
    {
      "id": "arxiv-2602.11487v1",
      "title": "Search-Based Quantum Program Testing via Commuting Pauli String",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11487v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum software testing is important for reliable quantum software engineering. Despite recent advances, existing quantum software testing approaches rely on simple test inputs and statistical oracles, costly program specifications, and limited validation on real quantum computers. To address these challenges, we propose SB-QOPS, a search-based quantum program testing approach via commuting Pauli strings. SB-QOPS, as a direct extension to a previously proposed QOPS approach, redefines test cases in terms of Pauli strings and introduces a measurement-centric oracle that exploits their commutation properties, enabling effective testing of quantum programs while reducing the need for full program specifications. By systematically exploring the search space through an expectation-value-based fitness function, SB-QOPS improves test budget utilization and increases the likelihood of uncovering subtle faults. We conduct a large-scale empirical evaluation on quantum circuits of up to 29 qubits on real quantum computers and emulators. We assess three search strategies: Genetic Algorithm, Hill Climbing, and the (1+1) Evolutionary Algorithm, and evaluate SB-QOPS under both simulated and real noisy conditions. Experiments span three quantum computing platforms: IBM, IQM, and Quantinuum. Results show that SB-QOPS significantly outperforms QOPS, achieving a fault-detection score of 100% for circuits up to 29 qubits, and demonstrating portability across quantum platforms.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11487v1",
        "authors": [
          "Asmar Muqeet",
          "Shaukat Ali",
          "Paolo Arcaini"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Commuting Pauli String Quantum",
        "Based Quantum Program Testing",
        "Evolutionary Algorithm",
        "Quantum Computing",
        "Genetic Algorithm",
        "Hill Climbing",
        "Oracle",
        "QOPS",
        "MIT",
        "IQM",
        "IBM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.398311"
    },
    {
      "id": "arxiv-2602.11481v1",
      "title": "Compiler-Guided Inference-Time Adaptation: Improving GPT-5 Programming Performance in Idris",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11481v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "GPT-5, a state of the art large language model from OpenAI, demonstrates strong performance in widely used programming languages such as Python, C++, and Java; however, its ability to operate in low resource or less commonly used languages remains underexplored. This work investigates whether GPT-5 can effectively acquire proficiency in an unfamiliar functional programming language, Idris, through iterative, feedback driven prompting. We first establish a baseline showing that with zero shot prompting the model solves only 22 out of 56 Idris exercises using the platform Exercism, substantially underperforming relative to higher resource languages (45 out of 50 in Python and 35 out of 47 in Erlang). We then evaluate several refinement strategies, including iterative prompting based on platform feedback, augmenting prompts with documentation and error classification guides, and iterative prompting using local compilation errors and failed test cases. Among these approaches, incorporating local compilation errors yields the most substantial improvements. Using this structured, error guided refinement loop, GPT-5 performance increased to an impressive 54 solved problems out of 56. These results suggest that while large language models may initially struggle in low resource settings, structured compiler level feedback can play a critical role in unlocking their capabilities.",
        "keywords": [
          "cs.PL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11481v1",
        "authors": [
          "Minda Li",
          "Bhaskar Krishnamachari"
        ],
        "arxiv_categories": [
          "cs.PL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Programming Performance",
        "Guided Inference",
        "Time Adaptation",
        "OpenAI",
        "GPT-5",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.398689"
    },
    {
      "id": "arxiv-2602.11472v1",
      "title": "Future Mining: Learning for Safety and Security",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11472v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Mining is rapidly evolving into an AI driven cyber physical ecosystem where safety and operational reliability depend on robust perception, trustworthy distributed intelligence, and continuous monitoring of miners and equipment. However, real world mining environments impose severe constraints, including poor illumination, GPS denied conditions, irregular underground topologies and intermittent connectivity. These factors degrade perception accuracy, disrupt situational awareness and weaken distributed learning systems. At the same time, emerging cyber physical threats such as backdoor triggers, sensor spoofing, label flipping attacks, and poisoned model updates further jeopardize operational safety as mines adopt autonomous vehicles, humanoid assistance, and federated learning for collaborative intelligence. Energy constrained sensors also experience uneven battery depletion, creating blind spots in safety coverage and disrupting hazard detection pipelines. This paper presents a vision for a Unified Smart Safety and Security Architecture that integrates multimodal perception, secure federated learning, reinforcement learning, DTN enabled communication, and energy aware sensing into a cohesive safety framework. We introduce five core modules: Miner Finder, Multimodal Situational Awareness, Backdoor Attack Monitor, TrustFed LFD, and IoT driven Equipment Health Monitoring. These modules collectively address miner localization, hazard understanding, federated robustness, and predictive maintenance. Together, they form an end to end framework capable of guiding miners through obstructed pathways, identifying compromised models or sensors, and ensuring mission critical equipment reliability. This work outlines a comprehensive research vision for building a resilient and trustworthy intelligent mining system capable of maintaining operational continuity under adversarial conditions.",
        "keywords": [
          "cs.CR",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11472v1",
        "authors": [
          "Md Sazedur Rahman",
          "Mizanur Rahman Jewel",
          "Sanjay Madria"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Situational Awareness",
        "Equipment Health Monitoring",
        "Backdoor Attack Monitor",
        "Security Architecture",
        "Unified Smart Safety",
        "Autonomous Vehicle",
        "Security Mining",
        "Future Mining",
        "Miner Finder",
        "Framework",
        "Battery",
        "Intel",
        "Act",
        "DTN",
        "LFD"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:15.399167"
    },
    {
      "id": "arxiv-2602.12178v1",
      "title": "Systematic Analysis of Penalty-Optimised Illumination Design for Tomographic Volumetric Additive Manufacturing via the Extendable Framework TVAM AID Using the Core Imaging Library",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12178v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Tomographic Volumetric Additive Manufacturing(TVAM) is a novel manufacturing method that allows for the fast creation of objects of complex geometry in layerless fashion. The process is based on the solidification of photopolymer that occurs when a sufficient threshold dose of light-energy is absorbed. In order to create complex shapes, an illumination plan must be designed to force solidification in some desired areas while leaving other regions liquid. Determining an illumination plan can be considered as an optimisation problem where a variety of objective functionals (penalties) can be used. This work considers a selection of penalty functions and their impact on selected printing metrics; linking the shape of penalty functions to ranges of light-energy dose levels in in-part regions that should be printed and out-of-part regions that should remain liquid. Further, the threshold parameters that are typically used to demarcate minimum light-energy for in-part regions and maximum light-energy for out-of-part regions are investigated systematically as design parameters on both existing and new methods. This enables the characterisation of their effects on some selected printing metrics as well as informed selection for default values. This work is underpinned by a reproducible and extensible framework, TVAM Adaptive Illumination Design(TVAM AID), which makes use of the open-source Core Imaging Library(CIL) that is designed for tomographic imaging with an emphasis on reconstruction. The foundation of TVAM AID which is presented here can hence be easily enhanced by existing functionality in CIL thus lowering the barrier to entry and encouraging use of strategies that already exist for reconstruction optimisation.",
        "keywords": [
          "cs.CE",
          "cs.MS",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12178v1",
        "authors": [
          "Nicole Pellizzon",
          "Richard Huber",
          "Jon Spangenberg",
          "Jakob Sauer Jørgensen"
        ],
        "arxiv_categories": [
          "cs.CE",
          "cs.MS",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tomographic Volumetric Additive Manufacturing",
        "Volumetric Additive Manufacturing",
        "Core Imaging Library Tomographic",
        "Optimised Illumination Design",
        "Adaptive Illumination Design",
        "Core Imaging Library",
        "Extendable Framework",
        "Systematic Analysis",
        "Framework",
        "TVAM",
        "Act",
        "AID",
        "CIL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.575482"
    },
    {
      "id": "arxiv-2602.12175v1",
      "title": "Improved Online Algorithms for Inventory Management Problems with Holding and Delay Costs: Riding the Wave Makes Things Simpler, Stronger, & More General",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12175v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Joint Replenishment Problem (JRP) is a classical inventory management problem, that aims to model the trade-off between coordinating orders for multiple commodities (and their cost) with holding costs incurred by meeting demand in advance. Moseley, Niaparast and Ravi introduced a natural online generalization of the JRP in which inventory corresponding to demands may be replenished late, for a delay cost, or early, for a holding cost. They established that when the holding and delay costs are monotone and uniform across demands, there is a 30-competitive algorithm that employs a greedy strategy and a dual-fitting based analysis. We develop a 5-competitive algorithm that handles arbitrary monotone demand-specific holding and delay cost functions, thus simultaneously improving upon the competitive ratio and relaxing the uniformity assumption. Our primal-dual algorithm is in the spirit of the work Buchbinder, Kimbrel, Levi, Makarychev, and Sviridenko, which maintains a wavefront dual solution to decide when to place an order and which items to order. The main twist is in deciding which requests to serve early. In contrast to the work of Moseley et al., which ranks early requests in ascending order of desired service time and serves them until their total holding cost matches the ordering cost incurred for that item, we extend to the non-uniform case by instead ranking in ascending order of when the delay cost of a demand would reach its current holding cost. An important special case of the JRP is the single-item lot-sizing problem. Here, Moseley et al. gave a 3-competitive algorithm when the holding and delay costs are uniform across demands. We provide a new algorithm for which the competitive ratio is $φ+1 \\approx 2.681$, where $φ$ is the golden ratio, which again holds for arbitrary monotone holding-delay costs.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12175v1",
        "authors": [
          "David Shmoys",
          "Varun Suriyanarayana",
          "Seeun William Umboh"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inventory Management Problems",
        "Improved Online Algorithms",
        "Wave Makes Things Simpler",
        "Replenishment Problem",
        "Delay Costs",
        "MIT",
        "JRP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.576903"
    },
    {
      "id": "arxiv-2602.12126v1",
      "title": "Optimizing Distances for Multi-Broadcast in Temporal Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12126v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Temporal graphs represent networks in which connections change over time, with edges available only at specific moments. Motivated by applications in logistics, multi-agent information spreading, and wireless networks, we introduce the D-Temporal Multi-Broadcast (D-TMB) problem, which asks for scheduling the availability of edges so that a predetermined subset of sources reach all other vertices while optimizing the worst-case temporal distance D from any source. We show that D-TMB generalizes ReachFast (arXiv:2112.08797). We then characterize the computational complexity and approximability of D-TMB under six definitions of temporal distance D, namely Earliest-Arrival (EA), Latest-Departure (LD), Fastest-Time (FT), Shortest-Traveling (ST), Minimum-Hop (MH), and Minimum-Waiting (MW). For a single source, we show that D-TMB can be solved in polynomial time for EA and LD, while for the other temporal distances it is NP-hard and hard to approximate within a factor that depends on the adopted distance function. We give approximation algorithms for FT and MW. For multiple sources, if feasibility is not assumed a priori, the problem is inapproximable within any factor unless P = NP, even with just two sources. We complement this negative result by identifying structural conditions that guarantee tractability for EA and LD for any number of sources.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12126v1",
        "authors": [
          "Daniele Carnevale",
          "Gianlorenzo D'Angelo"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Temporal Graphs Temporal",
        "Optimizing Distances",
        "Temporal Multi",
        "Act",
        "EPA",
        "TMB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.577357"
    },
    {
      "id": "arxiv-2602.12028v1",
      "title": "An Improved FPT Algorithm for Computing the Interleaving Distance between Merge Trees via Path-Preserving Maps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12028v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A merge tree is a fundamental topological structure used to capture the sub-level set (and similarly, super-level set) topology in scalar data analysis. The interleaving distance is a theoretically sound, stable metric for comparing merge trees. However, computing this distance exactly is NP-hard. First fixed-parameter tractable (FPT) algorithm for it's exact computation introduces the concept of an $\\varepsilon$-good map between two merge trees, where $\\varepsilon$ is a candidate value for the interleaving distance. The complexity of their algorithm is $O(2^{2τ}(2τ)^{2τ+2}\\cdot n^2\\log^3n)$ where $τ$ is the degree-bound parameter and $n$ is the total number of nodes in both the merge trees. Their algorithm exhibits exponential complexity in $τ$, which increases with the increasing value of $\\varepsilon$. In the current paper, we propose an improved FPT algorithm for computing the $\\varepsilon$-good map between two merge trees. Our algorithm introduces two new parameters, $η_f$ and $η_g$, corresponding to the numbers of leaf nodes in the merge trees $M_f$ and $M_g$, respectively. This parametrization is motivated by the observation that a merge tree can be decomposed into a collection of unique leaf-to-root paths. The proposed algorithm achieves a complexity of $O\\!\\left(n^2\\log n+η_g^{η_f}(η_f+η_g)\\, n \\log n \\right)$. To obtain this reduced complexity, we assume that number of possible $\\varepsilon$-good maps from $M_f$ to $M_g$ does not exceed that from $M_g$ to $M_f$. Notably, the parameters $η_f$ and $η_g$ are independent of the choice of $\\varepsilon$. Compared to their algorithm, our approach substantially reduces the search space for computing an optimal $\\varepsilon$-good map. We also provide a formal proof of correctness for the proposed algorithm.",
        "keywords": [
          "cs.CG",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12028v1",
        "authors": [
          "Althaf P",
          "Amit Chattopadhyay",
          "Osamu Saeki"
        ],
        "arxiv_categories": [
          "cs.CG",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interleaving Distance",
        "Preserving Maps",
        "Merge Trees",
        "An Improved",
        "Act",
        "FPT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.578675"
    },
    {
      "id": "arxiv-2602.11993v1",
      "title": "The Balanced Up-Down Walk",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11993v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Markov chains based on spanning trees have been hugely influential in algorithms for assessing fairness in political redistricting. The input graph represents the geographic building blocks of a jurisdiction. The goal is to output a large ensemble of random graph partitions, which is done by drawing and splitting random spanning trees. Crucially, these subtrees must be balanced, since political districts are required to have equal population. The Up-Down walk (on trees or forests) repeatedly adds a random edge then deletes a random edge to produce a new tree or forest; it can be used to efficiently generate a large ensemble, but the rejection rate to maintain balance grows exponentially with the number of parts. ReCom, the most widely-used class of Markov chains, circumvents this complexity barrier by merging and splitting pairs of districts at a time. This runs fast in practice but can have trouble exploring the state space. To overcome these efficiency and mixing barriers, we propose a new Markov chain called the Balanced Up-Down (BUD) walk. The main idea is to run the Up-Down walk on the space of trees, but require all steps to preserve the property that the tree is splittable into balanced subtrees. The BUD walk samples from a known invariant measure under exact balance. We prove that the BUD walk is irreducible in several cases, including a regime where ReCom is not irreducible. Running the BUD walk efficiently presents algorithmic challenges, especially when parts are allowed to deviate from their ideal size. A key subroutine is determining whether a tree is splittable into approximately-balanced subtrees. We give an improved analysis of an existing algorithm for this problem and prove that the associated counting problem is #P-complete. We empirically validate the usefulness of the BUD walk by comparing its performance to that of other existing methods for sampling partitions.",
        "keywords": [
          "cs.DM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11993v1",
        "authors": [
          "Hugo A. Akitaya",
          "Sarah Cannon",
          "Gregory Herschlag",
          "Gabe Schoenbach",
          "Kristopher Tapp"
        ],
        "arxiv_categories": [
          "cs.DM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Down Walk Markov",
        "Balanced Up",
        "Act",
        "BUD",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.579263"
    },
    {
      "id": "arxiv-2602.11975v1",
      "title": "Beyond Bilinear Complexity: What Works and What Breaks with Many Modes?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11975v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The complexity of bilinear maps (equivalently, of $3$-mode tensors) has been studied extensively, most notably in the context of matrix multiplication. While circuit complexity and tensor rank coincide asymptotically for $3$-mode tensors, this correspondence breaks down for $d \\geq 4$ modes. As a result, the complexity of $d$-mode tensors for larger fixed $d$ remains poorly understood, despite its relevance, e.g., in fine-grained complexity. Our paper explores this intermediate regime. First, we give a \"graph-theoretic\" proof of Strassen's $2ω/3$ bound on the asymptotic rank exponent of $3$-mode tensors. Our proof directly generalizes to an upper bound of $(d-1)ω/3$ for $d$-mode tensors. Using refined techniques available only for $d\\geq 4$ modes, we improve this bound beyond the current state of the art for $ω$. We also obtain a bound of $d/2+1$ on the asymptotic exponent of circuit complexity of generic $d$-mode tensors and optimized bounds for $d \\in \\{4,5\\}$. To the best of our knowledge, asymptotic circuit complexity (rather than rank) of tensors has not been studied before. To obtain a robust theory, we first ask whether low complexity of $T$ and $U$ imply low complexity of their Kronecker product $T \\otimes U$. While this crucially holds for rank (and thus for circuit complexity in $3$ modes), we show that assumptions from fine-grained complexity rule out such a submultiplicativity for the circuit complexity of tensors with many modes. In particular, assuming the Hyperclique Conjecture, this failure occurs already for $d=8$ modes. Nevertheless, we can salvage a restricted notion of submultiplicativity. From a technical perspective, our proofs heavily make use of the graph tensors $T_H$, as employed by Christandl and Zuiddam ({\\em Comput.~Complexity}~28~(2019)~27--56) and [...]",
        "keywords": [
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11975v1",
        "authors": [
          "Cornelius Brand",
          "Radu Curticapean",
          "Petteri Kaski",
          "Baitian Li",
          "Ian Orzel"
        ],
        "arxiv_categories": [
          "cs.CC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Beyond Bilinear Complexity",
        "Hyperclique Conjecture",
        "What Breaks",
        "Many Modes",
        "What Works",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.580557"
    },
    {
      "id": "arxiv-2602.11953v1",
      "title": "History-Independent Load Balancing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11953v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We give a (strongly) history-independent two-choice balls-and-bins algorithm on $n$ bins that supports both insertions and deletions on a set of up to $m$ balls, while guaranteeing a maximum load of $m / n + O(1)$ with high probability, and achieving an expected recourse of $O(\\log \\log (m/n))$ per operation. To the best of our knowledge, this is the first history-independent solution to achieve nontrivial guarantees of any sort for $m/n \\ge ω(1)$ and is the first fully dynamic solution (history independent or not) to achieve $O(1)$ overload with $o(m/n)$ expected recourse.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11953v1",
        "authors": [
          "Michael A. Bender",
          "William Kuszmaul",
          "Elaine Shi",
          "Rose Silver"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Independent Load Balancing We"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.581014"
    },
    {
      "id": "arxiv-2602.11843v1",
      "title": "Fast Evaluation of Truncated Neumann Series by Low-Product Radix Kernels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11843v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Truncated Neumann series $S_k(A)=I+A+\\cdots+A^{k-1}$ are used in approximate matrix inversion and polynomial preconditioning. In dense settings, matrix-matrix products dominate the cost of evaluating $S_k$. Naive evaluation needs $k-1$ products, while splitting methods reduce this to $O(\\log k)$. Repeated squaring, for example, uses $2\\log_2 k$ products, so further gains require higher-radix kernels that extend the series by $m$ terms per update. Beyond the known radix-5 kernel, explicit higher-radix constructions were not available, and the existence of exact rational kernels was unclear. We construct radix kernels for $T_m(B)=I+B+\\cdots+B^{m-1}$ and use them to build faster series algorithms. For radix 9, we derive an exact 3-product kernel with rational coefficients, which is the first exact construction beyond radix 5. This kernel yields $5\\log_9 k=1.58\\log_2 k$ products, a 21% reduction from repeated squaring. For radix 15, numerical optimization yields a 4-product kernel that matches the target through degree 14 but has nonzero spillover (extra terms) at degrees $\\ge 15$. Because spillover breaks the standard telescoping update, we introduce a residual-based radix-kernel framework that accommodates approximate kernels and retains coefficient $(μ_m+2)/\\log_2 m$. Within this framework, radix 15 attains $6/\\log_2 15\\approx 1.54$, the best known asymptotic rate. Numerical experiments support the predicted product-count savings and associated runtime trends.",
        "keywords": [
          "math.NA",
          "cs.MS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11843v1",
        "authors": [
          "Piyush Sao"
        ],
        "arxiv_categories": [
          "math.NA",
          "cs.MS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Product Radix Kernels Truncated",
        "Truncated Neumann Series",
        "Fast Evaluation",
        "Framework",
        "Standard",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.581987"
    },
    {
      "id": "arxiv-2602.11826v1",
      "title": "Combinatorial Perpetual Scheduling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11826v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper introduces a framework for combinatorial variants of perpetual-scheduling problems. Given a set system $(E,\\mathcal{I})$, a schedule consists of an independent set $I_t \\in \\mathcal{I}$ for every time step $t \\in \\mathbb{N}$, with the objective of fulfilling frequency requirements on the occurrence of elements in $E$. We focus specifically on combinatorial bamboo garden trimming, where elements accumulate height at growth rates $g(e)$ for $e \\in E$ given as a convex combination of incidence vectors of $\\mathcal{I}$ and are reset to zero when scheduled, with the goal of minimizing the maximum height attained by any element. Using the integrality of the matroid-intersection polytope, we prove that, when $(E,\\mathcal{I})$ is a matroid, it is possible to guarantee a maximum height of at most 2, which is optimal. We complement this existential result with efficient algorithms for specific matroid classes, achieving a maximum height of 2 for uniform and partition matroids, and 4 for graphic and laminar matroids. In contrast, we show that for general set systems, the optimal guaranteed height is $Θ(\\log |E|)$ and can be achieved by an efficient algorithm. For combinatorial pinwheel scheduling, where each element $e\\in E$ needs to occur in the schedule at least every $a_e \\in \\mathbb{N}$ time steps, our results imply bounds on the density sufficient for schedulability.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11826v1",
        "authors": [
          "Mirabel Mendoza-Cadena",
          "Arturo Merino",
          "Mads Anker Nielsen",
          "Kevin Schewior"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.582847"
    },
    {
      "id": "arxiv-2602.11796v1",
      "title": "Frankl's diversity theorem for permutations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11796v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In 1987, Frankl proved an influential stability result for the Erd\\H os--Ko--Rado theorem, which bounds the size of an intersecting family in terms of its distance from the nearest (subset of) star or trivial intersecting family. It is a far-reaching extension of the Hilton--Milner theorem. In this paper, we prove its analogue for permutations on $\\{1,\\ldots, n\\}$, provided $n$ is large. This provides a similar extension of a Hilton--Milner type result for permutations proved by Ellis.",
        "keywords": [
          "math.CO",
          "cs.DM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11796v1",
        "authors": [
          "Eduard Inozemtsev",
          "Andrey Kupavskii"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.583029"
    },
    {
      "id": "arxiv-2602.11791v1",
      "title": "Gray Codes With Constant Delay and Constant Auxiliary Space",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11791v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We give the first two algorithms to enumerate all binary words of $\\{0,1\\}^\\ell$ (like Gray codes) while ensuring that the delay and the auxiliary space is independent from $\\ell$, i.e., constant time for each word, and constant memory in addition to the $\\ell$ bits storing the current word. Our algorithms are given in two new computational models: tape machines and deque machines. We also study more restricted models, queue machines and stack machines, and show that they cannot enumerate all binary words with constant auxiliary space, even with unrestricted delay. A tape machine is a Turing machine that stores the current binary word on a single working tape of length $\\ell$. The machine has a single head and must edit its tape to reach all possible words of $\\{0,1\\}^{\\ell}$ , and output them (in unit time, by entering special output states), with no duplicates. We construct a tape machine that achieves this task with constant delay between consecutive outputs, which implies that the machine implements a so-called skew-tolerant quasi-Gray code. We then construct a more involved tape machine that implements a Gray code. A deque machine stores the current binary word on a double-ended queue of length $\\ell$, and stores a constant-size internal state. It works as a tape machine, except that it modifies the content of the deque by performing push and pop operations on the endpoints. We construct deque machines that enumerate all words of $\\{0,1\\}^\\ell$ with constant-delay. The main technical challenge in this model is to correctly detect when enumeration has finished. Our work on deque machine is also motivated by other contexts in which endpoint modifications occur naturally. In particular, our result is a first step towards enumerating walks in directed graphs with constant delay and constant auxiliary space, addressing a core task in modern graph database query processing.",
        "keywords": [
          "cs.DS",
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11791v1",
        "authors": [
          "Antoine Amarilli",
          "Claire David",
          "Nadime Francis",
          "Victor Marsault",
          "Mikaël Monet"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.CC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constant Auxiliary Space We",
        "Gray Codes With Constant",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.583538"
    },
    {
      "id": "arxiv-2602.11773v1",
      "title": "A Note on the Complexity of Directed Clique",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11773v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "For a directed graph $G$, and a linear order $\\ll$ on the vertices of $G$, we define backedge graph $G^\\ll$ to be the undirected graph on the same vertex set with edge $\\{u,w\\}$ in $G^\\ll$ if and only if $(u,w)$ is an arc in $G$ and $w \\ll u$. The directed clique number of a directed graph $G$ is defined as the minimum size of the maximum clique in the backedge graph $G^\\ll$ taken over all linear orders $\\ll$ on the vertices of $G$. A natural computational problem is to decide for a given directed graph $G$ and a positive integer $t$, if the directed clique number of $G$ is at most $t$. This problem has polynomial algorithm for $t=1$ and is known to be \\NP-complete for every fixed $t\\ge3$, even for tournaments. In this note we prove that this problem is $Σ^\\mathsf{P}_{2}$-complete when $t$ is given on the input.",
        "keywords": [
          "cs.CC",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11773v1",
        "authors": [
          "Grzegorz Gutowski",
          "Mikołaj Rams"
        ],
        "arxiv_categories": [
          "cs.CC",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Directed Clique For",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.584090"
    },
    {
      "id": "arxiv-2602.11716v1",
      "title": "Cycles of Well-Linked Sets II: an Elementary Bound for the Directed Grid Theorem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11716v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In 2015, Kawarabayashi and Kreutzer proved the Directed Grid Theorem - the generalisation of the well-known Excluded Grid Theorem to directed graphs - confirming a conjecture by Reed, Johnson, Robertson, Seymour and Thomas from the mid-nineties. The theorem states that there is a function $f$ such that every digraph of directed treewidth $f(k)$ contains a cylindrical grid of order $k$ as a butterfly minor. However, the given function grows faster than any non-elementary function of the size of the grid minor. More precisely, it is larger than a power tower whose height depends on the size of the grid. In this paper, we present an alternative proof of the Directed Grid Theorem which is conceptually much simpler, more modular in composition and improves the upper bound for the function $f$ to a power tower of height $22$. A key concept of our proof is a new structure called cycles of well-linked sets (CWS). We show that any digraph of large directed treewidth contains a large CWS, which in turn contains a large cylindrical grid.",
        "keywords": [
          "cs.DM",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11716v1",
        "authors": [
          "Meike Hatzel",
          "Stephan Kreutzer",
          "Marcelo Garlet Milani",
          "Irene Muzi"
        ],
        "arxiv_categories": [
          "cs.DM",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Elementary Bound",
        "Linked Sets",
        "BERT",
        "WHO",
        "CWS",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.584407"
    },
    {
      "id": "arxiv-2602.11476v1",
      "title": "Bounded Local Generator Classes for Deterministic State Evolution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11476v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We formalize a constructive subclass of locality-preserving deterministic operators acting on graph-indexed state systems. We define the class of Bounded Local Generator Classes (BLGC), consisting of finite-range generators operating on bounded state spaces under deterministic composition. Within this class, incremental update cost is independent of total system dimension. We prove that, under the BLGC assumptions, per-step operator work satisfies W_t = O(1) as the number of nodes M \\to \\infty, establishing a structural decoupling between global state size and incremental computational effort. The framework admits a Hilbert-space embedding in \\ell^2(V; \\mathbb{R}^d) and yields bounded operator norms on admissible subspaces. The result applies specifically to the defined subclass and does not claim universality beyond the stated locality and boundedness constraints.",
        "keywords": [
          "cs.OS",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11476v1",
        "authors": [
          "R. Jay Martin"
        ],
        "arxiv_categories": [
          "cs.OS",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deterministic State Evolution We",
        "Bounded Local Generator Classes",
        "Framework",
        "NIST",
        "BERT",
        "BLGC",
        "Act",
        "MIT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.584667"
    },
    {
      "id": "arxiv-2602.11454v1",
      "title": "Adaptive Power Iteration Method for Differentially Private PCA",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11454v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study $(ε,δ)$-differentially private algorithms for the problem of approximately computing the top singular vector of a matrix $A\\in\\mathbb{R}^{n\\times d}$ where each row of $A$ is a datapoint in $\\mathbb{R}^{d}$. In our privacy model, neighboring inputs differ by one single row/datapoint. We study the private variant of the power iteration method, which is widely adopted in practice. Our algorithm is based on a filtering technique which adapts to the coherence parameter of the input matrix. This technique provides a utility that goes beyond the worst-case guarantees for matrices with low coherence parameter. Our work departs from and complements the work by Hardt-Roth (STOC 2013) which designed a private power iteration method for the privacy model where neighboring inputs differ in one single entry by at most 1.",
        "keywords": [
          "cs.DS",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11454v1",
        "authors": [
          "Ta Duy Nguyem",
          "Alina Ene",
          "Huy Le Nguyen"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adaptive Power Iteration Method",
        "Differentially Private",
        "STOC",
        "Act",
        "EPA",
        "PCA"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:19.585226"
    },
    {
      "id": "arxiv-2602.12242v1",
      "title": "MagneX: A High-Performance, GPU-Enabled, Data-Driven Micromagnetics Solver for Spintronics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12242v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In order to comprehensively investigate the multiphysics coupling in spintronic devices, it is essential to parallelize and utilize GPU-acceleration to address the spatial and temporal disparities inherent in the relevant physics. Additionally, the use of cutting-edge time integration libraries as well as machine learning (ML) approaches to replace and potentially accelerate expensive computational routines are attractive capabilities to enhance modeling capabilities moving forward. Leveraging the Exascale Computing Project software framework AMReX, as well as SUNDIALS time-integration libraries and python-based ML workflows, we have developed an open-source micromagnetics modeling tool called MagneX. This tool incorporates various crucial magnetic coupling mechanisms, including Zeeman coupling, demagnetization coupling, crystalline anisotropy interaction, exchange coupling, and Dzyaloshinskii-Moriya interaction (DMI) coupling. We demonstrate the GPU performance and scalability of the code and rigorously validate MagneX's functionality using the mumag standard problems and widely-accepted DMI benchmarks. Furthermore, we demonstrate the data-driven capability of MagneX by replacing the computationally-expensive demagnetization physics with neural network libraries trained from our simulation data. With the capacity to explore complete physical interactions, this innovative approach offers a promising pathway to better understand and develop fully integrated spintronic and electronic systems.",
        "keywords": [
          "cs.CE",
          "cond-mat.other"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12242v1",
        "authors": [
          "Andy Nonaka",
          "Yingheng Tang",
          "Julian C. LePelch",
          "Prabhat Kumar",
          "Weiqun Zhang"
        ],
        "arxiv_categories": [
          "cs.CE",
          "cond-mat.other"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Micromagnetics Solver",
        "Exascale Computing Project",
        "Machine Learning",
        "Spintronics In",
        "Neural Network",
        "Framework",
        "Standard",
        "Act",
        "GPU",
        "DMI",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.772176"
    },
    {
      "id": "arxiv-2602.12220v1",
      "title": "Taming Subpacketization without Sacrificing Communication: A Packet Type-based Framework for D2D Coded Caching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12220v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Finite-length analysis is critical for bringing coded caching closer to practical deployment. In this work, we study the design of communication rate-optimal device-to-device (D2D) coded caching schemes with minimal subpacketization levels, a key bottleneck in finite-length settings. We present a novel \\tit{packet type-based} (PT) design framework that (i) strategically introduces \\tit{asymmetry} into file splitting through user grouping, and (ii) systematically exploits such asymmetry in both cache placement and multicast delivery to create subpacketization reduction opportunities. In particular, the induced asymmetry gives rise to two fundamental forms of subpacketization reduction gains: the \\emph{subfile saving gain}, achieved by eliminating certain types of subfiles through careful user grouping and transmitter selection, and the \\emph{further splitting saving gain}, attained by reducing the splitting granularity for the remaining subfiles. The combined effect of these two reduction gains yields an overall subpacketization improvement over the original Ji-Caire-Molisch (JCM) caching scheme~\\cite{ji2016fundamental}, as well as various state-of-the-art schemes, while preserving optimal communication rates. Under the PT framework, we formulate the caching scheme design as an integer linear program (ILP), where each feasible solution corresponds to a valid rate-optimal D2D coded caching scheme with potentially reduced subpacketization relative to the JCM baseline.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12220v1",
        "authors": [
          "Xiang Zhang",
          "Giuseppe Caire",
          "Mingyue Ji"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sacrificing Communication",
        "Taming Subpacketization",
        "Coded Caching Finite",
        "Packet Type",
        "Framework",
        "Act",
        "MIT",
        "JCM",
        "ILP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.772606"
    },
    {
      "id": "arxiv-2602.12206v1",
      "title": "Making the complete OpenAIRE citation graph easily accessible through compact data representation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12206v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The OpenAIRE graph contains a large citation graph dataset, with over 200 million publications and over 2 billion citations. The current graph is available as a dump with metadata which uncompressed totals ~TB. This makes it hard to process on conventional computers. To make this network more available for the community we provide a processed OpenAIRE graph which is downscaled to 32GB, while preserving the full graph structure. Apart from this we offer the processed data in very simple format, which allows further straightforward manipulation. We also provide a python pipeline, which can be used to process the next releases of the OpenAIRE graph.",
        "keywords": [
          "cs.SI",
          "cs.DL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12206v1",
        "authors": [
          "Joakim Skarding",
          "Pavel Sanda"
        ],
        "arxiv_categories": [
          "cs.SI",
          "cs.DL"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "OpenAI",
        "Meta",
        "Bill",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:23.772810"
    },
    {
      "id": "arxiv-2602.12182v1",
      "title": "Rate-Reliability Tradeoff for Deterministic Identification over Gaussian Channels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12182v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We extend the recent analysis of the rate-reliability tradeoff in deterministic identification (DI) to general linear Gaussian channels, marking the first such analysis for channels with continuous output. Because DI provides a framework that can substantially enhance communication efficiency, and since the linear Gaussian model underlies a broad range of physical communication systems, our results offer both theoretical insights and practical relevance for the performance evaluation of DI in future networks. Moreover, the structural parallels observed between the Gaussian and discrete-output cases suggest that similar rate-reliability behaviour may extend to wider classes of continuous channels.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12182v1",
        "authors": [
          "Pau Colomer",
          "Christian Deppe",
          "Holger Boche",
          "Andreas Winter"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deterministic Identification",
        "Reliability Tradeoff",
        "Gaussian Channels We",
        "Framework",
        "NIST",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.773076"
    },
    {
      "id": "arxiv-2602.12064v1",
      "title": "DIVER: A Robust Text-to-SQL System with Dynamic Interactive Value Linking and Evidence Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12064v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the era of large language models, Text-to-SQL, as a natural language interface for databases, is playing an increasingly important role. The sota Text-to-SQL models have achieved impressive accuracy, but their performance critically relies on expert-written evidence, which typically clarifies schema and value linking that existing models struggle to identify. Such limitations stem from the ambiguity of user queries and, more importantly, the complexity of comprehending large-scale and dynamic database values. Consequently, in real-world scenarios where expert assistance is unavailable, existing methods suffer a severe performance collapse, with execution accuracy dropping by over 10%. This underscores their lack of robustness. To address this, we propose DIVER, a robust system that automates evidence reasoning with dynamic interactive value linking. It leverages a compatible toolbox containing diverse tools to probe the database. Then, restricted by a structured workspace (CoTF, Chain of Thoughts and Facts), it reflects based on probe results and selects a new tool for next round of probing. Through this automatically iterative process, DIVER identifies schema and value linking missed by existing methods. Based on these accurate linkings, DIVER is able to infer correct usage of SQL functions and formulas and generate high-quality evidence, achieving robust Text-to-SQL without expert assistance. Extensive experiments demonstrate that: 1) The DIVER system significantly enhances the robustness of various Text-to-SQL models, improving performance by up to 10.82% in Execution Accuracy (EX) and 16.09% in Valid Efficiency Score (VES). 2) Our dynamic interactive value linking significantly improves the robustness of existing systems and the accuracy of schema and value linking, especially when confronted with challenges posed by large-scale, dynamic database values.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12064v1",
        "authors": [
          "Yafeng Nan",
          "Haifeng Sun",
          "Zirui Zhuang",
          "Qi Qi",
          "Guojun Chu"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Interactive Value Linking",
        "Valid Efficiency Score",
        "Evidence Reasoning In",
        "Execution Accuracy",
        "Robust Text",
        "DIVER",
        "SQL",
        "Act",
        "MIT",
        "VES",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.773776"
    },
    {
      "id": "arxiv-2602.12041v1",
      "title": "Compress, Cross and Scale: Multi-Level Compression Cross Networks for Efficient Scaling in Recommender Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12041v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Modeling high-order feature interactions efficiently is a central challenge in click-through rate and conversion rate prediction. Modern industrial recommender systems are predominantly built upon deep learning recommendation models, where the interaction backbone plays a critical role in determining both predictive performance and system efficiency. However, existing interaction modules often struggle to simultaneously achieve strong interaction capacity, high computational efficiency, and good scalability, resulting in limited ROI when models are scaled under strict production constraints. In this work, we propose MLCC, a structured feature interaction architecture that organizes feature crosses through hierarchical compression and dynamic composition, which can efficiently capture high-order feature dependencies while maintaining favorable computational complexity. We further introduce MC-MLCC, a Multi-Channel extension that decomposes feature interactions into parallel subspaces, enabling efficient horizontal scaling with improved representation capacity and significantly reduced parameter growth. Extensive experiments on three public benchmarks and a large-scale industrial dataset show that our proposed models consistently outperform strong DLRM-style baselines by up to 0.52 AUC, while reducing model parameters and FLOPs by up to 26$\\times$ under comparable performance. Comprehensive scaling analyses demonstrate stable and predictable scaling behavior across embedding dimension, head number, and channel count, with channel-based scaling achieving substantially better efficiency than conventional embedding inflation. Finally, online A/B testing on a real-world advertising platform validates the practical effectiveness of our approach, which has been widely adopted in Bilibili advertising system under strict latency and resource constraints.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12041v1",
        "authors": [
          "Heng Yu",
          "Xiangjun Zhou",
          "Jie Xia",
          "Heng Zhao",
          "Anxin Wu"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Compression Cross Networks",
        "Recommender Systems Modeling",
        "Efficient Scaling",
        "Deep Learning",
        "DLRM",
        "MLCC",
        "Act",
        "ROI",
        "MIT",
        "AUC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.774198"
    },
    {
      "id": "arxiv-2602.11986v1",
      "title": "Achievability Bounds of Coding with Finite Blocklength for Gaussian Broadcast Channels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11986v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we study the achievable performance of dirty paper coding for the Gaussian broadcast channel (BC) with finite blocklength and we propose two different achievability bounds for this problem. We present the broadcast adaptation of dependence testing bound of Polyanskiy et al. 2010, which is an upper bound on the average error probability that depends on the channel dispersion terms of each error event for fixed input. Additionally, we introduce the $κβ$ lower bounds on the maximal code sizes of each user using dirty paper coding.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11986v1",
        "authors": [
          "Ayşe Ünsal",
          "Jean-Marie Gorce"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Broadcast Channels In",
        "Achievability Bounds",
        "Finite Blocklength",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.774540"
    },
    {
      "id": "arxiv-2602.11969v1",
      "title": "UPDA: Unsupervised Progressive Domain Adaptation for No-Reference Point Cloud Quality Assessment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11969v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "While no-reference point cloud quality assessment (NR-PCQA) approaches have achieved significant progress over the past decade, their performance often degrades substantially when a distribution gap exists between the training (source domain) and testing (target domain) data. However, to date, limited attention has been paid to transferring NR-PCQA models across domains. To address this challenge, we propose the first unsupervised progressive domain adaptation (UPDA) framework for NR-PCQA, which introduces a two-stage coarse-to-fine alignment paradigm to address domain shifts. At the coarse-grained stage, a discrepancy-aware coarse-grained alignment method is designed to capture relative quality relationships between cross-domain samples through a novel quality-discrepancy-aware hybrid loss, circumventing the challenges of direct absolute feature alignment. At the fine-grained stage, a perception fusion fine-grained alignment approach with symmetric feature fusion is developed to identify domain-invariant features, while a conditional discriminator selectively enhances the transfer of quality-relevant features. Extensive experiments demonstrate that the proposed UPDA effectively enhances the performance of NR-PCQA methods in cross-domain scenarios, validating its practical applicability. The code is available at https://github.com/yokeno1/UPDA-main.",
        "keywords": [
          "eess.IV",
          "cs.CV",
          "cs.MM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11969v1",
        "authors": [
          "Bingxu Xie",
          "Fang Zhou",
          "Jincan Wu",
          "Yonghui Liu",
          "Weiqing Li"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.CV",
          "cs.MM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unsupervised Progressive Domain Adaptation",
        "Reference Point Cloud Quality",
        "Assessment While",
        "Framework",
        "Fusion",
        "PCQA",
        "UPDA",
        "Act",
        "NSF",
        "EPA",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.774849"
    },
    {
      "id": "arxiv-2602.11951v1",
      "title": "Robust Composite DNA Storage under Sampling Randomness, Substitution, and Insertion-Deletion Errors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11951v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "DNA data storage offers a high-density, long-term alternative to traditional storage systems, addressing the exponential growth of digital data. Composite DNA extends this paradigm by leveraging mixtures of nucleotides to increase storage capacity beyond the four standard bases. In this work, we model composite DNA storage as a multinomial channel and draw an analogy to digital modulation by representing composite letters on the three-dimensional probability simplex. To mitigate errors caused by sampling randomness, we derive transition probabilities and log-likelihood ratios (LLRs) for each constellation point and employ practical channel codes for error correction. We then extend this framework to substitution and insertion-deletion (ID) channels, proposing constellation update rules that account for these additional impairments. Numerical results demonstrate that our approach achieves reliable performance with existing LDPC codes, compared to the prior schemes designed for limited-magnitude probability errors, whose performance degrades significantly under sampling randomness.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11951v1",
        "authors": [
          "Busra Tegin",
          "Tolga M Duman"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sampling Randomness",
        "Robust Composite",
        "Deletion Errors",
        "Framework",
        "Standard",
        "LDPC",
        "Act",
        "WHO",
        "DNA",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.775104"
    },
    {
      "id": "arxiv-2602.11946v1",
      "title": "Towards a Sustainable Age of Information Metric: Carbon Footprint of Real-Time Status Updates",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11946v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The timeliness of collected information is essential for monitoring and control in data-driven intelligent infrastructures. It is typically quantified using the Age of Information (AoI) metric, which has been widely adopted to capture the freshness of information received in the form of status updates. While AoI-based metrics quantify how timely the collected information is, they largely overlook the environmental impact associated with frequent transmissions, specifically, the resulting Carbon Footprint (CF). To address this gap, we introduce a carbon-aware AoI framework. We first derive closed-form expressions for the average AoI under constrained CF budgets for the baseline $M/M/1$ and $M/M/1^*$ queuing models, assuming fixed Carbon Intensity (CI). We then extend the analysis by treating CI as a dynamic, time-varying parameter and solve the AoI minimization problem. Our results show that minimizing AoI does not inherently minimize CF, highlighting a clear trade-off between information freshness and environmental impact. CI variability further affects achievable AoI, indicating that sustainable operation requires joint optimization of CF budgets, Signal-to-noise Ratio (SNR), and transmission scheduling. This work lays the foundation for carbon-aware information freshness optimization in next-generation networks.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11946v1",
        "authors": [
          "Shih-Kai Chou",
          "Maice Costa",
          "Mihael Mohorčič",
          "Jernej Hribar"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Information Metric",
        "Carbon Intensity",
        "Carbon Footprint",
        "Sustainable Age",
        "Framework",
        "Intel",
        "Act",
        "SNR",
        "DOE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.775450"
    },
    {
      "id": "arxiv-2602.11941v1",
      "title": "IncompeBench: A Permissively Licensed, Fine-Grained Benchmark for Music Information Retrieval",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11941v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Multimodal Information Retrieval has made significant progress in recent years, leveraging the increasingly strong multimodal abilities of deep pre-trained models to represent information across modalities. Music Information Retrieval (MIR), in particular, has considerably increased in quality, with neural representations of music even making its way into everyday life products. However, there is a lack of high-quality benchmarks for evaluating music retrieval performance. To address this issue, we introduce \\textbf{IncompeBench}, a carefully annotated benchmark comprising $1,574$ permissively licensed, high-quality music snippets, $500$ diverse queries, and over $125,000$ individual relevance judgements. These annotations were created through the use of a multi-stage pipeline, resulting in high agreement between human annotators and the generated data. The resulting datasets are publicly available at https://huggingface.co/datasets/mixedbread-ai/incompebench-strict and https://huggingface.co/datasets/mixedbread-ai/incompebench-lenient with the prompts available at https://github.com/mixedbread-ai/incompebench-programs.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11941v1",
        "authors": [
          "Benjamin Clavié",
          "Atoof Shakir",
          "Jonah Turner",
          "Sean Lee",
          "Aamir Shakir"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Music Information Retrieval Multimodal",
        "Music Information Retrieval",
        "Permissively Licensed",
        "Information Retrieval",
        "Grained Benchmark",
        "Agreement",
        "MIR",
        "AI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.775716"
    },
    {
      "id": "arxiv-2602.11910v1",
      "title": "TADA! Tuning Audio Diffusion Models through Activation Steering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11910v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Audio diffusion models can synthesize high-fidelity music from text, yet their internal mechanisms for representing high-level concepts remain poorly understood. In this work, we use activation patching to demonstrate that distinct semantic musical concepts, such as the presence of specific instruments, vocals, or genre characteristics, are controlled by a small, shared subset of attention layers in state-of-the-art audio diffusion architectures. Next, we demonstrate that applying Contrastive Activation Addition and Sparse Autoencoders in these layers enables more precise control over the generated audio, indicating a direct benefit of the specialization phenomenon. By steering activations of the identified layers, we can alter specific musical elements with high precision, such as modulating tempo or changing a track's mood.",
        "keywords": [
          "cs.SD",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11910v1",
        "authors": [
          "Łukasz Staniszewski",
          "Katarzyna Zaleska",
          "Mateusz Modrzejewski",
          "Kamil Deja"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Contrastive Activation Addition",
        "Tuning Audio Diffusion Models",
        "Activation Steering Audio",
        "Sparse Autoencoders",
        "Fusion",
        "TADA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.775923"
    },
    {
      "id": "arxiv-2602.11909v1",
      "title": "Echo: Towards Advanced Audio Comprehension via Audio-Interleaved Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11909v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The maturation of Large Audio Language Models (LALMs) has raised growing expectations for them to comprehend complex audio much like humans. Current efforts primarily replicate text-based reasoning by contextualizing audio content through a one-time encoding, which introduces a critical information bottleneck. Drawing inspiration from human cognition, we propose audio-interleaved reasoning to break through this bottleneck. It treats audio as an active reasoning component, enabling sustained audio engagement and perception-grounded analysis. To instantiate it, we introduce a two-stage training framework, first teaching LALMs to localize salient audio segments through supervised fine-tuning, and then incentivizing proficient re-listening via reinforcement learning. In parallel, a structured data generation pipeline is developed to produce high-quality training data. Consequently, we present Echo, a LALM capable of dynamically re-listening to audio in demand during reasoning. On audio comprehension benchmarks, Echo achieves overall superiority in both challenging expert-level and general-purpose tasks. Comprehensive analysis further confirms the efficiency and generalizability of audio-interleaved reasoning, establishing it as a promising direction for advancing audio comprehension. Project page: https://github.com/wdqqdw/Echo.",
        "keywords": [
          "cs.SD",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11909v1",
        "authors": [
          "Daiqing Wu",
          "Xuan Zhang",
          "Dongbao Yang",
          "Jiashu Yao",
          "Longfei Chen"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Towards Advanced Audio Comprehension",
        "Large Audio Language Models",
        "Framework",
        "LALM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.776229"
    },
    {
      "id": "arxiv-2602.11903v1",
      "title": "Learning Perceptual Representations for Gaming NR-VQA with Multi-Task FR Signals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11903v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "No-reference video quality assessment (NR-VQA) for gaming videos is challenging due to limited human-rated datasets and unique content characteristics including fast motion, stylized graphics, and compression artifacts. We present MTL-VQA, a multi-task learning framework that uses full-reference metrics as supervisory signals to learn perceptually meaningful features without human labels for pretraining. By jointly optimizing multiple full-reference (FR) objectives with adaptive task weighting, our approach learns shared representations that transfer effectively to NR-VQA. Experiments on gaming video datasets show MTL-VQA achieves performance competitive with state-of-the-art NR-VQA methods across both MOS-supervised and label-efficient/self-supervised settings.",
        "keywords": [
          "eess.IV",
          "cs.CV",
          "cs.MM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11903v1",
        "authors": [
          "Yu-Chih Chen",
          "Michael Wang",
          "Chieh-Dun Wen",
          "Kai-Siang Ma",
          "Avinab Saha"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.CV",
          "cs.MM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Perceptual Representations",
        "Signals No",
        "Framework",
        "Act",
        "NSF",
        "VQA",
        "MIT",
        "MOS",
        "MTL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.776433"
    },
    {
      "id": "arxiv-2602.11901v1",
      "title": "On Fundamental Limits of Transmission Activity Detection in Fluid Antenna Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11901v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this letter, we develop a unified Cramér-Rao bound (CRB) framework to characterize the fundamental performance limits of transmission activity detection in fluid antenna systems (FASs) and conventional multiple fixed-position antenna (FPA) systems. To facilitate CRB analysis applicable to activity indicators, we relax the binary activity states to continuous parameters, thereby aligning the bound-based evaluation with practical threshold-based detection decisions. Closed-form CRB expressions are derived for two representative detection formulations, namely covariance-oriented and coherent models. Moreover, for single-antenna FASs, we obtain a closed-form coherent CRB by leveraging random matrix theory. The results demonstrate that CRB-based analysis provides a tractable and informative benchmark for evaluating activity detection across architectures and detection schemes, and further reveal that FASs can deliver strong spatial-diversity gains with significantly reduced complexity.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11901v1",
        "authors": [
          "Zhentian Zhang",
          "Kai-Kit Wong",
          "Hao Jiang",
          "Christos Masouros",
          "Chan-Byoung Chae"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Transmission Activity Detection",
        "Fluid Antenna Systems In",
        "On Fundamental Limits",
        "Framework",
        "Act",
        "FPA",
        "MIT",
        "CRB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.776891"
    },
    {
      "id": "arxiv-2602.11896v1",
      "title": "Musical Metamerism with Time--Frequency Scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11896v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The concept of metamerism originates from colorimetry, where it describes a sensation of visual similarity between two colored lights despite significant differences in spectral content. Likewise, we propose to call ``musical metamerism'' the sensation of auditory similarity which is elicited by two music fragments which differ in terms of underlying waveforms. In this technical report, we describe a method to generate musical metamers from any audio recording. Our method is based on joint time--frequency scattering in Kymatio, an open-source software in Python which enables GPU computing and automatic differentiation. The advantage of our method is that it does not require any manual preprocessing, such as transcription, beat tracking, or source separation. We provide a mathematical description of JTFS as well as some excerpts from the Kymatio source code. Lastly, we review the prior work on JTFS and draw connections with closely related algorithms, such as spectrotemporal receptive fields (STRF), modulation power spectra (MPS), and Gabor filterbank (GBFB).",
        "keywords": [
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11896v1",
        "authors": [
          "Vincent Lostanlen",
          "Han Han"
        ],
        "arxiv_categories": [
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Musical Metamerism",
        "Meta",
        "GBFB",
        "JTFS",
        "STRF",
        "EPA",
        "MPS",
        "GPU",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.777136"
    },
    {
      "id": "arxiv-2602.11874v1",
      "title": "Efficient Crawling for Scalable Web Data Acquisition (Extended Version)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11874v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Journalistic fact-checking, as well as social or economic research, require analyzing high-quality statistics datasets (SDs, in short). However, retrieving SD corpora at scale may be hard, inefficient, or impossible, depending on how they are published online. To improve open statistics data accessibility, we present a focused Web crawling algorithm that retrieves as many targets, i.e., resources of certain types, as possible, from a given website, in an efficient and scalable way, by crawling (much) less than the full website. We show that optimally solving this problem is intractable, and propose an approach based on reinforcement learning, namely using sleeping bandits. We propose SB-CLASSIFIER, a crawler that efficiently learns which hyperlinks lead to pages that link to many targets, based on the paths leading to the links in their enclosing webpages. Our experiments on websites with millions of webpages show that our crawler is highly efficient, delivering high fractions of a site's targets while crawling only a small part.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11874v1",
        "authors": [
          "Antoine Gauquier",
          "Ioana Manolescu",
          "Pierre Senellart"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Web Data Acquisition",
        "Efficient Crawling",
        "Extended Version",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.777428"
    },
    {
      "id": "arxiv-2602.11846v1",
      "title": "Universal Sequential Changepoint Detection of Quantum Observables via Classical Shadows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11846v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study sequential quantum changepoint detection in settings where the pre- and post-change regimes are specified through constraints on the expectation values of a finite set of observables. We consider an architecture with separate measurement and detection modules, and assume that the observables relevant to the detector are unknown to the measurement device. For this scenario, we introduce shadow-based sequential changepoint e-detection (eSCD), a novel protocol that combines a universal measurement strategy based on classical shadows with a nonparametric sequential test built on e-detectors. Classical shadows provide universality with respect to the detector's choice of observables, while the e-detector framework enables explicit control of the average run length (ARL) to false alarm. Under an ARL constraint, we establish finite-sample guarantees on the worst-case expected detection delay of eSCD. Numerical experiments validate the theory and demonstrate that eSCD achieves performance competitive with observable-specific measurement strategies, while retaining full measurement universality.",
        "keywords": [
          "quant-ph",
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11846v1",
        "authors": [
          "Matteo Zecchin",
          "Osvaldo Simeone",
          "Aaditya Ramdas"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universal Sequential Changepoint Detection",
        "Classical Shadows We",
        "Quantum Observables",
        "Framework",
        "Protocol",
        "EPA",
        "ARL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.777681"
    },
    {
      "id": "arxiv-2602.11841v1",
      "title": "Improving Neural Retrieval with Attribution-Guided Query Rewriting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11841v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Neural retrievers are effective but brittle: underspecified or ambiguous queries can misdirect ranking even when relevant documents exist. Existing approaches address this brittleness only partially: LLMs rewrite queries without retriever feedback, and explainability methods identify misleading tokens but are used for post-hoc analysis. We close this loop and propose an attribution-guided query rewriting method that uses token-level explanations to guide query rewriting. For each query, we compute gradient-based token attributions from the retriever and then use these scores as soft guidance in a structured prompt to an LLM that clarifies weak or misleading query components while preserving intent. Evaluated on BEIR collections, the resulting rewrites consistently improve retrieval effectiveness over strong baselines, with larger gains for implicit or ambiguous information needs.",
        "keywords": [
          "cs.IR",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11841v1",
        "authors": [
          "Moncef Garouani",
          "Josiane Mothe"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guided Query Rewriting Neural",
        "Improving Neural Retrieval",
        "BEIR",
        "LLM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.777894"
    },
    {
      "id": "arxiv-2602.11836v1",
      "title": "ULTRA:Urdu Language Transformer-based Recommendation Architecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11836v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Urdu, as a low-resource language, lacks effective semantic content recommendation systems, particularly in the domain of personalized news retrieval. Existing approaches largely rely on lexical matching or language-agnostic techniques, which struggle to capture semantic intent and perform poorly under varying query lengths and information needs. This limitation results in reduced relevance and adaptability in Urdu content recommendation. We propose ULTRA (Urdu Language Transformer-based Recommendation Architecture),an adaptive semantic recommendation framework designed to address these challenges. ULTRA introduces a dual-embedding architecture with a query-length aware routing mechanism that dynamically distinguishes between short, intent-focused queries and longer, context-rich queries. Based on a threshold-driven decision process, user queries are routed to specialized semantic pipelines optimized for either title/headline-level or full-content/document level representations, ensuring appropriate semantic granularity during retrieval. The proposed system leverages transformer-based embeddings and optimized pooling strategies to move beyond surface-level keyword matching and enable context-aware similarity search. Extensive experiments conducted on a large-scale Urdu news corpus demonstrate that the proposed architecture consistently improves recommendation relevance across diverse query types. Results show gains in precision above 90% compared to single-pipeline baselines, highlighting the effectiveness of query-adaptive semantic alignment for low-resource languages. The findings establish ULTRA as a robust and generalizable content recommendation architecture, offering practical design insights for semantic retrieval systems in low-resource language settings.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11836v1",
        "authors": [
          "Alishbah Bashir",
          "Fatima Qaiser",
          "Ijaz Hussain"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recommendation Architecture Urdu",
        "Recommendation Architecture",
        "Urdu Language Transformer",
        "Transformer",
        "Framework",
        "ULTRA",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.778263"
    },
    {
      "id": "arxiv-2602.11814v1",
      "title": "A Comparative Study of MAP and LMMSE Estimators for Blind Inverse Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11814v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Maximum-a-posteriori (MAP) approaches are an effective framework for inverse problems with known forward operators, particularly when combined with expressive priors and careful parameter selection. In blind settings, however, their use becomes significantly less stable due to the inherent non-convexity of the problem and the potential non-identifiability of the solutions. (Linear) minimum mean square error (MMSE) estimators provide a compelling alternative that can circumvent these limitations. In this work, we study synthetic two-dimensional blind deconvolution problems under fully controlled conditions, with complete prior knowledge of both the signal and kernel distributions. We compare tailored MAP algorithms with simple LMMSE estimators whose functional form is closely related to that of an optimal Tikhonov estimator. Our results show that, even in these highly controlled settings, MAP methods remain unstable and require extensive parameter tuning, whereas the LMMSE estimator yields a robust and reliable baseline. Moreover, we demonstrate empirically that the LMMSE solution can serve as an effective initialization for MAP approaches, improving their performance and reducing sensitivity to regularization parameters, thereby opening the door to future theoretical and practical developments.",
        "keywords": [
          "cs.IT",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11814v1",
        "authors": [
          "Nathan Buskulic",
          "Luca Calatroni"
        ],
        "arxiv_categories": [
          "cs.IT",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Blind Inverse Problems Maximum",
        "Comparative Study",
        "Framework",
        "LMMSE",
        "MMSE",
        "Act",
        "WHO",
        "MIT",
        "MAP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.778538"
    },
    {
      "id": "arxiv-2602.11788v1",
      "title": "The Arithmetic Singleton Bound on the Hamming Distances of Simple-rooted Constacyclic Codes over Finite Fields",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11788v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper establishes a novel upper bound-termed the arithmetic Singleton bound-on the Hamming distance of any simple-root constacyclic code over a finite field. The key technical ingredient is the notion of multiple equal-difference (MED) representations of the defining set of a simple-root polynomial, which generalizes the MED representation of a cyclotomic coset. We prove that every MED representation induces an upper bound on the minimum distance; the classical Singleton bound corresponds to the coarsest representation, while the strongest among these bounds is defined as the arithmetic Singleton bound. It is shown that the arithmetic Singleton bound is always at least as tight as the Singleton bound, and a precise criterion for it to be strictly tighter is obtained. For irreducible constacyclic codes, the bound is given explicitly by $ω+1$, where $ω$ is a constant closely related to the order of $q$ modulo the radical of the polynomial order. This work provides the first systematic translation of arithmetic structure-via MED representations-into restrictive constraints on the minimum distance, revealing that the Singleton bound may be unattainable not because of linear limitations, but due to underlying algebraic obstructions.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11788v1",
        "authors": [
          "Li Zhu",
          "Hongfeng Wu"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constacyclic Codes",
        "Hamming Distances",
        "MIT",
        "MED",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.779146"
    },
    {
      "id": "arxiv-2602.11756v1",
      "title": "Towards a theory of Façade-X data access: satisfiability of SPARQL basic graph patterns",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11756v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Data integration is the primary use case for knowledge graphs. However, integrated data are not typically graphs but come in different formats, for example, CSV, XML, or a relational database. Façade-X is a recently proposed method for providing direct access to an open-ended set of data formats. The method includes a meta-model that specialises RDF to fit general data structures. This model allows to express SPARQL queries targeting data sources with those structures. Previous work formalised Façade-X and demonstrated how it can theoretically represent any format expressible with a context-free grammar, as well as the relational model. A reference implementation, SPARQL Anything, demonstrates the feasibility of the approach in practice. It is noteworthy that Façade-X utilises a fraction of RDF, and, consequently, not all SPARQL queries yield a solution (i.e. are satisfiable) when evaluated over a Façade-X graph. In this article, we consolidate Façade-X, and we study the satisfiability of basic graph patterns. The theory is accompanied by an algorithm for deciding the satisfiability of basic graph patterns on Façade-X data sources. Furthermore, we provide extensive experiments with a proof-of-concept implementation, demonstrating practical feasibility, including with real-world queries. Our results pave the way for studying query execution strategies for Façade-X data access with SPARQL and supporting developers to build more efficient data integration systems for knowledge graphs.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11756v1",
        "authors": [
          "Luigi Asprino",
          "Enrico Daga"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SPARQL",
        "Meta",
        "Act",
        "RDF",
        "XML",
        "CSV"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.779788"
    },
    {
      "id": "arxiv-2602.11719v1",
      "title": "Uncertainty-aware Generative Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11719v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Generative Recommendation has emerged as a transformative paradigm, reformulating recommendation as an end-to-end autoregressive sequence generation task. Despite its promise, existing preference optimization methods typically rely on binary outcome correctness, suffering from a systemic limitation we term uncertainty blindness. This issue manifests in the neglect of the model's intrinsic generation confidence, the variation in sample learning difficulty, and the lack of explicit confidence expression, directly leading to unstable training dynamics and unquantifiable decision risks. In this paper, we propose Uncertainty-aware Generative Recommendation (UGR), a unified framework that leverages uncertainty as a critical signal for adaptive optimization. UGR synergizes three mechanisms: (1) an uncertainty-weighted reward to penalize confident errors; (2) difficulty-aware optimization dynamics to prevent premature convergence; and (3) explicit confidence alignment to empower the model with confidence expression capabilities. Extensive experiments demonstrate that UGR not only yields superior recommendation performance but also fundamentally stabilizes training, preventing the performance degradation often observed in standard methods. Furthermore, the learned confidence enables reliable downstream risk-aware applications.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11719v1",
        "authors": [
          "Chenxiao Fan",
          "Chongming Gao",
          "Yaxin Gong",
          "Haoyan Liu",
          "Fuli Feng"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generative Recommendation Generative Recommendation",
        "Generative Recommendation",
        "Framework",
        "Standard",
        "NSF",
        "UGR",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.780094"
    },
    {
      "id": "arxiv-2602.11712v1",
      "title": "Potential-energy gating for robust state estimation in bistable stochastic systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11712v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce potential-energy gating, a method for robust state estimation in systems governed by double-well stochastic dynamics. The observation noise covariance of a Bayesian filter is modulated by the local value of a known or assumed potential energy function: observations are trusted when the state is near a potential minimum and progressively discounted as it approaches the barrier separating metastable wells. This physics-based mechanism differs from purely statistical robust filters, which treat all regions of state space identically, and from constrained filters, which impose hard bounds on states rather than modulating observation trust. We implement the gating within Extended, Unscented, Ensemble, and Adaptive Kalman filters and particle filters, requiring only two additional hyperparameters. Synthetic benchmarks on a Ginzburg-Landau double-well process with 10% outlier contamination and Monte Carlo validation over 100 replications show 57-80% RMSE improvement over the standard Extended Kalman Filter, all statistically significant (p < 10^{-15}, Wilcoxon signed-rank test). A naive topological baseline using only distance to the nearest well achieves 57%, confirming that the continuous energy landscape adds an additional ~21 percentage points. The method is robust to misspecification: even when assumed potential parameters deviate by 50% from their true values, improvement never falls below 47%. Comparing externally forced and spontaneous Kramers-type transitions, gating retains 68% improvement under noise-induced transitions whereas the naive baseline degrades to 30%. As an empirical illustration, we apply the framework to Dansgaard-Oeschger events in the NGRIP delta-18O ice-core record, estimating asymmetry parameter gamma = -0.109 (bootstrap 95% CI: [-0.220, -0.011], excluding zero) and demonstrating that outlier fraction explains 91% of the variance in filter improvement.",
        "keywords": [
          "cs.LG",
          "cs.CE",
          "nlin.CD",
          "physics.data-an",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11712v1",
        "authors": [
          "Luigi Simeone"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CE",
          "nlin.CD",
          "physics.data-an",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Extended Kalman Filter",
        "Adaptive Kalman",
        "Monte Carlo",
        "Framework",
        "Standard",
        "NGRIP",
        "Meta",
        "RMSE",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.780478"
    },
    {
      "id": "arxiv-2602.11708v1",
      "title": "Systematic Trend-Following with Adaptive Portfolio Construction: Enhancing Risk-Adjusted Alpha in Cryptocurrency Markets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11708v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Cryptocurrency markets exhibit pronounced momentum effects and regime-dependent volatility, presenting both opportunities and challenges for systematic trading strategies. We propose AdaptiveTrend, a multi-component algorithmic trading framework that integrates high-frequency trend-following on 6-hour intervals with monthly adaptive portfolio construction and asymmetric long-short capital allocation. Our framework introduces three key innovations: (1) a dynamic trailing stop mechanism calibrated to intra-day volatility regimes, (2) a rolling Sharpe-ratio-based asset selection procedure with market-capitalization-aware filtering, and (3) a theoretically motivated asymmetric 70/30 long-short allocation scheme grounded in the empirical positive drift of crypto markets. Through extensive out-of-sample backtesting across 150+ cryptocurrency pairs over a 36-month evaluation window (2022-2024), AdaptiveTrend achieves an annualized Sharpe ratio of 2.41, a maximum drawdown of -12.7%, and a Calmar ratio of 3.18, significantly outperforming benchmark trend-following strategies (TSMOM, time-series momentum) and equal-weighted buy-and-hold portfolios. We further conduct rigorous robustness analyses including parameter sensitivity, transaction cost modeling, and regime-conditional performance decomposition, demonstrating the strategy's resilience across bull, bear, and sideways market conditions.",
        "keywords": [
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11708v1",
        "authors": [
          "Duc Bui",
          "Thanh Nguyen"
        ],
        "arxiv_categories": [
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cryptocurrency Markets Cryptocurrency",
        "Adaptive Portfolio Construction",
        "Systematic Trend",
        "Adjusted Alpha",
        "Enhancing Risk",
        "Framework",
        "TSMOM",
        "Wind",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.780773"
    },
    {
      "id": "arxiv-2602.11693v1",
      "title": "OMEGA-Avatar: One-shot Modeling of 360° Gaussian Avatars",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11693v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Creating high-fidelity, animatable 3D avatars from a single image remains a formidable challenge. We identified three desirable attributes of avatar generation: 1) the method should be feed-forward, 2) model a 360° full-head, and 3) should be animation-ready. However, current work addresses only two of the three points simultaneously. To address these limitations, we propose OMEGA-Avatar, the first feed-forward framework that simultaneously generates a generalizable, 360°-complete, and animatable 3D Gaussian head from a single image. Starting from a feed-forward and animatable framework, we address the 360° full-head avatar generation problem with two novel components. First, to overcome poor hair modeling in full-head avatar generation, we introduce a semantic-aware mesh deformation module that integrates multi-view normals to optimize a FLAME head with hair while preserving its topology structure. Second, to enable effective feed-forward decoding of full-head features, we propose a multi-view feature splatting module that constructs a shared canonical UV representation from features across multiple views through differentiable bilinear splatting, hierarchical UV mapping, and visibility-aware fusion. This approach preserves both global structural coherence and local high-frequency details across all viewpoints, ensuring 360° consistency without per-instance optimization. Extensive experiments demonstrate that OMEGA-Avatar achieves state-of-the-art performance, significantly outperforming existing baselines in 360° full-head completeness while robustly preserving identity across different viewpoints.",
        "keywords": [
          "cs.GR",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11693v1",
        "authors": [
          "Zehao Xia",
          "Yiqun Wang",
          "Zhengda Lu",
          "Kai Liu",
          "Jun Xiao"
        ],
        "arxiv_categories": [
          "cs.GR",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Avatars Creating",
        "Framework",
        "Fusion",
        "FLAME",
        "OMEGA",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.781408"
    },
    {
      "id": "arxiv-2602.11680v1",
      "title": "EpicCBR: Item-Relation-Enhanced Dual-Scenario Contrastive Learning for Cold-Start Bundle Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11680v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Bundle recommendation aims to recommend a set of items to users for overall consumption. Existing bundle recommendation models primarily depend on observed user-bundle interactions, limiting exploration of newly-emerged bundles that are constantly created. It pose a critical representation challenge for current bundle methods, as they usually treat each bundle as an independent instance, while neglecting to fully leverage the user-item (UI) and bundle-item (BI) relations over popular items. To alleviate it, in this paper we propose a multi-view contrastive learning framework for cold-start bundle recommendation, named EpicCBR. Specifically, it precisely mine and utilize the item relations to construct user profiles, identifying users likely to engage with bundles. Additionally, a popularity-based method that characterizes the features of new bundles through historical bundle information and user preferences is proposed. To build a framework that demonstrates robustness in both cold-start and warm-start scenarios, a multi-view graph contrastive learning framework capable of integrating these diverse scenarios is introduced to ensure the model's generalization capability. Extensive experiments conducted on three popular benchmarks showed that EpicCBR outperforms state-of-the-art by a large margin (up to 387%), sufficiently demonstrating the superiority of the proposed method in cold-start scenario. The code and dataset can be found in the GitHub repository: https://github.com/alexlovecoding/EpicCBR.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11680v1",
        "authors": [
          "Yihang Li",
          "Zhuo Liu",
          "Wei Wei"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Start Bundle Recommendation Bundle",
        "Scenario Contrastive Learning",
        "Enhanced Dual",
        "Framework",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.781706"
    },
    {
      "id": "arxiv-2602.11664v1",
      "title": "IntTravel: A Real-World Dataset and Generative Framework for Integrated Multi-Task Travel Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11664v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Next Point of Interest (POI) recommendation is essential for modern mobility and location-based services. To provide a smooth user experience, models must understand several components of a journey holistically: \"when to depart\", \"how to travel\", \"where to go\", and \"what needs arise via the route\". However, current research is limited by fragmented datasets that focus merely on next POI recommendation (\"where to go\"), neglecting the departure time, travel mode, and situational requirements along the journey. Furthermore, the limited scale of these datasets impedes accurate evaluation of performance. To bridge this gap, we introduce IntTravel, the first large-scale public dataset for integrated travel recommendation, including 4.1 billion interactions from 163 million users with 7.3 million POIs. Built upon this dataset, we introduce an end-to-end, decoder-only generative framework for multi-task recommendation. It incorporates information preservation, selection, and factorization to balance task collaboration with specialized differentiation, yielding substantial performance gains. The framework's generalizability is highlighted by its state-of-the-art performance across both IntTravel dataset and an additional non-travel benchmark. IntTravel has been successfully deployed on Amap serving hundreds of millions of users, leading to a 1.09% increase in CTR. IntTravel is available at https://github.com/AMAP-ML/IntTravel.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11664v1",
        "authors": [
          "Huimin Yan",
          "Longfei Xu",
          "Junjie Sun",
          "Zheng Liu",
          "Wei Luo"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Task Travel Recommendation Next",
        "Generative Framework",
        "Integrated Multi",
        "World Dataset",
        "Framework",
        "Bill",
        "AMAP",
        "Act",
        "EPA",
        "POI",
        "MIT",
        "CTR",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.782001"
    },
    {
      "id": "arxiv-2602.11638v1",
      "title": "Variation-aware Flexible 3D Gaussian Editing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11638v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Indirect editing methods for 3D Gaussian Splatting (3DGS) have recently witnessed significant advancements. These approaches operate by first applying edits in the rendered 2D space and subsequently projecting the modifications back into 3D. However, this paradigm inevitably introduces cross-view inconsistencies and constrains both the flexibility and efficiency of the editing process. To address these challenges, we present VF-Editor, which enables native editing of Gaussian primitives by predicting attribute variations in a feedforward manner. To accurately and efficiently estimate these variations, we design a novel variation predictor distilled from 2D editing knowledge. The predictor encodes the input to generate a variation field and employs two learnable, parallel decoding functions to iteratively infer attribute changes for each 3D Gaussian. Thanks to its unified design, VF-Editor can seamlessly distill editing knowledge from diverse 2D editors and strategies into a single predictor, allowing for flexible and effective knowledge transfer into the 3D domain. Extensive experiments on both public and private datasets reveal the inherent limitations of indirect editing pipelines and validate the effectiveness and flexibility of our approach.",
        "keywords": [
          "cs.GR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11638v1",
        "authors": [
          "Hao Qin",
          "Yukai Sun",
          "Meng Wang",
          "Ming Kong",
          "Mengxu Lu"
        ],
        "arxiv_categories": [
          "cs.GR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Editing Indirect",
        "Gaussian Splatting",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.782268"
    },
    {
      "id": "arxiv-2602.11622v1",
      "title": "Evolutionary Router Feature Generation for Zero-Shot Graph Anomaly Detection with Mixture-of-Experts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11622v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Zero-shot graph anomaly detection (GAD) has attracted increasing attention recent years, yet the heterogeneity of graph structures, features, and anomaly patterns across graphs make existing single GNN methods insufficiently expressive to model diverse anomaly mechanisms. In this regard, Mixture-of-experts (MoE) architectures provide a promising paradigm by integrating diverse GNN experts with complementary inductive biases, yet their effectiveness in zero-shot GAD is severely constrained by distribution shifts, leading to two key routing challenges. First, nodes often carry vastly different semantics across graphs, and straightforwardly performing routing based on their features is prone to generating biased or suboptimal expert assignments. Second, as anomalous graphs often exhibit pronounced distributional discrepancies, existing router designs fall short in capturing domain-invariant routing principles that generalize beyond the training graphs. To address these challenges, we propose a novel MoE framework with evolutionary router feature generation (EvoFG) for zero-shot GAD. To enhance MoE routing, we propose an evolutionary feature generation scheme that iteratively constructs and selects informative structural features via an LLM-based generator and Shapley-guided evaluation. Moreover, a memory-enhanced router with an invariant learning objective is designed to capture transferable routing patterns under distribution shifts. Extensive experiments on six benchmarks show that EvoFG consistently outperforms state-of-the-art baselines, achieving strong and stable zero-shot GAD performance.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11622v1",
        "authors": [
          "Haiyang Jiang",
          "Tong Chen",
          "Xinyi Gao",
          "Guansong Pang",
          "Quoc Viet Hung Nguyen"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Evolutionary Router Feature Generation",
        "Shot Graph Anomaly Detection",
        "Experts Zero",
        "Framework",
        "Act",
        "NSF",
        "EPA",
        "GAD",
        "GNN",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.782590"
    },
    {
      "id": "arxiv-2602.11605v1",
      "title": "Recurrent Preference Memory for Efficient Long-Sequence Generative Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11605v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Generative recommendation (GenRec) models typically model user behavior via full attention, but scaling to lifelong sequences is hindered by prohibitive computational costs and noise accumulation from stochastic interactions. To address these challenges, we introduce Rec2PM, a framework that compresses long user interaction histories into compact Preference Memory tokens. Unlike traditional recurrent methods that suffer from serial training, Rec2PM employs a novel self-referential teacher-forcing strategy: it leverages a global view of the history to generate reference memories, which serve as supervision targets for parallelized recurrent updates. This allows for fully parallel training while maintaining the capability for iterative updates during inference. Additionally, by representing memory as token embeddings rather than extensive KV caches, Rec2PM achieves extreme storage efficiency. Experiments on large-scale benchmarks show that Rec2PM significantly reduces inference latency and memory footprint while achieving superior accuracy compared to full-sequence models. Analysis reveals that the Preference Memory functions as a denoising Information Bottleneck, effectively filtering interaction noise to capture robust long-term interests.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11605v1",
        "authors": [
          "Yixiao Chen",
          "Yuan Wang",
          "Yue Liu",
          "Qiyao Wang",
          "Ke Cheng"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sequence Generative Recommendation Generative",
        "Recurrent Preference Memory",
        "Information Bottleneck",
        "Preference Memory",
        "Efficient Long",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.782862"
    },
    {
      "id": "arxiv-2602.11581v1",
      "title": "Analytical Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11581v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Analytical information needs, such as trend analysis and causal impact assessment, are prevalent across various domains including law, finance, science, and much more. However, existing information retrieval paradigms, whether based on relevance-oriented document ranking or retrieval-augmented generation (RAG) with large language models (LLMs), often struggle to meet the end-to-end requirements of such tasks at the corpus scale. They either emphasize information finding rather than end-to-end problem solving, or simply treat everything as naive question answering, offering limited control over reasoning, evidence usage, and verifiability. As a result, they struggle to support analytical queries that have diverse utility concepts and high accountability requirements. In this paper, we propose analytical search as a distinct and emerging search paradigm designed to fulfill these analytical information needs. Analytical search reframes search as an evidence-governed, process-oriented analytical workflow that explicitly models analytical intent, retrieves evidence for fusion, and produces verifiable conclusions through structured, multi-step inference. We position analytical search in contrast to existing paradigms, and present a unified system framework that integrates query understanding, recall-oriented retrieval, reasoning-aware fusion, and adaptive verification. We also discuss potential research directions for the construction of analytical search engines. In this way, we highlight the conceptual significance and practical importance of analytical search and call on efforts toward the next generation of search engines that support analytical information needs.",
        "keywords": [
          "cs.IR",
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11581v1",
        "authors": [
          "Yiteng Tu",
          "Shuo Miao",
          "Weihang Su",
          "Yiqun Liu",
          "Qingyao Ai"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Analytical Search Analytical",
        "Framework",
        "Fusion",
        "Act",
        "MIT",
        "LLM",
        "RAG",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.783181"
    },
    {
      "id": "arxiv-2602.11578v1",
      "title": "Quantum-Enhanced Temporal Embeddings via a Hybrid Seq2Seq Architecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11578v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This work investigates how shallow, NISQ-compatible quantum layers can improve temporal representation learning in real-world sequential data. We develop a QLSTM Seq2Seq autoencoder in which a depth-1 variational quantum circuit is embedded inside each recurrent gate, shaping the geometry of the learned latent manifold. Evaluated on fourteen rolling S and P 500 windows from 2022 to 2025, the quantum-enhanced encoder produces smoother trajectories, clearer regime transitions, and more stable, sector-coherent clusters than a classical LSTM baseline. These geometric properties support the use of a Radial Basis Function (RBF) kernel for downstream portfolio allocation, where both RBF-Graph and RBF-DivMom strategies consistently outperform their classical counterparts in risk-adjusted terms. Analysis across periods shows that compressed manifolds favor concentrated allocation, while dispersed manifolds favor diversification, demonstrating that latent geometry serves as a regime indicator. The results highlight a practical role for shallow hybrid quantum and classical layers in NISQ-era sequence modeling, offering a reproducible pathway for improving temporal embeddings in finance and other data-limited, noise-sensitive domains.",
        "keywords": [
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11578v1",
        "authors": [
          "Tien-Ching Hsieh",
          "Yun-Cheng Tsai",
          "Samuel Yen-Chi Chen"
        ],
        "arxiv_categories": [
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enhanced Temporal Embeddings",
        "Radial Basis Function",
        "QLSTM",
        "LSTM",
        "Wind",
        "NISQ",
        "Act",
        "MIT",
        "RBF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.783440"
    },
    {
      "id": "arxiv-2602.11577v1",
      "title": "LeafFit: Plant Assets Creation from 3D Gaussian Splatting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11577v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose LeafFit, a pipeline that converts 3D Gaussian Splatting (3DGS) of individual plants into editable, instanced mesh assets. While 3DGS faithfully captures complex foliage, its high memory footprint and lack of mesh topology make it incompatible with traditional game production workflows. We address this by leveraging the repetition of leaf shapes; our method segments leaves from the unstructured 3DGS, with optional user interaction included as a fallback. A representative leaf group is selected and converted into a thin, sharp mesh to serve as a template; this template is then fitted to all other leaves via differentiable Moving Least Squares (MLS) deformation. At runtime, the deformation is evaluated efficiently on-the-fly using a vertex shader to minimize storage requirements. Experiments demonstrate that LeafFit achieves higher segmentation quality and deformation accuracy than recent baselines while significantly reducing data size and enabling parameter-level editing.",
        "keywords": [
          "cs.GR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11577v1",
        "authors": [
          "Chang Luo",
          "Nobuyuki Umetani"
        ],
        "arxiv_categories": [
          "cs.GR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Splatting We",
        "Plant Assets Creation",
        "Moving Least Squares",
        "Gaussian Splatting",
        "Act",
        "MLS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.783652"
    },
    {
      "id": "arxiv-2602.11573v1",
      "title": "Fast Tuning the Index Construction Parameters of Proximity Graphs in Vector Databases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11573v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "k-approximate nearest neighbor search (k-ANNS) in high-dimensional vector spaces is a fundamental problem across many fields. With the advent of vector databases and retrieval-augmented generation, k-ANNS has garnered increasing attention. Among existing methods, proximity graphs (PG) based approaches are the state-of-the-art (SOTA) methods. However, the construction parameters of PGs significantly impact their search performance. Before constructing a PG for a given dataset, it is essential to tune these parameters, which first recommends a set of promising parameters and then estimates the quality of each parameter by building the corresponding PG and then testing its k-ANNS performance. Given that the construction complexity of PGs is superlinear, building and evaluating graph indexes accounts for the primary cost of parameter tuning. Unfortunately, there is currently no method considered and optimized this process.In this paper, we introduce FastPGT, an efficient framework for tuning the PG construction parameters. FastPGT accelerates parameter estimation by building multiple PGs simultaneously, thereby reducing repeated computations. Moreover, we modify the SOTA tuning model to recommend multiple parameters at once, which can be efficiently estimated using our method of building multiple PGs simultaneously. Through extensive experiments on real-world datasets, we demonstrate that FastPGT achieves up to 2.37x speedup over the SOTA method VDTuner, without compromising tuning quality.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11573v1",
        "authors": [
          "Wenyang Zhou",
          "Jiadong Xie",
          "Yingfan Liu",
          "Zhihao Yin",
          "Jeffrey Xu Yu"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Index Construction Parameters",
        "Vector Databases",
        "Proximity Graphs",
        "Fast Tuning",
        "Framework",
        "SOTA",
        "ANNS",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.783969"
    },
    {
      "id": "arxiv-2602.11568v1",
      "title": "Non-signaling Assisted Capacity of a Classical Channel with Causal CSIT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11568v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The non-signaling (NS) assisted capacity of a classical channel with causal channel state information at the transmitter (CSIT) is shown to be $C^{NS,ca}=\\max_{P_{X|S}}I(X;Y\\mid S)$, where $X, Y, S$ correspond to the input, output and state of the channel. Remarkably, this is the same as the capacity of the channel in the NS-assisted non-causal CSIT setting, $C^{NS,nc}=\\max_{P_{X|S}}I(X;Y\\mid S)$, which was previously established, and also matches the (either classical or with NS assistance) capacity of the channel where the state is available not only (either causally or non-causally) to the transmitter but also to the receiver. While the capacity remains unchanged, the optimal probability of error for fixed message size and blocklength, in the NS-assisted causal CSIT setting can be further improved if channel state is made available to the receiver. This is in contrast to corresponding NS-assisted non-causal CSIT setting where it was previously noted that the optimal probability of error cannot be further improved by providing the state to the receiver.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11568v1",
        "authors": [
          "Yuhang Yao",
          "Syed A. Jafar"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Assisted Capacity",
        "Classical Channel",
        "CSIT",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:23.784199"
    },
    {
      "id": "arxiv-2602.12243v1",
      "title": "Federated Gaussian Process Learning via Pseudo-Representations for Large-Scale Multi-Robot Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12243v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Multi-robot systems require scalable and federated methods to model complex environments under computational and communication constraints. Gaussian Processes (GPs) offer robust probabilistic modeling, but suffer from cubic computational complexity, limiting their applicability in large-scale deployments. To address this challenge, we introduce the pxpGP, a novel distributed GP framework tailored for both centralized and decentralized large-scale multi-robot networks. Our approach leverages sparse variational inference to generate a local compact pseudo-representation. We introduce a sparse variational optimization scheme that bounds local pseudo-datasets and formulate a global scaled proximal-inexact consensus alternating direction method of multipliers (ADMM) with adaptive parameter updates and warm-start initialization. Experiments on synthetic and real-world datasets demonstrate that pxpGP and its decentralized variant, dec-pxpGP, outperform existing distributed GP methods in hyperparameter estimation and prediction accuracy, particularly in large-scale networks.",
        "keywords": [
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12243v1",
        "authors": [
          "Sanket A. Salunkhe",
          "George P. Kontoudis"
        ],
        "arxiv_categories": [
          "cs.MA"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Federated Gaussian Process Learning",
        "Robot Systems Multi",
        "Gaussian Processes",
        "Scale Multi",
        "Framework",
        "Robot",
        "ADMM",
        "Act",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-15T13:53:27.966465"
    },
    {
      "id": "arxiv-2602.12231v1",
      "title": "Adjusted Winner: from Splitting to Selling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12231v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12231v1",
        "authors": [
          "Robert Bredereck",
          "Bin Sun",
          "Eyal Briman",
          "Nimrod Talmon"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Adjusted Winner",
        "Framework",
        "FPTAS",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.966680"
    },
    {
      "id": "arxiv-2602.12136v1",
      "title": "Embodied AI Agents for Team Collaboration in Co-located Blue-Collar Work",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12136v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Blue-collar work is often highly collaborative, embodied, and situated in shared physical environments, yet most research on collaborative AI has focused on white-collar work. This position paper explores how the embodied nature of AI agents can support team collaboration and communication in co-located blue-collar workplaces. From the context of our newly started CAI-BLUE research project, we present two speculative scenarios from industrial and maintenance contexts that illustrate how embodied AI agents can support shared situational awareness and facilitate inclusive communication across experience levels. We outline open questions related to embodied AI agent design around worker inclusion, agency, transformation of blue-collar collaboration practices over time, and forms of acceptable AI embodiments. We argue that embodiment is not just an aesthetic choice but should become a socio-material design strategy of AI systems in blue-collar workplaces.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12136v1",
        "authors": [
          "Kaisa Vaananen",
          "Niels van Berkel",
          "Donald McMillan",
          "Thomas Olsson"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Team Collaboration",
        "Collar Work Blue",
        "BLUE",
        "Act",
        "NSF",
        "CAI",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.967073"
    },
    {
      "id": "arxiv-2602.12118v1",
      "title": "Anonymous Contracts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12118v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents. We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees. In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12118v1",
        "authors": [
          "Johannes Brustle",
          "Paul Duetting",
          "Stefano Leonardi",
          "Tomasz Ponitka",
          "Matteo Russo"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Anonymous Contracts We",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.967448"
    },
    {
      "id": "arxiv-2602.12102v1",
      "title": "DEpiABS: Differentiable Epidemic Agent-Based Simulator",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12102v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The COVID-19 pandemic highlighted the limitations of existing epidemic simulation tools. These tools provide information that guides non-pharmaceutical interventions (NPIs), yet many struggle to capture complex dynamics while remaining computationally practical and interpretable. We introduce DEpiABS, a scalable, differentiable agent-based model (DABM) that balances mechanistic detail, computational efficiency and interpretability. DEpiABS captures individual-level heterogeneity in health status, behaviour, and resource constraints, while also modelling epidemic processes like viral mutation and reinfection dynamics. The model is fully differentiable, enabling fast simulation and gradient-based parameter calibration. Building on this foundation, we introduce a z-score-based scaling method that maps small-scale simulations to any real-world population sizes with negligible loss in output granularity, reducing the computational burden when modelling large populations. We validate DEpiABS through sensitivity analysis and calibration to COVID-19 and flu data from ten regions of varying scales. Compared to the baseline, DEpiABS is more detailed, fully interpretable, and has reduced the average normal deviation in forecasting from 0.97 to 0.92 on COVID-19 mortality data and from 0.41 to 0.32 on influenza-like-illness data. Critically, these improvements are achieved without relying on auxiliary data, making DEpiABS a reliable, generalisable, and data-efficient framework for future epidemic response modelling.",
        "keywords": [
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12102v1",
        "authors": [
          "Zhijian Gao",
          "Shuxin Li",
          "Bo An"
        ],
        "arxiv_categories": [
          "cs.MA"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Differentiable Epidemic Agent",
        "Framework",
        "COVID-19",
        "COVID",
        "NIST",
        "DABM",
        "Act",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-15T13:53:27.967749"
    },
    {
      "id": "arxiv-2602.12018v1",
      "title": "Artificial intelligence is creating a new global linguistic hierarchy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12018v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Artificial intelligence (AI) has the potential to transform healthcare, education, governance and socioeconomic equity, but its benefits remain concentrated in a small number of languages (Bender, 2019; Blasi et al., 2022; Joshi et al., 2020; Ranathunga and de Silva, 2022; Young, 2015). Language AI - the technologies that underpin widely-used conversational systems such as ChatGPT - could provide major benefits if available in people's native languages, yet most of the world's 7,000+ linguistic communities currently lack access and face persistent digital marginalization. Here we present a global longitudinal analysis of social, economic and infrastructural conditions across languages to assess systemic inequalities in language AI. We first analyze the existence of AI resources for 6003 languages. We find that despite efforts of the community to broaden the reach of language technologies (Bapna et al., 2022; Costa-Jussà et al., 2022), the dominance of a handful of languages is exacerbating disparities on an unprecedented scale, with divides widening exponentially rather than narrowing. Further, we contrast the longitudinal diffusion of AI with that of earlier IT technologies, revealing a distinctive hype-driven pattern of spread. To translate our findings into practical insights and guide prioritization efforts, we introduce the Language AI Readiness Index (EQUATE), which maps the state of technological, socio-economic, and infrastructural prerequisites for AI deployment across languages. The index highlights communities where capacity exists but remains underutilized, and provides a framework for accelerating more equitable diffusion of language AI. Our work contributes to setting the baseline for a transition towards more sustainable and equitable language technologies.",
        "keywords": [
          "cs.CY",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12018v1",
        "authors": [
          "Giulia Occhini",
          "Kumiko Tanaka-Ishii",
          "Anna Barford",
          "Refael Tikochinski",
          "Songbo Hu"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.CL"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Artificial Intelligence",
        "Readiness Index",
        "Framework",
        "ChatGPT",
        "EQUATE",
        "Fusion",
        "Intel",
        "Act",
        "NSF",
        "GPT",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.968541"
    },
    {
      "id": "arxiv-2602.11977v1",
      "title": "Multi-Defender Single-Attacker Perimeter Defense Game on a Cylinder: Special Case in which the Attacker Starts at the Boundary",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11977v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We describe a multi-agent perimeter defense game played on a cylinder. A team of n slow-moving defenders must prevent a single fast-moving attacker from crossing the boundary of a defensive perimeter. We describe the conditions necessary for the attacker to win in the special case that the intruder starts close to the boundary and in a region that is currently defended.",
        "keywords": [
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11977v1",
        "authors": [
          "Michael Otte",
          "Roderich Groß"
        ],
        "arxiv_categories": [
          "cs.MA"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Attacker Perimeter Defense Game",
        "Attacker Starts",
        "Defender Single",
        "Special Case",
        "Boundary We",
        "UN"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-15T13:53:27.968667"
    },
    {
      "id": "arxiv-2602.11967v1",
      "title": "Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11967v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve. Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11967v1",
        "authors": [
          "Moshe Babaioff",
          "Sijin Chen",
          "Zhaohua Chen",
          "Yiding Feng"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Buyer Mechanisms",
        "Efficient Multi",
        "Act",
        "MHR",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.968965"
    },
    {
      "id": "arxiv-2602.11962v1",
      "title": "Wisdom of the LLM Crowd: A Large Scale Benchmark of Multi-Label U.S. Election-Related Harmful Social Media Content",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11962v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The spread of election misinformation and harmful political content conveys misleading narratives and poses a serious threat to democratic integrity. Detecting harmful content at early stages is essential for understanding and potentially mitigating its downstream spread. In this study, we introduce USE24-XD, a large-scale dataset of nearly 100k posts collected from X (formerly Twitter) during the 2024 U.S. presidential election cycle, enriched with spatio-temporal metadata. To substantially reduce the cost of manual annotation while enabling scalable categorization, we employ six large language models (LLMs) to systematically annotate posts across five nuanced categories: Conspiracy, Sensationalism, Hate Speech, Speculation, and Satire. We validate LLM annotations with crowdsourcing (n = 34) and benchmark them against human annotators. Inter-rater reliability analyses show comparable agreement patterns between LLMs and humans, with LLMs exhibiting higher internal consistency and achieving up to 0.90 recall on Speculation. We apply a wisdom-of-the-crowd approach across LLMs to aggregate annotations and curate a robust multi-label dataset. 60% of posts receive at least one label. We further analyze how human annotator demographics, including political ideology and affiliation, shape labeling behavior, highlighting systematic sources of subjectivity in judgments of harmful content. The USE24-XD dataset is publicly released to support future research.",
        "keywords": [
          "cs.HC",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11962v1",
        "authors": [
          "Qile Wang",
          "Prerana Khatiwada",
          "Carolina Coimbra Vieira",
          "Benjamin E. Bagozzi",
          "Kenneth E. Barner"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Related Harmful Social Media",
        "Large Scale Benchmark",
        "Hate Speech",
        "Agreement",
        "Meta",
        "MIT",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.969267"
    },
    {
      "id": "arxiv-2602.11959v1",
      "title": "Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11959v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the \"competition complexity\" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions. First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \\approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\\leq n$, and any target fraction of the optimal revenue. Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers. Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11959v1",
        "authors": [
          "Moshe Babaioff",
          "Yiding Feng",
          "Zihan Luo"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Strengthening Bulow",
        "Style Results",
        "Standard",
        "Act",
        "WHO",
        "MHR",
        "MIT",
        "VCG",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.969615"
    },
    {
      "id": "arxiv-2602.11944v1",
      "title": "Using predictive multiplicity to measure individual performance within the AI Act",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11944v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "When building AI systems for decision support, one often encounters the phenomenon of predictive multiplicity: a single best model does not exist; instead, one can construct many models with similar overall accuracy that differ in their predictions for individual cases. Especially when decisions have a direct impact on humans, this can be highly unsatisfactory. For a person subject to high disagreement between models, one could as well have chosen a different model of similar overall accuracy that would have decided the person's case differently. We argue that this arbitrariness conflicts with the EU AI Act, which requires providers of high-risk AI systems to report performance not only at the dataset level but also for specific persons. The goal of this paper is to put predictive multiplicity in context with the EU AI Act's provisions on accuracy and to subsequently derive concrete suggestions on how to evaluate and report predictive multiplicity in practice. Specifically: (1) We argue that incorporating information about predictive multiplicity can serve compliance with the EU AI Act's accuracy provisions for providers. (2) Based on this legal analysis, we suggest individual conflict ratios and $δ$-ambiguity as tools to quantify the disagreement between models on individual cases and to help detect individuals subject to conflicting predictions. (3) Based on computational insights, we derive easy-to-implement rules on how model providers could evaluate predictive multiplicity in practice. (4) Ultimately, we suggest that information about predictive multiplicity should be made available to deployers under the AI Act, enabling them to judge whether system outputs for specific individuals are reliable enough for their use case.",
        "keywords": [
          "cs.LG",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11944v1",
        "authors": [
          "Karolin Frohnapfel",
          "Mara Seyfert",
          "Sebastian Bordt",
          "Ulrike von Luxburg",
          "Kristof Meding"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "Act When",
        "Act",
        "DOE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:27.970355"
    },
    {
      "id": "arxiv-2602.11924v1",
      "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11924v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping literature review and thematic analysis of 113 LLM-supported decision-making papers. Then, we evaluate these diverse archetypes across real-world clinical diagnostic cases to examine the potential effects of adopting distinct human-LLM archetypes on LLM outputs and decision outcomes. Finally, we present relevant tradeoffs and design choices across human-LLM archetypes, including decision control, social hierarchies, cognitive forcing strategies, and information requirements. Through our analysis, we show that selection of human-LLM interaction archetype can influence LLM outputs and decisions, bringing important risks and considerations for the designers of human-AI decision-making systems",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11924v1",
        "authors": [
          "Shreya Chappidi",
          "Jatinder Singh",
          "Andra V. Krauze"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Roles Assigned",
        "Who Does What",
        "During Human",
        "Act",
        "WHO",
        "DOE",
        "LLM",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.970583"
    },
    {
      "id": "arxiv-2602.11914v1",
      "title": "Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11914v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11914v1",
        "authors": [
          "Hanbing Liu",
          "Ningyuan Li",
          "Weian Li",
          "Qi Qi",
          "Changyuan Yu"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Selection Shortlisting",
        "Optimal Contest Design",
        "Incentive Effects",
        "Transparent Pre",
        "Off Score",
        "Act",
        "WHO",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.970791"
    },
    {
      "id": "arxiv-2602.11857v1",
      "title": "Scale-Invariant Fast Convergence in Games",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11857v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\\tilde{O}(A_{\\mathrm{diff}})$, where $A_{\\mathrm{diff}}$ is the payoff range, which implies an $\\tilde{O}(A_{\\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\\mathrm{max}} \\log T)$, where $U_{\\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\\mathrm{max}} \\log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.",
        "keywords": [
          "cs.GT",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11857v1",
        "authors": [
          "Taira Tsuchiya",
          "Haipeng Luo",
          "Shinji Ito"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Invariant Fast Convergence",
        "Games Scale",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.971070"
    },
    {
      "id": "arxiv-2602.11855v1",
      "title": "Decision Support System for Technology Opportunity Discovery: An Application of the Schwartz Theory of Basic Values",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11855v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Discovering technology opportunities (TOD) remains a critical challenge for innovation management, especially in early-stage development where consumer needs are often unclear. Existing methods frequently fail to systematically incorporate end-user perspectives, resulting in a misalignment between technological potentials and market relevance. This study proposes a novel decision support framework that bridges this gap by linking technological feasibility with fundamental human values. The framework integrates two distinct lenses: the engineering-based Technology Readiness Levels (TRL) and Schwartz's theory of basic human values. By combining these, the approach enables a structured exploration of how emerging technologies may satisfy diverse user motivations. To illustrate the framework's feasibility and insight potential, we conducted exploratory workshops with general consumers and internal experts at Sony Computer Science Laboratories, Inc., analyzing four real-world technologies (two commercial successes and two failures). Two consistent patterns emerged: (1) internal experts identified a wider value landscape than consumers (vision gap), and (2) successful technologies exhibited a broader range of associated human values (value breadth), suggesting strategic foresight may underpin market success. This study contributes both a practical tool for early-stage R\\&D decision-making and a theoretical link between value theory and innovation outcomes. While exploratory in scope, the findings highlight the promise of value-centric evaluation as a foundation for more human-centered technology opportunity discovery.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11855v1",
        "authors": [
          "Ayato Kitadai",
          "Takumi Ito",
          "Yumiko Nagoh",
          "Hiroki Takahashi",
          "Masanori Fujita"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Sony Computer Science Laboratories",
        "Technology Opportunity Discovery",
        "Technology Readiness Levels",
        "Basic Values Discovering",
        "Decision Support System",
        "An Application",
        "Framework",
        "Act",
        "TRL",
        "TOD",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.971376"
    },
    {
      "id": "arxiv-2602.11835v1",
      "title": "Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11835v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\\in\\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-Łojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.",
        "keywords": [
          "cs.GT",
          "cs.MA",
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11835v1",
        "authors": [
          "Yutong Chao",
          "Jalal Etesami"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.MA",
          "math.NA"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Global Convergence",
        "Nonconvex General",
        "Nash Equilibrium",
        "Condition We",
        "Sum Games",
        "Standard",
        "BCD",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.971858"
    },
    {
      "id": "arxiv-2602.11829v1",
      "title": "Towards Sustainable Investment Policies Informed by Opponent Shaping",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11829v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.",
        "keywords": [
          "cs.LG",
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11829v1",
        "authors": [
          "Juan Agustin Duque",
          "Razvan Ciuca",
          "Ayoub Echchahed",
          "Hugo Larochelle",
          "Aaron Courville"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Towards Sustainable Investment Policies",
        "Opponent Shaping Addressing",
        "Advantage Alignment",
        "Policy",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:27.972079"
    },
    {
      "id": "arxiv-2602.11822v1",
      "title": "Non-Trivial Consensus on Directed Matrix-Weighted Networks with Cooperative and Antagonistic Interactions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11822v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper investigates the non-trivial consensus problem on directed signed matrix-weighted networks\\textemdash a novel convergence state that has remained largely unexplored despite prior studies on bipartite consensus and trivial consensus. Notably, we first prove that for directed signed matrix-weighted networks, every eigenvalue of the grounded Laplacians has positive real part under certain conditions. This key finding ensures the global asymptotic convergence of systems states to the null spaces of signed matrix-weighted Laplacians, providing a foundational tool for analyzing dynamics on rooted signed matrix-weighted networks. To achieve non-trivial consensus, we propose a systematic approach involving the strategic selection of informed agents, careful design of external signals, and precise determination of coupling terms. Crucially, we derive the lower bounds of the coupling coefficients. Our consensus algorithm operates under milder connectivity conditions, and does not impose restrictions on whether the network is structurally balanced or unbalanced. Moreover, the non-trivial consensus state can be preset arbitrarily as needed. We also carry out the above analysis for undirected networks, with more relaxed conditions on the coupling coefficients comparing to the directed case. This paper further studies non-trivial consensus with switching topologies, and propose the necessary condition for the convergence of switching networks. The work in this paper demonstrates that groups with both cooperative and antagonistic multi-dimensional interactions can achieve consensus, which was previously deemed exclusive to fully cooperative groups.",
        "keywords": [
          "eess.SY",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11822v1",
        "authors": [
          "Tianmu Niu",
          "Bing Mao",
          "Xiaoqun Wu",
          "Tingwen Huang"
        ],
        "arxiv_categories": [
          "eess.SY",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Weighted Networks",
        "Trivial Consensus",
        "Directed Matrix",
        "NIST",
        "Act",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:27.972383"
    },
    {
      "id": "arxiv-2602.11772v1",
      "title": "Optimizing edge weights in the inverse eigenvector centrality problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11772v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper we study the inverse eigenvector centrality problem on directed graphs: given a prescribed node centrality profile, we seek edge weights that realize it. Since this inverse problem generally admits infinitely many solutions, we explicitly characterize the feasible set of admissible weights and introduce six optimization problems defined over this set, each corresponding to a different weight-selection strategy. These formulations provide representative solutions of the inverse problem and enable a systematic comparison of how different strategies influence the structure of the resulting weighted networks. We illustrate our framework using several real-world social network datasets, showing that different strategies produce different weighted graph structures while preserving the prescribed centrality. The results highlight the flexibility of the proposed approach and its potential applications in network reconstruction, and network design or network manipulation.",
        "keywords": [
          "cs.SI",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11772v1",
        "authors": [
          "Mauro Passacantando",
          "Fabio Raciti"
        ],
        "arxiv_categories": [
          "cs.SI",
          "math.OC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Framework",
        "Act",
        "MIT"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.972594"
    },
    {
      "id": "arxiv-2602.11754v1",
      "title": "Cooperation Breakdown in LLM Agents Under Communication Delays",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11754v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research.",
        "keywords": [
          "cs.MA",
          "cs.AI",
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11754v1",
        "authors": [
          "Keita Nishimoto",
          "Kimitaka Asatani",
          "Ichiro Sakata"
        ],
        "arxiv_categories": [
          "cs.MA",
          "cs.AI",
          "cs.GT"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Agents Under Communication Delays",
        "Cooperation Breakdown",
        "Continuous Prisoner",
        "Communication Delay",
        "Autonomous Agents",
        "Five Layers",
        "Framework",
        "FLCOA",
        "Act",
        "MAS",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-15T13:53:27.972830"
    },
    {
      "id": "arxiv-2602.11753v1",
      "title": "Building Intelligent User Interfaces for Human-AI Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11753v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Aligning AI systems with human values fundamentally relies on effective human feedback. While significant research has addressed training algorithms, the role of user interface is often overlooked and only treated as an implementation detail rather than a critical factor of alignment. This paper addresses this gap by introducing a reference model that offers a systematic framework for analyzing where and how user interface contributions can improve human-AI alignment. The structured taxonomy of the reference model is demonstrated through two case studies and a preliminary investigation featuring six user interfaces. This work highlights opportunities to advance alignment through human-computer interaction.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11753v1",
        "authors": [
          "Danqing Shi"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Building Intelligent User Interfaces",
        "Alignment Aligning",
        "Framework",
        "Intel",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.972978"
    },
    {
      "id": "arxiv-2602.11732v1",
      "title": "Achieving EF1 and Epistemic EFX Guarantees Simultaneously",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11732v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved. In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11732v1",
        "authors": [
          "Hannaneh Akrami",
          "Ryoga Mahara",
          "Kurt Mehlhorn",
          "Nidhi Rathi"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Guarantees Simultaneously We",
        "EEFX",
        "Act",
        "EFX",
        "EFL",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.973277"
    },
    {
      "id": "arxiv-2602.11707v1",
      "title": "Digital Ecosystems: Enabling Collaboration in a Fragmented World",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11707v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As geopolitical, organizational, and technological fragmentation deepens, resilient digital collaboration becomes imperative. This paper develops a spectrum framework of polycentric digital ecosystems-nested socio-technical systems spanning personal, organizational, inter-organizational, and global layers. Integration across these layers is enabled by four technology clusters: AI and automation, blockchain trust, federated data spaces, and immersive technologies. By redefining digital ecosystems as distributed, adaptive networks of loosely coupled actors, this study outlines new pathways for crossborder coordination and innovation. The framework extends platform theory by introducing a multi-layer conceptualization of polycentric digital ecosystems and demonstrates how AI-enabled infrastructures can be orchestrated to achieve digital integration in a fragmented, multipolar world.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11707v1",
        "authors": [
          "Marc Schmitt"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Enabling Collaboration",
        "Fragmented World As",
        "Digital Ecosystems",
        "Blockchain",
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.973493"
    },
    {
      "id": "arxiv-2602.11691v1",
      "title": "Searching for Optimal Prices in Two-Sided Markets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11691v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate online pricing in two-sided markets where a platform repeatedly posts prices based on binary accept/reject feedback to maximize gains-from-trade (GFT) or profit. We characterize the regret achievable across three mechanism classes: Single-Price, Two-Price, and Segmented-Price. For profit maximization, we design an algorithm using Two-Price Mechanisms that achieves $O(n^2 \\log\\log T)$ regret, where $n$ is the number of traders. For GFT maximization, the optimal regret depends critically on both market size and mechanism expressiveness. Constant regret is achievable in bilateral trade, but this guarantee breaks down as the market grows: even in a one-seller, two-buyer market, any algorithm using Single-Price Mechanisms suffers regret at least $Ω\\!\\big(\\frac{\\log\\log T}{\\log\\log\\log\\log T}\\big)$, and we provide a nearly matching $O(\\log\\log T)$ upper bound for general one-to-many markets. In full many-to-many markets, we prove that Two-Price Mechanisms inevitably incur linear regret $Ω(T)$ due to a \\emph{mismatch phenomenon}, wherein inefficient pairings prevent near-optimal trade. To overcome this barrier, we introduce \\emph{Segmented-Price Mechanisms}, which partition traders into groups and assign distinct prices per group. Using this richer mechanism, we design an algorithm achieving $O(n^2 \\log\\log T + n^3)$ regret for GFT maximization. Finally, we extend our results to the contextual setting, where traders' costs and values depend linearly on observed $d$-dimensional features that vary across rounds, obtaining regret bounds of $O(n^2 d \\log\\log T + n^2 d \\log d)$ for profit and $O(n^2 d^2 \\log T)$ for GFT. Our work delineates sharp boundaries between learnable and unlearnable regimes in two-sided dynamic pricing and demonstrates how modest increases in pricing expressiveness can circumvent fundamental hardness barriers.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11691v1",
        "authors": [
          "Yiding Feng",
          "Mengfan Ma",
          "Bo Peng",
          "Zongqi Wan"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Sided Markets We",
        "Price Mechanisms",
        "Optimal Prices",
        "Act",
        "GFT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.974242"
    },
    {
      "id": "arxiv-2602.11684v1",
      "title": "PatientHub: A Unified Framework for Patient Simulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11684v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "As Large Language Models increasingly power role-playing applications, simulating patients has become a valuable tool for training counselors and scaling therapeutic assessment. However, prior work is fragmented: existing approaches rely on incompatible, non-standardized data formats, prompts, and evaluation metrics, hindering reproducibility and fair comparison. In this paper, we introduce PatientHub, a unified and modular framework that standardizes the definition, composition, and deployment of simulated patients. To demonstrate PatientHub's utility, we implement several representative patient simulation methods as case studies, showcasing how our framework supports standardized cross-method evaluation and the seamless integration of custom evaluation metrics. We further demonstrate PatientHub's extensibility by prototyping two new simulator variants, highlighting how PatientHub accelerates method development by eliminating infrastructure overhead. By consolidating existing work into a single reproducible pipeline, PatientHub lowers the barrier to developing new simulation methods and facilitates cross-method and cross-model benchmarking. Our framework provides a practical foundation for future datasets, methods, and benchmarks in patient-centered dialogue, and the code is publicly available via https://github.com/Sahandfer/PatientHub.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11684v1",
        "authors": [
          "Sahand Sabour",
          "TszYam NG",
          "Minlie Huang"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Patient Simulation As Large",
        "Unified Framework",
        "Language Models",
        "Framework",
        "Standard",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:27.974473"
    },
    {
      "id": "arxiv-2602.11663v1",
      "title": "\"I Was Told to Come Back and Share This\": Social Media-Based Near-Death Experience Disclosures as Expressions of Spiritual Beliefs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11663v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "People who experienced near-death events often turn to personal expression as a way of processing trauma and articulating beliefs. While scholars have examined how individuals share near-death experiences (NDEs), limited research has explored how these narratives are communicated collaboratively on today's social media platforms. We analyzed 200 randomly sampled TikTok videos tagged with #nde and related hashtags. Content analysis revealed that individuals often use NDE narratives to articulate personal meaning, with spiritual and religious themes appearing in the majority of posts and serving as a means of exploring and making sense of personal spiritual perspectives. Consistent with this, analyses of comment sections reveal that videos containing spiritual themes tend to attract more engagement and foster deeper conversations around faith and meaning. Our findings offer insights into how online platforms facilitate community-level engagement with spirituality, and suggest implications for design of spaces that support shared expression and connection in specialized communities.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11663v1",
        "authors": [
          "Yifan Zhao",
          "Yuxin Fang",
          "Yihuan Chen",
          "RAY LC"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Death Experience Disclosures",
        "Spiritual Beliefs People",
        "Social Media",
        "Based Near",
        "Come Back",
        "Was Told",
        "Act",
        "WHO",
        "NDE",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.974687"
    },
    {
      "id": "arxiv-2602.11567v1",
      "title": "Behavioral Indicators of Overreliance During Interaction with Conversational Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11567v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "LLMs are now embedded in a wide range of everyday scenarios. However, their inherent hallucinations risk hiding misinformation in fluent responses, raising concerns about overreliance on AI. Detecting overreliance is challenging, as it often arises in complex, dynamic contexts and cannot be easily captured by post-hoc task outcomes. In this work, we aim to investigate how users' behavioral patterns correlate with overreliance. We collected interaction logs from 77 participants working with an LLM injected plausible misinformation across three real-world tasks and we assessed overreliance by whether participants detected and corrected these errors. By semantically encoding and clustering segments of user interactions, we identified five behavioral patterns linked to overreliance: users with low overreliance show careful task comprehension and fine-grained navigation; users with high overreliance show frequent copy-paste, skipping initial comprehension, repeated LLM references, coarse locating, and accepting misinformation despite hesitation. We discuss design implications for mitigation.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11567v1",
        "authors": [
          "Chang Liu",
          "Qinyi Zhou",
          "Xinjie Shen",
          "Xingyu Bruce Liu",
          "Tongshuang Wu"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Overreliance During Interaction",
        "Conversational Language Models",
        "Behavioral Indicators",
        "Act",
        "MIT",
        "LLM",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.974939"
    },
    {
      "id": "arxiv-2602.11522v1",
      "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11522v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the advisor's ability to create a correct schedule is important, the user's perception of expertise and trust is also influenced by how the expert utilized the AI assistant. These findings raise important considerations for the design of human-AI hybrid teams, particularly when the adoption of recommendations depends on the end-user's perception of the recommender's expertise.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11522v1",
        "authors": [
          "Dennis Kim",
          "Roya Daneshi",
          "Bruce Draper",
          "Sarath Sreedharan"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Expert Advisory Workflows Under",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.975115"
    },
    {
      "id": "arxiv-2602.11507v1",
      "title": "An Educational Human Machine Interface Providing Request-to-Intervene Trigger and Reason Explanation for Enhancing the Driver's Comprehension of ADS's System Limitations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11507v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Level 3 automated driving systems (ADS) have attracted significant attention and are being commercialized. A level 3 ADS prompts the driver to take control by issuing a request to intervene (RtI) when its operational design domains (ODD) are exceeded. However, complex traffic situations can cause drivers to perceive multiple potential triggers of RtI simultaneously, causing hesitation or confusion during take-over. Therefore, drivers need to clearly understand the ADS's system limitations to ensure safe take-over. This study proposes a voice-based educational human machine interface~(HMI) for providing RtI trigger cues and reason to help drivers understand ADS's system limitations. The results of a between-group experiment using a driving simulator showed that incorporating effective trigger cues and reason into the RtI was related to improved driver comprehension of the ADS's system limitations. Moreover, most participants, instructed via the proposed method, could proactively take over control of the ADS in cases where RtI fails; meanwhile, their number of collisions was lower compared with the other RtI HMI conditions. Therefore, using the proposed method to continually enhance the driver's understanding of the system limitations of ADS through the proposed method is associated with safer and more effective real-time interactions with ADS.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11507v1",
        "authors": [
          "Ryuji Matsuo",
          "Hailong Liu",
          "Toshihiro Hiraoka",
          "Takahiro Wada"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "An Educational Human Machine",
        "Interface Providing Request",
        "System Limitations Level",
        "Reason Explanation",
        "Intervene Trigger",
        "Fusion",
        "ODD",
        "Act",
        "HMI",
        "MIT",
        "ADS",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.975385"
    },
    {
      "id": "arxiv-2602.11492v1",
      "title": "Data-driven modelling of low-dimensional dynamical structures underlying complex full-body human movement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11492v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "One of the central challenges in the study of human motor control and learning is the degrees-of-freedom problem. Although the dynamical systems approach (DSA) has provided valuable insights into addressing this issue, its application has largely been confined to cyclic or simplified motor movements. To overcome this limitation, the present study employs neural ordinary differential equations (NODEs) to model the time evolution of non-cyclic full-body movements as a low-dimensional latent dynamical system. Given the temporal complexity full-body kinematic chains, baseball pitching was selected as a representative target movement to examine whether DSA could be extended to more complex, ecologically valid human movements. Results of the verification experiment demonstrated that the time evolution of a complex pitching motion could be accurately predicted (R^2 > 0.45) using the NODE-based dynamical model. Notably, approximately 50% of the variance in the latter half of the pitching motion was explained using only the initial ~8% of the temporal sequence, underscoring how subsequent movement evolves from initial conditions according to ODE-defined dynamics in latent space. These findings indicate the potential to extend the DSA to more complex and ecologically valid forms of human movement.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11492v1",
        "authors": [
          "Ryota Takamido",
          "Chiharu Suzuki",
          "Hiroki Nakamoto"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "NODE",
        "ODE",
        "MIT",
        "DSA",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.975618"
    },
    {
      "id": "arxiv-2602.11486v1",
      "title": "Dueling over Multiple Pieces of Dessert",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11486v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the dynamics of repeated fair division between two players, Alice and Bob, where Alice partitions a cake into two subsets and Bob chooses his preferred one over $T$ rounds. Alice aims to minimize her regret relative to the Stackelberg value -- the maximum utility she could achieve if she knew Bob's private valuation. We show that if Alice uses arbitrary measurable partitions, achieving strongly sublinear regret is impossible; she suffers a regret of $Ω\\Bigl(\\frac{T}{\\log^2 T}\\Bigr)$ regret even against a myopic Bob. However, when Alice uses at most $k$ cuts, the learning landscape becomes tractable. We analyze Alice's performance based on her knowledge of Bob's strategic sophistication (his regret budget). When Bob's learning rate is public, we establish a hierarchy of polynomial regret bounds determined by $k$ and Bob's regret budget. In contrast, when this learning rate is private, Alice can universally guarantee $O\\Bigl(\\frac{T}{\\log T}\\Bigr)$ regret, but any attempt to secure a polynomial rate $O(T^β)$ (for $β< 1$) leaves her vulnerable to incurring strictly linear regret against some Bob. Finally, as a corollary of our online learning dynamics, we characterize the randomized query complexity of finding approximate Stackelberg allocations with a constant number of cuts in the Robertson-Webb model.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11486v1",
        "authors": [
          "Simina Brânzei",
          "Reed Phillips"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Multiple Pieces",
        "Dessert We",
        "When Bob",
        "BERT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:27.976148"
    },
    {
      "id": "arxiv-2602.11483v1",
      "title": "Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11483v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Generative social agents (GSAs) use artificial intelligence to autonomously communicate with human users in a natural and adaptive manner. Currently, there is a lack of theorizing regarding interactions with GSAs, and likewise, few guidelines exist for studying how they influence user attitudes and behaviors. Consequently, we propose the Knowledge-based Persuasion Model (KPM) as a novel theoretical framework. According to the KPM, a GSA's self, user, and context-related knowledge drives its persuasive behavior, which in turn shapes the attitudes and behaviors of a responding human user. By synthesizing existing research, the model offers a structured approach to studying interactions with GSAs, supporting the development of agents that motivate rather than manipulate humans. Accordingly, the KPM encourages the integration of responsible GSAs that adhere to social norms and ethical standards with the goal of increasing user wellbeing. Implications of the KPM for research and application domains such as healthcare and education are discussed.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11483v1",
        "authors": [
          "Stephan Vonschallen",
          "Friederike Eyssel",
          "Theresa Schmiedel"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Understanding Persuasive Interactions",
        "Generative Social Agents",
        "Artificial Intelligence",
        "Persuasion Model",
        "Framework",
        "Guideline",
        "Standard",
        "Intel",
        "Act",
        "KPM",
        "GSA",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:27.976359"
    },
    {
      "id": "arxiv-2602.12261v1",
      "title": "Half-plane non-coexistence without FKG",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12261v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "For $μ$ an edge percolation measure on the infinite square lattice, let $μ_{\\textit{hp}}$ (respectively, $μ^*_{hp}$) denote its marginal (respectively, the marginal of its planar dual process) on the upper half-plane. We show that if $μ$ is translation-invariant and ergodic and almost surely has only finitely many infinite clusters, then either almost surely $μ_{hp}$ has no infinite cluster, or almost surely $μ^*_{hp}$ has no infinite cluster. By the classical Burton--Keane argument, these hypotheses are satisfied if $μ$ is translation-invariant and ergodic and has finite-energy. In contrast to previous ``non-coexistence'' theorems, our result does not impose a positive-correlation (FKG) hypothesis on $μ$. Our arguments also apply to the random-cluster model (including the regime $q<1$, which lacks FKG), the uniform spanning tree, and the uniform odd subgraph.",
        "keywords": [
          "math.PR",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12261v1",
        "authors": [
          "Frederik Ravn Klausen",
          "Noah Kravitz"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "FKG",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.154439"
    },
    {
      "id": "arxiv-2602.12234v1",
      "title": "Batch-based Bayesian Optimal Experimental Design in Linear Inverse Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12234v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Experimental design is central to science and engineering. A ubiquitous challenge is how to maximize the value of information obtained from expensive or constrained experimental settings. Bayesian optimal experimental design (OED) provides a principled framework for addressing such questions. In this paper, we study experimental design problems such as the optimization of sensor locations over a continuous domain in the context of linear Bayesian inverse problems. We focus in particular on batch design, that is, the simultaneous optimization of multiple design variables, which leads to a notoriously difficult non-convex optimization problem. We tackle this challenge using a promising strategy recently proposed in the frequentist setting, which relaxes A-optimal design to the space of finite positive measures. Our main contribution is the rigorous identification of the Bayesian inference problem corresponding to this relaxed A-optimal OED formulation. Moreover, building on recent work, we develop a Wasserstein gradient-flow -based optimization algorithm for the expected utility and introduce novel regularization schemes that guarantee convergence to an empirical measure. These theoretical results are supported by numerical experiments demonstrating both convergence and the effectiveness of the proposed regularization strategy.",
        "keywords": [
          "stat.ME",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12234v1",
        "authors": [
          "Sofia Mäkinen",
          "Andrew B. Duncan",
          "Tapio Helin"
        ],
        "arxiv_categories": [
          "stat.ME",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Linear Inverse Problems Experimental",
        "Bayesian Optimal Experimental Design",
        "Framework",
        "OED",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.154956"
    },
    {
      "id": "arxiv-2602.12230v1",
      "title": "First variation of flat traces on negatively curved surfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12230v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "For a closed negatively curved surface $(X,g)$ the flat trace of the geodesic Koopman operators $V_g^τf=f\\circ G_g^τ$ is the periodic orbit distribution \\[ \\mathrm{Tr}^{\\flat} V_{g}(τ)=\\sum_γ\\frac{L_γ^{\\#}}{\\lvert\\det(I-P_γ)\\rvert}\\,δ(τ-L_γ), \\qquad τ>0, \\] supported on the length spectrum and weighted by the linearized Poincaré maps $P_γ$. For a smooth family of negatively curved metrics $g_t$ we compute the first variation $\\partial_t\\vert_{0}\\,\\mathrm{Tr}^{\\flat} V_{g_t}$ as a distribution. At an isolated length $\\ell$ the leading singularity is a multiple of $δ'(τ-\\ell)$, and its coefficient is an explicit linear functional of the length variations $\\dot L_{γ^m}$ of the closed geodesics with $L_{γ^m}=\\ell$. This transport coefficient forces the marked lengths to be locally constant along any deformation with constant flat trace. As an application, if $\\mathrm{Tr}^{\\flat} V_{g_t}=\\mathrm{Tr}^{\\flat} V_{g_0}$ for all $t$ then $g_t$ is isometric to $g_0$ for all $t$. Together with Sunada-type constructions of non isometric pairs with equal flat traces, this shows that the flat trace is globally non-unique yet locally complete along smooth families.",
        "keywords": [
          "math.DS",
          "math.DG",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12230v1",
        "authors": [
          "Hy Lam"
        ],
        "arxiv_categories": [
          "math.DS",
          "math.DG",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.155833"
    },
    {
      "id": "arxiv-2602.12219v1",
      "title": "A Chain Ring Analogue of the Erdos-Ko-Rado Theorem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12219v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we prove an analogue of the Erdős-Ko-Rado theorem intersecting families of subspaces in projective Hjelmslev geometries over finite chain rings of nilpotency index 2. We give an example of maximal families that are not canonically intersectng.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12219v1",
        "authors": [
          "Ivan Landjev",
          "Emiliyan Rogachev",
          "Assia Rousseva"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chain Ring Analogue",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.156111"
    },
    {
      "id": "arxiv-2602.12214v1",
      "title": "The colored knapsack problem: structural properties and exact algorithms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12214v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce and study a novel generalization of the classical Knapsack Problem (KP), called the Colored Knapsack Problem (CKP). In this problem, the items are partitioned into classes of colors and the packed items need to be ordered such that no consecutive items are of the same color. We establish that the problem is weakly NP-hard and propose two exact dynamic programming algorithms with time complexities of $\\mathcal{O}(bn^4)$ and $\\mathcal{O}(b^2n^3)$, respectively. To enhance practical performance, we derive various dominance and fathoming rules for both approaches. From a theoretical perspective, we analyze the linear programming relaxation of the natural CKP formulation, proving that an optimal solution exists with at most two fractional items. We also show that the relaxation can be solved in $\\mathcal{O}(n)$ time, matching the complexity of the classical KP. Finally, we establish a comprehensive benchmark of CKP instances, derived from the Colored Bin Packing Problem. Extensive computational experiments demonstrate that the proposed dynamic programming algorithms significantly outperform state-of-the-art MIP solvers on most of these instances.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12214v1",
        "authors": [
          "Fabio Ciccarelli",
          "Alexander Helber",
          "Erik Mühmer"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Colored Bin Packing Problem",
        "Colored Knapsack Problem",
        "Knapsack Problem",
        "Act",
        "CKP",
        "MIP"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.156505"
    },
    {
      "id": "arxiv-2602.12211v1",
      "title": "On real algebraic realization of round fold maps of codimension $-1$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12211v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The canonical projections of the unit spheres are generalized to special generic maps and round fold maps, for example. They are generalizations from the viewpoint of singularity theory of differentiable maps and these maps restrict the topologies and the differentiable structures of the manifolds. We are concerned with round fold maps, defined as smooth maps locally represented as the product map of a Morse function and the identity map on a smooth manifold, and maps with singular value sets being concentric spheres. A bit different from differential topology, we are concerned with real algebraic geometric aspects of these maps. We discuss real algebraic realization of round fold maps of codimension $-1$ as our new work. Real algebraic realization of these maps is of fundamental and important studies in real algebraic geometry and a new study recently developing mainly due to the author.",
        "keywords": [
          "math.AG",
          "math.CO",
          "math.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12211v1",
        "authors": [
          "Naoki Kitazawa"
        ],
        "arxiv_categories": [
          "math.AG",
          "math.CO",
          "math.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.156814"
    },
    {
      "id": "arxiv-2602.12190v1",
      "title": "High-Temperature Increasing Propagation of Chaos and its breakdown for the Hopfield Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12190v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We analyze increasing propagation of chaos in the high temperature regime of a disordered mean-field model, the Hopfield model. We show that for $β<1$ (the true high temperature region) we have increasing propagation of chaos as long as the size of the marginals $k=k(N)$ and the number of patterns $M=M(N)$ satisfies $Mk/N \\to 0$. For $M=o(\\sqrt N)$ we show that propagation of chaos breaks down for $k/N \\to c>0$. At the ciritcal temperature we show that, for $M$ finite, there is increasing propagation of chaos, for $k=o(\\sqrt N)$, while we have breakdown of propagation of chaos for $k=c \\sqrt N$, for a $c>0$. All these reulst hold in probability in the disorder.",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12190v1",
        "authors": [
          "Matthias Löwe"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Temperature Increasing Propagation",
        "Hopfield Model We",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.157442"
    },
    {
      "id": "arxiv-2602.12188v1",
      "title": "A Discrete-Time Model of the Academic Pipeline in Mathematical Sciences with Constrained Hiring in the United States",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12188v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The field of the mathematical sciences relies on a continuous academic pipeline in which individuals progress from undergraduate study through graduate training and postdoctoral program to long term faculty employment. National statistics report trends in bachelor's, master's, and doctoral degree awards, but these data alone do not explain how individuals move through the academic system or how structural constraints shape downstream career outcomes. Persistent growth in postdoctoral appointments alongside relatively stable faculty employment indicates that degree production alone is insufficient to characterize workforce dynamics. In this study, we develop a discrete time compartmental model of the academic pipeline in the field of the mathematical sciences that links observed degree flows to latent population stocks. Undergraduate and graduate populations are reconstructed directly from nationally reported degree data, allowing postdoctoral and faculty dynamics to be examined under completion, exit, and hiring processes. Advancement to faculty positions is modeled as vacancy limited, with competition for permanent positions depending on downstream population size. Numerical simulations show that increases in degree inflow do not translate into proportional faculty growth when hiring is constrained by limited turnover. Instead, excess supply accumulates primarily at the postdoctoral stage, leading to sustained congestion and elevated competition. Sensitivity analyses indicate that long run workforce outcomes are governed mainly by faculty exit rates and hiring capacity rather than by degree production alone. These results demonstrate the central role of vacancy limited hiring in shaping academic career trajectories within the field of the mathematical sciences.",
        "keywords": [
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12188v1",
        "authors": [
          "Oluwatosin Babasola",
          "Olayemi Adeyemi",
          "Ron Buckmire",
          "Daozhou Gao",
          "Maila Hallare"
        ],
        "arxiv_categories": [
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mathematical Sciences",
        "Constrained Hiring",
        "Academic Pipeline",
        "Time Model",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.158015"
    },
    {
      "id": "arxiv-2602.12171v1",
      "title": "Global solutions and large time stabilization in a model for thermoacoustics in a standard linear solid",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12171v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This manuscript is concerned with the one-dimensional system \\[ \\begin{array}{l} τu_{ttt} + αu_{tt} = b \\big(γ(Θ) u_{xt}\\big)_x + \\big( γ(Θ) u_x\\big)_x, \\\\[1mm] Θ_t = D Θ_{xx} + bγ(Θ) u_{xt}^2, \\end{array} \\] which is connected to the simplified modeling of heat generation in Zener type materials subject to stress from acoustic waves. Under the assumption that the coefficients $τ>0, b>0$ and $α\\geq0$ satisfy \\begin{align}\\tag{$\\star$} αb >τ, \\end{align} it is shown that for all $Θ_\\star>0$ one can find $ν=ν(D,τ,α,b,Θ_\\star,γ)>0$ such that an associated Neumann type initial-boundary value problem with Neumann data admits a unique time-global solution in a suitable framework of strong solvability whenever the initial temperature distribution fulfills $$\\|Θ_0\\|_{L^\\infty(Ω)}\\leq Θ_\\star$$ and the derivatives of the initial data are sufficiently small in the sense of satisfying $$\\int_Ωu_{0xx}^2 + \\int_Ω(u_{0t})_{xx}^2 + \\int_Ω(u_{0tt})_x^2 < ν\\quad\\text{and}\\quad \\|Θ_{0x}\\|_{L^\\infty(Ω)} + \\|Θ_{0xx}\\|_{L^\\infty(Ω)} < ν.$$ The constructed solution moreover features an exponential stabilization property for both components. In particular, the parameter range described by ($\\star$) coincides with the full stability regime known for the corresponding Moore--Gibson--Thompson equation despite the fairly strong nonlinear coupling to the temperature variable.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12171v1",
        "authors": [
          "Tobias Black",
          "Michael Winkler"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.159019"
    },
    {
      "id": "arxiv-2602.12169v1",
      "title": "Independence Polynomials of graphs and degree of $h$-polynomials of edge ideals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12169v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Let $G = (V, E)$ be a finite simple graph. In this paper, we characterize the degree of the $h$-polynomial of the edge ideal of $G$ in terms of the independence number of $G$. The key tools are the value of the independence polynomial of $G$ at $-1$ and its derivative. Using this approach, we obtain, in particular, combinatorial formulas for the degree of the $h$-polynomial of paths, cycles, bipartite graphs, Cameron-Walker graphs and antiregular graphs.",
        "keywords": [
          "math.AC",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12169v1",
        "authors": [
          "Ton That Quoc Tan"
        ],
        "arxiv_categories": [
          "math.AC",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Independence Polynomials",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.159195"
    },
    {
      "id": "arxiv-2602.12166v1",
      "title": "Twisted Pollicott--Ruelle resonances and zeta function at zero on surfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12166v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "For an orientable closed surface $(Σ,g)$ of genus $G$ with Anosov geodesic flow, we show the existence of an open subset $U_g$ of finite-dimensional irreducible representations of the fundamental group of its unit tangent bundle, whose complement has complex codimension at least one and such that for any $ρ\\in U_g$, the twisted Ruelle zeta function $ζ_{g,ρ}(s)$ vanishes at $s=0$ to order ${\\rm dim}(ρ)(2G-2)$ if $ρ$ factors through $π_1(Σ)$, and does not vanish otherwise. In the second case, we show that $ζ_{g,ρ}(0)$ is given by the Reidemeister--Turaev torsion, thus extending Fried's conjecture to a generic set of acyclic (but not necessarily unitary) representations. Our proof relies on computing the dimensions of the spaces of generalized twisted Pollicott--Ruelle resonant states at zero for any $ρ\\in U_g$.",
        "keywords": [
          "math.DS",
          "math.AP",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12166v1",
        "authors": [
          "Tristan Humbert",
          "Zhongkai Tao"
        ],
        "arxiv_categories": [
          "math.DS",
          "math.AP",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Twisted Pollicott",
        "Act",
        "WHO",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.159760"
    },
    {
      "id": "arxiv-2602.12163v1",
      "title": "NLS with exponential nonlinearity on compact surfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12163v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we establish a probabilistic global theory in $H^1$ for the NLS with a Moser-Trudinger nonlinearity posed on compact surfaces. This equation is known to be the two dimensional counterpart to the classical energy-critical Schrödinger equations \\cite{CollianderIbrahimMajdoubMasmoudi2009}. The authors of \\cite{CollianderIbrahimMajdoubMasmoudi2009} also identified a trichotomy around the criticality of the equation based on the size of the total energy. In particular, for supercritical regimes (large energy), the equation is known to exhibit instabilities : the (uniform) continuity of the flow fails to hold. Large data distributional non unique probabilistic solutions have been obtained in \\cite{CasterasMonsaingeon2024}. The setting of \\cite{CasterasMonsaingeon2024} does not handle the uniqueness issue for the $H^1$-data and therefore could not define a flow for this regularity. Our main focus here is to build a single probabilistic framework that provides both existence, uniqueness, and continuity with respect to the initial data in $H^1$. Our uniqueness and continuity are based on the so-called Yudowich argument \\cite{Judovic1963}, and the probabilistic estimates are derived through the IID limit procedure \\cite{Sy2019}. Beyond the difficulties related to the borderline nature of the context, the major challenge resides in the need to satisfy two features that tend to play against each other : obtaining both continuity property of the flow and large data in the support of the reference measure. This made the design of the dissipation operator inherent in the method, as well as the analysis of the resulting quantities, particularly difficult. Regarding the supercritical regime, we show that a modified energy, with regularity similar to the original total energy, admits values as high as desired, suggesting that the constructed set of data contains supercritical ones.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12163v1",
        "authors": [
          "Filone G. Longmou-Moffo",
          "Mouhamadou Sy"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "IID",
        "NLS",
        "MIT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.160740"
    },
    {
      "id": "arxiv-2602.12130v1",
      "title": "On minimal pattern-containing inversion sequences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12130v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce the notion of minimal inversion sequences for a pattern $ρ$, which form the smallest set of inversion sequences whose avoidance is equivalent to the avoidance of $ρ$ for inversion sequences. We give a characterization of $ρ$-minimal inversion sequences based on the occurrences of the pattern $ρ$ they contain, and use it to find upper and lower bounds on the lengths of $ρ$-minimal inversion sequences. We provide some enumerative results on the exact number of minimal inversion sequences for some patterns, through a bijection with increasing trees, and some exhaustive generation. Lastly, we enumerate inversion sequences which are equal to their reduction, and find an interesting connection with poly-Bernoulli numbers.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12130v1",
        "authors": [
          "Benjamin Testart"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.161238"
    },
    {
      "id": "arxiv-2602.12122v1",
      "title": "The initial-to-final-state inverse problem with critically-singular potentials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12122v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Schrödinger equation in high dimensions describes the evolution of a quantum system. Assume that we are given the evolution map sending each initial state $f\\in L^2(\\mathbb{R}^n)$ of the system to the corresponding final state at a fixed time $T$. The main question we address in this paper is whether this initial-to-final-state map uniquely determines the Hamiltonian $-Δ+V$ that generates the evolution. We restrict attention to time-independent potentials $V$ and show that uniqueness holds provided $V \\in L^1(\\mathbb{R}^n)\\cap L^q(\\mathbb{R}^n)$, with $q>1$ if $n=2$ or $q\\geq n/2$ if $n\\geq 3$. This should be compared with the results of Caro and Ruiz, who proved that in the time-dependent case, uniqueness holds under the stronger assumption that the potential exhibits super-exponential decay at infinity, for both bounded and unbounded potentials. This paper extends earlier work of the same authors, where uniqueness was obtained for bounded time-independent potentials with polynomial decay at infinity. Here we only require $L^1$-type decay at infinity and allow for $L^q$-type singularities. We reach this improvement by providing a refinement of the Kenig-Ruiz-Sogge resolvent estimate, which replaces the classical Agmon-Hörmander estimates used previously. Crucially, the time-independent setting allows us to avoid the use of complex geometrical optics solutions and thereby dispense with strong decay assumptions at infinity.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12122v1",
        "authors": [
          "Manuel Cañizares",
          "Pedro Caro",
          "Ioannis Parissis",
          "Thanasis Zacharopoulos"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.162149"
    },
    {
      "id": "arxiv-2602.12121v1",
      "title": "Low T-Phase Rank Approximation of Third Order Tensors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12121v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study low T-phase-rank approximation of sectorial third-order tensors $\\mathscr{A}\\in\\mathbb{C}^{n\\times n\\times p}$ under the tensor T-product. We introduce canonical T-phases and T-phase rank, and formulate the approximation task as minimizing a symmetric gauge of the canonical phase vector under a T-phase-rank constraint. Our main tool is a tensor phase-majorization inequality for the geometric mean, obtained by lifting the matrix inequality through the block-circulant representation. In the positive-imaginary regime, this yields an exact optimal-value formula and an explicit optimal half-phase truncation family. We further establish tensor counterparts of classical matrix phase inequalities and derive a tensor small phase theorem for MIMO linear time-invariant systems.",
        "keywords": [
          "math.NA",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12121v1",
        "authors": [
          "Taehyeong Kim",
          "Hayoung Choi",
          "Yimin Wei"
        ],
        "arxiv_categories": [
          "math.NA",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Phase Rank Approximation",
        "Third Order Tensors We",
        "MIMO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.162397"
    },
    {
      "id": "arxiv-2602.12104v1",
      "title": "Liquidation Dynamics in DeFi and the Role of Transaction Fees",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12104v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Liquidation of collateral are the primary safeguard for solvency of lending protocols in decentralized finance. However, the mechanics of liquidations expose these protocols to predatory price manipulations and other forms of Maximal Extractable Value (MEV). In this paper, we characterize the optimal liquidation strategy, via a dynamic program, from the perspective of a profit-maximizing liquidator when the spot oracle is given by a Constant Product Market Maker (CPMM). We explicitly model Oracle Extractable Value (OEV) where liquidators manipulate the CPMM with sandwich attacks to trigger profitable liquidation events. We derive closed-form liquidation bounds and prove that CPMM transaction fees act as a critical security parameter. Crucially, we demonstrate that fees do not merely reduce attacker profits, but can make such manipulations unprofitable for an attacker. Our findings suggest that CPMM transaction fees serve a dual purpose: compensating liquidity providers and endogenously hardening CPMM oracles against manipulation without the latency of time-weighted averages or medianization.",
        "keywords": [
          "q-fin.MF",
          "math.DS",
          "q-fin.TR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12104v1",
        "authors": [
          "Agathe Sadeghi",
          "Zachary Feinstein"
        ],
        "arxiv_categories": [
          "q-fin.MF",
          "math.DS",
          "q-fin.TR"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Constant Product Market Maker",
        "Transaction Fees Liquidation",
        "Maximal Extractable Value",
        "Oracle Extractable Value",
        "Liquidation Dynamics",
        "Protocol",
        "Oracle",
        "CPMM",
        "Act",
        "MEV",
        "OEV",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:32.162717"
    },
    {
      "id": "arxiv-2602.12103v1",
      "title": "Local Integrable Symmetries of Diffieties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12103v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the framework of diffieties, introduced by Vinogradov, we introduce integrable infinitesimal symmetries and show that they define a one parameter pseudogroup of local diffiety morphisms. We prove some preliminary results allowing to reduce the computation of integrable infinitesimal symmetries of a given order to solving a system of partial differential equations.We provide examples for which we can reduce to a linear system that can be solved by hand computation, and investigate some consequences for the local classification of diffiety, with a special interest for testing if a diffiety is flat.",
        "keywords": [
          "math.DG",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12103v1",
        "authors": [
          "François Ollivier",
          "Yirmeyahu J. Kaminski"
        ],
        "arxiv_categories": [
          "math.DG",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Local Integrable Symmetries",
        "Diffieties In",
        "Framework",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.162914"
    },
    {
      "id": "arxiv-2602.12091v1",
      "title": "Series involving central binomial coefficients and harmonic numbers of order 2",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12091v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We derive modular parametrizations for certain infinite series whose summands involve central binomial coefficients and second-order harmonic numbers. When the rates of convergence are certain rational numbers, modularity allows us to reduce the corresponding series to special values of the Dirichlet $L$-values. For example, we establish the following identity that has been recently conjectured by Sun:\\[\\sum_{k=0}^\\infty\\binom{2k}{k}^3\\left[ \\mathsf H_{2k}^{(2)}-\\frac{25}{92}\\mathsf H_{ k}^{(2)} +\\frac{735L_{-7}(2)-86π^{2}}{1104}\\right]\\frac{1}{4096^{k}}=0,\\] where $ \\mathsf H^{(2)}_k:= \\sum_{0<j\\leq k}\\frac{1}{j^2}$ and $ L_{-7}(2):= \\sum_{n=1}^\\infty\\left(\\frac{-7}{n}\\right)\\frac{1}{n^2}=\\frac{1}{1^2}+\\frac{1}{2^2}-\\frac{1}{3^2}+\\frac{1}{4^{2}}-\\frac{1}{5^{2}}-\\frac{1}{6^{2}}+\\frac{1}{8^{2}}+\\cdots $.",
        "keywords": [
          "math.NT",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12091v1",
        "authors": [
          "Zhi-Wei Sun",
          "Yajun Zhou"
        ],
        "arxiv_categories": [
          "math.NT",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.163460"
    },
    {
      "id": "arxiv-2602.12073v1",
      "title": "Some remarks on monodromy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12073v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We consider hypoelliptic symbols over a very regular Lie group and discuss monodromy for a spectral stratification using results of Nilsson and Bäcklund.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12073v1",
        "authors": [
          "Tove Dahn"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.163593"
    },
    {
      "id": "arxiv-2602.12061v1",
      "title": "Bond failure in peridynamics: Nonequivalence of critical stretch and critical energy density criteria",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12061v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper rigorously analyzes bond failure in the peridynamic theory of solid mechanics, which is a fundamental component of fracture modeling. We compare analytically and numerically two common bond-failure criteria:~{\\em critical stretch} and~{\\em critical energy density}. In the former, bonds fail when they stretch to a critical value, whereas in the latter, bonds fail when the bond energy density exceeds a threshold. By focusing the analysis on bond-based models, we prove mathematically that the critical stretch criterion and the critical energy density criterion are not equivalent in general and result in different bond-breaking and fracture phenomena. Numerical examples showcase the striking differences between the effect of the two criteria on crack dynamics, including the crack tip evolution, crack propagation, and crack branching.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12061v1",
        "authors": [
          "Pablo Seleson",
          "Pablo Raúl Stinga",
          "Mary Vaughan"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.163930"
    },
    {
      "id": "arxiv-2602.12046v1",
      "title": "Local boundedness for solutions to parabolic $p,q$-problems with degenerate coefficients",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12046v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the local boundedness of solutions $u:Ω_T\\to\\mathbb{R}$ to parabolic equations of the form \\begin{equation*} \\partial_tu-\\mathrm{div}\\,\\mathcal{A}(x,t,Du)=0 \\qquad\\mbox{in }Ω_T=Ω\\times(0,T) \\end{equation*} that satisfy $p,q$-growth conditions and have degenerate coefficients. More precisely, we assume structure conditions of the type \\begin{align*} |\\mathcal{A}(x,t,ξ)|&\\le b(x,t)(μ^2+|ξ|^2)^{\\frac{q-1}{2}},\\\\ \\langle \\mathcal{A}(x,t,ξ),ξ\\rangle&\\ge a(x,t)(μ^2+|ξ|^2)^{\\frac {p-2}{2}}|ξ|^2, \\end{align*} for $2\\le p\\le q$ and $μ\\in[0,1]$, where the functions $a^{-1}, b:Ω_T\\to\\mathbb{R}$ are possibly unbounded and only satisfy some integrability condition. Under a certain assumption on the gap between $p$ and $q$, we prove two main results. First, we show that subsolutions that are contained in the natural energy space are locally bounded from above. Second, for parabolic equations with a variational structure, we use these bounds to show the existence of locally bounded variational solutions.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12046v1",
        "authors": [
          "Flavia Giannetti",
          "Antonia Passarelli di Napoli",
          "Christoph Scheven"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.164646"
    },
    {
      "id": "arxiv-2602.12033v1",
      "title": "On the interplay between $(p,q)$-growth and $x$-dependence of the energy integrand: a limit case",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12033v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We establish the local Lipschitz regularity of the local minimizers of non autonomous integral funtionals of the form \\[ \\int_ΩF(x, Dz)\\,dx, \\] where $Ω$ is a bounded open set of $\\mathbb{R}^n$, $n \\ge 2$. The energy density $F(x,ξ)$ satisfies $(p,q)-$growth conditions with respect to the gradient variable and belongs to the Sobolev class $W^{1,φ}$, with $φ(t)=t^r\\log^α(e+t),$ $r\\ge n$, $α\\ge 0$, as a function of the $x$ variable, under the condition $$ 1\\le\\frac{q}{p} \\le 1 + \\frac{1}{n} - \\frac{1}{r}. $$ We present a unified approach that covers the limit case $$ \\frac{q}{p} = 1 + \\frac{1}{n} - \\frac{1}{r} $$ and retrieves the results in \\cite{EMM16} and in \\cite{CGHPdN20}.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12033v1",
        "authors": [
          "M. Eleuteri",
          "P. Marcellini",
          "E. Mascolo",
          "A. Passarelli di Napoli"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.165144"
    },
    {
      "id": "arxiv-2602.12027v1",
      "title": "General-purpose post-sampling reweighting method for multimodal target measures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12027v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "When sampling multi-modal probability distributions, correctly estimating the relative probability of each mode, even when the modes have been discovered and locally sampled, remains challenging. We test a simple reweighting scheme designed for this situation, which consists in minimizing (in terms of weights) the Kullback-Leibler divergence of a weighted (regularized) empirical distribution of the samples with respect to the target measure.",
        "keywords": [
          "math.ST",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12027v1",
        "authors": [
          "Pierre Monmarché"
        ],
        "arxiv_categories": [
          "math.ST",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.165310"
    },
    {
      "id": "arxiv-2602.12023v1",
      "title": "Decomposition of Spillover Effects Under Misspecification:Pseudo-true Estimands and a Local--Global Extension",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12023v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Applied work with interference typically models outcomes as functions of own treatment and a low-dimensional exposure mapping of others' treatments, even when that mapping may be misspecified. This raises a basic question: what policy object are exposure-based estimands implicitly targeting, and how should we interpret their direct and spillover components relative to the underlying policy question? We take as primitive the marginal policy effect, defined as the effect of a small change in the treatment probability under the actual experimental design, and show that any researcher-chosen exposure mapping induces a unique pseudo-true outcome model. This model is the best approximation to the underlying potential outcomes that depends only on the user-chosen exposure. Utilizing that representation, the marginal policy effect admits a canonical decomposition into exposure-based direct and spillover effects, and each component provides its optimal approximation to the corresponding oracle objects that would be available if interference were fully known. We then focus on a setting that nests important empirical and theoretical applications in which both local network spillovers and global spillovers, such as market equilibrium, operate. There, the marginal policy effect further decomposes asymptotically into direct, local, and global channels. An important implication is that many existing methods are more robust than previously understood once we reinterpret their targets as channel-specific components of this pseudo-true policy estimand. Simulations and a semi-synthetic experiment calibrated to a large cash-transfer experiment show that these components can be recovered in realistic experimental designs.",
        "keywords": [
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12023v1",
        "authors": [
          "Yechan Park",
          "Xiaodong Yang"
        ],
        "arxiv_categories": [
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Spillover Effects Under Misspecification",
        "Global Extension Applied",
        "Oracle",
        "Policy",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:32.165757"
    },
    {
      "id": "arxiv-2602.12008v1",
      "title": "Mesh-free numerical method for Dirichlet eigenpairs of the Laplacian with potential",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12008v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper is concerned with the numerical approximation of the $L^2$ Dirichlet eigenpairs of the operator $-Δ+ V$ on a simply connected $C^2$ bounded domain $Ω\\subset \\mathbb{R}^2$ containing the origin, where $V$ is a radial potential. We propose a mesh-free method inspired by the Method of Particular Solutions for the Laplacian (i.e. $V=0$). Extending this approach to general $C^1$ radial potentials is challenging due to the lack of explicit basis functions analogous to Bessel functions. To overcome this difficulty, we consider the equation $-Δu + V u = λu$ on a ball containing $Ω$, without imposing boundary conditions, for a collection of values $λ$ forming a fine discretisation of the interval in which eigenvalues are sought. By rewriting the problem in polar coordinates and applying a Fourier expansion with respect to the angular variable, we obtain a decoupled system of ordinary differential equations. These equations are solved numerically using a one-dimensional Finite Element Method, yielding a family of basis functions that are solutions of the equation $-Δu + V u = λu$ on the ball and are independent of the domain $Ω$. Dirichlet eigenvalues of $-Δ+ V$ are then approximated by minimising the boundary values on $\\partial Ω$ among linear combinations of the basis functions and identifying those values of $λ$ for which the computed minimum is sufficiently small. The proposed method is highly memory-efficient compared to the standard Finite Element approach.",
        "keywords": [
          "math.NA",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12008v1",
        "authors": [
          "Dragoş Manea"
        ],
        "arxiv_categories": [
          "math.NA",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Finite Element Method",
        "Particular Solutions",
        "Finite Element",
        "Standard",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.166696"
    },
    {
      "id": "arxiv-2602.12007v1",
      "title": "Density of Neumann regular smooth functions in Sobolev spaces of subanalytic manifolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12007v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We give characterizations of the bounded subanalytic $\\mathscr{C}^\\infty$ submanifolds $M$ of $\\mathbb{R}^n$ for which the space of Neumann regular functions is dense in Sobolev spaces. By ``Neumann regular function'', we mean a function which is smooth at almost every boundary point and whose gradient is tangent to the boundary. In the case $p\\in [1,2]$, we prove that the Neumann regular elements of $\\mathscr{C}^\\infty(\\overline{M})$ are dense in $W^{1,p}(M)$ if and only if $M$ is connected at almost every boundary point. In the case $p$ large, we show that the Neumann regular Lipschitz elements of $\\mathscr{C}^\\infty(M)$ are dense in $W^{1,p}(M)$ if and only if $M$ is connected at every boundary point. The proof involves the construction of Lipschitz Neumann regular partitions of unity, which is of independent interest.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12007v1",
        "authors": [
          "Guillaume Valette"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lipschitz Neumann",
        "Act",
        "WHO",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.166951"
    },
    {
      "id": "arxiv-2602.12006v1",
      "title": "A Novel Approach to Peng's Maximum Principle for McKean-Vlasov Stochastic Differential Equations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12006v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a novel approach to the proof of Peng's maximum principle for McKean-Vlasov stochastic differential equations (SDE). The main step is the introduction of a third adjoint equation, a conditional McKean-Vlasov backward SDE, to accommodate the dualization of quadratic terms containing two independent copies of the first-order variational process. This is an intrinsic extension of the maximum principle from Peng for standard SDE and gives a conceptually consistent proof. Our approach will be useful in further extensions to the common noise setting and the infinite dimensional setting.",
        "keywords": [
          "math.PR",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12006v1",
        "authors": [
          "Johan Benedikt Spille",
          "Wilhelm Stannat"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vlasov Stochastic Differential Equations",
        "Maximum Principle",
        "Novel Approach",
        "Standard",
        "SDE",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.167160"
    },
    {
      "id": "arxiv-2602.12001v1",
      "title": "Inner regularity and Liouville theorems for stable solutions to the mean curvature equation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12001v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Let $f\\in C^1(\\mathbb{R})$. We study stable solutions $u$ of the mean curvature equation \\[ \\operatorname{div}\\left( \\frac{\\nabla u}{\\sqrt{1+|\\nabla u|^2}} \\right) = -f(u) \\qquad \\text{in}\\ Ω\\subset \\mathbb{R}^n. \\] In the local setting we prove that $\\nabla u$ satisfies inner Morrey regularity $M^{p_n}$, where \\[ p_n := \\left\\{ \\begin{array}{ll} n,\\qquad & \\text{if}\\ 2\\leq n\\leq 5, \\\\ \\frac{n}{n-4\\sqrt{n-1}+4},\\qquad & \\text{if}\\ n\\geq 6, \\end{array} \\right. \\] together with the estimate \\[ \\|\\nabla u\\|_{M^{p_n}(B_1)} \\leq C \\left( 1+\\|\\nabla u\\|_{L^1(B_2)} \\right). \\] The exponent $p_n$ is optimal for $n\\leq5$, as shown by an explicit one-dimensional example. For radial solutions we show that the symmetry center is at most a removable singularity. Globally, we establish Liouville-type theorem: any stable solution satisfying the growth condition \\[ |\\nabla u(x)| = \\left\\{ \\begin{array}{lll} o(|x|^{-1}) \\ & \\text{as}\\ |x|\\rightarrow +\\infty& \\text{when}\\ 2\\leq n\\leq 10, \\\\ o(|x|^{-n/2+\\sqrt{n-1}+1}) \\ & \\text{as}\\ |x|\\rightarrow +\\infty& \\text{when}\\ n\\geq 11, \\end{array} \\right. \\] must be constant. In particular, no nonconstant radial stable solution exists in dimensions \\(2\\leq n\\leq6\\), which highlights a global rigidity of stable radial solutions in low dimensions and extend the classical Liouville theorem of Farina and Navarro. Several exponents appearing in our results are new for mean curvature equations, showing both similarities and differences with the corresponding theorems for semilinear equations.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12001v1",
        "authors": [
          "Fanheng Xu"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.168081"
    },
    {
      "id": "arxiv-2602.11999v1",
      "title": "Local convergence of mean-field Langevin dynamics: from gradient flows to linearly monotone games",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11999v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the local convergence of diffusive mean-field systems, including Wasserstein gradient flows, min-max dynamics, and multi-species games. We establish exponential local convergence in $χ^2$-divergence with sharp rates, under two main assumptions: (i) the stationary measures satisfy a Poincaré inequality, and (ii) the velocity field satisfies a monotonicity condition, which reduces to linear convexity of the objective in the gradient flow case. We do not assume any form of displacement convexity or displacement monotonicity. In the gradient flow case, global exponential convergence is already known under our linear convexity assumption, with an asymptotic rate governed by the log-Sobolev constant of the stationary measure. Our contribution in this setting is to identify the sharp rate near equilibrium governed instead by the Poincaré constant. This rate coincides with the one suggested by Otto calculus (i.e. by a tight positivity estimate of the Wasserstein Hessian), and refines some results of Tamura (1984), extending them beyond quadratic objectives. More importantly, our proof technique extends to certain non-gradient systems, such as linearly monotone two-player and multi-player games. In this case, we obtain explicit local exponential convergence rates in $χ^2$-divergence, thereby partially answering the open question raised by the authors at COLT 2024. While that question concerns global convergence (which remains open), even local convergence results were previously unavailable. At the heart of our analysis is the design of a Lyapunov functional that mixes the $χ^2$-divergence with weighted negative Sobolev norms of the density relative to equilibrium.",
        "keywords": [
          "math.OC",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11999v1",
        "authors": [
          "Guillaume Wang",
          "Lénaïc Chizat"
        ],
        "arxiv_categories": [
          "math.OC",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wasserstein Hessian",
        "COLT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.169020"
    },
    {
      "id": "arxiv-2602.11991v1",
      "title": "Improved Interior Gradient Estimates for the Mean Curvature Equation under Nonlinear Assumptions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11991v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we investigate interior gradient estimates for solutions to the mean curvature equation $$ \\dive \\left( \\frac{\\nabla u}{\\sqrt{1 + |\\nabla u|^2}} \\right) = f(\\nabla u)$$ under various nonlinear assumptions on the right-hand side. Under the weakened initial assumption $u\\in C^1(B_R) \\cap C^3(\\{|\\nabla u|>0\\})$, we establish sharp gradient bounds that depend on the oscillation of the solution. These estimates are applicable to a wide class of nonlinear terms, including the specific forms arising from the elliptic regularization of the inverse mean curvature flow ($f=\\varepsilon\\sqrt{1+|\\nabla u|^2}$ ), minimal surface equation ($f=0$) and several polynomial and logarithmic growth regimes. As applications, the gradient bounds imply uniform ellipticity of the equation away from the critical set,which allows one to apply classical elliptic regularity theory and obtain higher regularity of solutions in the noncritical region. Moreover, when the solution grows at most linearly, all cases of our results can be applied in Moser's theory to establish the affine linear rigidity of global solutions. This directly leads to the Liouville-type theorems for global solutions without requiring additional proofs.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11991v1",
        "authors": [
          "Fanheng Xu"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Improved Interior Gradient Estimates",
        "Nonlinear Assumptions In",
        "Mean Curvature Equation",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.169330"
    },
    {
      "id": "arxiv-2602.11990v1",
      "title": "A positive instance of Scott's Conjecture on induced subdivisions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11990v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "For a graph $G$, $χ(G)$ denotes the chromatic number of $G$ and $ω(G)$ denotes the size of the largest clique in $G$. A hereditary class of graphs is called $χ$-bounded if there is a function $f$ such that for each graph $G$ in the class, $χ(G) \\le f(ω(G))$. Scott (1997) conjectured that for every graph $H$, the class of graphs which do not contain any subdivision of $H$ as an induced subgraph is $χ$-bounded. He proved his conjecture when $H$ is a tree and when $H$ is the complete graph on four vertices, $K_4$. Esperet and Trotignon (2019) proved that the conjecture holds when $H$ is $K_4$ with one edge subdivided once. Scott's conjecture was disproved by Pawlik et al. (2014). Chalopin et al. (2016) gave more counterexamples including the graph obtained from $K_4$ by subdividing each edge of a 4-cycle once. We prove that the conjecture holds when $H$ consists of a complete bipartite graph with and additional vertex which has exactly two neighbours, on the same side of the bipartition. As a special case, this proves Scott's conjecture when $H$ is obtained from $K_4$ by subdividing two disjoint edges.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11990v1",
        "authors": [
          "Kathie Cameron",
          "Ni Luh Dewi Sintiari",
          "Sophie Spirkl"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.169985"
    },
    {
      "id": "arxiv-2602.11987v1",
      "title": "Recovery of an Anisotropic Conductivity from the Neumann-to-Dirichlet Map in a Semilinear Elliptic Equation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11987v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the inverse boundary value problem of detecting a non-uniform conductivity motivated by pacing-guided ablation in cardiac electrophysiology. At the stationary level, the transmembrane potential $u$ in a region \\(Ω\\subset\\mathbb{R}^3\\) of cardiac tissue satisfies \\[ -\\nabla\\!\\cdot(γ\\nabla u)+αu^3=0 \\quad \\text{in }Ω,\\qquad γ\\nabla u\\cdotν=g \\quad \\text{on }\\partialΩ, \\] where $γ$ is an anisotropic conductivity tensor and $α$ a nonlinear ionic response coefficient. The Neumann data $g$ represent pacing currents, and the boundary values $u|_{\\partialΩ}$ correspond to invasive voltage measurements. Ischemic regions are modeled by a subdomain $D\\subsetΩ$ where $γ$ is piecewise constant. We address the inverse problem of determining $γ$ from the Neumann-to-Dirichlet (NtD) map, assuming that $α$ and $D$ are known. To our knowledge, uniqueness in the case of NtD data with anisotropic conductivities in this nonlinear setting has not been analyzed in previous work. Using a first-order linearization around a nontrivial pacing current, we prove uniqueness for $γ$.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11987v1",
        "authors": [
          "Elena Beretta",
          "Elisa Francini",
          "Dario Pierotti",
          "Eva Sincich"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Semilinear Elliptic Equation We",
        "Anisotropic Conductivity",
        "Dirichlet Map",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.170637"
    },
    {
      "id": "arxiv-2602.11981v1",
      "title": "Stability of Phase-Locked States in Signed Kuramoto Networks: Structure versus Adaptation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11981v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Adaptive Kuramoto models admit a variety of nontrivial phase-locked configurations, including antipodal and rotating-wave states. A central open question is whether the observed persistence of such configurations can be attributed to intrinsic properties of the associated signed interaction networks, or whether it relies essentially on adaptive coupling dynamics. To address this question, we study the stability of antipodal and rotating-wave phase configurations on fixed signed networks that preserve the same phase symmetries but are not generated by adaptive dynamics. We show that for two canonical classes of static signed networks, stability is highly constrained, with unstable modes persisting under parameter variations generically, and we characterize how adaptive coupling influences invariant sets and basins of attraction for the configurations where stability is permitted. Taken together, these results show that while static network structure imposes severe constraints on the stability of phase-locked configurations, adaptive coupling dynamics organize and delineate their robustness when stability is permitted.",
        "keywords": [
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11981v1",
        "authors": [
          "Jaeyoung Yoon",
          "Christian Kuehn"
        ],
        "arxiv_categories": [
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adaptation Adaptive Kuramoto",
        "Signed Kuramoto Networks",
        "Locked States",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.170933"
    },
    {
      "id": "arxiv-2602.11976v1",
      "title": "Lambda admissible subspaces of self adjoint matrices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11976v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Given a self-adjoint matrix $A$ and an index $h$ such that $λ_h(A)$ lies in a cluster of eigenvalues of $A$, we introduce the novel class of $Λ$-admissible subspaces of $A$ of dimension $h$. First, we show that the low-rank approximation of the form $P_{\\mathcal{T}} A P_{\\mathcal{T}}$, for a subspace $\\mathcal{T}$ that is close to any $Λ$-admissible subspace of $A$, has nice properties. Then, we prove that some well-known iterative algorithms (such as the Subspace Iteration Method, or the Krylov subspace method) produce subspaces that become arbitrarily close to $Λ$-admissible subspaces. We obtain upper bounds for the distance between subspaces obtained by the Rayleigh-Ritz method applied to $A$ and the class of $Λ$-admissible subspaces. We also find upper bounds for the condition number of the (set-valued) map computing the class of $Λ$-admissible subspaces of $A$. Finally, we include numerical examples that show the advantage of considering this new class of subspaces in the clustered eigenvalue setting.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11976v1",
        "authors": [
          "Francisco Arrieta Zuccalli",
          "Pedro Massey"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Subspace Iteration Method",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.171513"
    },
    {
      "id": "arxiv-2602.11972v1",
      "title": "Splitting Schemes for ODEs with Goal-Oriented Error Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11972v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a hybrid a-priori/a-posteriori goal oriented error estimator for a combination of dynamic iteration-based solution of ordinary differential equations discretized by finite elements. Our novel error estimator combines estimates from classical dynamic iteration methods, usually used to enable splitting-based distributed simulation, and from the dual weighted residual method to be able to evaluate and balance both, the dynamic iteration error and the discretization error in desired quantities of interest. The obtained error estimators are used to conduct refinements of the computational mesh and as a stopping criterion for the dynamic iteration. In particular, we allow for an adaptive and flexible discretization of the time domain, where variables can be discretized differently to match both goal and solution requirements, e.g. in view of multiple time scales. We endow the scheme with efficient solvers from numerical linear algebra to ensure its applicability to complex problems. Numerical experiments compare the adaptive approach to a uniform refinement.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11972v1",
        "authors": [
          "Erik Weyl",
          "Andreas Bartel",
          "Manuel Schaller"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oriented Error Estimation We",
        "Splitting Schemes",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.171785"
    },
    {
      "id": "arxiv-2602.11948v1",
      "title": "Insights on Muon from Simple Quadratics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11948v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Muon updates weight matrices along (approximate) polar factors of the gradients and has shown strong empirical performance in large-scale training. Existing attempts at explaining its performance largely focus on single-step comparisons (on quadratic proxies) and worst-case guarantees that treat the inexactness of the polar-factor as a nuisance ``to be argued away''. We show that already on simple strongly convex functions such as $L(W)=\\frac12\\|W\\|_{\\text{F}}^2$, these perspectives are insufficient, suggesting that understanding Muon requires going beyond local proxies and pessimistic worst-case bounds. Instead, our analysis exposes two observations that already affect behavior on simple quadratics and are not well captured by prevailing abstractions: (i) approximation error in the polar step can qualitatively alter discrete-time dynamics and improve reachability and finite-time performance -- an effect practitioners exploit to tune Muon, but that existing theory largely treats as a pure accuracy compromise; and (ii) structural properties of the objective affect finite-budget constants beyond the prevailing conditioning-based explanations. Thus, any general theory covering these cases must either incorporate these ingredients explicitly or explain why they are irrelevant in the regimes of interest.",
        "keywords": [
          "math.OC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11948v1",
        "authors": [
          "Antoine Gonon",
          "Andreea-Alexandra Muşat",
          "Nicolas Boumal"
        ],
        "arxiv_categories": [
          "math.OC",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Simple Quadratics Muon",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.172096"
    },
    {
      "id": "arxiv-2602.11947v1",
      "title": "Mixed-Integer Programming for Change-point Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11947v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a new mixed-integer programming (MIP) approach for offline multiple change-point detection by casting the problem as a globally optimal piecewise linear (PWL) fitting problem. Our main contribution is a family of strengthened MIP formulations whose linear programming (LP) relaxations admit integral projections onto the segment assignment variables, which encode the segment membership of each data point. This property yields provably tighter relaxations than existing formulations for offline multiple change-point detection. We further extend the framework to two settings of active research interest: (i) multidimensional PWL models with shared change-points, and (ii) sparse change-point detection, where only a subset of dimensions undergo structural change. Extensive computational experiments on benchmark real-world datasets demonstrate that the proposed formulations achieve reductions in solution times under both $\\ell_1$ and $\\ell_2$ loss functions in comparison to the state-of-the-art.",
        "keywords": [
          "math.OC",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11947v1",
        "authors": [
          "Apoorva Narula",
          "Santanu S. Dey",
          "Yao Xie"
        ],
        "arxiv_categories": [
          "math.OC",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Integer Programming",
        "Detection We",
        "Framework",
        "Act",
        "WHO",
        "PWL",
        "MIT",
        "MIP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.172327"
    },
    {
      "id": "arxiv-2602.11926v1",
      "title": "Optimal Quantization for Nonuniform Densities on Spherical Curves",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11926v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present an analysis of optimal quantization of probability measures with nonuniform densities on spherical curves. We begin by deriving the centroid condition, followed by a high-resolution asymptotic analysis to establish the point-density formula. We further quantify the asymptotic error formula for the nonuniform densities. We apply these theorems to the von Mises distributions and characterize the optimal condition. We also provide applications using the high-resolution asymptotic and its corresponding error formula. Our results can be used in geometric probability theory and quantization theory of spherical curves.",
        "keywords": [
          "math.PR",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11926v1",
        "authors": [
          "Silpi Saha",
          "Sangita Jha",
          "Mrinal Kanti Roychowdhury"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonuniform Densities",
        "Optimal Quantization",
        "Spherical Curves We",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.172493"
    },
    {
      "id": "arxiv-2602.11921v1",
      "title": "Relationship Between Controllability Scoring and Optimal Experimental Design",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11921v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Controllability scores provide control-theoretic centrality measures that quantify the relative importance of state nodes in networked dynamical systems. We establish a structural connection between finite-time controllability scoring and approximate optimal experimental design (OED): the finite-time controllability Gramian decomposes additively across nodes, yielding an affine matrix model of the same form as the information-matrix model in OED. This yields a direct correspondence between the volumetric controllability score (VCS) and D-optimality, and between the average energy controllability score (AECS) and A-optimality, implying that the classical D/A invariance gap has a direct analogue in controllability scoring. By contrast, we point out that controllability scoring typically admits a unique optimizer, unlike approximate-OED formulations. Finally, we uncover a long-horizon phenomenon with no OED counterpart: source-like state nodes without a negative self-loop can be increasingly downweighted by AECS as the horizon grows. Two numerical examples corroborate this long-horizon downweighting behavior.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11921v1",
        "authors": [
          "Kazuhiro Sato"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Relationship Between Controllability Scoring",
        "Optimal Experimental Design Controllability",
        "AECS",
        "OED",
        "MIT",
        "VCS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.172745"
    },
    {
      "id": "arxiv-2602.11915v1",
      "title": "Eigenfracture approximation of quasi-static crack growth in brittle materials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11915v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study an approximation scheme for a variational theory of quasi-static crack growth based on an eigendeformation approach. We consider a family of energy functionals depending on a small parameter $\\varepsilon$ and on two fields, the displacement field and an eigendeformation field that approximates the crack in the material. By imposing a suitable irreversibility condition and adopting an incremental minimization scheme, we define a notion of quasi-static evolution for this model. We then show that, as $\\varepsilon \\to 0$, these evolutions converge to a quasi-static crack evolution for the Griffith energy of brittle fracture, characterized by irreversibility, global stability, and an energy balance.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11915v1",
        "authors": [
          "Ba Duc Duong",
          "Manuel Friedrich"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.172923"
    },
    {
      "id": "arxiv-2602.11905v1",
      "title": "Strong convergence of random representations of free products of finite groups",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11905v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We extend the polynomial method of Chen--Garza-Vargas--Tropp--van Handel and Magee--Puder--van Handel for operator-norm bounds in random permutation models to the setting where torsion is present. The main new feature is that asymptotic expansion of traces naturally involves fractional powers of $N$ rather than an ordinary Laurent series. We formulate fractional-power analogues of the method's key hypotheses and prove they lead to strong convergence. We verify these analogues for free products of finite groups $Γ=G_1*\\cdots*G_m$. Concretely, for a uniformly random $φ_N\\in{\\rm hom}(Γ,{\\rm Sym}(N))$, set $π_N = {\\rm std} \\circ φ_N$, where ${\\rm std}$ denotes the standard $(N-1)$-dimensional representation of ${\\rm Sym}(N)$ (the permutation representation with the trivial subrepresentation removed). We deduce strong convergence of $π_N$ to the left regular representation of $Γ$. As applications, we obtain asymptotically sharp spectral gaps for the associated random Schreier graphs, including almost Ramanujan behavior for $C_2*C_2*C_2$ and an explicit non-Ramanujan limiting spectral radius for $C_2*C_3 \\cong {\\rm PSL}_2({\\bf Z})$.",
        "keywords": [
          "math.SP",
          "math.GR",
          "math.OA",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11905v1",
        "authors": [
          "Marco Barbieri",
          "Urban Jezernik"
        ],
        "arxiv_categories": [
          "math.SP",
          "math.GR",
          "math.OA",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Act",
        "MIT",
        "PSL",
        "N-1",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.173511"
    },
    {
      "id": "arxiv-2602.11892v1",
      "title": "On plane rigidity matroids",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11892v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We prove several results about matroids and matroidal families associated with rigidity in dimension $2$. In particular, we establish new properties of the generic rigidity matroid family $\\mathcal{R}$ and Kalai's hyperconnectivity matroid family $\\mathcal{H}$. We show that $\\mathcal{R}$ is the unique matroidal $2$-rigidity family in which $K_{3,3}$ is not a circuit. As a geometric corollary of this result and the Bolker-Roth theorem, it follows that $\\mathcal{H}$ and $\\mathcal{R}$ are the only $2$-rigidity families associated with algebraic curves in $\\mathbb{R}^2$. Bernstein used tropical geometry to characterize $\\mathcal{H}$-independent graphs as those admitting an edge-ordering without directed cycles and alternating closed trails. We provide a combinatorial proof of the sufficiency direction and extend Bernstein's theorem to positive characteristic. It follows that the wedge power matroid of $n$ generic points in dimension $n-2$ does not depend on the field characteristic. Our proof method allows to identify many graphs that are independent in every $2$-rigidity family. In particular, we show this for all connected cubic graphs, with exceptions of $K_4$ and $K_{3,3}$. This gives a complete classification of cubic graphs in this respect and answers a question of Kalai in a strong form. As a corollary, we obtain a new property of cubic graphs: every connected cubic graph except $K_4$ and $K_{3,3}$ has an orientation without directed and alternating cycles. Equivalently, it can be edge-partitioned into two forests in a special `interlocked' way.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11892v1",
        "authors": [
          "Mykhaylo Tyomkyn"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.173829"
    },
    {
      "id": "arxiv-2602.11889v1",
      "title": "Global Multiplicity and Comparison Principles for Singular Problems driven by Mixed Local-Nonlocal Operators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11889v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study a singular elliptic problem driven by a mixed local-nonlocal operator of the form \\begin{equation*} \\begin{aligned} -Δ_p u + (-Δ_q)^s u &= \\fracλ{u^δ} + u^r \\text{ in } Ω\\newline u > 0 \\text{ in } Ω,\\ u &= 0 \\text{ in } \\mathbb{R}^N \\setminus Ω \\end{aligned} \\end{equation*} where $p > sq$, $0<δ<1$ and $λ> 0$ is a parameter. The nonlinearity exhibits a singular power-type behavior near zero and displays at most a critical growth at infinity. We establish a global multiplicity result with respect to the parameter $λ$ by identifying a sharp threshold that separates existence, non-existence, and multiplicity regimes, a result that is new for singular problems involving mixed local-nonlocal operators. We also derive a Hopf-type strong comparison principle adapted to this nonlinear setting, which provides the main analytical tool for the global multiplicity result. Additionally, we investigate qualitative properties of solutions that are essential for the variational analysis, such as a uniform $L^{\\infty}$-estimate and a Sobolev versus Hölder local minimizer result. The analytical tools developed herein are of independent mathematical interest, with their applicability extending over a broader class of mixed local-nonlocal problems.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11889v1",
        "authors": [
          "R. Dhanya",
          "Sarbani Pramanik"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlocal Operators We",
        "Comparison Principles",
        "Global Multiplicity",
        "Singular Problems",
        "Mixed Local",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.174497"
    },
    {
      "id": "arxiv-2602.11872v1",
      "title": "A High-Performance Parallel Algorithm for Multi-Objective Integer Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11872v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Multi-objective integer optimization problems are hard to solve, mainly because the number of nondominated images is often extremely large. We present the first exact algorithm, called PEA, that fully utilizes the multicore architecture of modern hardware. By exploiting the structure of the parameter set of the underlying scalarization, PEA can use a high number of threads while avoiding the usual pitfalls of parallel computing. It is highly scalable and easy to implement. As a result, PEA can solve much larger instances than previous state-of-the-art algorithms. Besides, PEA has a sound theoretical foundation. Unlike other existing parallel algorithms, it always solves the same number of scalarization problems as comparable sequential algorithms. We demonstrate the potential of PEA in a computational study.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11872v1",
        "authors": [
          "Kathrin Prinz",
          "Levin Nemesch",
          "Stefan Ruzika"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Objective Integer Optimization Multi",
        "Performance Parallel Algorithm",
        "Act",
        "PEA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.174705"
    },
    {
      "id": "arxiv-2602.11870v1",
      "title": "Avoiding stabilization terms in virtual elements for eigenvalue problems: The Reduced Basis Virtual Element Method",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11870v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present the novel Reduced Basis Virtual Element Method (rbVEM) for solving the Laplace eigenvalue problem. This approach is based on the virtual element method and exploits the reduced basis technique to obtain an explicit representation of the virtual (non-polynomial) contribution to the discrete space. rbVEM yields a fully conforming discretization of the considered problem, so that stabilization terms are avoided. We prove that rbVEM provides the correct spectral approximation with optimal error estimates. Theoretical results are supplemented by an exhaustive numerical investigation.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11870v1",
        "authors": [
          "Silvia Bertoluzza",
          "Fabio Credali",
          "Francesca Gardini"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reduced Basis Virtual Element",
        "Element Method We",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:32.174878"
    },
    {
      "id": "arxiv-2602.12265v1",
      "title": "Holographic Equidistribution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12265v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Hecke operators acting on modular functions arise naturally in the context of 2d conformal field theory, but in seemingly disparate areas, including permutation orbifold theories, ensembles of code CFTs, and more recently in the context of the AdS$_3$/RMT$_2$ program. We use an equidistribution theorem for Hecke operators to show that in each of these large $N$ limits, an entire heavy sector of the partition function gets integrated out, leaving only contributions from Poincaré series of light states. This gives an immediate holographic interpretation as a sum over semiclassical handlebody geometries. We speculate on further physical interpretations for equidistribution, including a potential ergodicity statement.",
        "keywords": [
          "hep-th",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12265v1",
        "authors": [
          "Nico Cooper"
        ],
        "arxiv_categories": [
          "hep-th",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Holographic Equidistribution Hecke",
        "Act",
        "MIT",
        "RMT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.349225"
    },
    {
      "id": "arxiv-2602.12239v1",
      "title": "Tininess and right adjoints to exponentials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12239v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Objects $T$ whose exponential functor $(-)^T$ admits a right adjoint $(-)_T$ are known under different names. The fact that they exist, yet that the only set that satisfies this in the category of sets is the singleton made Lawvere suggest they ought to be ``amazingly tiny'' -- hence Lawvere's acronym ``A.T.O.M.'' This report explores how intuitively tiny any such object is. Evidences both in favor and to the contrary are produced by looking at their categorical behavior (subobjects, quotients, retracts, etc) when the ambient category is a topos. The topological behavior (connectedness, contractibility, connected components, etc) of both $T$ and $(-)_T$ is further analyzed in toposes that satisfy certain precohesive conditions over their decidable objects, where this tininess is tested against parts of Lawvere's foundational proposal for Synthetic Differential Geometry.",
        "keywords": [
          "math.CT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12239v1",
        "authors": [
          "Enrique Ruiz Hernández",
          "Pedro Solórzano"
        ],
        "arxiv_categories": [
          "math.CT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Synthetic Differential Geometry",
        "Act",
        "WHO",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.349588"
    },
    {
      "id": "arxiv-2602.12226v1",
      "title": "A resistance invariant of special alternating links",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12226v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce a new numerical invariant for special, reduced, alternating diagrams of oriented knots and links, defined in terms of the Laplacian matrix of the associated Tait graph. For a special alternating diagram, the Laplacian encodes both the combinatorics of the checkerboard graph and the crossing signs. While its spectrum depends on the chosen diagram, we show that a specific quadratic trace expression involving the Laplacian and its Moore-Penrose pseudoinverse is invariant under flype moves. The invariant admits an interpretation in terms of total effective resistance of the associated weighted graph viewed as an electrical network. Explicit computations for pairs of flype-related diagrams demonstrate that, although the Laplacian characteristic polynomials differ, the invariant FP coincides. Values for several prime alternating knots are provided.",
        "keywords": [
          "math.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12226v1",
        "authors": [
          "Michal Jablonowski"
        ],
        "arxiv_categories": [
          "math.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.349975"
    },
    {
      "id": "arxiv-2602.12217v1",
      "title": "Generalizing the Clunie--Hayman construction in an Erdős maximum-term problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12217v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Let $f(z)=\\sum_{n\\ge0}a_n z^n$ be a transcendental entire function and write $M(r,f):=\\max_{|z|=r}|f(z)|$ and $μ(r,f):=\\max_{n\\ge0}|a_n|\\,r^n$. A problem of Erdős asks for the value of $$ B:=\\sup_f \\liminf_{r\\to\\infty}\\frac{μ(r,f)}{M(r,f)}. $$ In 1964, Clunie and Hayman proved that $\\frac{4}{7}<B<\\frac{2}π$. In this paper we develop a generalization of their construction via a scaling identity and obtain the explicit lower bound $$ B>0.58507, $$ improving the classical constant $\\frac{4}{7}$.",
        "keywords": [
          "math.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12217v1",
        "authors": [
          "Yixin He",
          "Quanyu Tang"
        ],
        "arxiv_categories": [
          "math.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.350482"
    },
    {
      "id": "arxiv-2602.12213v1",
      "title": "On the dynamical Galois group of certain affine polynomials in positive characteristic",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12213v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We use explicit class field theory of rational function fields to prove a dynamical criterion for a polynomial of the form $x^{p^r}+ax+b$ over a field of characteristic $p$ to have dynamical Galois group as large as possible. When $p=2$ and $r=1$ this yields an analogue in characteristic $2$ of the celebrated criterion of Stoll for quadratic polynomials over fields of characteristic not $2$.",
        "keywords": [
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12213v1",
        "authors": [
          "Andrea Ferraguti",
          "Guido Maria Lido"
        ],
        "arxiv_categories": [
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.350805"
    },
    {
      "id": "arxiv-2602.12208v1",
      "title": "Generators for Tensor Product Components",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12208v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Let $p$ be a prime number, $F$ a field of characteristic $p$, and $G$ a cyclic group of order $q =p^a$ for some positive integer $a$. Under these circumstances every indecomposable $F G$-module is cyclic. For indecomposable $F G$-modules $U$ and $W$, we present a new recursive method for identifying a generator for each of the indecomposable components of $U \\otimes W$ in terms of a particular $F$-basis of $U \\otimes W$.",
        "keywords": [
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12208v1",
        "authors": [
          "Michael J. J. Barry"
        ],
        "arxiv_categories": [
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tensor Product Components Let",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.351099"
    },
    {
      "id": "arxiv-2602.12191v1",
      "title": "The higher connectivity at infinity of mapping class groups",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12191v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The higher connectivity at infinity for mapping class groups of surfaces with boundary components and punctures is understood with the exceptions of the mapping class groups for the closed surfaces of genus 3 and 4. In this paper we prove a general simply connected at infinity result for finitely presented groups that implies all mapping class groups of closed surfaces of genus $\\geq 3$ are simply connected at infinity. As these groups are duality groups the Proper Hurewicz Theorem implies that they are $(n-2)$-connected at infinity where $n$ is the dimension of the group. Combining this result with earlier work we give a complete list of all mapping class groups and their connectivity at infinity.",
        "keywords": [
          "math.GR",
          "math.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12191v1",
        "authors": [
          "Michael Mihalik"
        ],
        "arxiv_categories": [
          "math.GR",
          "math.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.351415"
    },
    {
      "id": "arxiv-2602.12186v1",
      "title": "Aleksandrov reflection for Geometric Flows in Hyperbolic Spaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12186v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We develop an Aleksandrov reflection framework for a large class of expanding curvature flows in hyperbolic space, with inverse mean curvature flow serving as a model case. The method applies to the level-set formulation of the flow. As a consequence, we obtain graphical and Lipschitz estimates. Using these estimates, we show that solutions become starshaped and therefore converge exponentially fast to an umbilic hypersurface at infinity. We also extend our results to the non-compact setting, assuming that the solution has a unique point at infinity. In this case, we prove that the flow becomes a graph over a horosphere with uniform gradient bounds and converges to a limiting horosphere.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12186v1",
        "authors": [
          "Theodora Bourni",
          "José M. Espinar",
          "Aakash Mishra"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hyperbolic Spaces We",
        "Geometric Flows",
        "Framework",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.351732"
    },
    {
      "id": "arxiv-2602.12149v1",
      "title": "On some convergence approach structures on hyperspaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12149v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the context of the category $\\mathsf{Cap}$ of convergence approach spaces and contractions, we introduce and study approach analogs of the upper and lower Kuratowski convergences, upper-Fell and Fell topologies on the set of closed subsets of the coreflection on the category $\\mathsf{Conv}$ of convergence spaces of a convergence approach space. In particular, over a pre-approach space, the $\\mathsf{Conv}$-coreflection of the lower Kuratowski convergence approach structure is the lower Kuratowski convergence associated with the $\\mathsf{Conv}$-coreflection of the base space, while the $\\mathsf{Conv}$-reflection is the lower Kuratowski convergence associated with the $\\mathsf{Conv}$-reflection. The $\\mathsf{Conv}$-coreflection of the upper Kuratowski convergence approach is is the upper Kuratowski convergence associated with the $\\mathsf{Conv}$-reflection of the base space, while the $\\mathsf{Conv}$-reflection is the upper Kuratowski convergence associated with the $\\mathsf{Conv}$-coreflection of the base space. We show that, over an approach space, the lower Kuratowski convergence approach structure is in fact an approach structure that coincides with the $\\vee$-Vietoris approach structure introduced by Lowen and his collaborators, though it may be strictly finer over a general convergence approach space. We show that the upper Fell convergence approach structure is a non-Archimedean approach structure coarser than the upper Kuratowski convergence approach, but finer than the upper Fell approach structure introduced by the first and third author. We also obtain a $\\mathsf{Cap}$ abstraction of the classical result that if the upper Kuratowski convergence over a topological space is pretopological, then it is also topological.",
        "keywords": [
          "math.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12149v1",
        "authors": [
          "M. Ateş",
          "F. Mynard",
          "S. Sağıroğlu"
        ],
        "arxiv_categories": [
          "math.GN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.352464"
    },
    {
      "id": "arxiv-2602.12131v1",
      "title": "Hilbert's Program and Infinity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12131v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The primary aim of Hilbert's proof theory was to establish the consistency of classical mathematics using finitary means only. Hilbert's strategy for doing this was to eliminate the infinite (in the form of unbounded quantifiers) from formalized proofs using the so-called epsilon substitution method. The result is a formal proof which does not mention or appeal to infinite objects or \"concept-formations.\" However, as later developments showed, the consistency proof itself lets the infinite back into proof theory, through a back door, so to speak. The paper outlines the epsilon substitution method as an example of how proof-theoretic constructions \"eliminate the infinite\" from formal proofs, and how they aim to establish conservativity and consistency. The proof also requires an argument that this proof theoretic construction always works. This second argument, however, requires possibly infinitary reasoning at the meta-level, using induction on ordinal notations.",
        "keywords": [
          "math.LO",
          "math.HO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12131v1",
        "authors": [
          "Richard Zach"
        ],
        "arxiv_categories": [
          "math.LO",
          "math.HO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "BERT",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.352839"
    },
    {
      "id": "arxiv-2602.12085v1",
      "title": "Refined half-integer condition on RG flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12085v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Renormalization group flows are constrained by symmetries. Traditionally, we have made the most of 't Hooft anomalies associated to the symmetries. The anomaly is mathematically part of the data for the monoidal structure on symmetry categories. The symmetry categories sometimes admit additional structures such as braiding. It was found that the additional structures give further constraints on renormalization group flows. One of these constraints is the half-integer condition. The condition claims the following. Braidings are characterized by conformal dimensions. A symmetry object $c$ in a braided symmetry category surviving all along the flow thus has two conformal dimensions, one in ultraviolet $h_c^\\text{UV}$ and the other in infrared $h_c^\\text{IR}$. In a renormalization group flow with a renormalization group defect, they add up to a half-integer $h_c^\\text{UV}+h_c^\\text{IR}\\in\\frac12\\mathbb Z$. We find a necessary condition for the sum to be half-integer. We solve some flows with the refined half-integer condition.",
        "keywords": [
          "hep-th",
          "cond-mat.str-el",
          "math-ph",
          "math.CT",
          "math.QA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12085v1",
        "authors": [
          "Ken Kikuchi"
        ],
        "arxiv_categories": [
          "hep-th",
          "cond-mat.str-el",
          "math-ph",
          "math.CT",
          "math.QA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.353333"
    },
    {
      "id": "arxiv-2602.12076v1",
      "title": "Weak stability conditions on coherent systems of genus four curves",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12076v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The derived category of coherent systems is an interesting triangulated category associated with a smooth, projective curve $C$. These categories admit Bridgeland stability conditions, as recently shown by Feyzbakhsh and Novik. Their construction depends explicitly on the higher rank Brill-Noether theory of $C$. In this short note, we study the Feyzbakhsh--Novik stability conditions for a general curve of genus four. We show that these stability conditions degenerate to a stability condition on the Kuznetsov component of the corresponding nodal cubic threefold, using a result of Alexeev-Kuznetsov.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12076v1",
        "authors": [
          "Nicolás Vilches"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.353609"
    },
    {
      "id": "arxiv-2602.12034v1",
      "title": "Anomaly Reparametrization of the Ligon--Schaaf Regularization in the Kepler problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12034v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We revisit the Ligon--Schaaf regularization of the Kepler problem and identify the geometric origin of the rotation appearing in their transformation. We show that this rotation is determined by the eccentric anomaly of the Kepler motion, providing a transparent dynamical interpretation of the angle that renders the Kepler flow uniform on $T^{*}S^{3}$. Building on this insight, we extend the construction to positive and zero energies via the corresponding hyperbolic and parabolic anomalies, obtaining a unified geometric description of the Kepler flow across all energy levels.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12034v1",
        "authors": [
          "Li-Chun Hsu"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Anomaly Reparametrization",
        "Schaaf Regularization",
        "NSF",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.353953"
    },
    {
      "id": "arxiv-2602.11984v1",
      "title": "Radicals in primitive axial algebras",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11984v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The paper contributes to the structure theory of primitive axial algebras. For a primitive axial algebra $A$ with a Frobenius form we compare the largest ideal $R(A)$ not containing any of the generating axes, the radical $A^\\perp$ of the form, and the Jacobson radical $J(A)$, which we define simply as the intersection of all maximal ideals of $A$.",
        "keywords": [
          "math.RA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11984v1",
        "authors": [
          "Andrey Mamontov",
          "Sergey Shpectorov",
          "Victor Zhelyabin"
        ],
        "arxiv_categories": [
          "math.RA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.354144"
    },
    {
      "id": "arxiv-2602.11971v1",
      "title": "Hypercovers in Differential Geometry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11971v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper we provide a simple proof that for several sites of interest in differential geometry, the local projective model structure and the Čech projective model structure are equal. In particular, this applies to the site of smooth manifolds with open covers and the site of cartesian spaces with good open covers. As an application, we show that for a presheaf of sets on these sites, applying the plus construction once is enough to sheafify.",
        "keywords": [
          "math.CT",
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11971v1",
        "authors": [
          "Cheyne Glass",
          "Emilio Minichiello"
        ],
        "arxiv_categories": [
          "math.CT",
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Differential Geometry In"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.354608"
    },
    {
      "id": "arxiv-2602.11955v1",
      "title": "Recovering Hardy spaces from optimal domains of integration operators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11955v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the optimal domains for bounded Volterra integration operators $T_g$ between distinct Hardy spaces $H^p$ and $H^q$ of the unit ball. It is shown that the intersection of the optimal domains is equal to $H^p$ if $p> q$, whereas if $p<q$, we show that this intersection is genuinely larger. In the unit disk, this problem was recently solved for $p=q$ by Bellavita, Daskalogiannis, Nikolaidis and Stylogiannis.",
        "keywords": [
          "math.CV",
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11955v1",
        "authors": [
          "Setareh Eskandari",
          "Antti Perälä"
        ],
        "arxiv_categories": [
          "math.CV",
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recovering Hardy",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.354834"
    },
    {
      "id": "arxiv-2602.11943v1",
      "title": "The Cylinder Simplicial DG Ring",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11943v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Given a DG ring $B$ and an integer $q \\geq 0$, we construct the $q$-th cylinder DG ring $Cyl_q(B)$. For $q = 1$ this is just Keller's cylinder DG ring, sometimes called the path object of $B$, which encodes homotopies between DG ring homomorphisms $A \\to B$. As $q$ changes the cylinder DG rings form a simplicial DG ring $Cyl(B)$. Hence, given another DG ring $A$, the DG ring homomorphisms $A \\to Cyl(B)$ form a simplicial set $Hom(A,Cyl(B))$. Our main theorem states that when $A$ is a semi-free DG ring, the simplicial set $Hom(A,Cyl(B))$ is a Kan complex. For the verification of the Kan condition we introduce a new construction, which may be of independent interest. Given a horn $Y$, we define the DG ring $N(Y,B)$, and we prove that $N(Y,B)$ represents this horn in the simplicial set $Hom(A,Cyl(B))$. In this way the Kan condition is implemented intrinsically in the category of DG rings, thus facilitating calculations. Presumably all the above can be extended, with little change, from DG rings to (small) DG categories. That would enable easy constructions and explicit calculations of some simplicial aspects of DG categories.",
        "keywords": [
          "math.RA",
          "math.CT",
          "math.KT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11943v1",
        "authors": [
          "Amnon Yekutieli"
        ],
        "arxiv_categories": [
          "math.RA",
          "math.CT",
          "math.KT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ring Given",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.355221"
    },
    {
      "id": "arxiv-2602.11930v1",
      "title": "Modified mean curvature flow of graphs in Riemannian manifolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11930v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We obtain height, gradient, and curvature a priori estimates for a modified mean curvature flow in Riemannian manifolds endowed with a Killing vector field. As a consequence, we prove the existence of smooth, entire, longtime solutions for this extrinsic flow with smooth initial data.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11930v1",
        "authors": [
          "Jocel Faustino Norberto de Oliveira",
          "Jorge Herbert Soares de Lira",
          "Matheus Nunes Soares"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.355368"
    },
    {
      "id": "arxiv-2602.11922v1",
      "title": "Trace arithmetic--$κ_p$ inequality",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11922v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Let $\\mathcal{A}$ be a unital $C^\\ast$-algebra equipped with a faithful tracial positive linear functional $τ$. Denote by $\\mathcal{A}_+$ its positive cone. For $p>0$ and $A,B\\in\\mathcal{A}_+$, we consider the operations $$ Aκ_p B := \\bigl(A^{p/4} B^{p/2} A^{p/4}\\bigr)^{1/p}, \\qquad A\\nabla B := \\frac{A+B}{2}. $$ We prove that, for all $p>0$ and all $A,B\\in\\mathcal{A}_+$, $$ τ(Aκ_p B)\\le \\sqrt{τ(A)τ(B)}\\le τ(A\\nabla B), $$ thereby answering \\cite[Problem~1]{KM24}, posed by Á.~Komálovics and L.~Molnár, in the affirmative. We also record a unitarily invariant norm analogue of the key estimate in the matrix case, and we provide explicit $2\\times2$ counterexamples showing that the triangle inequality for $d_p$ may fail when $0<p<1$ (already for $p=\\tfrac12$), giving a partial answer to \\cite[Problem~2]{KM24}.",
        "keywords": [
          "math.OA",
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11922v1",
        "authors": [
          "Teng Zhang"
        ],
        "arxiv_categories": [
          "math.OA",
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.355982"
    },
    {
      "id": "arxiv-2602.11913v1",
      "title": "Eigenvalue Estimates of the Hodge Laplacian Under Lower Ricci Curvature Bound",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11913v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We establish uniform lower and upper bounds for the eigenvalues of the Hodge Laplacian acting on differential forms on closed Riemannian manifolds with a lower Ricci curvature bound, a positive lower bound on the injectivity radius, and an upper bound on the diameter. Our results extend earlier work of Dodziuk, Lott, and Mantuano, which required bounded sectional curvature, to the broader setting of lower Ricci curvature bounds. As applications, we obtain uniform eigenvalue bounds for the connection Laplacian acting on $1$-forms and establish a global Poincaré inequality for differential forms under the same geometric assumptions.",
        "keywords": [
          "math.DG",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11913v1",
        "authors": [
          "Anusha Bhattacharya",
          "Soma Maity",
          "Aditya Tiwari"
        ],
        "arxiv_categories": [
          "math.DG",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hodge Laplacian Under Lower",
        "Ricci Curvature Bound We",
        "Eigenvalue Estimates",
        "Hodge Laplacian",
        "Act",
        "DOD",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.356446"
    },
    {
      "id": "arxiv-2602.11906v1",
      "title": "Largeness notions and polytime translation for $\\forall Σ^0_3$-consequences of $\\mathsf{RT}^2_2$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11906v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Le Houérou, Patey and Yokoyama defined a parameterized version of $α$-largeness to prove that $\\mathsf{WKL}_0 + \\mathsf{RT}^2_2$ is a $\\forall Σ^0_3$-conservative extension of $\\mathsf{RCA}_0 + \\mathsf{B}Σ^0_2$, where $\\forall Σ^0_3$ is the universal set-closure of the class of $Σ^0_3$-formulas. We introduce a variant of this notion of largeness and obtain polynomial bounds, using a tree partition theorem based on Milliken's tree theorem. Thanks to the framework of forcing interpretation, this yields that any proof of a $\\forall Σ^0_3$-sentence in the theory $\\mathsf{WKL}_0 + \\mathsf{RT}^2_2$ can be translated into a proof in $\\mathsf{RCA}_0 + \\mathsf{B}Σ^0_2$ at the cost of a polynomial increase in size.",
        "keywords": [
          "math.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11906v1",
        "authors": [
          "Quentin Le Houérou",
          "Ludovic Patey"
        ],
        "arxiv_categories": [
          "math.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "RCA",
        "WKL",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.357051"
    },
    {
      "id": "arxiv-2602.11900v1",
      "title": "The total geodesic curvature and the $(2+1)$-dimensional hyperbolic mass",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11900v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We consider a Jordan domain diffeomorphic to a closed two-dimensional disk with a smooth boundary. Assuming the Gauss curvature of the domain has a negative lower bound, the Gauss-Bonnet formula provides an upper bound for the total geodesic curvature of the boundary curve. This bound, however, inherently depends on the interior geometry of the region. In this paper, we derive an upper bound for the total geodesic curvature expressed solely in terms of the boundary data. Notably, the proof is connected to the positivity of the hyperbolic Hamiltonian mass in the (2+1)-dimensional gravity theory.",
        "keywords": [
          "math.DG",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11900v1",
        "authors": [
          "Xiaokai He",
          "Xiaoning Wu",
          "Naqing Xie"
        ],
        "arxiv_categories": [
          "math.DG",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:36.357352"
    },
    {
      "id": "arxiv-2602.12093v1",
      "title": "Covariant Chu-Kovasznay Decomposition: Resolving Thermodynamic Ambiguity in Compressible Flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12093v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We establish the Covariant Chu--Kovasznay Decomposition (CCKD), a geometric framework that resolves thermodynamic ambiguity in compressible mode content by formulating the decomposition on the effective acoustic spacetime. Enforcing orthogonality in the covariant Chu energy norm, we show that shock--turbulence interaction, often treated as a scattering source, is, in the idealized linear, inviscid setting, a near-unitary (Chu-isometric) scattering map constrained by conservation of covariant Chu-energy flux. In the canonical Shu-Osher problem, CCKD characterizes the shock as a thermo-acoustic lens, mathematically demonstrating that the transfer of entropy fluctuations into sound follows a geometric blue-shift ($k_{\\mathrm{out}}=Λk_{\\mathrm{in}}$) analogous to gravitational blue-shift. Thus, while the mean flow produces entropy across the shock, the fluctuation mapping is information-preserving on the retained subspace; practical information loss arises from noise, truncation, and model mismatch, not shock physics.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12093v1",
        "authors": [
          "Chanho Park",
          "Gyeongho Gong",
          "Yeachan Kwak",
          "Seongim Choi"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Kovasznay Decomposition",
        "Compressible Flows We",
        "Covariant Chu",
        "Framework",
        "CCKD",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.609269"
    },
    {
      "id": "arxiv-2602.12075v1",
      "title": "Efficient parallel finite-element methods for planetary gravitation: DtN and multipole expansions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12075v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Poisson equation governing a planet's gravitational field is posed on the unbounded domain, $\\mathbb{R}^3$, whereas finite-element computations require bounded meshes. We implement and compare three strategies for handling the infinite exterior in the finite-element method: (i) naive domain truncation; (ii) Dirichlet-to-Neumann (DtN) map on a truncated boundary; (iii) multipole expansion on a truncated boundary. While all these methods are known within the geophysical literature, we discuss their parallel implementations within modern open-source finite-element codes, focusing specifically on the widely-used MFEM package. We consider both calculating the gravitational potential for a static density structure and computing the linearised perturbation to the potential caused by a displacement field - a necessary step for coupling self-gravitation into planetary dynamics. In contrast to some earlier studies, we find that the domain truncation method can provide accurate solutions at an acceptable cost, with suitable coarsening of the mesh within the exterior domain. Nevertheless, the DtN and multipole methods provide superior accuracy at a lower cost within large-scale parallel geophysical simulations despite their need for non-local communication associated with spherical harmonic expansions. The DtN method, in particular, admits an efficient parallel implementation based on an MPI-communicator limited to processors that contain part of the mesh's outer boundary. A series of further illustrative calculations are provided to show the potential of the DtN and multipole methods within realistic geophysical modelling.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.IM",
          "math-ph",
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12075v1",
        "authors": [
          "Ziheng Yu",
          "Alex D. C. Myhill",
          "David Al-Attar"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.IM",
          "math-ph",
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "MFEM",
        "MIT",
        "MPI",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.609610"
    },
    {
      "id": "arxiv-2602.11847v1",
      "title": "Monitoring the upper atmospheric temperature and interplanetary magnetic field with the GRAPES-3 muon telescope",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11847v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Galactic Cosmic Rays (GCRs) have to travel through the heliosphere before they interact with the Earth's atmosphere. During this, they are deflected by the Sun's magnetic field, causing variations in this field to imprint on the flux, spectrum and angular distribution of GCRs detected at or near Earth. Studies of these variations over the past several decades have revealed the impact of both transient phenomena such as solar flares, coronal holes, sunspot activity and coronal mass ejections (CMEs) as well as their effects such as Forbush Decreases (FDs), precursors and Ground-Level Enhancements (GLEs). Periodic variations, such as due to the solar diurnal modulation, the 27-day solar rotation, the 11-year solar cycle, and the 22-year solar magnetic cycle have also been characterized. These Sun-induced phenomena are most prominent in GCR intensity variations up to $\\sim$30 GeV/nuc, beyond which the influence of solar modulation decreases rapidly as the gyro-radii of GCRs exceed the characteristic size of the heliosphere ($\\sim$100 AU).",
        "keywords": [
          "astro-ph.HE",
          "astro-ph.SR",
          "physics.space-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11847v1",
        "authors": [
          "S. Paul",
          "K. P. Arunbabu",
          "M. Chakraborty",
          "S. K. Gupta",
          "B. Hariharan"
        ],
        "arxiv_categories": [
          "astro-ph.HE",
          "astro-ph.SR",
          "physics.space-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Galactic Cosmic Rays",
        "Level Enhancements",
        "Forbush Decreases",
        "GRAPES-3",
        "GRAPES",
        "Solar",
        "Act",
        "GCR",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:40.609876"
    },
    {
      "id": "arxiv-2602.11825v1",
      "title": "CAAL: Confidence-Aware Active Learning for Heteroscedastic Atmospheric Regression",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11825v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantifying the impacts of air pollution on health and climate relies on key atmospheric particle properties such as toxicity and hygroscopicity. However, these properties typically require complex observational techniques or expensive particle-resolved numerical simulations, limiting the availability of labeled data. We therefore estimate these hard-to-measure particle properties from routinely available observations (e.g., air pollutant concentrations and meteorological conditions). Because routine observations only indirectly reflect particle composition and structure, the mapping from routine observations to particle properties is noisy and input-dependent, yielding a heteroscedastic regression setting. With a limited and costly labeling budget, the central challenge is to select which samples to measure or simulate. While active learning is a natural approach, most acquisition strategies rely on predictive uncertainty. Under heteroscedastic noise, this signal conflates reducible epistemic uncertainty with irreducible aleatoric uncertainty, causing limited budgets to be wasted in noise-dominated regions. To address this challenge, we propose a confidence-aware active learning framework (CAAL) for efficient and robust sample selection in heteroscedastic settings. CAAL consists of two components: a decoupled uncertainty-aware training objective that separately optimises the predictive mean and noise level to stabilise uncertainty estimation, and a confidence-aware acquisition function that dynamically weights epistemic uncertainty using predicted aleatoric uncertainty as a reliability signal. Experiments on particle-resolved numerical simulations and real atmospheric observations show that CAAL consistently outperforms standard AL baselines. The proposed framework provides a practical and general solution for the efficient expansion of high-cost atmospheric particle property databases.",
        "keywords": [
          "cs.LG",
          "physics.ao-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11825v1",
        "authors": [
          "Fei Jiang",
          "Jiyang Xia",
          "Junjie Yu",
          "Mingfei Sun",
          "Hugh Coe"
        ],
        "arxiv_categories": [
          "cs.LG",
          "physics.ao-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Heteroscedastic Atmospheric Regression Quantifying",
        "Aware Active Learning",
        "Framework",
        "Standard",
        "CAAL",
        "Act",
        "EPA",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:40.610241"
    },
    {
      "id": "arxiv-2602.11777v1",
      "title": "pycopm: An open-source tool to tailor OPM Flow geological models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11777v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Reservoir simulations help the energy industry make better decisions by predicting how fluids like oil, gas, water, hydrogen, and carbon dioxide will flow underground. To keep these predictions accurate, engineers often need to update geological models quickly as new information becomes available. pycopm is a tool designed to make this process faster and easier. It allows users to adjust geological models in several ways, such as simplifying complex grids, focusing on specific parts of a reservoir, or changing the shape and position of the model. These capabilities help engineers test different scenarios efficiently. Although pycopm was first used on two well-known public datasets, it has since become useful in many other situations because of its easy-to-use features and recent extensions. Today, it supports studies involving model refinement, comparing coarse and detailed models, analyzing interactions between nearby sites, and speeding up troubleshooting in large simulations.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11777v1",
        "authors": [
          "David Landa-Marbán"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Hydrogen",
        "Act",
        "OPM",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.610446"
    },
    {
      "id": "arxiv-2602.11689v1",
      "title": "A Preliminary Assessment of Coding Agents for CFD Workflows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11689v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the use of tool-using coding agents to automate end-to-end workflows in the open-source CFD package OpenFOAM. Building on general-purpose coding agent interfaces, we introduce a lightweight configuration that guides an agent toward tutorial reuse and log-driven repair to improve case setup and execution. We evaluate this approach on the FoamBench-Advanced benchmark, covering both tutorial-derivative and planar 2D obstacle-flow tasks. For tutorial-derivative cases, prompt guidance dramatically increases execution completion rates and reduces unnecessary tool calls. For obstacle-flow cases, stronger language models such as GPT-5.2 markedly improve mesh generation and overall task completion compared to earlier models. Our findings show that coding agents can correctly execute a range of CFD simulations with minimal configuration and that model capability significantly influences performance on tasks requiring geometry and mesh creation. These results suggest that coding agents have practical utility for automating portions of CFD workflows while highlighting areas that require further investigation.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11689v1",
        "authors": [
          "Ke Xiao",
          "Haoze Zhang",
          "Yangchen Xu",
          "Runze Mao",
          "Han Li"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Preliminary Assessment",
        "Coding Agents",
        "Workflows We",
        "GPT-5.2",
        "Act",
        "EPA",
        "CFD",
        "GPT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.610681"
    },
    {
      "id": "arxiv-2602.11631v1",
      "title": "Enforcing Reciprocity in Operator Learning for Seismic Wave Propagation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11631v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Accurate and efficient wavefield modeling underpins seismic structure and source studies. Traditional methods comply with physical laws but are computationally intensive. Data-driven methods, while opening new avenues for advancement, have yet to incorporate strict physical consistency. The principle of reciprocity is one of the most fundamental physical laws in wave propagation. We introduce the Reciprocity-Enforced Neural Operator (RENO), a transformer-based architecture for modeling seismic wave propagation that hard-codes the reciprocity principle. The model leverages the cross-attention mechanism and commutative operations to guarantee invariance under swapping source and receiver positions. Beyond improved physical consistency, the proposed architecture supports simultaneous realizations for multiple sources without crosstalk issues. This yields an order-of-magnitude inference speedup at a similar memory footprint over an reciprocity-unenforced neural operator on a realistic configuration. We demonstrate the functionality using the reciprocity relation for particle velocity fields under single forces. This architecture is also applicable to pressure fields under dilatational sources and travel-time fields governed by the eikonal equation, paving the way for encoding more complex reciprocity relations.",
        "keywords": [
          "physics.geo-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11631v1",
        "authors": [
          "Caifeng Zou",
          "Yaozhong Shi",
          "Zachary E. Ross",
          "Robert W. Clayton",
          "Kamyar Azizzadenesheli"
        ],
        "arxiv_categories": [
          "physics.geo-ph",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Seismic Wave Propagation Accurate",
        "Enforced Neural Operator",
        "Enforcing Reciprocity",
        "Operator Learning",
        "Transformer",
        "RENO",
        "NSF",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.610948"
    },
    {
      "id": "arxiv-2602.11626v1",
      "title": "ArGEnT: Arbitrary Geometry-encoded Transformer for Operator Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11626v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Learning solution operators for systems with complex, varying geometries and parametric physical settings is a central challenge in scientific machine learning. In many-query regimes such as design optimization, control and inverse problems, surrogate modeling must generalize across geometries while allowing flexible evaluation at arbitrary spatial locations. In this work, we propose Arbitrary Geometry-encoded Transformer (ArGEnT), a geometry-aware attention-based architecture for operator learning on arbitrary domains. ArGEnT employs Transformer attention mechanisms to encode geometric information directly from point-cloud representations with three variants-self-attention, cross-attention, and hybrid-attention-that incorporates different strategies for incorporating geometric features. By integrating ArGEnT into DeepONet as the trunk network, we develop a surrogate modeling framework capable of learning operator mappings that depend on both geometric and non-geometric inputs without the need to explicitly parametrize geometry as a branch network input. Evaluation on benchmark problems spanning fluid dynamics, solid mechanics and electrochemical systems, we demonstrate significantly improved prediction accuracy and generalization performance compared with the standard DeepONet and other existing geometry-aware saurrogates. In particular, the cross-attention transformer variant enables accurate geometry-conditioned predictions with reduced reliance on signed distance functions. By combining flexible geometry encoding with operator-learning capabilities, ArGEnT provides a scalable surrogate modeling framework for optimization, uncertainty quantification, and data-driven modeling of complex physical systems.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "physics.chem-ph",
          "physics.comp-ph",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11626v1",
        "authors": [
          "Wenqian Chen",
          "Yucheng Fu",
          "Michael Penwarden",
          "Pratanu Roy",
          "Panos Stinis"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "physics.chem-ph",
          "physics.comp-ph",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Operator Learning Learning",
        "Arbitrary Geometry",
        "Machine Learning",
        "Transformer",
        "Framework",
        "Standard",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:40.611273"
    },
    {
      "id": "arxiv-2602.11621v1",
      "title": "Differentiable Graph Neural Network Simulator for the Back-Analysis of Post-Liquefaction Residual Strength from Flow Failure Runout",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11621v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This study introduces Differentiable Graph Neural Network Simulators (Diff-GNS) as a physics-informed and automated framework for estimating post-liquefaction residual strengths ($S_r$). Traditional approaches to estimate $S_r$ rely on simplified physics, manual iterations, and assumptions about runout development. Diff-GNS overcomes these limitations by integrating a Graph Neural Network Simulator (GNS) that simulates granular flows, with gradient-based optimization through automatic differentiation. GNS accelerates forward runout simulations that are otherwise computationally intensive with conventional numerical methods, while gradient-based optimization automates the inversion to back-calculate $S_r$. The GNS is trained on simulations with the material point method on geometries informed by case-history runout failures, enabling focused learning of realistic runout mechanisms and the ability to simulate slopes across small and large scales. The Diff-GNS framework is validated using two well-documented liquefaction-induced flow failure case histories: the Lower San Fernando dam and La Marquesa dam. In the two cases, the inferred $S_r$ agrees closely with published estimates and reproduces physically consistent runout behaviors. The framework also has the ability to jointly infer multiple interacting parameters, extending beyond single-parameter back-analyses. By embedding the physics of runout processes, minimizing manual intervention, and accelerating the inversion process to estimate $S_r$, Diff-GNS provides an efficient, reproducible, and physically grounded approach for geotechnical analysis of liquefaction-induced flow failures.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11621v1",
        "authors": [
          "Yongjin Choi",
          "Jorge Macedo"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Differentiable Graph Neural Network",
        "Graph Neural Network Simulator",
        "Liquefaction Residual Strength",
        "Lower San Fernando",
        "Neural Network",
        "La Marquesa",
        "Framework",
        "Act",
        "GNS",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:40.611593"
    },
    {
      "id": "arxiv-2602.12255v1",
      "title": "Vision Transformer for Multi-Domain Phase Retrieval in Coherent Diffraction Imaging",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12255v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Bragg coherent diffraction imaging (BCDI) phase retrieval becomes rapidly difficult in the strong-phase regime, where a crystal contains distortions beyond half a lattice spacing. An important special case is the phase domain problem, where blocks of a crystal are displaced with sharp jumps at domain walls. The strong-phase, here defined as beyond $\\pm π/2$, generates split Bragg peaks and dense fringe structure for which classical iterative solvers often stagnate or return different solutions from different initialisations. Here, we introduce an unsupervised Fourier Vision Transformer (Fourier ViT) to solve this block-phase, multi-domain phase-retrieval problem directly from measured 2D Bragg diffraction intensities. Fourier ViT couples reciprocal-space information globally through multiscale Fourier token mixing, while shallow convolutional front and back-ends provide local filtering and reconstruction. We validate the approach on large-scale synthetic datasets of Voronoi multi-domain crystals with strong-phase contrast under realistic noise corruptions, and on experimental diffraction from a $\\mathrm{La}_{2-x}\\mathrm{Ca}_x\\mathrm{MnO}_4$ nanocrystal. Across the regimes considered, Fourier ViT achieves the lowest reciprocal-space mismatch ($χ^2$) among the compared methods and preserves domain-resolved phase reconstructions for increasing numbers of domains. On experimental data, with the same real-space support, Fourier ViT matches the iterative benchmark $χ^2$ while improving robustness to random initialisations, yielding a higher success rate of low-$χ^2$ reconstructions than the complex convolutional neural network baseline.",
        "keywords": [
          "physics.optics",
          "cond-mat.mtrl-sci",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12255v1",
        "authors": [
          "Jialun Liu",
          "David Yang",
          "Ian Robinson"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cond-mat.mtrl-sci",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Coherent Diffraction Imaging Bragg",
        "Fourier Vision Transformer",
        "Domain Phase Retrieval",
        "Vision Transformer",
        "Neural Network",
        "Transformer",
        "BCDI",
        "Act",
        "NSF",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.736310"
    },
    {
      "id": "arxiv-2602.12227v1",
      "title": "Phase Estimation from Amplitude Collapse in Correlated Matter-Wave Interference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12227v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Operating matter-wave interferometers as quantum detectors for fundamental physics or inertial sensors in real-world applications with unprecedented accuracies relies on noise rejection, often implemented by correlating two sensors. Such sensors can be spatially separated (gradiometry or gravitational-wave detection) or consist of different internal states (magnetometry or quantum clock interferometry), in which case a signal-amplitude modulation may serve as a signature of a differential phase. In this work, we introduce Phase Estimation from Amplitude Collapse (PEAC) by applying targeted fitting methods for different magnetically sensitive substates of an atom interferometer. We demonstrate that PEAC provides higher trueness (up to 80% bias reduction) than standard tools for perfectly correlated signals. At its working point near, but not exactly at phase settings resulting in vanishing amplitude, it achieves precision competitive with standard methods, contrasting prior claims of optimal operation at vanishing amplitude. PEAC presents a generally applicable complementary evaluation method for correlated interferometers without phase stability, increasing the overall accuracy and enabling applications beyond atom interferometry.",
        "keywords": [
          "quant-ph",
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12227v1",
        "authors": [
          "Daniel Derr",
          "Dominik Pfeiffer",
          "Ludwig Lind",
          "Gerhard Birkl",
          "Enno Giese"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wave Interference Operating",
        "Amplitude Collapse",
        "Correlated Matter",
        "Phase Estimation",
        "Standard",
        "PEAC",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.736756"
    },
    {
      "id": "arxiv-2602.12225v1",
      "title": "Second excited state of ${}^4\\mathrm{He}$ tetramer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12225v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The four-boson universality suggests the existence of the second excited tetramer state in a system of cold ${}^4\\mathrm{He}$ atoms. It is not bound but could be seen as a resonance in the atom-trimer scattering. This process is rigorously calculated using the momentum-space transition operator framework with two realistic interatomic potentials. The $S$-wave phase shift and cross section show a resonant behavior below the excited trimer threshold, but there are sizable nonresonant contributions from $P$ and $D$ waves as well. The position and width of the resonant state is determined, and for the latter significant finite-range effects are found.",
        "keywords": [
          "cond-mat.quant-gas",
          "nucl-th",
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12225v1",
        "authors": [
          "A. Deltuva"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "nucl-th",
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.737012"
    },
    {
      "id": "arxiv-2602.12179v1",
      "title": "Theoretical description of a photonic topological insulator based on a cubic lattice of bianisotropic resonators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12179v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the present paper, we construct a theoretical description of a three-dimensional photonic topological insulator in the form of a simple cubic lattice of bianisotropic resonators that is based on a dyadic Green's function approach. By considering electric and magnetic dipole modes and the interactions between different numbers of the nearest resonators, we obtain the Bloch Hamiltonians and the corresponding tight-binding models and analyze the band diagrams, spatial structure of the eigenmodes, and their localization, revealing quadratic degeneracies in the vicinity of high-symmetry points in the absence of bianisotropy and the emergence of in-gap states localized at a domain wall upon the introduction of bianisotropy. Finally, we visualize the Berry curvature distributions to study the topological properties of the considered models.",
        "keywords": [
          "physics.optics",
          "cond-mat.mes-hall",
          "physics.class-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12179v1",
        "authors": [
          "Alina Rozenblit",
          "Nikita Olekhno"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cond-mat.mes-hall",
          "physics.class-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bloch Hamiltonians",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.737326"
    },
    {
      "id": "arxiv-2602.12161v1",
      "title": "Coherent Perfect Tunneling at Exceptional Points via Directional Degeneracy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12161v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Coherent perfect tunneling in the presence of loss and asymmetry remains a fundamental challenge in wave transport, a universal problem across optics, acoustics, and quantum mechanics. Here we demonstrate coherent perfect tunneling at an exceptional point in a passive one-dimensional waveguide cascade with three coupled interfaces. Using a waveguide-invariant scattering framework, we show that the suppression of a selected output channel originates from a directional scattering degeneracy rather than from resonance or absorption collapse. This exceptional-point condition emerges when interference between boundary-induced feedback loops promotes a simple zero of the scattering response to a second-order degeneracy. As a direct consequence, fixed coherent excitation produces a robust quartic leakage law within a transparency-dominated tunneling window. These results establish directional degeneracy as a general mechanism for loss-tolerant tunneling enabled by exceptional points across a broad class of wave systems.",
        "keywords": [
          "physics.optics",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12161v1",
        "authors": [
          "Huayang Cai",
          "Bishuang Chen"
        ],
        "arxiv_categories": [
          "physics.optics",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Directional Degeneracy Coherent",
        "Coherent Perfect Tunneling",
        "Exceptional Points",
        "Framework",
        "Wind",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.737672"
    },
    {
      "id": "arxiv-2602.12152v1",
      "title": "Realization of a cavity-coupled Rydberg array",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12152v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Scalable quantum computers and quantum networks require the combination of quantum processing nodes with efficient light-matter interfaces to distribute quantum information in local or long-distance quantum networks. Neutral-atom arrays have both been coupled to Rydberg states to enable high-fidelity quantum gates in universal processing architectures, and to optical cavities to realize interfaces to photons. However, combining these two capabilities and coupling atom arrays to highly excited Rydberg states in the mode of an optical cavity has been an outstanding challenge. Here we present a novel cavity-coupled Rydberg array that achieves this long-standing goal. We prepare, detect, and control individual atoms in a scalable optical tweezer array, couple them strongly to the optical mode of a high-finesse optical cavity and excite them in a controlled way to Rydberg states. We show that strong coupling to an optical cavity - demonstrated via the dispersive shift of the resonance of the cavity in presence of the atoms - and strong Rydberg interactions - demonstrated via the collective enhancement of Rydberg coupling in the atomic array - can be achieved in our setup at the same spatial location. Our presented experimental platform opens the path to several new directions, including the realization of quantum network nodes, quantum simulation of long-range interacting, open quantum systems and photonic-state engineering leveraging high-fidelity Rydberg control.",
        "keywords": [
          "quant-ph",
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12152v1",
        "authors": [
          "Jacopo De Santis",
          "Balázs Dura-Kovács",
          "Mehmet Öncü",
          "Adrien Bouscal",
          "Dimitrios Vasileiadis"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "EPA",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.738137"
    },
    {
      "id": "arxiv-2602.12142v1",
      "title": "Protocols for a many-body phase microscope: From coherences and d-wave superconductivity to Green's functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12142v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum gas microscopes probe quantum many-body lattice states via projective measurements in the occupation basis, enabling access to various density and spin correlations. Phase information, however, cannot be directly obtained in these setups. Recent experiments went beyond this by measuring local current operators and local phase fluctuations. Here we propose how Fourier-space manipulation in a matter-wave microscope allows access to various long-range off-diagonal correlators in experimentally realistic settings, realizing a many-body phase microscope. We demonstrate in particular how the fermionic d-wave superconducting order parameter in arbitrary Hubbard-type models, the non-equal time Green's function yielding the spectral function, or the hidden order of composite bosons in a fractional Chern insulator can be directly measured. Our results show the great potential of matter-wave microscopy for accessing exotic correlators including phases and coherences and characterizing intriguing quantum many-body states.",
        "keywords": [
          "cond-mat.quant-gas",
          "cond-mat.str-el",
          "physics.atom-ph",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12142v1",
        "authors": [
          "Christof Weitenberg",
          "Luca Asteria",
          "Ola Carlsson",
          "Annabelle Bohrdt",
          "Fabian Grusdt"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "cond-mat.str-el",
          "physics.atom-ph",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.738495"
    },
    {
      "id": "arxiv-2602.12111v1",
      "title": "Variable dose slicer for refractive index engineering in two-photon polymerization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12111v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In two-photon polymerization (TPP), the degree of conversion (DC) of the resin has an effect on a broad range of material properties like refractive index (RI) or stiffness. Heterogeneous DC can substitute material doping and multimaterial structures, and outright enable structure designs not possible otherwise. However, obtaining variable DC in the polymer, typically achieved by implementing a variable exposure dose, is held back due to the lack of software support for fabrication and measurement techniques for validation, adding up to a high barrier of entry. This work presents two major breakthroughs in (3+1)D TPP: design freedom and variable-DC fabrication, that are provided by an open-source slicer, as well as calibration methodology for determination of the RI for any DC. Application examples include grayscale lithography, control over writing direction and trajectories, as well as bio-mimicking microphantoms with carefully engineered 3D RI. Results of the RI calibration demonstrate excellent repeatability, accuracy and stability of variable-DC structures. Supported by in-depth metrological analysis, the goal is to popularize variable DC printing within TPP community and to get more out of the existing TPP systems and workflows. In summary, this work provides a complete toolbox for 3D RI engineering and sets the stage for new inventions enabled by point-wise dose control.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12111v1",
        "authors": [
          "Michal Ziemczonok",
          "Koen Vanmol"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "TPP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.738942"
    },
    {
      "id": "arxiv-2602.12109v1",
      "title": "A critical assessment of bonding descriptors for predicting materials properties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12109v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Most machine learning models for materials science rely on descriptors based on materials compositions and structures, even though the chemical bond has been proven to be a valuable concept for predicting materials properties. Over the years, various theoretical frameworks have been developed to characterize bonding in solid-state materials. However, integrating bonding information from these frameworks into machine learning pipelines at scale has been limited by the lack of a systematically generated and validated database. Recent advances in high-throughput bonding analysis workflows have addressed this issue, and our previously computed Quantum-Chemical Bonding Database for Solid-State Materials was extended to include approximately 13,000 materials. This database is then used to derive a new set of quantum-chemical bonding descriptors. A systematic assessment is performed using statistical significance tests to evaluate how the inclusion of these descriptors influences the performance of machine-learning models that otherwise rely solely on structure- and composition-derived features. Models are built to predict elastic, vibrational, and thermodynamic properties typically associated with chemical bonding in materials. The results demonstrate that incorporating quantum-chemical bonding descriptors not only improves predictive performance but also helps identify intuitive expressions for properties such as the projected force constant and lattice thermal conductivity via symbolic regression.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12109v1",
        "authors": [
          "Aakash Ashok Naik",
          "Nidal Dhamrait",
          "Katharina Ueltzen",
          "Christina Ertural",
          "Philipp Benner"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chemical Bonding Database",
        "Machine Learning",
        "State Materials",
        "Framework",
        "Act",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.739420"
    },
    {
      "id": "arxiv-2602.12090v1",
      "title": "Unconditional full vector magnetometry using spin selectivity in Nitrogen Vacancy centers in diamond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12090v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum sensors based on nitrogen vacancy (NV) centers in diamond have been a central topic in the sensing community for more than a decade. The extraordinary properties at room temperature of the spin system in diamond have made it one of the most prominent quantum platforms for the development of commercial quantum sensors. In particular, the sensitivity of the electronic spin in NV centers has made diamond-based magnetic sensors of special interest for their potential application in medical, industrial or navigation solutions. However, the use of these sensors for universal vector magnetometry was constrained by the need for previous knowledge on the field being measured to fully exploit their benefits. In this work, we show a method to perform unconditional vector magnetometry without the need of external information on the magnetic field, based only on the spatial arrangement of the diamond and the microwave antenna combination. While previous NV-based vector magnetometry methods require partial knowledge of the magnetic field (e.g. a calibrated bias field), we exploit the possibilities of selecting particular directions of the spins in the diamond with elliptically polarized microwave fields. We prove that our method allows to estimate both magnitude and direction of external magnetic fields without further assumptions or constraints.",
        "keywords": [
          "quant-ph",
          "physics.app-ph",
          "physics.ins-det",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12090v1",
        "authors": [
          "Asier Mongelos-Martinez",
          "Jason Tarunesh Francis",
          "Julia Bertero-DiTella",
          "Geza Giedke",
          "Gabriel Molina-Terriza"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.app-ph",
          "physics.ins-det",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nitrogen Vacancy",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.739866"
    },
    {
      "id": "arxiv-2602.12086v1",
      "title": "Solvothermal vapor annealing and environmental control setup with adjustable magnetic field module for GISAXS studies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12086v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A compact, modular environmental control and solvothermal vapor annealing chamber designed for maintaining a controlled atmosphere with regard to solvent humidity and temperature is presented. The setup allows ex situ and in situ grazing incidence small-angle X-ray scattering (GISAXS) investigations of thin film self-assembly and reorganization. Its modular slotting system enables stable reconfiguration, including the integration of an adjustable magnetic field module. The temperature is maintained via a water-based heating and cooling loop supplemented by resistive elements, and the solvent vapor environment is regulated using a commercial controlled mixing and evaporation unit. The performance of the setup is validated through measurements of fill and quench times together with magnetic field mapping with Gauss meter measurements and finite element simulations. Further, the versatility of the setup is demonstrated with four research examples using the chamber for solvothermal vapor annealing of block copolymer thin films together with lab-based ex situ and in situ GISAXS measurements. The portable new design offers robust environmental control and flexibility for advanced thin film investigations both in the lab and at large scale facilities. The design can be adapted for grazing incidence small-angle neutron scattering, GISANS.",
        "keywords": [
          "cond-mat.soft",
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12086v1",
        "authors": [
          "Christian Kjeldbjerg",
          "Bo Jakobsen",
          "Miriam Varón",
          "Kim Lefmann",
          "Cathrine Frandsen"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "GISANS",
        "GISAXS",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.740308"
    },
    {
      "id": "arxiv-2602.12052v1",
      "title": "GPU-Accelerated Analytic Simulation of Sparse Signals in Pixelated Time Projection Detector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12052v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents a GPU-accelerated simulation package, TRED, for next-generation neutrino detectors with pixelated charge readout, leveraging community-driven software ecosystems to ensure sustainability and extensibility. We introduce two generic contributions: (i) an effective-charge calculation based on Gaussian quadrature rules for numerical integration, and (ii) a sparse, block-binned tensor representation that enables efficient FFT-based computation of induced signals on readout electrodes for sparsely activated detector volumes. The former captures sub-grid structure without requiring dense sampling, while the latter achieves low memory usage and scalable runtime, as demonstrated in benchmark studies. The underlying data representation is applicable to large-scale detectors and to other computational problems involving sparse activity.",
        "keywords": [
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12052v1",
        "authors": [
          "Yousen Zhang",
          "Brett Viren",
          "Mary Bishai",
          "Sergey Martynenko",
          "Xin Qian"
        ],
        "arxiv_categories": [
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Pixelated Time Projection Detector",
        "Accelerated Analytic Simulation",
        "Sparse Signals",
        "TRED",
        "FFT",
        "Act",
        "GPU",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.740626"
    },
    {
      "id": "arxiv-2602.11970v1",
      "title": "Tuning Optical Properties of FTO via Carbonaceous Al2O3 Microdot Deposition by DC plasma sputtering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11970v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Fluorine-doped tin oxide (FTO) is a key transparent conductive oxide for photovoltaic and optoelectronic devices, yet its high reflectance limits light-trapping efficiency. This work demonstrates a simple DC plasma sputtering approach to deposit carbonaceous Al2O3 microdots on FTO under controlled Ar, O2, and Ar-O2 atmospheres. For plasma discharge in the normal mode, with plasma density 10^-9 cm^-3 and temperature of 2 eV, Volmer-Weber growth produced discrete microdots whose size and distribution were tuned by gas composition: dense, uniform dots in Ar (approximately 0.89 um radius), agglomerated structures in O2, and intermediate morphologies in mixed atmospheres. Structural analysis confirmed gamma-Al2O3 formation with carbon incorporation, while SEM revealed morphology-driven optical behavior. UV-Vis measurements showed that Ar-O2 coatings achieved the lowest reflectance across the visible range, outperforming bare FTO and other conditions. These findings establish a clear link between sputtering parameters, surface morphology, and optical performance, offering a scalable route to anti-reflective, light-trapping coatings for next-generation solar cells and optoelectronic devices.",
        "keywords": [
          "physics.plasm-ph",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11970v1",
        "authors": [
          "Sarah Salah",
          "Ahmed Atlam",
          "Nagat Elkahwagy",
          "Abdelhamid Elshaer",
          "Mohammed Shihab"
        ],
        "arxiv_categories": [
          "physics.plasm-ph",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tuning Optical Properties",
        "Microdot Deposition",
        "Solar",
        "WHO",
        "SEM",
        "MIT",
        "FTO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.741028"
    },
    {
      "id": "arxiv-2602.11952v1",
      "title": "Intrabeam Scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11952v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Intrabeam scattering refers to the effects of the Coulomb interaction acting between pairs of charged particles within a bunch in an accelerator. One of the main consequences of intrabeam scattering is a change in the emittances of a bunch: in some circumstances (in particular, in hadron storage rings operating above transition), the transverse and longitudinal emittances may grow over time without limit. This may restrict the performance of machines for which maintaining low beam emittance is an important requirement. In this note, we describe some of the models used to analyse the effects of intrabeam scattering, and present in particular the Piwinski formulae for the emittance growth rates. We compare the predicted changes in emittance with measurements in a number of machines operating in different parameter regimes.",
        "keywords": [
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11952v1",
        "authors": [
          "Andrzej Wolski"
        ],
        "arxiv_categories": [
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Intrabeam Scattering Intrabeam",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.741309"
    },
    {
      "id": "arxiv-2602.11928v1",
      "title": "Topology-Enabled Switchable Unidirectional Radiative Band in a Bilayer Photonic Crystal",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11928v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Controlling how an open photonic system exchanges energy with its environment-and in particular how it radiates into the far field-is a cornerstone of non-Hermitian wave physics and a key enabler for directional photonic functionalities. Here, we propose a new route to robust unidirectional emission based on the non-Hermitian hybridization of resonances localized in spatially separated layers of a hetero-bilayer photonic crystal. By tailoring the interlayer coupling, we engineer hybrid photonc bands that exhibit strong unidirectional radiation across a broad spectral and momentum range while maintaining theoretically high quality factors. This asymmetric emission is organized by a topological vortex in a pseudo-polarization field defined from the front/back intensity imbalance, which endows the directionality with robustness against perturbations. We further show that, by tuning the surrounding refractive index, this singularity can be displaced in parameter space, enabling reversible switching of the emission direction and a reconfigurable far-field response. This framework opens perspectives for topological photonic sensing and for directional and switchable light sources, including unidirectional lasing supported by high-quality-factor modes.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11928v1",
        "authors": [
          "Zhiyi Yuan",
          "Vytautas Valuckas",
          "Yuhao Wang",
          "Thi Thu Ha Do",
          "Ningyuan Nie"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enabled Switchable Unidirectional Radiative",
        "Bilayer Photonic Crystal Controlling",
        "Framework",
        "Act",
        "EPA",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.741730"
    },
    {
      "id": "arxiv-2602.11884v1",
      "title": "Signatures of Damping Nonlinear Oscillations by KHI-induced Turbulence in Synthetic Observations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11884v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large-amplitude decaying kink oscillations of coronal loops are strongly influenced by nonlinear processes, such as Kelvin-Helmholtz instability (KHI) and turbulence, though comprehensive theory and observational confirmation remain limited. Building on the recently developed theory on nonlinear damping by KHI-induced turbulence in impulsively driven transverse loop oscillations, we investigate its observational signatures using 3D magnetohydrodynamic simulations and forward-modelled EUV images. The simulated oscillations exhibit time-varying frequency shifts and damping rates, which are broadly consistent with nonlinear turbulence-damping theory. Additionally, they exhibit excitation of higher-order modes, slightly increased periods relative to the linear kink period, and reduced displacement amplitudes. These features are generally preserved in synthetic observations, though resolving higher-order modes requires higher spatial resolution than currently available. For loops embedded in a hotter background, hotter channels (e.g., 193 Angstroms) are more sensitive to boundary dynamics, thus their oscillations decay faster with smaller displacements and larger phase shifts than those in cooler channels (e.g., 171 Angstroms). Comparisons of simulated and synthetic oscillations show close agreement at the early stage. At later times, synthetic oscillations exhibit smaller displacements and larger phase shifts, due to turbulence-induced asymmetry in the loop cross-section. Bayesian fitting shows that the initial oscillation amplitude and kink period are robustly constrained, whereas parameters controlling the damping profile are degenerate, indicating that additional observables would aid reliable seismological inference. These results provide a quantitative basis for identifying nonlinear damping and detecting KHI-driven turbulence in transverse loop oscillations.",
        "keywords": [
          "astro-ph.SR",
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11884v1",
        "authors": [
          "Sihui Zhong",
          "Andrew Hillier",
          "Iñigo Arregui"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Damping Nonlinear Oscillations",
        "Synthetic Observations Large",
        "Agreement",
        "KHI",
        "MIT",
        "EUV",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.742289"
    },
    {
      "id": "arxiv-2602.11868v1",
      "title": "Conditions for resonant optical tunnelling in three-layer photonic microsystems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11868v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This work focuses on optical tunneling across thin three-layer planar structures embedded in a thick and transparent dielectric medium. First, compact transmittance expressions for different configurations are obtained using a generalized Fresnel coefficient method. These expressions are subsequently used to analyze various tunnelling outcomes. We show that two types of tunneling effects can be distinguished, depending on the kind of waves that are present in the core layer. When harmonic waves propagate in this layer, the transmittance formula and the phase condition for resonant tunneling are identical to that obtained in a Fabry-Perot etalon. However, in the case of evanescent or damped waves in the core layer, the new expression for transmittance provides another resonant condition related, this time, to the wave amplitude. For clarity, transparent materials are addressed first (including ideal metals), and the implications of absorption are studied later. Different angular-spectral maps are displayed to exemplify the main features of the tunneling effect in each analyzed configuration. To highlight, it is shown that tunnelling can occur in photonic systems with thicknesses up to several wavelengths.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11868v1",
        "authors": [
          "Yago Arosa",
          "Alejandro Doval",
          "Raúl de la Fuente"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.742628"
    },
    {
      "id": "arxiv-2602.11763v1",
      "title": "Phase-Space Topology and Spectral Flow in Screened Magnetized Plasmas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11763v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Topological wave phenomena in continuous media are fundamentally challenged by unbounded spectra and the absence of a compact Brillouin zone, which obstruct conventional bulk--interface formulations. We develop a unified phase-space framework for screened magnetized plasma based on a pseudo-Hermitian formulation with a positive-definite metric, enabling a generalized Schrödinger description and a Weyl-symbol analysis of the bulk generator. We show that the bulk symbol hosts isolated band degeneracies acting as Berry--Chern monopoles, including a higher-order spin-1 degeneracy with topological charge $+2$ that generically splits into two spin-$\\tfrac{1}{2}$ Weyl points under symmetry breaking. To characterize topology in this noncompact setting, we introduce a strip-gap Chern number associated with finite real-frequency strips of the bulk spectrum, extending band Chern topology to continuum systems. This invariant governs the spectral flow of interface modes induced by spatial variations of the magnetic field and establishes a bulk--interface correspondence at the level of phase-space symbols. By solving the interface eigenvalue problem, we demonstrate that the net spectral flow across the strip gap is determined by the enclosed monopole charge. We further show that this correspondence persists under collisional damping, provided that a finite strip gap remains and no exceptional points enter it. Our results provide a systematic phase-space framework for topological wave transport in continuous media beyond compact-band and idealized Hermitian settings.",
        "keywords": [
          "cond-mat.mes-hall",
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11763v1",
        "authors": [
          "Xianhao Rao",
          "Adil Yolbarsop",
          "Hong Li",
          "Wandong Liu"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Screened Magnetized Plasmas Topological",
        "Space Topology",
        "Spectral Flow",
        "Framework",
        "Act",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.743481"
    },
    {
      "id": "arxiv-2602.11752v1",
      "title": "Broadband Tunable Photon-Pair Generation and Spectrum Measurement Based on Noncritical Lithium Niobate Crystals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11752v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Photon pairs play a vital role in modern science, driving extensive research into their generation. Yet, the narrow phase-matching bandwidth of conventional crystals has largely confined studies to specific wavelengths, leaving research on broadband tunable sources underexplored. Here, we employ a non-critical phase-matched lithium niobate (LN) crystal to generate widely tunable photon pairs. The generated near-infrared (NIR) photon pairs exhibit a high coincidence-to-accidental ratio (CAR > 20 dB) and are tunable across the 800-1600 nm range. We further showcase the utility of NIR photon pairs in spectroscopy by detecting carbon monoxide (CO) gas absorption. This approach will facilitate the design of advanced LN-based photonic experiments.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11752v1",
        "authors": [
          "Zhao-Qi-Zhi Han",
          "Bo-Wen Liu",
          "He Zhang",
          "Zhi-You Li",
          "Xiao-Hua Wang"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Noncritical Lithium Niobate Crystals",
        "Spectrum Measurement Based",
        "Broadband Tunable Photon",
        "Pair Generation",
        "CAR",
        "NIR",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.743755"
    },
    {
      "id": "arxiv-2602.11739v1",
      "title": "Experimental setup for the combined study of spin ensembles and superconducting quantum circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11739v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A hybrid quantum computing architecture combining quantum processors and quantum memory units allows for exploiting each component's unique properties to enhance the overall performance of the total system. However, superconducting qubits are highly sensitive to magnetic fields, while spin ensembles require finite fields for control, creating a major integration challenge. In this work, we demonstrate the first experimental setup that satisfies these constraints and provides verified qubit stability. Our cryogenic setup comprises two spatially and magnetically decoupled sample volumes inside a single dilution refrigerator: one hosting flux-tunable superconducting qubits and the other a spin ensemble equipped with a superconducting solenoid generating fields up to 50 mT. We show that several layers of Cryophy shielding and an additional superconducting aluminum shield suppress magnetic crosstalk by more than eight orders of magnitude, ensuring stability of the qubit's performance. Moreover, the operation of the solenoid adds minimal thermal load on the relevant stages of the dilution refrigerator. Our results enable scalable hybrid quantum architectures with low-loss integration, marking a key step toward scalable hybrid quantum computing platforms.",
        "keywords": [
          "physics.app-ph",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11739v1",
        "authors": [
          "Lukas Vogl",
          "Gerhard B. P. Huber",
          "Ana Strinić",
          "Achim Marx",
          "Stefan Filipp"
        ],
        "arxiv_categories": [
          "physics.app-ph",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Computing",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.744122"
    },
    {
      "id": "arxiv-2602.11734v1",
      "title": "Ultra-Fast 3D Porous Media Generation: a GPU- Accelerated List-Indexed Explicit Time-Stepping QSGS Algorithm",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11734v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Efficient generation of high-resolution synthetic microstructures is essential in digital rock physics, yet classical Quartet Structure Generation Set (QSGS) algorithms become prohibitively expensive on large three-dimensional grids. We develop a list-indexed explicit time-stepping (LIETS) formulation of QSGS that restricts stochastic growth operations to an explicit active front instead of the entire voxel grid. The method is implemented in Python using NumPy on CPUs and CuPy on GPUs, and incorporates seed-spacing control via diamond dilation together with a volume-fraction-dependent directional growth probability. For a 400^3 domain, LIETS reduces generation time from tens of minutes for a serial CPU implementation and several minutes for vectorized CPU and GPU QSGS to about 24 s on a consumer-grade RTX 4060, achieving peak throughputs up to 2.7x10^7 nodes/s. A Fontainebleau sandstone benchmark at 500^3 resolution shows that LIETS reproduces the dependence of pore and grain size distributions on seed spacing (optimal s=30 voxels) and yields permeability-porosity trends within the experimental envelope and consistent with previously published Fast-QSGS results.",
        "keywords": [
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11734v1",
        "authors": [
          "Ruofan Wang",
          "Mohammed Al-Kobaisi"
        ],
        "arxiv_categories": [
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quartet Structure Generation Set",
        "Porous Media Generation",
        "Indexed Explicit Time",
        "Algorithm Efficient",
        "Accelerated List",
        "LIETS",
        "QSGS",
        "Act",
        "RTX",
        "GPU",
        "CPU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.744473"
    },
    {
      "id": "arxiv-2602.11728v1",
      "title": "Beyond One-Thousandth Energy Resolution with an AlMn TES Detector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11728v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The superconducting Transition-Edge Sensor (TES) is a critical technology for next-generation X-ray spectrometers, known for its exceptional energy resolution. In the last decade, TESs based on AlMn alloy films have been extensively used in several cosmic microwave background (CMB) experiments. The advantages of simple fabrication process and easily tunable critical temperature make them an alternative to bilayer TESs. However, they have rarely been applied to X-ray detection until now. We developed an annular AlMn TES for X-ray detection and tested it in a dilution refrigerator with a Superconducting Quantum Interference Device (SQUID) amplifier, achieving an Full Width at Half Maximum (FWHM) of 12.1 +- 0.3 eV at 17.48 keV. To the best of our knowledge, this is the first demonstration of an AlMn TES achieving an energy resolution below 0.1%, highlighting its potential for high-resolution X-ray detection.",
        "keywords": [
          "astro-ph.IM",
          "hep-ex",
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11728v1",
        "authors": [
          "Liangpeng Xie",
          "Yifei Zhang",
          "Zhengwei Li",
          "Zhouhui Liu",
          "Shibo Shu"
        ],
        "arxiv_categories": [
          "astro-ph.IM",
          "hep-ex",
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superconducting Quantum Interference Device",
        "Thousandth Energy Resolution",
        "Half Maximum",
        "Edge Sensor",
        "Beyond One",
        "Full Width",
        "SQUID",
        "FWHM",
        "CMB",
        "TES",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.744782"
    },
    {
      "id": "arxiv-2602.11697v1",
      "title": "Hybridized-band parametric oscillations in coupled Kerr microresonators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11697v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Coupled resonators form band-like optical states that support rich nonlinearities beyond what is possible in single resonators. In these systems, four-wave mixing mediates interband coupling, displaying multimode dynamics that span both spatial and spectral degrees of freedom. In this study, we propose a framework describing the onset and control of hybridized optical parametric oscillation in three coupled silicon nitride microring resonators. In a symmetric configuration, we observe the emergence of diverse phase-matching pathways defined by the dispersive band structure. We develop an analytical model that captures the parametric gain of these interband processes and derive closed-form expressions for the dominant gain maxima; the analytical framework itself readily extends to more complex coupled networks. We further report an asymmetric design that co-engineers mode overlap and dispersion to operate on a compact 7-GHz spacing, free from mode competition. Our findings establish design principles for engineering nonlinear dynamics in coupled-resonator platforms, with implications for coherent photonic computing and quantum information processing.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11697v1",
        "authors": [
          "Luca O. Trinchão",
          "Luiz Peres",
          "Eduardo S. Gonçalves",
          "Miguel Nienstedt",
          "Laís Fujii dos Santos"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.745196"
    },
    {
      "id": "arxiv-2602.11695v1",
      "title": "Experimental challenges and prospects for quantum-enhanced energy conversion: Stationary Fano coherence in V-type qutrits interacting with polarized incoherent radiation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11695v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum coherence offers potential for energy conversion technologies. It influences light absorption and emission, affecting energy conversion limits and efficiency. As a result, quantum coherence is being harnessed to boost performance in quantum heat engines, photocells, and photosynthetic-inspired platforms. Of particular interest in this context is the generation of Fano coherences, i.e., the formation of quantum coherences due to the interaction with the continuum of modes characterizing an incoherent process. We aim to formalize mathematically the possibility of achieving steady-state Fano coherence in a V-type three-level quantum system using polarized incoherent radiation, without requiring the energy difference between the excited levels to tend to zero. We perform this analysis by deriving the Bloch-Redfield equation from first-principles by quantizing the incoherent radiation. The resulting reduced dynamics of the system are analysed, so as to determine the lifetime of Fano coherence and identify the conditions under which it becomes stationary. We characterise distinct dynamical regimes, ranging from weak to strong pumping, in which steady-state Fano coherence emerges, and we quantitatively determine its magnitude. For each regime, we analyse the generation of Fano coherence as a function of both the intensity of the incoherent pumping and the energy splitting between the excited levels. We also assess how obtaining Fano coherence is modified by symmetric or asymmetric decay rates. These findings indicate that a three-level quantum system driven by polarized incoherent light can act as a robust resource for coherence-assisted energy conversion and storage. Finally, we discuss the experimental challenges associated with the implementation of the proposed model using an ensemble of Rubidium atoms.",
        "keywords": [
          "quant-ph",
          "cond-mat.quant-gas",
          "physics.atom-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11695v1",
        "authors": [
          "Ludovica Donati",
          "Francesco Saverio Cataliotti",
          "Stefano Gherardini"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.quant-gas",
          "physics.atom-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stationary Fano",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.745697"
    },
    {
      "id": "arxiv-2602.11682v1",
      "title": "Synthetic Gauge Phase in Rydberg Electromagnetically Induced Transparency",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11682v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We demonstrate a synthetic gauge phase in Rydberg electromagnetically induced transparency (EIT) using room-temperature rubidium vapor. By exploiting polarization selection rules in a ladder-type system involving ground, intermediate, and Rydberg states, multiple Zeeman sublevels form closed-loop transitions that acquire a gauge phase. We show that the relative polarization angle between the linearly polarized probe and coupling lasers directly controls this gauge phase, which modulates the EIT transmission and Rydberg state population, consequently controlling the linewidth of EIT due to Rydberg dipole-dipole interactions between atoms. Our approach provides a simple polarization-based method for realizing synthetic gauge physics and manipulating many-body interactions in atomic ensembles without requiring laser cooling and dipole traps.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11682v1",
        "authors": [
          "Ya-Dong Hu",
          "Yi-Chen Zhang",
          "Qing-Xuan Jie",
          "Hong-Jie Fan",
          "Xiao-Kang Zhong"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rydberg Electromagnetically Induced Transparency",
        "Synthetic Gauge Phase",
        "Act",
        "EIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.745981"
    },
    {
      "id": "arxiv-2602.11659v1",
      "title": "Low-Energy, Octave-Spanning Supercontinuum Generation in Ta_2O_5 Waveguides: Towards Optical Coherence Metrology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11659v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Supercontinuum generation (SCG) on integrated photonic platforms is a pivotal technology for developing next-generation chip-scale systems for precision spectroscopy and metrology. While significant progress has been made with silicon (Si) and silicon nitride ($Si_3N_4$) platforms, they are often constrained by two-photon absorption (TPA) or moderate nonlinear coefficients, necessitating a trade-off between energy efficiency and bandwidth. Tantalum pentoxide ($Ta_2O_5$), possessing both high nonlinearity and a wide bandgap, emerges as a promising candidate; however, current implementations remain challenged by high pump energy consumption. Here, we report a low-loss $Ta_2O_5$ integrated waveguide fabricated via the Damascene process. It enables the generation of a two-octave-spanning spectrum with a low pulse energy of only 92.9 pJ (60 fs, 1550 nm). Notably, the corresponding peak power is a mere 1.36 kW, which is nearly an order of magnitude lower than that of state-of-the-art comparable broadband sources. Furthermore, at the maximum pump energy, our spectrum exhibits an ultrabroad coverage from 450 nm to 3400 nm, spanning nearly three octaves. Supported by numerical simulations, we analyze the dynamics of soliton fission. Furthermore, a Michelson interferometry system developed using this source exhibits superior performance, achieving not only micrometer-scale axial resolution but also a 6 dB sensitivity roll-off length of 3.1 mm. This exceptional roll-off performance, combined with a displacement measurement sensitivity of 346 nm, underscores the immense potential of the $Ta_2O_5$ platform for applications in biomedical imaging and precision metrology.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11659v1",
        "authors": [
          "Yanyan Zhang",
          "Qin Xie",
          "Xiaoqing Chen",
          "Xuetao Gan"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Towards Optical Coherence Metrology",
        "Spanning Supercontinuum Generation",
        "TPA",
        "SCG",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.746442"
    },
    {
      "id": "arxiv-2602.11613v1",
      "title": "Dynamic Dispersion Accumulation in Fiber Loops for Realizing Record-High Frequency Resolution or Ultra-Low Signal Sampling Rate in Dispersion-Based Photonics-Assisted Wideband Microwave Measurement Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11613v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Dispersion-based photonics-assisted microwave measurement systems provide immense potential for real-time analysis of wideband and dynamic signals. However, they face two critical challenges: a difficulty in achieving high frequency resolution over a wideband analysis bandwidth, and a reliance on large-bandwidth-and-high-sampling-rate oscilloscopes to capture the resulting ultra-narrow pulses. We introduce a dynamic dispersion accumulation technique to overcome these limitations. By circulating the optical signal in fiber loops containing a dispersion-compensating fiber, we achieve a high accumulated dispersion of -215700 ps/nm. This high dispersion relaxes the required chirp rate of the chirped optical signal, enabling two distinct advantages: When the analysis bandwidth is fixed, a lower chirp rate enables a longer temporal period, yielding a record-high frequency resolution of 27.9 MHz; When the temporal period is fixed, a lower chirp rate enables a smaller bandwidth, generating a wider pulse and thus relaxing pulse sampling requirements at the expense of analysis bandwidth. This sacrifice in analysis bandwidth can be compensated by a duty-cycle-enabling technique, which holds the potential to extend the analysis bandwidth beyond 100 GHz. This work breaks the performance and hardware limitations in dispersion-based systems, paving the way for high frequency resolution, wideband microwave measurement systems that are both real-time and cost-effective.",
        "keywords": [
          "physics.optics",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11613v1",
        "authors": [
          "Chi Jiang",
          "Taixia Shi",
          "Hang Yang",
          "Lei Gao",
          "Xianxin Zhang"
        ],
        "arxiv_categories": [
          "physics.optics",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Assisted Wideband Microwave Measurement",
        "Dynamic Dispersion Accumulation",
        "High Frequency Resolution",
        "Low Signal Sampling Rate",
        "Systems Dispersion",
        "Realizing Record",
        "Based Photonics",
        "Fiber Loops",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.746897"
    },
    {
      "id": "arxiv-2602.11597v1",
      "title": "Performance and pulse shape discrimination of glass scintillator SG101 for neutron detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11597v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a detailed characterization of the thermal neutron sensitive transparent glass scintillator SG101, benchmarked against the conventional LiF ZnS(Ag)based scintillator EJ426. The detection efficiency, energy resolution, and pulse shape discrimination (PSD) performance ofSG101 were evaluated under AmBe neutron irradiation. When coupled with organic scintillators(EJ200 or EJ276),the SG101 EJ200 system achieves a figure of merit (FOM) of 3.81 for thermal neutron/gamma separation, while the SG101 EJ276 configuration resolves three distinct particle populations gamma rays, fast neutrons, and thermal neutrons with FOM values of 3.46 and2.21, respectively. Correlation analysis reveals that the number of fast thermal neutron coincidence events significantly exceeds the accidental background, and the count of gamma fast thermal neutron triple-coincidence events is also far higher than the expected accidental rate, confirming significant physical correlations for both event types within a 100 us time window. These results demonstrate that SG101 is a promising candidate for applications requiring high-efficiency thermal neutron detection and precise event tagging coupling with a scintillator with PSD approach",
        "keywords": [
          "physics.ins-det",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11597v1",
        "authors": [
          "Yuhang Liu",
          "Fengpeng An",
          "Guang Luo",
          "Wei Wang",
          "Wei Wei"
        ],
        "arxiv_categories": [
          "physics.ins-det",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wind",
        "Act",
        "EPA",
        "PSD",
        "FOM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.747209"
    },
    {
      "id": "arxiv-2602.11593v1",
      "title": "Quantum Spin-1/2 Rings Built from [2]Triangulene Molecular Units",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11593v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum spin rings represent fundamental model systems that exhibit distinctive quantum phenomena-such as quantum critical behavior and quasiparticle excitations-arising from their periodic boundary conditions and enhanced quantum fluctuations. Here, we report the on-surface synthesis and atomic-scale characterization of antiferromagnetic S=1/2 quantum spin rings composed of pristine and unmodified [2]triangulene units on a Au(111) surface. Using stepwise on-surface synthesis followed by STM tip-induced dehydrogenation, we precisely constructed cyclic five- and six-membered spin rings and investigated their spin states via scanning probe microscopy and multireference calculations. Nc-AFM imaging reveals that the six-membered ring retains a planar geometry, whereas the five-membered ring exhibits pronounced structural distortion. The six-membered ring hosts a uniform excitation gap that can be accurately described by a Heisenberg spin model and multireference CASCI calculations. In contrast, the distorted five-membered ring displays spin ground states with asymmetric spatial distributions due to degeneracy lifting induced by structural distortion. Our findings establish a versatile molecular platform for exploring correlated magnetism and quantum spin phenomena in cyclic organic magnetic architectures with disorder.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11593v1",
        "authors": [
          "Can Li",
          "Manish Kumar",
          "Ying Wang",
          "Diego Manuel Soler Polo",
          "Yi-Jun Wang"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Triangulene Molecular Units Quantum",
        "Quantum Spin",
        "Rings Built",
        "Hydrogen",
        "Spin-1",
        "CASCI",
        "Act",
        "STM",
        "AFM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.747556"
    },
    {
      "id": "arxiv-2602.11563v1",
      "title": "Nonlinear optical spectra from Rydberg-mediated photon-photon interactions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11563v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "While Rydberg-Rydberg interactions are essential for quantum nonlinear optics and quantum information processing, their role in microwave and radio-frequency sensing remains poorly understood. Here we experimentally investigate Rydberg interaction-induced nonlinearity in cold-atom Rydberg electromagnetically induced transparency (EIT). In a three-level EIT system, increasing photon-photon interactions produces nonlinear spectral broadening accompanied by resonance shifts, while a microwave-dressed four-level system exhibits pronounced nonlinear broadening without detectable spectral shifts. Our three-level data can be explained by a conditional superatom model, whereas our four-level observations are surprisingly captured by a simple dephasing model. Comparisons with three representative models provide key insights to the role of many-body interactions in Rydberg EIT spectroscopy. Furthermore, our results clarify the conditions under which microwave field characterization can be performed in the nonlinear regime without introducing systematic bias. Our study advances both fundamental understanding of many-body physics and practical development of atomic sensors.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11563v1",
        "authors": [
          "Xinghan Wang",
          "Yupeng Wang",
          "Aishik Panja",
          "Qi-Yu Liang"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "While Rydberg",
        "Act",
        "EIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.747845"
    },
    {
      "id": "arxiv-2602.11535v1",
      "title": "Switchable high-Q light absorbers based on phase-change resonant metasurfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11535v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we propose a switchable high-Q light absorber based on a reconfigurable metasurface enabled by a lowloss phase-change material (PCM). By leveraging the coupling between guided-mode resonance and Fabry-Perot modes, mediated by the phase-transition dynamics of the embedded PCM, the resonance Q factor can be actively tuned. This allows the system to switch from a perfect dark state, governed by the physics of bound states in the continuum, to a critically coupled resonance with a finite Q factor. Consequently, the metasurface exhibits perfect absorption in the amorphous state and a reflection-dominated response in the crystalline state. The proposed metasurface holds significant potential for diverse nanophotonic applications, including photodetection and thermal emission control.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11535v1",
        "authors": [
          "Kai Qi",
          "Guoxiang Wang",
          "Xiang Shen",
          "Yixiao Gao"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "PCM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.748067"
    },
    {
      "id": "arxiv-2602.11526v1",
      "title": "Nonmonotonic Magnetic Friction from Collective Rotor Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11526v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Amontons' law postulates a monotonic relationship between frictional force and the normal load applied to a sliding contact. This empirical rule, however, fails in systems where internal degrees of freedom - such as structural or electronic order - play a central role. Here, we demonstrate that friction can emerge entirely from magnetically driven configurational dynamics in the absence of physical contact. Using a two-dimensional array of rotatable magnetic dipoles sliding over a commensurate magnetic substrate, we observe a pronounced non-monotonic dependence of friction on the interlayer separation, and thus on the effective load. The friction peaks at an intermediate distance where competing ferromagnetic and antiferromagnetic interactions induce dynamical frustration and hysteretic torque cycles during sliding. Molecular dynamics simulations and a simplified two-sublattice model confirm that energy dissipation is governed by collective magnetic reorientations and their hysteresis. Our results establish the occurrence of sliding-induced changes in collective magnetic order, which has a strong impact on friction, and thus open new possibilities for contactless friction control, magnetic sensing, and the design of reconfigurable, wear-free frictional interfaces and metamaterials.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.soft",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11526v1",
        "authors": [
          "Hongri Gu",
          "Anton Lüders",
          "Clemens Bechinger"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.soft",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Collective Rotor Dynamics Amontons",
        "Nonmonotonic Magnetic Friction",
        "Meta",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.748389"
    },
    {
      "id": "arxiv-2602.11508v1",
      "title": "Single-exposure holographic lithography of ultra-high aspect-ratio microstructures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11508v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Volumetric lithography offers a path to scalable fabrication of complex three-dimensional (3D) micro- and nanoscale architectures, yet existing approaches are limited by quasi-two-dimensional exposure physics or slow serial writing. We present a single-exposure volumetric fabrication strategy that enables creation of ultrahigh-aspect-ratio 3D structures with 6 um minimum features. An inverse-designed volumetric (holographic) phase mask generates an extended-depth-of-field intensity distribution inside a photoresist volume while preserving high transverse resolution, enabling uniform polymerization of the full volume in a single exposure. With exposure times of approximately 20 s, we fabricate lattices, Penrose tilings, and micromechanical elements with feature sizes down to 6 um over volumes up to 800 x 800 x 720 um^3, achieving aspect ratios exceeding 120:1. Quantitative analysis of capillary flow in hollow lattices demonstrates controlled fluid transport with an effective capillary transport coefficient of 176.3 um/(ms)^(1/2). In situ nanoindentation-based micro-compression reveals that the printed 3D hexagonal close-packed lattices exhibit a well-defined linear elastic regime with an effective Young's modulus of 5.7 GPa, followed by progressive buckling and densification characteristic of mechanically robust cellular architectures. Overlapping, tilted and multi-mask exposures further enable quasi-3D complex geometries with potential for reconfigurability. This approach establishes a new regime of high-throughput volumetric fabrication.",
        "keywords": [
          "physics.optics",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11508v1",
        "authors": [
          "Dajun Lin",
          "Brian Baker",
          "Rajesh Menon"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.748753"
    },
    {
      "id": "arxiv-2602.11489v1",
      "title": "Intermediate Thermal Equilibrium Stages in Molecular Dynamics Simulations of two Bodies in Contact",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11489v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Zeroth Law of Thermodynamics states that if two systems are in thermal equilibrium with a third one, then they are also in equilibrium with each other. This study explores not only the final state of thermal equilibrium between ideal gases separated by heat-conducting walls, but also the intermediate stages leading up to equilibrium, using classical molecular dynamics simulations. Two- and three-region models with argon atoms are analyzed. Fluctuations, correlations, and temperature distributions are observed, highlighting how heat conduction between regions influences the time to reach equilibrium. This work is distinguished by its detailed analysis of the intermediate stages that occur until the system reaches thermal equilibrium, in accordance with the Zeroth Law of Thermodynamics.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11489v1",
        "authors": [
          "Jonathas N. da Silva",
          "Octavio D. Rodriguez Salmon",
          "Minos A. Neto"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Molecular Dynamics Simulations",
        "Zeroth Law",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:44.748982"
    },
    {
      "id": "arxiv-2602.12240v1",
      "title": "Harmonic-to-anharmonic thermodynamic integration made simple using REG TI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12240v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Standard harmonic-to-anharmonic thermodynamic integration (TI) is known to develop a near singularity in the integrand for solids exhibiting diffusive degrees of freedom, such as rotating functional groups or migrating defects. This pathology results in numerical challenges for estimating absolute free energies within a single thermodynamic cycle. In this work, we introduce a simple regularization that removes this singularity and yields a well-behaved integrand that can be accurately evaluated on a uniform grid. The approach -- termed Regularized End-point Gradient (REG) TI -- is demonstrated on a model system and on predicting the relative stability of paracetamol polymorphs for which quasi-free methyl rotations lead to a near singularity in standard TI. We expect REG TI to simplify anharmonic free energy calculations for solids and to potentially enable their automation.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12240v1",
        "authors": [
          "Venkat Kapil"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Regularized End",
        "Standard",
        "REG",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.928809"
    },
    {
      "id": "arxiv-2602.12140v1",
      "title": "Spreading viscous fluids on a horizontal surface: project-based learning in fluid mechanics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12140v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The spreading of a thin viscous fluid film on a horizontal surface is an interesting problem in fluid mechanics with many practical applications ranging from coating processes to biological systems and environmental flows. It can even be observed in everyday situations, such as syrup spreading on a pancake. We present a project-based learning approach to this problem, in which engineering or physics undergraduates apply classroom knowledge to understand and solve it, using dimensional analysis, experiments, and theoretical modeling. First, a dimensional analysis is conducted to guide the design of the experiment suitable for an undergraduate laboratory or even at home. The problem is then simplified to obtain a mathematical model that accounts for the experimental results. Through this process, students are able to obtain a solution compatible with those published in fluid mechanics journals with minimal supervision from the instructor. This project not only develops important skills but also motivates students by showing that they have the ability to solve complex problems.",
        "keywords": [
          "physics.ed-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12140v1",
        "authors": [
          "R. Bolaños-Jimenez",
          "P. L. Luque-Escamilla"
        ],
        "arxiv_categories": [
          "physics.ed-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Laboratory",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:48.929105"
    },
    {
      "id": "arxiv-2602.12050v1",
      "title": "A Frequency-Optimized Optogenetic Study of Network-Level Potentiation in Cortical Cultures on Microelectrode Arrays",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12050v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Objective. Long-term potentiation (LTP) is a fundamental mechanism underlying learning and memory, yet its investigation at the network level in vitro remains challenging, particularly when optogenetic stimulation is used. The objective of this work is to develop a robust experimental and analytical framework for inducing and quantifying optogenetically driven LTP in neuronal cultures recorded with microelectrode arrays (MEAs). Approach. We first systematically investigate the effect of widefield optogenetic stimulation frequency on evoked neuronal activity, to identify a test-stimulus that reliably probes network responses without inducing activity modulation. By analyzing spike-rate dynamics during repeated stimulation, we characterize frequency-dependent response adaptation consistent with Channelrhodopsin-2 photocycle kinetics. Based on these results, an optimized low-frequency test-stimulus is selected and combined with a spatially confined tetanic optogenetic stimulation to induce LTP. Network responses are quantified using post-stimulus time histograms and a normalized efficacy metric, enabling electrode-wise and network-level analysis of plasticity. Main results. Low-frequency optical stimulation (<= 0.2 Hz) preserves stable evoked responses, whereas higher frequencies induce a pronounced sigmoid-like decay in firing rate. Following tetanic stimulation, a subset of electrodes exhibits robust and long-lasting potentiation, persisting for several hours. Significance. This work provides a systematic methodology for studying activity-dependent plasticity in optogenetically driven neuronal networks.",
        "keywords": [
          "physics.bio-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12050v1",
        "authors": [
          "Matteo Dominici",
          "Ilya Auslender",
          "Clara Zaccaria",
          "Yasaman Heydari",
          "Lorenzo Pavesi"
        ],
        "arxiv_categories": [
          "physics.bio-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Microelectrode Arrays Objective",
        "Optimized Optogenetic Study",
        "Level Potentiation",
        "Channelrhodopsin-2",
        "Cortical Cultures",
        "Framework",
        "Act",
        "LTP",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.929558"
    },
    {
      "id": "arxiv-2602.12037v1",
      "title": "Markov State Models for Tracking Reaction Dynamics on Catalytic Nanoparticles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12037v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Markov state models (MSMs) are a powerful tool to analyze and coarse-grain complex dynamical data into interpretable kinetic processes. This capability is particularly important in heterogeneous catalysis, where a medley of reactants and intermediates interact on surfaces that might simultaneously experience structural fluctuations. For these very complex systems, standard transition state theory (TST) approaches are no longer appropriate, motivating alternative approaches that can retain dynamical complexity while providing physical insight. With machine learned interatomic potentials being more and more ubiquitous, directly simulating complex catalytic systems with molecular dynamics (MD) is becoming increasingly feasible. Extending MSMs to dynamically coarse grain MD simulation data of catalytic processes, we analyze hydrogen dynamics on rhodium catalysts with slab and nanoparticle geometries over a range of hydrogen surface concentrations. Somewhat counterintuitively, nanoparticle features, such as corners and edges, effectively slow down the association/dissociation process, and the cooperative behavior of hydrogen-hydrogen interactions leads to a non-monotonic concentration dependence of the rates, which would not be predicted with standard TST.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12037v1",
        "authors": [
          "Caitlin A. McCandler",
          "Chatipat Lorpaiboon",
          "Timothy C. Berkelbach",
          "Jutta Rogal"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Catalytic Nanoparticles Markov",
        "Tracking Reaction Dynamics",
        "Markov State Models",
        "Standard",
        "Hydrogen",
        "Act",
        "TST",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.929880"
    },
    {
      "id": "arxiv-2602.12031v1",
      "title": "Thermodynamic Stability and Hydrogen Bonds in Mixed Halide Perovskites",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12031v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The stability of mixed halide perovskites against phase separation is crucial for their optoelectronic applications, yet difficult to rationalize due to the interplay of enthalpic, configurational, and dynamical effects. Here we present a simple thermodynamic framework for multicomponent halide perovskites of composition FA$_{1-x}$MA$_{x-y}$Cs$_y$Pb(I$_{1-z}$Br$_z$)$_3$, based on \\textit{ab initio} molecular dynamics. By decomposing the free energy of mixing into enthalpic, configurational, and rotational entropic contributions, we show that although the enthalpy of mixing is generally positive, the solid solutions are thermodynamically stable against phase separation due to the large configurational entropy associated with random substitution on cation and halide sublattices. Mixing reduces the rotational entropy of the organic cations, partially offsetting the configurational stabilization. However, within our model, this rotational penalty is not sufficient to overcome the configurational driving force, and a curvature analysis within a regular-solution model does not predict a miscibility gap for any of the mixing channels considered. Analysis of hydrogen-bond dynamics shows that MA--Y (Y = I, Br) interactions are more persistent than FA--Y interactions, while the dominant FA-donated N$-$H$\\cdots$I hydrogen bonds remain nearly composition-invariant. Cs-containing mixtures, in which Cs$^{+}$ forms no hydrogen bonds, can nevertheless be thermodynamically stable. These results demonstrate that hydrogen bonding does not control thermodynamic stability in mixed halide perovskites. Instead, phase stability is governed by the balance between strong configurational entropy and a smaller, systematically destabilizing rotational-entropy correction.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12031v1",
        "authors": [
          "Liz Camayo-Gutierrez",
          "Javiera Ubeda",
          "Ana L. Montero-Alejo",
          "Ricardo Grau-Crespo",
          "Eduardo Menéndez-Proupin"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hydrogen Bonds",
        "Framework",
        "Hydrogen",
        "Act",
        "EPA",
        "DOE",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.930302"
    },
    {
      "id": "arxiv-2602.11873v1",
      "title": "Temporally resolved aortic 3D shape reconstruction from a limited number of cine 2D MRI slices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11873v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Background and Objective: We propose a shape reconstruction framework to generate time-resolved, patient-specific 3D aortic geometries from a limited number of standard cine 2D magnetic resonance imaging (MRI) acquisitions. A statistical shape model of the aorta is coupled with differentiable volumetric mesh optimization to obtain personalized aortic meshes. Methods: The statistical shape model was constructed from retrospective data and optimized 2D slice placements along the aortic arch were identified. Cine 2D MRI slices were then acquired in 30 subjects (19 volunteers, 11 aortic stenosis patients). After manual segmentation, time-resolved aortic models were generated via differentiable volumetric mesh optimization to derive vessel shape features, centerline parameters, and radial wall strain. In 10 subjects, additional 4D flow MRI was acquired to compare peak-systolic shapes. Results: Anatomically accurate aortic geometries were obtained from as few as six cine 2D MRI slices, achieving a mean +/- standard deviation Dice score of (89.9 +/- 1.6) %, Intersection over Union of (81.7 +/- 2.7) %, Hausdorff distance of (7.3 +/- 3.3) mm, and Chamfer distance of (3.7 +/- 0.6) mm relative to 4D flow MRI. The mean absolute radius error was (0.8 +/- 0.6) mm. Significant age-related differences were observed for all shape features, including radial strain, which decreased progressively ((11.00 +/- 3.11) x 10-2 vs. (3.74 +/- 1.25) x 10-2 vs. (2.89 +/- 0.87) x 10-2 for young, mid-age, and elderly groups). Conclusion: The proposed method enables efficient extraction of time-resolved 3D aortic meshes from limited sets of standard cine 2D MRI acquisitions, suitable for computational shape and strain analysis.",
        "keywords": [
          "eess.IV",
          "physics.med-ph",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11873v1",
        "authors": [
          "Gloria Wolkerstorfer",
          "Stefano Buoso",
          "Rabea Schlenker",
          "Jochen von Spiczak",
          "Robert Manka"
        ],
        "arxiv_categories": [
          "eess.IV",
          "physics.med-ph",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "Act",
        "MRI",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.930716"
    },
    {
      "id": "arxiv-2602.11813v1",
      "title": "Early stages of collective cell invasion: Biomechanics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11813v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The early stages of the collective invasion may occur by single mesenchymal cells or hybrid epithelial-mesenchymal cell groups that detach from cancerous tissue. Tumors may also emit invading protrusions of epithelial cells, which could be led (or not) by a basal cell. Here we devise a fractional step cellular Potts model comprising passive and active cells able to describe these different types of collective invasion before cells start proliferating. Durotaxis and active forces have different symmetry properties and are included in different half steps of the fractional step method. Compared with a single step method, fractional step produces more realistic cellular invasion scenarios with little extra computational effort. Biochemical mechanisms that determine how cells acquire their different phenotypes and cellular proliferation will be incorporated to the model in future publications.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "q-bio.CB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11813v1",
        "authors": [
          "R. González-Albaladejo",
          "M. Carretero",
          "L. L. Bonilla"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "q-bio.CB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.930953"
    },
    {
      "id": "arxiv-2602.11702v1",
      "title": "A Hardware-Native Realisation of Semi-Empirical Electronic Structure Theory on Field-Programmable Gate Arrays",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11702v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-throughput quantum-chemical calculations underpin modern molecular modelling, materials discovery, and machine-learning workflows, yet even semi-empirical methods become restrictive when many molecules must be evaluated. Here we report the first hardware-native realisation of semi-empirical electronic structure theory on a field-programmable gate array (FPGA), implementing as a proof of principle Extended Hückel Theory (EHT) and non-self-consistent Density Functional Tight Binding (DFTB0). Our design performs Hamiltonian construction and diagonalisation on the FPGA device through a streaming dataflow, enabling deterministic execution without host intervention. On a mid-range Artix-7 FPGA, the DFTB0 Hamiltonian generator delivers a throughput over fourfold higher than that of a contemporary server-class CPU. Improvements in eigensolver design, memory capacity, and extensions to nuclear gradients and excited states could further expand capability. Combined with the inherent energy efficiency of FPGA dataflow, this work opens a pathway towards sustainable, hardware-native acceleration of electronic-structure simulation and direct hardware implementations of a broad class of methods.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11702v1",
        "authors": [
          "Xincheng Miao",
          "Roland Mitrić"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Density Functional Tight Binding",
        "Programmable Gate Arrays High",
        "Native Realisation",
        "Nuclear",
        "Artix-7",
        "NIST",
        "FPGA",
        "EHT",
        "CPU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.931560"
    },
    {
      "id": "arxiv-2602.11701v1",
      "title": "BSoNet: Deep Learning Solution for Optimizing Image Quality of Portable Backscatter Imaging Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11701v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Portable backscatter imaging systems (PBI) integrate an X-ray source and detector in a single unit, utilizing Compton scattering photons to rapidly acquire superficial or shallow structural information of an inspected object through single-sided imaging. The application of this technology overcomes the limitations of traditional transmission X-ray detection, offering greater flexibility and portability, making it the preferred tool for the rapid and accurate identification of potential threats in scenarios such as borders, ports, and industrial nondestructive security inspections. However, the image quality is significantly compromised due to the limited number of Compton backscattered photons. The insufficient photon counts result primarily from photon absorption in materials, the pencil-beam scanning design, and short signal sampling times. It therefore yields severe image noise and an extremely low signal-to-noise ratio, greatly reducing the accuracy and reliability of PBI systems. To address these challenges, this paper introduces BSoNet, a novel deep learning-based approach specifically designed to optimize the image quality of PBI systems. The approach significantly enhances image clarity, recognition, and contrast while meeting practical application requirements. It transforms PBI systems into more effective and reliable inspection tools, contributing significantly to strengthening security protection.",
        "keywords": [
          "eess.IV",
          "physics.med-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11701v1",
        "authors": [
          "Linxuan Li",
          "Wenjia Wei",
          "Yunfei Lu",
          "Wenwen Zhang",
          "Yanlong Zhang"
        ],
        "arxiv_categories": [
          "eess.IV",
          "physics.med-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Portable Backscatter Imaging Systems",
        "Optimizing Image Quality",
        "Deep Learning Solution",
        "Deep Learning",
        "Act",
        "NSF",
        "PBI",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.931886"
    },
    {
      "id": "arxiv-2602.11603v1",
      "title": "Rapid Dissipative Ground State Preparation at Chemical Transition States",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11603v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Simulating chemical reactions is a central challenge in computational chemistry, characterized by an uneven difficulty profile: while equilibrium reactant and product geometries are often classically tractable, intermediate transition states frequently exhibit strong correlation that defies standard approximations. We present a protocol for dissipative ground state preparation that exploits this structure by treating the reaction path itself as a computational primitive. Our protocol uses an approach where a state prepared at a tractable geometry is propagated along a discretized reaction coordinate using Procrustes-aligned orbital rotations and stabilized by engineered dissipative cooling. We show that for reaction paths satisfying a localized Eigenstate Thermalization Hypothesis (ETH) drift condition in the strongly correlated regime, the algorithm prepares ground states of chemical systems with $N_o$ orbitals to an energy error $ε_E$ with a total gate complexity scaling as $\\widetilde{O}(N_o^{3}/ε_E)$. We provide logical resource estimates for benchmark systems including FeMoco, Cytochrome P450, and Ru-based carbon capture catalysts.",
        "keywords": [
          "quant-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11603v1",
        "authors": [
          "Thomas W. Watts",
          "Soumya Sarkar",
          "Daniel Collins",
          "Nam Nguyen",
          "Luke Quezada"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chemical Transition States Simulating",
        "Rapid Dissipative Ground State",
        "Carbon Capture",
        "Standard",
        "Protocol",
        "Act",
        "EPA",
        "MIT",
        "ETH",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.932594"
    },
    {
      "id": "arxiv-2602.11601v1",
      "title": "Collaboration drives phase transitions towards cooperation in prisoner's dilemma",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11601v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a collaboration ring model -- a network of players playing the prisoner's dilemma game and collaborating among the nearest neighbours by forming coalitions. The microscopic stochastic updating of the players' strategies are driven by their innate nature of seeking selfish gains and shared intentionality. Cooperation emerges in such a structured population through non-equilibrium phase transitions driven by propensity of the players to collaborate and by the benefit that a cooperator generates. The robust results are qualitatively independent of number of neighbours and collaborators.",
        "keywords": [
          "physics.soc-ph",
          "cond-mat.stat-mech",
          "econ.TH",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11601v1",
        "authors": [
          "Joy Das Bairagya",
          "Jonathan Newton",
          "Sagar Chakraborty"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cond-mat.stat-mech",
          "econ.TH",
          "q-bio.PE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:48.932762"
    },
    {
      "id": "arxiv-2602.11540v1",
      "title": "Transition from traveling fronts to diffusion-limited growth in expanding populations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11540v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Reaction-diffusion equations describe various spatially extended processes that unfold as traveling fronts moving at constant velocity. We introduce and solve analytically a model that, besides such fronts, supports solutions advancing as the square root of time. These sublinear fronts preserve an invariant shape, with an effective diffusion constant that diverges at the transition to linear spreading. The model applies to dense cellular aggregates of nonmotile cells consuming a diffusible nutrient. The sublinear spread results from biomass redistribution slowing due to nutrient depletion, a phenomenon supported experimentally but often neglected. Our results provide a potential explanation for the linear rather than quadratic increase of colony area with time, which has been observed for many microbes.",
        "keywords": [
          "physics.bio-ph",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11540v1",
        "authors": [
          "Louis Brezin",
          "Kyle J. Shaffer",
          "Kirill S. Korolev"
        ],
        "arxiv_categories": [
          "physics.bio-ph",
          "q-bio.PE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:48.933005"
    },
    {
      "id": "arxiv-2602.11497v1",
      "title": "End-to-End Differentiable Photon Counting CT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11497v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantitative imaging is an important feature of spectral X-ray and CT systems, especially photon-counting CT (PCCT) imaging systems, which is achieved through material decomposition (MD) using spectral measurements. In this work, we present a novel framework that makes the PCCT imaging chain end-to-end differentiable (differentiable PCCT), with which we can leverage quantitative information in the image domain to enable cross-domain learning and optimization for upstream models. Specifically, the material decomposition from maximum-likelihood estimation (MLE) was made differentiable based on the Implicit Function Theorem and inserted as a layer into the imaging chain for end-to-end optimization. This framework allows for an automatic and adaptive solution of a wide range of imaging tasks, ultimately achieving quantitative imaging through computation rather than manual intervention. The end-to-end training mechanism effectively avoids the need for direct-domain training or supervision from intermediate references as models are trained using quantitative images. We demonstrate its applicability in two representative tasks: correcting detector energy bin drift and training an object scatter correction network using cross-domain reference from quantitative material images.",
        "keywords": [
          "physics.med-ph",
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11497v1",
        "authors": [
          "Sen Wang",
          "Yirong Yang",
          "Jooho Lee",
          "Grant M. Stevens",
          "Adam S. Wang"
        ],
        "arxiv_categories": [
          "physics.med-ph",
          "eess.IV"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "End Differentiable Photon Counting",
        "Framework",
        "PCCT",
        "MLE",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-15T13:53:48.933292"
    },
    {
      "id": "arxiv-2602.12282v1",
      "title": "Ubiquitous yet forgotten: broad absorptions in the optical spectra of low-mass X-ray binaries",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12282v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Optical outburst spectra of low-mass X-ray binaries enable studies of extreme accretion and ejection phenomena. While some of their spectroscopic features have been analysed in detail, the appearance of broad absorptions in the optical regime has been traditionally neglected. In this work, we introduce the first population study dedicated to these features with the aim to understand their fundamental properties and discuss them in the context of their origin. We complement the study with a spectroscopic database of six low-mass X-ray binaries during outburst, in order to assess their evolution. We find that broad absorptions are ubiquitous, with the majority of black hole low-mass X-ray binaries exhibiting them in spite of a typically scarce outburst coverage. Their detection does not depend on the orbital inclination or the compact object nature, but they seem favoured in systems with orbital periods shorter than < 11 h. They predominantly occur in the hydrogen Balmer series, being stronger at shorter wavelengths, and they are detected across all X-ray states. We find that the normalised depth of these broad absorptions is anti-correlated with the system luminosity, and that they show constant line ratios over the whole sample. Based on these properties, we favour a scenario where BAs arise from a stable, optically thick layer of the accretion disc, below the hotter chromosphere-like region producing the emission line components. Our study is consistent with the continuous presence of broad absorptions during the whole outburst, with their visibility being conditioned by the emission lines filling the broad absorption profile and veiling by the X-ray reprocessed continuum.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12282v1",
        "authors": [
          "D. Mata Sanchez",
          "T. Munoz-Darias",
          "J. Casares",
          "M. A. P. Torres",
          "M. Armas Padilla"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hydrogen",
        "Act",
        "WHO",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.133579"
    },
    {
      "id": "arxiv-2602.12277v1",
      "title": "Reionization Bubbles from Real-Space Cross Correlations of Line Intensity Maps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12277v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose a new way to reconstruct the ionized-bubble size distribution during the Epoch of Reionization (EoR) through the real-space cross-correlation of 21-cm and star-forming line-intensity maps. Understanding the evolution and timing of the EoR is crucial for both astrophysics and cosmology, and a wealth of information on the first sources can be extracted from the study of ionized bubbles. Nevertheless, directly mapping bubbles is challenging due to the high redshifts involved, possible selection biases, and foregrounds in 21-cm maps. Here, we exploit the real-space cross-correlation $ξ_{21,ν}$ between 21-cm and line-intensity mapping (LIM) signals to reconstruct the evolution of bubble sizes during reionization. For the first time, we show that $ξ_{21,ν}(r)$ departs from a saturation level for each separation $r$ when bubbles of size $r$ begin to form, providing a handle for the onset of bubbles of each radius. Moreover, we demonstrate that $ξ_{21,ν}$ evolves from positive to negative as the EoR progresses, reaching a minimum (i.e. maximum anti-correlation) when bubbles of radius $r$ reach peak abundance. We show that these results are robust to changes in the astrophysical model as well as the timing/topology of reionization. This real-space observable complements usual Fourier-space estimators by capturing the localized nature of bubbles, offering new insights into the sources driving cosmic reionization.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12277v1",
        "authors": [
          "Emilie Thélie",
          "Sarah Libanore",
          "Yonatan Sklansky",
          "Julian B. Muñoz",
          "Ely D. Kovetz"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Space Cross Correlations",
        "Line Intensity Maps We",
        "Reionization Bubbles",
        "Act",
        "EPA",
        "LIM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.134676"
    },
    {
      "id": "arxiv-2602.12272v1",
      "title": "The Wandering Supermassive Black Hole Powering the off-nuclear TDE AT2024tvd",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12272v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present an analysis of the spectral energy distribution (SED) of the off-nuclear tidal disruption event (TDE) AT2024tvd during its late-time plateau phase, combining X-ray spectra and UV/optical photometry. Using a fully relativistic, compact accretion disk model with self-consistent inner-disk Comptonization, we reproduce the observed SED without significant residuals. The inferred black hole mass ${\\rm log}{10}(M{\\bullet}/M_\\odot) \\approx 6.0 \\pm 0.2$, and the inferred disk parameters place AT2024tvd within known TDE-disk scaling relations ($L_{\\rm bol}^{\\rm disk}/L_{\\rm Edd} \\propto T_{\\rm p}^4 \\propto M_{\\bullet}^{-1}$, $L_{\\rm plat} \\propto M_{\\bullet}^{2/3}$, $R_{\\rm out}/r_{\\rm g} \\propto M_{\\bullet}^{-2/3}$). Our results show that: (i) there is no \\textit{detected} star cluster or dwarf galaxy associated with the source, down to a mass limit of $\\log_{10}(M_{\\rm gal}/M_{\\odot}) \\leq 7.6$; (ii) the black hole is a wandering supermassive, rather than intermediate-mass, black hole; and (iii) the source represents an extreme case of black hole-to-host mass ratio, with $M_{\\bullet}/M_{\\rm gal} > 3\\%$, consistent with a heavily tidally stripped nucleus. The latter aligns with cosmological simulations predicting that surviving host remnants of most wandering black holes should not retain a detectable stellar overdensity when located at small halo-centric distances. We discuss differences with previous analyses of this source and highlight why our modeling approach provides a more physically consistent solution with more reliable parameter inference.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12272v1",
        "authors": [
          "M. Guolo",
          "A. Mummery",
          "S. van Velzen",
          "M. Nicholl",
          "S. Gezari"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hole Powering",
        "Nuclear",
        "Act",
        "MIT",
        "SED",
        "TDE",
        "AI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.135206"
    },
    {
      "id": "arxiv-2602.12252v1",
      "title": "The Dark Side of the Moon: Listening to Scalar-Induced Gravitational Waves",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12252v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The collapse of large-amplitude primordial curvature perturbations into planetary-mass primordial black holes generates a scalar-induced gravitational wave background in the $μ$Hz frequency range that may be detectable by future Lunar Laser Ranging and Satellite Laser Ranging data. We derive projected constraints on the primordial black hole population from a null detection of stochastic gravitational wave background by these experiments, including the impact of the electroweak phase transition on the abundance of planetary-mass primordial black holes. We also discuss the connection between the obtained projected constraints and the recent microlensing observations by the HSC collaboration of the Andromeda Galaxy.",
        "keywords": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12252v1",
        "authors": [
          "D. Blas",
          "J. W. Foster",
          "Y. Gouttenoire",
          "A. J. Iovino",
          "I. Musco"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite Laser Ranging",
        "Lunar Laser Ranging",
        "Andromeda Galaxy",
        "Satellite",
        "Act",
        "HSC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.135810"
    },
    {
      "id": "arxiv-2602.12238v1",
      "title": "Status of the $S_8$ Tension: A 2026 Review of Probe Discrepancies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12238v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The parameter $S_8 \\equiv σ_8 (Ω_m/0.3)^{0.5}$ quantifies the amplitude of matter density fluctuations. A persistent discrepancy exists between early-universe CMB observations and late-universe probes. This review assesses the ``$S_8$ tension'' against a new 2026 baseline: a unified ``Combined CMB'' framework incorporating Planck, ACT DR6, and SPT-3G. This combined analysis yields $S_8 = 0.836^{+0.012}_{-0.013}$, providing a higher central value and reduced uncertainties compared to Planck alone. Compiling measurements from 2019--2026, we reveal a striking bifurcation: DES Year 6 results exhibit a statistically significant tension of $2.4σ$--$2.7σ$ \\citep{DESY6}, whereas KiDS Legacy results demonstrate statistical consistency at $<1σ$ \\citep{Wright2025}. We examine systematic origins of this dichotomy, including photometric redshift calibration, intrinsic alignment modeling, and shear measurement pipelines. We further contextualize these findings with cluster counts (where eROSITA favors high values while SPT favors low), galaxy-galaxy lensing, and redshift-space distortions. The heterogeneous landscape suggests survey-specific systematic effects contribute substantially to observed discrepancies, though new physics beyond $Λ$CDM cannot be excluded.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12238v1",
        "authors": [
          "Ioannis Pantos",
          "Leandros Perivolaropoulos"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "EPA",
        "SPT",
        "DES",
        "CDM",
        "ACT",
        "CMB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.136734"
    },
    {
      "id": "arxiv-2602.12232v1",
      "title": "Extending the Cosmological Collider: New Scaling Regimes and Constraints from BOSS",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12232v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Primordial non-Gaussianity generated by additional fields during inflation offers a compelling observational target. Heavy fields imprint characteristic oscillatory signals in non-Gaussian correlation functions of the inflaton, a process sometimes referred to as cosmological-collider physics. These distinct signatures are compelling windows into ultra-high-energy physics, but are often suppressed, making standard equilateral non-Gaussianity the most promising discovery channel in many scenarios. In this paper, we show that direct couplings between the inflaton and additional fields can lead to a wide variety of novel, observationally relevant signals which open new parameter regimes that simultaneously exhibit the characteristics of light and heavy fields. We identify these primordial signatures in the late-time observables of the large-scale structure of the Universe, where they most significantly modify the scale-dependent bias of the galaxy power spectrum to include an oscillatory modulation around a non-trivial power law. We explore the full range of parameters that phenomenologically arise in these models and study the sensitivity of current and future galaxy surveys, finding that this new class of primordial non-Gaussianity is particularly accessible in near-term surveys due to its oscillatory feature. Finally, we perform an analysis of existing data from the final release of the Baryon Oscillation Spectroscopic Survey (BOSS DR12). While we find no evidence for a signal, we demonstrate significant improvements in sensitivity over respective non-oscillatory scenarios and place the first constraints on this extended parameter space of oscillatory non-Gaussianity.",
        "keywords": [
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12232v1",
        "authors": [
          "Daniel Green",
          "Jiashu Han",
          "Benjamin Wallisch"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Baryon Oscillation Spectroscopic Survey",
        "Cosmological Collider",
        "New Scaling Regimes",
        "Standard",
        "Wind",
        "BOSS",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.137268"
    },
    {
      "id": "arxiv-2602.12201v1",
      "title": "Oxygen left behind: Atmospheric Enrichment due to Fractionation in Sub-Neptunes using BOREAS",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12201v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The evolution of exoplanetary atmospheres is strongly influenced by atmospheric escape, particularly for close-in planets. Fractionation during atmospheric loss can preferentially remove lighter elements such as hydrogen, while retaining heavier species like oxygen. In this study, we investigate how and under what conditions hydrodynamic escape and chemical fractionation jointly shape the mass and composition of exoplanet atmospheres, especially for mixed H2 + H2O atmospheres. We develop BOREAS, a self-consistent mass loss model coupling a 1D Parker wind formulation with a mass-dependent fractionation scheme, which we apply across a range of planet masses, radii, equilibrium temperatures, and incident XUV fluxes, allowing us to track hydrogen and oxygen escape rates at different snapshots in time. We find that oxygen is efficiently retained over most of the parameter space. Significant oxygen loss occurs under high incident XUV fluxes, while at intermediate fluxes oxygen loss is largely confined to low-gravity planets. Where oxygen is retained, irradiation is too weak to drive significant escape of hydrogen and thus limiting atmospheric enrichment. By contrast, our model predicts that sub-Neptunes undergo substantial atmospheric enrichment over approx. 200 Myr when hydrogen escape is efficient and accompanied by partial oxygen entrainment. Notably, our results imply that sub-Neptunes near the radius valley can evolve into water-rich planets, in agreement with GJ 9827 d. Present-day water-rich atmospheres may have originated from water-poor envelopes under some conditions, highlighting the need to include chemical fractionation in evolution models. BOREAS is publicly available.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12201v1",
        "authors": [
          "Marilina Valatsou",
          "Caroline Dorn",
          "Pierlou Marty",
          "James E. Owen"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Atmospheric Enrichment",
        "Agreement",
        "Hydrogen",
        "BOREAS",
        "Wind",
        "Act",
        "MIT",
        "XUV",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.137794"
    },
    {
      "id": "arxiv-2602.12200v1",
      "title": "What does a regular star look like?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12200v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recently, astronomers discovered unusual Einstein cross images of the galaxy HerS-3, which feature a bright central spot. Motivated by studies of images produced by regular stars, it has been proposed that optical appearances caused by compact stars acting as gravitational lenses may account for this central bright spot. We further suggest that images produced by regular stars exhibit additional characteristics distinct from those of ordinary black holes, such as the possible partial or complete absence of secondary images. These phenomena may serve as favorable observational criteria for identifying regular stars in future searches.",
        "keywords": [
          "gr-qc",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12200v1",
        "authors": [
          "Yu Liang",
          "Yuhao Cui",
          "Kai Lin",
          "Sen Guo",
          "V. H. Satheeshkumar"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "HerS-3",
        "Act",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.138042"
    },
    {
      "id": "arxiv-2602.12195v1",
      "title": "A simple model for extracting astrophysics from black hole images",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12195v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Event Horizon Telescope (EHT) is providing unprecedented high-resolution images of supermassive black holes. These images are fundamentally related to properties of the luminous accretion disks, since black holes themselves produce no light. We develop a simple prescription to relate observational features of black hole images to a toy model for the intensity profile of the associated accretion disk. We apply our model to the original EHT image of M87*, as well as to the reanalyzed image from the PRIMO algorithm, providing generic, simultaneous constraints on the mass of the black hole and properties of the accretion disk emission. While current images lack the resolution to confidently detect the photon ring, the consideration of multiple image parameters are found to contain enough information to provide constraints on the inner edge of the accretion disk along with the black hole mass. Using observed features of the original EHT image, we constrain the mass of M87* to be $6.6^{+1.2}_{-1.0}\\times 10^9 M_\\odot$ to 68$\\%$ confidence, and find that emission may extend all the way to the black hole horizon. When instead using constraints from the PRIMO algorithm's image along with constraints on the brightness asymmetry provided by the original EHT analysis, we find M87*'s mass to be $ 6.4^{+0.7}_{-0.7}\\times 10^9 M_\\odot$ to 68$\\%$ confidence, with the inner edge of the accretion disk between $3M$ and $5.3M$. Both analyses rule out an inner edge of the accretion disk coinciding with the innermost stable circular orbit for a Schwarzschild black hole. Furthermore, the narrow ring width reported in the PRIMO image also confidently rules out emission increasing all the way down to the black hole horizon. Further assumptions on the mass of M87* and connections between the accretion disk cutoff and physical radii allow for rudimentary black hole spin estimates.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12195v1",
        "authors": [
          "Alexandra G. Guerrero",
          "Daniel E. Holz"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "PRIMO",
        "Act",
        "EHT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.138605"
    },
    {
      "id": "arxiv-2602.12174v1",
      "title": "Probing baryonic feedback with fast radio bursts: joint analyses with cosmic shear and galaxy clustering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12174v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Cosmological inference from weak lensing (WL) surveys is increasingly limited by uncertainties in baryonic physics, which suppress the non-linear matter power spectrum on small scales. Multi-probe analyses that incorporate complementary tracers of the gas distribution around haloes offer a pathway to calibrate these effects and recover unbiased cosmological information. In this work, we forecast the constraining power of a joint analysis combining fiducial data from a Stage-IV WL survey with measurements of the dispersion measure from fast radio bursts (FRBs). We evaluate the ability of this approach to simultaneously constrain cosmological parameters and the astrophysical processes governing baryonic feedback, and we quantify the impact of key FRB systematics, including redshift uncertainties and source clustering. We find that, even after accounting for these effects, a 3$\\times$2-point analysis of WL and FRBs significantly improves cosmological constraints, reducing the degradation factor on $S_8$ by $\\sim 80\\%$ compared to WL alone. We further show that FRBs alone are sensitive only to a degenerate combination of the key baryonic parameters, $\\log_{10} M_{\\rm c}$ and $η_{\\rm b}$, and that the inclusion of WL measurements breaks this degeneracy. Finally, we extend our framework to incorporate galaxy clustering measurements using Luminous Red Galaxy and Emission Line Galaxy samples, performing a unified 6$\\times$2-point analysis of WL, dispersion measures of FRBs, and galaxy clustering. While this combined approach tightens constraints on $Ω_{\\rm m}$ and $\\log_{10} M_{\\rm c}$, it does not lead to a significant improvement in $S_8$ constraints beyond those obtained from WL and FRBs alone.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12174v1",
        "authors": [
          "Amy Wayland",
          "David Alonso",
          "Robert Reischke"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Emission Line Galaxy",
        "Luminous Red Galaxy",
        "Framework",
        "Act",
        "MIT",
        "DOE",
        "FRB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.139843"
    },
    {
      "id": "arxiv-2602.12165v1",
      "title": "Poloidal Field Amplification through Compression-Shear Dynamics in Schwarzschild Accretion: Pathways to MAD States",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12165v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The amplification of magnetic fields in black hole accretion flows governs key high-energy phenomena such as magnetically arrested disks and relativistic jets. We develop a semi-analytical general relativistic framework that extends classical compressional amplification models by incorporating rotational shear, and apply it to large-scale poloidal magnetic field evolution in accretion flows around a Schwarzschild black hole. By parameterizing the azimuthal velocity as a fraction of the Keplerian value ($ξ\\in [0,1]$), from purely radial infall ($ξ=0$) to Keplerian rotation ($ξ=1$), we examine the combined effects of radial compression and shear. Purely radial flows maximize amplification of both $B_r$ and $B_θ$ due to strong compression. In rotating flows, a distinct dichotomy emerges: sub-Keplerian regimes ($ξ<1$) preferentially enhance $B_r$, whereas Keplerian rotation strengthens $B_θ$ via shear. The transition from subsonic outer regions to supersonic relativistic inner regions further accelerates magnetic growth, revealing effects absent in earlier analytical treatments. These results show that rotational support controls both amplification efficiency and magnetic geometry, with sub-Keplerian phases particularly favorable for advecting the radial flux required for MAD formation. This work provides an analytical bridge between classical accretion theory and modern GRMHD simulations, with implications for X-ray binaries, AGNs, and EHT-scale systems.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12165v1",
        "authors": [
          "Malihe Mousapour Gharghabi",
          "Jamshid Ghanbari",
          "Mahboobe Moeen Moghaddas"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Poloidal Field Amplification",
        "Schwarzschild Accretion",
        "Shear Dynamics",
        "Framework",
        "GRMHD",
        "Act",
        "EHT",
        "MAD",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.140896"
    },
    {
      "id": "arxiv-2602.12115v1",
      "title": "Search for Sub-Solar Mass Binaries in the First Part of LIGO's Fourth Observing Run",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12115v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We report the first results of a sub-solar mass compact binary search using the data from the first part of the fourth observing run (O4a) of the Advanced LIGO detectors. Sub-solar mass neutron stars or primordial black holes are not expected to form via standard stellar evolution, and their observation would signify a new class of astrophysical object or the discovery of dark matter. Our search covers binaries with primary masses 0.1 to 2 $\\textrm{M}_\\odot$ and secondary masses 0.1 to 1 $\\textrm{M}_\\odot$. We explicitly incorporate tidal effects up to $7\\times10^5$ for extremely low mass neutron stars. No statistically significant candidates are identified. The advanced sensitivity of the O4a run enables an improvement in the sub-solar mass black hole merger rate limits by more than $2 \\times$ over the previous three observing runs (O1-O3b). We place a $90\\%$ confidence upper limit on the merger rate $\\mathcal{R}_{90}$ for sub-solar mass black holes to be $< 1.77\\times10^4 \\textrm{Gpc}^{-3} \\textrm{yr}^{-1}$ for a chirp mass of 0.2 $\\textrm{M}_\\odot$. We place the first constraints for binary neutron stars with tidal deformabilities up to $\\sim 7\\times10^5$ and improve the merger rate estimate by a factor $\\sim 4$ in comparison to previous O3 tidal searches for tidal deformabilities $< 10^4$. We further constrain the fraction of dark matter composed of primordial black hole $f_{\\rm PBH}< 2\\%$ for a chirp mass of 0.1 $\\textrm{M}_\\odot$. Our results significantly expand the observational search space for sub-solar binaries and provide rigorous constraints on the local abundance of compact objects that may arise from non-standard formation mechanisms.",
        "keywords": [
          "astro-ph.HE",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12115v1",
        "authors": [
          "Keisi Kacanja",
          "Kanchan Soni",
          "Aleyna Akyuz",
          "Alexander H. Nitz"
        ],
        "arxiv_categories": [
          "astro-ph.HE",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fourth Observing Run We",
        "Solar Mass Binaries",
        "First Part",
        "Standard",
        "Solar",
        "LIGO",
        "Act",
        "MIT",
        "PBH",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.141352"
    },
    {
      "id": "arxiv-2602.12110v1",
      "title": "Testing and Validation of the Updated Pixel-Based Non-Linearity Calibration File for WFC3/IR",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12110v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The WFC3\\IR channel has an innate non-linear response to incident photons, which is corrected for in the calwf3 pipeline with the NLINFILE reference file. The 2009 solution is based on an average polynomial correction for each IR quadrant and is found to be poorly constrained at high fluence levels (e-) approaching the saturation limit. Using a variety of image types, sources, and sample sequences, we test a new pixel-based linearity correction developed by Shenoy et al. (2025). In nearly all cases, the new correction improves the linearity at fluence levels higher than 50,000 e-, with improvements up to 7% for pixels with fluences approaching the saturation limit (80,000 e-) in the last ima reads. The pixel-based solution also significantly decreases the number of cosmic rays erroneously flagged (due to non-linearity correction errors) during ramp fitting in calwf3, leading to improved photometric accuracy in the calibrated flt data and higher signal-to-noise ratios, particularly in Quad 1 (upper-left detector quadrant). Because the new solution tends to make sources brighter, we recalibrate the five HST flux standards used to compute the IR zeropoints and find a negligible impact (0.1-0.2%) on the published values by Calamida et al. (2024), smaller than the RMS dispersion (0.5%) in the observed to synthetic flux ratios for all five flux standards. The new NLINFILE 9au15283i lin.fits was delivered to CRDS in October 2025 and will be used to reprocess all WFC3/IR imaging and grism observations in the MAST archive. An updated reference file a2412448i lin.fits was delivered in February 2026, improving the results at the highest fluence levels by a few tenths of a percent. Please consult the Addendum for details.",
        "keywords": [
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12110v1",
        "authors": [
          "K. Huynh",
          "V. Bajaj",
          "M. Marinelli",
          "J. Mack",
          "S. Shenoy"
        ],
        "arxiv_categories": [
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Linearity Calibration File",
        "Updated Pixel",
        "Based Non",
        "Standard",
        "CRDS",
        "MAST",
        "Act",
        "MIT",
        "RMS",
        "HST",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.141827"
    },
    {
      "id": "arxiv-2602.12077v1",
      "title": "Cosmographic Connection Between Cosmological And Planck Scales: The Barrow-Tsallis Entropy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12077v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "One of the fundamental challenges of quantum gravity is to understand how the microscopic degrees of freedom of the cosmological horizon shape the evolution of the Universe. One possible approach to this problem is based on the Barrow--Tsallis entropy. This entropy accounts for both quantum gravitational effects and the nonextensive effects inherent in any long-range interaction. Using a general method we developed for finding the parameters of cosmological models, we discovered a relationship between the parameter describing the microscopic structure of quantum foam and the parameter associated with macroscopic nonextensive effects. We also used our method for finding the parameters of cosmological models to evaluate the feasibility of using fractional derivatives to describe the late evolution of the Universe. The resulting relationships are exact. Therefore, the uncertainty in the relationship between the model parameters depends only on the current uncertainty in the values of the cosmographic parameters.",
        "keywords": [
          "gr-qc",
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12077v1",
        "authors": [
          "Yu. L. Bolotin",
          "V. V. Yanovsky",
          "D. A. Yerokhin"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cosmographic Connection Between Cosmological",
        "Tsallis Entropy One",
        "And Planck Scales",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.142135"
    },
    {
      "id": "arxiv-2602.12071v1",
      "title": "Thermal and Dielectric Properties of Juno's Regolith at One Millimeter Wavelength",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12071v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present the modeling results of the thermal lightcurve of asteroid (3) Juno at the wavelength of $λ$ = 1.3 mm measured by the Atacama Large Millimeter-submillimeter Array. A thermophysical model together with a radiative transfer model suggest a thermal inertia of 13$\\pm$10 [J m$^{-2}$ K$^{-1}$ s$^{-0.5}$], an equivalent emissivity of 0.8$\\pm$0.1, a loss tangent of 0.4$\\pm$0.3, and an index of refraction 1.8$\\pm$0.3. Based on previous laboratory measurements, the modeled index of refraction suggests a regolith porosity of about 45%. However, thermal inertia models using the material parameters of ordinary chondrite indicate a grain size of 10s $μ$m and require a high porosity of $\\sim$90% to explain the low thermal inertia. In order to explain such a contradiction, we postulate that some repulsive mechanism might be in effect to reduce the contact of grains and therefore the thermal inertia. The loss tangent of Juno's regolith corrected for the modeled thermal skin depth is in the order of 0.5, much higher than that of the lunar regolith and indicating an electrical skin depth of L = 0.1 - 1.4 mm that is within the thermal skin depth. The shape of the rotational lightcurve of Juno in the mm wavelengths is dominated by its irregular shape, but rotational variations in the thermal and/or dielectric properties cannot be ruled out. Our results demonstrate that mm-wavelength observations of asteroids provide an extra dimension of constraints to the porosity and grain size of asteroid regolith compared to the thermal infrared observations.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12071v1",
        "authors": [
          "Jian-Yang Li",
          "Timothy N. Titus",
          "Arielle Moullet",
          "Henry H. Hsieh"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "One Millimeter Wavelength We",
        "Atacama Large Millimeter",
        "Dielectric Properties",
        "Laboratory",
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.143177"
    },
    {
      "id": "arxiv-2602.12060v1",
      "title": "The Outflow of the B335 Protostar II: After the Outburst",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12060v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The B335 protostar has undergone a major outburst detected in the scattered light of its outflow cavity that has not yet ended. B335 therefore offers the rare opportunity to study its effect on the jet of a protostellar object. Photometry of background stars behind B335 is used to map visual continuum extinction and H$_2$O ice absorption and demonstrates that the outflow has carved out a cavity. Precise proper motions of the shock fronts emerging from the B335 protostar were obtained. The kinematic age of the most prominent shock front (3E) corresponds to the early phases of the ongoing outburst of the B335 protostar. Shock 3E shows strong CO gas emission, as well as H$_2$ and [\\ion{Fe}{2}] emission. Older shock fronts show diminished CO emission and are dominated by H$_2$ and [\\ion{Fe}{2}]. The emission feature 0E, closest to the protostar, is distinct in proper motion and radial velocity from the other shock fronts in the jet. In the span of 4\\arcsec\\ closest to the protostar, the continuum extinction in front of the outflow cavity increases by A$_V$~$\\approx$~200 mag. The CO-line-removed spectra close to the protostar show the unsaturated absorption features of $^{13}$CO$_2$, OCN$^-$, and OCS have strongly increasing column densities toward the protostar. The ice characteristics are overall similar to those found in lines of sight with less extinction. The central regions of the bipolar nebula show CO gas emission, but at distances of a few arcsec from the protostar, absorption by CO gas is also detected.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12060v1",
        "authors": [
          "Klaus W. Hodapp",
          "Adwin Boogert",
          "Doug Johnstone",
          "Valentin J. M. Le Gouellec",
          "Eleni Tsiakaliari"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "OCN",
        "OCS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.143619"
    },
    {
      "id": "arxiv-2602.12051v1",
      "title": "The Interstellar Scintillation of the Radio-Loud Magnetar XTE J1810-197",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12051v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a comprehensive interstellar scintillation (ISS) study of the radio-loud magnetar XTE~J1810$-$197, based on six years of multi-frequency monitoring (2018$-$2024) with the Shanghai Tian Ma Radio Telescope (TMRT) at 7.0, 8.6, and 14.0~GHz. The scintillation parameters--decorrelation bandwidth $Δν_{\\rm d}$, decorrelation time $Δτ_{\\rm d}$, and drift rate $dt/dν$--are fully characterized. Our measured $Δτ_{\\rm d}$ implies $Δτ_{\\rm d} < 4$~s at 575-725~MHz under a Kolmogorov spectrum, which is shorter than the magnetar's 5.54~s spin period. This result naturally explains the previously reported absence of pulse-to-pulse coherence at these frequencies. Kinematic modeling locates the dominant scattering screen at $1.6\\pm0.1$~kpc away from the Earth, within the Sagittarius Arm. The screen coincides with the HII region JCMTSE~J180921.2$-$201932 and is unrelated to the magnetar's 2018 outburst suggested by earlier studies. A scintillation arc detected at 14.0~GHz represents the highest-frequency arc observed to date. The asymmetry of arcs is linearly correlated with a dispersion-measure gradient across the screen ($r = 0.959$, $p < 10^{-8}$). We also measure its refractive scintillation timescale, which is only $1.21\\pm0.19$~d. Clear DISS at 14~GHz effectively resolves the debate over a possible strong-to-weak scattering transition at this frequency. These results extend the ISS characterization of magnetars to previously unexplored frequencies and provide a precise probe of the ionized interstellar medium in the Sagittarius Arm.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12051v1",
        "authors": [
          "Rui Wang",
          "Zhen Yan",
          "Zhiqiang Shen",
          "Zhenlong Liao",
          "Zhipeng Huang"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Shanghai Tian Ma Radio",
        "Sagittarius Arm",
        "Loud Magnetar",
        "J1810-197",
        "JCMTSE",
        "TMRT",
        "DISS",
        "Act",
        "XTE",
        "ISS",
        "HII",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.144622"
    },
    {
      "id": "arxiv-2602.12019v1",
      "title": "Is cosmic birefringence due to dark energy or dark matter? Simulation-based inference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12019v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Simulation-based inference (SBI) is a powerful inference technique for cases where the exact functional form of the likelihood is not known. A prime example is the likelihood of cross-correlation power spectra of the cosmic microwave background (CMB) fields at low multipoles, $\\ell\\lesssim 10$. In this paper, we investigate a parity-violating cross-correlation between $E$- and $B$- mode polarization fields using SBI. The $EB$ correlation at low $\\ell$ is essential to distinguish between possible axion dark energy and dark matter interpretations of `cosmic birefringence', a rotation of the plane of linear polarization of the CMB, recently reported from WMAP, Planck, and Atacama Cosmology Telescope data. We use neural likelihood estimation to infer the likelihood of the $EB$ correlation at low $\\ell$ and show that it is highly non-Gaussian. We then employ neural posterior estimation to constrain the scalar field mass ($m_φ$), the cosmic birefringence amplitude ($gφ_\\mathrm{in}/2$), and the instrumental miscalibration angle ($α$), from simulated datasets. We find that the posterior on $m_φ$ shows two regimes, with a transition marked by $10^{-32}$ eV, highlighting a strong sensitivity to the scale dependence of cosmic birefringence. To quantify this behavior, we compute the probability $p(m_φ < 10^{-32}$\\,eV) for various fiducial values of $m_φ$. We find that $α$ and the contribution of lensed $B$ modes ultimately limit our ability to exclude the dark energy scenario fully.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12019v1",
        "authors": [
          "Florie Carralot",
          "Patricia Diego-Palazuelos",
          "Adriaan J. Duivenvoorden",
          "Eiichiro Komatsu",
          "Nicoletta Krachmalnicoff"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Atacama Cosmology Telescope",
        "WMAP",
        "Act",
        "MIT",
        "SBI",
        "CMB",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.145503"
    },
    {
      "id": "arxiv-2602.12017v1",
      "title": "Velocities of Free Floaters in a Sea of Stars",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12017v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the velocity evolution of free-floating planets and interstellar objects (``free floaters'') through gravitational scatterings by field stars (with the stellar mass $m$ much larger than the mass of the floater, $m_p$). We show that the equilibrium velocity -- where dynamical friction balances stochastic acceleration -- is given by $σ\\sqrt{2\\ln(m/m_p)}$ (where $σ$ is the velocity disperson of the field stars), diverging from the standard energy equipartition scaling. While the timescale to reach this equilibrium is prohibitively long, we find that slow floaters ($v \\lesssim σ$) undergo mass-independent acceleration, doubling their velocities within a few relaxation times. Consequently, free floaters initially following the Maxwellian distribution of their parent stars develop distinctly non-Maxwellian velocity distributions on a relaxation timescale. Since the relaxation time of the Galactic disk is longer than the age, our results suggest that the kinematics of low-mass free floaters in the disk may preserve signatures of their parent stars and ejection history.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12017v1",
        "authors": [
          "Jun Yan Lau",
          "Dong Lai"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Free Floaters",
        "Standard",
        "Stars We",
        "Act",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.146125"
    },
    {
      "id": "arxiv-2602.12011v1",
      "title": "pespace: A new tool of GPU-accelerated and auto-differentiable response generation and likelihood evaluation for space-borne gravitational wave detectors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12011v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Space-borne gravitational wave detectors will expand the scope of gravitational wave astronomy to the milli-Hertz band in the near future. The development of data analysis software infrastructure at the current stage is crucial. In this paper, we introduce \\texttt{pespace} which can be used for the full Bayesian parameter estimation of massive black hole binaries with detectors including LISA, Taiji, and Tianqin. The core computations are implemented using the high-performance parallel programming framework \\texttt{taichi-lang} which enables automatic differentiation and hardware acceleration across different architectures. We also reimplement the waveform models \\texttt{PhenomXAS} and \\texttt{PhenomXHM} in the separate package \\texttt{tiwave} to integrate waveform generation within the \\texttt{taichi-lang} scope, making the entire computation accelerated and differentiable. To demonstrate the functionality of the tool, we use a typical signal from a massive black hole binary to perform the full Bayesian parameter estimation with the complete likelihood function for three scenarios: including a single detector using the waveform with only the dominant mode; a single detector using the waveform including higher modes; and a detector network with higher modes included. The results demonstrate that higher modes are essential in breaking degeneracies, and coincident observations by the detector network can significantly improve the measurement of source properties. Additionally, automatic differentiation provides an accurate way to obtain the Fisher matrix without manual fine-tuning of the finite difference step size. Using a subset of extrinsic parameters, we show that the approximated posteriors obtained by the Fisher matrix agree well with those derived from Bayesian parameter estimation.",
        "keywords": [
          "gr-qc",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12011v1",
        "authors": [
          "Rui Niu",
          "Chang Feng",
          "Wen Zhao"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "LISA",
        "EPA",
        "GPU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.146566"
    },
    {
      "id": "arxiv-2602.11994v1",
      "title": "Surface brightness-colour relations of Milky Way and Magellanic Clouds classical Cepheids based on Gaia magnitudes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11994v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Aims: We derive SBCRs for classical Cepheids in the Milky Way and in the Magellanic Clouds using the photometric data available in the Gaia database, and we quantify the metallicity effect. Methods: We first selected the data on the basis of a number of quality criteria and chose the best photometric data and the best parallaxes available in Gaia for Milky Way classical Cepheids. Secondly, we compiled an extensive list of period-radius (PR) relations available in the literature, and we also provide a new PR relation based on interferometric data in our previous work. Thirdly, combining the radius of classical Cepheids with distance estimates (based on Gaia parallaxes for the Milky Way and on eclipsing binaries for the Magellanic Clouds), we derived the surface brightness and colour of about 1700 classical Cepheids. Results: We first derived a new PR relation based on interferometric data and distances from the literature of seven classical Cepheids: $\\mathrm{\\log(R/R_{\\odot}) = 1.133_{\\pm 0.019} + 0.688_{\\pm 0.016} log(P)}$. The metallicity does not affect the PR relations. Secondly, we calculated three different SBCRs for the Milky Way and Large and Small Magellanic Cloud classical Cepheids based on this new PR relation that clearly show the dependence of the metallicity on the SBCR based on Gaia magnitudes alone. Finally, we derived relations between the slopes, the zero points (ZP), and the metallicity ([Fe/H]) of these three SBCRs: $\\mathrm{Slope_{SBCR}=-0.0663_{\\pm 0.0121} [Fe/H] - 0.3010_{\\pm 0.0030}}$ and $\\mathrm{ZP_{SBCR}=-0.1016_{\\pm 0.0091} [Fe/H] + 3.9988_{\\pm 0.0029}}$. Conclusions: These new SBCRs, dedicated to classical Cepheids in the Milky Way and Magellanic Clouds, are of particular importance to apply the inverse Baade-Wesselink method to classical Cepheids observed by Gaia in a forthcoming study.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11994v1",
        "authors": [
          "M. C. Bailleul",
          "N. Nardetto",
          "V. Hocdé",
          "P. Kervella",
          "W. Gieren"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Small Magellanic Cloud",
        "Magellanic Clouds",
        "Milky Way",
        "SBCR",
        "Meta",
        "DOE",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.147038"
    },
    {
      "id": "arxiv-2602.11989v1",
      "title": "Simulation-Based Cosmological Mass Calibration of XXL Galaxy Clusters using HSC Weak Lensing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11989v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present a cosmological analysis of the X-ray-selected galaxy cluster sample from the XXL survey, employing a simulation-based inference (SBI) framework to jointly constrain cosmological parameters and X-ray scaling relations through forward modeling of cluster counts, X-ray observables, and weak-lensing measurements. Our analysis combines X-ray data from the XMM-XXL survey with shear measurements from the three-year shape catalog of the Hyper Suprime-Cam Subaru Strategic Program. The analysis focuses on the XXL C1 sample, comprising 171 clusters for abundance modeling, a subset of 86 clusters located within the XXL-N region for lensing-based mass calibration, and 162 clusters with X-ray temperature and luminosity measurements used to constrain scaling relations. Using the density-estimation likelihood-free inference (DELFI) algorithm, we construct a forward model with 12 parameters that incorporates the XXL selection function and cluster population modeling and accounts for key systematic effects including cluster miscentering, photometric redshift bias, and mass-dependent weak-lensing bias. Our SBI analysis yields a constraint on the cosmological parameter $S_8 \\equiv σ_8 (Ω_{m}/0.3)^{0.5} = 0.867 \\pm 0.063$, with an additional 3% systematic uncertainty from neural network stochasticity. The result is consistent with Planck and recent cluster-based measurements. The inferred temperature-mass relation is consistent with self-similar expectations within uncertainties, whereas the luminosity-temperature relation exhibits a slope steeper than the self-similar prediction. From the resulting posterior distribution of the forward model, we derive lensing-calibrated mass estimates for all individual XXL clusters with measured X-ray temperatures or luminosities. These results provide a self-consistent mass calibration for future multi-probe cosmological analyses of the XXL sample.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11989v1",
        "authors": [
          "Sut-Ieng Tam",
          "Keiichi Umetsu",
          "Adam Amara",
          "Dominique Eckert",
          "Manon Regamey"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Cosmological Mass Calibration",
        "Cam Subaru Strategic Program",
        "Galaxy Clusters",
        "Weak Lensing We",
        "Neural Network",
        "Hyper Suprime",
        "Framework",
        "DELFI",
        "XMM",
        "SBI",
        "XXL",
        "HSC",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.148097"
    },
    {
      "id": "arxiv-2602.11936v1",
      "title": "Probing Dynamical Dark Energy with Late-Time Data: Evidence, Tensions, and the Limits of the $w_0w_a$CDM Framework",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11936v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We test the dynamical dark-energy $w_0w_a$CDM (CPL) framework against $Λ$CDM using CMB anisotropies and lensing together with late-time distance probes: DESI DR2 BAO, the completed SDSS-IV BAO consensus compilation, a transverse/angular BAO compilation (BAOtr), and the Cepheid-calibrated PantheonPlus SN~Ia likelihood (PP\\&SH0ES). We find that CPL inferences are strongly dataset-dependent. With CMB data alone, the broad geometric degeneracy in $(H_0,Ω_{\\rm m},w_0,w_a)$ admits an extrapolation tail that can extend to $q_0<-1$ (super-acceleration), whereas adding DESI DR2 BAO pulls the reconstruction toward a weakly accelerating or nearly coasting present-day Universe ($q_0\\simeq 0$). In contrast, combining CMB with PP\\&SH0ES and BAOtr yields a conventional moderately accelerating expansion ($-1<q_0\\lesssim 0$) and substantially reduces the Hubble tension. Across all combinations, $w(z\\to\\infty)=w_0+w_a<-1$, while at post-recombination redshifts the expansion remains matter dominated ($q\\to1/2$). The origin of this behavior can be traced to low-redshift distance information: BAOtr and DESI prefer different BAO distance ratios at $z\\lesssim 0.5$, which propagates into divergent expansion histories in CPL. In all cases, $r_{\\rm d}$ stays nearly unchanged, indicating that shifts in $H_0$ arise from late-time expansion freedom rather than early-Universe physics. Bayesian evidence mirrors this contingency: it is strong for CPL mainly when PP\\&SH0ES and/or BAOtr are included, while it is inconclusive for CMB-only and CMB+DESI and moderately favors $Λ$CDM for CMB+SDSS. Overall, our results show that the apparent support for CPL and its ability to ease the Hubble tension are not universal but depend sensitively on the adopted low-redshift distance data, motivating either more flexible late-time models or closer scrutiny of residual systematics in current BAO determinations.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11936v1",
        "authors": [
          "Tengpeng Xu",
          "Suresh Kumar",
          "Yun Chen",
          "Abraão J. S. Capistrano",
          "Özgür Akarsu"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Probing Dynamical Dark Energy",
        "Framework We",
        "Framework",
        "Time Data",
        "SDSS",
        "DESI",
        "MIT",
        "BAO",
        "CDM",
        "CPL",
        "CMB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.149144"
    },
    {
      "id": "arxiv-2602.11923v1",
      "title": "The Radius Cliff is a Waterfall: Explaining Sub-Neptune Exoplanets with Steam Worlds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11923v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The demographics of Kepler planets provide a key testbed for models of planet formation and evolution, particularly for explaining the radius valley separating super-Earths and sub-Neptunes. A primordial interpretation based on differences in bulk densities -- where rocky and water-rich planets form via migration pathways -- offers an alternative to atmospheric loss scenarios. Updated interior structure models of water worlds with adiabatic steam atmospheres reproduce the observed valley near $\\sim2~R_\\oplus$ more accurately. Furthermore, migration models from our Genesis library suggest that these formation pathways can also account for the distinct period distributions of super-Earths and sub-Neptunes, as well as the emergence of the hot Neptune desert. Motivated by this, we develop a Bayesian hierarchical mixture model for close-in Kepler planets ($P<100$ days), combining rocky planets and water worlds without H/He envelopes. The inferred mass distributions of rocky and water-rich planets peak at $\\sim2.6~M_\\oplus$ and $\\sim7~M_\\oplus$, respectively, with the water mass fraction of water worlds peaking at $\\sim41\\%$. Water worlds provide a good representation of the Kepler sub-Neptune population, with the radius cliff emerging as a ``waterfall\" -- a sharp decline in their occurrence. However, our mass-radius analysis shows that water worlds alone cannot explain planets with $R \\gtrsim 3~R_\\oplus$, implying that at least $\\sim20\\%$ of sub-Neptunes in the sample are enriched in H/He gas.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11923v1",
        "authors": [
          "Aritra Chakrabarty",
          "Gijs D. Mulders",
          "Artyom Aguichine",
          "Natalie Batalha"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.SR"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Neptune Exoplanets",
        "Explaining Sub",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.149511"
    },
    {
      "id": "arxiv-2602.11876v1",
      "title": "Spectro-timing origin of large amplitude X-ray variability in GRS 1915+105 using AstroSat/LAXPC and SXT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11876v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The origin of the large-amplitude, quasi-periodic X-ray flux variations in several classes of the Galactic microquasar GRS~1915+105 remains unresolved. We address this issue through flux-resolved, broadband (0.8-20 keV) spectral modelling and simultaneous covariance spectral analysis during two $κ$ and two $ω$ class observations using \\textit{AstroSat}/SXT and LAXPC. The lightcurves show strong, quasi-periodic oscillations involving rapid transitions between bright bursts and deep dips on timescales of a few tens of seconds. Flux-resolved spectroscopy indicates that high-flux intervals in both classes are dominated by a hot, optically thick accretion disc with steep Comptonized emission, whereas low-flux intervals correspond to a cooler or partially recessed disc and a harder coronal continuum. These transitions involve a systematic 1-2 keV drop in disc temperature and a pronounced hardening of the Comptonized component, with flux reductions of up to a factor of five. Using covariance spectra across 0.015-5 Hz, we show that the rapid coherent variability arises almost entirely from the disc, which exhibits strong energy-dependent variations, while the Comptonized component contributes minimally. The combined results suggest that radiation-pressure-driven structural changes in the disc, with a slower coronal response, produce the observed oscillations, consistent with cyclic disc evacuation and refilling in the $κ$ and $ω$ classes.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11876v1",
        "authors": [
          "Shree Suman",
          "Shuvajit Khatua",
          "Vishal Jadoliya",
          "Prathamesh Narayan Gupta",
          "Mayukh Pahari"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "LAXPC",
        "Act",
        "SXT",
        "GRS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.150394"
    },
    {
      "id": "arxiv-2602.11864v1",
      "title": "Selecting Optimal Stellar Calibration Fields for the CSST Imaging Survey",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11864v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The Chinese Space Station Survey Telescope (CSST) will perform a decade-long high-precision wide-field imaging survey that relies on rigorous on-orbit calibration. This necessitates stable celestial benchmark fields to maintain photometric and astrometric consistency throughout the mission lifetime. We establish comprehensive selection criteria including observational visibility, stellar number density, bright-star contamination, and interstellar dust extinction. Using the CSST Observation Strategy Analysis Tool (COSAT) and all-sky dust maps from Planck and SFD, we constrain eligible regions to the ranges of ecliptic latitude $ |β| > 50^\\circ$ and galactic latitude $|b| > 15^\\circ$. From an initial sample of 29 candidate clusters meeting these spatial constraints, six globular clusters (M13, M92, NGC 104, NGC 362, NGC 1261, and NGC 1851) are identified as optimal calibration fields, fulfilling all the critical criteria. These selected clusters are recommended as optimal calibration field candidates for CSST's on-orbit calibration program, and are fundamental to achieving unprecedented photometric precision in CSST's space-based survey.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11864v1",
        "authors": [
          "Chenxiaoji Ling",
          "Juanjuan Ren",
          "Li Shao",
          "Zhimin Zhou",
          "Peng Wei"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA",
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Selecting Optimal Stellar Calibration",
        "Observation Strategy Analysis Tool",
        "Space Station Survey Telescope",
        "COSAT",
        "CSST",
        "Act",
        "SFD",
        "NGC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.151089"
    },
    {
      "id": "arxiv-2602.11853v1",
      "title": "Three-dimensional mapping of coronal magnetic field and plasma parameters in a solar flare",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11853v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Diagnosing solar flare conditions is essential for understanding coronal energy release. Using combined microwave and X-ray data, we reconstruct three-dimensional maps of the magnetic field and plasma parameters in the SOL2021-05-07 flare. We use imaging spectroscopy from the Expanded Owens Valley Solar Array (EOVSA) to derive spatial maps of the magnetic field strength, thermal and nonthermal electron densities, and the power-law index of nonthermal electrons through gyrosynchrotron modeling. Simultaneous X-ray observations from Hinode/XRT and Solar Orbiter/STIX, obtained from different vantage points, enable a stereoscopic reconstruction of the flaring loop. By correlating the positions of microwave and thermal X-ray sources, we associate the three-dimensional coordinates with the microwave-derived plasma parameters. We derive observational three-dimensional maps of magnetic field strength, Alfvén speed, and plasma beta in the flaring volume, revealing a magnetically dominated environment. These spatially resolved diagnostics provide valuable constraints for models of magnetic reconnection and flare dynamics and represent a step toward a realistic three-dimensional characterization of energy release in solar eruptive events.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11853v1",
        "authors": [
          "Tatyana Kaltman",
          "Sijie Yu",
          "Gregory D. Fleishman",
          "Daniel F. Ryan"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Expanded Owens Valley Solar",
        "Solar Orbiter",
        "SOL2021-05",
        "Solar",
        "EOVSA",
        "STIX",
        "Act",
        "XRT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.151710"
    },
    {
      "id": "arxiv-2602.11838v1",
      "title": "NE2025: An Updated Electron Density Model for the Galactic Interstellar Medium",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11838v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Free electrons in the Galactic interstellar medium (ISM) disperse and scatter coherent radio waves, by amounts that depend on the distance to the radio source. Models of the Galactic electron density are thus widely used to predict distances and scattering of compact radio sources (including pulsars, fast radio bursts (FRBs), and long-period transients), in addition to mitigating ISM foregrounds in Galactic and extragalactic studies. We use a sample of 171 precise pulsar distances, based entirely on parallaxes and globular cluster associations, as well as scattering measurements of 568 pulsars, active galactic nuclei, and masers, to update the NE2001 Galactic electron density model. We refit the thick and thin disks and three of the spiral arms. The new parameters for these large-scale components significantly repartition free electrons between the thick disk and spiral arms, thereby correcting NE2001's systematic underestimation of pulsar distance and scattering. Sightlines with excessive dispersion and scattering are used to identify new clumps that are added to the model, in addition to refining clumps that were already included (e.g., Cygnus, Vela, and Gum). The Galactic Center component is revised, yielding scattering time predictions that are $10^3$ times smaller than the Galactic Center in NE2001. The updated model, NE2025, provides a factor of $20\\times$ improvement in median distance prediction accuracy and $100\\%$ median improvement in scattering predictions based on DM, relative to NE2001. There is a $15\\times$ improvement in median distance prediction accuracy relative to YMW16. NE2025 is available on Github and the Python Package Interface.",
        "keywords": [
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11838v1",
        "authors": [
          "S. K. Ocker",
          "J. M. Cordes"
        ],
        "arxiv_categories": [
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Galactic Interstellar Medium Free",
        "An Updated Electron Density",
        "Python Package Interface",
        "Galactic Center",
        "Act",
        "EPA",
        "MIT",
        "ISM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.152157"
    },
    {
      "id": "arxiv-2602.11818v1",
      "title": "Global magnetohydrodynamic simulations of the inner regions of protoplanetary discs. II. Vertical-net-flux regime",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11818v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The inner regions of protoplanetary discs, which encompass the putative habitable zone, are dynamically complex, featuring a relatively well-ionised, turbulent active zone located interior to a poorly ionised 'dead' zone. In this second paper, we investigate a model of the magnetohydrodynamic processes around the interface between these two regions, using five three-dimensional global magnetohydrodynamic simulations of discs threaded by a large-scale poloidal-net-flux magnetic field. We employ physically motivated profiles for Ohmic resistivity and ambipolar diffusion, alongside a simplified thermodynamic model comprising a cool disc and hot corona. Our results show that, first, the interface acts as a one-way barrier to inward transport of large-scale magnetic flux from the dead zone. This leads to magnetic flux depletion throughout most of the active zone, whereby it either advects inwards to the inner numerical boundary or accumulates just inside the interface. Second, two sources of strong variability emerge from the interface due to the difficulty of maintaining a constant, vertically integrated electrical current across distinct and evolving magnetic-field states. Third, despite the weak magnetothermal wind in the dead zone, a pressure maximum forms at the interface, leading to Rossby-wave-induced vortices. Fourth, unlike the model of Iwasaki et. al (2024), there is no 'transition zone' devoid of magnetic flux and magnetic winds. Instead, multiple outflow zones span all disc radii reflecting the radially varying launch conditions, with an inner turbulent wind impinging upon an outer, more laminar one. Fifth, a heated corona prevents the 'puffing up' of poloidal-net-flux, active disc regions.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11818v1",
        "authors": [
          "Matthew J. O. Roberts",
          "Henrik N. Latter",
          "Geoffroy Lesur"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Fusion",
        "Wind",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.152566"
    },
    {
      "id": "arxiv-2602.11809v1",
      "title": "Impact of crust-core connection procedures on the tidal deformability of neutron stars",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11809v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the impact of crust-core connection procedures on various neutron-star properties, especially on the tidal deformability. We consider three types of connection procedures to treat the discontinuity in a nonunified equation of state around the crust-core transition: (1) the direct connection procedure, (2) the crossover connection procedure, and (3) the segmented method. Our results indicate that the mass-radius relations of neutron stars are almost unaffected by the details of the connection procedure. However, the tidal deformabilities of neutron stars are sensitive to the crust-core connection procedures. The tidal deformability is closely related to gravitational-wave measurements. For a canonical 1.4$M_\\odot$ neutron star, uncertainties in the tidal deformability $Λ_{1.4}$ from different connection procedures can exceed 20\\%. We find that the direct connection procedure yields significantly larger uncertainties in the tidal deformability, while the segmented method and crossover connection procedure provide relatively stable results.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11809v1",
        "authors": [
          "Junbo Pang",
          "Hong Shen",
          "Jinniu Hu"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.153181"
    },
    {
      "id": "arxiv-2602.11806v1",
      "title": "GR from RG: Gravity Is Induced From Renormalization Group Flow In The Infrared",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11806v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this essay and utilizing the holographic Renormalization Group (RG) flow, we demonstrate how the effective action of a non-gravitating quantum field theory in the ultraviolet (UV) develops an Einstein-Hilbert term in the infrared (IR). That is, gravity is induced by the RG flow. An inherent outcome of holography that plays a crucial role in our analysis is the \\textit{RG flow of boundary conditions}: the rigid Dirichlet conditions on the background metric in the UV become an admixture of Dirichlet and Neumann as we flow to the IR, thereby ``unfreezing'' the metric and transforming it from a non-dynamical background into a dynamical field. This mechanism, which is a conceptually new addition to the standard Wilsonian RG flow, also provides the mechanism to evade the Weinberg-Witten no-go theorem. Within the GR from RG picture outlined here, the search for a quantum theory of gravity by treating the metric as a fundamental field may be a hunt for a phantom -- akin to seeking the atomic structure of water by quantizing the equations of hydrodynamics.",
        "keywords": [
          "hep-th",
          "astro-ph.CO",
          "gr-qc",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11806v1",
        "authors": [
          "M. M. Sheikh-Jabbari",
          "V. Taghiloo"
        ],
        "arxiv_categories": [
          "hep-th",
          "astro-ph.CO",
          "gr-qc",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Renormalization Group Flow In",
        "Gravity Is Induced From",
        "Renormalization Group",
        "Standard",
        "BERT",
        "Act",
        "NSF",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.153467"
    },
    {
      "id": "arxiv-2602.11783v1",
      "title": "Characterising Ly$α$ damping wings at the onset of reionisation: Evidence for highly efficient star formation driven by dense, neutral gas in UV-bright galaxies at $z>9$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11783v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "One of the major conundrums in contemporary extragalactic astrophysics is the apparent overabundance of a remarkable population of UV-bright galaxies at redshifts $z\\gtrsim 9$. We analyse galaxies spectroscopically observed by JWST/NIRSpec Prism and confirmed to lie at $z>9$, with sufficient signal-to-noise to carefully model their rest-frame UV to optical continua and line emission. In particular, we model the damped Lyman-$α$ (Ly$α$) absorption (DLA) features of each galaxy to place observational constraints on the gas assembly of neutral atomic hydrogen (HI) onto the galaxy halos at the onset of cosmic reionisation. Based on the derived HI column densities and star-formation rate (SFR) surface densities, we show that all galaxies are highly efficient at forming stars on rapid $\\sim 10-100\\,$Myr depletion timescales, greatly in excess compared to the canonical local universe Kennicutt-Schmidt relation and predictions from state-of-the-art galaxy formation simulations. The dense HI gas appears to also drive the offset from the fundamental-metallicity relation of these galaxies though its dust-to-gas ratio is seemingly consistent with values derived for local galaxies except for the lowest metallicity sight-lines. Our results provide the first robust observational constraints on the impact of pristine HI gas on early galaxy assembly, and imply that a combination of highly efficient star formation and low dust obscuration can likely explain the UV-brightness of galaxies at cosmic dawn.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11783v1",
        "authors": [
          "Clara L. Pollock",
          "Kasper E. Heintz",
          "Joris Witstok",
          "Rashmi Gottumukkala",
          "Gabriel Brammer"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Characterising Ly",
        "Hydrogen",
        "Meta",
        "JWST",
        "Act",
        "DLA",
        "SFR",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.154303"
    },
    {
      "id": "arxiv-2602.11765v1",
      "title": "Population synthesis predictions of the Galactic compact binary gravitational wave foreground detectable by LISA",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11765v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We use population synthesis modelling to predict the gravitational wave (GW) signal that the Laser Interferometer Space Antenna (LISA) will detect from the Galactic population of compact binary systems. We implement a realistic star formation history with time and position-dependent metallicity, and account for the effect of supernova kicks on present-day positions. We consider all binaries that have a white dwarf (WD), neutron star (NS), or black hole primary in the present-day. We predict that the summed GW signal from all Galactic binaries will already be detectable 3 months into the LISA mission, by measuring the power spectrum of the total GW strain. We provide a simple publicly available code to calculate such a power spectrum from a user-defined binary population. In the full 4 year baseline mission lifetime, we conservatively predict that $>2000$ binaries could be individually detectable as GW sources. We vary the assumed common envelope (CE) efficiency $α$, and find that it influences both the shape of the power spectrum and the relative number of detectable systems with WD and NS progenitors. In particular, the ratio of individually detectable binaries with chirp mass $\\mathcal{M} < M_\\odot$ to those with $\\mathcal{M} \\geqslant M_\\odot$ increases with $α$. We therefore conclude that LISA may be able to diagnose the CE efficiency, which is currently poorly constrained.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11765v1",
        "authors": [
          "Jake McMillan",
          "Adam Ingram",
          "Cordelia Dashwood Brown",
          "Andrei Igoshev",
          "Matthew Middleton"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Laser Interferometer Space Antenna",
        "LISA",
        "Meta",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.155029"
    },
    {
      "id": "arxiv-2602.11751v1",
      "title": "Evolution of submillimeter galaxies across cosmic-web environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11751v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Submillimeter galaxies (SMGs) provide valuable insights into galaxy formation and evolution and are likely influenced by their cosmic environment. However, their rarity makes environmental trends difficult to establish. We use the FLAMINGO simulation, which simultaneously reproduces the redshift distribution and number counts of SMGs. We use the DisPerSE to identify filamentary structures at $z=4$, 3, 2, 1.5, and 1. We define inner cluster-halo, outer cluster-halo, inner filament, outer filament, and void/wall environments at each redshift considering mass evolution of cluster-halos and density evolution of filaments. For a fixed stellar-mass cut of $M_* \\geq 10^{9}$ M$_{\\odot}$, the fraction of SMGs in the inner cluster-halo environment declines from $\\sim30\\%$ at $z=4$ to $\\sim3\\%$ by $z=1$, and similar trends are observed in other environments. The abundance of SMGs within a cluster-halo increases with halo mass, mirroring the increase in the total galaxy population. Consequently, the ratio of SMG halo occupation to that of all galaxies is largely insensitive to halo mass, but varies with redshift. In contrast, the ratio of the halo occupation of non-SMGs to that of all galaxies declines with halo mass and shows little redshift evolution. We show that the central and satellite SMGs form two distinct populations in inner cluster-halos. SMGs occupy the metal-rich side of the metallicity distribution, but rarely attain the highest metallicities because ongoing enrichment is limited by gas depletion. The brightest SMGs (S$_{850} > 10$ mJy) are found exclusively in inner cluster-halos, highlighting a strong connection between SMG luminosity and environmental density. Our results show that SMGs dominate star formation in dense environments, contributing up to $80\\%$ of the SFR in inner cluster-halos at $z=4$, but less than $50\\%$ in low-density regions.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11751v1",
        "authors": [
          "Ankit Kumar",
          "M. Celeste Artale",
          "Antonio D. Montero-Dorta",
          "Lucia Guaita",
          "Joop Schaye"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite",
        "Meta",
        "Act",
        "MIT",
        "SFR",
        "SMG",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.155443"
    },
    {
      "id": "arxiv-2602.11736v1",
      "title": "Subaru High-$z$ Exploration of Low-Luminosity Quasars (SHELLQs). XXV. Large-scale environments of low-luminosity quasars at $z\\sim6$ traced by Ly$α$ emitters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11736v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-$z$ quasars are believed to reside in massive dark matter haloes (DMHs), suggesting that they reside in galaxy overdense regions. However, previous observations have shown a range of environments around them. The previous targets are limited to bright quasars ($M_{1450}\\lesssim-25$), for which photoevaporation may hinder galaxy formation in their vicinity. Here, we present Subaru/Hyper-Suprime Cam observations of the environments of four low-luminosity quasars ($-24<M_{1450}<-22$) at $z\\sim6.18$, which are expected to have a smaller photoevaporation effect. We detect Lyman $α$ emitters (LAEs) around them with narrowband NB872 imaging, and measure the local LAE overdensity. One quasar (J0844$-$0132) resides in an overdense region ($δ_\\mathrm{LAE}=3.77\\pm0.97$), whereas the other three fields are consistent with normal fields. The result is confirmed over the proximity zone of each quasar, suggesting that the diverse environment around quasars is independent of photoevaporation. We find no significant correlation between the LAE overdensities and the properties of host galaxies and supermassive black holes. Our quasars have host stellar mass measurements from JWST, allowing us to compare them with the LAE overdensity around galaxies without quasar activity with comparable stellar masses. We find that the LAE overdensity in the J0844$-$0132 field is stronger than that of galaxies with similar stellar mass at $z\\sim6$, while the other quasar fields show a comparable LAE overdensity.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11736v1",
        "authors": [
          "Junya Arita",
          "Nobunari Kashikawa",
          "Yoshiki Matsuoka",
          "Masafusa Onoue",
          "Michael A. Strauss"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Luminosity Quasars",
        "Suprime Cam",
        "Subaru High",
        "JWST",
        "LAE",
        "Act",
        "MIT",
        "XXV",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.156280"
    },
    {
      "id": "arxiv-2602.11681v1",
      "title": "The faint end of the UV luminosity function at $0.4 < z < 0.7$ from the Hubble Frontier Fields",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11681v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "By extending the Hubble Frontier Fields (HFF) observations to the F225W band using HST WFC3/UVIS, we measure the rest-frame UV luminosity function (LF) of galaxies at $0.4 < z < 0.7$, pushing into the low-luminosity galaxy regime. In this first paper of a series, we describe the HST Cycle-27 GO-15940 F225W observations and data reduction, and present a corresponding catalog for the Abell 2744 field, which is the most data-rich HFF cluster field. Combining deep Near-UV imaging and the high magnification from strong gravitational lensing of the foreground cluster, we identify 152 faint galaxies with $-19.5 < M_{UV} < -12.1$ at $0.4 < z < 0.7$ through hybrid photometric-spectroscopic redshift selection from the Abell 2744 F225W catalog. Using a sample defined by a $50\\%$ completeness cut and applying the maximum likelihood estimation, we derive the best-fit Schechter parameters for the UV LF at $z \\sim 0.55$ down to $M_\\text{UV} < -13.5$ mag, including a faint-end slope of $α= -1.324^{+0.072}_{-0.074}$. We incorporate a curvature parameter $δ$ in parameter estimation to account for a possible turn-over at the faint end of the UV LF, leveraging the exceedingly low luminosities probed by our sample. Our results rule out a turn-over brighter than $M_{UV} = -15.5$ at the $3σ$ confidence level.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11681v1",
        "authors": [
          "Lei Sun",
          "Xiao-Lei Meng",
          "Xin Wang",
          "Hu Zhan",
          "Anahita Alavi"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hubble Frontier Fields By",
        "Hubble Frontier Fields",
        "GO-15940",
        "Cycle-27",
        "UVIS",
        "HST",
        "HFF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.157014"
    },
    {
      "id": "arxiv-2602.11652v1",
      "title": "Numerical simulation of the stochastic formalism including non-Markovianity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11652v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We numerically investigate stochastic dynamics in cosmology by solving Langevin equations for Infrared (IR) modes with stochastic noises generated by Ultraviolet (UV) modes at the coarse-graining scale. By construction, the stochastic formalism relies on the separation of scales, which requires solving the equations for UV modes on top of the evolving IR modes for all modes at every time step, leading to a non-Markovian system in general. In this paper, working on a de Sitter background, we analyze several representative models by simultaneously solving the Langevin equations for IR modes and the equations for UV modes at each time step. We demonstrate that once the effects of effective masses are treated consistently by our simulation, the flat direction in the minimal supersymmtric model (MSSM) does not saturate but instead evolves as an exactly flat direction. Furthermore, we investigate memory effects in simple two models; $V=λφ^4$ and $V=μφχ+ λφ^4$, and non-Markovian contributions can lead to quantitative differences, even in stationary configurations, when compared with Markovian approximations, particularly in the strong-coupling regime.",
        "keywords": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11652v1",
        "authors": [
          "Masahiro Kawasaki",
          "Tomotaka Kuroda"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Markovianity We",
        "MSSM",
        "Act",
        "EPA",
        "DOE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.157613"
    },
    {
      "id": "arxiv-2602.11649v1",
      "title": "Dynamic modeling of coronal abundances during flares on M-dwarf stars",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11649v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Solar atmospheric elemental abundances are now known to vary both in space and time. Dynamic modeling of these changes is therefore necessary to improve the accuracy of radiative hydrodynamic simulations. Recent studies have shown that including spatio-temporal variations in coronal abundances during solar flares leads to the formation of coronal condensations (rain), which are otherwise difficult to create in impulsively heated field aligned hydrodynamic flare models. These simulations start with a solar corona dominated by the first ionization potential (FIP) effect, and evaporate photospheric material into the post-flare loops. We here explore perhaps the most extreme non-solar starting condition for the coronal composition in these simulations: an initial corona dominated by the inverse FIP (iFIP) effect, such as is observed on active M-dwarf stars. We show that a flaring event in a corona enriched with high FIP elements leads to a solution similar to the solar case. Coronal rain is harder to form by this method during flares on M-dwarfs, however, if the corona is depleted of low FIP elements.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11649v1",
        "authors": [
          "David H. Brooks",
          "Jeffrey W. Reep",
          "Andy S. H. To",
          "Luke Fushimi Benavitz",
          "Lucas A. Tarr"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Solar",
        "Act",
        "FIP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.157871"
    },
    {
      "id": "arxiv-2602.11644v1",
      "title": "A Multiwavelength Evaluation of AGN in the Post-Starburst Phase",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11644v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The quenching of star formation is a crucial phase in galaxy evolution. Although active galactic nuclei (AGN) feedback has been proposed as a key driver of this transition, the lack of strong AGN in nearby quenching galaxies raises questions about its effectiveness. In this study, we investigate AGN activity in post-starburst galaxies (PSBs), star-forming galaxies (SFGs), and quiescent galaxies (QGs) at $z<$ 0.2, using multiwavelength data from eROSITA/eFEDS (X-ray), WISE (mid-infrared), and FIRST (radio). We assess AGN incidence and strength across different stages and apply stacking techniques to undetected galaxies to recover average AGN properties. Comparisons between observed luminosity and that expected from star formation (L$_{\\rm obs}$/L$_{\\rm SF}$) show that PSBs are consistent with star formation dominating their radio and X-ray emission. Although PSBs exhibit a MIR AGN incidence rate twice that of SFGs, their estimated AGN luminosities are small compared to those of MIR AGN in the literature. PSBs overall do not display significantly enhanced AGN emission relative to mass- and redshift-matched SFGs and QGs. While the presence of obscured, low-luminosity AGN in PSBs cannot be excluded, such AGN, if present, could be fueled by residual gas from the preceding starburst and may not play a dominant role in quenching. Our findings suggest that AGN's role in quenching at low redshift is more subtle than violently removing the gas -- the feedback is likely more \"preventive\" than \"ejective\".",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11644v1",
        "authors": [
          "Yuanze Luo",
          "Kate Rowlands",
          "Katherine Alatalo",
          "Lauranne Lanz",
          "Timothy Heckman"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multiwavelength Evaluation",
        "FIRST",
        "WISE",
        "Act",
        "AGN",
        "MIR",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.158194"
    },
    {
      "id": "arxiv-2602.11624v1",
      "title": "Understanding coronal geometry in NGC 4593 using Fourier frequency-resolved covariance and time-lag spectral analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11624v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Understanding disc-corona geometry through X-ray reverberation variability studies in Seyfert galaxies is crucial, yet our knowledge mostly relies on flux-averaged mean spectral analysis. In this study, we investigate the origin of the large X-ray variability of the Seyfert 1 galaxy NGC 4593 using two \\xmm{} observations, which are at least 65 ksec long and have a 0.3-10 keV X-ray flux difference by a factor of $\\sim$2.5. We extracted mean spectra, Fourier-frequency resolved covariance, and time-lag spectra and performed modelling of all spectra in a self-consistent manner. From the best-fit covariance spectra, we have shown that energy-dependent covariance during low flux shows dominances of direct powerlaw continuum over reflection continuum at all Fourier frequencies (2.1 $-$ 390 $\\times$ 10$^{-5}$ Hz). However, during high flux, the variabilities are dominated by the reflection components most of the time. Our results are further supported by the Fourier frequency-dependent time-lag (between soft: 0.3-1 keV and hard: 1-5 keV bands) spectral modeling during high and low fluxes. A significant change is observed in the X-ray reverberation delay timescale from 483 $\\pm$ 135 sec (during high flux) to $<$96 sec (during low flux), indicating a change in coronal size at least by a factor of $\\sim$2 (from $<$3.3 R$_g$ to $>$7.2 R$_g$) during low to high flux transitions.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11624v1",
        "authors": [
          "Shree Suman",
          "Mayukh Pahari",
          "Gulab Dewangan",
          "Ian M McHardy"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "NGC",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.158484"
    },
    {
      "id": "arxiv-2602.11620v1",
      "title": "Design and characterization of W-band and D-band calibration sources for the AliCPT-1 experiment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11620v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Ali Cosmic Microwave Background Polarization Telescope (AliCPT-1) is the first Chinese cosmic microwave background experiment aiming to make sensitive polarization maps of the potential B-mode signal from inflationary gravitational waves. The telescope was deployed on the Tibet Ali site at 5250 m above sea level in early 2025. Before and after each observation season, the instrument performance must be carefully calibrated, including the far field beam performance, far sidelobe, spectral response, polarization angle, and cross-polar beam response. To characterize these optical performances, several calibrators have been developed. We developed a W-band source and a D-band source for the AliCPT-1 telescope's beam characterizations. We present the design and performance of the two calibration sources.",
        "keywords": [
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11620v1",
        "authors": [
          "Xu-Fang Li",
          "Cong-Zhan Liu",
          "Ai-Mei Zhang",
          "Zheng-Wei Li",
          "Xue-Feng Lu"
        ],
        "arxiv_categories": [
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ali Cosmic Microwave Background",
        "Polarization Telescope",
        "Tibet Ali",
        "AliCPT-1",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.158687"
    },
    {
      "id": "arxiv-2602.11617v1",
      "title": "The ALMA-QUARKS Survey: Discovery of Dusty Fibrils inside Massive Star-forming Clumps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11617v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We report the discovery of more than 323 superfine dusty filamentary structures (fibrils) inside 121 massive star forming clumps that are located in widely different Galactic environments (Galactocentric distances of $\\sim$0.5-12.7 kpc). These fibrils are identified from the 1.3~mm continuum emission in the ALMA-QUARKS survey, which has a linear resolution of $\\sim900$ AU for a source at $\\sim$3 kpc, using the \\textit{FilFinder} software. Using \\textit{RadFil} software, we find that the typical width of these fibrils is $\\sim$0.01 pc, which is about ten times narrower than that of dusty filaments in nearby clouds identified by the \\textit{Herschel} Space Observatory. The mass ($M$) versus length ($L$) relation for these fibrils follows $M\\propto L^{2}$, similar to that of Galactic filaments identified in space (e.g., \\textit{Herschel}) and ground-based single-dish (e.g., \\textit{APEX}) surveys. However, these fibrils are significantly denser ($\\mathrm{N_{H_2} = 10^{23}-10^{24}\\ cm^{-2}}$) than the filaments found in previous \\textit{Herschel} surveys ($\\mathrm{N_{H_2} = 10^{20}-10^{23}\\ cm^{-2}}$). This work contributes a large sample of superfine fibrils in massive clumps, following the identification of large 0.1-pc wide filaments and associated internal velocity coherent fibers in nearby molecular clouds, further emphasizing the crucial role played by filamentary structures in star formation at various physical scales.",
        "keywords": [
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11617v1",
        "authors": [
          "Yan-Kun Zhang",
          "Tie Liu",
          "Wenyu Jiao",
          "Pak-Shing Li",
          "Jia Zeng"
        ],
        "arxiv_categories": [
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Space Observatory",
        "Dusty Fibrils",
        "Massive Star",
        "Clumps We",
        "QUARKS",
        "ALMA",
        "APEX",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.159034"
    },
    {
      "id": "arxiv-2602.11600v1",
      "title": "An optical transient candidate of $\\lesssim$ 2-second duration captured by wide-field video observations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11600v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Recent time-domain surveys have revealed rapid transients that evolve on timescales of $\\lesssim 10$ days, expanding the transient population into the short-duration regime. The transient search on even shorter timescales, particularly those lasting only seconds or less, remains a largely unexplored frontier. Very short-duration optical transients could serve as potential counterparts to millisecond-duration fast radio bursts (FRBs), providing clues to their origins. However, the optical search for transients on such short timescales has been limited primarily by instrumental constraints. Here we report the discovery of an optical transient candidate (TMG20200322) with a duration of $\\lesssim 2$~s by wide-field video observations in the direction of the Earth's shadow. TMG20200322 was detected in just two consecutive images of 1-second exposure time, with its shape becoming elongated in the second frame. PSF shape variability analysis of field stars reveals that such an elongated PSF cannot be explained by atmospheric fluctuations. We investigate the potential origins of TMG20200322 in two scenarios: meteoroid impact flashes on near-Earth asteroids (NEAs) and head-on meteors in the Earth's atmosphere. None of the scenarios provides a satisfactory explanation for this transient. We derive a sky-projected rate of the TMG20200322 event of $R_{\\mathrm{trans}} = (3.4 \\times 10^{-2})^{+0.13}_{-0.028}$~deg$^{-2}$~day$^{-1}$ and an upper limit on second-timescale transients with durations of $1~\\mathrm{s} \\leq τ\\lesssim 15~\\mathrm{s}$ of $R_{\\mathrm{trans}} \\lesssim 0.10$~deg$^{-2}$~day$^{-1}$ for the non-detection case. We highlight that continuous monitoring observations in the direction of the Earth's shadow could be a key strategy to unveil a new population of optical transients on timescales of seconds or less.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.HE",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11600v1",
        "authors": [
          "Noriaki Arima",
          "Mamoru Doi",
          "Shigeyuki Sako",
          "Yuu Niino",
          "Ryou Ohsawa"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.HE",
          "astro-ph.IM"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Act",
        "PSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.159880"
    },
    {
      "id": "arxiv-2602.11560v1",
      "title": "Analysis of Karin and Koronis2 asteroid families: new findings and challenges",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11560v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We use our home catalog of the asteroid proper elements to study the Karin family. The hierarchical clustering method provides formal identification with 3,863 members, but this set also includes objects from the neighboring Koronis2 and Kuitaisi families, as well as interlopers originating from the much older Koronis family. By tracking the trajectories of cluster objects backward in time, we identified 2,161 asteroids whose orbits converged with that of their parent body (832) Karin at $5.72\\pm 0.09$ My ago ($95$\\% C.L.). This method of calculating the family's age is based on a novel convergence metric that is directly related to the velocities at which fragments were ejected from (832) Karin. We analyze the extent to which members $\\leq 1.5$ km in diameter had drifted in semimajor axis due to Yarkovsky thermal forces and find it reflects the tilt of their rotation poles away from the ecliptic, recording the influence of the YORP torque. Karin's size frequency distribution in the $\\simeq(0.8-3)$ km range follows a power-law with a cumulative slope index $-3.20\\pm 0.01$. Removing members of the Karin family from the original group, we examine the Koronis2 family, whose members are associated with (158) Koronis. We find it difficult for large members of the Koronis2 family to converge with the orbit of (158) Koronis within its previously estimated age of $7.6$ My. Achieving such convergence would require the Koronis2 family to be older than $10$ My, but our result must be verified with a direct numerical approach in the future.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11560v1",
        "authors": [
          "David Vokrouhlický",
          "David Nesvorný",
          "William F. Bottke"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "YORP",
        "WHO",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.160196"
    },
    {
      "id": "arxiv-2602.11531v1",
      "title": "Eccentricity Evolution of Warm Jupiters: The Role of Distant Perturbers and Nearby Companions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11531v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Warm Jupiters-giant exoplanets with orbital periods between 10 and 200 days-exhibit a broad range of eccentricities and are often accompanied by nearby low-mass planets. Understanding the origins of their orbital architectures requires examining both their migration histories and subsequent dynamical interactions. In this study, we perform extensive N-body simulations to explore how distant giant planet perturbers affect the eccentricity evolution of warm Jupiters and the role of nearby super-Earth companions in mediating these interactions. We find that while distant perturbers can induce large-amplitude eccentricity oscillations in warm Jupiters via the von Zeipel-Lidov-Kozai mechanism, the presence of nearby super-Earth companions often suppresses these variations via strong dynamical coupling. This mechanism naturally leads to a bimodal eccentricity distribution: warm Jupiters with nearby companions tend to maintain low eccentricities, whereas those without exhibit significantly broader eccentricity distributions. We show that reproducing the observed eccentricity distribution of warm Jupiters lacking nearby companions is most naturally explained if a substantial fraction of distant perturbers occupy dynamically extreme orbits, either with large mutual inclinations or high orbital eccentricities. These results support a scenario in which warm Jupiters experience substantial post-disk dynamical evolution, shaped jointly by distant perturbers and nearby companions.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11531v1",
        "authors": [
          "Ying He",
          "Dong-Hong Wu",
          "Sheng Jin"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Nearby Companions Warm Jupiters",
        "Eccentricity Evolution",
        "Distant Perturbers",
        "Warm Jupiters",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:53:53.160496"
    },
    {
      "id": "arxiv-2602.11529v1",
      "title": "Searching for Anisotropy in the Gravitational Wave Background Using the Parkes Pulsar Timing Array",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11529v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In recent years, several pulsar timing array collaborations have reported evidence for a nanohertz gravitational wave background (GWB). Such a background signal could be produced by supermassive binary black holes, early-Universe processes such as inflation and phase transitions, or a mixture of both. One way to disentangle different contributions to the GWB is to search for anisotropic signatures. In this work, we search for anisotropy in the GWB using the third data release of the Parkes Pulsar Timing Array. Our analysis employs both the radiometer method and the spherical harmonic basis to characterize the distribution of GWB power across the sky. We calculate the angular power in the lowest five frequency bins and compare it with detection thresholds determined under the null hypothesis of isotropy. In the 5.26 nHz frequency bin, we identify a hotspot in the reconstructed sky map with a $p$-value of $0.016$ (the lowest in our analysis), which we attribute to noise fluctuations. While our search reveals no statistically significant anisotropy, we expect that the precise measurement of angular power spectrum of the GWB will become instrumental in determining the origin of the nanohertz GWB signal.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11529v1",
        "authors": [
          "Yiqin Chen",
          "Shi-Yi Zhao",
          "Zhi-Zhang Peng",
          "Xingjiang Zhu",
          "N. D. Ramesh Bhat"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gravitational Wave Background Using",
        "Parkes Pulsar Timing Array",
        "Act",
        "GWB",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:53.160780"
    },
    {
      "id": "arxiv-2602.12254v1",
      "title": "A Stochastic Cluster Expansion for Electronic Correlation in Large Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12254v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Accurate many-body treatments of condensed-phase systems are challenging because correlated solvers such as full configuration interaction (FCI) and the density matrix renormalization group (DMRG) scale exponentially with system size. Downfolding and embedding approaches mitigate this cost but typically require prior selection of a correlated subspace, which can be difficult to determine in heterogeneous or extended systems. Here, we introduce a stochastic cluster expansion framework for efficiently recovering the total correlation energy of large systems with near-DMRG accuracy, without the need to select an active space a priori. By combining correlation contributions from randomly sampled environment orbitals with an exactly treated subspace of interest, the method reproduces total energies for non-reacting and reactive systems while drastically reducing computational cost. The approach also provides a quantitative diagnostic for molecule-solvent correlation, guiding principled embedding decisions. This framework enables systematically improvable many-body calculations in extended systems, opening the door to high-accuracy studies of chemical processes in condensed phase environments.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12254v1",
        "authors": [
          "Annabelle Canestraight",
          "Anthony J. Dominic",
          "Andres Montoya-Castillo",
          "Libor Veis",
          "Vojtech Vlcek"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stochastic Cluster Expansion",
        "Large Systems Accurate",
        "Electronic Correlation",
        "Framework",
        "DMRG",
        "Act",
        "MIT",
        "FCI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.327094"
    },
    {
      "id": "arxiv-2602.12248v1",
      "title": "Simultaneous High-Fidelity Readout and Strong Coupling for a Donor-Based Spin Qubit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12248v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Superconducting resonators coupled to solid-state qubits offer a scalable architecture for long-range entangling operations and fast, high-fidelity readout. Realizing this requires low photon-loss rates and qubits with tunable electric dipole moments that couple strongly to the resonator's electric field while maintaining long coherence times. For spin qubits, spin-photon coupling is typically achieved via spin-charge hybridization. However, this introduces a fundamental trade-off: a large spin-charge admixture enhances the coupling strength, which boosts readout and resonator-mediated gate speeds, but exposes the qubit to increased decoherence, thereby increasing the threshold required for strong coupling and limiting the time available for accurate state measurement. This makes it essential to identify optimal operating points for each qubit platform. We address this for the donor-based flip-flop qubit, whose microwave-controllable electron-nuclear spin states make it suitable for coupling to microwave resonators. We demonstrate that, by choosing intermediate tunnel couplings that balance strong interaction with long qubit lifetimes, high-fidelity readout and strong coupling are simultaneously achievable. We also map out the respective charge-photon couplings and photon-loss rates required. Furthermore, we show that experimental constraints on charge-photon coupling and photon loss can be mitigated using squeezed input fields. As similar trade-offs appear in quantum-dot-based qubits, our methods and insights extend naturally to these platforms, offering a potential route toward scalable architectures.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12248v1",
        "authors": [
          "Si Yan Koh",
          "Weifan Wu",
          "Kelvin Onggadinata",
          "Arghya Maity",
          "Mark Chiyuan Ma"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Spin Qubit Superconducting",
        "Simultaneous High",
        "Fidelity Readout",
        "Strong Coupling",
        "Nuclear",
        "Act",
        "WHO",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.327746"
    },
    {
      "id": "arxiv-2602.12228v1",
      "title": "Non-Abelian Quantum Low-Density Parity Check Codes and Non-Clifford Operations from Gauging Logical Gates via Measurements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12228v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this work, we introduce constructions for non-Abelian qLDPC codes obtained by gauging transversal Clifford gates using measurement and feedback. In particular, we identify two qualitatively different approaches to gauging qLDPC codes to obtain their non-Abelian counterparts. The first approach applies to codes that exhibit a generalized form of Poincaré duality and leads to a qLDPC non-Abelian Clifford stabilizer code, whose stabilizers are reminiscent of the action of a Type-III twisted quantum double. Our second approach applies to general qLDPC codes, and uses a graph of ancilla qubits which may be tailored to properties of the input codes to gauge a single transversal gate. For both constructions, the resulting gauged codes are shown to have properties analogous to 2D non-Abelian topological order -- e.g. the analog of a single anyon on a torus. We conclude by demonstrating that our gauging procedures enable magic state preparation via the measurement of logical Clifford gates. Consequently, our gauging constructions offer a protocol for performing non-Clifford operations on any qLDPC code.",
        "keywords": [
          "quant-ph",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12228v1",
        "authors": [
          "Maine Christos",
          "Chiu Fan Bowen Lo",
          "Vedika Khemani",
          "Rahul Sahay"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Density Parity Check Codes",
        "Gauging Logical Gates",
        "Abelian Quantum Low",
        "Clifford Operations",
        "Abelian Clifford",
        "Measurements In",
        "Protocol",
        "Act",
        "WHO",
        "EPA",
        "III",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.328736"
    },
    {
      "id": "arxiv-2602.12223v1",
      "title": "Kagome edge states under lattice termination, spin-orbit coupling, and magnetic order",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12223v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the edge state properties of a two-dimensional kagome lattice using a tight-binding approach, focusing on the role of lattice termination, spin-orbit coupling, and magnetic order. In the pristine limit, we show that the existence of localized edge states is highly sensitive to boundary geometry, with certain terminations completely suppressing edge modes. Kane-Mele spin-orbit coupling opens a bulk gap and stabilizes topologically protected helical edge states, yielding a robust $\\mathbb{Z}_2$ insulating phase that is insensitive to termination details. In contrast, the combined effect of a Zeeman field and Rashba spin-orbit coupling drives the system into Chern insulating phases, with Chern numbers consistent with the number of chiral edge modes. We further demonstrate that non-coplanar magnetic textures generate multiple Chern phases through finite scalar spin chirality, with Kane-Mele coupling strongly tuning the topological gaps. Our results provide important insights into the tunability of edge states in the kagome lattice, which can be key to designing materials with novel electronic properties and topological phases.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.mes-hall",
          "cond-mat.supr-con"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12223v1",
        "authors": [
          "Sajid Sekh",
          "Annica M. Black-Schaffer",
          "Andrzej Ptok"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.mes-hall",
          "cond-mat.supr-con"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.329234"
    },
    {
      "id": "arxiv-2602.12212v1",
      "title": "Quantum-Coherent Thermodynamics: Leaf Typicality via Minimum-Variance Foliation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12212v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Equilibrium statistical ensembles commute with the Hamiltonian and thus carry no coherence in the energy eigenbasis. We develop a thermodynamic framework in which energy fluctuations can retain genuinely quantum-coherent contributions. We foliate state space into \"minimum-variance leaves,\" defined by minimizing the average energy variance over all pure-state decompositions, with the minimum set by the quantum Fisher information. On each leaf we construct the least-biased state compatible with normalization and mean energy, defining a leaf-canonical ensemble. The Gibbs ensemble is recovered on the distinguished commuting leaf, while generic states are organized by their leaf label. This structure provides a natural setting to extend eigenstate thermalization beyond equilibrium via a \"leaf typicality\" hypothesis. According to that hypothesis, under unitary time evolution local observables depend only on the leaf and energy and, at all times, are reproduced by evolving a representative (pure) state drawn from the optimal ensemble.",
        "keywords": [
          "quant-ph",
          "cond-mat.stat-mech",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12212v1",
        "authors": [
          "Maurizio Fagotti"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.stat-mech",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variance Foliation Equilibrium",
        "Leaf Typicality",
        "Framework",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.329652"
    },
    {
      "id": "arxiv-2602.12185v1",
      "title": "Charged moments and symmetry-resolved entanglement from Ballistic Fluctuation Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12185v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The charged moments of a reduced density matrix provide a natural starting point for deriving symmetry-resolved Rényi and entanglement entropies, which quantify how entanglement is distributed among symmetry sectors in the presence of a global internal symmetry in a quantum many-body system. In this work, we study charged moments within the framework of Ballistic Fluctuation Theory (BFT). This theory describes large-scale ballistic fluctuations of conserved charges and associated currents and, by exploiting the height-field formulation of twist fields, gives access to the asymptotic behaviour of their two-point correlation functions. In Del Vecchio Del Vecchio et al. $[1]$, this approach was applied to the special case of branch-point twist fields used to compute entanglement entropies within the replica approach. Here, we extend those results by applying BFT to composite branch-point twist fields, obtained by inserting an additional gauge field. Focusing on free fermions, we derive analytic expressions for charged Rényi entropies both at equilibrium, in generalized Gibbs ensembles, and out of equilibrium following a quantum quench from $U(1)$ preserving pair producing integrable initial states. In the latter case, our results agree with the conjecture arising from the quasiparticle picture.",
        "keywords": [
          "cond-mat.stat-mech",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12185v1",
        "authors": [
          "Giorgio Li",
          "Léonce Dupays",
          "Paola Ruggiero"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "In Del Vecchio Del",
        "Framework",
        "BFT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.330643"
    },
    {
      "id": "arxiv-2602.12168v1",
      "title": "Magnetopological mechanics in Maxwell lattice frustrated Mott insulators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12168v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Topological boundary modes, a hallmark of quantum topological phases, remarkably occur in classical mechanical systems through an interesting correspondence with the quantum case. Here, we explore the Maxwell lattice frustrated Mott insulators and argue that the combination of the intrinsic spin-lattice coupling and the spin exchanges could induce the topological mechanics with topological boundary floppy modes in the phonon spectra. This mechanism and phenomena are dubbed magnetic topological mechanics, or, magnetopological mechanics in short. Focusing on a two-dimensional kagomé lattice spin model, we illustrate how strong spin-lattice coupling drives a spontaneous lattice distortion, resulting in the topological Maxwell lattice with the topological polarization and non-trivial phonon spectra. Moreover, the magnetic field, that directly changes the spin state, indirectly influences the lattice structure via the spin-lattice coupling, thereby providing a method to control the Maxwell lattice and the boundary modes. We expect this work to inspire interests in the Maxwell lattice Mott insulating materials and the coupling between lattices and electronic orders.",
        "keywords": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12168v1",
        "authors": [
          "Hong-Hao Song",
          "Pengwei Zhao",
          "Gang v. Chen"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "LLM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.331590"
    },
    {
      "id": "arxiv-2602.12141v1",
      "title": "Elastoresistance as probe of strain-controlled entropy from Kondo scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12141v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Heavy-fermion metals are prototype correlated electron systems for the study of Kondo entanglement and quantum criticality. We use the symmetry decomposed elastoresistance to uncover the fingerprints of strain-dependent Kondo scattering as function of temperature and magnetic field in the prototypical tetragonal Kondo lattice YbRh$_2$Si$_2$. By combining longitudinal and transverse resistance measurements under uniaxial strain applied along the tetragonal $[100]$ and $[110]$ directions, we obtain the elastoresistive responses in the $A_{1g}$, $B_{1g}$, and $B_{2g}$ symmetry channels. While the responses in the symmetry-breaking channels are negligible, the isotropic $A_{1g}$ elastoresistance displays characteristic sign changes and approaches huge values at low temperatures. Scaling analysis and comparison with linear thermal expansion measurements reveals that the elastoresistance probes the contribution of Kondo scattering to the strain dependence of magnetic entropy and signals strain-controlled quantum criticality upon cooling to 2 K.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12141v1",
        "authors": [
          "Soumendra Nath Panja",
          "Jacques G. Pontanel",
          "Julian Kaiser",
          "Anton Jesche",
          "Philipp Gegenwart"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.332070"
    },
    {
      "id": "arxiv-2602.12069v1",
      "title": "Two-photon-assisted collisions in ultracold gases of polar molecules II : Optical shielding of ultracold polar molecular collisions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12069v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We theoretically investigate the collisions between ultracold polar molecules in the presence of two lasers ensuring a Raman resonant transition on individual molecules to suppress photon scattering, taking the example of bosonic $^{23}$Na$^{39}$K molecules. By varying laser detunings and intensities, we enable a repulsive long-range interaction potential between molecules. After solving a set of coupled Schrödinger equations with the Hamiltonian written in the basis of laser-dressed states of the molecule pair at infinite distance, we identify quasi-resonant conditions under which elastic collisions are favored over inelastic and reactive ones, by a factor of about 2, thus demonstrating a promising pathway for efficient two-photon optical shielding of ultracold molecular collisions. The results are analyzed in terms of scattering length of the colliding laser-dressed molecules, which exhibit prominent resonances assigned to the interaction of the entrance channel with other specific channels, consistent with the existence of a quasi-bound level of the long-range molecular pair induced by the lasers.",
        "keywords": [
          "cond-mat.quant-gas"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12069v1",
        "authors": [
          "Gohar Hovhannesyan",
          "Charbel Karam",
          "Romain Vexiau",
          "Leon Karpa",
          "Maxence Lepers"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.333173"
    },
    {
      "id": "arxiv-2602.12068v1",
      "title": "Stacking theory for bilayer two-dimensional magnets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12068v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Two-dimensional unconventional magnetism has recently attracted growing interest due to its intriguing physical properties and promising applications in spintronics. However, existing studies on stacking-induced unconventional magnetism mainly focus on specific materials and stacking configurations. Here, we develop a general symmetry-based stacking theory for two-dimensional magnets. We first introduce spin layer groups as the fundamental symmetry framework, providing the essential magnetic symmetry information for the stacking theory. Based on this framework, we construct the complete set of 448 collinear spin layer groups for describing two-dimensional collinear magnets. Subsequently, we develop a general magnetic stacking theory applicable to arbitrary magnetic systems and derive its general solutions. Using CrF$_3$ as an illustrative example, we show how this theory enables designs of two-dimensional unconventional magnetism, as validated by first-principles calculations. We realize two-dimensional fully compensated ferrimagnetism through our stacking theory. Our work provides a general symmetry-guided platform for discovering and designing stacking-induced unconventional magnetism.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12068v1",
        "authors": [
          "Jun-Xi Du",
          "Sike Zeng",
          "Yu-Jun Zhao"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.333617"
    },
    {
      "id": "arxiv-2602.12067v1",
      "title": "Momentum Distribution of the Dilute Fermi Gas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12067v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We consider a dilute quantum gas of interacting spin-1/2 fermions in the thermodynamic limit. For a trial state that resolves the ground state energy up to the precision of the Huang--Yang formula, we rigorously derive its momentum distribution. Our result agrees with the formal perturbative argument of Belyakov (Sov. Phys. JETP 13: 850--851 (1961)).",
        "keywords": [
          "math-ph",
          "cond-mat.quant-gas",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12067v1",
        "authors": [
          "Niels Benedikter",
          "Emanuela L. Giacomelli",
          "Asbjørn Bækgaard Lauritsen",
          "Sascha Lill"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.quant-gas",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Momentum Distribution",
        "Dilute Fermi Gas We",
        "JETP",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.333796"
    },
    {
      "id": "arxiv-2602.12053v1",
      "title": "Remarks on non-invertible symmetries on a tensor product Hilbert space in 1+1 dimensions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12053v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose an index of non-invertible symmetry operators in 1+1 dimensions and discuss its relation to the realizability of non-invertible symmetries on the tensor product of finite dimensional on-site Hilbert spaces on the lattice. Our index generalizes the Gross-Nesme-Vogts-Werner index of invertible symmetry operators represented by quantum cellular automata (QCAs). Assuming that all fusion channels of symmetry operators have the same index, we show that the fusion rules of finitely many symmetry operators on a tensor product Hilbert space can agree, up to QCAs, only with those of weakly integral fusion categories. We also discuss an attempt to establish an index theory for non-invertible symmetries within the framework of tensor networks. To this end, we first propose a general class of matrix product operators (MPOs) that describe non-invertible symmetries on a tensor product Hilbert space. These MPOs, which we refer to as topological injective MPOs, include all invertible symmetries, non-anomalous fusion category symmetries, and the Kramers-Wannier symmetries for finite abelian groups. For topological injective MPOs, we construct the defect Hilbert spaces and the corresponding sequential quantum circuit representations. We also show that all fusion channels of topological injective MPOs have the same index if there exist fusion and splitting tensors that satisfy appropriate conditions. The existence of such fusion and splitting tensors has not been proven in general, although we construct them explicitly for all examples of topological injective MPOs listed above.",
        "keywords": [
          "cond-mat.str-el",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12053v1",
        "authors": [
          "Kansei Inamura"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Fusion",
        "BERT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.334355"
    },
    {
      "id": "arxiv-2602.12048v1",
      "title": "Non-Hermitian topology of quantum spin-Hall systems to detect edge-state polarization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12048v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the non-Hermitian topology of multi-terminal transport in a quantum spin-Hall device described by the Bernevig-Hughes-Zhang model. We show that breaking time-reversal symmetry alone does not imply non-reciprocal transport or a non-Hermitian conductance matrix. Instead, non-Hermitian topology arises only when transport becomes directionally imbalanced. We identify two distinct mechanisms that generate such a response: spin-selective coupling at the contacts and an out-of-plane Zeeman field that unbalances the counter-propagating helical edge modes. We show, for unpolarized leads, that the spin polarization-dependent response to Zeeman fields, provides a transport-based probe of the intrinsic spin polarization of the helical edge states. Moreover, we demonstrate that non-Hermitian skin effect is more sensitive than conductance elements to detect the spin polarization of the edge states. Our results clarify the conditions required for non-Hermitian topology in quantum spin-Hall transport and establish non-Hermitian skin effect as a diagnostic tool for spin-selective coupling and edge-state polarization.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12048v1",
        "authors": [
          "Raghav Chaturvedi",
          "Ion Cosma Fulga",
          "Jeroen van den Brink",
          "Ewelina M. Hankiewicz"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.334735"
    },
    {
      "id": "arxiv-2602.12020v1",
      "title": "Topological chiral random walker",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12020v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Understanding how biological and synthetic systems achieve robust function in noisy environments remains a fundamental challenge across the physical and life sciences. To connect robust behavior with non-trivial topological features present already in the dynamics of individual units, here we introduce the topological chiral random walker (TCRW) model. While exploring the system, a TCRW locates edges and boundaries in the system and develops topologically protected edge currents even in the presence of defects and disorder. Drawing on the bulk-boundary correspondence found in hard condensed matter systems allows us to rationalize the emergence of robust edge currents through topological features of the dynamic spectrum. We show that chiral motion and rotational noise with opposite chirality are two crucial components in our inherently non-Hermitian model. As proofs of principle, we first show that a topological walker outperforms diffusive motion to efficiently solve complex mazes due to its property of remaining on the edge with some rare detachments. Second, we use this model to design building blocks that can perform efficient self-assembly overcoming the timescale bottlenecks of diffusion-limited growth and reducing self-assembly times by approximately 80%.",
        "keywords": [
          "cond-mat.stat-mech",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12020v1",
        "authors": [
          "Saeed Osat",
          "Ellen Meyberg",
          "Jakob Metson",
          "Thomas Speck"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "TCRW",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.335263"
    },
    {
      "id": "arxiv-2602.12000v1",
      "title": "Two-point functions in boundary loop models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12000v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Using techniques of conformal bootstrap, we propose analytical expressions for a large class of two-point functions of bulk fields in critical loop models defined on the upper-half plane. Our results include the two-point connectivities in the Fortuin--Kasteleyn random cluster model with both free and wired boundary conditions. We link the continuum expressions to lattice quantities by computing universal ratios of amplitudes for the two-point connectivities, and find excellent agreement with transfer-matrix numerics.",
        "keywords": [
          "math-ph",
          "cond-mat.stat-mech",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12000v1",
        "authors": [
          "Max Downing",
          "Jesper Lykke Jacobsen",
          "Rongvoram Nivesvivat",
          "Hubert Saleur"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.stat-mech",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "NSF",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.335475"
    },
    {
      "id": "arxiv-2602.11983v1",
      "title": "Dynamics and thermodynamics of the S = 5/2 almost-Heisenberg triangular lattice antiferromagnet K2Mn(SeO3)2",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11983v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We report calorimetric, magnetic, and neutron scattering studies on an S = 5/2, nearly Heisenberg triangular-lattice antiferromagnet K2Mn(SeO3)2 with weak XXZ easy-axis anisotropy. Multiple magnetic phases are identified, including a non-collinear Y phase in zero field, a field-induced collinear m = 1/3 magnetization plateau, and a high-field V phase. In the Y phase, the magnetic excitation spectrum exhibits both single-magnon excitations and an extended high-energy continuum. Both features are well described by non-linear spin wave theory. In the field-induced phases, complex effects of the spectrum renormalization even for large S = 5/2 material are clearly detectable. These results underscore the essential role of magnon-magnon interactions in the dynamics of large-S Heisenberg spin systems on a triangular lattice.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11983v1",
        "authors": [
          "Mengze Zhu",
          "V. Romerio",
          "D. Moser",
          "K. Yu. Povarov",
          "R. Sibille"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "XXZ",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.335801"
    },
    {
      "id": "arxiv-2602.11979v1",
      "title": "RING: Rabi oscillations induced by nonresonant geometric drive",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11979v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Coherent control of two-level quantum systems is typically achieved using resonant driving fields, forming the basis for qubit operations. Here, we report a mechanism for inducing complete Rabi oscillations in monochromatically driven two-level quantum systems, when the drive frequency is much larger than the Larmor frequency of the qubit. This effect$\\unicode{x2015}$Rabi oscillations induced by nonresonant geometric drive (RING)$\\unicode{x2015}$requires that the control field is elliptical, enclosing a nonzero area per cycle. We illustrate the effect with numerical simulations, and provide an analytical understanding via a simple effective Hamiltonian obtained from Floquet theory and perturbation theory. We show that RING enables coherent oscillations without relying on resonant energy exchange, allows for high-pass noise filtering, provides access to non-Abelian phases in finite magnetic fields. We detail a realization in electrically driven spin-orbit qubits and argue that the RING mechanism enables amplification of the Rabi frequency using the same gate voltage amplitudes at higher drive frequencies. Our results broaden the landscape of quantum control techniques, by highlighting a pathway to achieving coherent oscillations under off-resonant driving conditions.",
        "keywords": [
          "cond-mat.mes-hall",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11979v1",
        "authors": [
          "Baksa Kolok",
          "András Pályi"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "RING",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.336205"
    },
    {
      "id": "arxiv-2602.11963v1",
      "title": "Melting of quantum Hall Wigner and bubble crystals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11963v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A two-dimensional crystal melts via the proliferation and unbinding of topological defects, yet quantitatively predicting the melting temperature $T_m$ in real systems is challenging. Here we resolve this discrepancy in quantum Hall electron bubble phases by combining Corbino-geometry transport experiment in an ultraclean GaAs/AlGaAs quantum well for Landau levels 2 to 5 with Hartree--Fock elasticity and the full Kosterlitz--Thouless--Halperin--Nelson--Young melting criterion including the finite-temperature renormalization-group calculation. The theoretically obtained $T_m$ quantitatively captures the measured solid-liquid phase transition boundaries across all probed ranges, validating the bubble-crystal interpretation and establishing defect--mediated melting as a predictive framework for strongly interacting electronic solids. This agreement further supports using bulk transport to probe the energetics of topological defects and screening in quantum Hall physics, and the approach is readily extendable to other electronic crystals, including the generalized Wigner crystal in moiré Chern bands.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11963v1",
        "authors": [
          "H. Xia",
          "Qianhui Xu",
          "Jiasen Niu",
          "Jian Sun",
          "Yang Liu"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hall Wigner",
        "Framework",
        "Agreement",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.336991"
    },
    {
      "id": "arxiv-2602.11935v1",
      "title": "Proposal for realizing unpaired Weyl points in a three-dimensional periodically driven optical Raman lattice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11935v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In static lattice systems, the Nielsen-Ninomiya theorem enforces the pairing of Weyl points with opposite chiralities, which precludes the chiral magnetic effect (CME) in equilibrium. Periodic driving provides a viable route to circumvent this no-go constraint. Here, we propose a scheme to realize and control unpaired Weyl points using ultracold atoms in a three-dimensional (3D) optical Raman lattice under continuous periodic driving. By engineering distinct relative symmetries between the lattice and multiple Raman potentials, the configuration generates an effective 3D spin-orbit coupling and yields a tunable topological-insulator phase. Through adiabatic periodic modulation of this system, we show that eight Weyl points emerge in the quasienergy spectrum of the low-energy sector, whose net chirality can be precisely tuned. A nonzero total chirality directly corresponds to the formation of unpaired Weyl points. Furthermore, by implementing a synthetic magnetic field via laser-assisted tunneling in this setup, we demonstrate that the chirality imbalance drives a quantized charge current in the weak-field regime, providing a direct signature of the CME. We verify that the adiabatic condition of the driving protocol, as well as the proposed experimental preparation and detection techniques, are within reach of current ultracold-atom experiments. This work establishes a realistic and controllable platform for exploring chiral-anomaly physics and nonequilibrium topological phenomena linked to Weyl fermions.",
        "keywords": [
          "cond-mat.quant-gas",
          "cond-mat.mes-hall",
          "hep-lat"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11935v1",
        "authors": [
          "Xiao-Dong Lin",
          "Jinyi Zhang",
          "Long Zhang"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "cond-mat.mes-hall",
          "hep-lat"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "WHO",
        "EPA",
        "CME",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.337485"
    },
    {
      "id": "arxiv-2602.11932v1",
      "title": "Emergence of a Helical Metal in Rippled Ultrathin Topological Insulator Sb\\textsubscript{2}Te\\textsubscript{3} on Graphene",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11932v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The integration of topological insulators (TIs) with graphene offers a pathway to engineer hybrid quantum states, yet the impact of strain at the 2D limit remains a critical open question. Here, we investigate the structural properties of ultrathin (1 quintuple layer) Sb$_2$Te$_3$ grown on single-layer graphene and, motivated by the structural modulations observed at the TI surface, explore theoretically how such nanoscale corrugations may influence the electronic behavior of the system. Using low-temperature scanning tunneling microscopy (LT-STM), we observe a periodic rippling of the heterostructure with a wavelength of ~$\\sim8.7$ nm. Energetic analysis reveals that these ripples are not intrinsic but are driven by strain from the substrate during cooling. Density functional theory (DFT) calculations show that while the ideal flat heterostructure exhibits a hybridization gap of $\\sim40$ meV, the ripple-induced structural modulation closes this gap, restoring a metallic state. This gapless phase is not a trivial metal. By combining an effective moiré ladder model with spin-resolved DFT, we find that the proximity-induced spin-orbit coupling is redistributed across a dense manifold of minibands. The resulting ``Helical Metal'' has a complex spin-texture beyond a simple Rashba splitting. Remarkably, while the flat system is effectively spinless in this ultrathin limit due to hybridization, the ripples actively restore the spin polarization. Our findings suggest that rippled TI/graphene heterostructures provide an interesting platform to develop spintronics, where geometric modulation unlocks dense helical states that are inaccessible in the pristine flat limit.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11932v1",
        "authors": [
          "Francisco Munoz",
          "Manuel Fuenzalida",
          "Paula Mellado",
          "Hari C. Manoharan",
          "Valentina Gallardo"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rippled Ultrathin Topological Insulator",
        "Helical Metal",
        "Meta",
        "Act",
        "STM",
        "MIT",
        "DFT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.338484"
    },
    {
      "id": "arxiv-2602.11916v1",
      "title": "Microscopic field theory for active Brownian particles with translational and rotational inertia",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11916v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "While active matter physics has traditionally focused on particles with overdamped dynamics, recent years have seen an increase of experimental and theoretical work on active systems with inertia. This also leads to an increased need for theoretical models that describe inertial active dynamics. Here, we present a microscopic derivation for a general continuum model describing the nonequilibrium thermodynamics of inertial active matter that generalizes several previously existing works. It applies to particles with translational and rotational inertia and contains particle density, velocity, angular velocity, temperature, polarization, velocity polarization, and angular velocity polarization as dynamical variables. We moreover discuss to which extend commonly used approximations (factorization and local equilibrium) used in the derivation of hydrodynamic models are applicable to inertial active matter.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11916v1",
        "authors": [
          "Michael te Vrugt"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.338751"
    },
    {
      "id": "arxiv-2602.11894v1",
      "title": "Emergence of charge and spin current in non-Hermitian quantum ring",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11894v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the charge and spin transport in a non-Hermitian ring of electrons subject to an external Zeeman field. By introducing non-Hermiticity through anti-Hermitian hopping in the nearest neighbour bonds, we demonstrate that anti-Hermiticity, along with the applied Zeeman field significantly modify the energy spectrum and strongly influence transport properties. As a result, we obtain that when antiferromagnetic Zeeman field is considered, a finite charge current emerges in both the real and imaginary parts of the current, which are in contrast to the ferromagnetic case where only the imaginary current exist. On the other hand, in both cases, the spin current vanishes. Interestingly, we reveal an emergence and strong enhancement of spin currents under balanced spin population upon introducing quasiperiodicity in the presence of antiferromagnetic ordering. At the same time, the charge current also exhibits substantial enhancement due to quasiperiodic modulation. These results highlight non-Hermitian quantum rings as versatile platforms for unconventional spin-charge transport.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11894v1",
        "authors": [
          "Soumya Ranjan Padhi",
          "Souvik Roy",
          "Tapan Mishra"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.339062"
    },
    {
      "id": "arxiv-2602.11866v1",
      "title": "Phaseless auxiliary-field quantum Monte Carlo method with spin-orbit coupling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11866v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Spin-orbit coupling (SOC) is incorporated into the phaseless plane-wave-based auxiliary-field quantum Monte Carlo (pw-AFQMC) method. This integration is implemented using optimized multiple-projector norm-conserving pseudopotentials, which are derived from the fully-relativistic (FR) atomic all-electron Dirac-like equation. The inclusion of SOC enables accurate phaseless pw-AFQMC calculations that capture both electronic correlation and SOC effects concurrently, greatly improving the method's applicability for studying systems containing heavy atoms. We discuss the form of FR pseudopotentials and detail the corresponding formulations of phaseless pw-AFQMC with a two-component Hamiltonian in the spinor basis. The accuracy of our approach is demonstrated by computing the dissociation energy of molecule I2 and the cohesive energy of bulk Pb, highlighting the large influence of SOC in both. Subsequently, we determine the transition pressure of the III-V compound InP from its zinc-blende to rock-salt phase by constructing and analyzing their respective equations of state.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11866v1",
        "authors": [
          "Zheng Liu",
          "Shiwei Zhang",
          "Fengjie Ma"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "AFQMC",
        "III",
        "SOC",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.339371"
    },
    {
      "id": "arxiv-2602.11844v1",
      "title": "Parity-dependent double degeneracy and spectral statistics in the projected dice lattice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11844v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the spectral statistics of an interacting fermionic system derived by projecting the Hubbard interaction onto the two lowest-energy, degenerate flat bands of the dice lattice subjected to a $π$-flux. Surprisingly, the distributions of level spacings and gap ratios correspond to distinct Gaussian ensembles, depending on the parity of the particle number. For an even number of particles, the spectra conform to the Gaussian Orthogonal Ensemble, as expected for a time-reversal-symmetric Hamiltonian. In stark contrast, the odd-parity sector exhibits exact double degeneracy of all eigenstates even after resolving all known symmetries, and the Gaussian Unitary Ensemble accurately describes the spacing distribution between these doublets. The simultaneous emergence of two different random-matrix ensembles within a single physical system constitutes an unprecedented finding, opening new avenues for both random matrix theory and flat-band physics.",
        "keywords": [
          "cond-mat.str-el",
          "math-ph",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11844v1",
        "authors": [
          "Koushik Swaminathan",
          "Anouar Moustaj",
          "Jose L. Lado",
          "Sebastiano Peotta"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "math-ph",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gaussian Orthogonal Ensemble",
        "Gaussian Unitary Ensemble",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.340025"
    },
    {
      "id": "arxiv-2602.11781v1",
      "title": "Stacking-dependent magnetic ordering in bilayer ScI$_{2}$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11781v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Stacking-dependent magnetism in two-dimensional van der Waals materials offers an effective route for controlling magnetic order without chemical modification. Here, we present a combined first-principles and finite-temperature study of magnetic ordering in bilayer ScI$_{2}$ with different stacking configurations. Using density functional theory with Hubbard-U corrections, we investigate the structural, electronic, and magnetic properties of monolayer and bilayer ScI$_{2}$ in $AA$, $AB$, and $BA$ stackings. The electronic structure exhibits a spin-polarized ground state dominated by Sc-$d$ states near the Fermi level. Mapping total energies onto an effective Heisenberg spin Hamiltonian reveals strong intralayer ferromagnetic exchange that is largely insensitive to stacking, while the inter-layer exchange depends strongly on stacking geometry, favoring ferromagnetic coupling for $AA$ and $BA$ stackings and antiferromagnetic coupling for the $AB$ stacking. Spin-orbit coupling calculations show that both monolayer and bilayer ScI$_{2}$ possess a robust out-of-plane magnetic easy axis. Finite-temperature Monte Carlo simulations indicate that all bilayer configurations sustain magnetic ordering at and above room temperature, with ordering temperatures in the range $360-375$ K, as confirmed by Binder cumulant analysis and finite-size scaling. These results demonstrate that stacking geometry enables control of the magnetic ground state in bilayer ScI$_{2}$ without significantly affecting its thermal stability.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11781v1",
        "authors": [
          "Soumyajit Sarkar",
          "Soham Chandra"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.340468"
    },
    {
      "id": "arxiv-2602.11768v1",
      "title": "What is a Fluctuation Theorem?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11768v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This book provides a modern review of Fluctuation Relations and Fluctuation Theorems in nonequilibrium statistical mechanics. It focuses on the pioneering perspectives of Gallavotti and Cohen, according to which a fluctuation theorem describes the statistics of the deviations of entropy production from its expected value. For time-reversal invariant systems, these fluctuations obey a universal (i.e., model-independent) symmetry called the fluctuation relation. The probabilistic framework introduced in the first part of the book allows for a very general formulation of Fluctuation Relations and Theorems for both deterministic and stochastic dynamical systems. The authors further explore models of physical interest, illustrating this framework by concrete applications. The second part of the book focuses on chaotic dynamics. The formulation of two general Fluctuation Theorems, followed by the detailed study of a concrete example, provides the reader with an understanding of both the theoretical and practical aspects of the subject.",
        "keywords": [
          "math-ph",
          "cond-mat.stat-mech",
          "math.DS",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11768v1",
        "authors": [
          "Noé Cuneo",
          "Vojkan Jakšić",
          "Claude-Alain Pillet",
          "Armen Shirikyan"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.stat-mech",
          "math.DS",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fluctuation Relations",
        "Framework",
        "NIST",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.340766"
    },
    {
      "id": "arxiv-2602.11762v1",
      "title": "QCD phase diagram in a magnetic field with baryon and isospin chemical potentials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11762v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Based on the chiral perturbation theory at the leading order, we present the phase diagram of low-energy QCD in a magnetic field at finite baryon and isospin chemical potentials. The phase diagram consists of the QCD vacuum, the chiral soliton lattice, the uniform charged pion condensation, an Abrikosov vortex lattice of the charged pions, a baryonic vortex lattice composed of neutral and charged pion vortices with their topological linking number being the baryon number, and a hybrid phase of chiral soliton and vortex lattices, with their intersections carrying the baryon number. While the chiral soliton lattice demands ultra-strong magnetic field $\\sim 10^{19}$ G,the intersection phase appears at $\\sim10^{17}$ G, which is more realistic in neutron stars.",
        "keywords": [
          "hep-ph",
          "cond-mat.supr-con",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11762v1",
        "authors": [
          "Yu Hamada",
          "Muneto Nitta",
          "Zebin Qiu"
        ],
        "arxiv_categories": [
          "hep-ph",
          "cond-mat.supr-con",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "QCD",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.341075"
    },
    {
      "id": "arxiv-2602.11721v1",
      "title": "Emergence of a spin Hall topological Hall effect in the non-collinear phase of the ferrimagnetic insulator terbium-iron garnet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11721v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Magnetic compensation in rare-earth iron garnets (REIGs) offers a unique setting for which competing sublattice moments can give rise to non-collinear (canted) magnetic configurations, in which the sublattice magnetizations are not aligned with each other or with the external magnetic field. We show that this compensation regime can also host non-trivial magnetic textures. To explore this behavior, we investigated (111)-oriented epitaxial Tb$_3$Fe$_5$O$_{12}$/Pt heterostructures across the compensation temperature region using combined transverse magneto-transport and polar Kerr microscopy. Notably, we observe a topological Hall-like signal in the vicinity of the compensation temperature, a feature often interpreted as evidence for skyrmions in the absence of direct imaging. Here, in contrast, complementary Kerr microscopy reveals instead a non-collinear multidomain state which collapses outside the compensation regime, correlating directly with the appearance and disappearance of the spin Hall topological Hall effect (SH-THE) signal. These observations cannot be accounted for by a simple multi-anomalous-Hall-effect model, ruling out common artifacts as the origin, but indicate the presence of a topologically non-trivial contribution to the Hall response. These results establish strained REIG films as a tunable platform for exploring topological responses arising from compensation-driven non-collinear ferrimagnetic phases.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11721v1",
        "authors": [
          "Mehak Loyal",
          "Akashdeep Akashdeep",
          "Edoardo Mangini",
          "Edgar Galíndez-Ruales",
          "Maja Eich"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "REIG",
        "Act",
        "THE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.341496"
    },
    {
      "id": "arxiv-2602.11709v1",
      "title": "Rust-accelerated powder X-ray diffraction simulation for high-throughput and machine-learning-driven materials science",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11709v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-throughput powder X-ray diffraction (XRD) simulations are a key prerequisite for generating large datasets used in the development of machine-learning models for XRD-based materials analysis. However, the widely used pymatgen powder XRD calculator, implemented entirely in Python, can be computationally inefficient for large-scale workloads, limiting throughput. We present XRD-Rust, a Rust-accelerated implementation of the pymatgen powder XRD calculator that maintains full compatibility with existing Python-based workflows. The method retains pymatgen for crystal structure handling and symmetry analysis while reimplementing the computationally intensive parts of the XRD calculation in Rust. Performance benchmarks were carried out on large crystallographic datasets from the Materials Cloud Three-Dimensional Structure Database (MC3D, 33 142 structures) and the Crystallography Open Database (COD 515 181). For the MC3D dataset, XRD-Rust achieves an average speedup of 4.7 +- 1.6 and a maximum speedup of 25, reducing computation from 34.9 s to 1.4 s. For the COD dataset, the average speedup is 6.1 +- 4.6 with a maximum speedup of 719 (1437 min to 2 min). These benchmarks demonstrate that XRD-Rust significantly accelerates powder XRD simulations, enabling efficient high-throughput dataset generation and improved performance in interactive diffraction analysis applications.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11709v1",
        "authors": [
          "Miroslav Lebeda",
          "Jan Drahokoupil",
          "Petr Veřtát",
          "Petr Vlčák"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Structure Database",
        "Crystallography Open Database",
        "Materials Cloud Three",
        "Act",
        "COD",
        "MIT",
        "XRD",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.341890"
    },
    {
      "id": "arxiv-2602.11696v1",
      "title": "Symmetry Spans and Enforced Gaplessness",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11696v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Anomaly matching for continuous symmetries has been the primary tool for establishing symmetry enforced gaplessness - the phenomenon where global symmetry alone forces a quantum system to be gapless in the infrared. We introduce a new mechanism based on \\textit{symmetry spans}: configurations in which a global symmetry $\\mathcal{E}$ is simultaneously embedded into two larger symmetries, as $\\mathcal{D}\\hookleftarrow\\mathcal{E}\\hookrightarrow\\mathcal{C}$. Any gapped phase with the full symmetry must, upon restriction to $\\mathcal{E}$, arise as the restriction of both a gapped $\\mathcal{C}$-symmetric phase and a gapped $\\mathcal{D}$-symmetric phase. When no such compatible phase exists, gaplessness is enforced. This mechanism can operate with only discrete and non-anomalous continuous symmetries in the UV, both of which admit well-understood lattice realizations. We construct explicit symmetry spans enforcing gaplessness in 1+1 dimensions, exhibit their realization in conformal field theories, and provide lattice Hamiltonians with the relevant symmetry embeddings.",
        "keywords": [
          "cond-mat.str-el",
          "hep-th",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11696v1",
        "authors": [
          "Takamasa Ando",
          "Kantaro Ohmori"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "hep-th",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enforced Gaplessness Anomaly",
        "Symmetry Spans",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.342192"
    },
    {
      "id": "arxiv-2602.11694v1",
      "title": "Emergent spin-resolved electronic charge density waves and pseudogap phenomena from strong $d$-wave altermagnetism",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11694v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Inspired by recent discovery of metallic $d$-wave altermagnetism in KV$_2$Se$_2$O, we develop a self-consistent microscopic many-body calculation of density-wave order for an itinerant altermagnetic metal. We show that the strong $d$-wave spin-momentum locking inherent to the altermagnetic band structure reconstructs the Fermi surface into spin-selective quasi-1D open sheets. This unique topology of Fermi surface drives an instability toward spin-resolved electronic charge density waves (CDWs), in which the ordering wave vectors for spin-up and spin-down electrons condense along two mutually orthogonal directions, forming spin-resolved stripe phases. As a consequence, this results in pronounced gap openings near the Fermi surface, and the superposition of these spin-resolved stripe orders leads to a checkerboard CDW in the charge channel and an antiphase spin-density-wave modulation in the spin channel. Upon increasing temperature, the density-wave order melts at $T_c$ due to thermal phase fluctuation while the gap opening persists, giving rise to a robust pseudogap regime, which eventually closes at a higher temperature $T_g$. The resulting simulations quantitatively reproduce the key features observed in the spectroscopic measurements, offering a consistent and generic understanding of the reported phenomena in KV$_2$Se$_2$O and, more broadly, in metallic altermagnets with strong spin-momentum locking.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11694v1",
        "authors": [
          "Fei Yang",
          "Guo-Dong Zhao",
          "Binghai Yan",
          "Long-Qing Chen"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "CDW",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.342655"
    },
    {
      "id": "arxiv-2602.11647v1",
      "title": "Ordered states of undoped AB bilayer graphene: bias induced cascade of transitions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11647v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Using mean-field theory, we determine the electronic phase diagram of undoped AB-stacked bilayer graphene in the presence of a transverse electric field. In addition to multiple competing electronic instabilities characterized by excitonic order parameters, our framework incorporates the long-range Coulomb energy associated with interlayer polarization. This long-range interaction plays a crucial role, as it significantly influences both the structure and the relative energies of the competing ordered states. We derive a set of self-consistency equations and solve them both numerically and analytically. Our findings reveal that, as the bias field is varied, the bilayer undergoes a cascade of first-order transitions between several ordered insulating phases for which order-parameter structures are explicitly identified. Some of these phases are characterized by two inequivalent single-particle gaps, whose magnitudes depend on the valley and spin quantum numbers. Field-driven transitions are accompanied by discontinuous and non-monotonic variations of the single-electron gap. We relate our results to Hartree-Fock numerical calculations and to experimental research, including observations of fractional metallic phases that emerge upon doping the bilayer system.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11647v1",
        "authors": [
          "A. V. Rozhkov",
          "A. O. Sboychakov",
          "A. L. Rakhmanov"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Meta",
        "Act",
        "WHO",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.343006"
    },
    {
      "id": "arxiv-2602.11645v1",
      "title": "Epitaxial Growth and Anomalous Hall Effect in High-Quality Altermagnetic $α$-MnTe Thin Films",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11645v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The recent identification of $α$-MnTe as a candidate altermagnet has attracted considerable interest, particularly for its potential application in magnetic random-access memory. However, the development of high-quality thin films - essential for practical implementation - has remained limited. Here, we report the epitaxial growth of centimeter-scale $α$-MnTe thin films on InP(111) substrates via molecular beam epitaxy (MBE). Through X-ray diffraction (XRD) analysis, we construct a MnTe phase diagram that provides clear guidance for stabilizing the pure $α$-MnTe phase, revealing that it is favored under high Te/Mn flux ratios and elevated growth temperatures. Cross-sectional electron microscopy confirms an atomically sharp film-substrate interface, consistent with a layer-by-layer epitaxial growth mode. Remarkably, these high-quality $α$-MnTe films exhibit a pronounced anomalous Hall effect (AHE) originating from Berry curvature, despite a net magnetic moment approaching zero - a signature of robust altermagnetic character. Our work establishes a viable route for synthesizing wafer-scale $α$-MnTe thin films and highlights their promise for altermagnet-based spintronics and magnetic sensing.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11645v1",
        "authors": [
          "Tian-Hao Shao",
          "Xingze Dai",
          "Wenyu Hu",
          "Ming-Yuan Zhu",
          "Yuanqiang He"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quality Altermagnetic",
        "Anomalous Hall Effect",
        "Epitaxial Growth",
        "Act",
        "MIT",
        "AHE",
        "XRD",
        "MBE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.343832"
    },
    {
      "id": "arxiv-2602.11637v1",
      "title": "First-order phase transition in atom-molecule quantum degenerate mixtures with coherent three-body recombination",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11637v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We map the phase diagram of a two-mode atom-molecule Bose-Einstein condensate with Fano-Feshbach and coherent three-body recombination (cTBR) terms. The standard second order phase transition observed as the molecular energy is tuned through the Feshbach resonance, is replaced by a first order transition when cTBR becomes prominent, due to a double-well structure in the free energy landscape. This transition is associated with atom-molecule entanglement, bistability, and molecular metastability. Our results establish cTBR as a powerful knob for quantum state engineering and control of reaction dynamics in ultracold chemistry.",
        "keywords": [
          "cond-mat.quant-gas",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11637v1",
        "authors": [
          "G. A. Bougas",
          "A. Vardi",
          "H. R. Sadeghpour",
          "C. Chin",
          "S. I. Mistakidis"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Meta",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.344056"
    },
    {
      "id": "arxiv-2602.11634v1",
      "title": "Spin-Chain Incipient Magnetocaloric Effect and Rare-Earth Controlled Switching in the Haldane-Chain System, R2BaNiO5",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11634v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We have experimentally investigated the magnetocaloric effect (MCE) of a prototype spin-frustrated one-dimensional spin-chain system, the famous Haldane-chain system, R2BaNiO5 (R = Nd, Gd, Er, Dy). The significant MCE is observed far above long-range ordering, even in the paramagnetic region, which is attributed to the change in magnetic entropy due to short-range spin correlation arising from (low-dimensional) magnetic frustration. Such a spin-chain incipient MCE above long-range ordering is rarely reported. Interestingly, multiple magnetocaloric switching from conventional to inverse MCE (and vice versa) are observed below long-range magnetic ordering, as a function of temperature and magnetic field, for the R = Nd, Dy, and Er members. However, such MCE switching is absent in the Gd member, which is an S-state atom (orbital moment L = 0). Our systematic investigation of this series demonstrates that the interplay between crystal-electric field (CEF), strong spin-orbit coupling (SOC) and rare earth anisotropy of R-ions play an important role in spin reorientation, leading to multiple MCE switching due to intriguing changes in magnetic and lattice entropy. The maximum change of entropy for Er, Gd, Dy and Nd is 7.8, 6.8, 4.0 and 1.0 J Kg-1 K-1 respectively. Our study presents a pathway for tuning MCE switching and the MCE effect over large temperature regions in d-f coupled spin-frustrated and spin-chain oxide systems.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11634v1",
        "authors": [
          "Mohit Kumar",
          "Gourab Roy",
          "Sayan Ghosh",
          "Ekta Kushwaha",
          "Kiran Singh"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chain Incipient Magnetocaloric Effect",
        "Earth Controlled Switching",
        "Chain System",
        "Kg-1",
        "CEF",
        "SOC",
        "K-1",
        "MCE",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:53:57.344477"
    },
    {
      "id": "arxiv-2602.12266v1",
      "title": "Repulsive Gravitational Force as a Witness of the Quantum Nature of Gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12266v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We show that a single spatially superposed 'source' mass acting on a 'probe' matter wavepacket can reveal the quantum nature of the gravitational field. For this we use a specific state preparation and measurement of the superposed source mass, including a postselection, which altogether results in a repulsive gravitational force on the probe particle. A classical gravitational field can never lead to repulsion, as the effect requires quantum interference of two distinct states of gravity. We also present a calculation in the Heisenberg picture under the formalism of weak values that illustrates how repulsion is achieved. Finally, we estimate the range of parameters (masses and the spatio-temporal extent of interference) for which the experiment is feasible.",
        "keywords": [
          "quant-ph",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12266v1",
        "authors": [
          "Pablo L. Saldanha",
          "Chiara Marletto",
          "Vlatko Vedral"
        ],
        "arxiv_categories": [
          "quant-ph",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Repulsive Gravitational Force",
        "Quantum Nature",
        "Gravity We",
        "Act",
        "EPA",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.520221"
    },
    {
      "id": "arxiv-2602.12263v1",
      "title": "Systematic Operator Construction for Non-relativistic Effective Field Theories: Hilbert Series versus Young Tensor",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12263v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This work establishes a systematic framework for operator construction in the non-relativistic effective field theory, incorporating both the three dimensional Euclidean symmetry and the internal symmetries. By employing double cover of the rotation group, we extend the Hilbert series to the non-relativistic systems, and eliminates redundancies introduced by the spin operator. We also generalize the Young tensor method to the non-relativistic cases through the $SU(2)$ semi-standard Young tableaux, which allows for the construction of operator bases with repeated fields at any given mass dimension. Utilizing the Young tensor technique and Hibert series as cross-check, we obtain the complete operator bases for the following cases: heavy particle (and also heavy quark) effective theory operators up to mass dimension 9; pion-less effective theory operators, including nucleon-nucleon contact interactions up to $\\mathcal{O}(Q^4)$ and three-nucleon interactions at $\\mathcal{O}(Q^2)$; and finally the spin-1/2 dark matter-nucleon operators up to $\\mathcal{O}(v^4)$.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12263v1",
        "authors": [
          "Yong-Kang Li",
          "Yi-Ning Wang",
          "Jiang-Hao Yu"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Systematic Operator Construction",
        "Hilbert Series",
        "Framework",
        "Standard",
        "BERT",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.520679"
    },
    {
      "id": "arxiv-2602.12210v1",
      "title": "Stress stability criterion of $U(1)$ gauged non-topological solitons in the 3+1 dimensional O(3) sigma-model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12210v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the energy-momentum tensor of the spherically symmetric non-topological solitons of the $O(3)$ non-linear sigma-model with a standard kinetic term and with a symmetry breaking potential in 3+1 dimensional flat space-time. We evaluate the distributions of the corresponding energy density, shear forces and pressure and study the stability criteria for these solutions. We argue that the presence of domains with negative energy density and violation of the energy conditions most likely do not lead to destabilization of solitons.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12210v1",
        "authors": [
          "Aliaksei Mikhaliuk",
          "Yakov Shnir"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.521080"
    },
    {
      "id": "arxiv-2602.12197v1",
      "title": "Holographic entanglement entropy in Chern-Simons gravity with torsion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12197v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Holographic entanglement entropy is a key concept linking quantum information theory and gravity. Since the original conjecture of Ryu and Takayanagi, holographic entanglement entropy has been generalized beyond Einstein--Hilbert gravity to include higher-curvature corrections. In most existing generalizations, however, it is implicitly assumed that the bulk spacetime geometry is Riemannian, i.e. torsion-free. Here we propose a prescription for incorporating torsion into holographic entanglement entropy in the boundary theory dual to five-dimensional Chern--Simons gravity. We argue that the entanglement entropy acquires an additional universal divergent term proportional to the logarithm of the UV cutoff, and that this term is generated solely by torsion.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12197v1",
        "authors": [
          "Dušan Đorđević",
          "Dragoljub Gočanin"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.521402"
    },
    {
      "id": "arxiv-2602.12184v1",
      "title": "One-, two-, and three-dimensional photon femtoscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12184v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Femtoscopy with photon pairs is a particularly attractive tool for studying high-energy nuclear collisions. Proposed and extensively discussed in several influential theory articles, it has seen only few applications in experiment because of statistics limitations. With the progress of detectors and electronics, only now it is coming within reach. In this paper we discuss the choice of kinematic variables for two-photon correlation functions. In particular, we argue against $C(Q_{\\rm inv})$ and in favor of $C(ΔE,Q_{\\rm inv})$.",
        "keywords": [
          "nucl-ex",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12184v1",
        "authors": [
          "Dariusz Miśkowiec",
          "Klaus Reygers"
        ],
        "arxiv_categories": [
          "nucl-ex",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nuclear",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.521916"
    },
    {
      "id": "arxiv-2602.12176v1",
      "title": "Single-minus gluon tree amplitudes are nonzero",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12176v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Single-minus tree-level $n$-gluon scattering amplitudes are reconsidered. Often presumed to vanish, they are shown here to be nonvanishing for certain \"half-collinear\" configurations existing in Klein space or for complexified momenta. We derive a piecewise-constant closed-form expression for the decay of a single minus-helicity gluon into $n-1$ plus-helicity gluons as a function of their momenta. This formula nontrivially satisfies multiple consistency conditions including Weinberg's soft theorem.",
        "keywords": [
          "hep-th",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12176v1",
        "authors": [
          "Alfredo Guevara",
          "Alexandru Lupsasca",
          "David Skinner",
          "Andrew Strominger",
          "Kevin Weil"
        ],
        "arxiv_categories": [
          "hep-th",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.522127"
    },
    {
      "id": "arxiv-2602.12167v1",
      "title": "Time-Structured Tail Probabilities for Ultra-High-Energy Gamma-Hadron Discrimination in Water-Cherenkov Arrays",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12167v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Gamma-hadron discrimination based on shower observables is essential for identifying gamma-ray astrophysical sources at the highest energies. In this work, we introduce $P^{α, T}_{\\rm tail}$, a new discrimination variable for ultra-high-energy photon searches within the framework of a water-Cherenkov detector (WCD) array. The observable extends signal-integrated methods by incorporating the time structure of WCD traces, using cumulative signal distributions. Using simulated proton- and gamma-induced air showers at energies around $10^{17}\\,\\mathrm{eV}$, we evaluate the performance of $P^{α, T}_{\\rm tail}$ and compare it with established WCD-based observables such as $S_b$, risetime-based variables, and the SWGO-inspired, $P^α_{\\rm tail}$. The new variable attains a background contamination of roughly $2 \\times 10^{-2}$ at $50\\%$ gamma efficiency, improving upon existing WCD-only methods by nearly a factor of five and approaching the performance of an idealized muon-isolating reference. These results demonstrate the effectiveness of exploiting time-resolved signal tails to enhance ultra-high-energy photon searches in sparse surface arrays.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12167v1",
        "authors": [
          "Ruben Conceição",
          "Pedro J. Costa",
          "Mário Pimenta"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structured Tail Probabilities",
        "Cherenkov Arrays Gamma",
        "Hadron Discrimination",
        "Energy Gamma",
        "Framework",
        "SWGO",
        "Act",
        "WCD",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.523020"
    },
    {
      "id": "arxiv-2602.12154v1",
      "title": "Resurrecting Kaluza-Klein Dark Matter with Low-Temperature Reheating",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12154v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In Universal Extra Dimension (UED) scenarios, the lightest Kaluza-Klein (KK) particle is naturally stable due to a remnant discrete symmetry, KK parity, arising from extra-dimensional compactification. This stability requires no ad hoc symmetry and renders Kaluza-Klein dark matter a well-motivated candidate, provided it reproduces the observed relic abundance. The minimal UED (mUED) framework being highly predictive is strongly constrained by the combined requirements of relic density and collider searches under standard cosmological assumptions. We revisit the dark matter phenomenology of mUED in the presence of a nonstandard cosmological history featuring a low reheating temperature driven by prolonged inflaton decay. Solving the coupled Boltzmann equations for dark matter, radiation, and inflaton energy densities, we show that entropy injection during reheating can dilute the relic abundance by orders of magnitude, reopening large regions of parameter space previously ruled out. We further demonstrate that the revived parameter space is consistent with current collider, direct-detection, and indirect-detection constraints, while remaining testable by upcoming experiments.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12154v1",
        "authors": [
          "Kirtiman Ghosh",
          "Abhishek Roy",
          "Rameswar Sahu"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Temperature Reheating In Universal",
        "Resurrecting Kaluza",
        "Klein Dark Matter",
        "Extra Dimension",
        "Framework",
        "Standard",
        "Act",
        "UED",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.523470"
    },
    {
      "id": "arxiv-2602.12148v1",
      "title": "Resonating group method for baryon-baryon interactions with unequal oscillator frequencies and its application to the $NΔ$ system in a chiral quark model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12148v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The resonating group method (RGM) is widely used to investigate baryon-baryon interactions at the quark level, typically under the assumption that the two baryons involved share an identical harmonic-oscillator frequency. In reality, however, when a specific interaction Hamiltonian is given, different baryons should have unequal oscillator frequencies due to distinct interaction potentials induced by their different quantum numbers. In this work, we develop a new quark-level RGM formalism for baryon-baryon systems with unequal oscillator frequencies, with the aim of describing both single baryons and baryon-baryon interactions in a consistent framework. We present the formalism for solving bound-state and scattering problems, with particular emphasis on constructing the wave functions of two-baryon systems with unequal oscillator frequencies. The proposed formalism is then applied to the $NΔ$ system within a chiral SU(3) quark model, where the quark-quark interaction includes, in addition to the one-gluon exchange (OGE) and a phenomenological confinement potential, the nonet scalar and pseudoscalar meson exchanges arising from the spontaneous breaking of chiral SU(3) symmetry. The distinctive features of the newly developed formalism are elucidated by comparing the results from the new formulation with those from traditional calculations.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12148v1",
        "authors": [
          "Ke-Rang Song",
          "Fei Huang"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "RGM",
        "OGE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.524526"
    },
    {
      "id": "arxiv-2602.12145v1",
      "title": "Spin networks of quantum channels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12145v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Spin networks in Loop Quantum Gravity are traditionally described by unitary holonomies corresponding to noiseless transformations. In this work, we extend this framework to incorporate general quantum channels that model effects of environment, which can become significant at the Planck scale. Specifically, we demonstrate that the transformation properties of Kraus operators, which define completely positive trace-preserving (CPTP) maps, are consistent with the gauge invariance of spin networks. This enables the introduction of generalized spin network states that can be expressed in terms of the Kraus operators. Furthermore, the associated notion of an inner product is proposed, allowing for introduction of the Hilbert space. We illustrate these constructions with examples involving a Wilson loop and a dipole network.",
        "keywords": [
          "gr-qc",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12145v1",
        "authors": [
          "Bartosz Grygielski",
          "Jakub Mielczarek"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Loop Quantum Gravity",
        "Framework",
        "BERT",
        "CPTP",
        "NSF",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.524819"
    },
    {
      "id": "arxiv-2602.12119v1",
      "title": "Studies of low energy $l+p\\to l+p+γ$ process in covariant chiral perturbation theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12119v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This study presents a tree-level calculation of the scattering amplitude for the $lp\\to lpγ$ (with a hard photon) process within the framework of Chiral Perturbation Theory. Our calculations, based on the $O(p^2)$ and $O(p^3)$ nucleon-pion Lagrangians, aim to provide a theoretical prediction for the differential cross-section. The result shows that explicit inclusion of the nonzero lepton mass significantly influences the low energy differential cross section for $μp\\to μp γ$ process. The kinematic region of the present experimental data is beyond the validity domain of the $χ$PT and is therefore not suitable for determining the low-energy constants (LECs). By comparing our results with future experimental data, we expect to determine the values of the LECs as a further test of $χ$PT as an effective low-energy theory of QCD. The process is of significant interest as it can help to determine the generalized polarizabilities of the nucleon.",
        "keywords": [
          "hep-ph",
          "hep-ex",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12119v1",
        "authors": [
          "Xu Wang",
          "Kai-Ge Kang",
          "Zhiguang Xiao",
          "Han-Qing Zheng"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "QCD",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.525480"
    },
    {
      "id": "arxiv-2602.12101v1",
      "title": "Black Holes Trapped by Ghosts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12101v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Violent cosmic events, from black hole mergers to stellar collapses, often leave behind highly excited black hole remnants that inevitably relax to equilibrium. The prevailing view, developed over decades, holds that this relaxation is rapidly filtered into a linear regime, establishing linear perturbation theory as the bedrock of black hole spectroscopy and a key pillar of gravitational-wave physics. Here we unveil a distinct nonlinear regime that transcends the traditional paradigm: before the familiar linear ringdown, an intrinsically nonlinear, long-lived bottleneck can dominate the evolution. This stage is controlled by a saddle-node ghost in phase space, which traps the remnant and delays the onset of linearity by a timescale obeying a universal power-law. The ghost imprints a distinctive quiescence-burst signature on the emitted radiation: a prolonged silence followed by a violent burst and a delayed ringdown. Rooted in the bifurcation topology, it extends naturally to neutron and boson stars, echoing a topological universality shared with diverse nonlinear systems in nature. Our results expose a missing nonlinear chapter in gravitational dynamics and identify ghost-induced quiescence-burst patterns as clear targets for future observations.",
        "keywords": [
          "gr-qc",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12101v1",
        "authors": [
          "Cheng-Yong Zhang",
          "Yunqi Liu",
          "Bin Wang"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Black Holes Trapped",
        "Ghosts Violent",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.525895"
    },
    {
      "id": "arxiv-2602.12094v1",
      "title": "Elliptic flow of strange and multi-strange hadrons in isobar collisions at $\\sqrt{s_{\\mathrm {NN}}} = 200\\mathrm{~GeV}$ at RHIC",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12094v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We report a systematic measurement of elliptic flow ($v_{2}$) of $K_{s}^{0}$, $Λ$, $\\overlineΛ$, $φ$, $Ξ^{-}$, $\\overlineΞ^{+}$, and $Ω^{-}$+$\\overlineΩ^{+}$ at mid-rapidity ($|y| < 1.0$) for isobar, $^{96}_{44}$Ru+$^{96}_{44}$Ru and $^{96}_{40}$Zr+$^{96}_{40}$Zr, collisions at $\\sqrt{s_{\\mathrm {NN}}}$ = 200 GeV. The transverse momentum ($p_\\mathrm{T}$) dependence of $v_{2}$ is studied for various centrality classes. The number of constituent quark scaling of (multi-)strange hadrons is found to hold approximately within 20%, suggesting the development of partonic collectivity in isobar collisions similar to that observed in Au+Au collisions at $\\sqrt{s_{\\mathrm {NN}}}$ = 200 GeV. The average $v_{2}$ ratio shows $\\sim$2% deviation from unity in central and mid-central collisions for strange hadrons, indicating a difference in nuclear structure and deformation between the isobars. The $v_{2}$ in isobaric collisions is compared to Cu+Cu, Au+Au, and U+U collisions at similar collision energies. We observe an increase in $v_{2}(p_\\mathrm{T})$ with increasing system size. The difference in $v_{2}$ between the isobar and other collision systems increases with $p_\\mathrm{T}$. The results are compared with a multi-phase transport model calculations with a deformed density profile to provide further insight into the nuclear structure of these isobars.",
        "keywords": [
          "nucl-ex",
          "hep-ex",
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12094v1",
        "authors": [
          " The STAR Collaboration"
        ],
        "arxiv_categories": [
          "nucl-ex",
          "hep-ex",
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nuclear",
        "RHIC",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.526773"
    },
    {
      "id": "arxiv-2602.12088v1",
      "title": "GAN-based data augmentation for rare and exotic hadron searches in Pb--Pb collisions in ALICE",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12088v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This work presents a feasibility study aimed at enhancing the reconstruction sensitivity for rare heavy-flavour hadrons in Pb-Pb collisions in the ALICE experiment, using the $Ξ_{c}^{+}$ baryon as a benchmark. The $Ξ_{c}^{+}$ baryon has a low rate of production and some complex decay topologies as for instance the decay $Ξ_{c}^{+} \\rightarrow Ξ^{-} + π^{+} + π^{+}$ considered in this work. Traditional simulation workflows involving event embedding and full detector response are computationally expensive and statistically limited, especially for rare signals. This study represents the first exploration of generative models within the heavy-flavour programme of ALICE. It uses a dataset of reconstructed physics quantities, such as momenta, positions, and decay vertex coordinates of $Ξ_{c}^{+}$ decay products in Pb-Pb collisions as input features, derived from augmented ALICE Monte Carlo simulations. Such features will serve as a training set for Generative Adversarial Networks (GANs) designed to generate statistically significant synthetic signal samples without the need for additional full simulations. While $Ξ_{c}^{+}$ serves as a benchmark, the broader objective is to enable searches for exotic heavy-flavour hadrons or other exotic states with complex decay patterns. By leveraging GAN-based augmentation, this approach supports rare-signal extraction in computationally demanding analyses and opens the way to broader applications of generative models in the ALICE heavy-flavour programme.",
        "keywords": [
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12088v1",
        "authors": [
          "Anisa Khatun"
        ],
        "arxiv_categories": [
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generative Adversarial Networks",
        "Monte Carlo",
        "ALICE",
        "Act",
        "MIT",
        "GAN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.527735"
    },
    {
      "id": "arxiv-2602.12057v1",
      "title": "Primordial Black Hole Formation in Dust-Radiation Bouncing Cosmologies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12057v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Primordial black holes (PBHs) provide a unique probe of the early Universe and may have an enhanced abundance in bouncing cosmologies, where a long contracting phase can amplify perturbations. We develop a unified framework to study PBH formation in dust-radiation bouncing cosmologies, focusing on the classical contracting phase so that the results are insensitive to bounce details. We compute the curvature power spectrum for an extremely small dust equation of state using a stable semi-analytical (adiabatic) method, derive the Jeans length of the two-fluid system using dynamical-system analysis and the WKB approximation, and extend the three-zone model from the single- to the two-fluid case to model local collapse. We implement two collapse criteria to obtain the curvature perturbation threshold for PBH formation and estimate PBH mass fractions for benchmark masses spanning low-mass ($10^{-17} M_{\\odot}$) to supermassive ($10^{13} M_{\\odot}$) scales. The critical curvature threshold is extremely small and nearly mass-independent over a broad range $(ζ_c \\sim 10^{-21}$ for $10^{-14}$ to $10^{13} M_{\\odot})$, with deviations only near dust-radiation equality. Nevertheless, the square root of the curvature power spectrum at the relevant formation times is many orders of magnitude smaller, yielding vanishingly small PBH mass fractions across the benchmark masses. Compared with the pure-dust case, radiation pressure and the two-fluid collapse conditions significantly suppress PBH production, implying that substantial PBH formation in dust-radiation bouncing cosmologies would require additional mechanisms to amplify curvature perturbations.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12057v1",
        "authors": [
          "Xuan Ye",
          "Luiz Felipe Demetrio",
          "Eduardo Jose Barroso",
          "Shen-Feng Yan",
          "Nelson Pinto-Neto"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Radiation Bouncing Cosmologies Primordial",
        "Primordial Black Hole Formation",
        "Framework",
        "Act",
        "PBH",
        "WKB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.528857"
    },
    {
      "id": "arxiv-2602.12025v1",
      "title": "Study of multi-particle states with tensor renormalization group method",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12025v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the multi-particle states of the (1+1)-dimensional Ising model using a spectroscopy scheme based on the tensor renormalization group method. We start by computing the finite-volume energy spectrum of the model from the transfer matrix, which is numerically estimated using the coarse-grained tensor network. We then identify the quantum number and momentum of the eigenstates by using the symmetries of the system and the matrix elements of an appropriate interpolating operator. Next, we plot the energy for a particular quantum number and momentum as a function of system size to identify the number of particles in the corresponding energy eigenstates. With this method, we obtain one-, two-, and three-particle states. We also compute the two-particle scattering phase shift using Lüscher's formula as well as the wave function approach, and compare the results with the exact prediction.",
        "keywords": [
          "hep-lat"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12025v1",
        "authors": [
          "Fathiyya Izzatun Az-zahra",
          "Shinji Takeda",
          "Takeshi Yamazaki"
        ],
        "arxiv_categories": [
          "hep-lat"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.529444"
    },
    {
      "id": "arxiv-2602.12022v1",
      "title": "Dark matter distributions around extreme mass ratio inspirals: effects of radial pressure and relativistic treatment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12022v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate different treatments of dark matter (DM) distributions surrounding extreme mass ratio inspirals (EMRIs) to assess their impact on orbital evolution and gravitational wave emission. Density profiles derived from the mass current and from the energy-momentum tensor using a distribution function yield consistent results, but both differ substantially from profiles obtained using an anisotropic fluid model based on Einstein cluster ansatz. We find that the inclusion of radial pressure significantly modifies both the orbital dynamics and the resulting gravitational wave waveforms. By analyzing waveform dephasing and mismatches, we show that a fully relativistic treatment of DM distributions can substantially alter the detectability thresholds of DM halos. Our results demonstrate that radial pressure and relativistic modeling of DM are essential for accurately describing the dynamics and observational signatures of EMRIs embedded in DM halos.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12022v1",
        "authors": [
          "Yang Zhao",
          "Yungui Gong"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.529734"
    },
    {
      "id": "arxiv-2602.12010v1",
      "title": "Existence of the $DD^*\\bar{K}^*$ and $BB^*K^*$ three-body molecular states",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12010v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We investigate the existence of the three-body molecular state composed of $DD^*\\bar{K}^*$ within the one-boson-exchange (OBE) model. A major challenge is that while the pseudoscalar-meson couplings are well-determined, the couplings for scalar- and vector-meson exchanges render significant model dependence. To ensure the reliability of our predictions and reduce model dependence, we recalibrate the coupling constants of the OBE model. We treat the pole position of $Z_c(3900)$, or equivalently the scalar $σ$-exchange coupling constant, as the only unknown parameter. The coupling constants for the vector $ρ$- and $ω$-exchanges are determined by the pole positions of the well established states $X(3872)$ and $T_{cc}(3875)$. We demonstrate that these parameter sets also successfully describe the $T_{cs0}(2870)$ without further tuning. For the three-body system, our results indicate that an $I\\left(J^P\\right)=1 / 2\\left(0^{-}\\right)$ three-body molecular bound state exists when $Z_c(3900)$ is a virtual state located within approximately $-10~\\text{MeV}$ of the $D\\bar{D}^*$ threshold. Furthermore, we extend our analysis to the complex energy plane using the complex scaling method to search for molecular resonances, though no evidence of resonances is found in considered channels. We also apply this formalism to the bottom analog $BB^*K^*$ system. In this sector, the conditions for the existence of a three-body bound state are more relaxed, as a $Z_c(3900)$ virtual state located within $-25~\\text{MeV}$ below the threshold suffices, although three-body molecular resonances remain absent. We suggest that future experiments precisely measure the pole position of $Z_c(3900)$ or search for the three-body bound state in $DD\\bar{K}ππ$ and $DD\\bar{K}$ channels, as these efforts would mutually illuminate the nature of the associated states.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12010v1",
        "authors": [
          "Yan-Ke Chen",
          "Lu Meng",
          "Jun-Zhang Wang",
          "Shi-Lin Zhu"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "OBE",
        "UN",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.530933"
    },
    {
      "id": "arxiv-2602.11997v1",
      "title": "Recent progress in decays of $b$ and $c$ hadrons",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11997v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In the last ten years there has been great progress in calculations of decays of $B$ and $D$ mesons, and baryons containing a heavy $b$ or $c$ quark. One propelling factor has been the measurement of several anomalies in $b\\to s$ and $b\\to c$ transitions, these are one of the only signs of physics beyond the Standard Model. The deviations included measurements of branching ratios, angular observables and lepton universality ratios. Another factor is the exclusive-inclusive discrepancy in the determination of the CKM elements $V_{ub}$ and $V_{cb}$. We will first review recent calculations involving $b\\to s$ and $c\\to u$ transitions that could shed light on the neutral current anomalies. We will then summarise the progress the determination of the CKM elements, $V_{ub}$ and $V_{cb}$. Finally we will discuss the current theoretical status and experimental prospects for the lepton universality ratios in $b\\to s$ and $b\\to c$ semileptonic decays.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11997v1",
        "authors": [
          "Aoife Bharucha"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard Model",
        "Standard",
        "Act",
        "EPA",
        "CKM",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.531233"
    },
    {
      "id": "arxiv-2602.11996v1",
      "title": "Medium effects on light clusters from heavy-ion collisions within a relativistic mean-field description",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11996v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Central $^{136,124}$Xe$+^{124,112}$Sn collisions from INDRA data are analysed using a Bayesian inference on light nuclei multiplicities to estimate the thermodynamical parameters and in-medium modification of the cluster self-energies within a relativistic mean-field model. An excellent description of experimentally measured abundances of H and He isotopes is obtained. We examine two possible modelling of in-medium effects as an increased in-medium effective mass, or an increased vector repulsion. We show that these physical pictures cannot be discriminated by the data. In both cases, the temperature dependence of the meson couplings leads to a faster weakening of the light cluster abundances with temperature than previous studies predicted. Possible systematic errors due to out-of-equilibrium effects affecting the experimental abundances, are considered by repeating the Bayesian inference with reduced information. The abundance prediction of the species excluded from the constraint is well compatible with the experimental data, suggesting that there is no a priori need of accounting for non-equilibrium effects or finite state interactions that potentially affect the deuteron yield.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11996v1",
        "authors": [
          "Tiago Custódio",
          "Francesca Gulminelli",
          "Alex Rebillard-Soulié",
          "Diego Gruyer",
          "Rémi Bougault"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "INDRA",
        "Act",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.531597"
    },
    {
      "id": "arxiv-2602.11974v1",
      "title": "Measurement of the singly Cabibbo-suppressed decay $Λ_c^+\\to pη'$ with Deep Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11974v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Using $4.5$ fb$^{-1}$ of $e^+e^-$ collision data collected with the BESIII detector at center-of-mass energies from 4.600 to 4.699 GeV, we report a measurement of the singly Cabibbo-suppressed decay $Λ_c^+ \\to pη'$ with the single-tag method. To effectively distinguish the signal from the large backgrounds, we exploit a deep-learning classifier built on a Transformer-based neural network. Extensive validation and uncertainty quantification are carried out. The $Λ^+_c\\to pη'$ signal is observed with a statistical significance of $3.4 σ$. The ratio of branching fractions of $\\mathcal{B}{Λ^+_c\\to pη'}/\\mathcal{B}{Λ^+_c\\to pω}$= $0.55\\pm 0.22_{\\rm{stat.}} \\pm 0.05_{\\rm{syst.}}$ is obtained, where the first uncertainty is statistical and the second systematic.",
        "keywords": [
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11974v1",
        "authors": [
          " BESIII Collaboration",
          "M. Ablikim",
          "M. N. Achasov",
          "P. Adlarson",
          "X. C. Ai"
        ],
        "arxiv_categories": [
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deep Learning Using",
        "Neural Network",
        "Deep Learning",
        "Transformer",
        "BESIII",
        "Act",
        "NSF",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.533577"
    },
    {
      "id": "arxiv-2602.11927v1",
      "title": "Bosonic and fermionic statistics in nonperturbative quantum gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11927v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The relation between spin and statistics in quantum field theory relies on Poincaré invariance, a symmetry that is lost in the presence of a gravitational field, and replaced in general relativity by the principle of general covariance. In a nonperturbative approach to quantum gravity, beyond the picture of gravitational perturbations propagating on a flat background, it is an open question whether the gravitational field must still satisfy a bosonic statistics. By implementing the principle of general covariance through the requirement of invariance under active diffeomorphisms in loop quantum gravity, we find that the space of kinematical states of the gravitational field includes not only bosonic states, but also subspaces of fermionic and mixed statistics.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11927v1",
        "authors": [
          "Bekir Baytaş",
          "Patrick Rodrigues",
          "Nelson Yokomizo"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.534056"
    },
    {
      "id": "arxiv-2602.11888v1",
      "title": "Full Three-Loop Electroweak Multiplet Contributions to the Electron Electric Dipole Moment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11888v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Experimental sensitivity to the electric dipole moment (EDM) of the electron has improved remarkably in recent years. Consequently, future prospects could probe new physics whose contribution to the electron EDM first arises at three-loop order. Additional SU(2)$_L$ multiplets with CP-violating Yukawa interactions, which contribute to the electron EDM at three-loop level, is one such testable new physics scenario. In this scenario, the electron EDM is radiatively induced from two contributions: the CP-odd trilinear $W$-boson coupling, called the electroweak-Weinberg operator, and the CP-odd dipole operator of electron. The former and the latter operators are generated at two-loop and three-loop levels, respectively, after integrating out the SU(2)$_L$ multiplets. Within the same models, according to an analysis based on the Standard Model Effective Field Theory (SMEFT), we previously found that the contribution to the electron EDM from the electroweak-Weinberg operator can be probed in future experiments. However, the one-loop matching condition between the electron EDM and the electroweak-Weinberg operator does not receive a large logarithmic enhancement because the associated anomalous dimension is zero. The CP-odd dipole operator of the electron would contribute to the electron EDM at the same three-loop order as the contribution through the electroweak-Weinberg operator. In this paper, we directly calculate the electron EDM induced by the CP-violating Yukawa interactions of the SU(2)$_L$ multiplets at full three-loop level. A central result is that the full three-loop calculation is a factor of three larger than that of the electroweak-Weinberg operator alone.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11888v1",
        "authors": [
          "Tatsuya Banno",
          "Junji Hisano",
          "Teppei Kitahara",
          "Kiyoto Ogawa",
          "Naohiro Osamura"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Loop Electroweak Multiplet Contributions",
        "Electron Electric Dipole Moment",
        "Standard Model Effective Field",
        "Full Three",
        "Standard",
        "SMEFT",
        "Act",
        "WHO",
        "EDM",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.534500"
    },
    {
      "id": "arxiv-2602.11883v1",
      "title": "A unified framework for photon and massive particle hypersurfaces in stationary spacetimes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11883v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We revisit the notion of massive particle hypersurfaces and place it within a unified framework alongside photon hypersurfaces in stationary spacetimes. More precisely, for Killing-invariant timelike hypersurfaces $T=\\mathbb{R}\\times S_0$, where $S_0$ is a smooth embedded surface in a spacelike slice $S$ of the stationary spacetime, we show that $T$ is a photon hypersurface or a massive particle hypersurface if and only if $S_0$ is totally geodesic with respect to certain associated Finsler structures on the slice: a Randers metric governing null geodesics and a Jacobi--Randers metric governing timelike solutions of the Lorentz force equation at fixed energy and charge-to-mass ratio. We also prove existence and multiplicity results for proper-time parametrized solutions of the Lorentz force equation with fixed energy and charge-to-mass ratio, either connecting a point to a flow line of the Killing vector field or having periodic, non-constant projection on $S$.",
        "keywords": [
          "gr-qc",
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11883v1",
        "authors": [
          "Erasmo Caponio",
          "Anna valeria Germinario",
          "Antonio Masiello"
        ],
        "arxiv_categories": [
          "gr-qc",
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.534757"
    },
    {
      "id": "arxiv-2602.11879v1",
      "title": "Heavy-to-light Structure Functions at $\\mathcal{O}(α_s^3)$ in QCD",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11879v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present the first complete $\\mathcal{O}(α_s^2)$ and $\\mathcal{O}(α_s^3)$ perturbative QCD corrections to all five heavy-to-light structure functions underlying the triple-differential semi-leptonic decay rates of heavy quarks. This is achieved via a hybrid computational strategy that combines an efficient linear interpolation (with a suitable function basis) based on stratified Gauss-Kronrod points in the leptonic-mass $q^2$ with the differential equations in the other variable, further armed with reduced numerical $\\varepsilon$-dependence. Among the selected applications, we highlight the state-of-the-art prediction $Γ(B \\rightarrow X_u \\ell \\barν_{\\ell}) = \\frac{|V_{ub}|^2}{|3.82\\times 10^{-3}|^2}\\,\\big( 6.53 \\,\\pm 0.12 \\, \\pm 0.13\\, \\pm 0.03\\, \\big) \\times 10^{-16}\\,\\text{GeV}\\,$ derived in the kinetic-mass scheme. We report several notable observations regarding the convergence of the first three orders of QCD corrections to the $q^2$-spectrum and to inclusive moments of the lepton-energy spectrum in semi-leptonic weak decays of $b$- and $c$-quark in different quark-mass schemes; they are important both for improving the inclusive determinations of the relevant CKM elements, non-perturbative dynamical parameters, and for gaining new insights into the potential impact of high-order QCD corrections. Lastly we discuss a novel interesting point encountered in the consistent perturbative reformulation of the differential $q^2$-spectrum from the pole-mass to other mass schemes: certain boundary-effect terms are identified that are non-vanishing for $b \\rightarrow u \\ell \\barν_{\\ell}$ firstly at $\\mathcal{O}(α_s^3)$; their incorporation is essential to preserve the integrity of the integrated moments of the perturbatively re-expanded $q^2$-spectrum but necessitates histogramming from $\\mathcal{O}(α_s^3)$ onward even within pure perturbation theory.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11879v1",
        "authors": [
          "Long Chen",
          "Xiang Chen",
          "Xin Guan",
          "Yan-Qing Ma"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structure Functions",
        "Act",
        "CKM",
        "QCD",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.535766"
    },
    {
      "id": "arxiv-2602.11878v1",
      "title": "Effective Potential in Subleading Logarithmic Approximation in Arbitrary Non-renormalizable Scalar Field Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11878v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Following the previously developed approach to the calculation of quantum corrections to the effective potential in arbitrary scalar field theories in the leading logarithmic approximation, we extended it to the next-to-leading order. Based on Bogoliubov-Parasiuk-Hepp-Zimmerman renormalization procedure and the Bogoliubov-Parasiuk theorem, we construct recurrence relations and renormalization group equations that allow one to sum up the leading and subleading logarithms in all orders of perturbation theory. The formalism is applicable to an arbitrary scalar potential, renormalizable or not. To verify the results, we compare them with a renormalizable model treated within the standard renormalization group approach.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11878v1",
        "authors": [
          "R. M. Iakhibbaev",
          "D. I. Kazakov",
          "A. I. Mukhaeva",
          "D. M. Tolkachev"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Subleading Logarithmic Approximation",
        "Effective Potential",
        "Arbitrary Non",
        "Standard"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.535987"
    },
    {
      "id": "arxiv-2602.11828v1",
      "title": "Black holes in effective loop quantum gravity: Hawking radiation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11828v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Emergent modified gravity provides a covariant framework for holonomy effects in models of loop quantum gravity with consistent black hole solutions coupled to a scalar field. Several independent studies of the Hawking thermal distribution are shown here to lead to the same final result. This internal consistency is a direct consequence of general covariance, which is analogous to the situation in classical general relativity but highly nontrivial in the context of modified canonical gravity. Holonomy corrections to the evaporation rate enter through the greybody factor, slowing down the evaporation process when the holonomy modification function decreases monotonically. Accounting for backreaction, corrected covariant semi-classical stress-energy tensors are computed in various vacuum states. Thanks to these results, the new concept of a net stress-energy tensor makes it possible to compute evaporation rates directly from energy conservation laws.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11828v1",
        "authors": [
          "Idrus Husin Belfaqih",
          "Martin Bojowald",
          "Suddhasattwa Brahma",
          "Erick I. Duque"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.536238"
    },
    {
      "id": "arxiv-2602.11815v1",
      "title": "Two-Pion Exchange Contributions to the Nucleon-Nucleon Interaction from the Roper Resonance",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11815v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We derive the long-range components of the nucleon-nucleon (NN) two-pion-exchange potential with an intermediate Roper resonance. Leading-order interactions in heavy-baryon chiral perturbation theory are considered. NN phase shifts with orbital angular momentum $L\\geq 2$ are calculated in first-order perturbation theory and compared to those obtained without the Roper resonance. We show that the Roper contribution is sizeable for $D$ waves and improves the description of phase shifts for all the partial waves slightly. We also discuss the role of the Roper resonance in the NN interaction in the framework of resonance saturation.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11815v1",
        "authors": [
          "Yang Xiao",
          "Li-Sheng Geng",
          "U. van Kolck"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Pion Exchange Contributions",
        "Nucleon Interaction",
        "Roper Resonance We",
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.536435"
    },
    {
      "id": "arxiv-2602.11811v1",
      "title": "On the numerical evaluation of the `exact' Post-Newtonian parameters in Brans-Dicke and Entangled Relativity theories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11811v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In context of Brans-Dicke scalar-tensor theories of gravity, it has recently been obtained that the post-Newtonian parameters should be generalized in the context of strongly gravitating bodies, and that its generalization -- the so-called $\\textit{exact parameters}$ -- actually depends on the pressure and energy density of a considered celestial body. Here we develop two new methods to numerically obtain the $\\textit{exact parameters}$ by means of usual Tolman-Oppenheimer-Volkoff computation, and find that the difference with the value of standard post-Newtonian parameters can be more than 80% in some situations. We also provide the connection with the Damour-Esposito Farèse non-pertubative parameter $α_{DEF}$. We then apply the methodology to the case of Entangled Relativity, and derive these exact parameters for the Sun and the Earth, as well as for neutron stars. We argue that current and foreseeable experiments are likely able to constrain the theory under the assumption that $\\mathcal{L}_m=-ρ$, where $ρ$ is the total energy density. If $\\mathcal{L}_m=T$ instead, as often advocated in the literature, then there is no deviation with respect to General Relativity and the prospects of testing Entangled Relativity become much more remote in time, as only compact objects with extreme electric or magnetic fields could lead to some deviation from General Relativity.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11811v1",
        "authors": [
          "Thomas Chehab",
          "Olivier Minazzoli"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Entangled Relativity",
        "General Relativity",
        "Standard",
        "Act",
        "WTO",
        "DEF",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.537238"
    },
    {
      "id": "arxiv-2602.11744v1",
      "title": "Spectrum of $[cq][\\bar{s}\\bar{q}]$ tetraquarks: Nature of $D^*_{s0}(2317)$, $D_{s1}(2460)$ and $T^*_{c\\bar s0}(2900)$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11744v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Motivated by the recent observations of exotic open-charm tetraquark candidates \\(T^a_{c\\bar{s}0}(2900)^{++}\\) and \\(T^a_{c\\bar{s}0}(2900)^{0}\\), we systematically calculate the mass spectra of \\([cq][\\bar{s}\\bar{q}]\\) tetraquarks within a nonrelativistic constituent quark potential model. In the model, the tetraquark states are treated as diquark-antidiquark bound systems with an interior interaction similar to the quark-antiquark interaction in conventional mesons. The well established states \\(D_{s0}^*(2317)\\) with \\(J^P=0^+\\) and \\(D_{s1}(2460)\\) with \\(J^P=1^+\\) could be identified as the two ground states of the \\([cq][\\bar{s}\\bar{q}]\\) system. \\(T^a_{c\\bar{s}0}(2900)^{0}\\) and \\(T^a_{c\\bar{s}0}(2900)^{++}\\) could be naturally interpreted as radially excited \\(0^+\\) tetraquark states with different interior components. Their large mass difference may result from their different interior structure instead of an isospin symmetry breaking. Whether \\(T^a_{c\\bar{s}0}(2900)^{0}\\) and \\(T^a_{c\\bar{s}0}(2900)^{++}\\) belong to an isospin triplet deserves further experimental investigation. In addition, there may be another \\(0^+\\) \\([cq][\\bar{s}\\bar{q}]\\) tetraquark state with mass around $2450$ MeV, which is composed of a $cq$ diquark and a $\\bar s\\bar q$ antidiquark both with spin-0. In the energy region $2640-2700$ MeV, there may be a $J^P=2^+$ \\([cq][\\bar{s}\\bar{q}]\\) tetraquark state composed of the $cq$ diquark and the $\\bar s\\bar q$ antidiquark both with spin-1.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11744v1",
        "authors": [
          "Zhi-Yuan Chen",
          "Zhe-Hao Cao",
          "You-You Lin",
          "Ji-Ying Wang",
          "Ailin Zhang"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.537676"
    },
    {
      "id": "arxiv-2602.11713v1",
      "title": "QCD matter at a finite magnetic field and nonzero chemical potential",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11713v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We construct a hybrid equation of state (EoS) by smoothly interpolating the EoS in the hadron resonance gas at low temperatures to that in the ideal parton gas at high temperatures, and employ it to study the properties of the quantum chromodynamics (QCD) matter at a finite magnetic field and nonzero chemical potential. We find that dimensionless observables such as the entropy density $s/T^3$, the pressure $P/T^4$, the energy density $\\varepsilon/T^4$, the trace anomaly $Δ= (\\varepsilon - 3P)/T^4$, and the specific heat at constant volume $C_V/T^3$ are sensitive to both finite magnetic field and chemical potential. As the chemical potential increases from zero, these quantities rise in both the hadronic and quark-gluon plasma phases. In contrast, introducing a magnetic field suppresses them at low temperatures but enhances them at high temperatures. Furthermore, nonzero chemical potential and magnetic field introduce nontrivial modifications to the squared speed of sound $c_s^2$. Both effects increase $c_s^2$ close to the critical temperature while reducing it at lower temperatures. When the chemical potential and magnetic field are present simultaneously, their influences superimpose, leading to more intricate changes in the thermodynamic behavior. Finally, we compare our results with the lattice QCD data for the quadratic fluctuations of conserved charges and their correlations. The model successfully reproduces the temperature dependence of these observables at $eB=0$ and 0.04 GeV$^2$. However, at the stronger field strength $eB=0.14$ GeV$^2$, the model underestimates the magnitudes while still capturing the overall temperature trend.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11713v1",
        "authors": [
          "Zhi-Ying Qin",
          "Bo Feng",
          "Ya-Hui Hou",
          "Hong-Yue Song",
          "Wen-Chao Zhang"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "QCD",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:01.538579"
    },
    {
      "id": "arxiv-2602.12269v1",
      "title": "Certification of linear optical quantum state preparation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12269v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Certification is important to guarantee the correct functioning of quantum devices. A key certification task is verifying that a device has produced a desired output state. In this work, we study this task in the context of photonic platforms, where single photons are propagated through linear optical interferometers to create large, entangled resource states for metrology, communication, quantum advantage demonstrations and for so-called linear optical quantum computing (LOQC). This setting derives its computational power from the indistinguishability of the photons, i.e., their relative overlap. Therefore, standard fidelity witnesses developed for distinguishable particles (including qubits) do not apply directly, because they merely certify the closeness to some fixed target state. We introduce a measure of fidelity suitable for this setting and show several different ways to witness it, based on earlier proposals for measuring genuine multi-photon indistinguishability. We argue that a witness based upon the discrete Fourier transform is an optimal choice. We experimentally implement this witness and certify the fidelity of several multi-photon states.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12269v1",
        "authors": [
          "Riko Schadow",
          "Naomi Spier",
          "Stefan N. van den Hoven",
          "Malaquias Correa Anguita",
          "Redlef B. G. Braamhaar"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Computing",
        "Standard",
        "LOQC",
        "NSF",
        "EPA",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.713925"
    },
    {
      "id": "arxiv-2602.12258v1",
      "title": "Post-measurement states are (very) useful for measurement discrimination",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12258v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The standard approach to quantum measurement discrimination is to perform the given unknown measurement on a probe state, possibly entangled with an auxiliary system, and make a decision based on the measurement outcome obtained. In this work, we go beyond the standard aforementioned scenarios by consider not only the classical measurement outcome of a measurement, but also its the post-measurement quantum state. More specifically, instead of considering only the positive-operator valued measure (POVM) operators, we consider their associated Lüders' instrument associated with them. We prove that, when the post-measurement quantum states are available, the task of discriminating two qubit projective measurements is equivalent to discriminating two copies of quantum states associated to each projector pair, extending previous results known for the case where probe states are separable. Then, we proceed by showing that the advantage of considering post-measurement states in measurement discrimination can be large. We formalise this claim by presenting a family of pairs of measurements where the ratio between the discrimination bias of the measurement discrimination task with and without post-measurement states can be arbitrarily large. This shows that, while the post-measurement state was neglected in most of the previous literature, its use can significantly improve the performance of quantum measurement discrimination.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12258v1",
        "authors": [
          "Charbel Eid",
          "Marco Túlio Quintino"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "POVM",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.715068"
    },
    {
      "id": "arxiv-2602.12193v1",
      "title": "A Framework for Spatial Quantum Sensing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12193v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Analytical and algebraic geometry are valuable tools for dealing with problems involving analytical functions and polynomials. In what we connote as spatial quantum sensing the goal is, given an underlying field and a set of quantum sensors interrogating the field in a set of positions, to find an estimator for some property the field. This property can have multiple forms, be it distinguishing the source of a target signal, or evaluating the field (or a derivative thereof) in an arbitrary position. In this work we also link this problem to networks of quantum sensors, and the role and usefulness of entangling these sensors. We find that the estimators that come out as a solution to the problem are such that a non-local entangled strategy provides maximum precision. We start by working under the assumption of polynomial fields, which relates to the interpolation problem, and then generalize for any signal that is modeled via analytical functions, giving rise to any general least-squares estimator. We discuss the effects of the placement of the sensors in the estimation, namely, how to find well defined, construction error-free placements for the sensors. In the case of interpolation we provide concrete examples and proofs in a $m$-dimensional array of sensors, and discuss necessary and sufficient conditions for the more general cases. We provide clear examples of the possible use-cases and statements, and compare a non-local entangled strategy with the best local strategy for an interpolation problem, showing the benefit in terms of precision in a distributed sensing scenario. This is a key tool for a wide-range of problem in sensing problems, ranging from large-scale such as earth-sized experiments, to local-scale, such has biological experiments.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12193v1",
        "authors": [
          "Luís Bugalho",
          "Yasser Omar",
          "Damian Markham"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spatial Quantum Sensing Analytical",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.715911"
    },
    {
      "id": "arxiv-2602.12156v1",
      "title": "Deterministic Generation of Arbitrary Fock States via Resonant Subspace Engineering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12156v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Deterministic preparation of high-excitation Fock states is a central challenge in bosonic quantum information, with control complexity that generically explodes as the Hilbert space dimension grows. Here we introduce resonant subspace engineering (RSE), a protocol that analytically confines the infinite-dimensional bosonic dynamics to a two-dimensional invariant subspace spanned by an initial coherent state and the target state. State transfer then reduces to a geodesic rotation on a synthetic Bloch sphere, governed by resonance and phase-matching conditions we derive in closed form. For single Fock states, RSE achieves $O(n^{1/4})$ scaling in both evolution time and gate depth, showing a fundamental improvement over existing deterministic schemes. The construction generalizes to $K$-component superpositions via a $(K{+}1)$-dimensional invariant subspace with full $\\mathrm{SU}(K{+}1)$ controllability, requiring only 3-5 iterations of operations for superpositions spanning photon numbers 70--100. RSE provides a scalable and analytically transparent framework for large-scale bosonic state engineering and gate synthesis across single- and multimode platforms.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12156v1",
        "authors": [
          "Shan Jin",
          "Ming Li",
          "Weizhou Cai",
          "Zi-Jie Chen",
          "Yifang Xu"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Resonant Subspace Engineering Deterministic",
        "Deterministic Generation",
        "Arbitrary Fock States",
        "Framework",
        "Protocol",
        "NIST",
        "BERT",
        "NSF",
        "EPA",
        "RSE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.716486"
    },
    {
      "id": "arxiv-2602.12097v1",
      "title": "Hierarchy of saturation conditions for multiparameter quantum metrology bounds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12097v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The quantum Cramér-Rao (QCR) bound sets the ultimate local precision limit for unbiased multiparameter estimation. Yet, unlike in the single-parameter case, its saturability is not generally guaranteed and is often assessed through commutativity-based conditions. Here, we resolve the logical hierarchy of these commutativity conditions for unitary parameter-encoding transformations. We identify strict gaps between them, uncover previously assumed but missing implications, and construct explicit counterexamples to characterize the boundaries between distinct classes. In particular, we show that commutativity of the parameter-encoding generators alone does not ensure the saturability of the QCR bound once realistic noise produces mixed probe states. Our results provide a systematic classification of saturability conditions in multiparameter quantum metrology and clarify fundamental precision limits in noisy distributed quantum sensing beyond idealized pure-state settings.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12097v1",
        "authors": [
          "Satoya Imai",
          "Jing Yang",
          "Luca Pezzè"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "NSF",
        "MIT",
        "QCR",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.717441"
    },
    {
      "id": "arxiv-2602.12042v1",
      "title": "Scalable Preparation of Matrix Product States with Sequential and Brick Wall Quantum Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12042v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Preparing arbitrary quantum states requires exponential resources. Matrix Product States (MPS) admit more efficient constructions, particularly when accuracy is traded for circuit complexity. Existing approaches to MPS preparation mostly rely on heuristic circuits that are deterministic but quickly saturate in accuracy, or on variational optimization methods that reach high fidelities but scale poorly. This work introduces an end-to-end MPS preparation framework that combines the strengths of both strategies within a single pipeline. Heuristic staircase-like and brick wall disentangler circuits provide warm-start initializations for variational optimization, enabling high-fidelity state preparation for large systems. Target MPSs are either specified as physical quantum states or constructed from classical datasets via amplitude encoding, using step-by-step singular value decompositions or tensor cross interpolation. The framework incorporates entanglement-based qubit reordering, reformulated as a quadratic assignment problem, and low-level optimizations that reduce depths by up to 50% and CNOT counts by 33%. We evaluate the full pipeline on datasets of varying complexity across systems of 19-50 qubits and identify trade-offs between fidelity, gate count, and circuit depth. Optimized brick wall circuits typically achieve the lowest depths, while the optimized staircase-like circuits minimize gate counts. Overall, our results provide principled and scalable protocols for preparing MPSs as quantum circuits, supporting utility-scale applications on near-term quantum devices.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12042v1",
        "authors": [
          "Tomasz Szołdra",
          "Rick Mukherjee",
          "Peter Schmelcher"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Brick Wall Quantum Circuits",
        "Matrix Product States",
        "Scalable Preparation",
        "Framework",
        "Protocol",
        "NIST",
        "CNOT",
        "EPA",
        "MIT",
        "MPS",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.718224"
    },
    {
      "id": "arxiv-2602.11985v1",
      "title": "A New Angle on Quantum Subspace Diagonalization for Quantum Chemistry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11985v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum subspace diagonalization and quantum Krylov algorithms offer a feasible, pre- or early-fault tolerant alternative to quantum phase estimation for using quantum computers to estimate the low-lying spectra of quantum systems. However, despite promising proof-of-principle results, such methods suffer from high sensitivity to noise (including intrinsic sources such as sampling noise), making their utility for realistic industry-relevant problems an open question. To improve the potential applicability of such methods, we introduce a new variant of thresholding for noisy generalized eigenvalue problems that arise in quantum subspace diagonalization that has the potential to better control sensitivity to noise. Our approach leverages eigenvector-preserving transformations (rotations) of the generalized eigenvalue problem prior to thresholding. We study this effect in practical settings by applying this rotation thresholding scheme to an iterative quantum Krylov algorithm for several chemical systems, including the industry-relevant Fe(III)-NTA chelate complex. We develop a particular heuristic to select the rotation angle from noisy data and find for certain systems and noise regimes that the samples required to reach a target error for ground state estimation can be reduced by a factor of up to 100. Furthermore, with oracle access to the optimal transformation, more dramatic improvements are possible and we observe reductions in sample requirements by up to $10^4$, motivating the continued development of methods that can realize these improvements in practice. While we develop our approach in the context of quantum subspace diagonalization, the improved thresholding scheme we develop could be advantageous in any context where one must solve noisy, ill-conditioned generalized eigenvalue problems.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11985v1",
        "authors": [
          "Xeno De Vriendt",
          "Jacob Bringewatt",
          "Nik O. Gjonbalaj",
          "Stefan Ostermann",
          "Davide Vodola"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Subspace Diagonalization",
        "Quantum Chemistry Quantum",
        "New Angle",
        "Oracle",
        "NTA",
        "Act",
        "NSF",
        "III",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.718897"
    },
    {
      "id": "arxiv-2602.11912v1",
      "title": "Millisecond-Scale Calibration and Benchmarking of Superconducting Qubits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11912v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Superconducting qubit parameters drift on sub-second timescales, motivating calibration and benchmarking techniques that can be executed on millisecond timescales. We demonstrate an on-FPGA workflow that co-locates pulse generation, data acquisition, analysis, and feed-forward, eliminating CPU round trips. Within this workflow, we introduce sparse-sampling and on-FPGA inference tools, including computationally efficient methods for estimation of exponential and sine-like response functions, as well as on-FPGA implementations of Nelder-Mead optimization and golden-section search. These methods enable low-latency primitives for readout calibration, spectroscopy, pulse-amplitude calibration, coherence estimation, and benchmarking. We deploy this toolset to estimate $T_1$ in 10 ms, optimize readout parameters in 100 ms, optimize pulse amplitudes in 1 ms, and perform Clifford randomized gate benchmarking in 107 ms on a flux-tunable superconducting transmon qubit. Running a closed-loop on-FPGA recalibration protocol continuously for 6 hours enables more than 74,000 consecutive recalibrations and yields gate errors that consistently retain better performance than the baseline initial calibration. Correlation analysis shows that recalibration suppresses coupling of gate error to control-parameter drift while preserving a coherence-linked performance. Finally, we quantify uncertainty versus time-to-decision under our sparse sampling approaches and identify optimal parameter regimes for efficient estimation of qubit and pulse parameters.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11912v1",
        "authors": [
          "Malthe A. Marciniak",
          "Rune T. Birke",
          "Johann B. Severin",
          "Fabrizio Berritta",
          "Daniel Kjær"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superconducting Qubits Superconducting",
        "Scale Calibration",
        "Protocol",
        "FPGA",
        "MIT",
        "CPU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.719577"
    },
    {
      "id": "arxiv-2602.11895v1",
      "title": "Benchmarking Classical and Quantum Optimization Approaches for Rider-Order Assignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11895v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The logistics industry is widely regarded as a promising application domain for emerging optimization paradigms, including quantum computing. The Rider-Order Assignment problem is a practically motivated optimization problem arising in online food delivery and related logistics applications. While the problem is closely related to the classical matching problem, the inclusion of realistic operational constraints renders it computationally challenging. In this work, we formulate the Rider-Order Assignment problem as a constrained binary optimization problem and perform a comparative analysis of classical, quantum-inspired, and gate-based quantum solvers for this problem across multiple instance sizes. Solver performance is assessed using solution quality, computational runtime, and constraint satisfaction, with a consistent post-processing procedure applied to ensure feasibility.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11895v1",
        "authors": [
          "Tharrmashastha SAPV",
          "Surya Prakash Palanivel",
          "Jasjyot Singh Gulati",
          "M Maruthu Pandi"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Optimization Approaches",
        "Benchmarking Classical",
        "Quantum Computing",
        "Order Assignment",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.719953"
    },
    {
      "id": "arxiv-2602.11869v1",
      "title": "Resource-Efficient Teleportation of High-Dimensional Quantum Coherence via Initial Phase Engineering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11869v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-dimensional quantum systems leverage an expanded Hilbert space to enhance resilience against decoherence and noise. However, standard quantum teleportation is fundamentally limited by the quadratic growth of measurement complexity and high classical communication overhead, requiring the resolution of $d^2$ Bell states and $2\\log_2 d$ classical bits. In this study, we propose a resource-efficient high-dimensional coherence teleportation (REHDCT) protocol. By designing $d$ sets of specialized positive operator-valued measure (POVM) bases, our protocol achieves a 50\\% reduction in classical communication by utilizing one of the $d$ designed POVM sets, which effectively scales the measurement complexity from $O(d^2)$ to $O(d)$. Furthermore, we demonstrate that by utilizing initial phase engineering to align the target qudit with the measurement basis, theoretically perfect teleportation of quantum coherence can be achieved for arbitrary qudit states. A quantitative robustness analysis reveals that the protocol remains highly resilient to operational errors, maintaining an efficiency above 99.6\\% even under a 0.1 rad phase deviation for $d=16$. Our analysis under various noise models (amplitude damping, phase flip, depolarizing, and dit-flip) confirms that high-dimensional systems exhibit an expanding quantum advantage window as dimensionality increases. Notably, under dit-flip noise, perfect coherence teleportation can be restored through the optimal selection of the POVM basis. These findings establish REHDCT as a practical, hardware-friendly framework for resource-efficient quantum communication in future high-dimensional networks.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11869v1",
        "authors": [
          "Long Huang",
          "Cai-Hong Liao",
          "Yan-Ling Li",
          "Xing Xiao"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Initial Phase Engineering High",
        "Dimensional Quantum Coherence",
        "Efficient Teleportation",
        "Framework",
        "Standard",
        "Protocol",
        "REHDCT",
        "Wind",
        "POVM",
        "BERT",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.720488"
    },
    {
      "id": "arxiv-2602.11839v1",
      "title": "Single-shot GHZ characterization with connectivity-aware fanout constructions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11839v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We propose a practical recipe to transform any depth-$L$ block of CNOTs that prepares $n$-qubit GHZ states into an $n$-qubit fanout gate (multitarget-CNOT) of depth $2L-1$, without the need for ancilla qubits. Considering known logarithmic-depth circuits to prepare GHZ-states, this allows us to construct an $n$-qubit fanout gate with depth $2\\log_2(n)-1$, reproducing previous ancillaless constructions. We employ our recipe to construct $n$-qubit fanout gates under heavy-hex connectivity restrictions, obtaining a depth of $O(n^{1/2})$, again reproducing previous complexity theory constructions. Using this recipe on the \\textit{ibm\\_fez} architecture yields a $156$-qubit fanout construction with depth $33$. Additionally, we show how to employ these $n$-qubit fanout constructions to measure complete sets of commuting observables from the $n$-body Pauli group with the same depth, allowing for efficient single-shot characterization of any GHZ-like state in a given known basis, e.g. fully characterizing a single copy of a $156$-qubit GHZ state using circuit depth $33$ in $\\textit{ibm\\_fez}$ (its preparation requires an additional depth of $17$).",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11839v1",
        "authors": [
          "Giancarlo Gatti"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "CNOT",
        "Act",
        "NSF",
        "EPA",
        "GHZ",
        "IBM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.720970"
    },
    {
      "id": "arxiv-2602.11833v1",
      "title": "Operational limits to entanglement-based satellite quantum key distribution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11833v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Space-based distribution of quantum entanglement will be essential for global quantum networking and secure communications. Modelling and analysis of the performance of satellite entanglement pair distribution is important for the architecture and design of constellations and space systems. Entanglement-based quantum key distribution, in the absence of quantum repeaters, is especially prone to finite key effects due to low coincident count rates compared to trusted node single-path links. Therefore, there is a need for a comprehensive study of finite-key effects in the context of direct dual downlink quantum key distribution taking into account the characteristics of the overpass geometries. We develop a high-fidelity model of pair distribution from a low Earth orbit satellite that captures orbital dynamics, elevation-dependent loss, background noise, and extraneous detector effects. We integrate this with a rigorous finite-key security framework for the BBM92 protocol to optimise secret key length across different overpass geometries, orbital altitudes, and optical ground station (OGS) separations. These results provide quantitative performance bounds and design guidelines for near-term SatQKD missions, enabling informed trade-offs between satellite payload complexity, ground infrastructure, and achievable secure key throughput.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11833v1",
        "authors": [
          "Jasminder S. Sidhu",
          "Sarah E. McCarthy",
          "Cameron Paterson",
          "Daniel K. L. Oi"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite",
        "Guideline",
        "Framework",
        "Protocol",
        "Act",
        "EPA",
        "MIT",
        "OGS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.721398"
    },
    {
      "id": "arxiv-2602.11797v1",
      "title": "Learning functions of quantum states with distributed architectures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11797v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Distributed architectures are gaining prominence in quantum machine learning as a means to overcome hardware limitations and enable scalable quantum information processing. In this context, we analyze the design and performance of distributed Quantum Extreme Learning Machine (QELM) architectures for learning functions of quantum states directly from data, restricting measurements to easily implementable projective measurements in the computational basis. The aim is to determine which schemes can effectively recover specific properties of input quantum states, including both linear and nonlinear features, while also quantifying the resource requirements in terms of measurements and reservoir dimensionality. We compare standard three-layer QELM with a spatially multiplexed architecture composed of multiple independent three-layer units for linear (quantum) tasks, showing a linear reduction in resource requirements per unit. For nonlinear properties, the study examines the multiple-injection architecture and introduces a novel distributed design that incorporates entanglement between subsystems within a spatially multiplexed framework, evaluating its performance through the reconstruction of complex nonlinear quantities such as polynomial targets, Rényi entropy, and entanglement measures. Our results demonstrate that the distributed design enables the reconstruction of higher-order nonlinearities by increasing the number of interacting subsystems with reduced resources, rather than increasing the size of an individual reservoir, providing a scalable and hardware-efficient route to quantum property learning.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11797v1",
        "authors": [
          "Marta Gili",
          "Eliana Fiorelli",
          "Ane Blázquez-García",
          "Gian Luca Giorgi",
          "Roberta Zambrini"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Extreme Learning Machine",
        "Machine Learning",
        "Framework",
        "Standard",
        "QELM",
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.722395"
    },
    {
      "id": "arxiv-2602.11627v1",
      "title": "Krylov Subspace Dynamics as Near-Horizon AdS$_2$ Holography",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11627v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We establish a holographic gravitational dual for the fundamental dynamical equations governing operator growth in Krylov subspace. Specifically, we show that the deep interior of the Krylov subspace maps directly to the near-horizon regime of AdS$_2$ gravity. We demonstrate that, in the continuum limit, the discrete evolution on the Krylov chain transforms into the dynamics of a continuous field, which is isomorphic to the Klein-Gordon equation for a scalar field in the AdS$_2$ throat. This correspondence identifies the linear growth rate of Lanczos coefficients with the Hawking temperature, $α=πT$, thereby recovering the saturation of the maximal chaos bound. Notably, the Breitenlohner-Freedman bound, a fundamental stability criterion in AdS gravity, emerges as a necessary consistency requirement for the dual description of Krylov subspace dynamics. Our results advance a Krylov-based holographic dictionary in a unified $SL(2, \\mathbb{R})$ representation, revealing that the emergent geometry of Krylov subspace is a reflection of the near-horizon AdS spacetime.",
        "keywords": [
          "hep-th",
          "cond-mat.str-el",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11627v1",
        "authors": [
          "Hyun-Sik Jeong"
        ],
        "arxiv_categories": [
          "hep-th",
          "cond-mat.str-el",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Krylov Subspace Dynamics",
        "Holography We",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.723398"
    },
    {
      "id": "arxiv-2602.11616v1",
      "title": "The Power of Two Bases: Robust and copy-optimal certification of nearly all quantum states with few-qubit measurements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11616v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "A central task in quantum information science is state certification: testing whether an unknown state is $ε_1$-close to a fixed target state, or $ε_2$-far. Recent work has shown that surprisingly simple measurement protocols--comprising only single-qubit measurements--suffice to certify arbitrary $n$-qubit states [Huang, Preskill, Soleimanifar '25; Gupta, He, O'Donnell '25]. However, these certification protocols are not robust: rather than allowing constant $ε_1$, they can only positively certify states within $ε_1=O(1/n)$ trace distance of the target. In many experimental settings, the appropriate error tolerance is constant as the system size grows, so this lack of robustness renders existing tests inapplicable at scale, no matter how many times the test is repeated. Here we present robust certification protocols based on few-qubit measurements that apply to all but a $O(2^{-n})$-fraction of pure target states. Our first protocol achieves constant robustness, i.e. $ε_1=Θ(1)$, using a single $O(\\log n)$-qubit measurement along with single-qubit measurements in the $Z$ or $X$ basis on the other qubits. As a corollary of its robustness, this protocol also achieves constant (in $n$) copy complexity, which is optimal. Our second protocol uses exclusively single-qubit measurements and is nearly robust: $ε_1=Ω(1/\\log n)$. Our tests are based on a new uncertainty principle for conditional fidelities, which may be of independent interest.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11616v1",
        "authors": [
          "Andrea Coladangelo",
          "Jerry Li",
          "Joseph Slote",
          "Ellen Wu"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Two Bases",
        "Protocol",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.724497"
    },
    {
      "id": "arxiv-2602.11604v1",
      "title": "Quantization Mapping on Dirac Dynamics via Voltage-Driven Charge Density in Monolayer Graphene: A Klein Paradox and Entropy-Ruled Wavevector Mechanics Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11604v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Thermodynamics coupled with quantum features on electron and hole dynamics in Dirac materials is quite interesting and crucial for real device applications. The correlation between the formation of electron-hole puddles in nearer to the charge neutrality point (CNP), and the role of disorder is fundamentally important for Dirac transport in graphene systems. Numerous studies on graphene further urge the necessity to find a better descriptor for disorder-charge puddles relation, which directly influences electrical conductivity. In principle, the external bias-driven energy level shift and its relevant density of states (DOS) provide information about the effect of total interactive potential on linear energy dispersion in terms of wavevector, but yet to be well-explored. With this ground, here we map the energy quantization for Dirac materials through the empirical relation of voltage-driven charge density in monolayer graphene, using the differential entropy (h)-ruled wavevector (k) mechanics. For this work, we propose the four postulates which are the key observable descriptions of earlier research reports, to study the precise electronic transport via an entropy-guided wavevector propagation approach, along with the Klein paradox, which pertains to the ultrafast dynamics in the Dirac or quasi-Dirac systems. The introduced h-ruled k and h-ruled N relations generalize the electron dynamics in both the unbounded and potentially bounded Dirac systems. Through the quantization mapping procedure under different voltage-driven potential (U=eV) boundary conditions, the observed energy shift from lower to excited quantum state obeys the relation of N(k)=N(U)^3; here, N(U) is the voltage-driven potential energy contribution factor for the quantum state existence. This study reveals information about the interaction potential-DOS relationship in the Dirac materials.",
        "keywords": [
          "cond-mat.mes-hall",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11604v1",
        "authors": [
          "Karuppuchamy Navamani"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ruled Wavevector Mechanics Study",
        "Driven Charge Density",
        "Quantization Mapping",
        "Monolayer Graphene",
        "Dirac Dynamics",
        "Klein Paradox",
        "Act",
        "DOS",
        "CNP",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.725101"
    },
    {
      "id": "arxiv-2602.11592v1",
      "title": "Scalable and Highly Fault-Tolerant Circular Quantum Byzantine Agreement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11592v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Quantum Byzantine Agreement (QBA), a cornerstone of quantum blockchain, offers inherent advantages in security and fault tolerance over classical protocols, guaranteed by the laws of quantum mechanics. However, existing multiparty QBA protocols face challenges for large-scale deployment due to exponential communication complexity or reliance on complex multi-particle entanglement. To address this, we propose a multiparty circular QBA protocol that adopts a semi-decentralized architecture, leveraging circular message gathering and quantum digital signatures to achieve quadratic communication complexity and enhanced fault tolerance. Our protocol is experimentally feasible, requiring only weak coherent states, and is compatible with existing star-shaped quantum networks. Simulations conducted on a global satellite-to-ground network demonstrate that the protocol sustains high consensus rates among multiple users, even when employing different key generation protocols under realistic conditions. This work presents a scalable framework for large-scale QBA networks, establishing the foundation for a practical quantum blockchain that enables secure and fault-tolerant decentralized services.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11592v1",
        "authors": [
          "Chen-Xun Weng",
          "Ming-Yang Li",
          "Shi-Gen Li",
          "Mengya Zhu",
          "Xiao-Ran Sun"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement Quantum Byzantine Agreement",
        "Tolerant Circular Quantum Byzantine",
        "Highly Fault",
        "Blockchain",
        "Satellite",
        "Framework",
        "Agreement",
        "Protocol",
        "Act",
        "QBA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.725554"
    },
    {
      "id": "arxiv-2602.11586v1",
      "title": "Complete freezing of initially maximal entanglement in Schwarzschild black hole",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11586v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Gravitational effects associated with black holes are widely believed to universally degrade quantum entanglement, with the loss of maximal entanglement being particularly severe and even irreversible for bosonic fields. In this work, we investigate the entanglement properties of the four-qubit cluster state ($CL_4$) for fermionic fields in the curved spacetime of a Schwarzschild black hole. Remarkably, we uncover a counterintuitive phenomenon: as the Hawking temperature increases, quantum entanglement ($1$-$3$ tangle) of the $CL_4$ state remains strictly constant, indicating a ``complete freezing of initially maximal entanglement\". This constitutes the first explicit example in which maximal entanglement remains perfectly preserved in a black hole environment, defying the conventional expectation that gravitational effects can only suppress maximal quantum correlations. Moreover, our results indicate that, within a relativistic framework, the $CL_4$ state constitutes a high-quality quantum resource with potential applications in relativistic quantum information processing, and may significantly improve the performance of such protocols.",
        "keywords": [
          "gr-qc",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11586v1",
        "authors": [
          "Si-Han Li",
          "Hui-Chen Yang",
          "Rui-Yang Xu",
          "Shu-Min Wu"
        ],
        "arxiv_categories": [
          "gr-qc",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Protocol",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.725934"
    },
    {
      "id": "arxiv-2602.11576v1",
      "title": "Control the qubit-qubit coupling with double superconducting resonators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11576v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We experimentally studied the switching off processes in the double-resonator coupler superconducting quantum circuit.In both frequency and time-domain, we observed the variation of qubit-qubit effective coupling by tuning qubits'frequencies. According to the measurement results, by just shifting qubits' frequencies smaller than 50 MHz, the effective qubit-qubit coupling strength can be tuned from switching off point to two qubit gate point (effective coupling larger than 5 MHz) in double-resonator superconducting quantum circuit. The double-resonator coupler superconducting quantum circuit has the advantage of simple fabrications, introducing less flux noises, reducing occupancy of dilution refrigerator cables, which might supply a promising platform for future large-scale superconducting quantum processors.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11576v1",
        "authors": [
          "Hui Wang",
          "Rui Wang",
          "Daichi Sugiyama",
          "J. S. Tsai"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.726223"
    },
    {
      "id": "arxiv-2602.11503v1",
      "title": "Generalized entropic uncertainty relation and non-classicality in Schwarzschild black hole",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11503v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The uncertainty principle constitutes a fundamental pillar of quantum theory, representing one of the most distinctive features that differentiates quantum mechanics from classical physics. In this study, we firstly propose a novel generalized entropic uncertainty relation (EUR) for arbitrary multi-measurement in the many-body systems, and rigorously derive a significantly tighter bound compared to existing formulations. Specifically, we discuss the proposed EUR in the context of Schwarzschild black hole, where we demonstrate the superior tightness of our derived bound. The study further elucidates the dynamical evolution of multipartite quantum coherence and entanglement in the curved spacetime. A particularly noteworthy finding reveals the exact equivalence between entanglement and $l_1$-norm coherence for arbitrary $N$-partite Greenberger-Horne-Zeilinger-type (GHZ-type) states. Moreover, we find that quantum coherence is significantly diminished and the measurement uncertainty increases to a stable maximum with increasing Hawking temperature. Thus, the findings of this study contribute to a deeper understanding of non-classicality and quantum resources in black holes.",
        "keywords": [
          "gr-qc",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11503v1",
        "authors": [
          "Rui-Jie Yao",
          "Dong Wang"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "EUR",
        "GHZ",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.726608"
    },
    {
      "id": "arxiv-2602.11469v1",
      "title": "Structural control of two-level defect density revealed by high-throughput correlative measurements of Josephson junctions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11469v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Materials defects in Josephson junctions (JJs), often referred to as two-level systems (TLS), couple to superconducting qubits and are a critical bottleneck for scalable quantum processors. Despite their importance, understanding the microscopic sources of TLS and how to mitigate them has remained a major challenge. Here, we demonstrate a high-throughput, correlated approach to trace the microstructural origins of strongly-coupled TLS in Josephson circuits. We assembled a massive dataset of TLS across 6,000 Al/AlOx/Al JJs and more than 600 atomic resolution transmission electron microscopy images. We statistically link fabrication, microstructure, and TLS occurrence, revealing a strong correlation between Al electrode thickness, Al grain size, and TLS density. Correspondingly, we find a two-thirds reduction in TLS prompted by a change in electrode fabrication parameters. These results demonstrate a robust, data-driven methodology to understand and control defects in quantum circuits and pave the way for significantly reducing TLS density.",
        "keywords": [
          "quant-ph",
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11469v1",
        "authors": [
          "Oliver F. Wolff",
          "Harshvardhan Mantry",
          "Rahim Raja",
          "Wei-Hsiang Peng",
          "Kaushik Singirikonda"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "TLS",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.726995"
    },
    {
      "id": "arxiv-2602.11457v1",
      "title": "The Pinnacle Architecture: Reducing the cost of breaking RSA-2048 to 100 000 physical qubits using quantum LDPC codes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11457v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The realisation of utility-scale quantum computing inextricably depends on the design of practical, low-overhead fault-tolerant architectures. We introduce the \\textit{Pinnacle Architecture}, which uses quantum low-density parity check (QLDPC) codes to allow for universal, fault-tolerant quantum computation with a spacetime overhead significantly smaller than that of any competing architecture. With this architecture, we show that 2048-bit RSA integers can be factored with less than one hundred thousand physical qubits, given a physical error rate of $10^{-3}$, code cycle time of $1$ \\textmu s and a reaction time of $10$ \\textmu s. We thereby demonstrate the feasibility of utility-scale quantum computing with an order of magnitude fewer physical qubits than has previously been believed necessary.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11457v1",
        "authors": [
          "Paul Webster",
          "Lucas Berent",
          "Omprakash Chandra",
          "Evan T. Hockings",
          "Nouédyn Baspin"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Pinnacle Architecture",
        "Quantum Computing",
        "RSA-2048",
        "QLDPC",
        "LDPC",
        "Act",
        "RSA",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:05.727309"
    },
    {
      "id": "arxiv-2602.12114v1",
      "title": "Matrix bordering structure of the Faddeev-Jackiw algorithm: Schur complement regularization and symbolic automation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12114v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We show that the iterative Faddeev-Jackiw (FJ) reduction for singular Lagrangian systems constitutes a geometrically constrained instance of the Matrix Bordering Technique (MBT). For a first-order Lagrangian with singular pre-symplectic form, each iteration of the Barcelos-Neto-Wotzasek algorithm produces an extended symplectic matrix of canonical bordered form, \\begin{eqnarray} f^{(m)} = \\left( \\begin{matrix} f^{(0)} & B \\\\ -B^{\\mathsf{T}} & 0 \\end{matrix} \\right) \\end{eqnarray} where the bordering block $B$ is determined by the gradients of the consistency constraints. We prove that the nondegeneracy of the extended matrix is governed by the corresponding Schur complement, which is algebraically isomorphic to the Poisson bracket matrix of constraints. As a consequence, the Faddeev-Jackiw algorithm terminates if and only if the constraint algebra is nondegenerate, i.e., when the constraints form a second-class system. This algebraic characterization provides a rigorous foundation for automating the Faddeev-Jackiw procedure symbolically. We present a fully symbolic implementation in the Wolfram Language, and validate the approach on representative mechanical systems with nontrivial constraint structure. The resulting rule-based engine preserves parametric dependencies throughout the reduction, enabling reliable analysis of degeneracy, structural stability (when no bifurcations occur), and possible bifurcation scenarios as critical parameters are varied.",
        "keywords": [
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12114v1",
        "authors": [
          "E. Chan-López",
          "A. Martín-Ruiz",
          "Jaime Manuel Cabrera",
          "Jorge Mauricio Paulin Fuentes"
        ],
        "arxiv_categories": [
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Matrix Bordering Technique",
        "Wolfram Language",
        "Act",
        "MBT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:09.900191"
    },
    {
      "id": "arxiv-2602.11787v1",
      "title": "On the interaction between a rigid-body and a viscous-fluid: existence of a weak solution and a suitable Théorème de Structure",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11787v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In this paper, we prove the existence and a partial regularity of a weak solution to the system governing the interaction between a rigid body and a viscous incompressible Newtonian fluid. The evolution of the system body-fluid is studied in a frame attached to the body. The choice of this special frame becomes critical from an analytical point of view due to the presence of the term $ω\\times x\\cdot\\nabla u$ in the balance of momentum equation for the fluid. As a consequence, we are forced to look for a technique that is different from the ones usually employed both for the existence and for the partial regularity of a weak solution to the Navier-Stokes problem. Hence, we prove the existence of a weak solution in an original way and give a new proof of the celebrated Théorème de Structure due to Leray. However, the regularity obtained for our weak solution is only for large times, hence our result is weaker compared to the one obtained by Leray.",
        "keywords": [
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11787v1",
        "authors": [
          "Paolo Maremonti",
          "Filippo Palma"
        ],
        "arxiv_categories": [
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structure In",
        "Act",
        "WTO",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:09.900905"
    },
    {
      "id": "arxiv-2602.12066v1",
      "title": "Chaos and Misallocation under Price Controls",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12066v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Price controls kill the incentive for arbitrage. We prove a Chaos Theorem: under a binding price ceiling, suppliers are indifferent across destinations, so arbitrarily small cost differences can determine the entire allocation. The economy tips to corner outcomes in which some markets are fully served while others are starved; small parameter changes flip the identity of the corners, generating discontinuous welfare jumps. These corner allocations create a distinct source of cross-market misallocation, separate from the aggregate quantity loss (the Harberger triangle) and from within-market misallocation emphasized in prior work. They also create an identification problem: welfare depends on demand far from the observed equilibrium. We derive sharp bounds on misallocation that require no parametric assumptions. In an efficient allocation, shadow prices are equalized across markets; combined with the adding-up constraint, this collapses the infinite-dimensional welfare problem to a one-dimensional search over a common shadow price, with extremal losses achieved by piecewise-linear demand schedules. Calibrating the bounds to station-level AAA survey data from the 1973-74 U.S. gasoline crisis, misallocation losses range from roughly 1 to 9 times the Harberger triangle.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12066v1",
        "authors": [
          "Brian C. Albrecht",
          "Alex Tabarrok",
          "Mark Whitmeyer"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Price Controls Price",
        "EPA",
        "AAA",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.139789"
    },
    {
      "id": "arxiv-2602.12043v1",
      "title": "Improved Inference for CSDID Using the Cluster Jackknife",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12043v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Obtaining reliable inferences with traditional difference-in-differences (DiD) methods can be difficult. Problems can arise when both outcomes and errors are serially correlated, when there are few clusters or few treated clusters, when cluster sizes vary greatly, and in various other cases. In recent years, recognition of the ``staggered adoption'' problem has shifted the focus away from inference towards consistent estimation of treatment effects. One of the most popular new estimators is the CSDID procedure of Callaway and Sant'Anna (2021). We find that the issues of over-rejection with few clusters and/or few treated clusters are at least as severe for CSDID as for traditional DiD methods. We also propose using a cluster jackknife for inference with CSDID, which simulations suggest greatly improves inference. We provide software packages in Stata csdidjack and R didjack to calculate cluster-jackknife standard errors easily.",
        "keywords": [
          "econ.EM",
          "stat.ME",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12043v1",
        "authors": [
          "Sunny R. Karim",
          "Morten Ørregaard Nielsen",
          "James G. MacKinnon",
          "Matthew D. Webb"
        ],
        "arxiv_categories": [
          "econ.EM",
          "stat.ME",
          "stat.ML"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Cluster Jackknife Obtaining",
        "Improved Inference",
        "Standard",
        "CSDID",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.140223"
    },
    {
      "id": "arxiv-2602.12035v1",
      "title": "The Algorithmic Advantage: How Reinforcement Learning Generates Rich Communication",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12035v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We analyze strategic communication when advice is generated by a reinforcement-learning algorithm rather than by a fully rational sender. Building on the cheap-talk framework of Crawford and Sobel (1982), an advisor adapts its messages based on payoff feedback, while a decision maker best-responds. We provide a theoretical analysis of the long-run communication outcomes induced by such reward-driven adaptation. With aligned preferences, we establish that learning robustly leads to informative communication even from uninformative initial policies. With misaligned preferences, no stable outcome exists; instead, learning generates cycles that sustain highly informative communication and payoffs exceeding those of any static equilibrium.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12035v1",
        "authors": [
          "Emilio Calvano",
          "Clemens Possnig",
          "Juha Tolvanen"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "How Reinforcement Learning Generates",
        "Rich Communication We",
        "Framework",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.140567"
    },
    {
      "id": "arxiv-2602.11992v1",
      "title": "Labor Supply under Temporary Wage Increases: Evidence from a Randomized Field Experiment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11992v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We conduct a pre-registered randomized controlled trial to test for income targeting in labor supply decisions among sellers of a Swedish street paper. These workers face liquidity constraints, high income volatility, and discretion over hours. Treated individuals received a 25 percent bonus per copy sold for the duration of an issue, simulating an increase in earnings potential. Treated sellers sold more papers, worked longer hours, and took fewer days off. These findings contrast with studies on intertemporal labor supply that find small substitution effects. Notably, when we apply strategies similar to observational studies, we recover patterns consistent with income targeting.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11992v1",
        "authors": [
          "Mats Ekman",
          "Niklas Jakobsson",
          "Andreas Kotsadam"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Randomized Field Experiment We",
        "Temporary Wage Increases",
        "Labor Supply",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.140989"
    },
    {
      "id": "arxiv-2602.11831v1",
      "title": "A weighted approach to identifying key team contributors: Individual productivity in professional road cycling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11831v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Assessing an individual's contribution within a team remains a fundamental challenge across many domains, particularly when recognition for collective achievements is limited to only a few members. This issue is especially important in professional road cycling, where personal success depends on both individual talent and group effort. Existing points-based ranking systems tend to disproportionately reward high-scoring team leaders while undervaluing domestiques - riders who sacrifice personal success to support group performance. To better capture a rider's impact on the team, we propose a weighted measure of cycling productivity that factors in race points, a redistribution metric, and an adapted version of the CoScore formula. This formula assesses an individual's productivity relative to their teammates' performance. Using data from the 2023 season, we show that our approach offers a comprehensive evaluation of professional cyclists, addressing key limitations of existing ranking systems.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11831v1",
        "authors": [
          "Aitor Calo-Blanco"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Act",
        "WHO",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.141396"
    },
    {
      "id": "arxiv-2602.11687v1",
      "title": "Exact Value Solution to the Equity Premium Puzzle",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11687v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The aim of this article is to provide the solution to the equity premium puzzle without using calibrated values. Calibrated values of subjective time discount factor were used in the prior derived models because 4 variables were determined from 3 different equations. Furthermore, calculated values and risk behavior determination of prior models were compatible with empirical literature. 4 unknown variables are now calculated from 4 different equations in the new derived model in this article. Subjective time discount factor and coefficient of relative risk aversion are found 0.9581 and 1.0319, respectively from the system of equations which are compatible with empirical studies. Micro and macro studies about CRRA value affirm each other for the first time in the literature. Furthermore, equity and risk-free asset investors are pinned down to be insufficient risk-loving, which can be considered a type of risk-averse behavior. Hence it can be said that calculated values and risk attitude determination align with empirical literature. This shows that derived model is valid and make CCAPM work under the same assumptions with those of prior derived models.",
        "keywords": [
          "q-fin.GN",
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11687v1",
        "authors": [
          "Atilla Aras"
        ],
        "arxiv_categories": [
          "q-fin.GN",
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Exact Value Solution",
        "CCAPM",
        "CRRA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:14.141845"
    },
    {
      "id": "arxiv-2602.12030v1",
      "title": "Time-Inhomogeneous Volatility Aversion for Financial Applications of Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12030v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "In finance, sequential decision problems are often faced, for which reinforcement learning (RL) emerges as a promising tool for optimisation without the need of analytical tractability. However, the objective of classical RL is the expected cumulated reward, while financial applications typically require a trade-off between return and risk. In this work, we focus on settings where one cares about the time split of the total return, ruling out most risk-aware generalisations of RL which optimise a risk measure defined on the latter. We notice that a preference for homogeneous splits, which we found satisfactory for hedging, can be unfit for other problems, and therefore propose a new risk metric which still penalises uncertainty of the single rewards, but allows for an arbitrary planning of their target levels. We study the properties of the resulting objective and the generalisation of learning algorithms to optimise it. Finally, we show numerical results on toy examples.",
        "keywords": [
          "q-fin.CP",
          "q-fin.TR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12030v1",
        "authors": [
          "Federico Cacciamani",
          "Roberto Daluiso",
          "Marco Pinciroli",
          "Michele Trapletti",
          "Edoardo Vittori"
        ],
        "arxiv_categories": [
          "q-fin.CP",
          "q-fin.TR"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Inhomogeneous Volatility Aversion",
        "Reinforcement Learning In",
        "Financial Applications",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-15T13:54:18.290787"
    },
    {
      "id": "arxiv-2602.12216v1",
      "title": "Bayesian inference for the automultinomial model with an application to landcover data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12216v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Multicategory lattice data arise in a wide variety of disciplines such as image analysis, biology, and forestry. We consider modeling such data with the automultinomial model, which can be viewed as a natural extension of the autologistic model to multicategory responses, or equivalently as an extension of the Potts model that incorporates covariate information into a pure-intercept model. The automultinomial model has the advantage of having a unique parameter that controls the spatial correlation. However, the model's likelihood involves an intractable normalizing function of the model parameters that poses serious computational problems for likelihood-based inference. We address this difficulty by performing Bayesian inference through the Double-Metropolis Hastings algorithm, and implement diagnostics to assess the convergence to the target posterior distribution. Through simulation studies and an application to land cover data, we find that the automultinomial model is flexible across a wide range of spatial correlations while maintaining a relatively simple specification. For large data sets we find it also has advantages over spatial generalized linear mixed models. To make this model practical for scientists, we provide recommendations for its specification and computational implementation.",
        "keywords": [
          "stat.OT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12216v1",
        "authors": [
          "Maria Paula Duenas-Herrera",
          "Stephen Berg",
          "Murali Haran"
        ],
        "arxiv_categories": [
          "stat.OT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Metropolis Hastings",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.485512"
    },
    {
      "id": "arxiv-2602.12072v1",
      "title": "Enhanced Forest Inventories for Habitat Mapping: A Case Study in the Sierra Nevada Mountains of California",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12072v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Traditional forest inventory systems, originally designed to quantify merchantable timber volume, often lack the spatial resolution and structural detail required for modern multi-resource ecosystem management. In this manuscript, we present an Enhanced Forest Inventory (EFI) and demonstrate its utility for high-resolution wildlife habitat mapping. The project area covers 270,000 acres of the Eldorado National Forest in California's Sierra Nevada. By integrating 118 ground-truth Forest Inventory and Analysis (FIA) plots with multi-modal remote sensing data (LiDAR, aerial photography, and Sentinel-2 satellite imagery), we developed predictive models for key forest attributes. Our methodology employed a two-tier segmentation approach, partitioning the landscape into approximately 575,000 reporting units with an average size of 0.5 acre to capture forest heterogeneity. We utilized an Elastic-Net Regression framework and automated feature selection to relate remote sensing metrics to ground-measured variables such as basal area, stems per acre, and canopy cover. These physical metrics were translated into functional habitat attributes to evaluate suitability for two focal species: the California Spotted Owl (Strix occidentalis occidentalis) and the Pacific Fisher (Pekania pennanti). Our analysis identified 25,630 acres of nesting and 26,622 acres of foraging habitat for the owl, and 25,636 acres of likely habitat for the fisher based on structural requirements like large-diameter trees and high canopy closure. The results demonstrate that EFIs provide a critical bridge between forestry and conservation ecology, offering forest managers a spatially explicit tool to monitor ecosystem health and manage vulnerable species in complex environments.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12072v1",
        "authors": [
          "Maxime Turgeon",
          "Michael Kieser",
          "Dwight Wolfe",
          "Bruce MacArthur"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enhanced Forest Inventories",
        "Enhanced Forest Inventory",
        "Eldorado National Forest",
        "Sierra Nevada Mountains",
        "California Traditional",
        "California Spotted Owl",
        "Forest Inventory",
        "Habitat Mapping",
        "Pacific Fisher",
        "Net Regression",
        "Sierra Nevada",
        "Sentinel-2",
        "Case Study",
        "Framework",
        "Satellite"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.486396"
    },
    {
      "id": "arxiv-2602.11920v1",
      "title": "Learning Conditional Averages",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11920v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce the problem of learning conditional averages in the PAC framework. The learner receives a sample labeled by an unknown target concept from a known concept class, as in standard PAC learning. However, instead of learning the target concept itself, the goal is to predict, for each instance, the average label over its neighborhood -- an arbitrary subset of points that contains the instance. In the degenerate case where all neighborhoods are singletons, the problem reduces exactly to classic PAC learning. More generally, it extends PAC learning to a setting that captures learning tasks arising in several domains, including explainability, fairness, and recommendation systems. Our main contribution is a complete characterization of when conditional averages are learnable, together with sample complexity bounds that are tight up to logarithmic factors. The characterization hinges on the joint finiteness of two novel combinatorial parameters, which depend on both the concept class and the neighborhood system, and are closely related to the independence number of the associated neighborhood graph.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11920v1",
        "authors": [
          "Marco Bressan",
          "Nataly Brukhim",
          "Nicolo Cesa-Bianchi",
          "Emmanuel Esposito",
          "Yishay Mansour"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Conditional Averages We",
        "Framework",
        "Standard",
        "Act",
        "PAC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.487103"
    },
    {
      "id": "arxiv-2602.11760v1",
      "title": "Aggregate Models, Not Explanations: Improving Feature Importance Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11760v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Feature-importance methods show promise in transforming machine learning models from predictive engines into tools for scientific discovery. However, due to data sampling and algorithmic stochasticity, expressive models can be unstable, leading to inaccurate variable importance estimates and undermining their utility in critical biomedical applications. Although ensembling offers a solution, deciding whether to explain a single ensemble model or aggregate individual model explanations is difficult due to the nonlinearity of importance measures and remains largely understudied. Our theoretical analysis, developed under assumptions accommodating complex state-of-the-art ML models, reveals that this choice is primarily driven by the model's excess risk. In contrast to prior literature, we show that ensembling at the model level provides more accurate variable-importance estimates, particularly for expressive models, by reducing this leading error term. We validate these findings on classical benchmarks and a large-scale proteomic study from the UK Biobank.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11760v1",
        "authors": [
          "Joseph Paillard",
          "Angel Reyero Lobo",
          "Denis A. Engemann",
          "Bertrand Thirion"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Improving Feature Importance Estimation",
        "Aggregate Models",
        "Not Explanations",
        "Machine Learning",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.487701"
    },
    {
      "id": "arxiv-2602.11747v1",
      "title": "High-Probability Minimax Adaptive Estimation in Besov Spaces via Online-to-Batch",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11747v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study nonparametric regression over Besov spaces from noisy observations under sub-exponential noise, aiming to achieve minimax-optimal guarantees on the integrated squared error that hold with high probability and adapt to the unknown noise level. To this end, we propose a wavelet-based online learning algorithm that dynamically adjusts to the observed gradient noise by adaptively clipping it at an appropriate level, eliminating the need to tune parameters such as the noise variance or gradient bounds. As a by-product of our analysis, we derive high-probability adaptive regret bounds that scale with the $\\ell_1$-norm of the competitor. Finally, in the batch statistical setting, we obtain adaptive and minimax-optimal estimation rates for Besov spaces via a refined online-to-batch conversion. This approach carefully exploits the structure of the squared loss in combination with self-normalized concentration inequalities.",
        "keywords": [
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11747v1",
        "authors": [
          "Paul Liautaud",
          "Pierre Gaillard",
          "Olivier Wintenberger"
        ],
        "arxiv_categories": [
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Probability Minimax Adaptive Estimation",
        "Besov Spaces",
        "Batch We",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.488093"
    },
    {
      "id": "arxiv-2602.11722v1",
      "title": "PAC-Bayesian Generalization Guarantees for Fairness on Stochastic and Deterministic Classifiers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11722v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Classical PAC generalization bounds on the prediction risk of a classifier are insufficient to provide theoretical guarantees on fairness when the goal is to learn models balancing predictive risk and fairness constraints. We propose a PAC-Bayesian framework for deriving generalization bounds for fairness, covering both stochastic and deterministic classifiers. For stochastic classifiers, we derive a fairness bound using standard PAC-Bayes techniques. Whereas for deterministic classifiers, as usual PAC-Bayes arguments do not apply directly, we leverage a recent advance in PAC-Bayes to extend the fairness bound beyond the stochastic setting. Our framework has two advantages: (i) It applies to a broad class of fairness measures that can be expressed as a risk discrepancy, and (ii) it leads to a self-bounding algorithm in which the learning procedure directly optimizes a trade-off between generalization bounds on the prediction risk and on the fairness. We empirically evaluate our framework with three classical fairness measures, demonstrating not only its usefulness but also the tightness of our bounds.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11722v1",
        "authors": [
          "Julien Bastian",
          "Benjamin Leblanc",
          "Pascal Germain",
          "Amaury Habrard",
          "Christine Largeron"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deterministic Classifiers Classical",
        "Bayesian Generalization Guarantees",
        "Framework",
        "Standard",
        "NIST",
        "PAC",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.488558"
    },
    {
      "id": "arxiv-2602.11711v1",
      "title": "Estimation of instrument and noise parameters for inverse problem based on prior diffusion model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11711v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification.",
        "keywords": [
          "stat.ML",
          "cs.LG",
          "math.NA",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11711v1",
        "authors": [
          "Jean-François Giovannelli"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG",
          "math.NA",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Fusion",
        "MCMC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.489065"
    },
    {
      "id": "arxiv-2602.11679v1",
      "title": "Provable Offline Reinforcement Learning for Structured Cyclic MDPs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11679v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We introduce a novel cyclic Markov decision process (MDP) framework for multi-step decision problems with heterogeneous stage-specific dynamics, transitions, and discount factors across the cycle. In this setting, offline learning is challenging: optimizing a policy at any stage shifts the state distributions of subsequent stages, propagating mismatch across the cycle. To address this, we propose a modular structural framework that decomposes the cyclic process into stage-wise sub-problems. While generally applicable, we instantiate this principle as CycleFQI, an extension of fitted Q-iteration enabling theoretical analysis and interpretation. It uses a vector of stage-specific Q-functions, tailored to each stage, to capture within-stage sequences and transitions between stages. This modular design enables partial control, allowing some stages to be optimized while others follow predefined policies. We establish finite-sample suboptimality error bounds and derive global convergence rates under Besov regularity, demonstrating that CycleFQI mitigates the curse of dimensionality compared to monolithic baselines. Additionally, we propose a sieve-based method for asymptotic inference of optimal policy values under a margin condition. Experiments on simulated and real-world Type 1 Diabetes data sets demonstrate CycleFQI's effectiveness.",
        "keywords": [
          "stat.ML",
          "cs.AI",
          "cs.LG",
          "math.OC",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11679v1",
        "authors": [
          "Kyungbok Lee",
          "Angelica Cristello Sarteau",
          "Michael R. Kosorok"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.AI",
          "cs.LG",
          "math.OC",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Provable Offline Reinforcement Learning",
        "Structured Cyclic",
        "Framework",
        "Policy",
        "Act",
        "MIT",
        "MDP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.489577"
    },
    {
      "id": "arxiv-2602.11610v1",
      "title": "Improving the adjusted Benjamini--Hochberg method using e-values in knockoff-assisted variable selection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11610v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Considering the knockoff-based multiple testing framework of Barber and Candès [2015], we revisit the method of Sarkar and Tang [2022] and identify it as a specific case of an un-normalized e-value weighted Benjamini-Hochberg procedure. Building on this insight, we extend the method to use bounded p-to-e calibrators that enable more refined and flexible weight assignments. Our approach generalizes the method of Sarkar and Tang [2022], which emerges as a special case corresponding to an extreme calibrator. Within this framework, we propose three procedures: an e-value weighted Benjamini-Hochberg method, its adaptive extension using an estimate of the proportion of true null hypotheses, and an adaptive weighted Benjamini-Hochberg method. We establish control of the false discovery rate (FDR) for the proposed methods. While we do not formally prove that the proposed methods outperform those of Barber and Candès [2015] and Sarkar and Tang [2022], simulation studies and real-data analysis demonstrate large and consistent improvement over the latter in all cases, and better performance than the knockoff method in scenarios with low target FDR, a small number of signals, and weak signal strength. Simulation studies and a real-data application in HIV-1 drug resistance analysis demonstrate strong finite sample FDR control and exhibit improved, or at least competitive, power relative to the aforementioned methods.",
        "keywords": [
          "stat.ME",
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11610v1",
        "authors": [
          "Aniket Biswas",
          "Aaditya Ramdas"
        ],
        "arxiv_categories": [
          "stat.ME",
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "HIV-1",
        "FDR",
        "HIV",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.490667"
    },
    {
      "id": "arxiv-2602.11520v1",
      "title": "Locally Interpretable Individualized Treatment Rules for Black-Box Decision Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11520v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Individualized treatment rules (ITRs) aim to optimize healthcare by tailoring treatment decisions to patient-specific characteristics. Existing methods typically rely on either interpretable but inflexible models or highly flexible black-box approaches that sacrifice interpretability; moreover, most impose a single global decision rule across patients. We introduce the Locally Interpretable Individualized Treatment Rule (LI-ITR) method, which combines flexible machine learning models to accurately learn complex treatment outcomes with locally interpretable approximations to construct subject-specific treatment rules. LI-ITR employs variational autoencoders to generate realistic local synthetic samples and learns individualized decision rules through a mixture of interpretable experts. Simulation studies show that LI-ITR accurately recovers true subject-specific local coefficients and optimal treatment strategies. An application to precision side-effect management in breast cancer illustrates the necessity of flexible predictive modeling and highlights the practical utility of LI-ITR in estimating optimal treatment rules while providing transparent, clinically interpretable explanations.",
        "keywords": [
          "stat.ME",
          "cs.AI",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11520v1",
        "authors": [
          "Yasin Khadem Charvadeh",
          "Katherine S. Panageas",
          "Yuan Chen"
        ],
        "arxiv_categories": [
          "stat.ME",
          "cs.AI",
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Locally Interpretable Individualized Treatment",
        "Box Decision Models Individualized",
        "Machine Learning",
        "Act",
        "ITR",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.491140"
    },
    {
      "id": "arxiv-2602.11511v1",
      "title": "Representation Learning with Blockwise Missingness and Signal Heterogeneity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11511v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Unified representation learning for multi-source data integration faces two important challenges: blockwise missingness and blockwise signal heterogeneity. The former arises from sources observing different, yet potentially overlapping, feature sets, while the latter involves varying signal strengths across subject groups and feature sets. While existing methods perform well with fully observed data or uniform signal strength, their performance degenerates when these two challenges coincide, which is common in practice. To address this, we propose Anchor Projected Principal Component Analysis (APPCA), a general framework for representation learning with structured blockwise missingness that is robust to signal heterogeneity. APPCA first recovers robust group-specific column spaces using all observed feature sets, and then aligns them by projecting shared \"anchor\" features onto these subspaces before performing PCA. This projection step induces a significant denoising effect. We establish estimation error bounds for embedding reconstruction through a fine-grained perturbation analysis. In particular, using a novel spectral slicing technique, our bound eliminates the standard dependency on the signal strength of subject embeddings, relying instead solely on the signal strength of integrated feature sets. We validate the proposed method through extensive simulation studies and an application to multimodal single-cell sequencing data.",
        "keywords": [
          "stat.ME",
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11511v1",
        "authors": [
          "Ziqi Liu",
          "Ye Tian",
          "Weijing Tang"
        ],
        "arxiv_categories": [
          "stat.ME",
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Anchor Projected Principal Component",
        "Signal Heterogeneity Unified",
        "Representation Learning",
        "Blockwise Missingness",
        "Framework",
        "Standard",
        "APPCA",
        "Act",
        "PCA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.491681"
    },
    {
      "id": "arxiv-2602.11496v1",
      "title": "High-Dimensional Mediation Analysis for Generalized Linear Models Using Bayesian Variable Selection Guided by Mediator Correlation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11496v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "High-dimensional mediation analysis aims to identify mediating pathways and to estimate indirect effects linking an exposure to an outcome. In this paper, we propose a Bayesian framework to address key challenges in these analyses, including high dimensionality, complex dependence among omics mediators, and non-continuous outcomes. Furthermore, commonly used approaches assume independent mediators or ignore correlations in the selection stage, which can reduce power when mediators are highly correlated. Addressing these challenges leads to a non-Gaussian likelihood and specialized selection priors, which in turn require efficient and adaptive posterior computation. Our proposed framework selects active pathways under generalized linear models while accounting for mediator dependence. Specifically, the mediators are modeled using a multivariate distribution, exposure-mediator selection is guided by a Markov random field prior on inclusion indicators, and mediator-outcome activation is restricted to mediators supported in the exposure-mediator model through a sequential subsetting Bernoulli prior. Simulation studies show improved operating characteristics in correlated-mediator settings, with appropriate error control under the global null and stable performance under model misspecification. We illustrate the method using real-world metabolomics data to study metabolites that mediate the association between adherence to the Alternate Mediterranean Diet score and two cardiometabolic outcomes.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11496v1",
        "authors": [
          "Youngho Bae",
          "Chanmin Kim",
          "Fenglei Wang",
          "Qi Sun",
          "Kyu Ha Lee"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bayesian Variable Selection Guided",
        "Generalized Linear Models Using",
        "Dimensional Mediation Analysis",
        "Alternate Mediterranean Diet",
        "Mediator Correlation High",
        "Framework",
        "Meta",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:22.492268"
    },
    {
      "id": "arxiv-2602.11956v1",
      "title": "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11956v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The brain interprets visual information through learned regularities, a computation formalized as probabilistic inference under a prior. The visual cortex establishes priors for this inference, some delivered through established top-down connections that inform low-level cortices about statistics represented at higher levels in the cortical hierarchy. While evidence shows that adaptation leads to priors reflecting the structure of natural images, it remains unclear whether similar priors can be flexibly acquired when learning a specific task. To investigate this, we built a generative model of V1 optimized for a simple discrimination task and analyzed it together with large-scale recordings from mice performing an analogous task. In line with recent approaches, we assumed that neuronal activity in V1 corresponds to latent posteriors in the generative model, enabling investigation of task-related priors in neuronal responses. To obtain a flexible test bed, we extended the VAE formalism so that a task can be acquired efficiently by reusing previously learned representations. Task-specific priors learned by this Task-Amortized VAE were used to investigate biases in mice and model when presenting stimuli that violated trained task statistics. Mismatch between learned task statistics and incoming sensory evidence produced signatures of uncertainty in stimulus category in the TAVAE posterior, reflecting properties of bimodal response profiles in V1 recordings. The task-optimized generative model accounted for key characteristics of V1 population activity, including within-day updates to population responses. Our results confirm that flexible task-specific contextual priors can be learned on demand by the visual system and deployed as early as the entry level of visual cortex.",
        "keywords": [
          "q-bio.NC",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11956v1",
        "authors": [
          "Balázs Meszéna",
          "Keith T. Murray",
          "Julien Corbo",
          "O. Batuhan Erkat",
          "Márton A. Hajnal"
        ],
        "arxiv_categories": [
          "q-bio.NC",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Adaptable Priors Explains Contextual",
        "TAVAE",
        "Act",
        "VAE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-15T13:54:26.686746"
    },
    {
      "id": "arxiv-2602.11618v1",
      "title": "How Well Do Large-Scale Chemical Language Models Transfer to Downstream Tasks?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11618v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Chemical Language Models (CLMs) pre-trained on large scale molecular data are widely used for molecular property prediction. However, the common belief that increasing training resources such as model size, dataset size, and training compute improves both pretraining loss and downstream task performance has not been systematically validated in the chemical domain. In this work, we evaluate this assumption by pretraining CLMs while scaling training resources and measuring transfer performance across diverse molecular property prediction (MPP) tasks. We find that while pretraining loss consistently decreases with increased training resources, downstream task performance shows limited improvement. Moreover, alternative metrics based on the Hessian or loss landscape also fail to estimate downstream performance in CLMs. We further identify conditions under which downstream performance saturates or degrades despite continued improvements in pretraining metrics, and analyze the underlying task dependent failure modes through parameter space visualizations. These results expose a gap between pretraining based evaluation and downstream performance, and emphasize the need for model selection and evaluation strategies that explicitly account for downstream task characteristics.",
        "keywords": [
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11618v1",
        "authors": [
          "Tatsuya Sagawa",
          "Ryosuke Kojima"
        ],
        "arxiv_categories": [
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scale Chemical Language Models",
        "Chemical Language Models",
        "How Well Do Large",
        "Downstream Tasks",
        "Act",
        "NSF",
        "MIT",
        "MPP",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:26.687646"
    },
    {
      "id": "arxiv-2602.11609v1",
      "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11609v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotation, developmental-trajectory reconstruction, and transcription-factor targeting, into step-by-step reasoning problems that the model must solve, justify, and, when needed, revise with new evidence. To measure progress, we release scBench, a suite of 9 expertly curated datasets and graders that faithfully evaluate the omics-native reasoning capability of scPilot w.r.t various LLMs. Experiments with o1 show that iterative omics-native reasoning lifts average accuracy by 11% for cell-type annotation and Gemini-2.5-Pro cuts trajectory graph-edit distance by 30% versus one-shot prompting, while generating transparent reasoning traces explain marker gene ambiguity and regulatory logic. By grounding LLMs in raw omics data, scPilot enables auditable, interpretable, and diagnostically informative single-cell analyses. Code, data, and package are available at https://github.com/maitrix-org/scPilot",
        "keywords": [
          "cs.AI",
          "q-bio.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11609v1",
        "authors": [
          "Yiming Gao",
          "Zhen Wang",
          "Jefferson Chen",
          "Mark Antkowiak",
          "Mengzhou Hu"
        ],
        "arxiv_categories": [
          "cs.AI",
          "q-bio.GN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Model Reasoning",
        "Toward Automated Single",
        "Cell Analysis",
        "Discovery We",
        "Gemini-2.5",
        "Framework",
        "Act",
        "LLM",
        "RNA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:26.688363"
    },
    {
      "id": "arxiv-2602.11478v1",
      "title": "Defining causal mechanism in dual process theory and two types of feedback control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11478v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Mental events are considered to supervene on physical events. A supervenient event does not change without a corresponding change in the underlying subvenient physical events. Since wholes and their parts exhibit the same supervenience-subvenience relations, inter-level causation has been expected to serve as a model for mental causation. We proposed an inter-level causation mechanism to construct a model of consciousness and an agent's self-determination. However, a significant gap exists between this mechanism and cognitive functions. Here, we demonstrate how to integrate the inter-level causation mechanism with the widely known dual-process theories. We assume that the supervenience level is composed of multiple supervenient functions (i.e., neural networks), and we argue that inter-level causation can be achieved by controlling the feedback error defined through changing algebraic expressions combining these functions. Using inter-level causation allows for a dual laws model in which each level possesses its own distinct dynamics. In this framework, the feedback error is determined independently by two processes: (1) the selection of equations combining supervenient functions, and (2) the negative feedback error reduction to satisfy the equations through adjustments of neurons and synapses. We interpret these two independent feedback controls as Type 1 and Type 2 processes in the dual process theories. As a result, theories of consciousness, agency, and dual process theory are unified into a single framework, and the characteristic features of Type 1 and Type 2 processes are naturally derived.",
        "keywords": [
          "q-bio.NC",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11478v1",
        "authors": [
          "Yoshiyuki Ohmura",
          "Yasuo Kuniyoshi"
        ],
        "arxiv_categories": [
          "q-bio.NC",
          "eess.SY"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Neural Network",
        "Framework",
        "Act",
        "WHO",
        "DOE",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-15T13:54:26.689188"
    },
    {
      "id": "arxiv-2602.12202v1",
      "title": "Equivalent Circuit Modeling of Grid-Forming Inverters in (Sub)-Transient Time-Frame",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12202v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The widely accepted definition of grid-forming (GFM) inverter states that it should behave as a (nearly) constant voltage source behind an impedance by maintaining a (nearly) constant internal voltage phasor in the sub-transient to transient time frame. Some system operators further mandate permissible ranges for this effective impedance. However, these specifications do not clearly define the location of the internal voltage source, and no systematic method exists to quantify its effective impedance for a black-box GFM model. To address this, we first compare the transient responses of an ideal voltage source and a GFM to show that an idealistic GFM maintains a (nearly) constant voltage across the filter capacitor, rather than at the inverter switches. Then we propose a systematic method to quantify the effective impedance of a GFM from its black-box model using frequency-domain admittance plots. Using standard PSCAD GFM models developed by NREL, we demonstrate that the GFM's equivalent impedance model captures the sub-transient response and static voltage stability limit reasonably accurately.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12202v1",
        "authors": [
          "Ambuj Gupta",
          "Balarko Chaudhuri",
          "Mark O'Malley"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Equivalent Circuit Modeling",
        "Forming Inverters",
        "Transient Time",
        "Standard",
        "PSCAD",
        "NREL",
        "MIT",
        "GFM",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.870825"
    },
    {
      "id": "arxiv-2602.12198v1",
      "title": "Continuous and Discrete-Time Filters: A Unified Operational Perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12198v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents a unified tutorial treatment of continuous-time and discrete-time linear time-invariant systems, emphasizing their shared dynamical structure and the physical constraints that differentiate their realizations. Rather than introducing new mathematical tools, the manuscript revisits foundational concepts-transfer functions, poles and zeros, impulse responses, and stability-from an operational perspective rooted in practical signal processing and circuit implementation. First-order systems are used as a minimal yet expressive framework to illustrate how integration, differentiation, filtering, and delay manifest across the Laplace and Z domains. Particular attention is given to causality, bandwidth limitations, sampling effects, and the approximation errors inherent in discrete-time representations. The goal is to bridge the gap between formal mathematical descriptions and the intuition required for reliable system design in mixed analog-digital environments.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12198v1",
        "authors": [
          "Luca Giangrande"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Filters",
        "Framework",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.871382"
    },
    {
      "id": "arxiv-2602.12098v1",
      "title": "ViPer NL-COMM: Making Vector Perturbation Precoding Practical",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12098v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Large MIMO systems rely on efficient downlink precoding to enhance data rates and improve connectivity through spatial multiplexing. However, currently employed linear precoding techniques, such as MMSE, significantly limit the achievable spectral efficiency. To meet practical error-rate targets, existing linear methods require an excessively high number of access point antennas relative to the number of supported users, leading to disproportionate increases in power consumption.Efficient non-linear processing frameworks for uplink MIMO transmissions, such as NL-COMM, have been proposed. However, downlink non-linear precoding methods, such as Vector Perturbation (VP), remain impractical for real-world deployment due to their exponentially increasing computational complexity with the number of supported streams. This work presents ViPer NL-COMM, the first practical algorithmic and implementation framework for VP-based precoding. ViPer NL-COMM extends the core principles of NL-COMM to the precoding problem, enabling scalable parallelization and real-time computational performance while maintaining the substantial spectral-efficiency benefits of VP precoding. ViPer NL-COMM consists of a novel mathematical framework and an FPGA prototype capable of supporting large MIMO configurations (up to 16x16), high-order modulation (256-QAM), and wide bandwidths (100 MHz) within practical power and resource budgets. System-level evaluations demonstrate that ViPer NL-COMM achieves target error rates using only half the number of transmit antennas required by linear precoding, yielding net power savings on the order of hundreds of Watts at the RF front end. Moreover, ViPer NL-COMM enables supporting more information streams than available AP antennas when the streams are of low-rate, paving the way for enhanced massive-connectivity scenarios in next-generation wireless networks.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12098v1",
        "authors": [
          "Thomas James Thomas",
          "George N. Katsaros",
          "Chathura Jayawardena",
          "Konstantinos Nikitopoulos"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Making Vector Perturbation Precoding",
        "Vector Perturbation",
        "Practical Large",
        "Framework",
        "MIMO",
        "MMSE",
        "FPGA",
        "COMM",
        "Act",
        "MIT",
        "QAM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.872195"
    },
    {
      "id": "arxiv-2602.12040v1",
      "title": "Exploiting Structural Flexibility in SIM-Enabled Communications: From Adaptive Inter-Layer Spacing to Fully Morphable Layers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12040v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Stacked intelligent metasurfaces (SIMs) have recently emerged as a promising metasurface-based physical-layer paradigm for wireless communications, enabling wave-domain signal processing through multiple cascaded metasurface layers. However, conventional SIM designs rely on rigid planar layers with fixed interlayer spacing, which constrain the propagation geometry and can lead to performance saturation as the number of layers increases. This paper investigates the potential of introducing structural flexibility into SIM-enabled communication systems. Specifically, we consider two flexible SIM architectures: distance-adaptive SIM (DSIM), where interlayer distances are optimized, and stacked flexible intelligent metasurface (SFIM), where each metasurface layer is fully morphable. We jointly design the meta-atom positions and responses together with the transmit beamformer to maximize the system sum rate under per-user rate, quantization, morphing, and interlayer distance constraints. An alternating optimization framework combining gradient projection, penalty-based method, and successive convex approximation is developed to address the resulting non-convex problems. Perturbation analysis reveals that the flexibility gains of both DSIM and SFIM scale approximately linearly with the morphing range, with SFIM exhibiting a faster growth rate. Simulation results demonstrate that flexible SIM designs mitigate performance saturation with increasing layers and achieve significant transmit power savings compared to rigid SIMs.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12040v1",
        "authors": [
          "Ahmed Magbool",
          "Vaibhav Kumar",
          "Marco Di Renzo",
          "Mark F. Flanagan"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Exploiting Structural Flexibility",
        "Fully Morphable Layers Stacked",
        "Enabled Communications",
        "From Adaptive Inter",
        "Layer Spacing",
        "Framework",
        "Intel",
        "DSIM",
        "Meta",
        "SFIM",
        "MIT",
        "SIM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.872844"
    },
    {
      "id": "arxiv-2602.12016v1",
      "title": "Adaptive Behavioral Predictive Control: State-Free Regulation Without Hankel Weights",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.12016v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents adaptive behavioral predictive control (ABPC), an indirect adaptive predictive control framework operating on streaming data. An LPV--ARX predictor is identified online via kernel--recursive least squares and used to compute closed-form predictive control sequences over a finite horizon, avoiding batch Hankel constructions and iterative optimization. Nonlinear kernel dictionaries extend model expressiveness within a behavioral formulation. Numerical studies on Hammerstein and NARX systems demonstrate effective performance when the dictionary aligns with the plant class and highlight conditioning and feature-selection effects. The paper emphasizes numerical simulation, computational feasibility, and reproducibility.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.12016v1",
        "authors": [
          "Tam W. Nguyen"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adaptive Behavioral Predictive Control",
        "Free Regulation Without Hankel",
        "Regulation",
        "Framework",
        "ABPC",
        "NARX",
        "LPV",
        "ARX"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.873150"
    },
    {
      "id": "arxiv-2602.11950v1",
      "title": "Radio Map Prediction from Noisy Environment Information and Sparse Observations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11950v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Many works have investigated radio map and path loss prediction in wireless networks using deep learning, in particular using convolutional neural networks. However, most assume perfect environment information, which is unrealistic in practice due to sensor limitations, mapping errors, and temporal changes. We demonstrate that convolutional neural networks trained with task-specific perturbations of geometry, materials, and Tx positions can implicitly compensate for prediction errors caused by inaccurate environment inputs. When tested with noisy inputs on synthetic indoor scenarios, models trained with perturbed environment data reduce error by up to 25\\% compared to models trained on clean data. We verify our approach on real-world measurements, achieving 2.1 dB RMSE with noisy input data and 1.3 dB with complete information, compared to 2.3-3.1 dB for classical methods such as ray-tracing and radial basis function interpolation. Additionally, we compare different ways of encoding environment information at varying levels of detail and we find that, in the considered single-room indoor scenarios, binary occupancy encoding performs at least as well as detailed material property information, simplifying practical deployment.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11950v1",
        "authors": [
          "Fabian Jaensch",
          "Çağkan Yapar",
          "Giuseppe Caire",
          "Begüm Demir"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Noisy Environment Information",
        "Sparse Observations Many",
        "Radio Map Prediction",
        "Neural Network",
        "Deep Learning",
        "RMSE",
        "Act",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.873643"
    },
    {
      "id": "arxiv-2602.11899v1",
      "title": "Gradient-Based Adaptive Prediction and Control for Nonlinear Dynamical Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11899v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper investigates gradient-based adaptive prediction and control for nonlinear stochastic dynamical systems under a weak convexity condition on the prediction-based loss. This condition accommodates a broad range of nonlinear models in control and machine learning such as saturation functions, sigmoid, ReLU and tanh activation functions, and standard classification models. Without requiring any persistent excitation of the data, we establish global convergence of the proposed adaptive predictor and derive explicit rates for its asymptotic performance. Furthermore, under a classical nonlinear minimum-phase condition and with a linear growth bound on the nonlinearities, we establish the convergence rate of the resulting closed-loop control error. Finally, we demonstrate the effectiveness of the proposed adaptive prediction algorithm on a real-world judicial sentencing dataset. The adaptive control performance will also be evaluated via a numerical simulation.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11899v1",
        "authors": [
          "Yujing Liu",
          "Xin Zheng",
          "Zhixin Liu",
          "Lei Guo"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Adaptive Prediction",
        "Machine Learning",
        "Standard",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.874155"
    },
    {
      "id": "arxiv-2602.11891v1",
      "title": "Is Downlink Training Necessary for User-Centric Cell-Free RSMA Systems With Mobile Users?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11891v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "We study the spectral efficiency (SE) of a ratesplitting multiple access (RSMA) enabled multi-clustered cell-free (CF) massive multiple-input multiple-output (mMIMO) system. The access points (APs) in each cluster serve mobile user equipments (UEs) by employing RSMA. The UEs employ successive interference cancellation to decode their data. This work emphasizes the role of downlink (DL) pilots in realizing RSMA benefits in practical CF systems with spatially-correlated Rician channels which observe random phase shifts, pilot contamination, and channel aging due to UE mobility. We numerically show that DL pilots are required for RSMA in user-centric CF mMIMO systems with channel aging to outperform spatial division multiple access. We show that the degraded channel quality due to higher UE velocity and longer resource block lengths significantly reduces the RSMA SE. Increasing the number of clusters can compensate for the SE loss.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11891v1",
        "authors": [
          "Ravi Kiran Palla",
          "Dheeraj Naidu Amudala",
          "Ronit Budhiraja"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Is Downlink Training Necessary",
        "Systems With Mobile Users",
        "Centric Cell",
        "RSMA",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.874740"
    },
    {
      "id": "arxiv-2602.11842v1",
      "title": "A day-ahead market model for power systems: benchmarking and security implications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11842v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Power system security assessments, e.g. via cascading outage models, often use operational set-points based on optimal power flow (OPF) dispatch. However, driven by cost minimization, OPF provides an ideal, albeit unrealistic, clearing of the generating units, disregarding the complex interactions among market participants. The security of the system, therefore, may be overestimated. To address this gap, we introduce a market model with a social-welfare-based day-ahead market clearing mechanism. The security implications are analyzed via Cascades, a cascading outage analysis framework. We apply this framework to the IEEE-118 bus system with three independent control zones. The results show that market dispatch leads to an increase in demand not served of up to 80% higher than OPF, highlighting a security overestimation. Operators can use this information to properly allocate reserves and perform efficient expansion planning strategies.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11842v1",
        "authors": [
          "Andrej Stankovski",
          "Blazhe Gjorgiev",
          "James Ciyu Qin",
          "Giovanni Sansavini"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "IEEE-118",
        "IEEE",
        "Act",
        "OPF",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.875341"
    },
    {
      "id": "arxiv-2602.11834v1",
      "title": "EqDeepRx: Learning a Scalable MIMO Receiver",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11834v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "While machine learning (ML)-based receiver algorithms have received a great deal of attention in the recent literature, they often suffer from poor scaling with increasing spatial multiplexing order and lack of explainability and generalization. This paper presents EqDeepRx, a practical deep-learning-aided multiple-input multiple-output (MIMO) receiver, which is built by augmenting linear receiver processing with carefully engineered ML blocks. At the core of the receiver model is a shared-weight DetectorNN that operates independently on each spatial stream or layer, enabling near-linear complexity scaling with respect to multiplexing order. To ensure better explainability and generalization, EqDeepRx retains conventional channel estimation and augments it with a lightweight DenoiseNN that learns frequency-domain smoothing. To reduce the dimensionality of the DetectorNN inputs, the receiver utilizes two linear equalizers in parallel: a linear minimum mean-square error (LMMSE) equalizer with interference-plus-noise covariance estimation and a regularized zero-forcing (RZF) equalizer. The parallel equalized streams are jointly consumed by the DetectorNN, after which a compact DemapperNN produces bit log-likelihood ratios for channel decoding. 5G/6G-compliant end-to-end simulations across multiple channel scenarios, pilot patterns, and inter-cell interference conditions show improved error rate and spectral efficiency over a conventional baseline, while maintaining low-complexity inference and support for different MIMO configurations without retraining.",
        "keywords": [
          "eess.SP",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11834v1",
        "authors": [
          "Mikko Honkala",
          "Dani Korpi",
          "Elias Raninen",
          "Janne M. J. Huttunen"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Receiver While",
        "LMMSE",
        "MIMO",
        "Act",
        "RZF",
        "5G",
        "6G",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.875924"
    },
    {
      "id": "arxiv-2602.11804v1",
      "title": "Efficient Segment Anything with Depth-Aware Fusion and Limited Training Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11804v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Segment Anything Models (SAM) achieve impressive universal segmentation performance but require massive datasets (e.g., 11M images) and rely solely on RGB inputs. Recent efficient variants reduce computation but still depend on large-scale training. We propose a lightweight RGB-D fusion framework that augments EfficientViT-SAM with monocular depth priors. Depth maps are generated with a pretrained estimator and fused mid-level with RGB features through a dedicated depth encoder. Trained on only 11.2k samples (less than 0.1\\% of SA-1B), our method achieves higher accuracy than EfficientViT-SAM, showing that depth cues provide strong geometric priors for segmentation.",
        "keywords": [
          "cs.CV",
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11804v1",
        "authors": [
          "Yiming Zhou",
          "Xuenjie Xie",
          "Panfeng Li",
          "Albrecht Kunz",
          "Ahmad Osman"
        ],
        "arxiv_categories": [
          "cs.CV",
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Limited Training Data Segment",
        "Efficient Segment Anything",
        "Anything Models",
        "Aware Fusion",
        "Framework",
        "Fusion",
        "MIT",
        "SAM",
        "RGB",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.876432"
    },
    {
      "id": "arxiv-2602.11784v1",
      "title": "On the Maintainability of Pinching-Antenna Systems: A Failure-Repair Perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11784v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "The pinching-antenna system (PASS) enables wireless channel reconfiguration through optimized placement of pinching antennas along dielectric waveguides. In this article, a unified analytical framework is proposed to characterize the maintainability of PASS. Within this framework, random waveguide failures and repairs are modeled by treating the waveguide lifetime and repair time as exponentially distributed random variables, which are characterized by the failure rate and the repair rate, respectively. The operational state of the waveguide is described by a two-state continuous-time Markov chain, for which the transition probabilities and steady-state probabilities of the waveguide being working or failed are analyzed. By incorporating the randomness of the waveguide operational state into the transmission rate, system maintainability is characterized using the probability of non-zero rate (PNR) and outage probability (OP). The proposed framework is applied to both a conventional PASS employing a single long waveguide and a segmented waveguide-enabled pinching-antenna system (SWAN) composed of multiple short waveguide segments under two operational protocols: segment switching (SS) and segment aggregation (SA). Closed-form expressions for the PNR and OP are derived for both architectures, and the corresponding scaling laws are analyzed with respect to the service-region size and the number of segments. It is proven that both SS-based and SA-based SWAN achieve higher PNR and lower OP than conventional PASS, which confirms the maintainability advantage of segmentation. Numerical results demonstrate that: i) the maintainability gain of SWAN over conventional PASS increases with the number of segments, and ii) SA provides stronger maintainability than SS.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11784v1",
        "authors": [
          "Chongjun Ouyang",
          "Hao Jiang",
          "Zhaolin Wang",
          "Yuanwei Liu",
          "Zhiguo Ding"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Antenna Systems",
        "Framework",
        "Protocol",
        "SWAN",
        "PASS",
        "PNR",
        "Act",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.877091"
    },
    {
      "id": "arxiv-2602.11704v1",
      "title": "U-DAVI: Uncertainty-Aware Diffusion-Prior-Based Amortized Variational Inference for Image Reconstruction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11704v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Ill-posed imaging inverse problems remain challenging due to the ambiguity in mapping degraded observations to clean images. Diffusion-based generative priors have recently shown promise, but typically rely on computationally intensive iterative sampling or per-instance optimization. Amortized variational inference frameworks address this inefficiency by learning a direct mapping from measurements to posteriors, enabling fast posterior sampling without requiring the optimization of a new posterior for every new set of measurements. However, they still struggle to reconstruct fine details and complex textures. To address this, we extend the amortized framework by injecting spatially adaptive perturbations to measurements during training, guided by uncertainty estimates, to emphasize learning in the most uncertain regions. Experiments on deblurring and super-resolution demonstrate that our method achieves superior or competitive performance to previous diffusion-based approaches, delivering more realistic reconstructions without the computational cost of iterative refinement.",
        "keywords": [
          "eess.IV",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11704v1",
        "authors": [
          "Ayush Varshney",
          "Katherine L. Bouman",
          "Berthy T. Feng"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Amortized Variational Inference",
        "Image Reconstruction Ill",
        "Aware Diffusion",
        "Framework",
        "Fusion",
        "DAVI",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.877529"
    },
    {
      "id": "arxiv-2602.11670v1",
      "title": "Exploring Frequency-Domain Feature Modeling for HRTF Magnitude Upsampling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11670v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Accurate upsampling of Head-Related Transfer Functions (HRTFs) from sparse measurements is crucial for personalized spatial audio rendering. Traditional interpolation methods, such as kernel-based weighting or basis function expansions, rely on measurements from a single subject and are limited by the spatial sampling theorem, resulting in significant performance degradation under sparse sampling. Recent learning-based methods alleviate this limitation by leveraging cross-subject information, yet most existing neural architectures primarily focus on modeling spatial relationships across directions, while spectral dependencies along the frequency dimension are often modeled implicitly or treated independently. However, HRTF magnitude responses exhibit strong local continuity and long-range structure in the frequency domain, which are not fully exploited. This work investigates frequency-domain feature modeling by examining how different architectural choices, ranging from per-frequency multilayer perceptrons to convolutional, dilated convolutional, and attention-based models, affect performance under varying sparsity levels, showing that explicit spectral modeling consistently improves reconstruction accuracy, particularly under severe sparsity. Motivated by this observation, a frequency-domain Conformer-based architecture is adopted to jointly capture local spectral continuity and long-range frequency correlations. Experimental results on the SONICOM and HUTUBS datasets demonstrate that the proposed method achieves state-of-the-art performance in terms of interaural level difference and log-spectral distortion.",
        "keywords": [
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11670v1",
        "authors": [
          "Xingyu Chen",
          "Hanwen Bi",
          "Fei Ma",
          "Sipei Zhao",
          "Eva Cheng"
        ],
        "arxiv_categories": [
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Magnitude Upsampling Accurate",
        "Related Transfer Functions",
        "Domain Feature Modeling",
        "Exploring Frequency",
        "HUTUBS",
        "HRTF",
        "NSF",
        "MIT",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.878170"
    },
    {
      "id": "arxiv-2602.11654v1",
      "title": "Beamforming Gain Maximization for Fluid Reconfigurable Intelligent Surface: A Minkowski Geometry Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11654v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper investigates beamforming-gain maximization for a fluid reconfigurable intelligent surface (FRIS)-assisted downlink system, where each active port applies a finite-resolution unit-modulus phase selected from a discrete codebook. The resulting design couples the multi-antenna base-station (BS) beamformer with combinatorial FRIS port selection and discrete phase assignment, leading to a highly nonconvex mixed discrete optimization. To address this challenge, we develop an alternating-optimization (AO) framework that alternates between a closed-form maximum-ratio-transmission (MRT) update at the BS and an {optimal} FRIS-configuration update. The key step of the proposed FRIS configuration is a Minkowski-geometry reformulation of the FRIS codebook superposition: by convexifying the feasible reflected-sum set and exploiting support-function identities, we convert the FRIS subproblem into a one-dimensional maximization over a directional parameter. For each direction, the optimal configuration is obtained constructively via per-port directional scoring, Top-$M_o$ port selection, and optimal codeword assignment. For the practically important regular $M_p$-gon phase-shifter codebook, we further derive closed-form score expressions and establish a piecewise-smooth structure of the resulting support function, which leads to a finite critical-angle search that provably identifies the global optimum without exhaustive angular sweeping. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks, achieves near-optimal beamforming gains in exhaustive-search validations, accurately identifies the optimal direction via support-function maximization, and converges rapidly within a few AO iterations.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11654v1",
        "authors": [
          "Hong-Bae Jeon"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fluid Reconfigurable Intelligent Surface",
        "Beamforming Gain Maximization",
        "Framework",
        "Intel",
        "FRIS",
        "Act",
        "MRT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.878693"
    },
    {
      "id": "arxiv-2602.11547v1",
      "title": "H.265/HEVC Video Steganalysis Based on CU Block Structure Gradients and IPM Mapping",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11547v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Existing H.265/HEVC video steganalysis research mainly focuses on statistical feature modeling at the levels of motion vectors (MV), intra prediction modes (IPM), or transform coefficients. In contrast, studies targeting the coding-structure level - especially the analysis of block-level steganographic behaviors in Coding Units (CUs) - remain at an early stage. As a core component of H.265/HEVC coding decisions, the CU partition structure often exhibits steganographic perturbations in the form of structural changes and reorganization of prediction relationships, which are difficult to characterize effectively using traditional pixel-domain features or mode statistics. To address this issue, this paper, for the first time from the perspective of CU block-level steganalysis, proposes an H.265/HEVC video steganalysis method based on CU block-structure gradients and intra prediction mode mapping. The proposed method constructs a CU block-structure gradient map to explicitly describe changes in coding-unit partitioning, and combines it with a block-level mapping representation of IPM to jointly model the structural perturbations introduced by CU-level steganographic embedding. On this basis, we design a Transformer network, GradIPMFormer, tailored for CU-block steganalysis, thereby effectively enhancing the capability to perceive CU-level steganographic behaviors. Experimental results show that under different quantization parameters and resolution settings, the proposed method consistently achieves superior detection performance across multiple H.265/HEVC steganographic algorithms, validating the feasibility and effectiveness of conducting video steganalysis from the coding-structure perspective. This study provides a new CU block-level analysis paradigm for H.265/HEVC video steganalysis and has significant research value for covert communication security detection.",
        "keywords": [
          "eess.IV",
          "cs.MM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11547v1",
        "authors": [
          "Xiang Zhang",
          "Haiyang Xia",
          "Ziwen He",
          "Wenbin Huang",
          "Fei Peng"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.MM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Block Structure Gradients",
        "Video Steganalysis Based",
        "Mapping Existing",
        "Coding Units",
        "Transformer",
        "HEVC",
        "Act",
        "NSF",
        "IPM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.879450"
    },
    {
      "id": "arxiv-2602.11546v1",
      "title": "TC-BiMamba: Trans-Chunk bidirectionally within BiMamba for unified streaming and non-streaming ASR",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11546v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This work investigates bidirectional Mamba (BiMamba) for unified streaming and non-streaming automatic speech recognition (ASR). Dynamic chunk size training enables a single model for offline decoding and streaming decoding with various latency settings. In contrast, existing BiMamba based streaming method is limited to fixed chunk size decoding. When dynamic chunk size training is applied, training overhead increases substantially. To tackle this issue, we propose the Trans-Chunk BiMamba (TC-BiMamba) for dynamic chunk size training. Trans-Chunk mechanism trains both bidirectional sequences in an offline style with dynamic chunk size. On the one hand, compared to traditional chunk-wise processing, TC-BiMamba simultaneously achieves 1.3 times training speedup, reduces training memory by 50%, and improves model performance since it can capture bidirectional context. On the other hand, experimental results show that TC-BiMamba outperforms U2++ and matches LC-BiMmaba with smaller model size.",
        "keywords": [
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11546v1",
        "authors": [
          "Qingshun She",
          "Jing Peng",
          "Yangui Fang",
          "Yu Xi",
          "Kai Yu"
        ],
        "arxiv_categories": [
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "ASR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.879800"
    },
    {
      "id": "arxiv-2602.11488v1",
      "title": "When Audio-LLMs Don't Listen: A Cross-Linguistic Study of Modality Arbitration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11488v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "When audio and text conflict, speech-enabled language models follow the text 10 times more often than when arbitrating between two text sources, even when explicitly instructed to trust the audio. Using ALME, a benchmark of 57,602 controlled audio-text conflict stimuli across 8 languages, we find that Gemini 2.0 Flash exhibits 16.6\\% text dominance under audio-text conflict versus 1.6\\% under text-text conflict with identical reliability cues. This gap is not explained by audio quality: audio-only accuracy (97.2\\%) exceeds cascade accuracy (93.9\\%), indicating audio embeddings preserve more information than text transcripts. We propose that text dominance reflects an asymmetry not in information content but in arbitration accessibility: how easily the model can reason over competing representations. This framework explains otherwise puzzling findings. Forcing transcription before answering increases text dominance (19\\% to 33\\%), sacrificing audio's information advantage without improving accessibility. Framing text as ``deliberately corrupted'' reduces text dominance by 80\\%. A fine-tuning ablation provides interventional evidence: training only the audio projection layer increases text dominance (+26.5\\%), while LoRA on the language model halves it ($-$23.9\\%), localizing text dominance to the LLM's reasoning rather than the audio encoder. Experiments across four state-of-the-art audio-LLMs and 8 languages show consistent trends with substantial cross-linguistic and cross-model variation, establishing modality arbitration as a distinct reliability dimension not captured by standard speech benchmarks.",
        "keywords": [
          "cs.CL",
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11488v1",
        "authors": [
          "Jayadev Billa"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Modality Arbitration When",
        "Linguistic Study",
        "When Audio",
        "Framework",
        "Standard",
        "ALME",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.880353"
    },
    {
      "id": "arxiv-2602.11477v1",
      "title": "SLD-L2S: Hierarchical Subspace Latent Diffusion for High-Fidelity Lip to Speech Synthesis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11477v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Although lip-to-speech synthesis (L2S) has achieved significant progress in recent years, current state-of-the-art methods typically rely on intermediate representations such as mel-spectrograms or discrete self-supervised learning (SSL) tokens. The potential of latent diffusion models (LDMs) in this task remains largely unexplored. In this paper, we introduce SLD-L2S, a novel L2S framework built upon a hierarchical subspace latent diffusion model. Our method aims to directly map visual lip movements to the continuous latent space of a pre-trained neural audio codec, thereby avoiding the information loss inherent in traditional intermediate representations. The core of our method is a hierarchical architecture that processes visual representations through multiple parallel subspaces, initiated by a subspace decomposition module. To efficiently enhance interactions within and between these subspaces, we design the diffusion convolution block (DiCB) as our network backbone. Furthermore, we employ a reparameterized flow matching technique to directly generate the target latent vectors. This enables a principled inclusion of speech language model (SLM) and semantic losses during training, moving beyond conventional flow matching objectives and improving synthesized speech quality. Our experiments show that SLD-L2S achieves state-of-the-art generation quality on multiple benchmark datasets, surpassing existing methods in both objective and subjective evaluations.",
        "keywords": [
          "eess.AS",
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11477v1",
        "authors": [
          "Yifan Liang",
          "Andong Li",
          "Kang Yang",
          "Guochen Yu",
          "Fangkun Liu"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hierarchical Subspace Latent Diffusion",
        "Speech Synthesis Although",
        "Fidelity Lip",
        "Framework",
        "Fusion",
        "Act",
        "EPA",
        "SLM",
        "SLD",
        "SSL",
        "AI",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.880896"
    },
    {
      "id": "arxiv-2602.11473v1",
      "title": "Radar Sensing using Dual-Beam Reconfigurable Intelligent Surface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11473v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Around-the-corner radar sensing offers an opportunity for the radar to exploit multipath scattering along walls to detect targets beyond blockages. However, the radar detection performance is limited to spotting uncooperative targets at specular angles. Recently, reconfigurable intelligent surfaces (RIS) involving metasurfaces with tunable unit cells have been researched for enhancing radar coverage around corners by directing beams towards non-specular angles. This article examines how practical considerations regarding the phase tuning of unit cells impact the RIS performance. Specifically, we examine the radar cross-section (RCS) obtained from two RIS configurations: In the first, each atom of the RIS is tuned based on a theoretical analog phase shift to realize idealized one-beam patterns at the desired angles. In the second configuration, each atom of the RIS is tuned based on a low-complexity, one-bit quantized element phase shift, which results in dual symmetric beams. The RIS configurations are then benchmarked with a metal plate of similar dimensions in both simulations and measurements.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11473v1",
        "authors": [
          "Kainat Yasmeen",
          "Shobha Sundar Ram",
          "Debidas Kundu"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Beam Reconfigurable Intelligent Surface",
        "Radar Sensing",
        "Intel",
        "Meta",
        "Act",
        "MIT",
        "RCS",
        "RIS",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.881261"
    },
    {
      "id": "arxiv-2602.11471v1",
      "title": "Around-the-corner Radar Sensing Using Reconfigurable Intelligent Surface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11471v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Around-the-corner radar (ACR) sensing of targets in non-line-of-sight (NLOS) conditions has been explored for security and surveillance applications and look-ahead warning systems in automotive scenarios. Here, the targets are detected around corners without direct line-of-sight (LOS) propagation by exploiting multipath bounces from the walls. However, the overall detection metrics are weak due to the low strength of the multipath signals. Our study presents the application of reconfigurable intelligent surface (RIS) to improve radar sensing in ACR scenarios by directing incident beams on the RIS into NLOS regions. Experimental results at 5.5 GHz demonstrate that micro-Doppler signatures of the walking motion of humans can now be captured in NLOS conditions through the strategic deployment of RIS.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11471v1",
        "authors": [
          "Kainat Yasmeen",
          "Debidas Kundu",
          "Shobha Sundar Ram"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Radar Sensing Using Reconfigurable",
        "Intelligent Surface Around",
        "Intel",
        "NLOS",
        "ACR",
        "LOS",
        "RIS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.881553"
    },
    {
      "id": "arxiv-2602.11463v1",
      "title": "Estimation of Electrical Characteristics of Complex Walls Using Deep Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11463v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Electromagnetic wave propagation through complex inhomogeneous walls introduces significant distortions to through-wall radar signatures. Estimation of wall thickness, dielectric, and conductivity profiles may enable wall effects to be deconvolved from target scattering. We propose to use deep neural networks (DNNs) to estimate wall characteristics from broadband scattered electric fields on the same side of the wall as the transmitter. We demonstrate that both single deep artificial and convolutional neural networks and dual networks involving generative adversarial networks are capable of performing the highly nonlinear regression operation of electromagnetic inverse scattering for wall characterization. These networks are trained with simulation data generated from full wave solvers and validated on both simulated and real wall data with approximately 95% accuracy.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11463v1",
        "authors": [
          "Kainat Yasmeen",
          "Shobha Sundar Ram"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Networks Electromagnetic",
        "Electrical Characteristics",
        "Complex Walls Using Deep",
        "Neural Network",
        "Act",
        "MIT",
        "AI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.881860"
    },
    {
      "id": "arxiv-2602.11461v1",
      "title": "EM-Aware Physical Synthesis: Neural Inductor Modeling and Intelligent Placement & Routing for RF Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11461v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "This paper presents an ML-driven framework for automated RF physical synthesis that transforms circuit netlists into manufacturable GDSII layouts. While recent ML approaches demonstrate success in topology selection and parameter optimization, they fail to produce manufacturable layouts due to oversimplified component models and lack of routing capabilities. Our framework addresses these limitations through three key innovations: (1) a neural network framework trained on 18,210 inductor geometries with frequency sweeps from 1-100 GHz, generating 7.5 million training samples, that predicts inductor Q-factor with less than 2% error and enables fast gradient-based layout optimization with a 93.77% success rate in producing high-Q layouts; (2) an intelligent P-Cell optimizer that reduces layout area while maintaining design-rule-check (DRC) compliance; and (3) a complete placement and routing engine with frequency-dependent EM spacing rules and DRC-aware synthesis. The neural inductor model demonstrates superior accuracy across 1-100 GHz, enabling EM-accurate component synthesis with real-time inference. The framework successfully generates DRC-aware GDSII layouts for RF circuits, representing a significant step toward automated RF physical design.",
        "keywords": [
          "cs.AR",
          "cs.AI",
          "cs.LG",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11461v1",
        "authors": [
          "Yilun Huang",
          "Asal Mehradfar",
          "Salman Avestimehr",
          "Hamidreza Aghasi"
        ],
        "arxiv_categories": [
          "cs.AR",
          "cs.AI",
          "cs.LG",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Inductor Modeling",
        "Aware Physical Synthesis",
        "Intelligent Placement",
        "Neural Network",
        "Framework",
        "GDSII",
        "Intel",
        "DRC",
        "Act",
        "NSF",
        "MIT",
        "AI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:30.882279"
    },
    {
      "id": "arxiv-2602.11823v1",
      "title": "Intrinsic speed characteristics of a self-propelled camphor disk under repulsive perturbations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.11823v1",
        "published_date": "2026-02-12"
      },
      "content": {
        "abstract": "Camphor is a well-studied material capable of generating self-propelled motion at a water surface, and the resulting dynamics can exhibit a wide range of behaviors. Here, we analyze a one-dimensional model describing a mobile camphor disk perturbed by a second localized camphor source. The interaction between the rotor and the perturbing disk is represented by a distance-dependent potential. The study is motivated by experiments in which a camphor rotor interacts with a fixed camphor disk placed on the water surface. Numerical simulations of the model reproduce the essential features of the experimentally observed position-dependent rotor velocity for all considered forms of the potential. For weak perturbations, we derive analytical solutions valid for arbitrary potential profiles. Both the simulations and the analytical results demonstrate a pronounced asymmetry in the rotor velocity depending on whether the rotor approaches or recedes from the perturbation.",
        "keywords": [
          "nlin.AO",
          "nlin.PS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.11823v1",
        "authors": [
          "Yuki Koyano",
          "Jerzy Górecki",
          "Hiroyuki Kitahata"
        ],
        "arxiv_categories": [
          "nlin.AO",
          "nlin.PS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-15T13:54:35.061806"
    }
  ]
}