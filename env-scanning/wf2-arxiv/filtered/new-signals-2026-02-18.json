{
  "metadata": {
    "workflow": "wf2-arxiv",
    "scan_date": "2026-02-18",
    "dedup_summary": {
      "raw_count": 475,
      "stage1_removed": 0,
      "stage2_removed": 0,
      "internal_dedup": 0,
      "final_count": 475
    }
  },
  "items": [
    {
      "id": "arxiv-2602.15830v1",
      "title": "Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15830v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).",
        "keywords": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15830v1",
        "authors": [
          "Christopher David Roberts"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Transformer",
        "Framework",
        "ECMWF",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:57:52.368014"
    },
    {
      "id": "arxiv-2602.15829v1",
      "title": "Operationalising the Superficial Alignment Hypothesis via Task Complexity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15829v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The superficial alignment hypothesis (SAH) posits that large language models learn most of their knowledge during pre-training, and that post-training merely surfaces this knowledge. The SAH, however, lacks a precise definition, which has led to (i) different and seemingly orthogonal arguments supporting it, and (ii) important critiques to it. We propose a new metric called task complexity: the length of the shortest program that achieves a target performance on a task. In this framework, the SAH simply claims that pre-trained models drastically reduce the complexity of achieving high performance on many tasks. Our definition unifies prior arguments supporting the SAH, interpreting them as different strategies to find such short programs. Experimentally, we estimate the task complexity of mathematical reasoning, machine translation, and instruction following; we then show that these complexities can be remarkably low when conditioned on a pre-trained model. Further, we find that pre-training enables access to strong performances on our tasks, but it can require programs of gigabytes of length to access them. Post-training, on the other hand, collapses the complexity of reaching this same performance by several orders of magnitude. Overall, our results highlight that task adaptation often requires surprisingly little information -- often just a few kilobytes.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15829v1",
        "authors": [
          "Tomás Vergara-Browne",
          "Darshan Patil",
          "Ivan Titov",
          "Siva Reddy",
          "Tiago Pimentel"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superficial Alignment Hypothesis",
        "Framework",
        "SAH",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.368454"
    },
    {
      "id": "arxiv-2602.15828v1",
      "title": "Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15828v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.",
        "keywords": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15828v1",
        "authors": [
          "Yuxuan Kuang",
          "Sungjae Park",
          "Katerina Fragkiadaki",
          "Shubham Tulsiani"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Real Dexterous Manipulation Learning",
        "Agnostic Point Track Policy",
        "Framework",
        "Policy",
        "Robot",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.368973"
    },
    {
      "id": "arxiv-2602.15827v1",
      "title": "Perceptive Humanoid Parkour: Chaining Dynamic Human Skills via Motion Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15827v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "While recent advances in humanoid locomotion have achieved stable walking on varied terrains, capturing the agility and adaptivity of highly dynamic human motions remains an open challenge. In particular, agile parkour in complex environments demands not only low-level robustness, but also human-like motion expressiveness, long-horizon skill composition, and perception-driven decision-making. In this paper, we present Perceptive Humanoid Parkour (PHP), a modular framework that enables humanoid robots to autonomously perform long-horizon, vision-based parkour across challenging obstacle courses. Our approach first leverages motion matching, formulated as nearest-neighbor search in a feature space, to compose retargeted atomic human skills into long-horizon kinematic trajectories. This framework enables the flexible composition and smooth transition of complex skill chains while preserving the elegance and fluidity of dynamic human motions. Next, we train motion-tracking reinforcement learning (RL) expert policies for these composed motions, and distill them into a single depth-based, multi-skill student policy, using a combination of DAgger and RL. Crucially, the combination of perception and skill composition enables autonomous, context-aware decision-making: using only onboard depth sensing and a discrete 2D velocity command, the robot selects and executes whether to step over, climb onto, vault or roll off obstacles of varying geometries and heights. We validate our framework with extensive real-world experiments on a Unitree G1 humanoid robot, demonstrating highly dynamic parkour skills such as climbing tall obstacles up to 1.25m (96% robot height), as well as long-horizon multi-obstacle traversal with closed-loop adaptation to real-time obstacle perturbations.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.LG",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15827v1",
        "authors": [
          "Zhen Wu",
          "Xiaoyu Huang",
          "Lujie Yang",
          "Yuanhang Zhang",
          "Koushil Sreenath"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.LG",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chaining Dynamic Human Skills",
        "Perceptive Humanoid Parkour",
        "Motion Matching While",
        "Framework",
        "Policy",
        "Robot",
        "PHP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.369547"
    },
    {
      "id": "arxiv-2602.15823v1",
      "title": "CrispEdit: Low-Curvature Projections for Scalable Non-Destructive LLM Editing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15823v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A central challenge in large language model (LLM) editing is capability preservation: methods that successfully change targeted behavior can quietly game the editing proxy and corrupt general capabilities, producing degenerate behaviors reminiscent of proxy/reward hacking. We present CrispEdit, a scalable and principled second-order editing algorithm that treats capability preservation as an explicit constraint, unifying and generalizing several existing editing approaches. CrispEdit formulates editing as constrained optimization and enforces the constraint by projecting edit updates onto the low-curvature subspace of the capability-loss landscape. At the crux of CrispEdit is expressing capability constraint via Bregman divergence, whose quadratic form yields the Gauss-Newton Hessian exactly and even when the base model is not trained to convergence. We make this second-order procedure efficient at the LLM scale using Kronecker-factored approximate curvature (K-FAC) and a novel matrix-free projector that exploits Kronecker structure to avoid constructing massive projection matrices. Across standard model-editing benchmarks, CrispEdit achieves high edit success while keeping capability degradation below 1% on average across datasets, significantly improving over prior editors.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15823v1",
        "authors": [
          "Zarif Ikram",
          "Arad Firouzkouhi",
          "Stephen Tu",
          "Mahdi Soltanolkotabi",
          "Paria Rashidinejad"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Curvature Projections",
        "Newton Hessian",
        "Scalable Non",
        "Standard",
        "WTO",
        "WHO",
        "LLM",
        "FAC",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.369973"
    },
    {
      "id": "arxiv-2602.15820v1",
      "title": "Stabilizing Test-Time Adaptation of High-Dimensional Simulation Surrogates via D-Optimal Statistics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15820v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Machine learning surrogates are increasingly used in engineering to accelerate costly simulations, yet distribution shifts between training and deployment often cause severe performance degradation (e.g., unseen geometries or configurations). Test-Time Adaptation (TTA) can mitigate such shifts, but existing methods are largely developed for lower-dimensional classification with structured outputs and visually aligned input-output relationships, making them unstable for the high-dimensional, unstructured and regression problems common in simulation. We address this challenge by proposing a TTA framework based on storing maximally informative (D-optimal) statistics, which jointly enables stable adaptation and principled parameter selection at test time. When applied to pretrained simulation surrogates, our method yields up to 7% out-of-distribution improvements at negligible computational cost. To the best of our knowledge, this is the first systematic demonstration of effective TTA for high-dimensional simulation regression and generative design optimization, validated on the SIMSHIFT and EngiBench benchmarks.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15820v1",
        "authors": [
          "Anna Zimmel",
          "Paul Setinek",
          "Gianluca Galletti",
          "Johannes Brandstetter",
          "Werner Zellinger"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Simulation Surrogates",
        "Optimal Statistics Machine",
        "Machine Learning",
        "Stabilizing Test",
        "Time Adaptation",
        "Framework",
        "MIT",
        "TTA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.370289"
    },
    {
      "id": "arxiv-2602.15819v1",
      "title": "VideoSketcher: Video Models Prior Enable Versatile Sequential Sketch Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15819v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Sketching is inherently a sequential process, in which strokes are drawn in a meaningful order to explore and refine ideas. However, most generative models treat sketches as static images, overlooking the temporal structure that underlies creative drawing. We present a data-efficient approach for sequential sketch generation that adapts pretrained text-to-video diffusion models to generate sketching processes. Our key insight is that large language models and video diffusion models offer complementary strengths for this task: LLMs provide semantic planning and stroke ordering, while video diffusion models serve as strong renderers that produce high-quality, temporally coherent visuals. We leverage this by representing sketches as short videos in which strokes are progressively drawn on a blank canvas, guided by text-specified ordering instructions. We introduce a two-stage fine-tuning strategy that decouples the learning of stroke ordering from the learning of sketch appearance. Stroke ordering is learned using synthetic shape compositions with controlled temporal structure, while visual appearance is distilled from as few as seven manually authored sketching processes that capture both global drawing order and the continuous formation of individual strokes. Despite the extremely limited amount of human-drawn sketch data, our method generates high-quality sequential sketches that closely follow text-specified orderings while exhibiting rich visual detail. We further demonstrate the flexibility of our approach through extensions such as brush style conditioning and autoregressive sketch generation, enabling additional controllability and interactive, collaborative drawing.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15819v1",
        "authors": [
          "Hui Ren",
          "Yuval Alaluf",
          "Omer Bar Tal",
          "Alexander Schwing",
          "Antonio Torralba"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Versatile Sequential Sketch Generation",
        "Video Models Prior Enable",
        "Fusion",
        "MIT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.370696"
    },
    {
      "id": "arxiv-2602.15817v1",
      "title": "Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15817v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.",
        "keywords": [
          "cs.LG",
          "cs.RO",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15817v1",
        "authors": [
          "Oswin So",
          "Eric Yang Yu",
          "Songyuan Zhang",
          "Matthew Cleaveland",
          "Mitchell Black"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.RO",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcement Learning Recent",
        "Robust Avoid Problems",
        "Unknown Feasibility",
        "Guided Exploration",
        "Solving Parameter",
        "Policy",
        "FGE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.371017"
    },
    {
      "id": "arxiv-2602.15816v1",
      "title": "Developing AI Agents with Simulated Data: Why, what, and how?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15816v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation solutions.",
        "keywords": [
          "cs.AI",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15816v1",
        "authors": [
          "Xiaoran Liu",
          "Istvan David"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Simulated Data",
        "Framework",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.371181"
    },
    {
      "id": "arxiv-2602.15814v1",
      "title": "Avey-B",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15814v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15814v1",
        "authors": [
          "Devang Acharya",
          "Mohammad Hammoud"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Transformer",
        "Standard",
        "BERT",
        "NLP",
        "NSF",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.371408"
    },
    {
      "id": "arxiv-2602.15811v1",
      "title": "Task-Agnostic Continual Learning for Chest Radiograph Classification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15811v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Clinical deployment of chest radiograph classifiers requires models that can be updated as new datasets become available without retraining on previously ob- served data or degrading validated performance. We study, for the first time, a task-incremental continual learning setting for chest radiograph classification, in which heterogeneous chest X-ray datasets arrive sequentially and task identifiers are unavailable at inference. We propose a continual adapter-based routing learning strategy for Chest X-rays (CARL-XRay) that maintains a fixed high-capacity backbone and incrementally allocates lightweight task-specific adapters and classifier heads. A latent task selector operates on task-adapted features and leverages both current and historical context preserved through compact prototypes and feature-level experience replay. This design supports stable task identification and adaptation across sequential updates while avoiding raw-image storage. Experiments on large-scale public chest radiograph datasets demonstrate robust performance retention and reliable task-aware inference under continual dataset ingestion. CARL-XRay outperforms joint training under task-unknown deployment, achieving higher routing accuracy (75.0\\% vs.\\ 62.5\\%), while maintaining competitive diagnostic performance with AUROC of 0.74 in the oracle setting with ground-truth task identity and 0.75 under task-unknown inference, using significantly fewer trainable parameters. Finally, the proposed framework provides a practical alternative to joint training and repeated full retraining in continual clinical deployment.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15811v1",
        "authors": [
          "Muthu Subash Kavitha",
          "Anas Zafar",
          "Amgad Muneer",
          "Jia Wu"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Chest Radiograph Classification Clinical",
        "Agnostic Continual Learning",
        "Framework",
        "Oracle",
        "AUROC",
        "CARL",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.371788"
    },
    {
      "id": "arxiv-2602.15809v1",
      "title": "Decision Quality Evaluation Framework at Pinterest",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15809v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework's practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.",
        "keywords": [
          "stat.AP",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15809v1",
        "authors": [
          "Yuqi Tian",
          "Robert Paine",
          "Attila Dobi",
          "Kevin O'Sullivan",
          "Aravindh Manickavasagam"
        ],
        "arxiv_categories": [
          "stat.AP",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Decision Quality Evaluation Framework",
        "Large Language Models",
        "Pinterest Online",
        "Golden Set",
        "Framework",
        "Policy",
        "Intel",
        "LLM",
        "GDS",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.372103"
    },
    {
      "id": "arxiv-2602.15799v1",
      "title": "The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15799v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Fine-tuning aligned language models on benign tasks unpredictably degrades safety guardrails, even when training data contains no harmful content and developers have no adversarial intent. We show that the prevailing explanation, that fine-tuning updates should be orthogonal to safety-critical directions in high-dimensional parameter space, offers false reassurance: we show this orthogonality is structurally unstable and collapses under the dynamics of gradient descent. We then resolve this through a novel geometric analysis, proving that alignment concentrates in low-dimensional subspaces with sharp curvature, creating a brittle structure that first-order methods cannot detect or defend. While initial fine-tuning updates may indeed avoid these subspaces, the curvature of the fine-tuning loss generates second-order acceleration that systematically steers trajectories into alignment-sensitive regions. We formalize this mechanism through the Alignment Instability Condition, three geometric properties that, when jointly satisfied, lead to safety degradation. Our main result establishes a quartic scaling law: alignment loss grows with the fourth power of training time, governed by the sharpness of alignment geometry and the strength of curvature coupling between the fine-tuning task and safety-critical parameters. These results expose a structural blind spot in the current safety paradigm. The dominant approaches to safe fine-tuning address only the initial snapshot of a fundamentally dynamic problem. Alignment fragility is not a bug to be patched; it is an intrinsic geometric property of gradient descent on curved manifolds. Our results motivate the development of curvature-aware methods, and we hope will further enable a shift in alignment safety analysis from reactive red-teaming to predictive diagnostics for open-weight model deployment.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15799v1",
        "authors": [
          "Max Springer",
          "Chung Peng Lee",
          "Blossom Metevier",
          "Jane Castleman",
          "Bohdan Turbal"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Alignment Instability Condition",
        "Tuning Breaks Safety Fine",
        "Alignment Collapse",
        "When Fine",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.372542"
    },
    {
      "id": "arxiv-2602.15791v1",
      "title": "Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15791v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional encoding methods (e.g., one-hot) often fail to convey the nuanced relationships among closely related subtypes, limiting AI's semantic comprehension. To address this limitation, this study proposes a novel training approach that employs large language model (LLM) embeddings (e.g., OpenAI GPT and Meta LLaMA) as encodings to preserve finer distinctions in building semantics. We evaluated the proposed method by training GraphSAGE models to classify 42 building object subtypes across five high-rise residential building information models (BIMs). Various embedding dimensions were tested, including original high-dimensional LLM embeddings (1,536, 3,072, or 4,096) and 1,024-dimensional compacted embeddings generated via the Matryoshka representation model. Experimental results demonstrated that LLM encodings outperformed the conventional one-hot baseline, with the llama-3 (compacted) embedding achieving a weighted average F1-score of 0.8766, compared to 0.8475 for one-hot encoding. The results underscore the promise of leveraging LLM-based encodings to enhance AI's ability to interpret complex, domain-specific building semantics. As the capabilities of LLMs and dimensionality reduction techniques continue to evolve, this approach holds considerable potential for broad application in semantic elaboration tasks throughout the AECO industry.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15791v1",
        "authors": [
          "Suhyung Jang",
          "Ghang Lee",
          "Jaekun Lee",
          "Hyunjun Lee"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enhancing Building Semantics Preservation",
        "Large Language Model Encodings",
        "Model Training",
        "OpenAI",
        "Meta",
        "AECO",
        "MIT",
        "GPT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.372933"
    },
    {
      "id": "arxiv-2602.15785v1",
      "title": "This human study did not involve human subjects: Validating LLM simulations as behavioral evidence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15785v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A growing literature uses large language models (LLMs) as synthetic participants to generate cost-effective and nearly instantaneous responses in social science experiments. However, there is limited guidance on when such simulations support valid inference about human behavior. We contrast two strategies for obtaining valid estimates of causal effects and clarify the assumptions under which each is suitable for exploratory versus confirmatory research. Heuristic approaches seek to establish that simulated and observed human behavior are interchangeable through prompt engineering, model fine-tuning, and other repair strategies designed to reduce LLM-induced inaccuracies. While useful for many exploratory tasks, heuristic approaches lack the formal statistical guarantees typically required for confirmatory research. In contrast, statistical calibration combines auxiliary human data with statistical adjustments to account for discrepancies between observed and simulated responses. Under explicit assumptions, statistical calibration preserves validity and provides more precise estimates of causal effects at lower cost than experiments that rely solely on human participants. Yet the potential of both approaches depends on how well LLMs approximate the relevant populations. We consider what opportunities are overlooked when researchers focus myopically on substituting LLMs for human participants in a study.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15785v1",
        "authors": [
          "Jessica Hullman",
          "David Broska",
          "Huaman Sun",
          "Aaron Shaw"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "MIT",
        "LLM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.373279"
    },
    {
      "id": "arxiv-2602.15783v1",
      "title": "Context-aware Skin Cancer Epithelial Cell Classification with Scalable Graph Transformers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15783v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Whole-slide images (WSIs) from cancer patients contain rich information that can be used for medical diagnosis or to follow treatment progress. To automate their analysis, numerous deep learning methods based on convolutional neural networks and Vision Transformers have been developed and have achieved strong performance in segmentation and classification tasks. However, due to the large size and complex cellular organization of WSIs, these models rely on patch-based representations, losing vital tissue-level context. We propose using scalable Graph Transformers on a full-WSI cell graph for classification. We evaluate this methodology on a challenging task: the classification of healthy versus tumor epithelial cells in cutaneous squamous cell carcinoma (cSCC), where both cell types exhibit very similar morphologies and are therefore difficult to differentiate for image-based approaches. We first compared image-based and graph-based methods on a single WSI. Graph Transformer models SGFormer and DIFFormer achieved balanced accuracies of $85.2 \\pm 1.5$ ($\\pm$ standard error) and $85.1 \\pm 2.5$ in 3-fold cross-validation, respectively, whereas the best image-based method reached $81.2 \\pm 3.0$. By evaluating several node feature configurations, we found that the most informative representation combined morphological and texture features as well as the cell classes of non-epithelial cells, highlighting the importance of the surrounding cellular context. We then extended our work to train on several WSIs from several patients. To address the computational constraints of image-based models, we extracted four $2560 \\times 2560$ pixel patches from each image and converted them into graphs. In this setting, DIFFormer achieved a balanced accuracy of $83.6 \\pm 1.9$ (3-fold cross-validation), while the state-of-the-art image-based model CellViT256 reached $78.1 \\pm 0.5$.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15783v1",
        "authors": [
          "Lucas Sancéré",
          "Noémie Moreau",
          "Katarzyna Bozek"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Graph Transformers Whole",
        "Skin Cancer Epithelial Cell",
        "Vision Transformers",
        "Graph Transformers",
        "Graph Transformer",
        "Neural Network",
        "Deep Learning",
        "Transformer",
        "Standard",
        "NSF",
        "WHO",
        "WSI",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.373718"
    },
    {
      "id": "arxiv-2602.15782v1",
      "title": "Meteorological data and Sky Images meets Neural Models for Photovoltaic Power Forecasting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15782v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Due to the rise in the use of renewable energies as an alternative to traditional ones, and especially solar energy, there is increasing interest in studying how to address photovoltaic forecasting in the face of the challenge of variability in photovoltaic energy production, using different methodologies. This work develops a hybrid approach for short and long-term forecasting based on two studies with the same purpose. A multimodal approach that combines images of the sky and photovoltaic energy history with meteorological data is proposed. The main goal is to improve the accuracy of ramp event prediction, increase the robustness of forecasts in cloudy conditions, and extend capabilities beyond nowcasting, to support more efficient operation of the power grid and better management of solar variability. Deep neural models are used for both nowcasting and forecasting solutions, incorporating individual and multiple meteorological variables, as well as an analytical solar position. The results demonstrate that the inclusion of meteorological data, particularly the surface long-wave, radiation downwards, and the combination of wind and solar position, significantly improves current predictions in both nowcasting and forecasting tasks, especially on cloudy days. This study highlights the importance of integrating diverse data sources to improve the reliability and interpretability of solar energy prediction models.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15782v1",
        "authors": [
          "Ines Montoya-Espinagosa",
          "Antonio Agudo"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Photovoltaic Power Forecasting Due",
        "Neural Models",
        "Sky Images",
        "Solar",
        "Wind",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.374064"
    },
    {
      "id": "arxiv-2602.15781v1",
      "title": "Neural Scaling Laws for Boosted Jet Tagging",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15781v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The success of Large Language Models (LLMs) has established that scaling compute, through joint increases in model capacity and dataset size, is the primary driver of performance in modern machine learning. While machine learning has long been an integral component of High Energy Physics (HEP) data analysis workflows, the compute used to train state-of-the-art HEP models remains orders of magnitude below that of industry foundation models. With scaling laws only beginning to be studied in the field, we investigate neural scaling laws for boosted jet classification using the public JetClass dataset. We derive compute optimal scaling laws and identify an effective performance limit that can be consistently approached through increased compute. We study how data repetition, common in HEP where simulation is expensive, modifies the scaling yielding a quantifiable effective dataset size gain. We then study how the scaling coefficients and asymptotic performance limits vary with the choice of input features and particle multiplicity, demonstrating that increased compute reliably drives performance toward an asymptotic limit, and that more expressive, lower-level features can raise the performance limit and improve results at fixed dataset size.",
        "keywords": [
          "hep-ex",
          "cs.LG",
          "hep-ph",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15781v1",
        "authors": [
          "Matthias Vigl",
          "Nicole Hartman",
          "Michael Kagan",
          "Lukas Heinrich"
        ],
        "arxiv_categories": [
          "hep-ex",
          "cs.LG",
          "hep-ph",
          "physics.data-an"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models",
        "High Energy Physics",
        "Neural Scaling Laws",
        "Machine Learning",
        "MIT",
        "LLM",
        "HEP",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.374376"
    },
    {
      "id": "arxiv-2602.15778v1",
      "title": "*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15778v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15778v1",
        "authors": [
          "Quentin Lemesle",
          "Léane Jourdan",
          "Daisy Munson",
          "Pierre Alain",
          "Jonathan Chevelu"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Improved Evaluation Evaluating",
        "Llm Used",
        "PLUIE",
        "MIT",
        "LLM",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.374568"
    },
    {
      "id": "arxiv-2602.15776v1",
      "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15776v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15776v1",
        "authors": [
          "Yiqin Yang",
          "Xu Yang",
          "Yuhua Jiang",
          "Ni Mu",
          "Hao Hu"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Global State Diffusion Algorithm",
        "State Diffusion Process",
        "Partial Observability",
        "Agent Systems In",
        "Fusion",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.374886"
    },
    {
      "id": "arxiv-2602.15775v1",
      "title": "NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15775v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15775v1",
        "authors": [
          "Laura Salort-Benejam",
          "Antonio Agudo"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Radiance Fields",
        "Endoscopy Endoscopy",
        "Varying Tissues",
        "NSF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.375173"
    },
    {
      "id": "arxiv-2602.15772v1",
      "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15772v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of \"generate-understand-regenerate\". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15772v1",
        "authors": [
          "Sen Ye",
          "Mengde Xu",
          "Shuyang Gu",
          "Di He",
          "Liwei Wang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Navigating Optimization Dilemma",
        "Multimodal Models Current",
        "Framework",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.375423"
    },
    {
      "id": "arxiv-2602.15769v1",
      "title": "ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15769v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15769v1",
        "authors": [
          "Yahia Alqurnawi",
          "Preetom Biswas",
          "Anmol Rao",
          "Tejas Anvekar",
          "Chitta Baral"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Evaluating Multimodal Large Language",
        "Visual Table Attribution Multimodal",
        "Large Language Models",
        "JSON",
        "MIT",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.375711"
    },
    {
      "id": "arxiv-2602.15767v1",
      "title": "Robot-Assisted Social Dining as a White Glove Service",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15767v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15767v1",
        "authors": [
          "Atharva S Kashyap",
          "Ugne Aleksandra Morkute",
          "Patricia Alves-Oliveira"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "White Glove Service Robot",
        "Assisted Social Dining",
        "Robot",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.375979"
    },
    {
      "id": "arxiv-2602.15763v1",
      "title": "GLM-5: from Vibe Coding to Agentic Engineering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15763v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly reduce training and inference costs while maintaining long-context fidelity. To advance model alignment and autonomy, we implement a new asynchronous reinforcement learning infrastructure that drastically improves post-training efficiency by decoupling generation from training. Furthermore, we propose novel asynchronous agent RL algorithms that further improve RL quality, enabling the model to learn from complex, long-horizon interactions more effectively. Through these innovations, GLM-5 achieves state-of-the-art performance on major open benchmarks. Most critically, GLM-5 demonstrates unprecedented capability in real-world coding tasks, surpassing previous baselines in handling end-to-end software engineering challenges. Code, models, and more information are available at https://github.com/zai-org/GLM-5.",
        "keywords": [
          "cs.LG",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15763v1",
        "authors": [
          "GLM-5 Team",
          " :",
          "Aohan Zeng",
          "Xin Lv",
          "Zhenyu Hou"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agentic Engineering We",
        "Vibe Coding",
        "GLM-5",
        "GLM",
        "DSA",
        "ARC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.376617"
    },
    {
      "id": "arxiv-2602.15758v1",
      "title": "ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15758v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15758v1",
        "authors": [
          "Manav Nitin Kapadnis",
          "Lawanya Baghel",
          "Atharva Naik",
          "Carolyn Rosé"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Large Language Models",
        "Multimodal Language Models While",
        "Evaluating Grounded Multi",
        "Turn Chart Editing",
        "Framework",
        "NSF",
        "MIT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.376956"
    },
    {
      "id": "arxiv-2602.15757v1",
      "title": "Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15757v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15757v1",
        "authors": [
          "Laura De Grazia",
          "Danae Sánchez Villegas",
          "Desmond Elliott",
          "Mireia Farrús",
          "Mariona Taulé"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Beyond Binary Classification",
        "Social Media Videos Online",
        "Grained Sexism",
        "Detecting Fine",
        "LLM",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.377243"
    },
    {
      "id": "arxiv-2602.15756v1",
      "title": "A Note on Non-Composability of Layerwise Approximate Verification for Neural Inference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15756v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $δ$; therefore the final output is a reasonable inference result''. This short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).",
        "keywords": [
          "cs.CR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15756v1",
        "authors": [
          "Or Zamir"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Layerwise Approximate Verification",
        "Neural Inference",
        "Neural Network",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.377635"
    },
    {
      "id": "arxiv-2602.15755v1",
      "title": "RaCo: Ranking and Covariance for Practical Learned Keypoints",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15755v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces RaCo, a lightweight neural network designed to learn robust and versatile keypoints suitable for a variety of 3D computer vision tasks. The model integrates three key components: the repeatable keypoint detector, a differentiable ranker to maximize matches with a limited number of keypoints, and a covariance estimator to quantify spatial uncertainty in metric scale. Trained on perspective image crops only, RaCo operates without the need for covisible image pairs. It achieves strong rotational robustness through extensive data augmentation, even without the use of computationally expensive equivariant network architectures. The method is evaluated on several challenging datasets, where it demonstrates state-of-the-art performance in keypoint repeatability and two-view matching, particularly under large in-plane rotations. Ultimately, RaCo provides an effective and simple strategy to independently estimate keypoint ranking and metric covariance without additional labels, detecting interpretable and repeatable interest points. The code is available at https://github.com/cvg/RaCo.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15755v1",
        "authors": [
          "Abhiram Shenoi",
          "Philipp Lindenberger",
          "Paul-Edouard Sarlin",
          "Marc Pollefeys"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.377910"
    },
    {
      "id": "arxiv-2602.15753v1",
      "title": "Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15753v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15753v1",
        "authors": [
          "Chahan Vidal-Gorène",
          "Bastien Kindt",
          "Florian Cafiero"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Natural Language Processing",
        "Classical Armenian",
        "Ancient Greek",
        "Old Georgian",
        "Syriac Low",
        "GPT-4",
        "POS",
        "GPT",
        "LLM",
        "PIE",
        "RNN",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.378220"
    },
    {
      "id": "arxiv-2602.15752v1",
      "title": "Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15752v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck. In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15752v1",
        "authors": [
          "Ren Kishimoto",
          "Rikiya Takehi",
          "Koichi Tanaka",
          "Masahiro Nomura",
          "Riku Togashi"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Beyond Match Maximization",
        "Sided Matching On",
        "Optimized Two",
        "MIT",
        "WHO",
        "LTR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.378652"
    },
    {
      "id": "arxiv-2602.15751v1",
      "title": "Enabling Low-Latency Machine learning on Radiation-Hard FPGAs with hls4ml",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15751v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper presents the first demonstration of a viable, ultra-fast, radiation-hard machine learning (ML) application on FPGAs, which could be used in future high-energy physics experiments. We present a three-fold contribution, with the PicoCal calorimeter, planned for the LHCb Upgrade II experiment, used as a test case. First, we develop a lightweight autoencoder to compress a 32-sample timing readout, representative of that of the PicoCal, into a two-dimensional latent space. Second, we introduce a systematic, hardware-aware quantization strategy and show that the model can be reduced to 10-bit weights with minimal performance loss. Third, as a barrier to the adoption of on-detector ML is the lack of support for radiation-hard FPGAs in the High-Energy Physics community's standard ML synthesis tool, hls4ml, we develop a new backend for this library. This new back-end enables the automatic translation of ML models into High-Level Synthesis (HLS) projects for the Microchip PolarFire family of FPGAs, one of the few commercially available and radiation hard FPGAs. We present the synthesis of the autoencoder on a target PolarFire FPGA, which indicates that a latency of 25 ns can be achieved. We show that the resources utilized are low enough that the model can be placed within the inherently protected logic of the FPGA. Our extension to hls4ml is a significant contribution, paving the way for broader adoption of ML on FPGAs in high-radiation environments.",
        "keywords": [
          "hep-ex",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15751v1",
        "authors": [
          "Katya Govorkova",
          "Julian Garcia Pardinas",
          "Vladimir Loncar",
          "Victoria Nguyen",
          "Sebastian Schmitt"
        ],
        "arxiv_categories": [
          "hep-ex",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Level Synthesis",
        "Latency Machine",
        "Energy Physics",
        "Enabling Low",
        "Standard",
        "FPGA",
        "HLS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.379032"
    },
    {
      "id": "arxiv-2602.15750v1",
      "title": "UrbanVerse: Learning Urban Region Representation Across Cities and Tasks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15750v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent advances in urban region representation learning have enabled a wide range of applications in urban analytics, yet existing methods remain limited in their capabilities to generalize across cities and analytic tasks. We aim to generalize urban representation learning beyond city- and task-specific settings, towards a foundation-style model for urban analytics. To this end, we propose UrbanVerse, a model for cross-city urban representation learning and cross-task urban analytics. For cross-city generalization, UrbanVerse focuses on features local to the target regions and structural features of the nearby regions rather than the entire city. We model regions as nodes on a graph, which enables a random walk-based procedure to form \"sequences of regions\" that reflect both local and neighborhood structural features for urban region representation learning. For cross-task generalization, we propose a cross-task learning module named HCondDiffCT. This module integrates region-conditioned prior knowledge and task-conditioned semantics into the diffusion process to jointly model multiple downstream urban prediction tasks. HCondDiffCT is generic. It can also be integrated with existing urban representation learning models to enhance their downstream task effectiveness. Experiments on real-world datasets show that UrbanVerse consistently outperforms state-of-the-art methods across six tasks under cross-city settings, achieving up to 35.89% improvements in prediction accuracy.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15750v1",
        "authors": [
          "Fengze Sun",
          "Egemen Tanin",
          "Shanika Karunasekera",
          "Zuqing Li",
          "Flora D. Salim"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Urban Region Representation",
        "Across Cities",
        "Tasks Recent",
        "Fusion",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.379393"
    },
    {
      "id": "arxiv-2602.15740v1",
      "title": "MRC-GAT: A Meta-Relational Copula-Based Graph Attention Network for Interpretable Multimodal Alzheimer's Disease Diagnosis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15740v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative condition necessitating early and precise diagnosis to provide prompt clinical management. Given the paramount importance of early diagnosis, recent studies have increasingly focused on computer-aided diagnostic models to enhance precision and reliability. However, most graph-based approaches still rely on fixed structural designs, which restrict their flexibility and limit generalization across heterogeneous patient data. To overcome these limitations, the Meta-Relational Copula-Based Graph Attention Network (MRC-GAT) is proposed as an efficient multimodal model for AD classification tasks. The proposed architecture, copula-based similarity alignment, relational attention, and node fusion are integrated as the core components of episodic meta-learning, such that the multimodal features, including risk factors (RF), Cognitive test scores, and MRI attributes, are first aligned via a copula-based transformation in a common statistical space and then combined by a multi-relational attention mechanism. According to evaluations performed on the TADPOLE and NACC datasets, the MRC-GAT model achieved accuracies of 96.87% and 92.31%, respectively, demonstrating state-of-the-art performance compared to existing diagnostic models. Finally, the proposed model confirms the robustness and applicability of the proposed method by providing interpretability at various stages of disease diagnosis.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15740v1",
        "authors": [
          "Fatemeh Khalvandi",
          "Saadat Izadi",
          "Abdolah Chalechale"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interpretable Multimodal Alzheimer",
        "Based Graph Attention Network",
        "Disease Diagnosis Alzheimer",
        "Relational Copula",
        "Fusion",
        "Meta",
        "NACC",
        "MRC",
        "NSF",
        "MIT",
        "GAT",
        "MRI",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.379760"
    },
    {
      "id": "arxiv-2602.15738v1",
      "title": "Beyond Labels: Information-Efficient Human-in-the-Loop Learning using Ranking and Selection Queries",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15738v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Integrating human expertise into machine learning systems often reduces the role of experts to labeling oracles, a paradigm that limits the amount of information exchanged and fails to capture the nuances of human judgment. We address this challenge by developing a human-in-the-loop framework to learn binary classifiers with rich query types, consisting of item ranking and exemplar selection. We first introduce probabilistic human response models for these rich queries motivated by the relationship experimentally observed between the perceived implicit score of an item and its distance to the unknown classifier. Using these models, we then design active learning algorithms that leverage the rich queries to increase the information gained per interaction. We provide theoretical bounds on sample complexity and develop a tractable and computationally efficient variational approximation. Through experiments with simulated annotators derived from crowdsourced word-sentiment and image-aesthetic datasets, we demonstrate significant reductions on sample complexity. We further extend active learning strategies to select queries that maximize information rate, explicitly balancing informational value against annotation cost. This algorithm in the word sentiment classification task reduces learning time by more than 57\\% compared to traditional label-only active learning.",
        "keywords": [
          "cs.HC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15738v1",
        "authors": [
          "Belén Martín-Urcelay",
          "Yoonsang Lee",
          "Matthieu R. Bloch",
          "Christopher J. Rozell"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.LG"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Selection Queries Integrating",
        "Machine Learning",
        "Efficient Human",
        "Beyond Labels",
        "Loop Learning",
        "Framework",
        "Oracle",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:57:52.380092"
    },
    {
      "id": "arxiv-2602.15734v1",
      "title": "Language and Geometry Grounded Sparse Voxel Representations for Holistic Scene Understanding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15734v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Existing 3D open-vocabulary scene understanding methods mostly emphasize distilling language features from 2D foundation models into 3D feature fields, but largely overlook the synergy among scene appearance, semantics, and geometry. As a result, scene understanding often deviates from the underlying geometric structure of scenes and becomes decoupled from the reconstruction process. In this work, we propose a novel approach that leverages language and geometry grounded sparse voxel representations to comprehensively model appearance, semantics, and geometry within a unified framework. Specifically, we use 3D sparse voxels as primitives and employ an appearance field, a density field, a feature field, and a confidence field to holistically represent a 3D scene. To promote synergy among the appearance, density, and feature fields, we construct a feature modulation module and distill language features from a 2D foundation model into our 3D scene model. In addition, we integrate geometric distillation into feature field distillation to transfer geometric knowledge from a geometry foundation model to our 3D scene representations via depth correlation regularization and pattern consistency regularization. These components work together to synergistically model the appearance, semantics, and geometry of the 3D scene within a unified framework. Extensive experiments demonstrate that our approach achieves superior overall performance compared with state-of-the-art methods in holistic scene understanding and reconstruction.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15734v1",
        "authors": [
          "Guile Wu",
          "David Huang",
          "Bingbing Liu",
          "Dongfeng Bai"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Holistic Scene Understanding Existing",
        "Geometry Grounded Sparse Voxel",
        "Framework",
        "NSF",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.380460"
    },
    {
      "id": "arxiv-2602.15733v1",
      "title": "MeshMimic: Geometry-Aware Humanoid Motion Learning through 3D Scene Reconstruction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15733v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Humanoid motion control has witnessed significant breakthroughs in recent years, with deep reinforcement learning (RL) emerging as a primary catalyst for achieving complex, human-like behaviors. However, the high dimensionality and intricate dynamics of humanoid robots make manual motion design impractical, leading to a heavy reliance on expensive motion capture (MoCap) data. These datasets are not only costly to acquire but also frequently lack the necessary geometric context of the surrounding physical environment. Consequently, existing motion synthesis frameworks often suffer from a decoupling of motion and scene, resulting in physical inconsistencies such as contact slippage or mesh penetration during terrain-aware tasks. In this work, we present MeshMimic, an innovative framework that bridges 3D scene reconstruction and embodied intelligence to enable humanoid robots to learn coupled \"motion-terrain\" interactions directly from video. By leveraging state-of-the-art 3D vision models, our framework precisely segments and reconstructs both human trajectories and the underlying 3D geometry of terrains and objects. We introduce an optimization algorithm based on kinematic consistency to extract high-quality motion data from noisy visual reconstructions, alongside a contact-invariant retargeting method that transfers human-environment interaction features to the humanoid agent. Experimental results demonstrate that MeshMimic achieves robust, highly dynamic performance across diverse and challenging terrains. Our approach proves that a low-cost pipeline utilizing only consumer-grade monocular sensors can facilitate the training of complex physical interactions, offering a scalable path toward the autonomous evolution of humanoid robots in unstructured environments.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15733v1",
        "authors": [
          "Qiang Zhang",
          "Jiahao Ma",
          "Peiran Liu",
          "Shuai Shi",
          "Zeran Su"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Humanoid Motion Learning",
        "Scene Reconstruction Humanoid",
        "Framework",
        "Robot",
        "Intel",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.380907"
    },
    {
      "id": "arxiv-2602.15730v1",
      "title": "Causal Effect Estimation with Latent Textual Treatments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15730v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.",
        "keywords": [
          "cs.CL",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15730v1",
        "authors": [
          "Omri Feldman",
          "Amar Venugopal",
          "Jann Spiess",
          "Amir Feder"
        ],
        "arxiv_categories": [
          "cs.CL",
          "econ.EM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Latent Textual Treatments Understanding",
        "Causal Effect Estimation",
        "MIT",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.381203"
    },
    {
      "id": "arxiv-2602.15727v1",
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15727v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a \"space of LoRAs\". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.GR",
          "cs.LG",
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15727v1",
        "authors": [
          "Hila Manor",
          "Rinon Gal",
          "Haggai Maron",
          "Tomer Michaeli",
          "Gal Chechik"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.GR",
          "cs.LG",
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Visual Analogy Space",
        "Rank Adaptation",
        "Weight Basis",
        "NVIDIA",
        "Labs",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.381569"
    },
    {
      "id": "arxiv-2602.15725v1",
      "title": "Recursive Concept Evolution for Compositional Reasoning in Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15725v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve reasoning by expanding token-level search through chain-of-thought prompting, self-consistency, or reinforcement learning, but they leave the model's latent representation space fixed. When the required abstraction is not already encoded in this space, performance collapses. We propose Recursive Concept Evolution (RCE), a framework that enables pretrained language models to modify their internal representation geometry during inference. RCE introduces dynamically generated low-rank concept subspaces that are spawned when representational inadequacy is detected, selected through a minimum description length criterion, merged when synergistic, and consolidated via constrained optimization to preserve stability. This process allows the model to construct new abstractions rather than recombining existing ones. We integrate RCE with Mistral-7B and evaluate it across compositional reasoning benchmarks. RCE yields 12-18 point gains on ARC-AGI-2, 8-14 point improvements on GPQA and BBH, and consistent reductions in depth-induced error on MATH and HLE.",
        "keywords": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15725v1",
        "authors": [
          "Sarim Chaudhry"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recursive Concept Evolution",
        "Large Language Models Large",
        "Compositional Reasoning",
        "Framework",
        "AGI-2",
        "GPQA",
        "MATH",
        "BBH",
        "RCE",
        "AGI",
        "ARC",
        "HLE",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.381892"
    },
    {
      "id": "arxiv-2602.15724v1",
      "title": "Learning to Retrieve Navigable Candidates for Efficient Vision-and-Language Navigation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15724v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Vision-and-Language Navigation (VLN) requires an agent to follow natural-language instructions and navigate through previously unseen environments. Recent approaches increasingly employ large language models (LLMs) as high-level navigators due to their flexibility and reasoning capability. However, prompt-based LLM navigation often suffers from inefficient decision-making, as the model must repeatedly interpret instructions from scratch and reason over noisy and verbose navigable candidates at each step. In this paper, we propose a retrieval-augmented framework to improve the efficiency and stability of LLM-based VLN without modifying or fine-tuning the underlying language model. Our approach introduces retrieval at two complementary levels. At the episode level, an instruction-level embedding retriever selects semantically similar successful navigation trajectories as in-context exemplars, providing task-specific priors for instruction grounding. At the step level, an imitation-learned candidate retriever prunes irrelevant navigable directions before LLM inference, reducing action ambiguity and prompt complexity. Both retrieval modules are lightweight, modular, and trained independently of the LLM. We evaluate our method on the Room-to-Room (R2R) benchmark. Experimental results demonstrate consistent improvements in Success Rate, Oracle Success Rate, and SPL on both seen and unseen environments. Ablation studies further show that instruction-level exemplar retrieval and candidate pruning contribute complementary benefits to global guidance and step-wise decision efficiency. These results indicate that retrieval-augmented decision support is an effective and scalable strategy for enhancing LLM-based vision-and-language navigation.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15724v1",
        "authors": [
          "Shutian Gu",
          "Chengkai Huang",
          "Ruoyu Wang",
          "Lina Yao"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Retrieve Navigable Candidates",
        "Language Navigation Vision",
        "Language Navigation",
        "Oracle Success Rate",
        "Efficient Vision",
        "Success Rate",
        "Framework",
        "Oracle",
        "VLN",
        "MIT",
        "SPL",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.382302"
    },
    {
      "id": "arxiv-2602.15721v1",
      "title": "Lifelong Scalable Multi-Agent Realistic Testbed and A Comprehensive Study on Design Choices in Lifelong AGV Fleet Management Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15721v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present Lifelong Scalable Multi-Agent Realistic Testbed (LSMART), an open-source simulator to evaluate any Multi-Agent Path Finding (MAPF) algorithm in a Fleet Management System (FMS) with Automated Guided Vehicles (AGVs). MAPF aims to move a group of agents from their corresponding starting locations to their goals. Lifelong MAPF (LMAPF) is a variant of MAPF that continuously assigns new goals for agents to reach. LMAPF applications, such as autonomous warehouses, often require a centralized, lifelong system to coordinate the movement of a fleet of robots, typically AGVs. However, existing works on MAPF and LMAPF often assume simplified kinodynamic models, such as pebble motion, as well as perfect execution and communication for AGVs. Prior work has presented SMART, a software capable of evaluating any MAPF algorithms while considering agent kinodynamics, communication delays, and execution uncertainties. However, SMART is designed for MAPF, not LMAPF. Generalizing SMART to an FMS requires many more design choices. First, an FMS parallelizes planning and execution, raising the question of when to plan. Second, given planners with varying optimality and differing agent-model assumptions, one must decide how to plan. Third, when the planner fails to return valid solutions, the system must determine how to recover. In this paper, we first present LSMART, an open-source simulator that incorporates all these considerations to evaluate any MAPF algorithms in an FMS. We then provide experiment results based on state-of-the-art methods for each design choice, offering guidance on how to effectively design centralized lifelong AGV Fleet Management Systems. LSMART is available at https://smart-mapf.github.io/lifelong-smart.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15721v1",
        "authors": [
          "Jingtian Yan",
          "Yulun Zhang",
          "Zhenting Liu",
          "Han Zhang",
          "He Jiang"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fleet Management Systems We",
        "Automated Guided Vehicles",
        "Fleet Management Systems",
        "Fleet Management System",
        "Agent Realistic Testbed",
        "Lifelong Scalable Multi",
        "Comprehensive Study",
        "Agent Path Finding",
        "Design Choices",
        "LSMART",
        "Robot",
        "LMAPF",
        "SMART",
        "MAPF",
        "FMS"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.382748"
    },
    {
      "id": "arxiv-2602.15720v1",
      "title": "ToaSt: Token Channel Selection and Structured Pruning for Efficient ViT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15720v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Vision Transformers (ViTs) have achieved remarkable success across various vision tasks, yet their deployment is often hindered by prohibitive computational costs. While structured weight pruning and token compression have emerged as promising solutions, they suffer from prolonged retraining times and global propagation that creates optimization challenges, respectively. We propose ToaSt, a decoupled framework applying specialized strategies to distinct ViT components. We apply coupled head-wise structured pruning to Multi-Head Self-Attention modules, leveraging attention operation characteristics to enhance robustness. For Feed-Forward Networks (over 60\\% of FLOPs), we introduce Token Channel Selection (TCS) that enhances compression ratios while avoiding global propagation issues. Our analysis reveals TCS effectively filters redundant noise during selection. Extensive evaluations across nine diverse models, including DeiT, ViT-MAE, and Swin Transformer, demonstrate that ToaSt achieves superior trade-offs between accuracy and efficiency, consistently outperforming existing baselines. On ViT-MAE-Huge, ToaSt achieves 88.52\\% accuracy (+1.64 \\%) with 39.4\\% FLOPs reduction. ToaSt transfers effectively to downstream tasks, cccccachieving 52.2 versus 51.9 mAP on COCO object detection. Code and models will be released upon acceptance.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15720v1",
        "authors": [
          "Hyunchan Moon",
          "Cheonjun Park",
          "Steven L. Waslander"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Token Channel Selection",
        "Vision Transformers",
        "Structured Pruning",
        "Forward Networks",
        "Swin Transformer",
        "Transformer",
        "Head Self",
        "Framework",
        "For Feed",
        "COCO",
        "TCS",
        "MAE",
        "NSF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.383074"
    },
    {
      "id": "arxiv-2602.15716v1",
      "title": "Rethinking Metrics for Lexical Semantic Change Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15716v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15716v1",
        "authors": [
          "Roksana Goworek",
          "Haim Dubossarsky"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Symmetric Average Minimum Distance",
        "Lexical Semantic Change Detection",
        "Average Pairwise Distance",
        "Average Minimum Distance",
        "Rethinking Metrics",
        "LSCD",
        "SAMD",
        "AMD",
        "APD",
        "PRT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.383291"
    },
    {
      "id": "arxiv-2602.15712v1",
      "title": "Criteria-first, semantics-later: reproducible structure discovery in image-based sciences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15712v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Across the natural and life sciences, images have become a primary measurement modality, yet the dominant analytic paradigm remains semantics-first. Structure is recovered by predicting or enforcing domain-specific labels. This paradigm fails systematically under the conditions that make image-based science most valuable, including open-ended scientific discovery, cross-sensor and cross-site comparability, and long-term monitoring in which domain ontologies and associated label sets drift culturally, institutionally, and ecologically. A deductive inversion is proposed in the form of criteria-first and semantics-later. A unified framework for criteria-first structure discovery is introduced. It separates criterion-defined, semantics-free structure extraction from downstream semantic mapping into domain ontologies or vocabularies and provides a domain-general scaffold for reproducible analysis across image-based sciences. Reproducible science requires that the first analytic layer perform criterion-driven, semantics-free structure discovery, yielding stable partitions, structural fields, or hierarchies defined by explicit optimality criteria rather than local domain ontologies. Semantics is not discarded; it is relocated downstream as an explicit mapping from the discovered structural product to a domain ontology or vocabulary, enabling plural interpretations and explicit crosswalks without rewriting upstream extraction. Grounded in cybernetics, observation-as-distinction, and information theory's separation of information from meaning, the argument is supported by cross-domain evidence showing that criteria-first components recur whenever labels do not scale. Finally, consequences are outlined for validation beyond class accuracy and for treating structural products as FAIR, AI-ready digital objects for long-term monitoring and digital twins.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15712v1",
        "authors": [
          "Jan Bumberger"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "FAIR",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.383670"
    },
    {
      "id": "arxiv-2602.15711v1",
      "title": "Random Wavelet Features for Graph Kernel Machines",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15711v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15711v1",
        "authors": [
          "Valentin de Bassompierre",
          "Jean-Charles Delvenne",
          "Laurent Jacques"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Graph Kernel Machines Node",
        "Random Wavelet Features",
        "WHO",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.383898"
    },
    {
      "id": "arxiv-2602.15708v1",
      "title": "Outer Diversity of Structured Domains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15708v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.",
        "keywords": [
          "cs.GT",
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15708v1",
        "authors": [
          "Piotr Faliszewski",
          "Krzysztof Sornat",
          "Stanisław Szufa",
          "Tomasz Wąs"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Structured Domains An",
        "Outer Diversity",
        "EPA",
        "EU",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:57:52.384004"
    },
    {
      "id": "arxiv-2602.15707v1",
      "title": "Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15707v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Real-time conversational assistants for procedural tasks often depend on video input, which can be computationally expensive and compromise user privacy. For the first time, we propose a real-time conversational assistant that provides comprehensive guidance for a procedural task using only lightweight privacy-preserving modalities such as audio and IMU inputs from a user's wearable device to understand the context. This assistant proactively communicates step-by-step instructions to a user performing a furniture assembly task, and answers user questions. We construct a dataset containing conversations where the assistant guides the user in performing the task. On observing that an off-the-shelf language model is a very talkative assistant, we design a novel User Whim Agnostic (UWA) LoRA finetuning method which improves the model's ability to suppress less informative dialogues, while maintaining its tendency to communicate important instructions. This leads to >30% improvement in the F-score. Finetuning the model also results in a 16x speedup by eliminating the need to provide in-context examples in the prompt. We further describe how such an assistant is implemented on edge devices with no dependence on the cloud.",
        "keywords": [
          "cs.MM",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15707v1",
        "authors": [
          "Rehana Mahfuz",
          "Yinyi Guo",
          "Erik Visser",
          "Phanidhar Chinchili"
        ],
        "arxiv_categories": [
          "cs.MM",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Proactive Conversational Assistant",
        "Procedural Manual Task",
        "User Whim Agnostic",
        "UWA",
        "IMU",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.384282"
    },
    {
      "id": "arxiv-2602.15704v1",
      "title": "Controlled oscillation modeling using port-Hamiltonian neural networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15704v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Learning dynamical systems through purely data-driven methods is challenging as they do not learn the underlying conservation laws that enable them to correctly generalize. Existing port-Hamiltonian neural network methods have recently been successfully applied for modeling mechanical systems. However, even though these methods are designed on power-balance principles, they usually do not consider power-preserving discretizations and often rely on Runge-Kutta numerical methods. In this work, we propose to use a second-order discrete gradient method embedded in the learning of dynamical systems with port-Hamiltonian neural networks. Numerical results are provided for three systems deliberately selected to span different ranges of dynamical behavior under control: a baseline harmonic oscillator with quadratic energy storage; a Duffing oscillator, with a non-quadratic Hamiltonian offering amplitude-dependent effects; and a self-sustained oscillator, which can stabilize in a controlled limit cycle through the incorporation of a nonlinear dissipation. We show how the use of this discrete gradient method outperforms the performance of a Runge-Kutta method of the same order. Experiments are also carried out to compare two theoretically equivalent port-Hamiltonian systems formulations and to analyze the impact of regularizing the Jacobian of port-Hamiltonian neural networks during training.",
        "keywords": [
          "cs.LG",
          "eess.SY",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15704v1",
        "authors": [
          "Maximino Linares",
          "Guillaume Doras",
          "Thomas Hélie"
        ],
        "arxiv_categories": [
          "cs.LG",
          "eess.SY",
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.384581"
    },
    {
      "id": "arxiv-2602.15698v1",
      "title": "How to Disclose? Strategic AI Disclosure in Crowdfunding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15698v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15698v1",
        "authors": [
          "Ning Wang",
          "Chen Liang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Artificial Intelligence",
        "Leveraging Kickstarter",
        "Crowdfunding As",
        "Framework",
        "Policy",
        "Intel",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:57:52.384919"
    },
    {
      "id": "arxiv-2602.15689v1",
      "title": "A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15689v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15689v1",
        "authors": [
          "Meirav Segal",
          "Noa Linder",
          "Omer Antverg",
          "Gil Gekker",
          "Tomer Fichman"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cybersecurity Refusal Decisions",
        "Offensive Action Contribution",
        "Large Language Models Large",
        "Technical Complexity",
        "Expected Frequency",
        "Defensive Benefit",
        "Legitimate Users",
        "Based Framework",
        "Offensive Risk",
        "Framework",
        "Policy",
        "LLM",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.385206"
    },
    {
      "id": "arxiv-2602.15684v1",
      "title": "Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15684v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.HC",
          "eess.SP",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15684v1",
        "authors": [
          "Feras Kiki",
          "Pouya P. Niaz",
          "Alireza Madani",
          "Cagatay Basdogan"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.HC",
          "eess.SP",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Collaborative Robotic Tasks",
        "Estimating Human Muscular Fatigue",
        "Based Models Assessing",
        "Linear Regression",
        "Neural Network",
        "Random Forest",
        "Framework",
        "Robot",
        "RMSE",
        "NSF",
        "MIT",
        "EMG",
        "CNN",
        "FCF",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.385600"
    },
    {
      "id": "arxiv-2602.15678v1",
      "title": "Revisiting Northrop Frye's Four Myths Theory with Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15678v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15678v1",
        "authors": [
          "Edirlei Soares de Lima",
          "Marco A. Casanova",
          "Antonio L. Furtado"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models Northrop",
        "Revisiting Northrop Frye",
        "Large Language Models",
        "Framework",
        "Agreement",
        "NIST",
        "LLM",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.386491"
    },
    {
      "id": "arxiv-2602.15677v1",
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15677v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
        "keywords": [
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15677v1",
        "authors": [
          "Neelay Velingker",
          "Alaia Solko-Breslin",
          "Mayank Keoliya",
          "Seewon Choi",
          "Jiayi Xin"
        ],
        "arxiv_categories": [
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Forecasting Cardiac Events Electrocardiograms",
        "Language Model",
        "Framework",
        "CAMEL",
        "SOTA",
        "ECG",
        "LLM",
        "ELM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.386796"
    },
    {
      "id": "arxiv-2602.15676v1",
      "title": "Relative Geometry of Neural Forecasters: Linking Accuracy and Alignment in Learned Latent Geometry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15676v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Neural networks can accurately forecast complex dynamical systems, yet how they internally represent underlying latent geometry remains poorly understood. We study neural forecasters through the lens of representational alignment, introducing anchor-based, geometry-agnostic relative embeddings that remove rotational and scaling ambiguities in latent spaces. Applying this framework across seven canonical dynamical systems - ranging from periodic to chaotic - we reveal reproducible family-level structure: multilayer perceptrons align with other MLPs, recurrent networks with RNNs, while transformers and echo-state networks achieve strong forecasts despite weaker alignment. Alignment generally correlates with forecasting accuracy, yet high accuracy can coexist with low alignment. Relative geometry thus provides a simple, reproducible foundation for comparing how model families internalize and represent dynamical structure.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15676v1",
        "authors": [
          "Deniz Kucukahmetler",
          "Maximilian Jean Hemmann",
          "Julian Mosig von Aehrenfeld",
          "Maximilian Amthor",
          "Christian Deubel"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learned Latent Geometry Neural",
        "Neural Forecasters",
        "Relative Geometry",
        "Linking Accuracy",
        "Neural Network",
        "Transformer",
        "Framework",
        "NSF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.387025"
    },
    {
      "id": "arxiv-2602.15675v1",
      "title": "LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15675v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15675v1",
        "authors": [
          "Ahmed Khaled Khamis",
          "Hesham Ali"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Synthetic Data Pipeline",
        "Training Dialectal Text",
        "Speech Models Despite",
        "Modern Spoken Arabic",
        "Egyptian Arabic",
        "XTTS",
        "TTS",
        "MSA",
        "LLM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.387296"
    },
    {
      "id": "arxiv-2602.15669v1",
      "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15669v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15669v1",
        "authors": [
          "Xiachong Feng",
          "Liang Zhao",
          "Weihong Zhong",
          "Yichong Huang",
          "Yuxuan Gu"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Activation Vector Algebra Current",
        "Time Personality Control",
        "Compositional Inference",
        "Large Language Models",
        "Framework",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.387608"
    },
    {
      "id": "arxiv-2602.15660v1",
      "title": "Bayesian Optimization for Design Parameters of 3D Image Data Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15660v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15660v1",
        "authors": [
          "David Exler",
          "Joaquin Eduardo Urrutia Gómez",
          "Martin Krüger",
          "Maike Schliephake",
          "John Jbeily"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Analysis Optimization Pipeline",
        "Image Data Analysis Deep",
        "Bayesian Optimization",
        "Design Parameters",
        "Deep Learning",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.387907"
    },
    {
      "id": "arxiv-2602.15656v1",
      "title": "A Novel Public Dataset for Strawberry (Fragaria x ananassa) Ripeness Detection and Comparative Evaluation of YOLO-Based Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15656v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The strawberry (Fragaria x ananassa), known worldwide for its economic value and nutritional richness, is a widely cultivated fruit. Determining the correct ripeness level during the harvest period is crucial for both preventing losses for producers and ensuring consumers receive a quality product. However, traditional methods, i.e., visual assessments alone, can be subjective and have a high margin of error. Therefore, computer-assisted systems are needed. However, the scarcity of comprehensive datasets accessible to everyone in the literature makes it difficult to compare studies in this field. In this study, a new and publicly available strawberry ripeness dataset, consisting of 566 images and 1,201 labeled objects, prepared under variable light and environmental conditions in two different greenhouses in Turkey, is presented to the literature. Comparative tests conducted on the data set using YOLOv8, YOLOv9, and YOLO11-based models showed that the highest precision value was 90.94% in the YOLOv9c model, while the highest recall value was 83.74% in the YOLO11s model. In terms of the general performance criterion mAP@50, YOLOv8s was the best performing model with a success rate of 86.09%. The results show that small and medium-sized models work more balanced and efficiently on this type of dataset, while also establishing a fundamental reference point for smart agriculture applications.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15656v1",
        "authors": [
          "Mustafa Yurdakul",
          "Zeynep Sena Bastug",
          "Ali Emre Gok",
          "Sakir Taşdemir"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Comparative Evaluation",
        "Novel Public Dataset",
        "Ripeness Detection",
        "YOLO",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.388227"
    },
    {
      "id": "arxiv-2602.15654v1",
      "title": "Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15654v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the agent into a puppet of the attacker. We present a black-box attack framework that uses only indirect exposure through attacker-controlled web content. The attack has two phases. During infection, the agent reads a poisoned source while completing a benign task and writes the payload into long-term memory through its normal update process. During trigger, the payload is retrieved or carried forward and causes unauthorized tool behavior. We design mechanism-specific persistence strategies for common memory implementations, including sliding-window and retrieval-augmented memory, to resist truncation and relevance filtering. We evaluate the attack on representative agent setups and tasks, measuring both persistence over time and the ability to induce unauthorized actions while preserving benign task quality. Our results show that memory evolution can convert one-time indirect injection into persistent compromise, which suggests that defenses focused only on per-session prompt filtering are not sufficient for self-evolving agents.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15654v1",
        "authors": [
          "Xianglin Yang",
          "Yufei He",
          "Shuo Ji",
          "Bryan Hooi",
          "Jin Song Dong"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcing Injections Self",
        "Persistent Control",
        "Zombie Agents",
        "Zombie Agent",
        "Framework",
        "Wind",
        "LLM",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.388565"
    },
    {
      "id": "arxiv-2602.15651v1",
      "title": "UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15651v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This work considers merging two independent models, TTS and A2F, into a unified model to enable internal feature transfer, thereby improving the consistency between audio and facial expressions generated from text. We also discuss the extension of the emotion control mechanism from TTS to the joint model. This work does not aim to showcase generation quality; instead, from a system design perspective, it validates the feasibility of reusing intermediate representations from TTS for joint modeling of speech and facial expressions, and provides engineering practice references for subsequent speech expression co-design. The project code has been open source at: https://github.com/GoldenFishes/UniTAF",
        "keywords": [
          "cs.SD",
          "cs.CV",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15651v1",
        "authors": [
          "Qiangong Zhou",
          "Nagasaka Tomohiro"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.CV",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Modular Framework",
        "Joint Text",
        "Framework",
        "DOE",
        "TTS",
        "NSF",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.388744"
    },
    {
      "id": "arxiv-2602.15650v1",
      "title": "Concept-Enhanced Multimodal RAG: Towards Interpretable and Accurate Radiology Report Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15650v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Radiology Report Generation (RRG) through Vision-Language Models (VLMs) promises to reduce documentation burden, improve reporting consistency, and accelerate clinical workflows. However, their clinical adoption remains limited by the lack of interpretability and the tendency to hallucinate findings misaligned with imaging evidence. Existing research typically treats interpretability and accuracy as separate objectives, with concept-based explainability techniques focusing primarily on transparency, while Retrieval-Augmented Generation (RAG) methods targeting factual grounding through external retrieval. We present Concept-Enhanced Multimodal RAG (CEMRAG), a unified framework that decomposes visual representations into interpretable clinical concepts and integrates them with multimodal RAG. This approach exploits enriched contextual prompts for RRG, improving both interpretability and factual accuracy. Experiments on MIMIC-CXR and IU X-Ray across multiple VLM architectures, training regimes, and retrieval configurations demonstrate consistent improvements over both conventional RAG and concept-only baselines on clinical accuracy metrics and standard NLP measures. These results challenge the assumed trade-off between interpretability and performance, showing that transparent visual concepts can enhance rather than compromise diagnostic accuracy in medical VLMs. Our modular design decomposes interpretability into visual transparency and structured language model conditioning, providing a principled pathway toward clinically trustworthy AI-assisted radiology.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15650v1",
        "authors": [
          "Marco Salmè",
          "Federico Siciliano",
          "Fabrizio Silvestri",
          "Paolo Soda",
          "Rosa Sicilia"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Accurate Radiology Report Generation",
        "Radiology Report Generation",
        "Towards Interpretable",
        "Augmented Generation",
        "Enhanced Multimodal",
        "Language Models",
        "Framework",
        "Standard",
        "CEMRAG",
        "MIMIC",
        "VLM",
        "EPA",
        "RRG",
        "RAG",
        "NLP"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.389090"
    },
    {
      "id": "arxiv-2602.15649v1",
      "title": "Continuous-Time Piecewise-Linear Recurrent Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15649v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In dynamical systems reconstruction (DSR) we aim to recover the dynamical system (DS) underlying observed time series. Specifically, we aim to learn a generative surrogate model which approximates the underlying, data-generating DS, and recreates its long-term properties (`climate statistics'). In scientific and medical areas, in particular, these models need to be mechanistically tractable -- through their mathematical analysis we would like to obtain insight into the recovered system's workings. Piecewise-linear (PL), ReLU-based RNNs (PLRNNs) have a strong track-record in this regard, representing SOTA DSR models while allowing mathematical insight by virtue of their PL design. However, all current PLRNN variants are discrete-time maps. This is in disaccord with the assumed continuous-time nature of most physical and biological processes, and makes it hard to accommodate data arriving at irregular temporal intervals. Neural ODEs are one solution, but they do not reach the DSR performance of PLRNNs and often lack their tractability. Here we develop theory for continuous-time PLRNNs (cPLRNNs): We present a novel algorithm for training and simulating such models, bypassing numerical integration by efficiently exploiting their PL structure. We further demonstrate how important topological objects like equilibria or limit cycles can be determined semi-analytically in trained models. We compare cPLRNNs to both their discrete-time cousins as well as Neural ODEs on DSR benchmarks, including systems with discontinuities which come with hard thresholds.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15649v1",
        "authors": [
          "Alena Brändle",
          "Lukas Eisenmann",
          "Florian Götz",
          "Daniel Durstewitz"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Linear Recurrent Neural Networks",
        "Neural Network",
        "Time Piecewise",
        "PLRNN",
        "SOTA",
        "NIST",
        "MIT",
        "DSR",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.389420"
    },
    {
      "id": "arxiv-2602.15648v1",
      "title": "Guided Diffusion by Optimized Loss Functions on Relaxed Parameters for Inverse Material Design",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15648v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Inverse design problems are common in engineering and materials science. The forward direction, i.e., computing output quantities from design parameters, typically requires running a numerical simulation, such as a FEM, as an intermediate step, which is an optimization problem by itself. In many scenarios, several design parameters can lead to the same or similar output values. For such cases, multi-modal probabilistic approaches are advantageous to obtain diverse solutions. A major difficulty in inverse design stems from the structure of the design space, since discrete parameters or further constraints disallow the direct use of gradient-based optimization. To tackle this problem, we propose a novel inverse design method based on diffusion models. Our approach relaxes the original design space into a continuous grid representation, where gradients can be computed by implicit differentiation in the forward simulation. A diffusion model is trained on this relaxed parameter space in order to serve as a prior for plausible relaxed designs. Parameters are sampled by guided diffusion using gradients that are propagated from an objective function specified at inference time through the differentiable simulation. A design sample is obtained by backprojection into the original parameter space. We develop our approach for a composite material design problem where the forward process is modeled as a linear FEM problem. We evaluate the performance of our approach in finding designs that match a specified bulk modulus. We demonstrate that our method can propose diverse designs within 1% relative error margin from medium to high target bulk moduli in 2D and 3D settings. We also demonstrate that the material density of generated samples can be minimized simultaneously by using a multi-objective loss function.",
        "keywords": [
          "cs.LG",
          "cs.CE",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15648v1",
        "authors": [
          "Jens U. Kreber",
          "Christian Weißenfels",
          "Joerg Stueckler"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CE",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inverse Material Design Inverse",
        "Optimized Loss Functions",
        "Relaxed Parameters",
        "Guided Diffusion",
        "Fusion",
        "FEM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.389805"
    },
    {
      "id": "arxiv-2602.15645v1",
      "title": "CARE Drive A Framework for Evaluating Reason-Responsiveness of Vision Language Models in Automated Driving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15645v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Foundation models, including vision language models, are increasingly used in automated driving to interpret scenes, recommend actions, and generate natural language explanations. However, existing evaluation methods primarily assess outcome based performance, such as safety and trajectory accuracy, without determining whether model decisions reflect human relevant considerations. As a result, it remains unclear whether explanations produced by such models correspond to genuine reason responsive decision making or merely post hoc rationalizations. This limitation is especially significant in safety critical domains because it can create false confidence. To address this gap, we propose CARE Drive, Context Aware Reasons Evaluation for Driving, a model agnostic framework for evaluating reason responsiveness in vision language models applied to automated driving. CARE Drive compares baseline and reason augmented model decisions under controlled contextual variation to assess whether human reasons causally influence decision behavior. The framework employs a two stage evaluation process. Prompt calibration ensures stable outputs. Systematic contextual perturbation then measures decision sensitivity to human reasons such as safety margins, social pressure, and efficiency constraints. We demonstrate CARE Drive in a cyclist overtaking scenario involving competing normative considerations. Results show that explicit human reasons significantly influence model decisions, improving alignment with expert recommended behavior. However, responsiveness varies across contextual factors, indicating uneven sensitivity to different types of reasons. These findings provide empirical evidence that reason responsiveness in foundation models can be systematically evaluated without modifying model parameters.",
        "keywords": [
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15645v1",
        "authors": [
          "Lucas Elbert Suryana",
          "Farah Bierenga",
          "Sanne van Buuren",
          "Pepijn Kooij",
          "Elsefien Tulleners"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Context Aware Reasons Evaluation",
        "Automated Driving Foundation",
        "Vision Language Models",
        "Evaluating Reason",
        "Framework",
        "CARE",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.390192"
    },
    {
      "id": "arxiv-2602.15640v1",
      "title": "Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15640v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation.",
        "keywords": [
          "eess.SP",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15640v1",
        "authors": [
          "Peizheng Li",
          "Xinyi Lin",
          "Adnan Aijaz"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Semantic Communications Semantic",
        "Loop Reinforcement Learning",
        "Framework",
        "Policy",
        "Intel",
        "CMDP",
        "HITL",
        "PPO",
        "WHO",
        "Act",
        "RAN",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.390465"
    },
    {
      "id": "arxiv-2602.15637v1",
      "title": "The Stationarity Bias: Stratified Stress-Testing for Time-Series Imputation in Regulated Dynamical Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15637v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Time-series imputation benchmarks employ uniform random masking and shape-agnostic metrics (MSE, RMSE), implicitly weighting evaluation by regime prevalence. In systems with a dominant attractor -- homeostatic physiology, nominal industrial operation, stable network traffic -- this creates a systematic \\emph{Stationarity Bias}: simple methods appear superior because the benchmark predominantly samples the easy, low-entropy regime where they trivially succeed. We formalize this bias and propose a \\emph{Stratified Stress-Test} that partitions evaluation into Stationary and Transient regimes. Using Continuous Glucose Monitoring (CGM) as a testbed -- chosen for its rigorous ground-truth forcing functions (meals, insulin) that enable precise regime identification -- we establish three findings with broad implications:(i)~Stationary Efficiency: Linear interpolation achieves state-of-the-art reconstruction during stable intervals, confirming that complex architectures are computationally wasteful in low-entropy regimes.(ii)~Transient Fidelity: During critical transients (post-prandial peaks, hypoglycemic events), linear methods exhibit drastically degraded morphological fidelity (DTW), disproportionate to their RMSE -- a phenomenon we term the \\emph{RMSE Mirage}, where low pointwise error masks the destruction of signal shape.(iii)~Regime-Conditional Model Selection: Deep learning models preserve both pointwise accuracy and morphological integrity during transients, making them essential for safety-critical downstream tasks. We further derive empirical missingness distributions from clinical trials and impose them on complete training data, preventing models from exploiting unrealistically clean observations and encouraging robustness under real-world missingness. This framework generalizes to any regulated system where routine stationarity dominates critical transients.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15637v1",
        "authors": [
          "Amirreza Dolatpour Fathkouhi",
          "Alireza Namazi",
          "Heman Shakeri"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Using Continuous Glucose Monitoring",
        "Regulated Dynamical Systems Time",
        "Conditional Model Selection",
        "Stationary Efficiency",
        "Transient Fidelity",
        "Series Imputation",
        "Stationarity Bias",
        "Stratified Stress",
        "Deep Learning",
        "Framework",
        "RMSE",
        "CGM",
        "MSE",
        "DTW",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.390862"
    },
    {
      "id": "arxiv-2602.15635v1",
      "title": "On inferring cumulative constraints",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15635v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Cumulative constraints are central in scheduling with constraint programming, yet propagation is typically performed per constraint, missing multi-resource interactions and causing severe slowdowns on some benchmarks. I present a preprocessing method for inferring additional cumulative constraints that capture such interactions without search-time probing. This approach interprets cumulative constraints as linear inequalities over occupancy vectors and generates valid inequalities by (i) discovering covers, the sets of tasks that cannot run in parallel, (ii) strengthening the cover inequalities for the discovered sets with lifting, and (iii) injecting the resulting constraints back into the scheduling problem instance. Experiments on standard RCPSP and RCPSP/max test suites show that these inferred constraints improve search performance and tighten objective bounds on favorable instances, while incurring little degradation on unfavorable ones. Additionally, these experiments discover 25 new lower bounds and five new best solutions; eight of the lower bounds are obtained directly from the inferred constraints.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15635v1",
        "authors": [
          "Konstantin Sidorov"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "RCPSP",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.391085"
    },
    {
      "id": "arxiv-2602.15634v1",
      "title": "Beyond ReLU: Bifurcation, Oversmoothing, and Topological Priors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15634v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Graph Neural Networks (GNNs) learn node representations through iterative network-based message-passing. While powerful, deep GNNs suffer from oversmoothing, where node features converge to a homogeneous, non-informative state. We re-frame this problem of representational collapse from a \\emph{bifurcation theory} perspective, characterizing oversmoothing as convergence to a stable ``homogeneous fixed point.'' Our central contribution is the theoretical discovery that this undesired stability can be broken by replacing standard monotone activations (e.g., ReLU) with a class of functions. Using Lyapunov-Schmidt reduction, we analytically prove that this substitution induces a bifurcation that destabilizes the homogeneous state and creates a new pair of stable, non-homogeneous \\emph{patterns} that provably resist oversmoothing. Our theory predicts a precise, nontrivial scaling law for the amplitude of these emergent patterns, which we quantitatively validate in experiments. Finally, we demonstrate the practical utility of our theory by deriving a closed-form, bifurcation-aware initialization and showing its utility in real benchmark experiments.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15634v1",
        "authors": [
          "Erkan Turan",
          "Gaspard Abel",
          "Maysam Behmanesh",
          "Emery Pierson",
          "Maks Ovsjanikov"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Topological Priors Graph Neural",
        "Using Lyapunov",
        "Neural Network",
        "Standard",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.391317"
    },
    {
      "id": "arxiv-2602.15632v1",
      "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15632v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks.",
        "keywords": [
          "physics.comp-ph",
          "cs.LG",
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15632v1",
        "authors": [
          "Changhong Mou",
          "Binghang Lu",
          "Guang Lin"
        ],
        "arxiv_categories": [
          "physics.comp-ph",
          "cs.LG",
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Functional Nonlinear Proper",
        "Neural Proper Orthogonal Decomposition",
        "Proper Orthogonal Decomposition",
        "Play Neural Operator Framework",
        "Neural Network",
        "Framework",
        "SVD",
        "ROM",
        "IoT",
        "POD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.391668"
    },
    {
      "id": "arxiv-2602.15620v1",
      "title": "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15620v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\\%, which we term \\emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\\% over GRPO, 20-Entropy and JustRL.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15620v1",
        "authors": [
          "Shiqi Liu",
          "Zeyu He",
          "Guojian Zhan",
          "Letian Tao",
          "Zhilong Zheng"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stabilizing Reinforcement Learning",
        "Silencing Rare Spurious Tokens",
        "Aware Policy Optimization",
        "Reinforcement Learning",
        "Policy",
        "STAPO",
        "GRPO",
        "LLM",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.391946"
    },
    {
      "id": "arxiv-2602.15617v1",
      "title": "DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15617v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.",
        "keywords": [
          "cs.LG",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15617v1",
        "authors": [
          "Kaifeng Lu",
          "Markus Rupp",
          "Stefan Schwarz"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adjustable Fairness Ensuring",
        "Throughput Maximization",
        "User Beamforming",
        "Enabled Multi",
        "Transformer",
        "DNN",
        "CSI",
        "NSF",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.392147"
    },
    {
      "id": "arxiv-2602.15603v1",
      "title": "Symbolic recovery of PDEs from measurement data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15603v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.",
        "keywords": [
          "cs.LG",
          "cs.SC",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15603v1",
        "authors": [
          "Erion Morina",
          "Philipp Scholl",
          "Martin Holler"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.SC",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "MIT",
        "PDE",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.392422"
    },
    {
      "id": "arxiv-2602.15602v1",
      "title": "Certified Per-Instance Unlearning Using Individual Sensitivity Bounds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15602v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Certified machine unlearning can be achieved via noise injection leading to differential privacy guarantees, where noise is calibrated to worst-case sensitivity. Such conservative calibration often results in performance degradation, limiting practical applicability. In this work, we investigate an alternative approach based on adaptive per-instance noise calibration tailored to the individual contribution of each data point to the learned solution. This raises the following challenge: how can one establish formal unlearning guarantees when the mechanism depends on the specific point to be removed? To define individual data point sensitivities in noisy gradient dynamics, we consider the use of per-instance differential privacy. For ridge regression trained via Langevin dynamics, we derive high-probability per-instance sensitivity bounds, yielding certified unlearning with substantially less noise injection. We corroborate our theoretical findings through experiments in linear settings and provide further empirical evidence on the relevance of the approach in deep learning settings.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15602v1",
        "authors": [
          "Hanna Benarroch",
          "Jamal Atif",
          "Olivier Cappé"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Instance Unlearning Using Individual",
        "Sensitivity Bounds Certified",
        "Deep Learning",
        "Certified Per",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.392644"
    },
    {
      "id": "arxiv-2602.15600v1",
      "title": "The geometry of online conversations and the causal antecedents of conflictual discourse",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15600v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned.",
        "keywords": [
          "cs.SI",
          "cs.AI",
          "econ.EM",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15600v1",
        "authors": [
          "Carlo Santagiustina",
          "Caterina Cruciani"
        ],
        "arxiv_categories": [
          "cs.SI",
          "cs.AI",
          "econ.EM",
          "stat.AP"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Agreement",
        "LLM",
        "Act"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:57:52.392980"
    },
    {
      "id": "arxiv-2602.15595v1",
      "title": "Multi-Objective Coverage via Constraint Active Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15595v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we formulate the new multi-objective coverage (MOC) problem where our goal is to identify a small set of representative samples whose predicted outcomes broadly cover the feasible multi-objective space. This problem is of great importance in many critical real-world applications, e.g., drug discovery and materials design, as this representative set can be evaluated much faster than the whole feasible set, thus significantly accelerating the scientific discovery process. Existing works cannot be directly applied as they either focus on sample space coverage or multi-objective optimization that targets the Pareto front. However, chemically diverse samples often yield identical objective profiles, and safety constraints are usually defined on the objectives. To solve this MOC problem, we propose a novel search algorithm, MOC-CAS, which employs an upper confidence bound-based acquisition function to select optimistic samples guided by Gaussian process posterior predictions. For enabling efficient optimization, we develop a smoothed relaxation of the hard feasibility test and derive an approximate optimizer. Compared to the competitive baselines, we show that our MOC-CAS empirically achieves superior performances across large-scale protein-target datasets for SARS-CoV-2 and cancer, each assessed on five objectives derived from SMILES-based features.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15595v1",
        "authors": [
          "Zakaria Shams Siam",
          "Xuefeng Liu",
          "Chong Liu"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constraint Active Search In",
        "Objective Coverage",
        "SMILES",
        "CoV-2",
        "SARS",
        "CAS",
        "WHO",
        "MOC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.393245"
    },
    {
      "id": "arxiv-2602.15593v1",
      "title": "A unified theory of feature learning in RNNs and DNNs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15593v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recurrent and deep neural networks (RNNs/DNNs) are cornerstone architectures in machine learning. Remarkably, RNNs differ from DNNs only by weight sharing, as can be shown through unrolling in time. How does this structural similarity fit with the distinct functional properties these networks exhibit? To address this question, we here develop a unified mean-field theory for RNNs and DNNs in terms of representational kernels, describing fully trained networks in the feature learning ($μ$P) regime. This theory casts training as Bayesian inference over sequences and patterns, directly revealing the functional implications induced by the RNNs' weight sharing. In DNN-typical tasks, we identify a phase transition when the learning signal overcomes the noise due to randomness in the weights: below this threshold, RNNs and DNNs behave identically; above it, only RNNs develop correlated representations across timesteps. For sequential tasks, the RNNs' weight sharing furthermore induces an inductive bias that aids generalization by interpolating unsupervised time steps. Overall, our theory offers a way to connect architectural structure to functional biases.",
        "keywords": [
          "cs.LG",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15593v1",
        "authors": [
          "Jan P. Bauer",
          "Kirsten Fischer",
          "Moritz Helias",
          "Agostina Palmigiano"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cond-mat.dis-nn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "DOE",
        "DNN",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.393778"
    },
    {
      "id": "arxiv-2602.15592v1",
      "title": "Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15592v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics.",
        "keywords": [
          "physics.flu-dyn",
          "cs.LG",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15592v1",
        "authors": [
          "Xiao Xue",
          "Tianyue Yang",
          "Mingyang Gao",
          "Leyu Pan",
          "Maida Wang"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cs.LG",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Machine Learning",
        "Framework",
        "Fusion",
        "EPA",
        "IoT",
        "HPC",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:57:52.394098"
    },
    {
      "id": "arxiv-2602.15586v1",
      "title": "Uniform error bounds for quantized dynamical models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15586v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper provides statistical guarantees on the accuracy of dynamical models learned from dependent data sequences. Specifically, we develop uniform error bounds that apply to quantized models and imperfect optimization algorithms commonly used in practical contexts for system identification, and in particular hybrid system identification. Two families of bounds are obtained: slow-rate bounds via a block decomposition and fast-rate, variance-adaptive, bounds via a novel spaced-point strategy. The bounds scale with the number of bits required to encode the model and thus translate hardware constraints into interpretable statistical complexities.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15586v1",
        "authors": [
          "Abdelkader Metakalard",
          "Fabien Lauer",
          "Kevin Colin",
          "Marion Gilson"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.394249"
    },
    {
      "id": "arxiv-2602.15584v1",
      "title": "An Industrial Dataset for Scene Acquisitions and Functional Schematics Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15584v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Aligning functional schematics with 2D and 3D scene acquisitions is crucial for building digital twins, especially for old industrial facilities that lack native digital models. Current manual alignment using images and LiDAR data does not scale due to tediousness and complexity of industrial sites. Inconsistencies between schematics and reality, and the scarcity of public industrial datasets, make the problem both challenging and underexplored. This paper introduces IRIS-v2, a comprehensive dataset to support further research. It includes images, point clouds, 2D annotated boxes and segmentation masks, a CAD model, 3D pipe routing information, and the P&ID (Piping and Instrumentation Diagram). The alignment is experimented on a practical case study, aiming at reducing the time required for this task by combining segmentation and graph matching.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15584v1",
        "authors": [
          "Flavien Armangeon",
          "Thibaud Ehret",
          "Enric Meinhardt-Llopis",
          "Rafael Grompone von Gioi",
          "Guillaume Thibault"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Functional Schematics Alignment Aligning",
        "Instrumentation Diagram",
        "An Industrial Dataset",
        "Scene Acquisitions",
        "IRIS",
        "DOE",
        "CAD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.394448"
    },
    {
      "id": "arxiv-2602.15580v1",
      "title": "How Vision Becomes Language: A Layer-wise Information-Theoretic Analysis of Multimodal Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15580v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "When a multimodal Transformer answers a visual question, is the prediction driven by visual evidence, linguistic reasoning, or genuinely fused cross-modal computation -- and how does this structure evolve across layers? We address this question with a layer-wise framework based on Partial Information Decomposition (PID) that decomposes the predictive information at each Transformer layer into redundant, vision-unique, language-unique, and synergistic components. To make PID tractable for high-dimensional neural representations, we introduce \\emph{PID Flow}, a pipeline combining dimensionality reduction, normalizing-flow Gaussianization, and closed-form Gaussian PID estimation. Applying this framework to LLaVA-1.5-7B and LLaVA-1.6-7B across six GQA reasoning tasks, we uncover a consistent \\emph{modal transduction} pattern: visual-unique information peaks early and decays with depth, language-unique information surges in late layers to account for roughly 82\\% of the final prediction, and cross-modal synergy remains below 2\\%. This trajectory is highly stable across model variants (layer-wise correlations $>$0.96) yet strongly task-dependent, with semantic redundancy governing the detailed information fingerprint. To establish causality, we perform targeted Image$\\rightarrow$Question attention knockouts and show that disrupting the primary transduction pathway induces predictable increases in trapped visual-unique information, compensatory synergy, and total information cost -- effects that are strongest in vision-dependent tasks and weakest in high-redundancy tasks. Together, these results provide an information-theoretic, causal account of how vision becomes language in multimodal Transformers, and offer quantitative guidance for identifying architectural bottlenecks where modality-specific information is lost.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15580v1",
        "authors": [
          "Hongxuan Wu",
          "Yukun Zhang",
          "Xueqing Zhou"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Partial Information Decomposition",
        "How Vision Becomes Language",
        "Multimodal Reasoning When",
        "Transformer",
        "LLaVA-1.6",
        "Framework",
        "LLaVA-1.5",
        "DOE",
        "NSF",
        "GQA",
        "Act",
        "PID",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.394788"
    },
    {
      "id": "arxiv-2602.15579v1",
      "title": "Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15579v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification in OCT images using machine learning techniques. The proposed method integrates image preprocessing, guidewire artifact removal, polar-to-Cartesian transformation, unsupervised K-means clustering, and local feature extraction. These features are used to train Logistic Regression and Support Vector Machine classifiers for pixel-wise vessel classification. Experimental results demonstrate excellent performance, achieving precision, recall, and F1-score values up to 1.00 and overall classification accuracy of 99.68%. The proposed approach provides accurate vessel boundary detection while maintaining low computational complexity and requiring minimal manual annotation. This method offers a reliable and efficient solution for automated OCT image analysis and has potential applications in clinical decision support and real-time medical image processing.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15579v1",
        "authors": [
          "Amal Lahchim",
          "Lambros Athanasiou"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Intracoronary Optical Coherence Tomography",
        "Learning Intracoronary Optical Coherence",
        "Vessel Classification Using Machine",
        "Support Vector Machine",
        "Logistic Regression",
        "Machine Learning",
        "Image Processing",
        "OCT",
        "NSF",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.395027"
    },
    {
      "id": "arxiv-2602.15578v1",
      "title": "Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15578v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15578v1",
        "authors": [
          "Chaithra Nerella",
          "Chiranjeevi Yarra"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Speech Representations Depression",
        "Clinically Inspired Symptom",
        "Guided Depression Detection",
        "Framework",
        "Standard",
        "EDAIC",
        "PHQ-8",
        "PHQ",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.395301"
    },
    {
      "id": "arxiv-2602.15572v1",
      "title": "Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15572v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.",
        "keywords": [
          "cs.LG",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15572v1",
        "authors": [
          "M Lopes Alves",
          "Joel Dyer",
          "Doyne Farmer",
          "Michael Wooldridge",
          "Anisoara Calinescu"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Parameter Estimation",
        "Labour Market Agent",
        "Based Model Agent",
        "Neural Network",
        "Framework",
        "MIT",
        "ABM",
        "SBI",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.395530"
    },
    {
      "id": "arxiv-2602.15571v1",
      "title": "Accelerated Predictive Coding Networks via Direct Kolen-Pollack Feedback Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15571v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Predictive coding (PC) is a biologically inspired algorithm for training neural networks that relies only on local updates, allowing parallel learning across layers. However, practical implementations face two key limitations: error signals must still propagate from the output to early layers through multiple inference-phase steps, and feedback decays exponentially during this process, leading to vanishing updates in early layers. We propose direct Kolen-Pollack predictive coding (DKP-PC), which simultaneously addresses both feedback delay and exponential decay, yielding a more efficient and scalable variant of PC while preserving update locality. Leveraging direct feedback alignment and direct Kolen-Pollack algorithms, DKP-PC introduces learnable feedback connections from the output layer to all hidden layers, establishing a direct pathway for error transmission. This yields an algorithm that reduces the theoretical error propagation time complexity from O(L), with L being the network depth, to O(1), removing depth-dependent delay in error signals. Moreover, empirical results demonstrate that DKP-PC achieves performance at least comparable to, and often exceeding, that of standard PC, while offering improved latency and computational performance, supporting its potential for custom hardware-efficient implementations.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15571v1",
        "authors": [
          "Davide Casnici",
          "Martin Lefebvre",
          "Justin Dauwels",
          "Charlotte Frenkel"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Accelerated Predictive Coding Networks",
        "Pollack Feedback Alignment Predictive",
        "Neural Network",
        "Direct Kolen",
        "Standard",
        "MIT",
        "Act",
        "DKP",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.395797"
    },
    {
      "id": "arxiv-2602.15568v1",
      "title": "Scenario Approach with Post-Design Certification of User-Specified Properties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15568v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The scenario approach is an established data-driven design framework that comes equipped with a powerful theory linking design complexity to generalization properties. In this approach, data are simultaneously used both for design and for certifying the design's reliability, without resorting to a separate test dataset. This paper takes a step further by guaranteeing additional properties, useful in post-design usage but not considered during the design phase. To this end, we introduce a two-level framework of appropriateness: baseline appropriateness, which guides the design process, and post-design appropriateness, which serves as a criterion for a posteriori evaluation. We provide distribution-free upper bounds on the risk of failing to meet the post-design appropriateness; these bounds are computable without using any additional test data. Under additional assumptions, lower bounds are also derived. As part of an effort to demonstrate the usefulness of the proposed methodology, the paper presents two practical examples in H2 and pole-placement problems. Moreover, a method is provided to infer comprehensive distributional knowledge of relevant performance indexes from the available dataset.",
        "keywords": [
          "stat.ME",
          "cs.LG",
          "eess.SY",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15568v1",
        "authors": [
          "Algo Carè",
          "Marco C. Campi",
          "Simone Garatti"
        ],
        "arxiv_categories": [
          "stat.ME",
          "cs.LG",
          "eess.SY",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Design Certification",
        "Scenario Approach",
        "Framework",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.396046"
    },
    {
      "id": "arxiv-2602.15564v1",
      "title": "Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15564v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15564v1",
        "authors": [
          "Yihan Wang",
          "Peiyu Liu",
          "Runyu Chen",
          "Wei Xu"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Dynamic Workflows",
        "Beyond Static Pipelines",
        "Framework",
        "MIT",
        "SQL",
        "LLM",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.396299"
    },
    {
      "id": "arxiv-2602.15563v1",
      "title": "1-Bit Wonder: Improving QAT Performance in the Low-Bit Regime through K-Means Quantization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15563v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantization-aware training (QAT) is an effective method to drastically reduce the memory footprint of LLMs while keeping performance degradation at an acceptable level. However, the optimal choice of quantization format and bit-width presents a challenge in practice. The full design space of quantization is not fully explored in the context of QAT, and the precise trade-off between quantization and downstream performance is poorly understood, as comparisons often rely solely on perplexity-based evaluations. In this work, we address these shortcomings with an empirical study of QAT in the low-bit regime. We show that k-means based weight quantization outperforms integer formats and can be implemented efficiently on standard hardware. Furthermore, we find that, under a fixed inference memory budget, the best performance on generative downstream tasks is achieved with $1$-bit quantized weights.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15563v1",
        "authors": [
          "Sohir Maskey",
          "Constantin Eichenberg",
          "Johannes Messner",
          "Douglas Orr"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Means Quantization Quantization",
        "Bit Wonder",
        "Bit Regime",
        "Standard",
        "QAT",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.396498"
    },
    {
      "id": "arxiv-2602.15556v1",
      "title": "Revealing and Enhancing Core Visual Regions: Harnessing Internal Attention Dynamics for Hallucination Mitigation in LVLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15556v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "LVLMs have achieved strong multimodal reasoning capabilities but remain prone to hallucinations, producing outputs inconsistent with visual inputs or user instructions. Existing training-free methods, including contrastive decoding and auxiliary expert models, which incur several times more computational overhead and may introduce potential interference, as well as static internal signal enhancement, are often vulnerable to the attention sink phenomenon. We find that internal Positive Attention Dynamics (PAD) in LVLMs naturally reveal semantically core visual regions under the distortions of attention sinks. Based on this, we propose Positive Attention Dynamics Enhancement (PADE), a training-free attention intervention that constructs a PAD map to identify semantically core visual regions, applies per-head Median Absolute Deviation Scaling to adaptively control the intervention strength, and leverages System-Token Compensation to maintain attention to complex user instructions and support long-term output consistency. Experiments on multiple LVLMs and benchmarks show that PADE improves visual grounding and reduces hallucinations, validating the effectiveness of leveraging internal attention dynamics for reliable multimodal reasoning.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15556v1",
        "authors": [
          "Guangtao Lyu",
          "Qi Liu",
          "Chenghao Xu",
          "Jiexi Yan",
          "Muli Yang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Positive Attention Dynamics Enhancement",
        "Harnessing Internal Attention Dynamics",
        "Median Absolute Deviation Scaling",
        "Enhancing Core Visual Regions",
        "Positive Attention Dynamics",
        "Hallucination Mitigation",
        "Token Compensation",
        "PADE",
        "MIT",
        "PAD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.396767"
    },
    {
      "id": "arxiv-2602.15553v1",
      "title": "RUVA: Personalized Transparent On-Device Graph Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15553v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Personal AI landscape is currently dominated by \"Black Box\" Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves sensitive data, the user cannot inspect the cause nor correct the error. Worse, \"deleting\" a concept from a vector space is mathematically imprecise, leaving behind probabilistic \"ghosts\" that violate true privacy. We propose Ruva, the first \"Glass Box\" architecture designed for Human-in-the-Loop Memory Curation. Ruva grounds Personal AI in a Personal Knowledge Graph, enabling users to inspect what the AI knows and to perform precise redaction of specific facts. By shifting the paradigm from Vector Matching to Graph Reasoning, Ruva ensures the \"Right to be Forgotten.\" Users are the editors of their own lives; Ruva hands them the pen. The project and the demo video are available at http://sisinf00.poliba.it/ruva/.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15553v1",
        "authors": [
          "Gabriele Conte",
          "Alessio Mattiace",
          "Gianni Carmosino",
          "Potito Aghilar",
          "Giovanni Servedio"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Personalized Transparent On",
        "Personal Knowledge Graph",
        "Loop Memory Curation",
        "Augmented Generation",
        "Graph Reasoning",
        "Vector Matching",
        "Black Box",
        "Glass Box",
        "Standard",
        "RUVA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.396979"
    },
    {
      "id": "arxiv-2602.15552v1",
      "title": "Latent Regularization in Generative Test Input Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15552v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.",
        "keywords": [
          "cs.SE",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15552v1",
        "authors": [
          "Giorgi Merabishvili",
          "Oliver Weißl",
          "Andrea Stocco"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generative Test Input Generation",
        "Latent Regularization",
        "Deep Learning",
        "CIFAR-10",
        "MNIST",
        "CIFAR",
        "NIST",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.397142"
    },
    {
      "id": "arxiv-2602.15549v1",
      "title": "VLM-DEWM: Dynamic External World Model for Verifiable and Resilient Vision-Language Planning in Manufacturing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15549v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Vision-language model (VLM) shows promise for high-level planning in smart manufacturing, yet their deployment in dynamic workcells faces two critical challenges: (1) stateless operation, they cannot persistently track out-of-view states, causing world-state drift; and (2) opaque reasoning, failures are difficult to diagnose, leading to costly blind retries. This paper presents VLM-DEWM, a cognitive architecture that decouples VLM reasoning from world-state management through a persistent, queryable Dynamic External World Model (DEWM). Each VLM decision is structured into an Externalizable Reasoning Trace (ERT), comprising action proposal, world belief, and causal assumption, which is validated against DEWM before execution. When failures occur, discrepancy analysis between predicted and observed states enables targeted recovery instead of global replanning. We evaluate VLM-DEWM on multi-station assembly, large-scale facility exploration, and real-robot recovery under induced failures. Compared to baseline memory-augmented VLM systems, VLM DEWM improves state-tracking accuracy from 56% to 93%, increases recovery success rate from below 5% to 95%, and significantly reduces computational overhead through structured memory. These results establish VLM-DEWM as a verifiable and resilient solution for long-horizon robotic operations in dynamic manufacturing environments.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15549v1",
        "authors": [
          "Guoqin Tang",
          "Qingxuan Jia",
          "Gang Chen",
          "Tong Li",
          "Zeyuan Huang"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Externalizable Reasoning Trace",
        "Dynamic External World Model",
        "Manufacturing Vision",
        "Language Planning",
        "Resilient Vision",
        "Robot",
        "DEWM",
        "EPA",
        "VLM",
        "ERT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.397410"
    },
    {
      "id": "arxiv-2602.15547v1",
      "title": "jina-embeddings-v5-text: Task-Targeted Embedding Distillation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15547v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15547v1",
        "authors": [
          "Mohammad Kalim Akram",
          "Saba Sturua",
          "Nastia Havriushenko",
          "Quentin Herreros",
          "Michael Günther"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Targeted Embedding Distillation Text",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.397612"
    },
    {
      "id": "arxiv-2602.15546v1",
      "title": "CEPAE: Conditional Entropy-Penalized Autoencoders for Time Series Counterfactuals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15546v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The ability to accurately perform counterfactual inference on time series is crucial for decision-making in fields like finance, healthcare, and marketing, as it allows us to understand the impact of events or treatments on outcomes over time. In this paper, we introduce a new counterfactual inference approach tailored to time series data impacted by market events, which is motivated by an industrial application. Utilizing the abduction-action-prediction procedure and the Structural Causal Model framework, we first adapt methods based on variational autoencoders and adversarial autoencoders, both previously used in counterfactual literature although not in time series settings. Then, we present the Conditional Entropy-Penalized Autoencoder (CEPAE), a novel autoencoder-based approach for counterfactual inference, which employs an entropy penalization loss over the latent space to encourage disentangled data representations. We validate our approach both theoretically and experimentally on synthetic, semi-synthetic, and real-world datasets, showing that CEPAE generally outperforms the other approaches in the evaluated metrics.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15546v1",
        "authors": [
          "Tomàs Garriga",
          "Gerard Sanz",
          "Eduard Serrahima de Cambra",
          "Axel Brando"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structural Causal Model",
        "Penalized Autoencoders",
        "Penalized Autoencoder",
        "Conditional Entropy",
        "Framework",
        "CEPAE",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.397832"
    },
    {
      "id": "arxiv-2602.15540v1",
      "title": "Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15540v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15540v1",
        "authors": [
          "Tim Fischer",
          "Chris Biemann"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interactive Document Clustering",
        "Discourse Analysis Tool Suite",
        "Digital Humanities",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.398012"
    },
    {
      "id": "arxiv-2602.15539v1",
      "title": "Dynamic Training-Free Fusion of Subject and Style LoRAs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15539v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.SC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15539v1",
        "authors": [
          "Qinglong Cao",
          "Yuntian Chen",
          "Chao Ma",
          "Xiaokang Yang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.SC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Training",
        "Free Fusion",
        "Framework",
        "Fusion",
        "CLIP",
        "DINO",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.398262"
    },
    {
      "id": "arxiv-2602.15538v1",
      "title": "Functional Central Limit Theorem for Stochastic Gradient Descent",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15538v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the asymptotic shape of the trajectory of the stochastic gradient descent algorithm applied to a convex objective function. Under mild regularity assumptions, we prove a functional central limit theorem for the properly rescaled trajectory. Our result characterizes the long-term fluctuations of the algorithm around the minimizer by providing a diffusion limit for the trajectory. In contrast with classical central limit theorems for the last iterate or Polyak-Ruppert averages, this functional result captures the temporal structure of the fluctuations and applies to non-smooth settings such as robust location estimation, including the geometric median.",
        "keywords": [
          "stat.ML",
          "cs.LG",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15538v1",
        "authors": [
          "Kessang Flamand",
          "Victor-Emmanuel Brunel"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stochastic Gradient Descent We",
        "Fusion",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.398408"
    },
    {
      "id": "arxiv-2602.15537v1",
      "title": "ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15537v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.",
        "keywords": [
          "cs.CL",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15537v1",
        "authors": [
          "Nicol Visser",
          "Simon Malan",
          "Danel Slabbert",
          "Herman Kamper"
        ],
        "arxiv_categories": [
          "cs.CL",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Resource Syllable Tokenization",
        "Spoken Language Modeling Pure",
        "Simple Zero",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.398614"
    },
    {
      "id": "arxiv-2602.15535v1",
      "title": "Advanced Acceptance Score: A Holistic Measure for Biometric Quantification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15535v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantifying biometric characteristics within hand gestures involve derivation of fitness scores from a gesture and identity aware feature space. However, evaluating the quality of these scores remains an open question. Existing biometric capacity estimation literature relies upon error rates. But these rates do not indicate goodness of scores. Thus, in this manuscript we present an exhaustive set of evaluation measures. We firstly identify ranking order and relevance of output scores as the primary basis for evaluation. In particular, we consider both rank deviation as well as rewards for: (i) higher scores of high ranked gestures and (ii) lower scores of low ranked gestures. We also compensate for correspondence between trends of output and ground truth scores. Finally, we account for disentanglement between identity features of gestures as a discounting factor. Integrating these elements with adequate weighting, we formulate advanced acceptance score as a holistic evaluation measure. To assess effectivity of the proposed we perform in-depth experimentation over three datasets with five state-of-the-art (SOTA) models. Results show that the optimal score selected with our measure is more appropriate than existing other measures. Also, our proposed measure depicts correlation with existing measures. This further validates its reliability. We have made our \\href{https://github.com/AmanVerma2307/MeasureSuite}{code} public.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15535v1",
        "authors": [
          "Aman Verma",
          "Seshan Srirangarajan",
          "Sumantra Dutta Roy"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Biometric Quantification Quantifying",
        "Advanced Acceptance Score",
        "Holistic Measure",
        "SOTA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.398877"
    },
    {
      "id": "arxiv-2602.15532v1",
      "title": "Quantifying construct validity in large language model evaluations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15532v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The LLM community often reports benchmark results as if they are synonymous with general model capabilities. However, benchmarks can have problems that distort performance, like test set contamination and annotator error. How can we know that a benchmark is a reliable indicator of some capability that we want to measure? This question concerns the construct validity of LLM benchmarks, and it requires separating benchmark results from capabilities when we model and predict LLM performance. Both social scientists and computer scientists propose formal models - latent factor models and scaling laws - for identifying the capabilities underlying benchmark scores. However, neither technique is satisfactory for construct validity. Latent factor models ignore scaling laws, and as a result, the capabilities they extract often proxy model size. Scaling laws ignore measurement error, and as a result, the capabilities they extract are both uninterpretable and overfit to the observed benchmarks. This thesis presents the structured capabilities model, the first model to extract interpretable and generalisable capabilities from a large collection of LLM benchmark results. I fit this model and its two alternatives on a large sample of results from the OpenLLM Leaderboard. Structured capabilities outperform latent factor models on parsimonious fit indices, and exhibit better out-of-distribution benchmark prediction than scaling laws. These improvements are possible because neither existing approach separates model scale from capabilities in the appropriate way. Model scale should inform capabilities, as in scaling laws, and these capabilities should inform observed results up to measurement error, as in latent factor models. In combining these two insights, structured capabilities demonstrate better explanatory and predictive power for quantifying construct validity in LLM evaluations.",
        "keywords": [
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15532v1",
        "authors": [
          "Ryan Othniel Kearns"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "LLM",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:52.399204"
    },
    {
      "id": "arxiv-2602.15813v1",
      "title": "FAST-EQA: Efficient Embodied Question Answering with Global and Local Region Relevancy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15813v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Embodied Question Answering (EQA) combines visual scene understanding, goal-directed exploration, spatial and temporal reasoning under partial observability. A central challenge is to confine physical search to question-relevant subspaces while maintaining a compact, actionable memory of observations. Furthermore, for real-world deployment, fast inference time during exploration is crucial. We introduce FAST-EQA, a question-conditioned framework that (i) identifies likely visual targets, (ii) scores global regions of interest to guide navigation, and (iii) employs Chain-of-Thought (CoT) reasoning over visual memory to answer confidently. FAST-EQA maintains a bounded scene memory that stores a fixed-capacity set of region-target hypotheses and updates them online, enabling robust handling of both single and multi-target questions without unbounded growth. To expand coverage efficiently, a global exploration policy treats narrow openings and doors as high-value frontiers, complementing local target seeking with minimal computation. Together, these components focus the agent's attention, improve scene coverage, and improve answer reliability while running substantially faster than prior approaches. On HMEQA and EXPRESS-Bench, FAST-EQA achieves state-of-the-art performance, while performing competitively on OpenEQA and MT-HM3D.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15813v1",
        "authors": [
          "Haochen Zhang",
          "Nirav Savaliya",
          "Faizan Siddiqui",
          "Enna Sachdeva"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Embodied Question Answering",
        "Local Region Relevancy Embodied",
        "Question Answering",
        "Framework",
        "Policy",
        "HMEQA",
        "FAST",
        "EQA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.991400"
    },
    {
      "id": "arxiv-2602.15794v1",
      "title": "Service Orchestration in the Computing Continuum: Structural Challenges and Vision",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15794v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Computing Continuum (CC) integrates different layers of processing infrastructure, from Edge to Cloud, to optimize service quality through ubiquitous and reliable computation. Compared to central architectures, however, heterogeneous and dynamic infrastructure increases the complexity for service orchestration. To guide research, this article first summarizes structural problems of the CC, and then, envisions an ideal solution for autonomous service orchestration across the CC. As one instantiation, we show how Active Inference, a concept from neuroscience, can support self-organizing services in continuously interpreting their environment to optimize service quality. Still, we conclude that no existing solution achieves our vision, but that research on service orchestration faces several structural challenges. Most notably: provide standardized simulation and evaluation environments for comparing the performance of orchestration mechanisms. Together, the challenges outline a research roadmap toward resilient and scalable service orchestration in the CC.",
        "keywords": [
          "cs.DC",
          "cs.ET",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15794v1",
        "authors": [
          "Boris Sedlak",
          "Víctor Casamayor Pujol",
          "Ildefons Magrans de Abril",
          "Praveen Kumar Donta",
          "Adel N. Toosi"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.ET",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Service Orchestration",
        "Structural Challenges",
        "Computing Continuum",
        "Active Inference",
        "Standard",
        "Act",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.991682"
    },
    {
      "id": "arxiv-2602.15762v1",
      "title": "PRISM: Photonics-Informed Inverse Lithography for Manufacturable Inverse-Designed Photonic Integrated Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15762v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent advances in photonic inverse design have demonstrated the ability to automatically synthesize compact, high-performance photonic components that surpass conventional, hand-designed structures, offering a promising path toward scalable and functionality-rich photonic hardware. However, the practical deployment of inverse-designed PICs is bottlenecked by manufacturability: their irregular, subwavelength geometries are highly sensitive to fabrication variations, leading to large performance degradation, low yield, and a persistent gap between simulated optimality and fabricated performance. Unlike electronics, photonics lacks a systematic, flexible mask optimization flow. Fabrication deviations in photonic components cause large optical response drift and compounding error in cascaded circuits, while calibrating fabrication models remains costly and expertise-heavy, often requiring repeated fabrication cycles that are inaccessible to most designers. To bridge this gap, we introduce PRISM, a photonics-informed inverse lithography workflow that makes photonic mask optimization data-efficient, reliable, and optics-informed. PRISM (i) synthesizes compact, informative calibration patterns to minimize required fabrication data, (ii) trains a physics-grounded differentiable fabrication model, enabling gradient-based optimization, and (iii) performs photonics-informed inverse mask optimization that prioritizes performance-critical features beyond geometry matching. Across multiple inverse-designed components with both electron-beam lithography and deep ultra-violet photolithography processes, PRISM significantly boosts post-fabrication performance and yield while reducing calibration area and turnaround time, enabling and democratizing manufacturable and high-yield inverse-designed photonic hardware at scale.",
        "keywords": [
          "physics.optics",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15762v1",
        "authors": [
          "Hongjian Zhou",
          "Haoyu Yang",
          "Nicholas Gangi",
          "Tianle Xu",
          "Rena Huang"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Designed Photonic Integrated Circuits",
        "Informed Inverse Lithography",
        "Manufacturable Inverse",
        "PRISM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.992236"
    },
    {
      "id": "arxiv-2602.15642v1",
      "title": "Spatially-Aware Adaptive Trajectory Optimization with Controller-Guided Feedback for Autonomous Racing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15642v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a closed-loop framework for autonomous raceline optimization that combines NURBS-based trajectory representation, CMA-ES global trajectory optimization, and controller-guided spatial feedback. Instead of treating tracking errors as transient disturbances, our method exploits them as informative signals of local track characteristics via a Kalman-inspired spatial update. This enables the construction of an adaptive, acceleration-based constraint map that iteratively refines trajectories toward near-optimal performance under spatially varying track and vehicle behavior. In simulation, our approach achieves a 17.38% lap time reduction compared to a controller parametrized with maximum static acceleration. On real hardware, tested with different tire compounds ranging from high to low friction, we obtain a 7.60% lap time improvement without explicitly parametrizing friction. This demonstrates robustness to changing grip conditions in real-world scenarios.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15642v1",
        "authors": [
          "Alexander Wachter",
          "Alexander Willert",
          "Marc-Philip Ecker",
          "Christian Hartl-Nesic"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Adaptive Trajectory Optimization",
        "Autonomous Racing We",
        "Guided Feedback",
        "Framework",
        "NURBS",
        "CMA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.992984"
    },
    {
      "id": "arxiv-2602.15633v1",
      "title": "SpecFuse: A Spectral-Temporal Fusion Predictive Control Framework for UAV Landing on Oscillating Marine Platforms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15633v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Autonomous landing of Uncrewed Aerial Vehicles (UAVs) on oscillating marine platforms is severely constrained by wave-induced multi-frequency oscillations, wind disturbances, and prediction phase lags in motion prediction. Existing methods either treat platform motion as a general random process or lack explicit modeling of wave spectral characteristics, leading to suboptimal performance under dynamic sea conditions. To address these limitations, we propose SpecFuse: a novel spectral-temporal fusion predictive control framework that integrates frequency-domain wave decomposition with time-domain recursive state estimation for high-precision 6-DoF motion forecasting of Uncrewed Surface Vehicles (USVs). The framework explicitly models dominant wave harmonics to mitigate phase lags, refining predictions in real time via IMU data without relying on complex calibration. Additionally, we design a hierarchical control architecture featuring a sampling-based HPO-RRT* algorithm for dynamic trajectory planning under non-convex constraints and a learning-augmented predictive controller that fuses data-driven disturbance compensation with optimization-based execution. Extensive validations (2,000 simulations + 8 lake experiments) show our approach achieves a 3.2 cm prediction error, 4.46 cm landing deviation, 98.7% / 87.5% success rates (simulation / real-world), and 82 ms latency on embedded hardware, outperforming state-of-the-art methods by 44%-48% in accuracy. Its robustness to wave-wind coupling disturbances supports critical maritime missions such as search and rescue and environmental monitoring. All code, experimental configurations, and datasets will be released as open-source to facilitate reproducibility.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15633v1",
        "authors": [
          "Haichao Liu",
          "Yufeng Hu",
          "Shuang Wang",
          "Kangjun Guo",
          "Jun Ma"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oscillating Marine Platforms Autonomous",
        "Temporal Fusion Predictive Control",
        "Uncrewed Surface Vehicles",
        "Uncrewed Aerial Vehicles",
        "Framework",
        "Fusion",
        "Wind",
        "RRT",
        "MIT",
        "IMU",
        "Act",
        "HPO",
        "UAV",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.993627"
    },
    {
      "id": "arxiv-2602.15608v1",
      "title": "Grip as Needed, Glide on Demand: Ultrasonic Lubrication for Robotic Locomotion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15608v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Friction is the essential mediator of terrestrial locomotion, yet in robotic systems it is almost always treated as a passive property fixed by surface materials and conditions. Here, we introduce ultrasonic lubrication as a method to actively control friction in robotic locomotion. By exciting resonant structures at ultrasonic frequencies, contact interfaces can dynamically switch between \"grip\" and \"slip\" states, enabling locomotion. We developed two friction control modules, a cylindrical design for lumen-like environments and a flat-plate design for external surfaces, and integrated them into bio-inspired systems modeled after inchworm and wasp ovipositor locomotion. Both systems achieved bidirectional locomotion with nearly perfect locomotion efficiencies that exceeded 90%. Friction characterization experiments further demonstrated substantial friction reduction across various surfaces, including rigid, soft, granular, and biological tissue interfaces, under dry and wet conditions, and on surfaces with different levels of roughness, confirming the broad applicability of ultrasonic lubrication to locomotion tasks. These findings establish ultrasonic lubrication as a viable active friction control mechanism for robotic locomotion, with the potential to reduce design complexity and improve efficiency of robotic locomotion systems.",
        "keywords": [
          "cs.RO",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15608v1",
        "authors": [
          "Mostafa A. Atalla",
          "Daan van Bemmel",
          "Jack Cummings",
          "Paul Breedveld",
          "Michaël Wiertlewski"
        ],
        "arxiv_categories": [
          "cs.RO",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robotic Locomotion Friction",
        "Ultrasonic Lubrication",
        "Robot",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.994202"
    },
    {
      "id": "arxiv-2602.15567v1",
      "title": "Constraining Streaming Flow Models for Adapting Learned Robot Trajectory Distributions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15567v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Robot motion distributions often exhibit multi-modality and require flexible generative models for accurate representation. Streaming Flow Policies (SFPs) have recently emerged as a powerful paradigm for generating robot trajectories by integrating learned velocity fields directly in action space, enabling smooth and reactive control. However, existing formulations lack mechanisms for adapting trajectories post-training to enforce safety and task-specific constraints. We propose Constraint-Aware Streaming Flow (CASF), a framework that augments streaming flow policies with constraint-dependent metrics that reshape the learned velocity field during execution. CASF models each constraint, defined in either the robot's workspace or configuration space, as a differentiable distance function that is converted into a local metric and pulled back into the robot's control space. Far from restricted regions, the resulting metric reduces to the identity; near constraint boundaries, it smoothly attenuates or redirects motion, effectively deforming the underlying flow to maintain safety. This allows trajectories to be adapted in real time, ensuring that robot actions respect joint limits, avoid collisions, and remain within feasible workspaces, while preserving the multi-modal and reactive properties of streaming flow policies. We demonstrate CASF in simulated and real-world manipulation tasks, showing that it produces constraint-satisfying trajectories that remain smooth, feasible, and dynamically consistent, outperforming standard post-hoc projection baselines.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15567v1",
        "authors": [
          "Jieting Long",
          "Dechuan Liu",
          "Weidong Cai",
          "Ian Manchester",
          "Weiming Zhi"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constraining Streaming Flow Models",
        "Adapting Learned Robot Trajectory",
        "Streaming Flow Policies",
        "Aware Streaming Flow",
        "Distributions Robot",
        "Framework",
        "Standard",
        "Robot",
        "CASF",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.994793"
    },
    {
      "id": "arxiv-2602.15543v1",
      "title": "Selective Perception for Robot: Task-Aware Attention in Multimodal VLA",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15543v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In robotics, Vision-Language-Action (VLA) models that integrate diverse multimodal signals from multi-view inputs have emerged as an effective approach. However, most prior work adopts static fusion that processes all visual inputs uniformly, which incurs unnecessary computational overhead and allows task-irrelevant background information to act as noise. Inspired by the principles of human active perception, we propose a dynamic information fusion framework designed to maximize the efficiency and robustness of VLA models. Our approach introduces a lightweight adaptive routing architecture that analyzes the current text prompt and observations from a wrist-mounted camera in real-time to predict the task-relevance of multiple camera views. By conditionally attenuating computations for views with low informational utility and selectively providing only essential visual features to the policy network, Our framework achieves computation efficiency proportional to task relevance. Furthermore, to efficiently secure large-scale annotation data for router training, we established an automated labeling pipeline utilizing Vision-Language Models (VLMs) to minimize data collection and annotation costs. Experimental results in real-world robotic manipulation scenarios demonstrate that the proposed approach achieves significant improvements in both inference efficiency and control performance compared to existing VLA models, validating the effectiveness and practicality of dynamic information fusion in resource-constrained, real-time robot control environments.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15543v1",
        "authors": [
          "Young-Chae Son",
          "Jung-Woo Lee",
          "Yoon-Ji Choi",
          "Dae-Kwan Ko",
          "Soo-Chul Lim"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Selective Perception",
        "Aware Attention",
        "Language Models",
        "Framework",
        "Fusion",
        "Policy",
        "Robot",
        "VLA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.995270"
    },
    {
      "id": "arxiv-2602.15533v1",
      "title": "Efficient Knowledge Transfer for Jump-Starting Control Policy Learning of Multirotors through Physics-Aware Neural Architectures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15533v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Efficiently training control policies for robots is a major challenge that can greatly benefit from utilizing knowledge gained from training similar systems through cross-embodiment knowledge transfer. In this work, we focus on accelerating policy training using a library-based initialization scheme that enables effective knowledge transfer across multirotor configurations. By leveraging a physics-aware neural control architecture that combines a reinforcement learning-based controller and a supervised control allocation network, we enable the reuse of previously trained policies. To this end, we utilize a policy evaluation-based similarity measure that identifies suitable policies for initialization from a library. We demonstrate that this measure correlates with the reduction in environment interactions needed to reach target performance and is therefore suited for initialization. Extensive simulation and real-world experiments confirm that our control architecture achieves state-of-the-art control performance, and that our initialization scheme saves on average up to $73.5\\%$ of environment interactions (compared to training a policy from scratch) across diverse quadrotor and hexarotor designs, paving the way for efficient cross-embodiment transfer in reinforcement learning.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15533v1",
        "authors": [
          "Welf Rehberg",
          "Mihir Kulkarni",
          "Philipp Weiss",
          "Kostas Alexis"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Neural Architectures Efficiently",
        "Starting Control Policy Learning",
        "Efficient Knowledge Transfer",
        "Policy",
        "Robot",
        "NSF",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.995566"
    },
    {
      "id": "arxiv-2602.15529v1",
      "title": "Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15529v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present new distributed quantum algorithms for fundamental distributed computing problems, namely, leader election, broadcast, Minimum Spanning Tree (MST), and Breadth-First Search (BFS) tree, in arbitrary networks. These algorithms are (essentially) optimal with respect to their communication (message) complexity in the {\\em quantum routing model} introduced in [PODC 2025]. The message complexity of our algorithms is $\\tilde{O}(n)$ for leader election, broadcast, and MST, and $\\tilde{O}(\\sqrt{mn})$ for BFS ($n$ and $m$ are the number of nodes and edges of the network, respectively). These message bounds are nearly tight in the quantum routing model since we show almost matching corresponding quantum message lower bounds. Our results significantly improve on the prior work of [PODC 2025], who presented distributed quantum algorithms under the same model that had a message complexity of $\\tilde{O}(\\sqrt{mn})$ for leader election. Our algorithms demonstrate the significant communication advantage that quantum routing has over classical in distributed computing, since $Ω(m)$ is a well-established classical message lower bound for leader election, broadcast, MST, and BFS that applies even to randomized Monte-Carlo algorithms [JACM 2015]. Thus, our quantum algorithms can, in general, give a quadratic advantage in the communication cost for these fundamental problems. A main technical tool we use to design our distributed algorithms is quantum walks based on electric networks. We posit a framework for using quantum walks in the distributed setting to design communication-efficient distributed quantum algorithms. Our framework can be used as a black box to significantly reduce communication costs and may be of independent interest. Additionally, our lower-bound technique for establishing distributed quantum message lower bounds can also be applied to other problems.",
        "keywords": [
          "quant-ph",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15529v1",
        "authors": [
          "Fabien Dufoulon",
          "Frédéric Magniez",
          "Gopal Pandurangan"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tight Communication Bounds",
        "Quantum Routing Model We",
        "Distributed Algorithms",
        "Minimum Spanning Tree",
        "First Search",
        "Framework",
        "PODC",
        "JACM",
        "BFS",
        "WHO",
        "MST",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.996744"
    },
    {
      "id": "arxiv-2602.15513v1",
      "title": "Improving MLLMs in Embodied Exploration and Question Answering with Human-Inspired Memory Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15513v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Deploying Multimodal Large Language Models as the brain of embodied agents remains challenging, particularly under long-horizon observations and limited context budgets. Existing memory assisted methods often rely on textual summaries, which discard rich visual and spatial details and remain brittle in non-stationary environments. In this work, we propose a non-parametric memory framework that explicitly disentangles episodic and semantic memory for embodied exploration and question answering. Our retrieval-first, reasoning-assisted paradigm recalls episodic experiences via semantic similarity and verifies them through visual reasoning, enabling robust reuse of past observations without rigid geometric alignment. In parallel, we introduce a program-style rule extraction mechanism that converts experiences into structured, reusable semantic memory, facilitating cross-environment generalization. Extensive experiments demonstrate state-of-the-art performance on embodied question answering and exploration benchmarks, yielding a 7.3% gain in LLM-Match and an 11.4% gain in LLM MatchXSPL on A-EQA, as well as +7.7% success rate and +6.8% SPL on GOAT-Bench. Analyses reveal that our episodic memory primarily improves exploration efficiency, while semantic memory strengthens complex reasoning of embodied agents.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15513v1",
        "authors": [
          "Ji Li",
          "Jing Xia",
          "Mingyi Li",
          "Shiyan Hu"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inspired Memory Modeling Deploying",
        "Multimodal Large Language Models",
        "Embodied Exploration",
        "Question Answering",
        "Framework",
        "GOAT",
        "EQA",
        "MIT",
        "SPL",
        "LLM",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.997135"
    },
    {
      "id": "arxiv-2602.15510v1",
      "title": "On the Geometric Coherence of Global Aggregation in Federated GNN",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15510v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Federated Learning (FL) enables distributed training across multiple clients without centralized data sharing, while Graph Neural Networks (GNNs) model relational data through message passing. In federated GNN settings, client graphs often exhibit heterogeneous structural and propagation characteristics. When standard aggregation mechanisms are applied to such heterogeneous updates, the global model may converge numerically while exhibiting degraded relational behavior.Our work identifies a geometric failure mode of global aggregation in Cross- Domain Federated GNNs. Although GNN parameters are numerically represented as vectors, they encode relational transformations that govern the direction, strength, and sensitivity of information flow across graph neighborhoods. Aggregating updates originating from incompatible propagation regimes can therefore introduce destructive interference in this transformation space.This leads to loss of coherence in global message passing. Importantly, this degradation is not necessarily reflected in conventional metrics such as loss or accuracy.To address this issue, we propose GGRS (Global Geometric Reference Structure), a server-side framework that regulates client updates prior to aggregation based on geometric admissibility criteria. GGRS preserves directional consistency of relational transformations as well as maintains diversity of admissible propagation subspaces. It also stabilizes sensitivity to neighborhood interactions, without accessing client data or graph topology. Experiments on heterogeneous GNN-native, Amazon Co-purchase datasets demonstrate that GGRS preserves global message-passing coherence across training rounds by highlighting the necessity of geometry-aware regulation in federated graph learning.",
        "keywords": [
          "cs.LG",
          "cs.DC",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15510v1",
        "authors": [
          "Chethana Prasad Kabgere",
          "Shylaja SS"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.DC",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Global Geometric Reference Structure",
        "Graph Neural Networks",
        "Geometric Coherence",
        "Federated Learning",
        "Global Aggregation",
        "Domain Federated",
        "Neural Network",
        "Regulation",
        "Framework",
        "Amazon Co",
        "Standard",
        "Amazon",
        "GGRS",
        "NSF",
        "GNN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.997678"
    },
    {
      "id": "arxiv-2602.15477v1",
      "title": "Quantum Computing for Healthcare Digital Twin Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15477v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications.",
        "keywords": [
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15477v1",
        "authors": [
          "Asma Taheri Monfared",
          "Andrea Bombarda",
          "Angelo Gargantini",
          "Majid Haghparast"
        ],
        "arxiv_categories": [
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Healthcare Digital Twin Systems",
        "Quantum Digital Twins",
        "Quantum Computing",
        "Digital Twins",
        "Framework",
        "Intel",
        "QDT",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.998086"
    },
    {
      "id": "arxiv-2602.15424v1",
      "title": "Lyapunov-Based $\\mathcal{L}_2$-Stable PI-Like Control of a Four-Wheel Independently Driven and Steered Robot",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15424v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this letter, Lyapunov-based synthesis of a PI-like controller is proposed for $\\mathcal{L}_2$-stable motion control of an independently driven and steered four-wheel mobile robot. An explicit, structurally verified model is used to enable systematic controller design with stability and performance guarantees suitable for real-time operation. A Lyapunov function is constructed to yield explicit bounds and $\\mathcal{L}_2$ stability results, supporting feedback synthesis that reduces configuration dependent effects. The resulting control law maintains a PI-like form suitable for standard embedded implementation while preserving rigorous stability properties. Effectiveness and robustness are demonstrated experimentally on a real four-wheel mobile robot platform.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15424v1",
        "authors": [
          "Branimir Ćaran",
          "Vladimir Milić",
          "Bojan Jerbić"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wheel Independently Driven",
        "Steered Robot In",
        "Like Control",
        "Standard",
        "Robot",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.998378"
    },
    {
      "id": "arxiv-2602.15400v1",
      "title": "One Agent to Guide Them All: Empowering MLLMs for Vision-and-Language Navigation via Explicit World Representation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15400v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A navigable agent needs to understand both high-level semantic instructions and precise spatial perceptions. Building navigation agents centered on Multimodal Large Language Models (MLLMs) demonstrates a promising solution due to their powerful generalization ability. However, the current tightly coupled design dramatically limits system performance. In this work, we propose a decoupled design that separates low-level spatial state estimation from high-level semantic planning. Unlike previous methods that rely on predefined, oversimplified textual maps, we introduce an interactive metric world representation that maintains rich and consistent information, allowing MLLMs to interact with and reason on it for decision-making. Furthermore, counterfactual reasoning is introduced to further elicit MLLMs' capacity, while the metric world representation ensures the physical validity of the produced actions. We conduct comprehensive experiments in both simulated and real-world environments. Our method establishes a new zero-shot state-of-the-art, achieving 48.8\\% Success Rate (SR) in R2R-CE and 42.2\\% in RxR-CE benchmarks. Furthermore, to validate the versatility of our metric representation, we demonstrate zero-shot sim-to-real transfer across diverse embodiments, including a wheeled TurtleBot 4 and a custom-built aerial drone. These real-world deployments verify that our decoupled framework serves as a robust, domain-invariant interface for embodied Vision-and-Language navigation.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15400v1",
        "authors": [
          "Zerui Li",
          "Hongpei Zheng",
          "Fangguo Zhao",
          "Aidan Chan",
          "Jian Zhou"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Large Language Models",
        "Explicit World Representation",
        "Language Navigation",
        "Success Rate",
        "One Agent",
        "Framework",
        "Drone",
        "EPA",
        "NSF",
        "MIT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.998787"
    },
    {
      "id": "arxiv-2602.15398v1",
      "title": "Hybrid F' and ROS2 Architecture for Vision-Based Autonomous Flight: Design and Experimental Validation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15398v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Autonomous aerospace systems require architectures that balance deterministic real-time control with advanced perception capabilities. This paper presents an integrated system combining NASA's F' flight software framework with ROS2 middleware via Protocol Buffers bridging. We evaluate the architecture through a 32.25-minute indoor quadrotor flight test using vision-based navigation. The vision system achieved 87.19 Hz position estimation with 99.90\\% data continuity and 11.47 ms mean latency, validating real-time performance requirements. All 15 ground commands executed successfully with 100 % success rate, demonstrating robust F'--PX4 integration. System resource utilization remained low (15.19 % CPU, 1,244 MB RAM) with zero stale telemetry messages, confirming efficient operation on embedded platforms. Results validate the feasibility of hybrid flight-software architectures combining certification-grade determinism with flexible autonomy for autonomous aerial vehicles.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15398v1",
        "authors": [
          "Abdelrahman Metwally",
          "Monijesu James",
          "Aleksey Fedoseev",
          "Miguel Altamirano Cabrera",
          "Dzmitry Tsetserukou"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Experimental Validation Autonomous",
        "Based Autonomous Flight",
        "Protocol Buffers",
        "Framework",
        "Protocol",
        "NASA",
        "NIST",
        "RAM",
        "CPU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.999026"
    },
    {
      "id": "arxiv-2602.15397v1",
      "title": "ActionCodec: What Makes for Good Action Tokenizers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15397v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Vision-Language-Action (VLA) models leveraging the native autoregressive paradigm of Vision-Language Models (VLMs) have demonstrated superior instruction-following and training efficiency. Central to this paradigm is action tokenization, yet its design has primarily focused on reconstruction fidelity, failing to address its direct impact on VLA optimization. Consequently, the fundamental question of \\textit{what makes for good action tokenizers} remains unanswered. In this paper, we bridge this gap by establishing design principles specifically from the perspective of VLA optimization. We identify a set of best practices based on information-theoretic insights, including maximized temporal token overlap, minimized vocabulary redundancy, enhanced multimodal mutual information, and token independence. Guided by these principles, we introduce \\textbf{ActionCodec}, a high-performance action tokenizer that significantly enhances both training efficiency and VLA performance across diverse simulation and real-world benchmarks. Notably, on LIBERO, a SmolVLM2-2.2B fine-tuned with ActionCodec achieves a 95.5\\% success rate without any robotics pre-training. With advanced architectural enhancements, this reaches 97.4\\%, representing a new SOTA for VLA models without robotics pre-training. We believe our established design principles, alongside the released model, will provide a clear roadmap for the community to develop more effective action tokenizers.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15397v1",
        "authors": [
          "Zibin Dong",
          "Yicheng Liu",
          "Shiduo Zhang",
          "Baijun Ye",
          "Yifu Yuan"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Good Action Tokenizers Vision",
        "Language Models",
        "SmolVLM2-2",
        "What Makes",
        "LIBERO",
        "Robot",
        "SOTA",
        "VLA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.999378"
    },
    {
      "id": "arxiv-2602.15388v1",
      "title": "Iterative LLM-Based Assertion Generation Using Syntax-Semantic Representations for Functional Coverage-Guided Verification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15388v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "While leveraging LLMs to automatically generate SystemVerilog assertions (SVAs) from natural language specifications holds great potential, existing techniques face a key challenge: LLMs often lack sufficient understanding of IC design, leading to poor assertion quality in a single pass. Therefore, verifying whether the generated assertions effectively cover the functional specifications and designing feedback mechanisms based on this coverage remain significant hurdles. To address these limitations, this paper introduces CoverAssert, a novel iterative framework for optimizing SVA generation with LLMs. The core contribution is a lightweight mechanism for matching generated assertions with specific functional descriptions in the specifications. CoverAssert achieves this by clustering the joint representations of semantic features of LLM-generated assertions and structural features extracted from abstract syntax trees (ASTs) about signals related to assertions, and then mapping them back to the specifications to analyze functional coverage quality. Leveraging this capability, CoverAssert constructs a feedback loop based on functional coverage to guide LLMs in prioritizing uncovered functional points, thereby iteratively improving assertion quality. Experimental evaluations on four open-source designs demonstrate that integrating CoverAssert with state-of-the-art generators, AssertLLM and Spec2Assertion, achieves average improvements of 9.57 % in branch coverage, 9.64 % in statement coverage, and 15.69 % in toggle coverage.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15388v1",
        "authors": [
          "Yonghao Wang",
          "Jiaxin Zhou",
          "Yang Yin",
          "Hongqin Lyu",
          "Zhiteng Chao"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Assertion Generation Using",
        "Guided Verification While",
        "Semantic Representations",
        "Functional Coverage",
        "Framework",
        "SVA",
        "MIT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:57.999731"
    },
    {
      "id": "arxiv-2602.15379v1",
      "title": "FlashMem: Supporting Modern DNN Workloads on Mobile with GPU Memory Hierarchy Optimizations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15379v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The increasing size and complexity of modern deep neural networks (DNNs) pose significant challenges for on-device inference on mobile GPUs, with limited memory and computational resources. Existing DNN acceleration frameworks primarily deploy a weight preloading strategy, where all model parameters are loaded into memory before execution on mobile GPUs. We posit that this approach is not adequate for modern DNN workloads that comprise very large model(s) and possibly execution of several distinct models in succession. In this work, we introduce FlashMem, a memory streaming framework designed to efficiently execute large-scale modern DNNs and multi-DNN workloads while minimizing memory consumption and reducing inference latency. Instead of fully preloading weights, FlashMem statically determines model loading schedules and dynamically streams them on demand, leveraging 2.5D texture memory to minimize data transformations and improve execution efficiency. Experimental results on 11 models demonstrate that FlashMem achieves 2.0x to 8.4x memory reduction and 1.7x to 75.0x speedup compared to existing frameworks, enabling efficient execution of large-scale models and multi-DNN support on resource-constrained mobile GPUs.",
        "keywords": [
          "cs.DC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15379v1",
        "authors": [
          "Zhihao Shu",
          "Md Musfiqur Rahman Sanim",
          "Hangyu Zheng",
          "Kunxiong Zhu",
          "Miao Yin"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Supporting Modern",
        "Neural Network",
        "Framework",
        "DNN",
        "GPU",
        "NSF",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.000117"
    },
    {
      "id": "arxiv-2602.15357v1",
      "title": "Fluoroscopy-Constrained Magnetic Robot Control via Zernike-Based Field Modeling and Nonlinear MPC",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15357v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Magnetic actuation enables surgical robots to navigate complex anatomical pathways while reducing tissue trauma and improving surgical precision. However, clinical deployment is limited by the challenges of controlling such systems under fluoroscopic imaging, which provides low frame rate and noisy pose feedback. This paper presents a control framework that remains accurate and stable under such conditions by combining a nonlinear model predictive control (NMPC) framework that directly outputs coil currents, an analytically differentiable magnetic field model based on Zernike polynomials, and a Kalman filter to estimate the robot state. Experimental validation is conducted with two magnetic robots in a 3D-printed fluid workspace and a spine phantom replicating drug delivery in the epidural space. Results show the proposed control method remains highly accurate when feedback is downsampled to 3 Hz with added Gaussian noise (sigma = 2 mm), mimicking clinical fluoroscopy. In the spine phantom experiments, the proposed method successfully executed a drug delivery trajectory with a root mean square (RMS) position error of 1.18 mm while maintaining safe clearance from critical anatomical boundaries.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15357v1",
        "authors": [
          "Xinhao Chen",
          "Hongkun Yao",
          "Anuruddha Bhattacharjee",
          "Suraj Raval",
          "Lamar O. Mair"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constrained Magnetic Robot Control",
        "Based Field Modeling",
        "Framework",
        "Robot",
        "NMPC",
        "MPC",
        "MIT",
        "RMS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.000520"
    },
    {
      "id": "arxiv-2602.15356v1",
      "title": "Co-Design and Evaluation of a CPU-Free MPI GPU Communication Abstraction and Implementation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15356v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Removing the CPU from the communication fast path is essential to efficient GPU-based ML and HPC application performance. However, existing GPU communication APIs either continue to rely on the CPU for communication or rely on APIs that place significant synchronization burdens on programmers. In this paper we describe the design, implementation, and evaluation of an MPI-based GPU communication API enabling easy-to-use, high-performance, CPU-free communication. This API builds on previously proposed MPI extensions and leverages HPE Slingshot 11 network card capabilities. We demonstrate the utility and performance of the API by showing how the API naturally enables CPU-free gather/scatter halo exchange communication primitives in the Cabana/Kokkos performance portability framework, and through a performance comparison with Cray MPICH on the Frontier and Tuolumne supercomputers. Results from this evaluation show up to a 50% reduction in medium message latency in simple GPU ping-pong exchanges and a 28% speedup improvement when strong scaling a halo-exchange benchmark to 8,192 GPUs of the Frontier supercomputer.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15356v1",
        "authors": [
          "Patrick G. Bridges",
          "Derek Schafer",
          "Jack Lange",
          "James B. White",
          "Anthony Skjellum"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Communication Abstraction",
        "Implementation Removing",
        "Framework",
        "MPICH",
        "GPU",
        "HPC",
        "MIT",
        "API",
        "MPI",
        "CPU",
        "HPE",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.000914"
    },
    {
      "id": "arxiv-2602.15354v1",
      "title": "A Comparison of Bayesian Prediction Techniques for Mobile Robot Trajectory Tracking",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15354v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper presents a performance comparison of different estimation and prediction techniques applied to the problem of tracking multiple robots. The main performance criteria are the magnitude of the estimation or prediction error, the computational effort and the robustness of each method to non-Gaussian noise. Among the different techniques compared are the well known Kalman filters and their different variants (e.g. extended and unscented), and the more recent techniques relying on Sequential Monte Carlo Sampling methods, such as particle filters and Gaussian Mixture Sigma Point Particle Filter.",
        "keywords": [
          "cs.RO",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15354v1",
        "authors": [
          "Jose Luis Peralta-Cabezas",
          "Miguel Torres-Torriti",
          "Marcelo Guarini-Hermann"
        ],
        "arxiv_categories": [
          "cs.RO",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mobile Robot Trajectory Tracking",
        "Sequential Monte Carlo Sampling",
        "Bayesian Prediction Techniques",
        "Gaussian Mixture Sigma Point",
        "Particle Filter",
        "Robot",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.001125"
    },
    {
      "id": "arxiv-2602.15351v1",
      "title": "Feasibility-aware Imitation Learning from Observation with Multimodal Feedback",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15351v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Imitation learning frameworks that learn robot control policies from demonstrators' motions via hand-mounted demonstration interfaces have attracted increasing attention. However, due to differences in physical characteristics between demonstrators and robots, this approach faces two limitations: i) the demonstration data do not include robot actions, and ii) the demonstrated motions may be infeasible for robots. These limitations make policy learning difficult. To address them, we propose Feasibility-Aware Behavior Cloning from Observation (FABCO). FABCO integrates behavior cloning from observation, which complements robot actions using robot dynamics models, with feasibility estimation. In feasibility estimation, the demonstrated motions are evaluated using a robot-dynamics model, learned from the robot's execution data, to assess reproducibility under the robot's dynamics. The estimated feasibility is used for multimodal feedback and feasibility-aware policy learning to improve the demonstrator's motions and learn robust policies. Multimodal feedback provides feasibility through the demonstrator's visual and haptic senses to promote feasible demonstrated motions. Feasibility-aware policy learning reduces the influence of demonstrated motions that are infeasible for robots, enabling the learning of policies that robots can execute stably. We conducted experiments with 15 participants on two tasks and confirmed that FABCO improves imitation learning performance by more than 3.2 times compared to the case without feasibility feedback.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15351v1",
        "authors": [
          "Kei Takahashi",
          "Hikaru Sasaki",
          "Takamitsu Matsubara"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Feedback Imitation",
        "Aware Behavior Cloning",
        "Imitation Learning",
        "Framework",
        "Policy",
        "Robot",
        "FABCO",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.001536"
    },
    {
      "id": "arxiv-2602.15336v1",
      "title": "Human-AI Interaction: Evaluating LLM Reasoning on Digital Logic Circuit included Graph Problems, in terms of creativity in design and analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15336v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) are increasingly used by undergraduate students as on-demand tutors, yet their reliability on circuit- and diagram-based digital logic problems remains unclear. We present a human- AI study evaluating three widely used LLMs (GPT, Gemini, and Claude) on 10 undergraduate-level digital logic questions spanning non-standard counters, JK-based state transitions, timing diagrams, frequency division, and finite-state machines. Twenty-four students performed pairwise model comparisons, providing per-question judgments on (i) preferred model, (ii) perceived correctness, (iii) consistency, (iv) verbosity, and (v) confidence, along with global ratings of overall model quality, satisfaction across multiple dimensions (e.g., accuracy and clarity), and perceived mental effort required to verify answers. To benchmark technical validity, we applied an independent judge-based evaluation against official solutions for all ten questions, using strict correctness criteria. Results reveal a consistent gap between perceived helpfulness and formal correctness: for the most sequentially demanding problems (Q1- Q7), none of the evaluated LLMs matched the official answers, despite producing confident, well-structured explanations that students often rated favorably. Error analysis indicates that models frequently default to canonical textbook templates (e.g., standard ripple counters) and struggle to translate circuit structure into exact state evolution and timing behavior. These findings suggest that, without verification scaffolds, LLMs may be unreliable for core digital logic topics and can inadvertently reinforce misconceptions in undergraduate instruction.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15336v1",
        "authors": [
          "Yogeswar Reddy Thota",
          "Setareh Rafatirad",
          "Homayoun Houman",
          "Tooraj Nikoubin"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Digital Logic Circuit",
        "Large Language Models",
        "Graph Problems",
        "Standard",
        "GPT",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.001994"
    },
    {
      "id": "arxiv-2602.15326v1",
      "title": "SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15326v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose SCENE (Self-Centering Noncoherent Estimator), a pilot-free and phase-invariant aggregation primitive for over-the-air federated distillation (OTA-FD). Each device maps its soft-label (class-probability) vector to nonnegative transmit energies under constant per-round power and constant-envelope signaling (PAPR near 1). At the server, a self-centering energy estimator removes the noise-energy offset and yields an unbiased estimate of the weighted soft-label average, with variance decaying on the order of 1/(SM) in the number of receive antennas M and repetition factor S. We also develop a pilot-free ratio-normalized variant that cancels unknown large-scale gains, provide a convergence bound consistent with coherent OTA-FD analyses, and present an overhead-based crossover comparison. SCENE targets short-coherence and hardware-constrained regimes, where avoiding per-round CSI is essential: it trades a modest noncoherent variance constant for zero uplink pilots, unbiased aggregation, and hardware-friendly transmission, and can outperform coherent designs when pilot overhead is non-negligible.",
        "keywords": [
          "eess.SP",
          "cs.AI",
          "cs.DC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15326v1",
        "authors": [
          "Hao Chen",
          "Zavareh Bozorgasl"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.AI",
          "cs.DC",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Centering Noncoherent Estimator",
        "Air Federated Distillation We",
        "SCENE",
        "PAPR",
        "CSI",
        "MIT",
        "OTA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.002314"
    },
    {
      "id": "arxiv-2602.15309v1",
      "title": "OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15309v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.",
        "keywords": [
          "cs.RO",
          "physics.med-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15309v1",
        "authors": [
          "Mostafa A. Atalla",
          "Anand S. Sekar",
          "Remi van Starkenburg",
          "David J. Jager",
          "Aimée Sakes"
        ],
        "arxiv_categories": [
          "cs.RO",
          "physics.med-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Propelling Capsule Robot",
        "Colonoscopy Self",
        "An Ovipositor",
        "Inspired Self",
        "Agreement",
        "Robot",
        "OSCAR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.002816"
    },
    {
      "id": "arxiv-2602.15288v1",
      "title": "AI Sessions for Network-Exposed AI-as-a-Service",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15288v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Cloud-based Artificial Intelligence (AI) inference is increasingly latency- and context-sensitive, yet today's AI-as-a-Service is typically consumed as an application-chosen endpoint, leaving the network to provide only best-effort transport. This decoupling prevents enforceable tail-latency guarantees, compute-aware admission control, and continuity under mobility. This paper proposes Network-Exposed AI-as-a-Service (NE-AIaaS) built around a new service primitive: the AI Session (AIS)-a contractual object that binds model identity, execution placement, transport Quality-of-Service (QoS), and consent/charging scope into a single lifecycle with explicit failure semantics. We introduce the AI Service Profile (ASP), a compact contract that expresses task modality and measurable service objectives (e.g., time-to-first-response/token, p99 latency, success probability) alongside privacy and mobility constraints. On this basis, we specify protocol-grade procedures for (i) DISCOVER (model/site discovery), (ii) AI PAGING (context-aware selection of execution anchor), (iii) two-phase PREPARE/COMMIT that atomically co-reserves compute and QoS resources, and (iv) make-before-break MIGRATION for session continuity. The design is standard-mappable to Common API Framework (CAPIF) style northbound exposure, ETSI Multi-access Edge Computing (MEC) execution substrates, 5G QoS flows for transport enforcement, and Network Data Analytics Function (NWDAF) style analytics for closed-loop paging/migration triggers.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15288v1",
        "authors": [
          "Merve Saimler",
          "Mohaned Chraiti"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Network Data Analytics Function",
        "Artificial Intelligence",
        "Service Profile",
        "Edge Computing",
        "Service Cloud",
        "Framework",
        "Protocol",
        "Standard",
        "PAGING",
        "COMMIT",
        "Intel",
        "NWDAF",
        "CAPIF",
        "ETSI",
        "EPA"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.003186"
    },
    {
      "id": "arxiv-2602.15286v1",
      "title": "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15286v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.",
        "keywords": [
          "cs.NI",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15286v1",
        "authors": [
          "Merve Saimler",
          "Mohaned Chraiti"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Execution Anchoring",
        "Service With",
        "Policy",
        "COMMIT",
        "AEXF",
        "AISI",
        "AIST",
        "MIT",
        "Act",
        "6G",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.003536"
    },
    {
      "id": "arxiv-2602.15281v1",
      "title": "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15281v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "To support the emergence of AI-as-a-Service (AIaaS), communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and joint network-compute orchestration, i.e., reliable and timely end-to-end delivery. The resulting end-to-end AIaaS service thus becomes governed by communications impairments (delay, loss) and inference impairments (latency, error). A central open problem is an operational AIaaS control-and-orchestration framework that enforces high fidelity, particularly under multi-domain federation. This paper introduces an assurance-oriented AIaaS management plane based on Tail-Risk Envelopes (TREs): signed, composable per-domain descriptors that combine deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, we derive bounds on end-to-end delay violation probabilities across tandem domains and obtain an optimization-ready risk-budget decomposition. We show that tenant-level reservations prevent bursty traffic from inflating tail latency under TRE contracts. An auditing layer then uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk to each domain for accountability. Packet-level Monte-Carlo simulations demonstrate improved p99.9 compliance under overload via admission control and robust tenant isolation under correlated burstiness.",
        "keywords": [
          "cs.NI",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15281v1",
        "authors": [
          "Merve Saimler",
          "Mohaned Chraiti",
          "Ozgur Ercetin"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fidelity Network Management",
        "Domain Orchestration To",
        "Risk Envelopes",
        "Framework",
        "NIST",
        "NSF",
        "CSP",
        "Act",
        "TRE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:57:58.003886"
    },
    {
      "id": "arxiv-2602.15821v1",
      "title": "Computation and Size of Interpolants for Hybrid Modal Logics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15821v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent research has established complexity results for the problem of deciding the existence of interpolants in logics lacking the Craig Interpolation Property (CIP). The proof techniques developed so far are non-constructive, and no meaningful bounds on the size of interpolants are known. Hybrid modal logics (or modal logics with nominals) are a particularly interesting class of logics without CIP: in their case, CIP cannot be restored without sacrificing decidability and, in applications, interpolants in these logics can serve as definite descriptions and separators between positive and negative data examples in description logic knowledge bases. In this contribution we show, using a new hypermosaic elimination technique, that in many standard hybrid modal logics Craig interpolants can be computed in fourfold exponential time, if they exist. On the other hand, we show that the existence of uniform interpolants is undecidable, which is in stark contrast to modal or intuitionistic logic where uniform interpolants always exist.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15821v1",
        "authors": [
          "Jean Christoph Jung",
          "Jędrzej Kołodziejski",
          "Frank Wolter"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Craig Interpolation Property",
        "Hybrid Modal Logics Recent",
        "Standard",
        "NIST",
        "CIP",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.589851"
    },
    {
      "id": "arxiv-2602.15815v1",
      "title": "Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15815v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as Rényi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.",
        "keywords": [
          "cs.CR",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15815v1",
        "authors": [
          "Matthew Regehr",
          "Bingshan Hu",
          "Ethan Leeman",
          "Pasin Manurangsi",
          "Pierre Tholoniat"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Natural Privacy Filters Are",
        "Free Natural Filters We",
        "Not Always Free",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.590428"
    },
    {
      "id": "arxiv-2602.15802v1",
      "title": "Local Node Differential Privacy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15802v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We initiate an investigation of node differential privacy for graphs in the local model of private data analysis. In our model, dubbed LNDP, each node sees its own edge list and releases the output of a local randomizer on this input. These outputs are aggregated by an untrusted server to obtain a final output. We develop a novel algorithmic framework for this setting that allows us to accurately answer arbitrary linear queries on a blurry approximation of the input graph's degree distribution. For some natural problems, the resulting algorithms match the accuracy achievable with node privacy in the central model, where data are held and processed by a trusted server. We also prove lower bounds on the error required by LNDP that imply the optimality of our algorithms for several fundamental graph statistics. We then lift these lower bounds to the interactive LNDP setting, demonstrating the optimality of our algorithms even when constantly many rounds of interaction are permitted. Obtaining our lower bounds requires new approaches, since those developed for the usual local model do not apply to the inherently overlapping inputs that arise from graphs. Finally, we prove structural results that reveal qualitative differences between local node privacy and the standard local model for tabular data.",
        "keywords": [
          "cs.DS",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15802v1",
        "authors": [
          "Sofya Raskhodnikova",
          "Adam Smith",
          "Connor Wagaman",
          "Anatoly Zavyalov"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Local Node Differential Privacy",
        "Framework",
        "Standard",
        "LNDP",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.590796"
    },
    {
      "id": "arxiv-2602.15761v1",
      "title": "A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15761v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15761v1",
        "authors": [
          "Simantika Bhattacharjee Dristi",
          "Matthew B. Dwyer"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generated Code Refactorings With",
        "Functional Equivalence",
        "Differential Fuzzing",
        "Based Evaluation",
        "Qwen-2.5",
        "Olmo-3",
        "GPT",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.591162"
    },
    {
      "id": "arxiv-2602.15705v1",
      "title": "Privacy-Preserving and Secure Spectrum Sharing for Database-Driven Cognitive Radio Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15705v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Database-driven cognitive radio networks (DB-CRNs) enable dynamic spectrum sharing through geolocation databases but introduce critical security and privacy challenges, including mandatory location disclosure, susceptibility to location spoofing, and denial-of-service (DoS) attacks on centralized services. Existing approaches address these issues in isolation and lack a unified, regulation-compliant solution under realistic adversarial conditions. In this work, we present a unified security framework for DB-CRNs that simultaneously provides location privacy, user anonymity, verifiable location, and DoS resilience. Our framework, denoted as SLAPX, enables privacy-preserving spectrum queries using delegatable anonymous credentials, supports adaptive location verification without revealing precise user location, and mitigates DoS attacks through verifiable delay functions (VDFs) combined with RLRS-based rate limiting. Extensive cryptographic benchmarking and network simulations demonstrate that SLAPX achieves significantly lower latency and communication overhead than existing solutions while effectively resisting location spoofing and DoS attacks. These results show that SLAPX is practical and well-suited for secure next-generation DB-CRN deployments.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15705v1",
        "authors": [
          "Saleh Darzia",
          "Gökcan Cantalib",
          "Attila Altay Yavuza",
          "Gürkan Gür"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Cognitive Radio Networks",
        "Secure Spectrum Sharing",
        "Regulation",
        "Framework",
        "SLAPX",
        "RLRS",
        "MIT",
        "CRN",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.591577"
    },
    {
      "id": "arxiv-2602.15671v1",
      "title": "Revisiting Backdoor Threat in Federated Instruction Tuning from a Signal Aggregation Perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15671v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Federated learning security research has predominantly focused on backdoor threats from a minority of malicious clients that intentionally corrupt model updates. This paper challenges this paradigm by investigating a more pervasive and insidious threat: \\textit{backdoor vulnerabilities from low-concentration poisoned data distributed across the datasets of benign clients.} This scenario is increasingly common in federated instruction tuning for language models, which often rely on unverified third-party and crowd-sourced data. We analyze two forms of backdoor data through real cases: 1) \\textit{natural trigger (inherent features as implicit triggers)}; 2) \\textit{adversary-injected trigger}. To analyze this threat, we model the backdoor implantation process from signal aggregation, proposing the Backdoor Signal-to-Noise Ratio to quantify the dynamics of the distributed backdoor signal. Extensive experiments reveal the severity of this threat: With just less than 10\\% of training data poisoned and distributed across clients, the attack success rate exceeds 85\\%, while the primary task performance remains largely intact. Critically, we demonstrate that state-of-the-art backdoor defenses, designed for attacks from malicious clients, are fundamentally ineffective against this threat. Our findings highlight an urgent need for new defense mechanisms tailored to the realities of modern, decentralized data ecosystems.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15671v1",
        "authors": [
          "Haodong Zhao",
          "Jinming Hu",
          "Gongshen Liu"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Signal Aggregation Perspective Federated",
        "Federated Instruction Tuning",
        "Revisiting Backdoor Threat",
        "Backdoor Signal",
        "Noise Ratio",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.592065"
    },
    {
      "id": "arxiv-2602.15631v1",
      "title": "Meflex: A Multi-agent Scaffolding System for Entrepreneurial Ideation Iteration via Nonlinear Business Plan Writing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15631v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Business plan (BP) writing plays a key role in entrepreneurship education by helping learners construct, evaluate, and iteratively refine their ideas. However, conventional BP writing remains a rigid, linear process that often fails to reflect the dynamic and recursive nature of entrepreneurial ideation. This mismatch is particularly challenging for novice entrepreneurial students, who struggle with the substantial cognitive demands of developing and refining ideas. While reflection and meta-reflection are critical strategies for fostering divergent and convergent thinking, existing writing tools rarely scaffold these higher-order processes. To address this gap, we present the Meflex System, a large language model (LLM)-based writing tool that integrates BP writing scaffolding with a nonlinear idea canvas to support iterative ideation through reflection and meta-reflection. We report findings from an exploratory user study with 30 participants that examined the system's usability and cognitive impact. Results show that Meflex effectively scaffolds BP writing, promotes divergent thinking through LLM-supported reflection, and enhances meta-reflective awareness while reducing cognitive load during complex idea development. These findings highlight the potential of non-linear LLM-based writing tools to foster deeper and coherent entrepreneurial thinking.",
        "keywords": [
          "cs.HC",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15631v1",
        "authors": [
          "Lan Luo",
          "Dongyijie Primo Pan",
          "Junhua Zhu",
          "Muzhi Zhou",
          "Pan Hui"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.SE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Entrepreneurial Ideation Iteration",
        "Nonlinear Business Plan Writing",
        "Scaffolding System",
        "Meflex System",
        "Meta",
        "WHO",
        "LLM",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:03.592518"
    },
    {
      "id": "arxiv-2602.15614v1",
      "title": "Onto-DP: Constructing Neighborhoods for Differential Privacy on Ontological Databases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15614v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we investigate how attackers can discover sensitive information embedded within databases by exploiting inference rules. We demonstrate the inadequacy of naively applied existing state of the art differential privacy (DP) models in safeguarding against such attacks. We introduce ontology aware differential privacy (Onto-DP), a novel extension of differential privacy paradigms built on top of any classical DP model by enriching it with semantic awareness. We show that this extension is a sufficient condition to adequately protect against attackers aware of inference rules.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15614v1",
        "authors": [
          "Yasmine Hayder",
          "Adrien Boiret",
          "Cédric Eichler",
          "Benjamin Nguyen"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constructing Neighborhoods",
        "Ontological Databases In",
        "Differential Privacy",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.592736"
    },
    {
      "id": "arxiv-2602.15591v1",
      "title": "Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15591v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15591v1",
        "authors": [
          "Denesa Zyberaj",
          "Lukasz Mazur",
          "Pascal Hirmer",
          "Nenad Petrovic",
          "Marco Aiello"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Child Presence Detection System",
        "Vehicle Execution Testing",
        "Test Artifact Generation",
        "Large Language Models",
        "Defined Vehicles",
        "Language Models",
        "Standard",
        "CPDS",
        "NSF",
        "SDV",
        "VSS",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.593119"
    },
    {
      "id": "arxiv-2602.15511v1",
      "title": "Generating Theorems by Generating Proof Structures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15511v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We address generating theorems from a given set of axioms, without proof goal, aiming at value from a mathematical point of view or as lemmas for automated proving. As benchmark, we convert a fragment of the Metamath database set.mm. Our techniques are centered on proof terms and condensed detachment, which ties in with approaches to automated first-order proving by proof structure enumeration, and links to Metamath as well as to formulas-as-types. Our methods for generating theorems are based on partitioning the set of proof terms into inductively characterized levels. We study two ideas for improvement: Lemma synthesis by DAG compression of proof term sets and incorporating combinators into proof term construction.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15511v1",
        "authors": [
          "Christoph Wernhard"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generating Proof Structures We",
        "Meta",
        "DAG",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.593419"
    },
    {
      "id": "arxiv-2602.15502v1",
      "title": "MMPersistence: A mathematical morphology-oriented software library for computing persistent homology on cubical complexes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15502v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Mathematical morphology (MM) is a powerful and widely used framework in image processing. Through set-theoretic and discrete geometric principles, MM operations such as erosion, dilation, opening, and closing effectively manipulate digital images by modifying local structures via structuring elements (SEs), while cubical homology captures global topological features such as connected components and loop structures within images. Building on the GUDHI package for persistent homology (PH) computation on cubical complexes, we propose the MMPersistence library, which integrates MM operations with diverse SEs and PH computation to extract multiscale persistence information. By employing SEs of different shapes to construct topological filtrations, the proposed MM-based PH framework encodes both spatial and morphological characteristics of digital images, providing richer local geometric information than conventional cubical homology alone and establishing a unified foundation for analyzing digital images that integrates topological insight with morphological image processing techniques.",
        "keywords": [
          "cs.SE",
          "math.AT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15502v1",
        "authors": [
          "Chuan-Shen Hu"
        ],
        "arxiv_categories": [
          "cs.SE",
          "math.AT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "GUDHI",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.593791"
    },
    {
      "id": "arxiv-2602.15485v1",
      "title": "SecCodeBench-V2 Technical Report",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15485v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce SecCodeBench-V2, a publicly released benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code. SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions, where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five programming languages: Java, C, Python, Go, and Node.js. SecCodeBench-V2 adopts a function-level task formulation: each scenario provides a complete project scaffold and requires the model to implement or patch a designated target function under fixed interfaces and dependencies. For each scenario, SecCodeBench-V2 provides executable proof-of-concept (PoC) test cases for both functional validation and security verification. All test cases are authored and double-reviewed by security experts, ensuring high fidelity, broad coverage, and reliable ground truth. Beyond the benchmark itself, we build a unified evaluation pipeline that assesses models primarily via dynamic execution. For most scenarios, we compile and run model-generated artifacts in isolated environments and execute PoC test cases to validate both functional correctness and security properties. For scenarios where security issues cannot be adjudicated with deterministic test cases, we additionally employ an LLM-as-a-judge oracle. To summarize performance across heterogeneous scenarios and difficulty levels, we design a Pass@K-based scoring protocol with principled aggregation over scenarios and severity, enabling holistic and comparable evaluation across models. Overall, SecCodeBench-V2 provides a rigorous and reproducible foundation for assessing the security posture of AI coding assistants, with results and artifacts released at https://alibaba.github.io/sec-code-bench. The benchmark is publicly available at https://github.com/alibaba/sec-code-bench.",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15485v1",
        "authors": [
          "Longfei Chen",
          "Ji Zhao",
          "Lanxiao Cui",
          "Tong Su",
          "Xingbo Pan"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Common Weakness Enumeration",
        "Large Language Model",
        "Technical Report We",
        "Alibaba Group",
        "Protocol",
        "Oracle",
        "NIST",
        "CWE",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.594405"
    },
    {
      "id": "arxiv-2602.15483v1",
      "title": "Exploring VASS Parameterised by Geometric Dimension",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15483v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The geometric dimension $g$ of a Vector Addition System with States (VASS) is the dimension of the vector space generated by cycles in the VASS; this parameter refines the standard dimension $d$, the number of counters. Recently, it was discovered that the fastest-known algorithm for solving the reachability problem for VASS has the same complexity in terms of $g$ as in terms of $d$. This suggests that the geometric dimension may in fact be a more adequate parameter for measuring the complexity of VASS reachability problems. We initiate a more systematic study of the geometric dimension. We discuss differences between two parameters: the geometric dimension and the SCC dimension. Our main technical result states that classical results about the coverability and boundedness problems can be improved from dimension $d$ to geometric dimension $g$. Namely, coverability is witnessed by runs of length $n^{2^{\\mathcal{O}(g)}}$ instead of $n^{2^{\\mathcal{O}(d)}}$, and unboundedness can be witnessed by runs of length $n^{2^{\\mathcal{O}(g\\log g)}}$ instead of $n^{2^{\\mathcal{O}(d\\log d )}}$, where $n$ is the size of the instance. We also study integer reachability and simultaneous unboundedness in VASS parameterised by the geometric dimension.",
        "keywords": [
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15483v1",
        "authors": [
          "Wojciech Czerwiński",
          "Roland Guttenberg",
          "Łukasz Orlikowski",
          "Henry Sinclair-Banks",
          "Yangluo Zheng"
        ],
        "arxiv_categories": [
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vector Addition System",
        "Standard",
        "VASS",
        "SCC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.594808"
    },
    {
      "id": "arxiv-2602.15449v1",
      "title": "TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15449v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.",
        "keywords": [
          "cs.CL",
          "cs.LG",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15449v1",
        "authors": [
          "Chansung Park",
          "Juyong Jiang",
          "Fan Wang",
          "Sayak Paul",
          "Jiasi Shen"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.LG",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Curriculum Reinforcement Fine",
        "Large Language Models Large",
        "Reinforcement Fine",
        "Code Generation",
        "Language Models",
        "TAROT",
        "RFT",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.595344"
    },
    {
      "id": "arxiv-2602.15435v1",
      "title": "TARZAN: A Region-Based Library for Forward and Backward Reachability of Timed Automata (Extended Version)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15435v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The zone abstraction, widely adopted for its notable practical efficiency, is the de facto standard in the verification of Timed Automata (TA). Nonetheless, region-based abstractions have been shown to outperform zones in specific subclasses of TA. To complement and support mature zone-based tools, we introduce TARZAN, a C++ region-based verification library for TA. The algorithms implemented in TARZAN use a novel region abstraction that tracks the order in which clocks become unbounded. This additional ordering induces a finer partitioning of the state space, enabling backward algorithms to avoid the combinatorial explosion associated with enumerating all ordered partitions of unbounded clocks, when computing immediate delay predecessor regions. We validate TARZAN by comparing forward reachability results against the state-of-the-art tools Uppaal and TChecker. The experiments confirm that zones excel when TA have large constants and strict guards. In contrast, TARZAN exhibits superior performance on closed TA and TA with punctual guards. Finally, we demonstrate the efficacy of our backward algorithms, establishing a foundation for region-based analysis in domains like Timed Games, where backward exploration is essential.",
        "keywords": [
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15435v1",
        "authors": [
          "Andrea Manini",
          "Matteo Rossi",
          "Pierluigi San Pietro"
        ],
        "arxiv_categories": [
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Backward Reachability",
        "Extended Version",
        "Timed Automata",
        "Based Library",
        "Timed Games",
        "Standard",
        "TARZAN",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.595701"
    },
    {
      "id": "arxiv-2602.15412v1",
      "title": "Social Life of Code: Modeling Evolution through Code Embedding and Opinion Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15412v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Software repositories provide a detailed record of software evolution by capturing developer interactions through code-related activities such as pull requests and modifications. To better understand the underlying dynamics of codebase evolution, we introduce a novel approach that integrates semantic code embeddings with opinion dynamics theory, offering a quantitative framework to analyze collaborative development processes. Our approach begins by encoding code snippets into high-dimensional vector representations using state-of-the-art code embedding models, preserving both syntactic and semantic features. These embeddings are then processed using Principal Component Analysis (PCA) for dimensionality reduction, with data normalized to ensure comparability. We model temporal evolution using the Expressed-Private Opinion (EPO) model to derive trust matrices and track opinion trajectories across development cycles. These opinion trajectories reflect the underlying dynamics of consensus formation, influence propagation, and evolving alignment (or divergence) within developer communities -- revealing implicit collaboration patterns and knowledge-sharing mechanisms that are otherwise difficult to observe. By bridging software engineering and computational social science, our method provides a principled way to quantify software evolution, offering new insights into developer influence, consensus formation, and project sustainability. We evaluate our approach on data from three prominent open-source GitHub repositories, demonstrating its ability to reveal interpretable behavioral trends and variations in developer interactions. The results highlight the utility of our framework in improving open-source project maintenance through data-driven analysis of collaboration dynamics.",
        "keywords": [
          "cs.SE",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15412v1",
        "authors": [
          "Yulong He",
          "Nikita Verbin",
          "Sergey Kovalchuk"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.SI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Principal Component Analysis",
        "Opinion Dynamics Software",
        "Modeling Evolution",
        "Private Opinion",
        "Code Embedding",
        "Social Life",
        "Framework",
        "PCA",
        "EPO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.596161"
    },
    {
      "id": "arxiv-2602.15409v1",
      "title": "Hennessy-Milner Logic in CSLib, the Lean Computer Science Library",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15409v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a library-level formalisation of Hennessy-Milner Logic (HML) - a foundational logic for labelled transition systems (LTSs) - for the Lean Computer Science Library (CSLib). Our development includes the syntax, satisfaction relation, and denotational semantics of HML, as well as a complete metatheory including the Hennessy-Milner theorem - bisimilarity coincides with theory equivalence for image-finite LTSs. Our development emphasises generality and reusability: it is parametric over arbitrary LTSs, definitions integrate with CSLib's infrastructure (such as the formalisation of bisimilarity), and proofs leverage Lean's automation (notably the grind tactic). All code is publicly available in CSLib and can be readily applied to systems that use its LTS API.",
        "keywords": [
          "cs.LO",
          "cs.PL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15409v1",
        "authors": [
          "Fabrizio Montesi",
          "Marco Peressotti",
          "Alexandre Rademaker"
        ],
        "arxiv_categories": [
          "cs.LO",
          "cs.PL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lean Computer Science Library",
        "Milner Logic",
        "Meta",
        "HML",
        "LTS",
        "API",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.596404"
    },
    {
      "id": "arxiv-2602.15395v1",
      "title": "MEV in Binance Builder",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15395v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the builder-driven MEV arbitrage on BNB Smart Chain (BSC). BSC's Proposer--Builder Separation (PBS) adopts a leaner design: only whitelisted builders can participate, blocks are produced at shorter intervals, and private order flow bypasses the public mempool. These features have long raised community concerns over centralization, which we empirically confirm by tracing arbitrage activity of the two dominant builders from May to November 2025. Within months, 48Club and Blockrazor produced over 96\\% of blocks and captured about 92\\% of MEV profits. We find that profits concentrate in short, low-hop arbitrage routes over wrapped tokens and stablecoins, and that block construction rapidly converges toward monopoly. Beyond concentration alone, our analysis reveals a structural source of inequality: BSC's short block interval and whitelisted PBS collapse the contestable window for MEV competition, amplifying latency advantages and excluding slower builders and searchers. MEV extraction on BSC is not only more centralized than on Ethereum, but also structurally more vulnerable to censorship and weakened fairness.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15395v1",
        "authors": [
          "Qin Wang",
          "Ruiqiang Li",
          "Guangsheng Yu",
          "Vincent Gramoli",
          "Shiping Chen"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Binance Builder We",
        "Builder Separation",
        "Smart Chain",
        "Wind",
        "EPA",
        "BSC",
        "BNB",
        "PBS",
        "MEV",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.596717"
    },
    {
      "id": "arxiv-2602.15376v1",
      "title": "A Unified Evaluation of Learning-Based Similarity Techniques for Malware Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15376v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Cryptographic digests (e.g., MD5, SHA-256) are designed to provide exact identity. Any single-bit change in the input produces a completely different hash, which is ideal for integrity verification but limits their usefulness in many real-world tasks like threat hunting, malware analysis and digital forensics, where adversaries routinely introduce minor transformations. Similarity-based techniques address this limitation by enabling approximate matching, allowing related byte sequences to produce measurably similar fingerprints. Modern enterprises manage tens of thousands of endpoints with billions of files, making the effectiveness and scalability of the proposed techniques more important than ever in security applications. Security researchers have proposed a range of approaches, including similarity digests and locality-sensitive hashes (e.g., ssdeep, sdhash, TLSH), as well as more recent machine-learning-based methods that generate embeddings from file features. However, these techniques have largely been evaluated in isolation, using disparate datasets and evaluation criteria. This paper presents a systematic comparison of learning-based classification and similarity methods using large, publicly available datasets. We evaluate each method under a unified experimental framework with industry-accepted metrics. To our knowledge, this is the first reproducible study to benchmark these diverse learning-based similarity techniques side by side for real-world security workloads. Our results show that no single approach performs well across all dimensions; instead, each exhibits distinct trade-offs, indicating that effective malware analysis and threat-hunting platforms must combine complementary classification and similarity techniques rather than rely on a single method.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15376v1",
        "authors": [
          "Udbhav Prasad",
          "Aniesh Chawla"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Malware Detection Cryptographic",
        "Based Similarity Techniques",
        "Unified Evaluation",
        "Framework",
        "SHA-256",
        "TLSH",
        "Bill",
        "SHA",
        "NSF",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.597185"
    },
    {
      "id": "arxiv-2602.15364v1",
      "title": "MarkSweep: A No-box Removal Attack on AI-Generated Image Watermarking via Noise Intensification and Frequency-aware Denoising",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15364v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "AI watermarking embeds invisible signals within images to provide provenance information and identify content as AI-generated. In this paper, we introduce MarkSweep, a novel watermark removal attack that effectively erases the embedded watermarks from AI-generated images without degrading visual quality. MarkSweep first amplifies watermark noise in high-frequency regions via edge-aware Gaussian perturbations and injects it into clean images for training a denoising network. This network then integrates two modules, the learnable frequency decomposition module and the frequency-aware fusion module, to suppress amplified noise and eliminate watermark traces. Theoretical analysis and extensive experiments demonstrate that invisible watermarks are highly vulnerable to MarkSweep, which effectively removes embedded watermarks, reducing the bit accuracy of HiDDeN and Stable Signature watermarking schemes to below 67%, while preserving perceptual quality of AI-generated images.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15364v1",
        "authors": [
          "Jie Cao",
          "Zelin Zhang",
          "Qi Li",
          "Jianbing Ni"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generated Image Watermarking",
        "Noise Intensification",
        "Stable Signature",
        "Removal Attack",
        "Fusion",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.597495"
    },
    {
      "id": "arxiv-2602.15362v1",
      "title": "Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15362v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15362v1",
        "authors": [
          "Devendra Tata",
          "Mona Rajhans"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Natural Language Error Explanation",
        "Automated Multi Source Debugging",
        "Dashboard Applications Modern",
        "Large Language Models",
        "Source Debugging",
        "Automated Multi",
        "Mean Time",
        "Framework",
        "Intel",
        "NSF",
        "API",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.597841"
    },
    {
      "id": "arxiv-2602.15342v1",
      "title": "SACS: A Code Smell Dataset using Semi-automatic Generation Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15342v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15342v1",
        "authors": [
          "Hanyu Zhang",
          "Tomoji Kishi"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generation Approach Code",
        "Code Smell Dataset",
        "Machine Learning",
        "Feature Envy",
        "Large Class",
        "Long Method",
        "Guideline",
        "SACS",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.598303"
    },
    {
      "id": "arxiv-2602.15323v1",
      "title": "Unforgeable Watermarks for Language Models via Robust Signatures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15323v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Language models now routinely produce text that is difficult to distinguish from human writing, raising the need for robust tools to verify content provenance. Watermarking has emerged as a promising countermeasure, with existing work largely focused on model quality preservation and robust detection. However, current schemes provide limited protection against false attribution. We strengthen the notion of soundness by introducing two novel guarantees: unforgeability and recoverability. Unforgeability prevents adversaries from crafting false positives, texts that are far from any output from the watermarked model but are nonetheless flagged as watermarked. Recoverability provides an additional layer of protection: whenever a watermark is detected, the detector identifies the source text from which the flagged content was derived. Together, these properties strengthen content ownership by linking content exclusively to its generating model, enabling secure attribution and fine-grained traceability. We construct the first undetectable watermarking scheme that is robust, unforgeable, and recoverable with respect to substitutions (i.e., perturbations in Hamming metric). The key technical ingredient is a new cryptographic primitive called robust (or recoverable) digital signatures, which allow verification of messages that are close to signed ones, while preventing forgery of messages that are far from all previously signed messages. We show that any standard digital signature scheme can be boosted to a robust one using property-preserving hash functions (Boyle, LaVigne, and Vaikuntanathan, ITCS 2019).",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15323v1",
        "authors": [
          "Huijia Lin",
          "Kameron Shahabi",
          "Min Jae Song"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robust Signatures Language",
        "Unforgeable Watermarks",
        "Language Models",
        "Standard",
        "ITCS",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.598726"
    },
    {
      "id": "arxiv-2602.15290v1",
      "title": "Intellicise Wireless Networks Meet Agentic AI: A Security and Privacy Perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15290v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Intellicise (Intelligent and Concise) wireless network is the main direction of the evolution of future mobile communication systems, a perspective now widely acknowledged across academia and industry. As a key technology within it, Agentic AI has garnered growing attention due to its advanced cognitive capabilities, enabled through continuous perception-memory-reasoning-action cycles. This paper first analyses the unique advantages that Agentic AI introduces to intellicise wireless networks. We then propose a structured taxonomy for Agentic AI-enhanced secure intellicise wireless networks. Building on this framework, we identify emerging security and privacy challenges introduced by Agentic AI and summarize targeted strategies to address these vulnerabilities. A case study further demonstrates Agentic AI's efficacy in defending against intelligent eavesdropping attacks. Finally, we outline key open research directions to guide future exploration in this field.",
        "keywords": [
          "cs.CR",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15290v1",
        "authors": [
          "Rui Meng",
          "Zhidi Zhang",
          "Song Gao",
          "Yaheng Wang",
          "Xiaodong Xu"
        ],
        "arxiv_categories": [
          "cs.CR",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Intellicise Wireless Networks Meet",
        "Privacy Perspective Intellicise",
        "Framework",
        "Intel",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:03.599030"
    },
    {
      "id": "arxiv-2602.15797v1",
      "title": "On Graham's rearrangement conjecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15797v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Graham conjectured in 1971 that for any prime $p$, any subset $S\\subseteq \\mathbb{Z}_p\\setminus \\{0\\}$ admits an ordering $s_1,s_2,\\dots,s_{|S|}$ where all partial sums $s_1, s_1+s_2,\\dots,s_1+s_2+\\dots+s_{|S|}$ are distinct. We prove this conjecture for all subsets $S\\subseteq \\mathbb{Z}_p\\setminus \\{0\\}$ with $|S|\\le p^{1-α}$ and $|S|$ sufficiently large with respect to $α$, for any $α\\in (0,1)$. Combined with earlier results, this gives a complete resolution of Graham's rearrangement conjecture for all sufficiently large primes $p$.",
        "keywords": [
          "math.CO",
          "cs.DM",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15797v1",
        "authors": [
          "Huy Tuan Pham",
          "Lisa Sauermann"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "On Graham",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.990854"
    },
    {
      "id": "arxiv-2602.15702v1",
      "title": "A Weighted-to-Unweighted Reduction for Matroid Intersection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15702v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Given two matroids $\\mathcal{M}_1$ and $\\mathcal{M}_2$ over the same ground set, the matroid intersection problem is to find the maximum cardinality common independent set. In the weighted version of the problem, the goal is to find a maximum weight common independent set. It has been a matter of interest to find efficient approximation algorithms for this problem in various settings. In many of these models, there is a gap between the best known results for the unweighted and weighted versions. In this work, we address the question of closing this gap. Our main result is a reduction which converts any $α$-approximate unweighted matroid intersection algorithm into an $α(1-\\varepsilon)$-approximate weighted matroid intersection algorithm, while increasing the runtime of the algorithm by a $\\log W$ factor, where $W$ is the aspect ratio. Our framework is versatile and translates to settings such as streaming and one-way communication complexity where matroid intersection is well-studied. As a by-product of our techniques, we derive new results for weighted matroid intersection in these models.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15702v1",
        "authors": [
          "Aditi Dudeja",
          "Mara Grilnberger"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Matroid Intersection Given",
        "Unweighted Reduction",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.991756"
    },
    {
      "id": "arxiv-2602.15683v1",
      "title": "Fair Correlation Clustering Meets Graph Parameters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15683v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the generalization of Correlation Clustering which incorporates fairness constraints via the notion of fairlets. The corresponding Fair Correlation Clustering problem has been studied from several perspectives to date, but has so far lacked a detailed analysis from the parameterized complexity paradigm. We close this gap by providing tractability results for the problem under a variety of structural graph parameterizations, including treewidth, treedepth and the vertex cover number; our results lie at the very edge of tractability given the known NP-hardness of the problem on severely restricted inputs.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15683v1",
        "authors": [
          "Johannes Blaha",
          "Robert Ganian",
          "Katharina Gillig",
          "Jonathan S. Højlev",
          "Simon Wietheger"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fair Correlation Clustering Meets",
        "Fair Correlation Clustering",
        "Correlation Clustering",
        "Graph Parameters We",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.992069"
    },
    {
      "id": "arxiv-2602.15613v1",
      "title": "Algorithmic differentiation for domain specific languages in C++ with expression templates",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15613v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The application of operator overloading algorithmic differentiation (AD) to computer programs in order to compute the derivative is quite common. But, the replacement of the underlying computational floating point type with the specialized type of an AD tool has two problems. First, the memory structure of the program is changed and floating-point data is interleaved with identifiers from AD. This prevents the compiler from performing optimizations such as SIMD optimizations. Second, the AD tool does not see any domain-specific operations, e.,g. linear algebra operations, that the program uses. This prevents the AD tool from using specialized algorithms in such places. We propose a new AD tool that is tailored to such situations. The memory structure of the primal data is retained by associating an identifier with each entity, e.,g. matrix, and not with each floating point value, e.,g. element of the matrix. Operations on such entities can then be annotated and a generator is used to create the AD overloads. We demonstrate that this approach provides performance comparable to that of other specializations. In addition, the run-time factor is below the theoretical 4.5 of reverse AD for programs that are written purely with linear algebra entities and operations.",
        "keywords": [
          "cs.MS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15613v1",
        "authors": [
          "Max Sagebaum",
          "Nicolas R. Gauger"
        ],
        "arxiv_categories": [
          "cs.MS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SIMD",
        "DOE",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.992497"
    },
    {
      "id": "arxiv-2602.15497v1",
      "title": "Polynomial-time isomorphism test for $k$-generated extensions of abelian groups",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15497v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The group isomorphism problem asks whether two finite groups given by their Cayley tables are isomorphic or not. Although there are polynomial-time algorithms for some specific group classes, the best known algorithm for testing isomorphism of arbitrary groups of order $ n $ has time complexity $ n^{O(\\log n)} $. We consider the group isomorphism problem for some extensions of abelian groups by $ k $-generated groups for bounded $ k $. In particular, we prove that one can decide isomorphism of abelian-by-cyclic extensions in polynomial time, generalizing a 2009 result of Le Gall for coprime extensions. As another application, we give a polynomial-time isomorphism test for abelian-by-simple group extensions, generalizing a 2017 result of Grochow and Qiao for central extensions. The main novelty of the proof is a polynomial-time algorithm for computing the unit group of a finite ring, which might be of independent interest.",
        "keywords": [
          "math.GR",
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15497v1",
        "authors": [
          "Saveliy V. Skresanov"
        ],
        "arxiv_categories": [
          "math.GR",
          "cs.CC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Le Gall",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.992970"
    },
    {
      "id": "arxiv-2602.15417v1",
      "title": "Memory Reallocation with Polylogarithmic Overhead",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15417v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Memory Reallocation problem asks to dynamically maintain an assignment of given objects of various sizes to non-overlapping contiguous chunks of memory, while supporting updates (insertions/deletions) in an online fashion. The total size of live objects at any time is guaranteed to be at most a $1-ε$ fraction of the total memory. To handle an online update, the allocator may rearrange the objects in memory to make space, and the overhead for this update is defined as the total size of moved objects divided by the size of the object being inserted/deleted. Our main result is an allocator with worst-case expected overhead $\\mathrm{polylog}(ε^{-1})$. This exponentially improves the previous worst-case expected overhead $\\tilde O(ε^{-1/2})$ achieved by Farach-Colton, Kuszmaul, Sheffield, and Westover (2024), narrowing the gap towards the $Ω(\\logε^{-1})$ lower bound. Our improvement is based on an application of the sunflower lemma previously used by Erdős and Sárközy (1992) in the context of subset sums. Our allocator achieves polylogarithmic overhead only in expectation, and sometimes performs expensive rebuilds. Our second technical result shows that this is necessary: it is impossible to achieve subpolynomial overhead with high probability.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15417v1",
        "authors": [
          "Ce Jin"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Memory Reallocation",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.993850"
    },
    {
      "id": "arxiv-2602.15375v1",
      "title": "Asymptotic Tightness of the Pigeonhole Bound for Large-Order Davenport-Schinzel Sequences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15375v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We prove that the pigeonhole upper bound $λ(s,m) \\leq \\binom{m}{2}(s+1)$ is asymptotically tight whenever $s/\\!\\sqrt{m} \\to \\infty$. In particular, $λ(s,m) \\sim \\binom{m}{2}\\,s$ in this regime. As corollaries: $λ(n,n)/n^3 \\to \\frac{1}{2}$, resolving the leading constant from the previously known interval $[\\frac{1}{3}, \\frac{1}{2}]$; and more generally $λ(an,bn) \\sim \\frac{ab^2}{2}\\,n^3$ for any constants $a,b > 0$.",
        "keywords": [
          "math.CO",
          "cs.DM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15375v1",
        "authors": [
          "Jesse Geneson"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Schinzel Sequences We",
        "Asymptotic Tightness",
        "Pigeonhole Bound",
        "Order Davenport",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.994250"
    },
    {
      "id": "arxiv-2602.15372v1",
      "title": "Self-dual Stacked Quantum Low-Density Parity-Check Codes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15372v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantum low-density parity-check (qLDPC) codes are promising candidates for fault-tolerant quantum computation due to their high encoding rates and distances. However, implementing logical operations using qLDPC codes presents significant challenges. Previous research has demonstrated that self-dual qLDPC codes facilitate the implementation of transversal Clifford gates. Here we introduce a method for constructing self-dual qLDPC codes by stacking non-self-dual qLDPC codes. Leveraging this methodology, we develop double-chain bicycle codes, double-layer bivariate bicycle (BB) codes, double-layer twisted BB codes, and double-layer reflection codes, many of which exhibit favorable code parameters. Additionally, we conduct numerical calculations to assess the performance of these codes as quantum memory under the circuit-level noise model, revealing that the logical failure rate can be significantly reduced with high pseudo-thresholds.",
        "keywords": [
          "quant-ph",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15372v1",
        "authors": [
          "Ze-Chuan Liu",
          "Chong-Yuan Xu",
          "Yong Xu"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Check Codes Quantum",
        "Stacked Quantum Low",
        "Density Parity",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.994580"
    },
    {
      "id": "arxiv-2602.15341v1",
      "title": "Testing Monotonicity of Real-Valued Functions on DAGs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15341v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study monotonicity testing of real-valued functions on directed acyclic graphs (DAGs) with $n$ vertices. For every constant $δ>0$, we prove a $Ω(n^{1/2-δ}/\\sqrt{\\varepsilon})$ lower bound against non-adaptive two-sided testers on DAGs, nearly matching the classical $O(\\sqrt{n/\\varepsilon})$-query upper bound. For constant $\\varepsilon$, we also prove an $Ω(\\sqrt n)$ lower bound for randomized adaptive one-sided testers on explicit bipartite DAGs, whereas previously only an $Ω(\\log n)$ lower bound was known. A key technical ingredient in both lower bounds is positive-matching Ruzsa--Szemerédi families. On the algorithmic side, we give simple non-adaptive one-sided testers with query complexity $O(\\sqrt{m\\,\\ell}/(\\varepsilon n))$ and $O(m^{1/3}/\\varepsilon^{2/3})$, where $m$ is the number of edges in the transitive reduction and $\\ell$ is the number of edges in the transitive closure. For constant $\\varepsilon>0$, these improve over the previous $O(\\sqrt{n/\\varepsilon})$ bound when $m\\ell=o(n^3)$ and $m=o(n^{3/2})$, respectively.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15341v1",
        "authors": [
          "Yuichi Yoshida"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Testing Monotonicity",
        "Valued Functions",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.995314"
    },
    {
      "id": "arxiv-2602.15314v1",
      "title": "Revisiting the Sparse Matrix Compression Problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15314v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The sparse matrix compression problem asks for a one-dimensional representation of a binary $n \\times \\ell$ matrix, formed by an integer array of row indices and a shift function for each row, such that accessing a matrix entry is possible in constant time by consulting this representation. It has been shown that the decision problem for finding an integer array of length $\\ell+ρ$ or restricting the shift function up to values of $ρ$ is NP-complete (cf. the textbook of Garey and Johnson). As a practical heuristic, a greedy algorithm has been proposed to shift the $i$-th row until it forms a solution with its predecessor rows. Despite that this greedy algorithm is cherished for its good approximation in practice, we show that it actually exhibits an approximation ratio of $Θ(\\sqrt{\\ell+ρ})$. We give further hardness results for parameterizations such as the number of distinct rows or the maximum number of non-zero entries per row. Finally, we devise a DP-algorithm that solves the problem for double-logarithmic matrix widths or logarithmic widths for further restrictions. We study all these findings also under a new perspective by introducing a variant of the problem, where we wish to minimize the length of the resulting integer array by trimming the non-zero borders, which has not been studied in the literature before but has practical motivations.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15314v1",
        "authors": [
          "Vincent Jugé",
          "Dominik Köppl",
          "Vincent Limouzy",
          "Andrea Marino",
          "Jannik Olblich"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sparse Matrix Compression Problem",
        "Act",
        "UN",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.996334"
    },
    {
      "id": "arxiv-2602.15311v1",
      "title": "Near-real-time Solutions for Online String Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15311v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Based on the Breslauer-Italiano online suffix tree construction algorithm (2013) with double logarithmic worst-case guarantees on the update time per letter, we develop near-real-time algorithms for several classical problems on strings, including the computation of the longest repeating suffix array, the (reversed) Lempel-Ziv 77 factorization, and the maintenance of minimal unique substrings, all in an online manner. Our solutions improve over the best known running times for these problems in terms of the worst-case time per letter, for which we achieve a poly-log-logarithmic time complexity, within a linear space. Best known results for these problems require a poly-logarithmic time complexity per letter or only provide amortized complexity bounds. As a result of independent interest, we give conversions between the longest previous factor array and the longest repeating suffix array in space and time bounds based on their irreducible representations, which can have sizes sublinear in the length of the input string.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15311v1",
        "authors": [
          "Dominik Köppl",
          "Gregory Kucherov"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Online String Problems Based",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.996710"
    },
    {
      "id": "arxiv-2602.15285v1",
      "title": "Tensor Decomposition for Non-Clifford Gate Minimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15285v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Fault-tolerant quantum computation requires minimizing non-Clifford gates, whose implementation via magic state distillation dominates the resource costs. While $T$-count minimization is well-studied, dedicated $CCZ$ factories shift the natural target to direct Toffoli minimization. We develop algebraic methods for this problem, building on a connection between Toffoli count and tensor decomposition over $\\mathbb{F}_2$. On standard benchmarks, these methods match or improve all reported results for both Toffoli and $T$-count, with most circuits completing in under a minute on a single CPU instead of thousands of TPUs used by prior work.",
        "keywords": [
          "quant-ph",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15285v1",
        "authors": [
          "Kirill Khoruzhii",
          "Patrick Gelß",
          "Sebastian Pokutta"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Clifford Gate Minimization Fault",
        "Tensor Decomposition",
        "Standard",
        "WHO",
        "CPU",
        "CCZ",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:08.996951"
    },
    {
      "id": "arxiv-2602.15773v1",
      "title": "Efficient Densest Flow Queries in Transaction Flow Networks (Complete Version)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15773v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Transaction flow networks are crucial in detecting illicit activities such as wash trading, credit card fraud, cashback arbitrage fraud, and money laundering. \\revise{Our collaborator, Grab, a leader in digital payments in Southeast Asia, faces increasingly sophisticated fraud patterns in its transaction flow networks. In industry settings such as Grab's fraud detection pipeline, identifying fraudulent activities heavily relies on detecting dense flows within transaction networks. Motivated by this practical foundation,} we propose the \\emph{\\(S\\)-\\(T\\) densest flow} (\\SDMF{}) query. Given a transaction flow network \\( G \\), a source set \\( \\Src \\), a sink set \\( \\Dst \\), and a size threshold \\( k \\), the query outputs subsets \\( \\Src' \\subseteq \\Src \\) and \\( \\Dst' \\subseteq \\Dst \\) such that the maximum flow from \\( \\Src' \\) to \\( \\Dst' \\) is densest, with \\(|\\Src' \\cup \\Dst'| \\geq k\\). Recognizing the NP-hardness of the \\SDMF{} query, we develop an efficient divide-and-conquer algorithm, CONAN. \\revise{Driven by industry needs for scalable and efficient solutions}, we introduce an approximate flow-peeling algorithm to optimize the performance of CONAN, enhancing its efficiency in processing large transaction networks. \\revise{Our approach has been integrated into Grab's fraud detection scenario, resulting in significant improvements in identifying fraudulent activities.} Experiments show that CONAN outperforms baseline methods by up to three orders of magnitude in runtime and more effectively identifies the densest flows. We showcase CONAN's applications in fraud detection on transaction flow networks from our industry partner, Grab, and on non-fungible tokens (NFTs).",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15773v1",
        "authors": [
          "Jiaxin Jiang",
          "Yunxiang Zhao",
          "Lyu Xu",
          "Byron Choi",
          "Bingsheng He"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Densest Flow Queries",
        "Transaction Flow Networks",
        "Complete Version",
        "Southeast Asia",
        "CONAN",
        "SDMF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.388994"
    },
    {
      "id": "arxiv-2602.15766v1",
      "title": "TAC: Timestamped Audio Captioning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15766v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large Audio Language Models struggle to disentangle overlapping events in complex acoustic scenes, yielding temporally inconsistent captions and frequent hallucinations. We introduce Timestamped Audio Captioner (TAC), a model that produces temporally grounded audio descriptions at varying degrees of detail and resolution. TAC is trained with a synthetic data pipeline that constructs challenging and dynamic mixtures from real-world audio sources, enabling robust learning under realistic polyphonic conditions. Across event detection and dense captioning, TAC outperforms all competing methods, with a low hallucination rate and accurate temporal grounding. We also introduce TAC-V, an audio-visual pipeline to generate semantically rich audio-visual descriptions. We then show that TAC and TAC-V serves as a \"semantic bridge\" for a text-only reasoner: a simple TAC$\\rightarrow$LLM and TAC-V$\\rightarrow$LLM cascade achieves state-of-the-art scores on benchmarks for both audio (MMAU-Pro, MMSU, MMAR) and audio-visual (DailyOmni, VideoHolmes) understanding and reasoning respectively.",
        "keywords": [
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15766v1",
        "authors": [
          "Sonal Kumar",
          "Prem Seetharaman",
          "Ke Chen",
          "Oriol Nieto",
          "Jiaqi Su"
        ],
        "arxiv_categories": [
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Timestamped Audio Captioning Large",
        "Timestamped Audio Captioner",
        "Audio Language Models",
        "MMSU",
        "MMAR",
        "MMAU",
        "TAC",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.389343"
    },
    {
      "id": "arxiv-2602.15749v1",
      "title": "A Generative-First Neural Audio Autoencoder",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15749v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Neural autoencoders underpin generative models. Practical, large-scale use of neural autoencoders for generative modeling necessitates fast encoding, low latent rates, and a single model across representations. Existing approaches are reconstruction-first: they incur high latent rates, slow encoding, and separate architectures for discrete vs. continuous latents and for different audio channel formats, hindering workflows from preprocessing to inference conditioning. We introduce a generative-first architecture for audio autoencoding that increases temporal downsampling from 2048x to 3360x and supports continuous and discrete representations and common audio channel formats in one model. By balancing compression, quality, and speed, it delivers 10x faster encoding, 1.6x lower rates, and eliminates channel-format-specific variants while maintaining competitive reconstruction quality. This enables applications previously constrained by processing costs: a 60-second mono signal compresses to 788 tokens, making generative modeling more tractable.",
        "keywords": [
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15749v1",
        "authors": [
          "Jonah Casebeer",
          "Ge Zhu",
          "Zhepei Wang",
          "Nicholas J. Bryan"
        ],
        "arxiv_categories": [
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "First Neural Audio Autoencoder",
        "EPA",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.389644"
    },
    {
      "id": "arxiv-2602.15739v1",
      "title": "Hierarchical Decomposition of Separable Workflow-Nets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15739v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Partially Ordered Workflow Language (POWL) has recently emerged as a process modeling notation, offering strong quality guarantees and high expressiveness. While early versions of POWL relied on strict block-structured operators for choices and loops, the language has recently evolved into POWL 2.0, introducing choice graphs to enable the modeling of non-block-structured decisions and cycles. To bridge the gap between the theoretical advantages of POWL and the practical need for compatibility with established notations, robust model transformations are required. This paper presents a novel algorithm for transforming safe and sound workflow nets (WF-nets) into equivalent POWL 2.0 models. The algorithm recursively identifies structural patterns within the WF-net and translates them into their POWL representation. Unlike the previous approach that required separate detection strategies for exclusive choices and loops, our new algorithm utilizes choice graphs to capture generalized decision and cyclic patterns. We formally prove the correctness of our approach, showing that the generated POWL model preserves the language of the input WF-net. Furthermore, we prove the completeness of our algorithm on the class of separable WF-nets, which corresponds to nets constructed via the hierarchical nesting of state machines and marked graphs. We evaluate our algorithm on large-scale process models to demonstrate its high scalability. Furthermore, to test its practical expressiveness, we applied it to a benchmark of 1,493 industrial and synthetic process models. Our algorithm successfully transformed all models in this benchmark, suggesting that POWL 2.0's expressive power is generally sufficient to capture the complex logic found in real-world business processes. This work paves the way for broader adoption of POWL in practical process analysis and improvement applications.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15739v1",
        "authors": [
          "Humam Kourani",
          "Gyunam Park",
          "Wil M. P. van der Aalst"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hierarchical Decomposition",
        "Separable Workflow",
        "Workflow Language",
        "POWL",
        "EPA",
        "NSF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.390132"
    },
    {
      "id": "arxiv-2602.15682v1",
      "title": "The Next Paradigm Is User-Centric Agent, Not Platform-Centric Service",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15682v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Modern digital services have evolved into indispensable tools, driving the present large-scale information systems. Yet, the prevailing platform-centric model, where services are optimized for platform-driven metrics such as engagement and conversion, often fails to align with users' true needs. While platform technologies have advanced significantly-especially with the integration of large language models (LLMs)-we argue that improvements in platform service quality do not necessarily translate to genuine user benefit. Instead, platform-centric services prioritize provider objectives over user welfare, resulting in conflicts against user interests. This paper argues that the future of digital services should shift from a platform-centric to a user-centric agent. These user-centric agents prioritize privacy, align with user-defined goals, and grant users control over their preferences and actions. With advancements in LLMs and on-device intelligence, the realization of this vision is now feasible. This paper explores the opportunities and challenges in transitioning to user-centric intelligence, presents a practical device-cloud pipeline for its implementation, and discusses the necessary governance and ecosystem structures for its adoption.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15682v1",
        "authors": [
          "Luankang Zhang",
          "Hang Lv",
          "Qiushi Pan",
          "Kefen Wang",
          "Yonghao Huang"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Centric Service Modern",
        "Centric Agent",
        "Not Platform",
        "Intel",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.390617"
    },
    {
      "id": "arxiv-2602.15681v1",
      "title": "A universal LLM Framework for General Query Refinements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15681v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Numerous studies have explored the SQL query refinement problem, where the objective is to minimally modify an input query so that it satisfies a specified set of constraints. However, these works typically target restricted classes of queries or constraints. We present OmniTune, a general framework for refining arbitrary SQL queries using LLM-based optimization by prompting (OPRO). OmniTune employs a two-step OPRO scheme that explores promising refinement subspaces and samples candidates within them, supported by concise history and skyline summaries for effective feedback. Experiments on a comprehensive benchmark demonstrate that OmniTune handles both previously studied refinement tasks and more complex scenarios beyond the scope of existing solutions.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15681v1",
        "authors": [
          "Eldar Hacohen",
          "Yuval Moskovitch",
          "Amit Somech"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "General Query Refinements Numerous",
        "Framework",
        "OPRO",
        "SQL",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.390853"
    },
    {
      "id": "arxiv-2602.15659v1",
      "title": "Can Recommender Systems Teach Themselves? A Recursive Self-Improving Framework with Fidelity Control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15659v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The scarcity of high-quality training data presents a fundamental bottleneck to scaling machine learning models. This challenge is particularly acute in recommendation systems, where extreme sparsity in user interactions leads to rugged optimization landscapes and poor generalization. We propose the Recursive Self-Improving Recommendation (RSIR) framework, a paradigm in which a model bootstraps its own performance without reliance on external data or teacher models. RSIR operates in a closed loop: the current model generates plausible user interaction sequences, a fidelity-based quality control mechanism filters them for consistency with user's approximate preference manifold, and a successor model is augmented on the enriched dataset. Our theoretical analysis shows that RSIR acts as a data-driven implicit regularizer, smoothing the optimization landscape and guiding models toward more robust solutions. Empirically, RSIR yields consistent, cumulative gains across multiple benchmarks and architectures. Notably, even smaller models benefit, and weak models can generate effective training curricula for stronger ones. These results demonstrate that recursive self-improvement is a general, model-agnostic approach to overcoming data sparsity, suggesting a scalable path forward for recommender systems and beyond. Our anonymized code is available at https://anonymous.4open.science/r/RSIR-7C5B .",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15659v1",
        "authors": [
          "Luankang Zhang",
          "Hao Wang",
          "Zhongzhou Liu",
          "Mingjia Yin",
          "Yonghao Huang"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Can Recommender Systems Teach",
        "Improving Recommendation",
        "Improving Framework",
        "Machine Learning",
        "Recursive Self",
        "Framework",
        "RSIR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.391255"
    },
    {
      "id": "arxiv-2602.15585v1",
      "title": "Optimal detection of planted stars via a random energy model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15585v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the problem of detecting a planted star in the Erd{ő}s--R{é}nyi random graph $G(n,m)$, formulated as a hypothesis test. We determine the scaling window for critical detection in $m$ in terms of the star size, and characterize the asymptotic total variation distance between the null and alternative hypotheses in this window. In the course of the proofs we show a condensation phase transition in the likelihood ratio that closely resembles that of the random energy model from spin glass theory.",
        "keywords": [
          "math.ST",
          "cs.IT",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15585v1",
        "authors": [
          "Ijay Narang",
          "Will Perkins",
          "Timothy L. H. Wee"
        ],
        "arxiv_categories": [
          "math.ST",
          "cs.IT",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wind",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.391747"
    },
    {
      "id": "arxiv-2602.15554v1",
      "title": "Efficient Road Renovation Scheduling under Uncertainty using Lower Bound Pruning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15554v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Urban infrastructure degrades over time, necessitating periodic renovation to maintain functionality and safety. When renovation is delayed beyond the infrastructure's remaining lifespan, costly emergency interventions become necessary to prevent failure. Decision makers must therefore balance expected emergency intervention costs against traffic congestion impacts. We formalize this trade-off as a road network maintenance scheduling problem with uncertain deadlines, which presents optimization challenges including computationally expensive evaluation and an exponentially growing solution space. To address these challenges, this paper contributes a hybrid optimization approach combining machine learning with genetic algorithms for large-scale infrastructure renovation scheduling under uncertainty. We formulate the problem as a bi-level multi-objective optimization problem that explicitly accounts for uncertain infrastructure lifespans through probabilistic failure models. We develop a progressive lower bound evaluation method that integrates machine learning surrogate models with a multi-objective genetic algorithm to improve solution quality by enabling more iterations within fixed computational budgets. We demonstrate the method's effectiveness on substantially larger problem instances (76 projects) than previously addressed in the literature, achieving statistically significant improvements across multiple performance metrics by increasing computational efficiency up to 40 times compared to standard approaches.",
        "keywords": [
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15554v1",
        "authors": [
          "Robbert Bosch",
          "Patricia Rogetzer",
          "Wouter van Heeswijk",
          "Martijn Mes"
        ],
        "arxiv_categories": [
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Road Renovation Scheduling",
        "Lower Bound Pruning Urban",
        "Machine Learning",
        "Standard",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.392155"
    },
    {
      "id": "arxiv-2602.15531v1",
      "title": "GenAI-LA: Generative AI and Learning Analytics Workshop (LAK 2026), April 27--May 1, 2026, Bergen, Norway",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15531v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the ScienceQA benchmark, spanning science, language, and social science across K-12 grade levels. For each question, one human-teacher explanation is provided and six are generated by LLM-simulated teacher roles. These roles are inspired by instructional styles and shortcomings observed in real educational practice and are instantiated via prompt engineering. We further propose a pedagogical risk rubric aligned with established educational standards, operationalizing five complementary risk dimensions: factual correctness, explanatory depth and completeness, focus and relevance, student-level appropriateness, and ideological bias. All explanations are annotated with binary risk labels through a semi-automatic process with expert teacher review. Finally, we present preliminary validation experiments to assess the suitability of EduEVAL-DB for evaluation. We benchmark a state-of-the-art education-oriented model (Gemini 2.5 Pro) against a lightweight local Llama 3.1 8B model and examine whether supervised fine-tuning on EduEVAL-DB supports pedagogical risk detection using models deployable on consumer hardware.",
        "keywords": [
          "cs.AI",
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15531v1",
        "authors": [
          "Javier Irigoyen",
          "Roberto Daza",
          "Aythami Morales",
          "Julian Fierrez",
          "Francisco Jurado"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Analytics Workshop",
        "Standard",
        "K-12",
        "LAK",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.392555"
    },
    {
      "id": "arxiv-2602.15519v1",
      "title": "Enroll-on-Wakeup: A First Comparative Study of Target Speech Extraction for Seamless Interaction in Real Noisy Human-Machine Dialogue Scenarios",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15519v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Target speech extraction (TSE) typically relies on pre-recorded high-quality enrollment speech, which disrupts user experience and limits feasibility in spontaneous interaction. In this paper, we propose Enroll-on-Wakeup (EoW), a novel framework where the wake-word segment, captured naturally during human-machine interaction, is automatically utilized as the enrollment reference. This eliminates the need for pre-collected speech to enable a seamless experience. We perform the first systematic study of EoW-TSE, evaluating advanced discriminative and generative models under real diverse acoustic conditions. Given the short and noisy nature of wake-word segments, we investigate enrollment augmentation using LLM-based TTS. Results show that while current TSE models face performance degradation in EoW-TSE, TTS-based assistance significantly enhances the listening experience, though gaps remain in speech recognition accuracy.",
        "keywords": [
          "eess.AS",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15519v1",
        "authors": [
          "Yiming Yang",
          "Guangyong Wang",
          "Haixin Guan",
          "Yanhua Long"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Dialogue Scenarios Target",
        "Target Speech Extraction",
        "First Comparative Study",
        "Seamless Interaction",
        "Real Noisy Human",
        "Framework",
        "TTS",
        "TSE",
        "MIT",
        "LLM",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.392857"
    },
    {
      "id": "arxiv-2602.15508v1",
      "title": "Eco-Amazon: Enriching E-commerce Datasets with Product Carbon Footprint for Sustainable Recommendations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15508v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In the era of responsible and sustainable AI, information retrieval and recommender systems must expand their scope beyond traditional accuracy metrics to incorporate environmental sustainability. However, this research line is severely limited by the lack of item-level environmental impact data in standard benchmarks. This paper introduces Eco-Amazon, a novel resource designed to bridge this gap. Our resource consists of an enriched version of three widely used Amazon datasets (i.e., Home, Clothing, and Electronics) augmented with Product Carbon Footprint (PCF) metadata. CO2e emission scores were generated using a zero-shot framework that leverages Large Language Models (LLMs) to estimate item-level PCF based on product attributes. Our contribution is three-fold: (i) the release of the Eco-Amazon datasets, enriching item metadata with PCF signals; (ii) the LLM-based PCF estimation script, which allows researchers to enrich any product catalogue and reproduce our results; (iii) a use case demonstrating how PCF estimates can be exploited to promote more sustainable products. By providing these environmental signals, Eco-Amazon enables the community to develop, benchmark, and evaluate the next generation of sustainable retrieval and recommendation models. Our resource is available at https://doi.org/10.5281/zenodo.18549130, while our source code is available at: http://github.com/giuspillo/EcoAmazon/.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15508v1",
        "authors": [
          "Giuseppe Spillo",
          "Allegra De Filippo",
          "Cataldo Musto",
          "Michela Milano",
          "Giovanni Semeraro"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sustainable Recommendations In",
        "Product Carbon Footprint",
        "Large Language Models",
        "Framework",
        "Standard",
        "Amazon",
        "Meta",
        "MIT",
        "LLM",
        "Act",
        "PCF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.393251"
    },
    {
      "id": "arxiv-2602.15505v1",
      "title": "Binge Watch: Reproducible Multimodal Benchmarks Datasets for Large-Scale Movie Recommendation on MovieLens-10M and 20M",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15505v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "With the growing interest in Multimodal Recommender Systems (MRSs), collecting high-quality datasets provided with multimedia side information (text, images, audio, video) has become a fundamental step. However, most of the current literature in the field relies on small- or medium-scale datasets that are either not publicly released or built using undocumented processes. In this paper, we aim to fill this gap by releasing M3L-10M and M3L-20M, two large-scale, reproducible, multimodal datasets for the movie domain, obtained by enriching with multimodal features the popular MovieLens-10M and MovieLens-20M, respectively. By following a fully documented pipeline, we collect movie plots, posters, and trailers, from which textual, visual, acoustic, and video features are extracted using several state-of-the-art encoders. We publicly release mappings to download the original raw data, the extracted features, and the complete datasets in multiple formats, fostering reproducibility and advancing the field of MRSs. In addition, we conduct qualitative and quantitative analyses that showcase our datasets across several perspectives. This work represents a foundational step to ensure reproducibility and replicability in the large-scale, multimodal movie recommendation domain. Our resource can be fully accessed at the following link: https://zenodo.org/records/18499145, while the source code is accessible at https://github.com/giuspillo/M3L_10M_20M.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15505v1",
        "authors": [
          "Giuseppe Spillo",
          "Alessandro Petruzzelli",
          "Cataldo Musto",
          "Marco de Gemmis",
          "Pasquale Lops"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reproducible Multimodal Benchmarks Datasets",
        "Multimodal Recommender Systems",
        "Scale Movie Recommendation",
        "Binge Watch",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.393661"
    },
    {
      "id": "arxiv-2602.15491v1",
      "title": "The Equalizer: Introducing Shape-Gain Decomposition in Neural Audio Codecs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15491v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Neural audio codecs (NACs) typically encode the short-term energy (gain) and normalized structure (shape) of speech/audio signals jointly within the same latent space. As a result, they are poorly robust to a global variation of the input signal level in the sense that such variation has strong influence on the embedding vectors at the output of the encoder and their quantization. This methodology is inherently inefficient, leading to codebook redundancy and suboptimal bitrate-distortion performance. To address these limitations, we propose to introduce shape-gain decomposition, widely used in classical speech/audio coding, into the NAC framework. The principle of the proposed Equalizer methodology is to decompose the input signal -- before the NAC encoder -- into gain and normalized shape vector on a short-term basis. The shape vector is processed by the NAC, while the gain is quantized with scalar quantization and transmitted separately. The output (decoded) signal is reconstructed from the normalized output of the NAC and the quantized gain. Our experiments conducted on speech signals show that this general methodology, easily applicable to any NAC, enables a substantial gain in bitrate-distortion performance, as well as a massive reduction in complexity.",
        "keywords": [
          "cs.SD",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15491v1",
        "authors": [
          "Samir Sadok",
          "Laurent Girin",
          "Xavier Alameda-Pineda"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Audio Codecs Neural",
        "Gain Decomposition",
        "Introducing Shape",
        "Framework",
        "EPA",
        "MIT",
        "NAC",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.394016"
    },
    {
      "id": "arxiv-2602.15488v1",
      "title": "Efficient Approximate Nearest Neighbor Search under Multi-Attribute Range Filter",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15488v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nearest neighbor search on high-dimensional vectors is fundamental in modern AI and database systems. In many real-world applications, queries involve constraints on multiple numeric attributes, giving rise to range-filtering approximate nearest neighbor search (RFANNS). While there exist RFANNS indexes for single-attribute range predicates, extending them to the multi-attribute setting is nontrivial and often ineffective. In this paper, we propose KHI, an index for multi-attribute RFANNS that combines an attribute-space partitioning tree with HNSW graphs attached to tree nodes. A skew-aware splitting rule bounds the tree height by $O(\\log n)$, and queries are answered by routing through the tree and running greedy search on the HNSW graphs. Experiments on four real-world datasets show that KHI consistently achieves high query throughput while maintaining high recall. Compared with the state-of-the-art RFANNS baseline, KHI improves QPS by $2.46\\times$ on average and up to $16.22\\times$ on the hard dataset, with larger gains for smaller selectivity, larger $k$, and higher predicate cardinality.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15488v1",
        "authors": [
          "Yuanhang Yu",
          "Dawei Cheng",
          "Ying Zhang",
          "Lu Qin",
          "Wenjie Zhang"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Approximate Nearest Neighbor",
        "Attribute Range Filter Nearest",
        "RFANNS",
        "HNSW",
        "KHI",
        "QPS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.394333"
    },
    {
      "id": "arxiv-2602.15458v1",
      "title": "A Universal Neural Receiver that Learns at the Speed of Wireless",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15458v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Today we design wireless networks using mathematical models that govern communication in different propagation environments. We rely on measurement campaigns to deliver parametrized propagation models, and on the 3GPP standards process to optimize model-based performance, but as wireless networks become more complex this model-based approach is losing ground. Mobile Network Operators (MNOs) are counting on Artificial Intelligence (AI) to transform wireless by increasing spectral efficiency, reducing signaling overhead, and enabling continuous network innovation through software upgrades. They may also be interested in new use cases like integrated sensing and communications (ISAC). All we need is an AI-native physical layer, so why not simply tailor the offline AI algorithms that have revolutionized image and natural language processing to the wireless domain? We argue that these algorithms rely on off-line training that is precluded by the sub-millisecond speeds at which the wireless interference environment changes. We present an alternative architecture, a universal neural receiver based on convolution, which governs transmit and receive signal processing of any signal in any part of the wireless spectrum. Our neural receiver is designed to invert convolution, and we separate the question of which convolution to invert from the actual deconvolution. The neural network that performs deconvolution is very simple, and we configure this network by setting weights based on domain knowledge. By telling our neural network what we know, we avoid extensive offline training. By developing a universal receiver, we hope to simplify discussions about the proper choice of waveform for different use cases in the international standards. Since the receiver architecture is largely independent of technologies introduced at the base station, we hope to increase the rate of innovation in wireless.",
        "keywords": [
          "cs.IT",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15458v1",
        "authors": [
          "Lingjia Liu",
          "Lizhong Zheng",
          "Yang Yi",
          "Robert Calderbank"
        ],
        "arxiv_categories": [
          "cs.IT",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universal Neural Receiver",
        "Mobile Network Operators",
        "Artificial Intelligence",
        "Neural Network",
        "Wireless Today",
        "Standard",
        "Intel",
        "ISAC",
        "EPA",
        "NSF",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.394773"
    },
    {
      "id": "arxiv-2602.15423v1",
      "title": "GaiaFlow: Semantic-Guided Diffusion Tuning for Carbon-Frugal Search",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15423v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "As the burgeoning power requirements of sophisticated neural architectures escalate, the information retrieval community has recognized ecological sustainability as a pivotal priority that necessitates a fundamental paradigm shift in model design. While contemporary neural rankers have attained unprecedented accuracy, the substantial environmental externalities associated with their computational intensity often remain overlooked in large-scale deployments. We present GaiaFlow, an innovative framework engineered to facilitate carbon-frugal search by operationalizing semantic-guided diffusion tuning. Our methodology orchestrates the convergence of retrieval-guided Langevin dynamics and a hardware-independent performance modeling strategy to optimize the trade-off between search precision and environmental preservation. By incorporating adaptive early exit protocols and precision-aware quantized inference, the proposed architecture significantly mitigates operational carbon footprints while maintaining robust retrieval quality across heterogeneous computing infrastructures. Extensive experimental evaluations demonstrate that GaiaFlow achieves a superior equilibrium between effectiveness and energy efficiency, offering a scalable and sustainable pathway for next-generation neural search systems.",
        "keywords": [
          "cs.IR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15423v1",
        "authors": [
          "Rong Fu",
          "Wenxin Zhang",
          "Jia Yee Tan",
          "Chunlei Meng",
          "Shuo Yin"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guided Diffusion Tuning",
        "Frugal Search As",
        "Framework",
        "Protocol",
        "Fusion",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.395102"
    },
    {
      "id": "arxiv-2602.15413v1",
      "title": "StatCounter: A Longitudinal Study of a Portable Scholarly Metric Display",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15413v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study explores a handheld, battery-operated e-ink device displaying Google Scholar citation statistics. The StatCounter places academic metrics into the flow of daily life rather than a desktop context. The work draws on a first-person, longitudinal auto-ethnographic inquiry examining how constant access to scholarly metrics influences motivation, attention, reflection, and emotional responses across work and non-work settings. The ambient proximity and pervasive availability of scholarly metrics invites frequent micro-checks, short reflective pauses, but also introduces moments of second-guessing when numbers drop or stagnate. Carrying the device prompts new narratives about academic identity, including a sense of companionship during travel and periods away from the office. Over time, the presence of the device turns metrics from an occasional reference into an ambient background of scholarly life. The study contributes insight into how situated, embodied access to academic metrics reshapes their meaning, and frames opportunities for designing tools that engage with scholarly evaluation in reflective ways.",
        "keywords": [
          "cs.HC",
          "cs.DL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15413v1",
        "authors": [
          "Jonas Oppenlaender"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.DL"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Portable Scholarly Metric Display",
        "Longitudinal Study",
        "Google Scholar",
        "Battery",
        "Google",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:14.395387"
    },
    {
      "id": "arxiv-2602.15381v1",
      "title": "Automatic Funny Scene Extraction from Long-form Cinematic Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15381v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Automatically extracting engaging and high-quality humorous scenes from cinematic titles is pivotal for creating captivating video previews and snackable content, boosting user engagement on streaming platforms. Long-form cinematic titles, with their extended duration and complex narratives, challenge scene localization, while humor's reliance on diverse modalities and its nuanced style add further complexity. This paper introduces an end-to-end system for automatically identifying and ranking humorous scenes from long-form cinematic titles, featuring shot detection, multimodal scene localization, and humor tagging optimized for cinematic content. Key innovations include a novel scene segmentation approach combining visual and textual cues, improved shot representations via guided triplet mining, and a multimodal humor tagging framework leveraging both audio and text. Our system achieves an 18.3% AP improvement over state-of-the-art scene detection on the OVSD dataset and an F1 score of 0.834 for detecting humor in long text. Extensive evaluations across five cinematic titles demonstrate 87% of clips extracted by our pipeline are intended to be funny, while 98% of scenes are accurately localized. With successful generalization to trailers, these results showcase the pipeline's potential to enhance content creation workflows, improve user engagement, and streamline snackable content generation for diverse cinematic media formats.",
        "keywords": [
          "cs.IR",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15381v1",
        "authors": [
          "Sibendu Paul",
          "Haotian Jiang",
          "Caren Chen"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Automatic Funny Scene Extraction",
        "Cinematic Videos Automatically",
        "Framework",
        "OVSD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.395733"
    },
    {
      "id": "arxiv-2602.15360v1",
      "title": "Crane: An Accurate and Scalable Neural Sketch for Graph Stream Summarization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15360v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Graph streams are rapidly evolving sequences of edges that convey continuously changing relationships among entities, playing a crucial role in domains such as networking, finance, and cybersecurity. Their massive scale and high dynamism make obtaining accurate statistics challenging with limited memory constraints. Traditional methods summarize graph streams through hand-crafted sketches, while recent studies have begun to replace these sketches with neural counterparts to improve adaptability and accuracy. However, this shift faces a major challenge: under limited memory, dominant frequent items tend to overshadow rare ones, hindering the neural network's ability to recover accurate statistics. To address this, we propose Crane, a hierarchical neural sketch architecture for graph stream summarization. Crane uses a hierarchical carry mechanism that automatically elevates frequent items to higher memory layers, reducing interference between frequent and infrequent items within the same layer. To better accommodate real-world deployment, Crane further adopts an adaptive memory expansion strategy that dynamically adds new layers once the occupancy of the top layer exceeds a threshold, enabling scalability across diverse data magnitudes. Extensive experiments on various datasets ranging from 20K to 60M edges demonstrate that Crane reduces estimation error by roughly 10x compared to state-of-the-art methods.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15360v1",
        "authors": [
          "Boyan Wang",
          "Zhuochen Fan",
          "Dayu Wang",
          "Fangcheng Fu",
          "Zeyu Luan"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Graph Stream Summarization Graph",
        "Scalable Neural Sketch",
        "Neural Network",
        "An Accurate",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.396079"
    },
    {
      "id": "arxiv-2602.15359v1",
      "title": "Semantics-Aware Denoising: A PLM-Guided Sample Reweighting Strategy for Robust Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15359v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Implicit feedback, such as user clicks, serves as the primary data source for modern recommender systems. However, click interactions inherently contain substantial noise, including accidental clicks, clickbait-induced interactions, and exploratory browsing behaviors that do not reflect genuine user preferences. Training recommendation models with such noisy positive samples leads to degraded prediction accuracy and unreliable recommendations. In this paper, we propose SAID (Semantics-Aware Implicit Denoising), a simple yet effective framework that leverages semantic consistency between user interests and item content to identify and downweight potentially noisy interactions. Our approach constructs textual user interest profiles from historical behaviors and computes semantic similarity with target item descriptions using pre-trained language model (PLM) based text encoders. The similarity scores are then transformed into sample weights that modulate the training loss, effectively reducing the impact of semantically inconsistent clicks. Unlike existing denoising methods that require complex auxiliary networks or multi-stage training procedures, SAID only modifies the loss function while keeping the backbone recommendation model unchanged. Extensive experiments on two real-world datasets demonstrate that SAID consistently improves recommendation performance, achieving up to 2.2% relative improvement in AUC over strong baselines, with particularly notable robustness under high noise conditions.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15359v1",
        "authors": [
          "Xikai Yang",
          "Yang Wang",
          "Yilin Li",
          "Sebastian Sun"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guided Sample Reweighting Strategy",
        "Robust Recommendation Implicit",
        "Aware Implicit Denoising",
        "Aware Denoising",
        "Framework",
        "SAID",
        "AUC",
        "PLM",
        "NSF",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.396442"
    },
    {
      "id": "arxiv-2602.15335v1",
      "title": "Corrected-Inverse-Gaussian First-Hitting-Time Modeling for Molecular Communication Under Time-Varying Drift",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15335v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper develops a tractable analytical channel model for first-hitting-time molecular communication systems under time-varying drift. While existing studies of nonstationary transport rely primarily on numerical solutions of advection--diffusion equations or parametric impulse-response fitting, they do not provide a closed-form description of trajectory-level arrival dynamics at absorbing boundaries. By adopting a change-of-measure formulation, we reveal a structural decomposition of the first-hitting-time density into a cumulative-drift displacement term and a stochastic boundary-flux modulation factor. This leads to an explicit analytical expression for the Corrected-Inverse-Gaussian (C-IG) density, extending the classical IG model to strongly nonstationary drift conditions while preserving constant-complexity evaluation. High-precision Monte Carlo simulations under both smooth pulsatile and abrupt switching drift profiles confirm that the proposed model accurately captures complex transport phenomena, including phase modulation, multi-pulse dispersion, and transient backflow. The resulting framework provides a physics-informed, computationally efficient channel model suitable for system-level analysis and receiver design in dynamic biological and molecular communication environments.",
        "keywords": [
          "cs.IT",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15335v1",
        "authors": [
          "Yen-Chi Lee"
        ],
        "arxiv_categories": [
          "cs.IT",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Molecular Communication Under Time",
        "Gaussian First",
        "Time Modeling",
        "Monte Carlo",
        "Framework",
        "Fusion",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.396765"
    },
    {
      "id": "arxiv-2602.15307v1",
      "title": "What Do Neurons Listen To? A Neuron-level Dissection of a General-purpose Audio Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15307v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we analyze the internal representations of a general-purpose audio self-supervised learning (SSL) model from a neuron-level perspective. Despite their strong empirical performance as feature extractors, the internal mechanisms underlying the robust generalization of SSL audio models remain unclear. Drawing on the framework of mechanistic interpretability, we identify and examine class-specific neurons by analyzing conditional activation patterns across diverse tasks. Our analysis reveals that SSL models foster the emergence of class-specific neurons that provide extensive coverage across novel task classes. These neurons exhibit shared responses across different semantic categories and acoustic similarities, such as speech attributes and musical pitch. We also confirm that these neurons have a functional impact on classification performance. To our knowledge, this is the first systematic neuron-level analysis of a general-purpose audio SSL model, providing new insights into its internal representation.",
        "keywords": [
          "eess.AS",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15307v1",
        "authors": [
          "Takao Kawamura",
          "Daisuke Niizumi",
          "Nobutaka Ono"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "What Do Neurons Listen",
        "Audio Model In",
        "Framework",
        "NIST",
        "SSL",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.397030"
    },
    {
      "id": "arxiv-2602.15303v1",
      "title": "On the Entropy of General Mixture Distributions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15303v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Mixture distributions are a workhorse model for multimodal data in information theory, signal processing, and machine learning. Yet even when each component density is simple, the differential entropy of the mixture is notoriously hard to compute because the mixture couples a logarithm with a sum. This paper develops a deterministic, closed-form toolkit for bounding and accurately approximating mixture entropy directly from component parameters. Our starting point is an information-theoretic channel viewpoint: the latent mixture label plays the role of an input, and the observation is the output. This viewpoint separates mixture entropy into an average within-component uncertainty plus an overlap term that quantifies how much the observation reveals about the hidden label. We then bound and approximate this overlap term using pairwise overlap integrals between component densities, yielding explicit expressions whenever these overlaps admit a closed form. A simple, family-dependent offset corrects the systematic bias of the Jensen overlap bound and is calibrated to be exact in the two limiting regimes of complete overlap and near-perfect separation. A final clipping step guarantees that the estimate always respects universal information-theoretic bounds. Closed-form specializations are provided for Gaussian, factorized Laplacian, uniform, and hybrid mixtures, and numerical experiments validate the resulting bounds and approximations across separation, dimension, number of components, and correlated covariances.",
        "keywords": [
          "cs.IT",
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15303v1",
        "authors": [
          "Namyoon Lee"
        ],
        "arxiv_categories": [
          "cs.IT",
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "General Mixture Distributions Mixture",
        "Machine Learning",
        "NIST",
        "EPA",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:14.397378"
    },
    {
      "id": "arxiv-2602.15784v1",
      "title": "Stability in Distance Preservation Games on Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15784v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a new class of network allocation games called graphical distance preservation games. Here, we are given a graph, called a topology, and a set of agents that need to be allocated to its vertices. Moreover, every agent has an ideal (and possibly different) distance in which to be from some of the other agents. Given an allocation of agents, each one of them suffers a cost that is the sum of the differences from the ideal distance for each agent in their subset. The goal is to decide whether there is a stable allocation of the agents, i.e., no agent would like to deviate from their location. Specifically, we consider three different stability notions: envy-freeness, swap stability, and jump stability. We perform a comprehensive study of the (parameterized) complexity of the problem in three different dimensions: the topology of the graph, the number of agents, and the structure of preferences of the agents.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15784v1",
        "authors": [
          "Argyrios Deligkas",
          "Eduard Eiben",
          "Tiger-Lily Goldsmith",
          "Dušan Knop",
          "Šimon Schierreich"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Distance Preservation Games",
        "Graphs We"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:19.837060"
    },
    {
      "id": "arxiv-2602.15745v1",
      "title": "Unraveling Entangled Feeds: Rethinking Social Media Design to Enhance User Well-being",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15745v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Social media platforms have rapidly adopted algorithmic curation with little consideration for the potential harm to users' mental well-being. We present findings from design workshops with 21 participants diagnosed with mental illness about their interactions with social media platforms. We find that users develop cause-and-effect explanations, or folk theories, to understand their experiences with algorithmic curation. These folk theories highlight a breakdown in algorithmic design that we explain using the framework of entanglement, a phenomenon where there is a disconnect between users' actions and platform outcomes on an emotional level. Participants' designs to address entanglement and mitigate harms centered on contextualizing their engagement and restoring explicit user control on social media. The conceptualization of entanglement and the resulting design recommendations have implications for social computing and recommender systems research, particularly in evaluating and designing social media platforms that support users' mental well-being.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15745v1",
        "authors": [
          "Ashlee Milton",
          "Dan Runningen",
          "Loren Terveen",
          "Harmanpreet Kaur",
          "Stevie Chancellor"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Rethinking Social Media Design",
        "Unraveling Entangled Feeds",
        "Enhance User Well",
        "Framework",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.837563"
    },
    {
      "id": "arxiv-2602.15736v1",
      "title": "SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15736v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs.",
        "keywords": [
          "cs.SI",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15736v1",
        "authors": [
          "Jorge Luiz Franco",
          "Thomas Peron",
          "Alcebiades Dal Col",
          "Fabiano Petronetto",
          "Filipe Alves Neto Verri"
        ],
        "arxiv_categories": [
          "cs.SI",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Unified Spectral Framework",
        "Hypergraphs Identifying",
        "Incidence Centrality",
        "Directed Networks",
        "Hodge Laplacians",
        "Edge Analysis",
        "Regulation",
        "Framework",
        "SVD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.838153"
    },
    {
      "id": "arxiv-2602.15638v1",
      "title": "Who Is Doing the Thinking? AI as a Dynamic Cognitive Partner: A Learner-Informed Framework",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15638v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Artificial intelligence is increasingly embedded in education, yet there remains a need to explain how students conceptualize AI's role in their thinking and learning. This study proposes a framework positioning AI as a dynamic cognitive partner whose function shifts across learning situations. Using qualitative analysis of written responses from 133 secondary students in Hong Kong following completion of an AI literacy course, we identified nine interrelated dimensions through which learners described AI as partnering with their cognition: conceptual scaffolding for difficult ideas; feedback and error detection; idea stimulation; cognitive organization; adaptive tutoring support; metacognitive monitoring support; task and cognitive load regulation; learning continuity beyond classroom boundaries; and explanation reframing through representational flexibility during moments of being stuck or overwhelmed. Across these dimensions, students distinguished between productive support that extends understanding and unproductive reliance that replaces cognitive effort, indicating situational awareness of when AI should and should not be used. Grounded in sociocultural theory, distributed cognition, self-regulated learning, and cognitive load perspectives, the framework clarifies how AI becomes integrated into learners' cognitive activity while illuminating the boundary between cognitive extension and substitution.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15638v1",
        "authors": [
          "C. K. Y Chan"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Informed Framework Artificial",
        "Dynamic Cognitive Partner",
        "Artificial Intelligence",
        "Who Is Doing",
        "Regulation",
        "Hong Kong",
        "Framework",
        "Intel",
        "Meta",
        "WHO",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.840047"
    },
    {
      "id": "arxiv-2602.15569v1",
      "title": "\"What Are You Doing?\": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15569v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Using a dual-task paradigm with an in-car voice assistant, we found that intermediate feedback significantly improved perceived speed, trust, and user experience while reducing task load - effects that held across varying task complexities and interaction contexts. Interviews further revealed user preferences for an adaptive approach: high initial transparency to establish trust, followed by progressively reducing verbosity as systems prove reliable, with adjustments based on task stakes and situational context. We translate our empirical findings into design implications for feedback timing and verbosity in agentic assistants, balancing transparency and efficiency.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15569v1",
        "authors": [
          "Johannes Kirmayr",
          "Raphael Wennmacher",
          "Khanh Huynh",
          "Lukas Stappen",
          "Elisabeth André"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Car Assistants During Multi",
        "Step Processing Agentic",
        "Intermediate Feedback",
        "What Are You Doing",
        "LLM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.840901"
    },
    {
      "id": "arxiv-2602.15566v1",
      "title": "Simultaneous Ordinal Maximin Share and Envy-Based Guarantees",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15566v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the fair allocation of indivisible goods among agents with additive valuations. The fair division literature has traditionally focused on two broad classes of fairness notions: envy-based notions and share-based notions. Within the share-based framework, most attention has been devoted to the maximin share (MMS) guarantee and its relaxations, while envy-based fairness has primarily centered on EFX and its relaxations. Recent work has shown the existence of allocations that simultaneously satisfy multiplicative approximate MMS and envy-based guarantees such as EF1 or EFX. Motivated by this line of research, we study for the first time the compatibility between ordinal approximations of MMS and envy-based fairness notions. In particular, we establish the existence of allocations satisfying the following combined guarantees: (i) simultaneous $1$-out-of-$\\lceil 3n/2 \\rceil$ MMS and EFX for ordered instances; (ii) simultaneous $1$-out-of-$\\lceil 3n/2 \\rceil$ MMS and EF1 for top-$n$ instances; and (iii) simultaneous $1$-out-of-$4\\lceil n/3 \\rceil$ MMS and EF1 for ordered instances.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15566v1",
        "authors": [
          "Hannaneh Akrami",
          "Timo Reichert"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Simultaneous Ordinal Maximin Share",
        "Based Guarantees We",
        "Framework",
        "EFX",
        "MMS",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:19.841298"
    },
    {
      "id": "arxiv-2602.15489v1",
      "title": "Reflecting on 1,000 Social Media Journeys: Generational Patterns in Platform Transition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15489v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Social media has billions of users, but we still do not fully understand why users prefer one platform over another. Establishing new platforms among already popular competitors is difficult. Prior research has richly documented people's experiences within individual platforms, yet situating those experiences within the entirety of a user's social media experience remains challenging. What platforms have people used, and why have they transitioned between them? We collected data from a quota-based sample of 1,000 U.S. participants. We introduce the concept of \\emph{Social Media Journeys} to study the entirety of their social media experiences systematically. We identify push and pull factors across the social media landscape. We also show how different generations adopted social media platforms based on personal needs. With this work, we advance HCI by moving towards holistic perspectives when discussing social media technology, offering new insights for platform design, governance, and regulation.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15489v1",
        "authors": [
          "Artur Solomonik",
          "Nicolas Ruiz",
          "Hendrik Heuer"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Platform Transition Social",
        "Social Media Journeys",
        "Generational Patterns",
        "Regulation",
        "Bill",
        "HCI",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.841703"
    },
    {
      "id": "arxiv-2602.15476v1",
      "title": "How to Detect Information Voids Using Longitudinal Data from Social Media and Web Searches",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15476v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The model of the attention economy, where content producers compete for the attention of users, relies on two key forces: information supply and demand. This study leverages the feedback loop between these forces to develop a method for detecting and quantifying information voids, i.e., periods in which little or no reliable information is available on a given topic. Using a case study on COVID-19 vaccines rollout in six European countries, and drawing on data from multiple platforms including Facebook, Google, Twitter, Wikipedia, and online news outlets, we examine how information voids emerge, persist and correlate with a decline in the proportion of high-quality information circulating online. By conceptualising information voids as a specific regime of information spreading, we also quantify their counterpart, information overabundance, which constitute a central component of the current definition of infodemic. We show that information voids are associated with a higher prevalence of misinformation, thus representing problematic hotspots in which individuals are more likely to be misled by low-quality online content. Overall, our findings provide empirical support for the inclusion of information voids in mechanistic explanations of misinformation emergence.",
        "keywords": [
          "cs.CY",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15476v1",
        "authors": [
          "Irene Scalco",
          "Francesco Gesualdo",
          "Roy Cerqueti",
          "Matteo Cinelli"
        ],
        "arxiv_categories": [
          "cs.CY",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Detect Information Voids Using",
        "Longitudinal Data",
        "Social Media",
        "COVID-19",
        "Vaccine",
        "Google",
        "COVID",
        "NIST",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.842213"
    },
    {
      "id": "arxiv-2602.15439v1",
      "title": "Algorithmic Approaches to Opinion Selection for Online Deliberation: A Comparative Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15439v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "During deliberation processes, mediators and facilitators typically need to select a small and representative set of opinions later used to produce digestible reports for stakeholders. In online deliberation platforms, algorithmic selection is increasingly used to automate this process. However, such automation is not without consequences. For instance, enforcing consensus-seeking algorithmic strategies can imply ignoring or flattening conflicting preferences, which may lead to erasing minority voices and reducing content diversity. More generally, across the variety of existing selection strategies (e.g., consensus, diversity), it remains unclear how each approach influences desired democratic criteria such as proportional representation. To address this gap, we benchmark several algorithmic approaches in this context. We also build on social choice theory to propose a novel algorithm that incorporates both diversity and a balanced notion of representation in the selection strategy. We find empirically that while no single strategy dominates across all democratic desiderata, our social-choice-inspired selection rule achieves the strongest trade-off between proportional representation and diversity.",
        "keywords": [
          "cs.CY",
          "cs.AI",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15439v1",
        "authors": [
          "Salim Hafid",
          "Manon Berriche",
          "Jean-Philippe Cointet"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.AI",
          "cs.SI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Comparative Study During",
        "Algorithmic Approaches",
        "Online Deliberation",
        "Opinion Selection",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.842692"
    },
    {
      "id": "arxiv-2602.15432v1",
      "title": "From Earthquake Solidarity to Educational Equity: Conceptualizing a Sustainable, Volunteer-Driven P2P Learning Ecosystem at Scale",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15432v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study examines the evolution of a grassroots, volunteer-driven peer-to-peer (P2P) educational initiative from an emergency response to the 2023 Türkiye earthquake into a sustainable ecosystem that operated for over two years and supported 300+ middle-school learners with 40+ volunteer tutors. Employing an interpretive case study approach, we triangulated data from participant observation, focus groups, questionnaires, and collaborative visioning workshops to investigate the socio-technical dynamics enabling long-term resilience in a fully online, nonreciprocal far-peer tutoring setting. Our findings reveal that while age proximity fosters trust and open communication, it also poses challenges for tutors who must balance peer rapport with instructional authority. Volunteer engagement is driven primarily by intrinsic motives - educational impact and community belonging - while optional micro-earning is envisioned as a practical enabler for long-term sustainability. Tutees report significant gains in confidence, self-expression, and accelerated comprehension, attributing these outcomes to personalized, interactive sessions within a \"family-like\" safe space that combines academic instruction with socio-emotional support. Notably, tutees view tutors as aspirational role models and express strong intentions to return as tutors themselves, envisioning a self-regenerating cycle of intergenerational reciprocity that carries knowledge and solidarity from generation to generation. Both cohorts call for a dedicated platform featuring integrated scheduling, personalization, feedback, and quality assurance mechanisms. We synthesize these insights into theory-informed implications and five design principles for sustainable P2P learning ecosystems at scale.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15432v1",
        "authors": [
          "Öykü Kaplan",
          "Adam Przybyłek",
          "Michael Neumann",
          "Netta Iivari"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "From Earthquake Solidarity",
        "Learning Ecosystem",
        "Educational Equity",
        "MIT",
        "WHO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.844012"
    },
    {
      "id": "arxiv-2602.15428v1",
      "title": "What makes an Expert? Comparing Problem-solving Practices in Data Science Notebooks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15428v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The development of data science expertise requires tacit, process-oriented skills that are difficult to teach directly. This study addresses the resulting challenge of empirically understanding how the problem-solving processes of experts and novices differ. We apply a multi-level sequence analysis to 440 Jupyter notebooks from a public dataset, mapping low-level coding actions to higher-level problem-solving practices. Our findings reveal that experts do not follow fundamentally different transitions between data science phases than novices (e.g., Data Import, EDA, Model Training, Visualization). Instead, expertise is distinguished by the overall workflow structure from a problem-solving perspective and cell-level, fine-grained action patterns. Novices tend to follow long, linear processes, whereas experts employ shorter, more iterative strategies enacted through efficient, context-specific action sequences. These results provide data science educators with empirical insights for curriculum design and assessment, shifting the focus from final products toward the development of the flexible, iterative thinking that defines expertise-a priority in a field increasingly shaped by AI tools.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15428v1",
        "authors": [
          "Manuel Valle Torre",
          "Marcus Specht",
          "Catharine Oertel"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Comparing Problem",
        "Model Training",
        "Data Import",
        "EDA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.844445"
    },
    {
      "id": "arxiv-2602.15371v1",
      "title": "From PhysioNet to Foundation Models -- A history and potential futures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15371v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Over the last 35 years, the sharing of medical data and models for research has evolved from sneakernet to the internet - from mailing magnetic tapes and compact discs of a handful of well-curated recordings, to the high-speed download of relatively comprehensive hospital databases. More recently, the fervor around the potential for modern machine learning and 'AI' to catapult us into the next industrial revolution has led to a seemingly insatiable desire to pump almost any source of data into large models. Although this has great potential, it also presents a whole set of new challenges. In this article I examine these trends over the last 30 years, drawing on examples from cardiology, one of the oldest data-intensive fields that is undergoing a renaissance via machine learning. From the early days of computerized cardiology, the Research Resource for Complex Physiologic Signals (PhysioNet) has been at the cutting edge of this field. This article, therefore, includes much of the Resource's history and the contributions drawn from 25 years of firsthand experience of co-developing elements of the Resource with its founders. I identify the most promising future directions for the PhysioNet Resource, and more generally, the growing issues and opportunities around dissemination and use of massive physiological databases, associated open access code, and public competitions, along with potential solutions to the key issues facing our field. Topics range from how we should approach foundation models in the context of the rapidly growing AI carbon footprint, to the potential of Tiny-ML and edge computing. I also cover issues around prizes and incentives, funding models, and scientific repeatability, as well as how we might address these issues by leveraging the PhysioNet Challenges, consistent with the philosophy of open-access from the early days of the PhysioNet Resource.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15371v1",
        "authors": [
          "Gari D. Clifford"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Complex Physiologic Signals",
        "Foundation Models",
        "Research Resource",
        "Machine Learning",
        "Edge Computing",
        "WHO",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.845166"
    },
    {
      "id": "arxiv-2602.15317v1",
      "title": "Enhancing Computational Efficiency in NetLogo: Best Practices for Running Large-Scale Agent-Based Models on AWS and Cloud Infrastructures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15317v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The rising complexity and scale of agent-based models (ABMs) necessitate efficient computational strategies to manage the increasing demand for processing power and memory. This manuscript provides a comprehensive guide to optimizing NetLogo, a widely used platform for ABMs, for running large-scale models on Amazon Web Services (AWS) and other cloud infrastructures. It covers best practices in memory management, Java options, BehaviorSpace execution, and AWS instance selection. By implementing these optimizations and selecting appropriate AWS instances, we achieved a 32\\% reduction in computational costs and improved performance consistency. Through a comparative analysis of NetLogo simulations on different AWS instances using the wolf-sheep predation model, we demonstrate the performance gains achievable through these optimizations.",
        "keywords": [
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15317v1",
        "authors": [
          "Michael A. Duprey",
          "Georgiy V. Bobashev"
        ],
        "arxiv_categories": [
          "cs.MA"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Enhancing Computational Efficiency",
        "Amazon Web Services",
        "Best Practices",
        "Running Large",
        "Based Models",
        "Scale Agent",
        "Amazon",
        "AWS",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-18T13:58:19.845499"
    },
    {
      "id": "arxiv-2602.15280v1",
      "title": "Supporting Multimodal Data Interaction on Refreshable Tactile Displays: An Architecture to Combine Touch and Conversational AI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15280v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Combining conversational AI with refreshable tactile displays (RTDs) offers significant potential for creating accessible data visualization for people who are blind or have low vision (BLV). To support researchers and developers building accessible data visualizations with RTDs, we present a multimodal data interaction architecture along with an open-source reference implementation. Our system is the first to combine touch input with a conversational agent on an RTD, enabling deictic queries that fuse touch context with spoken language, such as \"what is the trend between these points?\" The architecture addresses key technical challenges, including touch sensing on RTDs, visual-to-tactile encoding, integrating touch context with conversational AI, and synchronizing multimodal output. Our contributions are twofold: (1) a technical architecture integrating RTD hardware, external touch sensing, and conversational AI to enable multimodal data interaction; and (2) an open-source reference implementation demonstrating its feasibility. This work provides a technical foundation to support future research in multimodal accessible data visualization.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15280v1",
        "authors": [
          "Samuel Reinders",
          "Munazza Zaib",
          "Matthew Butler",
          "Bongshin Lee",
          "Ingrid Zukerman"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Supporting Multimodal Data Interaction",
        "Refreshable Tactile Displays",
        "An Architecture",
        "Combine Touch",
        "BLV",
        "WHO",
        "RTD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.845906"
    },
    {
      "id": "arxiv-2602.15273v1",
      "title": "FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15273v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Information ecosystems increasingly shape how people internalize exposure to adverse digital experiences, raising concerns about the long-term consequences for information health. In modern search and recommendation systems, ranking and personalization policies play a central role in shaping such exposure and its long-term effects on users. To study these effects in a controlled setting, we present FrameRef, a large-scale dataset of 1,073,740 systematically reframed claims across five framing dimensions: authoritative, consensus, emotional, prestige, and sensationalist, and propose a simulation-based framework for modeling sequential information exposure and reinforcement dynamics characteristic of ranking and recommendation systems. Within this framework, we construct framing-sensitive agent personas by fine-tuning language models with framing-conditioned loss attenuation, inducing targeted biases while preserving overall task competence. Using Monte Carlo trajectory sampling, we show that small, systematic shifts in acceptance and confidence can compound over time, producing substantial divergence in cumulative information health trajectories. Human evaluation further confirms that FrameRef's generated framings measurably affect human judgment. Together, our dataset and framework provide a foundation for systematic information health research through simulation, complementing and informing responsible human-centered research. We release FrameRef, code, documentation, human evaluation data, and persona adapter models at https://github.com/infosenselab/frameref.",
        "keywords": [
          "cs.CY",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15273v1",
        "authors": [
          "Victor De Lima",
          "Jiqun Liu",
          "Grace Hui Yang"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.CL"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Modeling Bounded Rational Information",
        "Health Information",
        "Simulation Testbed",
        "Using Monte Carlo",
        "Framing Dataset",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:19.846404"
    },
    {
      "id": "arxiv-2602.15822v1",
      "title": "Finite Free Information Inequalities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15822v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop finite free information theory for real-rooted polynomials, establishing finite free analogues of entropy and Fisher information monotonicity, as well as the Stam and entropy power inequalities. These results resolve conjectures by Shlyakhtenko and Gribinski and recover inequalities in free probability in the large-degree limit. Equivalently, our results may be interpreted as potential-theoretic inequalities for the zeros of real-rooted polynomials under differential operators which preserve real-rootedness. Our proofs leverage a new connection between score vectors and Jacobians of root maps, combined with convexity results for hyperbolic polynomials.",
        "keywords": [
          "math.PR",
          "math.CA",
          "math.CO",
          "math.OA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15822v1",
        "authors": [
          "Jorge Garza-Vargas",
          "Nikhil Srivastava",
          "Zachary Stier"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.CA",
          "math.CO",
          "math.OA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Finite Free Information Inequalities",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.258682"
    },
    {
      "id": "arxiv-2602.15810v1",
      "title": "Effective energy-enstrophy diffusion process and condensation bound",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15810v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this article we use Gaussian measure on $\\mathbb{R}^N$ to define the coefficients of an elliptic diffusion on an open cone of $\\mathbb{R}^2$. We prove the existence and uniqueness of a stationary distribution for this diffusion. In a companion article, we show that the diffusion constructed in this work is the inviscid limit of the laws of the ``enstrophy-energy'' process of a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (the strength of which can be made to go to zero in the inviscid limit). In the present work, owing to the special properties of the coefficients constructed with the Gaussian measure, we bound the distance to $1$ of the ratio of the expected energy to the expected enstrophy (this ratio is at most $1$ with our normalization). Together with our companion article, this shows that for suitable Brownian forcings an inviscid condensation inducing an attrition of all but the lowest modes takes place.",
        "keywords": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15810v1",
        "authors": [
          "Alain-Sol Sznitman",
          "Klaus Widmayer"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.259119"
    },
    {
      "id": "arxiv-2602.15805v1",
      "title": "Inviscid limit and an effective energy-enstrophy diffusion process",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15805v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this article we consider a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (of arbitrarily small strength). We show that the stationary diffusion in an open two-dimensional cone constructed in a companion article, stands as the inviscid limit of the laws of the ``enstrophy-energy'' process of the $N$-dimensional diffusion process considered here, this regardless of the strength of the stirring. With the help of the quantitative condensation bounds of the companion article, we infer quantitative inviscid condensation bounds, which for suitable forcings show an attrition of all but the lowest modes in the inviscid limit.",
        "keywords": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15805v1",
        "authors": [
          "Alain-Sol Sznitman",
          "Klaus Widmayer"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.259380"
    },
    {
      "id": "arxiv-2602.15786v1",
      "title": "Timelike bounce hypersurfaces in charged null dust collapse",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15786v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We establish results on the dynamics of interacting charged null fluids in general relativity, specifically in the context of the bouncing continuation proposed in [Ori91]. In this model - the setting for a number of prominent case studies on black hole formation - charged massless particles may instantaneously change direction (bounce) after losing all their 4-momentum due to electrostatic repulsion. We initiate the study of timelike bounce hypersurfaces in spherical symmetry: scenarios in which an incoming beam of charged null dust changes direction along a timelike surface $\\mathcal{B}$, which is the (free) boundary of an interacting 2-dust region. We identify a novel decoupling of the equations of motion in this region. First, it is shown that every timelike curve segment $γ$ in the spherically symmetric quotient of Minkowski or Reissner-Nordström spacetimes arises as the bounce hypersurface $\\mathcal{B}$ of a charged null dust beam incident from past null infinity $\\mathcal{I}^-$. We construct a spacetime $(\\mathcal{M},g_{μν})$ describing the full trajectory of the beam, which includes gluing to Reissner-Nordström and Vaidya regions. Across $\\mathcal{B}$ the metric has regularity $g_{μν}\\in C^{2,1}$ and satisfies Einstein's equation classically, while $C^\\infty$ gluing may be achieved across all other interfaces. We also obtain examples of timelike bounce hypersurfaces terminating in a null point. Since these constructions are teleological, we secondly consider a given charged incoming beam from past null infinity. We formulate and solve a free boundary problem which represents the formation of a timelike bounce hypersurface. The result is conditional, applying only in the exterior region of a Reissner-Nordström spacetime, and subject to a technical regularity condition.",
        "keywords": [
          "gr-qc",
          "math-ph",
          "math.AP",
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15786v1",
        "authors": [
          "David Bick"
        ],
        "arxiv_categories": [
          "gr-qc",
          "math-ph",
          "math.AP",
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.260701"
    },
    {
      "id": "arxiv-2602.15764v1",
      "title": "Quantitative local recovery of Kerr-de Sitter parameters from high-frequency equatorial quasinormal modes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15764v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study an inverse resonance problem for the scalar wave equation on the Kerr-de Sitter family. In a compact subextremal slow-rotation regime and at a fixed overtone index, high-frequency quasinormal modes admit semiclassical quantization and a real-analytic labeling by angular momentum indices. Using this structure, we first prove that a finite equatorial high-frequency package of quasinormal-mode frequencies determines the mass and rotation parameter $(M,a)$ (for fixed cosmological constant $Λ>0$), with a quantitative stability estimate. As a key geometric input we compute explicit second-order (in $a$) corrections to the equatorial photon-orbit invariants which control the leading real and imaginary parts of the quasinormal modes. Finally, allowing $Λ$ to vary in a compact interval, we show that adding one damping observable (the scaled imaginary part of a single equatorial mode) yields a three-parameter inverse theorem: a finite package of three independent real observables determines $(M,a,Λ)$ locally in the slow-rotation regime away from $a=0$.",
        "keywords": [
          "math-ph",
          "gr-qc",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15764v1",
        "authors": [
          "Ruiliang Li"
        ],
        "arxiv_categories": [
          "math-ph",
          "gr-qc",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.261526"
    },
    {
      "id": "arxiv-2602.15754v1",
      "title": "Power monoids and their arithmetic: a survey",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15754v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The non-empty finite subsets of a multiplicatively written monoid form a monoid in their own right, and so do the finite subsets that contain the identity element. Partly due to their unusual arithmetic properties, these structures, known as power monoids, have attracted increasing attention in recent years and have in turn stimulated growing interest in new perspectives in factorization theory, better suited to non-cancellative settings. We survey these developments and briefly review some related aspects.",
        "keywords": [
          "math.RA",
          "math.CO",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15754v1",
        "authors": [
          "Salvatore Tringali"
        ],
        "arxiv_categories": [
          "math.RA",
          "math.CO",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.261733"
    },
    {
      "id": "arxiv-2602.15722v1",
      "title": "Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15722v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme.",
        "keywords": [
          "math.OC",
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15722v1",
        "authors": [
          "Cheng Guo",
          "Lauren Henderson",
          "Ryan Cory-Wright",
          "Boshi Yang"
        ],
        "arxiv_categories": [
          "math.OC",
          "econ.GN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlinear Markets With Semidefinite",
        "Relaxations Nonconvexities",
        "Pricing Discrete",
        "Framework",
        "IEEE",
        "MIT",
        "SDP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.262208"
    },
    {
      "id": "arxiv-2602.15719v1",
      "title": "Weak mixing for area preserving flows on surfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15719v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Let $(φ_t)$ be an area-preserving smooth flow on a compact, connected, orientable surface $\\mathcal M$ with at least one but finitely many fixed points. Assume that $(φ_t)$ is analytic (up to a canonical change of coordinates) in the neighborhood of each saddle fixed point. We show that the flow $(φ_t)$ is weakly mixing on each of its (finitely many) quasi-minimal components.",
        "keywords": [
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15719v1",
        "authors": [
          "Adam Kanigowski",
          "Alexey Okunev",
          "Rigoberto Zelada"
        ],
        "arxiv_categories": [
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.262553"
    },
    {
      "id": "arxiv-2602.15718v1",
      "title": "Asymptotics and zero distribution of geometric polynomials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15718v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We obtain some results on the asymptotic behavior and zero distribution of the so-called geometric polynomials. The asymptotics is given both on compact subsets of $\\C\\setminus [-1,0]$ and on compact subsets of the interval $(-1,0)$. The zeros of these polynomials are simple and lie in $(-1,0]$; moreover, the zeros of consecutive polynomials interlace. Its zero distribution is a measure whose density is similar to Cauchy weight. Some orthogonality properties of these polynomials are also proved.",
        "keywords": [
          "math.CA",
          "math.CO",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15718v1",
        "authors": [
          "M. Bello-Hernández",
          "M. Benito",
          "Ó. Ciaurri",
          "E. Fernández"
        ],
        "arxiv_categories": [
          "math.CA",
          "math.CO",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "WHO",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.262759"
    },
    {
      "id": "arxiv-2602.15715v1",
      "title": "Fine regularity of fractional harmonic maps and applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15715v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we derive several regularity results for harmonic mappings into Euclidean spheres associated with rather general energies related to fractional Sobolev spaces. These maps generalize families of maps introduced by Da Lio, Rivière and Schikorra and are related to harmonic maps with free boundaries. In our context, there is in general no monotonicity formula, which prevents the use of some classical methods. Despite this limitation, under natural assumptions on a Gagliardo-type energy, we succeed in proving a variety of small energy regularity results and improve on known results, even in the isotropic case for which some monotonicity formula is available. To this end, we exploit recent developments in the regularity theory of nonlocal equations and as a by-product, we explain how these results apply to classes of harmonic maps with free boundary and lead to new potential-theoretic estimates. As another application, we obtain higher differentiability results for the fractional harmonic map heat flow.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15715v1",
        "authors": [
          "Kyeongbae Kim",
          "Simon Nowak",
          "Yannick Sire"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Da Lio",
        "MIT",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.263366"
    },
    {
      "id": "arxiv-2602.15710v1",
      "title": "All roads lead to Rome: Path-following Augmented Lagrangian Methods via Bregman Proximal Regularization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15710v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study Bregman proximal augmented Lagrangian methods with second-order oracles for convex convex-composite optimization problems. The outer loop is an instance of the Bregman proximal point algorithm with relative errors in the sense of Solodov and Svaiter, applied to the KKT operator associated with the problem. Akin to classical Lagrange-Newton methods, including primal-dual interior point methods the Bregman proximal point algorithm repeatedly solves regularized KKT inclusions by minimizing a smooth Bregman augmented Lagrangian function, obtained after marginalizing out the multiplier variables. Thanks to non-Euclidean geometries the marginal function is generalized self-concordant and therefore within the regime of Newton's method which converges quadratically if the step-size in the outer proximal point loop is chosen carefully. The operator-theoretic viewpoint allows us to employ the framework of metric subregularity to derive fast rates for the outer loop, and eventually state a joint complexity bound. Important special cases of our framework are a proximal variant of the exponential multiplier method due to Tseng and Bertsekas and interior-point proximal augmented Lagrangian schemes closely related to those of Pougkakiotis and Gondzio.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15710v1",
        "authors": [
          "Emanuel Laude"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bregman Proximal Regularization We",
        "Augmented Lagrangian Methods",
        "Framework",
        "Oracle",
        "BERT",
        "WTO",
        "IoT",
        "KKT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.263724"
    },
    {
      "id": "arxiv-2602.15709v1",
      "title": "On the depth of depth-weighted trees",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15709v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The depth-weighted tree DWT($f$) with weight function $f:\\{0,1,2,\\ldots\\}\\to (0,\\infty)$ is a dynamic random tree grown from a root $r$ where vertices arrive consecutively and every new vertex attaches to a parent $u$ with probability proportional to $f$(distance between $u$ and $r$). This work is dedicated to a systematic analysis of the depth of DWT($f$). Namely, we provide precise analytic expressions of the typical depth of DWT($f$) for convergent, periodic, slowly growing, and (super-)exponentially growing weight functions. Furthermore, for bounded or exponentially growing $f$, we determine the typical depth up to a multiplicative constant, thus confirming and strengthening a conjecture of Leckey, Mitsche and Wormald.",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15709v1",
        "authors": [
          "Lyuben Lichev",
          "Amitai Linker",
          "Bas Lodewijks",
          "Dieter Mitsche"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "DWT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.263951"
    },
    {
      "id": "arxiv-2602.15701v1",
      "title": "Solving Dirichlet problem on unbounded uniform domains by using sphericalization techniques",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15701v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Within the setting of metric spaces equipped with a doubling measure and supporting a $p$-Poincaré inequality, establishing existence of solutions to Dirichlet problem in a bounded domain in such a metric space is accomplished via direct methods of calculus of variation and the use of a Maz'ya type inequality, which is a consequence of the Poincaré inequality. However, when the domain and its boundary are unbounded, such a method is unavailable. In this paper, using the technique of sphericalization developed in the prior paper~[32], we establish the existence of solutions to the Dirichlet boundary value problem for $p$-harmonic functions in unbounded uniform domains with unbounded boundary when $1<p<\\infty$. We also explore the issue of whether such solutions are unique by considering $p$-parabolicity and $p$-hyperbolicity properties of the domain.",
        "keywords": [
          "math.AP",
          "math.MG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15701v1",
        "authors": [
          "Riikka Korte",
          "Sari Rogovin",
          "Nageswari Shanmugalingam",
          "Timo Takala"
        ],
        "arxiv_categories": [
          "math.AP",
          "math.MG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Solving Dirichlet",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.264516"
    },
    {
      "id": "arxiv-2602.15693v1",
      "title": "On the intersections of projected Hamiltonian orbits in cotangent bundles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15693v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the generic behavior of Hamiltonian trajectories on a regular level set in the cotangent bundle, after projection to the base. We prove that for a generic submersive level set, projected trajectories have discrete (self-)intersections. Additionally, fixing end-point fibers, we prove that all intersections can be perturbed away if the base has dimension at least three. In particular, this applies to periodic orbits, and both results hold for Reeb flows on fiber-wise star-shaped hypersurfaces, including non-reversible Finsler flows, which answers a question of Rademacher. In the proof we make use of a multi-jet transversality theorem.",
        "keywords": [
          "math.DS",
          "math.DG",
          "math.SG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15693v1",
        "authors": [
          "Lucas Dahinden",
          "Jacobus de Pooter"
        ],
        "arxiv_categories": [
          "math.DS",
          "math.DG",
          "math.SG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.264730"
    },
    {
      "id": "arxiv-2602.15670v1",
      "title": "Quantitative enstrophy bounds for measure vorticities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15670v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider the two-dimensional incompressible Navier-Stokes equations with measure initial vorticity. By means of improved Nash inequalities, we establish quantitative estimates for the enstrophy depending on the absolute vorticity decay on balls. The bounds are optimal in several aspects and yield to a conjecturally sharp rate of the dissipation in the Delort's class.",
        "keywords": [
          "math.AP",
          "math-ph",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15670v1",
        "authors": [
          "Luigi De Rosa",
          "Margherita Marcotullio"
        ],
        "arxiv_categories": [
          "math.AP",
          "math-ph",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.264872"
    },
    {
      "id": "arxiv-2602.15647v1",
      "title": "On the Robin problem for the Laplace equation in multiply connected domains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15647v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper complements the existing theory developed in [5] for the Dirichlet and Neumann problems for the Laplace equation, in multiply connected domains. Within the framework of layer potential methods, we study the Laplace equation under Robin boundary conditions, representing the solutions by means of a double layer potential. We observe that the classical approach searches the solutions in terms of a single layer potential.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15647v1",
        "authors": [
          "Alberto Cialdea",
          "Vita Leonessa"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "UN",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.265034"
    },
    {
      "id": "arxiv-2602.15643v1",
      "title": "Reinforcement Learning in Real Option Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15643v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate an entropy-regularized reinforcement learning (RL) approach to optimal stopping problems motivated by real option models. Classical stopping rules are strict and non-randomized, limiting natural exploration in RL settings. To address this, we introduce entropy regularization, allowing randomized stopping policies that balance exploitation and exploration. We derive an explicit analytical solution to the regularized problem and prove convergence of the associated free boundary to the classical stopping threshold as the entropy vanishes. The regularized problem admits a natural formulation as a singular stochastic control problem. Building on this structure, we propose both model-based and model-free policy iteration algorithms to learn the optimal boundary. The model-free method operates without knowledge of system dynamics, using only trajectories from the stochastic environment. We establish convergence guarantees and illustrate strong numerical performance. This framework provides a principled and tractable approach for data-driven stopping problems under uncertainty.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15643v1",
        "authors": [
          "Jodi Dianetti",
          "Giorgio Ferrari",
          "Renyuan Xu"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcement Learning",
        "Real Option Models We",
        "Framework",
        "Policy",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.265339"
    },
    {
      "id": "arxiv-2602.15622v1",
      "title": "Integral and arithmetic structures of alternating (zigzag) numbers $A_n$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15622v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The alternating (zigzag) numbers $A_n$, counting the ascending alternating permutations of $\\left\\{1,\\cdots,n\\right\\}$ and defined by the exponential generating function $\\tan x+\\sec x$, admit several classical combinatorial and analytic representations. In this work we unify and extend three complementary structures of $A_n$. First, starting from the Stirling number expansion of zigzag numbers, we derive a contour integral representation, as well as a positive Laplace-type integral representation $$ A_n = 2^n \\int_0^\\infty e^{-y} f_n(y)\\, dy, \\qquad f_n(y) := \\sum_{k=0}^{n} (-1)^k S(n,k) \\left(\\frac{y}{2}\\right)^k, $$ where the kernel $f_n(y)$ is the polynomial generating function of Stirling numbers. A continuous interpolation of the discrete product (falling factorial) is introduced subsequently. This provides a direct analytic bridge between set partitions and Laplace asymptotics. Second, using the partial fraction expansion of $\\tan$, we obtain the well-known hyperbolic integral representation $$ A_{2n+1}=\\frac{1}π\\int_0^\\infty\\frac{y^{2n+1}}{\\sinh(y/2)}\\,dy, $$ equivalently expressed in classical $\\cosh$ form for $A_{2n}$. This representation interprets zigzag numbers as spectral moments associated with half-integer poles. The connection with Fourier analysis and Mellin transforms is also outlined. Finally, combining spectral expansions with Stirling identities, we derive congruence relations modulo primes for $A_n$. These results exhibit a dual analytic-combinatorial structure of zigzag numbers, linking partition expansions, trigonometric spectra, and arithmetic properties.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15622v1",
        "authors": [
          "Jean-Christophe Pain"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSF",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.266394"
    },
    {
      "id": "arxiv-2602.15621v1",
      "title": "Completeness theorems on the boundary for a parabolic equation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15621v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Let $\\{v_α\\}$ be a system of polynomial solutions of the parabolic equation $a_{hk}\\partial_{x_{h}x_{k}}u - \\partial_t u =0$ in a bounded $C^1$-cylinder $Ω_{T}$ contained in $\\mathbb{R}^{n+1}$. Here $a_{hk}\\partial_{x_{h}x_{k}}$ is an elliptic operator with real constant coefficients. We prove that $\\{v_α\\}$ is complete in $L^{p}(Σ')$, where $Σ'$ is the parabolic boundary of $Ω_{T}$. Similar results are proved for the adjoint equation $a_{hk}\\partial_{x_{h}x_{k}} u+ \\partial_t u =0$.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15621v1",
        "authors": [
          "Alberto Cialdea",
          "Carmine Sebastiano Mare"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.266771"
    },
    {
      "id": "arxiv-2602.15601v1",
      "title": "Uniqueness and Zeroth-Order Analysis of Weak Solutions to the Non-cutoff Boltzmann equation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15601v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We establish the uniqueness of large solutions to the non-cutoff Boltzmann equation with moderate soft potentials. Specifically, the weak solution $F=μ+μ^{\\frac{1}{2}}f$ is unique as long as it has finite energy, in the sense that the norm $\\|f\\|_{L^\\infty_t L^{r}_{x,v}}+\\|f\\|_{L^\\infty_t L^2_{x,v}}$ remains bounded (arbitrary large) for some sufficiently large $r>0$. Our approach applies dilated dyadic decompositions in phase space $(v,ξ,η)$ to capture hypoellipticity and to reduce the fractional derivative structure $(-Δ_v)^{s}$ of the Boltzmann collision operator to zeroth order. The difficulties posed by the large solution are overcome through the negative-order hypoelliptic estimate that gains integrability in $(t,x)$.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15601v1",
        "authors": [
          "Dingqun Deng",
          "Shota Sakamoto"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Weak Solutions",
        "Order Analysis",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.267353"
    },
    {
      "id": "arxiv-2602.15594v1",
      "title": "BORWin: Exact algorithm based on a Bi-Objective Relaxation for Window-constrained problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15594v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A mixed integer maximization problem involving several additional constraints defined with both a lower and an upper bound is considered. It is assumed that one of such constraints is more restrictive than the others. As it can be seen as a resource window constraint, it defines the so-called window-constrained problem. From a bi-objective perspective, a 2-phase algorithm, called BORWin, is devised. It stands for Bi-Objective Relaxation for Window-constrained problems. The first phase is generic for any window-constrained problem and provides a family of upper bounds based on a bi-objective relaxation of the additional constraints. It is shown that the latter bounds strongly relate to the Lagrangian dual bounds. The second phase is derived for a variant involving a graph structure, namely the window-constrained longest-path problem on an acyclic graph. The aim is to take advantage of the upper bounds to devise an efficient label extension algorithm. It is shown that complementary upper bounds could be derived to further improve performance in some special cases. A typical example is when the additional constraints have special knapsack structures. This is the case for the Hydro-Unit Commitment problem with a single plant (1-HUC). From numerical experiments for the 1-HUC, BOR-Win appears to be very efficient compared to state-of-the-art approaches.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15594v1",
        "authors": [
          "Christian Artigues",
          "Pascale Bendotti",
          "Alexandre Heintzmann",
          "Sandra Ulrich Ngueveu",
          "Cécile Rottner"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Objective Relaxation",
        "Unit Commitment",
        "Wind",
        "MIT",
        "HUC",
        "BOR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.267740"
    },
    {
      "id": "arxiv-2602.15587v1",
      "title": "Adjusted Scores for Discrete Langevin Algorithms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15587v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Sampling from discrete distributions is a ubiquitous task in machine learning, recently revisited by the emergence of discrete diffusion models. While Langevin algorithms constitute the state of the art for continuous spaces, discrete versions lack similar theoretical guarantees when the step-size becomes small. In this paper, we address this limitation by interpreting discrete sampling algorithms as discretizations of continuous-time dynamics on the hypercube. In particular, we describe several score functions for discrete algorithms which result in approximations of Glauber dynamics for the correct target distribution. We also compute upper bounds for the contraction of these algorithms, with or without Metropolis adjustment.",
        "keywords": [
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15587v1",
        "authors": [
          "Armand Gissler",
          "Saeed Saremi",
          "Francis Bach"
        ],
        "arxiv_categories": [
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Discrete Langevin Algorithms Sampling",
        "Machine Learning",
        "Adjusted Scores",
        "While Langevin",
        "Fusion",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.267973"
    },
    {
      "id": "arxiv-2602.15559v1",
      "title": "Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15559v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails.",
        "keywords": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15559v1",
        "authors": [
          "Gabriel Saco"
        ],
        "arxiv_categories": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Logged Propensities Adaptive",
        "Adaptive Experiments",
        "Normalized Inference",
        "Horizon Self",
        "Standard",
        "AIPW",
        "NIST",
        "ATE",
        "MIT",
        "DML",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.268369"
    },
    {
      "id": "arxiv-2602.15557v1",
      "title": "Stochastic Games on Large Sparse Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15557v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a framework for stochastic games on large sparse graphs, covering continuous-time and discrete-time dynamic games as well as static games. Players are indexed by the vertices of simple, locally finite graphs, allowing both finite and countably infinite populations, with asymptotics described through local weak convergence of marked graphs. The framework allows path-dependent utility functionals that may be heterogeneous across players. Under a contraction condition, we prove existence and uniqueness of Nash equilibria and establish exponential decay of correlations with graph distance. We further show that global equilibria can be approximated by truncated local games, and can even be reconstructed exactly on subgraphs given information on their boundary. Finally, we prove convergence of Nash equilibria along locally weakly convergent graph sequences, including sequences sampled from hyperfinite unimodular random graphs.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15557v1",
        "authors": [
          "Eyal Neuman",
          "Sturmius Tuschmann"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Sparse Graphs We",
        "Stochastic Games",
        "Framework",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.268638"
    },
    {
      "id": "arxiv-2602.15517v1",
      "title": "A Model Order Reduction Method for Seismic Applications Using the Laplace Transform",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15517v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We devise and analyze a reduced basis model order reduction (MOR) strategy for an abstract wave problem with vanishing initial conditions and a source term given by the product of a temporal Ricker wavelet and a spatial profile. Such wave problems comprise the acoustic and elastic wave equations, with applications in seismic modeling. Motivated by recent Laplace-domain MOR methodologies, we construct reduced bases that approximate the time-domain solution with exponential accuracy. We prove convergence bounds that are explicit and robust with respect to the parameters controlling the Ricker wavelet's shape and width and identify an intrinsic accuracy limit dictated by the wavelet's value at the initial time. In particular, the resulting error bound is independent of the underlying Galerkin discretization space and yields computable criteria for the regime in which exponential convergence is observed.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15517v1",
        "authors": [
          "Fernando Henriquez",
          "Matthias Schlottbom"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Model Order Reduction Method",
        "Seismic Applications Using",
        "Laplace Transform We",
        "NSF",
        "MIT",
        "MOR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.268942"
    },
    {
      "id": "arxiv-2602.15479v1",
      "title": "A Degenerate Elliptic System Solvable by Transport: A Cautionary Example",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15479v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We exhibit a one-parameter family of first-order real elliptic systems on the plane whose ellipticity constant degenerates to zero as $δ\\to 0$, with condition number $κ= O(δ^{-2})$. For any fixed elliptic solver operating at finite precision, the parameter $δ$ can be chosen small enough to defeat the solver; no uniform numerical scheme based on the ellipticity constant alone can handle the entire family. Despite this, every member of the family is explicitly solvable -- and its initial value problem well posed -- by elementary means once a transport-theoretic invariant is identified. The cost of the transport solution is independent of $δ$. The example serves as a cautionary tale: the ellipticity constant alone does not determine the practical difficulty of a first-order PDE. Before invoking an elliptic solver, one should compute the transport obstruction $G$; its vanishing -- or smallness -- signals structure that standard elliptic methods miss entirely.",
        "keywords": [
          "math.AP",
          "math.CV",
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15479v1",
        "authors": [
          "Daniel Alayón-Solarz"
        ],
        "arxiv_categories": [
          "math.AP",
          "math.CV",
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Degenerate Elliptic System Solvable",
        "Cautionary Example We",
        "Standard",
        "DOE",
        "WHO",
        "PDE",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.269506"
    },
    {
      "id": "arxiv-2602.15471v1",
      "title": "Conformal Metrics on the Disk with Prescribed Negative Gaussian Curvature and Boundary Geodesic Curvature",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15471v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the problem of prescribing the Gaussian curvature on the disk and the geodesic curvature on its boundary via a conformal change of the metric. In this paper the case of negative Gaussian curvature is treated, a regime for which the bubbling behavior of approximate solutions is not so well understood. This is due to the possible appearance of blow-up solutions with diverging length and area. We give an existence result under assumptions on the curvatures which are somewhat natural, in view of some obstructions inherent to the problem. Our strategy is variational and relies on the study of certain families of approximated problems. By performing a refined blow-up analysis for solutions with bounded Morse index, we conclude compactness.",
        "keywords": [
          "math.AP",
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15471v1",
        "authors": [
          "Rafael López-Soriano",
          "Francisco J. Reyes-Sánchez",
          "David Ruiz"
        ],
        "arxiv_categories": [
          "math.AP",
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Prescribed Negative Gaussian Curvature",
        "Boundary Geodesic Curvature We",
        "Conformal Metrics",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.269728"
    },
    {
      "id": "arxiv-2602.15455v1",
      "title": "A Phase Transition For Repeated K-Averages",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15455v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Let $x_1,\\dots,x_{n}$ be a fixed sequence of real numbers. At each stage, pick $k$ integers $\\{I_{i}\\}_{1\\leq i \\leq k}$ uniformly at random without replacement and then for each $i \\in \\{1,2,\\dots,k\\}$ replace $x_{I_i}$ by $(x_{I_1}+x_{I_2}+\\dots+x_{I_k})/k$. It is easy to observe that all the co-ordinates converge to $(x_1+\\dots+x_n)/n$. In this article, we extend the result of \\cite{chatterjee2019note} by establishing order of decay of the expected $L^{2}$ distance. Furthermore, we establish the mixing time to be in between $\\frac{n}{k \\log k}\\log n$ and $\\frac{n}{k-1}\\log n$.",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15455v1",
        "authors": [
          "Rohit Chaudhuri"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Phase Transition For Repeated",
        "Averages Let",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.269901"
    },
    {
      "id": "arxiv-2602.15447v1",
      "title": "Household size can explain 40% of the variance in cumulative COVID-19 incidence across Europe",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15447v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Household size impacts the spread of respiratory infectious diseases: Larger households tend to boost transmission by acquiring external infections more frequently and subsequently transmitting them back into the community. Furthermore, mandatory interventions primarily modulate contagion between households rather than within them. We developed an approach to quantify the role of household size in epidemics by separating within-household from out-household transmission, and found that household size explains 41% of the variability in cumulative COVID-19 incidence across 34 European countries (95% confidence interval: [15%, 46%]). The contribution of households to the overall dynamics can be quantified by a boost factor that increases with the effective household size, implying that countries with larger households require more stringent interventions to achieve the same levels of containment. This suggests that households constitute a structural (dis-)advantage that must be considered when designing and evaluating mitigation strategies.",
        "keywords": [
          "q-bio.PE",
          "math.DS",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15447v1",
        "authors": [
          "Seba Contreras",
          "Philipp Dönges",
          "Maciej Filinski",
          "Joel Wagner",
          "Viktor Bezborodov"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.DS",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Europe Household",
        "COVID-19",
        "COVID",
        "EPA",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:25.270187"
    },
    {
      "id": "arxiv-2602.15445v1",
      "title": "A discrete gradient scheme for preserving QSR-dissipativity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15445v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The notion of dissipative dynamical systems provides a formal description of processes that cannot generate energy internally. For these systems, changes in energy can only occur due to an external energy supply or dissipation effects. Unfortunately, dissipative properties tend to deteriorate in numerical computations, especially in nonlinear systems. Discrete gradient methods can help mitigate this problem. In this paper, we present a class of structure-preserving time discretization schemes based on discrete gradients for a special class of systems that are dissipative with respect to a quadratic supply rate.",
        "keywords": [
          "math.NA",
          "math.DS",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15445v1",
        "authors": [
          "Attila Karsai",
          "Philipp Schulze"
        ],
        "arxiv_categories": [
          "math.NA",
          "math.DS",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "QSR",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.270370"
    },
    {
      "id": "arxiv-2602.15443v1",
      "title": "Tropical linearization and stability analysis of discrete dynamical systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15443v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The tropical semiring is a semiring of extended real numbers, where the operations of `max' and `+' replace the usual addition and multiplication, respectively. Difference equations obtained from the ultradiscrete limit of discrete dynamical systems are described in terms of the tropical semiring. We propose a tropical linearization approach for the stability analysis of difference equations, including those describing ulradiscrete dynamical systems. We show that the fixed point at the tropical origin is asymptotically stable if the maximum eigenvalue of the tropical Jacobian matrix is negative. On the other hand, it is unstable if the maximum eigenvalue of the tropical Jacobian matrix is positive. Since $0$ is the tropical multiplicative identity, these results are analogous to those in the usual linearization process.",
        "keywords": [
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15443v1",
        "authors": [
          "Yuki Nishida",
          "Sennosuke Watanabe",
          "Yoshihide Watanabe"
        ],
        "arxiv_categories": [
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.270596"
    },
    {
      "id": "arxiv-2602.15411v1",
      "title": "Conservativeness of time changed processes and Liouville property for Schrödinger operators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15411v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We establish a criterion for the Liouville property for Schrödinger operators via the conservativeness of time changed processes. Using this criterion, we obtain necessary and sufficient conditions for the Liouville property for some Schrödinger operators in terms of the decay rates of the potentials at infinity/boundary.",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15411v1",
        "authors": [
          "Yuichi Shiozawa",
          "Masayoshi Takeda"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.270821"
    },
    {
      "id": "arxiv-2602.15399v1",
      "title": "Total variation regularization with reduced basis in electrical impedance tomography",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15399v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This work considers using reduced basis techniques in connection to (smoothened) total variation regularization in electrical impedance tomography, but analogous ideas can also be used for other inverse elliptic boundary value problems. It is demonstrated that resorting to reduced bases can speed up a reconstruction algorithm based on combining the lagged diffusivity algorithm with sequential linearizations and preconditioned LSQR iteration without any significant loss of reconstruction quality or of the edge-enhancing nature of total variation regularization. The ideas are numerically tested in three dimensions on unstructured finite element meshes with both simulated and experimental data, resulting in online reconstruction times of only a few seconds on a standard laptop computer.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15399v1",
        "authors": [
          "A. Hannukainen",
          "N. Hyvönen",
          "V. Toresen"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "LSQR",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.271042"
    },
    {
      "id": "arxiv-2602.15394v1",
      "title": "A Regularized Framework and Admissible Solutions for Liquid-Vapor Phase Transitions in Steady Compressible Flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15394v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the well-posedness of the periodic boundary value problem for the steady compressible isentropic Navier-Stokes system under the van der Waals equation of state. The main difficulty arises from the non-monotonicity of the pressure, which induces liquid-vapor phase transitions and consequently leads to both physical instabilities and mathematical non-uniqueness of solutions. It is shown that the occurrence of a phase transition is determined by whether the integral average of the specific volume lies inside the gas-liquid coexistence region defined by the Maxwell construction. By introducing an artificial viscosity, we construct an approximate system. When the integral average of the specific volume falls within the Maxwell region, the approximate solution converges, as the artificial viscosity tends to zero, to the equilibrium states given by Maxwell's construction, with the diffuse interface sharpening into a discontinuity. Conversely, if the integral average of the specific volume lies outside this region, the limiting solution remains outside as well, meaning that no phase transition occurs. These results demonstrate that the non-monotonicity of the pressure, combined with the condition that the integral average of the specific volume belongs to the Maxwell region, can act as a nucleation mechanism for phase transitions in the isentropic gas-liquid problem. Furthermore, the proposed approximation not only offers a regularized framework for describing phase transitions but also provides, from a rigorous mathematical viewpoint, a definition of admissible solutions related to phase transitions. The detailed proof relies on the artificial viscosity method, the calculus of variations, the anti-derivative technique, phase-plane analysis, and the level-set method.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15394v1",
        "authors": [
          "Yazhou Chen",
          "Qiaolin He",
          "Dongjuan Niu",
          "Yi Peng",
          "Xiaoding Shi"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Steady Compressible Flows We",
        "Vapor Phase Transitions",
        "Regularized Framework",
        "Admissible Solutions",
        "Framework",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.271473"
    },
    {
      "id": "arxiv-2602.15390v1",
      "title": "Space-filling lattice designs for computer experiments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15390v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper investigates the construction of space-filling designs for computer experiments. The space-filling property is characterized by the covering and separation radii of a design, which are integrated through the unified criterion of quasi-uniformity. We focus on a special class of designs, known as quasi-Monte Carlo (QMC) lattice point sets, and propose two construction algorithms. The first algorithm generates rank-1 lattice point sets as an approximation of quasi-uniform Kronecker sequences, where the generating vector is determined explicitly. As a byproduct of our analysis, we prove that this explicit point set achieves an isotropic discrepancy of $O(N^{-1/d})$. The second algorithm utilizes Korobov lattice point sets, employing the Lenstra--Lenstra--Lovász (LLL) basis reduction algorithm to identify the generating vector that ensures quasi-uniformity. Numerical experiments are provided to validate our theoretical claims regarding quasi-uniformity. Furthermore, we conduct empirical comparisons between various QMC point sets in the context of Gaussian process regression, showcasing the efficacy of the proposed designs for computer experiments.",
        "keywords": [
          "stat.ME",
          "math.NA",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15390v1",
        "authors": [
          "Naoki Sakai",
          "Takashi Goda"
        ],
        "arxiv_categories": [
          "stat.ME",
          "math.NA",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "EPA",
        "MIT",
        "QMC",
        "LLL",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.272048"
    },
    {
      "id": "arxiv-2602.15370v1",
      "title": "A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15370v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates.",
        "keywords": [
          "math.OC",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15370v1",
        "authors": [
          "Hannah Michalska",
          "Miguel Torres-Torriti"
        ],
        "arxiv_categories": [
          "math.OC",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Feedback Stabilization",
        "Geometric Approach",
        "Nonlinear Systems",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.272289"
    },
    {
      "id": "arxiv-2602.15365v1",
      "title": "Data Informativeness in Linear Optimization under Uncertainty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15365v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the problem of determining what data is required to solve a decision-making task when only partial information about the state of the world is available. Focusing on linear programs, we introduce a decision-focused notion of data informativeness that formalizes when a data set is sufficient to recover the optimal decision. Our notion abstracts away the notion of estimators (how data is used): it depends solely on the structure of the optimization task and the uncertainty. Our main result provides a geometric characterization of data sufficiency: a data set is sufficient if and only if, together with prior knowledge, it captures all cost directions that can change the optimal solution, given the task structure and the uncertainty set. Building on our characterization, we develop a tractable algorithm to determine minimal sufficient data sets under general data collection constraints. Taken together, our work introduces a principled framework for task-aware data collection. We demonstrate the approach in two applications: selecting where to conduct field experiments to inform infrastructure design and choosing which candidates to interview in order to make an optimal hiring decision. Our results illustrate that small, carefully selected data sets often suffice to determine the optimal decisions.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15365v1",
        "authors": [
          "Omar Bennouna",
          "Amine Bennouna",
          "Saurabh Amin",
          "Asuman Ozdaglar"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Data Informativeness",
        "Linear Optimization",
        "Uncertainty We",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.272618"
    },
    {
      "id": "arxiv-2602.15328v1",
      "title": "Non-Stationary Covariance Functions for Spatial Data on Linear Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15328v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a novel class of non-stationary covariance functions for random fields on linear networks that allows both the variance and the correlation range of the random field to vary spatially. The proposed covariance functions are useful to model random fields with a spatial dependence that is locally isotropic with respect to the resistance metric, a distance that reflects the topology of the network. We assess the statistical and computational performance of a weighted local likelihood estimator for the proposed models using synthetic data generated on the street network of the University of Chicago neighborhood.",
        "keywords": [
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15328v1",
        "authors": [
          "Alfredo Alegría"
        ],
        "arxiv_categories": [
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stationary Covariance Functions",
        "Linear Networks We",
        "Spatial Data",
        "University",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.272805"
    },
    {
      "id": "arxiv-2602.15316v1",
      "title": "Point Count of the Top-dimensional Open Positroid Variety",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15316v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In [GL24], Galashin and Lam discovered that when $k$ and $n$ are coprime, the proportion of subspaces in $\\mathrm{Gr}(k,n)(\\mathbb{F}_q)$ that lie in the top-dimensional open positroid variety $Π_{k,n}^\\circ(\\mathbb{F}_q)$ is $|(\\mathbb{F}_q^\\times)^n|/|\\mathbb{F}_{q^n}^\\times|$. In this paper, I recover this point count identity by relating the split torus action on $(Π_{k,n}^\\circ)_{\\mathbb{F}_q}$ and an anisotropic torus action on a $\\mathbb{F}_q$ rational form of $Π_{k,n}^\\circ$. The main step in the point count argument and the main technical result in this paper is that cyclic rotation acts trivially on the torus-equivariant cohomology of $Π_{k,n}^\\circ$ when $k$ and $n$ are coprime.",
        "keywords": [
          "math.CO",
          "math.AG",
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15316v1",
        "authors": [
          "Calvin Yost-Wolff"
        ],
        "arxiv_categories": [
          "math.CO",
          "math.AG",
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Open Positroid Variety In",
        "Point Count",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.273224"
    },
    {
      "id": "arxiv-2602.15300v1",
      "title": "Carleman Inequalities for the Heat Equation with Fourier Boundary Conditions: Applications to Null Controllability Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15300v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work, we establish a Carleman inequality for the heat equation with Fourier boundary conditions of the form $\\partial_νy+by=f1_γ$, where the control acts on a small portion $γ$ of the boundary. We apply this inequality to address the null controllability problem with boundary control supported on this small region. An explicit solution to this problem is obtained via a system of coupled parabolic equations. Based on these results, we propose an iterative numerical method to solve the coupled system.",
        "keywords": [
          "math.OC",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15300v1",
        "authors": [
          "Jose Antonio Villa"
        ],
        "arxiv_categories": [
          "math.OC",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Null Controllability Problems In",
        "Fourier Boundary Conditions",
        "Carleman Inequalities",
        "Heat Equation",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.273649"
    },
    {
      "id": "arxiv-2602.15299v1",
      "title": "Szemerédi's Theorem Along Cantor Sets of Integers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15299v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Let $\\mathcal C= \\{k_1<k_2 < \\cdots\\}$ be Cantor set of integers, that is a set of integers with restricted digits modulo a base $b$, and suppose $0$ is one of the restricted digits. We show that $$ \\liminf_N \\Expectation_{n\\in [N]} m(A\\cap T^{-k_n} A \\cap \\cdots \\cap T^{-\\ell k_n} A )>0. $$ This is an extension of the IP Ergodic Theorem of Furstenberg and Katznelson, and a partial extension of recent work of Kra and Shalom. In particular, this implies that for any subset of integers $A$ of positive upper Banach density, there is a set $B$ of integers $n$ of positive lower Banach density such that $A$ contains an $\\ell+1$ term progression, with step size $k_n$, where $n\\in B$. This is a complement to recent results of Kra and Shalom, for IP Sets of integers, and Burgin, concerning Sarkozy's Theorem for Primes with restricted digits.",
        "keywords": [
          "math.NT",
          "math.CA",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15299v1",
        "authors": [
          "Alex Burgin",
          "Anastasios Fragkos",
          "Michael T. Lacey",
          "Dario Mena",
          "Maria Carmen Reguera"
        ],
        "arxiv_categories": [
          "math.NT",
          "math.CA",
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Integers Let",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:25.274094"
    },
    {
      "id": "arxiv-2602.15824v1",
      "title": "Connection formulas for Askey--Wilson polynomials and related expansions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15824v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We derive and study expansions of and over the Askey--Wilson polynomials. We study these expansions and examine some limits to the continuous dual $q$-Hahn, Al-Salam--Chihara, continuous big $q$-Hermite and continuous $q$-Hermite polynomials and their $q^{-1}$-analogues. The Poisson kernel for the infinite discrete orthogonality relation for the $q^{-1}$-Al-Salam--Chihara polynomials is derived which in a special case reduces to the Gupta--Masson biorthogonal rational ${}_4φ_3$-functions. This Poisson kernel implies new infinite series connection relations for the Askey--Wilson polynomials involving these rational ${}_4φ_3$-functions. We also consider various interesting limits.",
        "keywords": [
          "math.CA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15824v1",
        "authors": [
          "Howard S. Cohl",
          "Wolter Groenevelt"
        ],
        "arxiv_categories": [
          "math.CA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.688138"
    },
    {
      "id": "arxiv-2602.15812v1",
      "title": "Separable C*-algebras Without the Countable Axiom of Choice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15812v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The goal of this paper is twofold. In addition to the results stated in the next paragraph, we present some classical results on absoluteness relevant to functional analysis that are well known to logicians but not nearly as well advertised as they should be. We show that the theory of separable C*-algebras can be developed in ZF (that is, without using any Choice). This includes proving the Gelfand-Naimark representation theorems as well as the Spectral Mapping Theorem for polynomials and developing continuous functional calculus for commuting normal elements. Some of our proofs are modifications of the standard ones, obtained by avoiding the use of Choice. Some other proofs require new ideas in order to avoid the use of Choice. Yet another batch of proofs proceeds by using the set-theoretic Shoenfield Absoluteness Theorem. This result (well known to logicians but regrettably not as well advertised as it deserves) implies that statements about standard Borel spaces of low quantifier complexity that are provable in ZFC, or even ZFC together with the Continuum Hypothesis are provable in ZF. One of the main objectives of this paper is to present these results in a convenient form that can be utilized by analysts not familiar with set theory. We also show that in the absence of Choice (more precisely, assuming the existence of a Russell set) there is a concretely representable unital commutative \\cstar-algebra that is not isomorphic to C(X) for any compact Hausdorff space X. Finally, from the model-theoretic point of view, while the property of having a tracial state is provably axiomatizable in ZFC, it is not provably axiomatizable in ZF+DC.",
        "keywords": [
          "math.OA",
          "math.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15812v1",
        "authors": [
          "Bruce Blackadar",
          "Ilijas Farah"
        ],
        "arxiv_categories": [
          "math.OA",
          "math.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Continuum Hypothesis",
        "Countable Axiom",
        "Standard",
        "EPA",
        "ZFC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.688544"
    },
    {
      "id": "arxiv-2602.15807v1",
      "title": "The dimension of the tangent bundle and the universality of the vertical lift",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15807v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper explores a new perspective on the universality of the vertical lift in tangent categories by presenting a categorification of the dimension of smooth manifolds. The universality of the vertical lift is a key part of the axioms of a tangent category as presented in [4]. The categorical dimension presented in this paper provides insight into the nature of this property. The main result is Theorem 3.7, showing that if it exists, the dimension of the tangent bundle must fulfill an equation relating the dimension of the tangent bundle to the dimension of the base. In particular, when the dimension function is a strong tangent dimension, Theorem 3.8 shows that the dimension of the tangent bundles is either twice the dimension of the base, or equal to the dimension of the base. Many examples of dimension functions are provided to demonstrate the utility of the definition. In particular, a consequence of Theorem 3.7 is that there are limitations on which functors may be tangent bundle endofunctors for a category. We show that this means that there are no non-trivial tangent structures on sets, as an example.",
        "keywords": [
          "math.CT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15807v1",
        "authors": [
          "Florian Schwarz"
        ],
        "arxiv_categories": [
          "math.CT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.688809"
    },
    {
      "id": "arxiv-2602.15804v1",
      "title": "General Casorati Inequality for Riemannian Submersions Involving Horizontal and Vertical Casorati Curvatures and Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15804v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we develop and introduce a Casorati inequality for Riemannian submersions involving the Casorati curvatures of both the vertical and horizontal distributions. A general form of the inequality is derived for Riemannian submersions between Riemannian manifolds, and the corresponding equality cases are completely characterised. As applications, we obtain the inequality for Riemannian submersions whose total spaces are real, complex, generalised Sasakian, Sasakian, cosymplectic, Kenmotsu, and almost $c(α)$-space forms. For each theorem, we present illustrative examples. Some of these examples achieve equality, while others do not. Furthermore, these inequalities are derived for invariant, anti-invariant, slant, semi-slant, hemi-slant, and bi-slant Riemannian submersions.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15804v1",
        "authors": [
          "Ravindra Singh"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Riemannian Submersions Involving Horizontal",
        "Vertical Casorati Curvatures",
        "General Casorati Inequality",
        "Applications In",
        "WHO",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.689268"
    },
    {
      "id": "arxiv-2602.15798v1",
      "title": "Mutation of torsion pairs for finite-dimensional algebras",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15798v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the lattice $\\mathbf{tors}(A)$ of torsion pairs in the category $\\mathrm{mod}(A)$ of finitely generated modules over an artinian ring $A$. It was shown by the authors in previous work that $\\mathbf{tors}(A)$ is isomorphic to a lattice formed by certain closed sets, called maximal rigid, in the Ziegler spectrum of the unbounded derived category $\\mathrm{D}(A)$ of $A$. Moreover, the structure of this lattice is described by an operation on maximal rigid sets which encompasses (the dual of) silting mutation. In this paper we provide an explicit description of this operation and we discuss how it is reflected in the lattice $\\mathbf{tors}(A)$. We establish a bijection between the wide intervals in $\\mathbf{tors}(A)$ and the closed rigid sets in the Ziegler spectrum of $\\mathrm{D}(A)$. Moreover, we show that the arrows in the Hasse quiver of $\\mathbf{tors}(A)$ correspond to the closed rigid sets that are almost complete, or equivalently, that can be completed to a maximal rigid set in exactly two ways. Our results are most interesting in the case when $A$ is a finite dimensional algebra. In fact, we generalise results by Adachi, Iyama and Reiten, with an important difference: not every point in a maximal rigid set is mutable. We use the topology on the Ziegler spectrum to determine the mutable points. In the last section of the paper we illustrate our results by the example of a finite dimensional algebra arising from a triangulation of an annulus.",
        "keywords": [
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15798v1",
        "authors": [
          "Lidia Angeleri Hügel",
          "Rosanna Laking",
          "Francesco Sentieri"
        ],
        "arxiv_categories": [
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.689590"
    },
    {
      "id": "arxiv-2602.15796v1",
      "title": "On the triple product property for subgroups of finite nilpotent groups of class $2$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15796v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A number of upper bounds are proved relating to the triple product property (TPP) for subgroups of finite nilpotent groups of class $2$. The TPP is the property defined for three non-empty subsets $S, T, U$ of a group $G$ that the group equation $s's^{-1}t't^{-1}u'u^{-1} = 1$, over pairs of elements $s', s \\in S$, $t', t \\in T$, $u', u \\in U$, is satisfied if and only if $s' = s$, $t' = t$, $u' = u$. When $G$ is finite, and the parameter $ρ_0(G)$, called \\emph{subgroup TPP ratio}, is defined as $ρ_0(G) := \\max\\frac{|S||T||U|}{|G|}$, where the maximum is over the collection of all triples of subgroups $S, T, U$ of $G$ satisfying the TPP, this paper proves that \\textup{(1)} $ρ_0(G) < \\sqrt{|G:Z(G)}$} for (all) groups of nilpotency class $2$, \\textup{(2)} $ρ_0(G) \\leq p$ for $p$-groups with a cyclic commutator subgroup of order $p$, \\textup{(3)} $ρ_0(G) = 1$ for $p$-groups of nilpotency class $2$ with a \"large\" centre, loosely defined as those satisfying $p^2 \\leq |G:Z(G)| \\leq p^3$, \\textup{(4)} and $ρ_0(G) = 1$ for $p$-groups of nilpotency class $2$ with \"small\" (irreducible, complex) character degrees of $1$ or $p$.",
        "keywords": [
          "math.GR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15796v1",
        "authors": [
          "Sandeep R. Murthy"
        ],
        "arxiv_categories": [
          "math.GR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "TPP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.690197"
    },
    {
      "id": "arxiv-2602.15771v1",
      "title": "Generic neck pinch singularities along 2D Lagrangian mean curvature flow",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15771v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a notion of nondegenerate neck pinch singularity along the Lagrangian mean curvature flow of surfaces in a Calabi-Yau surface. We show that such singularities can occur, are stable under small perturbations, and any neck pinch singularity can be perturbed to such a nondegenerate singularity near the singular time. Using this we answer some questions raised by Neves and Joyce. We also introduce nondegenerate teardrop singularities and show that these cannot occur for embedded flows.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15771v1",
        "authors": [
          "Gábor Székelyhidi"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.690397"
    },
    {
      "id": "arxiv-2602.15748v1",
      "title": "Conjugacy classes of regular integer matrices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15748v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper is devoted to the theory of $GL_n({\\mathbb Z})$-conjugacy classes of regular integer $n\\times n$ matrices. Such a matrix is $GL_n({\\mathbb Q})$-conjugate to the companion matrix of its characteristic polynomial. But the set of $GL_n({\\mathbb Z})$-conjugacy classes of regular integer matrices with a fixed characteristic polynomial $f$ is usually nontrivial (finite if $f$ has simple roots, infinite if $f$ has multiple roots). It is in 1:1-correspondence to a subsemigroup of a certain quotient semigroup of the commutative semigroup of full lattices in the algebra ${\\mathbb Q}[t]/(f)$. In its first part, the paper gives a survey on old and new results on full lattices and orders in a finite dimensional commutative ${\\mathbb Q}$-algebra with unit element and on induced semigroups. In its longer second part, the paper applies this theory to many examples, essentially all cases with $n=2$, many cases with $n=3$ and two cases with arbitrary $n$, the case with $n$ different integer eigenvalues and the case of a single $n\\times n$ Jordan block.",
        "keywords": [
          "math.RA",
          "math.NT",
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15748v1",
        "authors": [
          "Claus Hertling",
          "Khadija Larabi"
        ],
        "arxiv_categories": [
          "math.RA",
          "math.NT",
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.690659"
    },
    {
      "id": "arxiv-2602.15728v1",
      "title": "Immersions with small normal curvature",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15728v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study Gromov's problem concerning minimal normal curvature immersions in the unit ball. In particular, we determine the minimal possible value of the normal curvature of an $S^n\\times S^1$. We also prove a differentiable sphere theorem and an existence result for minimizers in this context.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15728v1",
        "authors": [
          "Otis Chodosh",
          "Chao Li"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.690757"
    },
    {
      "id": "arxiv-2602.15726v1",
      "title": "Minimal Projective Resolutions, Möbius Inversion, and Bottleneck Stability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15726v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a stability theory for minimal projective resolutions of $\\mathbf{P}$-modules, where $\\mathbf{P}$ is a finite metric poset. On the module side, we introduce the \\emph{Galois transport distance}, defined by factoring two modules through a common ``apex'' poset via pairs of Galois insertions and measuring the maximal displacement in the index poset. This construction generalizes the interleaving distance in both the classical one-parameter and multiparameter settings, and yields an extended metric on isomorphism classes of $\\mathbf{P}$-modules. On the homological side, we define a bottleneck distance between minimal projective resolutions by matching indecomposable projectives degreewise, with contractible cones playing the role of diagonal terms. Our main theorem shows that this resolution-level bottleneck distance is always bounded above by the Galois transport distance, providing a metric stability result formulated entirely at the level of modules and their minimal projective resolutions. We then treat persistence as an application. Passing to the interval poset and a kernel construction, we interpret persistence diagrams as minimal projective resolutions of kernel modules and obtain a corresponding stability inequality. In the one-parameter case this recovers classical bottleneck stability, while in the multiparameter setting it extends naturally to signed diagrams arising from minimal projective resolutions. Via a general relationship between minimal projective resolutions and Möbius inversion, these results can be interpreted as a stability theorem for Möbius homology, while remaining entirely phrased in the language of projective resolutions.",
        "keywords": [
          "math.RT",
          "math.AT",
          "math.CT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15726v1",
        "authors": [
          "Hideto Asashiba",
          "Amit K. Patel"
        ],
        "arxiv_categories": [
          "math.RT",
          "math.AT",
          "math.CT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Minimal Projective Resolutions",
        "Bottleneck Stability We",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.691467"
    },
    {
      "id": "arxiv-2602.15717v1",
      "title": "On the existence of a morphism between certain Artin-Schreier curves",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15717v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It is well known that, given two curves $\\mathcal{X}: y^p+cy=x^m$ and $\\mathcal{Y}:y^p+cy=x^n$, defined over $\\F_p$, if $n$ divides $m$ then there exists a nonconstant morphism $\\mathcal{X} \\longrightarrow \\mathcal{Y}$. In this paper we are interested in studying whether the converse of this statement is true, i.e., if there exists a morphism $\\mathcal{X} \\longrightarrow\\mathcal{Y}$ then must it be true that $n$ divides $m$? In particular, we consider the case when $m=p^{k}+1$ and $n=p^\\ell+1$. We prove that the converse is true under certain hypotheses. We deal with both the cases of Galois morphisms and non-Galois morphisms.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15717v1",
        "authors": [
          "Beatriz Barbero Lucas",
          "Stefano Lia",
          "Gary McGuire"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.691656"
    },
    {
      "id": "arxiv-2602.15713v1",
      "title": "On the minimum modulus of dual truncated Toeplitz operators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15713v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This article provides a systematic investigation of the minimum modulus of dual truncated Toeplitz operators (DTTOs) $D_{\\varphi}$ acting on the orthogonal complement of the model space $\\mathcal{K}_u^{\\perp}$, where $u$ is a nonconstant inner function and $\\varphi \\in L^\\infty(\\T)$. We first establish an explicit formula for the minimum modulus of the compressed shift $S_u$ and its dual $D_u$ in terms of $|u(0)|$, and prove that the minimum is always attained. For normal DTTOs, we derive sharp spectral bounds utilizing the essential range of the symbol and characterize the conditions under which $m(D_{\\varphi})$ coincides with the essential infimum of $|\\varphi|$. In the general setting, for unimodular $\\vp$, we obtain exact formulas and two sided estimates for $m(D_{\\varphi})$ by analyzing the norms of associated Toeplitz and Hankel operators restricted to the model space. Finally, we provide several concrete examples to illustrate our results.",
        "keywords": [
          "math.FA",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15713v1",
        "authors": [
          "Sudip Ranjan Bhuia",
          "Ramesh Golla",
          "Puspendu Nag"
        ],
        "arxiv_categories": [
          "math.FA",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.691877"
    },
    {
      "id": "arxiv-2602.15703v1",
      "title": "Nef divisors of surfaces given by pencils at infinity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15703v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We give generators for the nef cone and the cone of curves of rational surfaces obtained by blowing-up the complex projective plane at a set of points $\\mathcal{B} \\cup \\mathcal{D}$, where $\\mathcal{B}$ is the set of (proper and infinitely near) base points of a pencil associated with a curve having one place at infinity, and $\\mathcal{D}$ is a set of finitely many infinitely near free points on the strict transforms of curves of the pencil. We also prove that, when the pencil is given by an AMS-type curve and $\\mathcal{D}$ contains at most two free points on any curve considered, the Cox ring of the obtained surface is finitely generated.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15703v1",
        "authors": [
          "Carlos Galindo",
          "Francisco Monserrat",
          "Carlos-Jesús Moreno-Ávila",
          "Elvira Pérez-Callejo"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSF",
        "AMS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692047"
    },
    {
      "id": "arxiv-2602.15696v1",
      "title": "A Knaster--Reichbach type theorem for graph structures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15696v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the properties of a generic object $\\mathbb{P}$ in the category of finite graphs. It turns out that this object, being topologically a Cantor set, has the Knaster--Reichbach type property. Namely, every homeomorphism and isomorphism $h\\colon K\\to L$ where $K$ and $L$ are nowhere dense closed sets in $\\mathbb{P}$ and consisting only of isolated vertices in $K$ and $L$ can be extended to the autohomeomorphism and autoisomorphism of the whole graph $\\mathbb{P}$.",
        "keywords": [
          "math.GN",
          "math.CT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15696v1",
        "authors": [
          "Wiesław Kubiś",
          "Andrzej Kucharski",
          "Sławomir Turek"
        ],
        "arxiv_categories": [
          "math.GN",
          "math.CT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "WHO"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692220"
    },
    {
      "id": "arxiv-2602.15685v1",
      "title": "Upper bounds for logarithmic Gromov-Witten invariants of projective space",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15685v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We provide an upper bound for the genus zero logarithmic Gromov-Witten invariants of projective space relative to its toric boundary. The upper bound is polynomial in the contact orders, with degree depending on the number of marked points. The result hinges on the positivity of intersections for projective spaces.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15685v1",
        "authors": [
          "Dan Simms"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692351"
    },
    {
      "id": "arxiv-2602.15667v1",
      "title": "Relative and lax volutive categories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15667v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper we introduce the notion of a relative volutive (higher) category, specializing to the notion of a lax volutive (higher) category. Our primary motivation to study these objects is the following: while any rigid symmetric monoidal category admits a volutive structure, any closed symmetric monoidal category admits a lax volutive structure. We develop some of the basic theory of relative volutive categories and provide several equivalent formulations of lax volutive categories. We then study examples of interest, including categories of complete bornological vector spaces and modules over star-rings. We will also separately discuss unbounded operators between Hilbert spaces and Morita 2-categories, the latter of which in the context of fully closed symmetric monoidal 2-categories.",
        "keywords": [
          "math.CT",
          "math.QA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15667v1",
        "authors": [
          "Tim Lüders"
        ],
        "arxiv_categories": [
          "math.CT",
          "math.QA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "EPA",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692535"
    },
    {
      "id": "arxiv-2602.15666v1",
      "title": "The stability of Yang-Mills connections on $δ$-pinched manifolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15666v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this article, we establish pinching conditions under which all weakly stable Yang-Mills connections on compact manifolds are flat. As a corollary, we provide a dimension-dependent constant $δ(n)$ and prove that there exist no non-flat weakly stable Yang-Mills connections on $δ(n)$-pinched compact simply-connected Riemannian manifolds.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15666v1",
        "authors": [
          "Xiaoli Han",
          "Yang Wen"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692738"
    },
    {
      "id": "arxiv-2602.15665v1",
      "title": "Magnetic Hardy inequalities with singular integral weights",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15665v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper we present Hardy type inequalities for magnetic Dirichlet forms with singular integral weights. We analyze the local and global optimality of the integral weight and discuss several examples in details. An application of our results to spectral estimates for magnetic Schrödinger operators is provided as well.",
        "keywords": [
          "math-ph",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15665v1",
        "authors": [
          "Hynek Kovarik",
          "Pier Cristoforo Rossaro"
        ],
        "arxiv_categories": [
          "math-ph",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Magnetic Hardy",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.692909"
    },
    {
      "id": "arxiv-2602.15661v1",
      "title": "On the long time behavior of ancient homogeneous Ricci flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15661v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We prove a precompactness theorem for invariant metrics on compact homogeneous spaces without injectivity radius bounds, assuming uniform bounds on the diameter and on all derivatives of the curvature tensor. As a consequence, we prove that every ancient homogeneous Ricci flow on a compact manifold admits a blow-down sequence that converges to a gradient shrinking Ricci soliton.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15661v1",
        "authors": [
          "Anusha M. Krishnan",
          "Francesco Pediconi"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.693014"
    },
    {
      "id": "arxiv-2602.15641v1",
      "title": "On the discriminant and index of a certain class of polynomials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15641v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Let $f(x) = (x^{2}+1)^{n} - a x^{n} \\in \\mathbb{Z}[x]$ and assume $f(x)$ is irreducible. Let $θ$ be a root of $f(x)$, set $K= \\mathbb{Q}(θ)$, and denote by $\\mathbb{Z}_{K}$ the ring of integers of $K$. The index of $f$, denoted $\\operatorname{ind}(f)$, is the index of $\\mathbb{Z}[θ]$ in $\\mathbb{Z}_{K}$. A polynomial $f(x)$ is said to be monogenic if $\\operatorname{ind}(f) = 1$. In this article, we explicitly compute the discriminant of the polynomial $f(x)$, and then derive necessary and sufficient conditions on the parameters $a$ and $n$ for $f(x)$ to be monogenic. Furthermore, we provide a complete description of the primes that divide $\\operatorname{ind}(f)$.",
        "keywords": [
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15641v1",
        "authors": [
          "Rupam Barman",
          "Anuj Narode",
          "Vinay Wagh"
        ],
        "arxiv_categories": [
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.693356"
    },
    {
      "id": "arxiv-2602.15636v1",
      "title": "On certain subspaces of $2$-configuration spaces of graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15636v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the large-scale geometry of graph braid groups \\(\\bbB_n(\\graf)\\) using the cubical structure of their discrete configuration spaces \\(UD_n(\\graf)\\). First, we give a complete classification of when a graph \\(n\\)-braid group is free, using only cubical methods and without appealing to discrete Morse theory. We then focus on graph \\(2\\)-braid groups and study the square complex \\(UD_2(\\graf)\\), which is special in the sense of Haglund--Wise, via its maximal product subcomplexes and intersection complex introduced in \\cite{Oh22}. Under natural connectivity and embeddedness assumptions, we show that the union \\(UP_2(\\graf)\\) of maximal product subcomplexes of \\(UD_2(\\graf)\\) captures essential quasi-isometry information of \\(\\bbB_2(\\graf)\\), the fundamental group of \\(UD_2(\\graf)\\). Applying this framework to an infinite family of graphs, we obtain infinitely many graph \\(2\\)-braid groups that are quasi-isometric to right-angled Artin groups and infinitely many that are not, extending the examples of \\cite{Oh22}, and we indicate new phenomena in relative hyperbolicity.",
        "keywords": [
          "math.GT",
          "math.GR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15636v1",
        "authors": [
          "Byung Hee An",
          "Sangrok Oh"
        ],
        "arxiv_categories": [
          "math.GT",
          "math.GR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.693577"
    },
    {
      "id": "arxiv-2602.15629v1",
      "title": "Steenrod operations and symplectic arithmetic duality",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15629v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This expository article elaborates upon my talk at the 2025 AMS Summer Institute on Algebraic Geometry. It gives an introduction to a conjecture from Tate's 1966 Séminaire Bourbaki report, predicting the existence of a symplectic form on Brauer groups of surfaces over finite fields, and then an informal tour of the proof in \\cite{Feng20} and \\cite{CF}.",
        "keywords": [
          "math.AG",
          "math.AT",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15629v1",
        "authors": [
          "Tony Feng"
        ],
        "arxiv_categories": [
          "math.AG",
          "math.AT",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Algebraic Geometry",
        "Summer Institute",
        "Institute",
        "AMS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.693756"
    },
    {
      "id": "arxiv-2602.15612v1",
      "title": "Partial desingularization in characteristic 0",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15612v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It is shown by Belotto da Silva and Bierstone [arXiv:2602.09114] and Włodarczyk [arxiv:2602.14266] that, if one allows to introduce stack theoretic weighted blowups, any variety $X$ over a field of characteristic 0 admits a normal crossings resolution. We introduce a principle that makes such results possible and inevitable, see Theorem 3.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15612v1",
        "authors": [
          "Dan Abramovich",
          "Michael Temkin"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:30.693958"
    },
    {
      "id": "arxiv-2602.15768v1",
      "title": "Southern Ocean latent heat flux variability driven by oceanic meso- and submesoscale motions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15768v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Latent heat flux is a primary pathway for ocean-atmosphere exchange of heat and moisture, yet the influence of sea surface temperature variability at fine scales ($\\leq$ 100 km) on latent heat flux variability, particularly over the Southern Ocean, remains poorly understood. Here we quantify the scale-dependent drivers of latent heat flux (LHF) variability using a year-long, global, fully coupled ocean-atmosphere simulation with kilometer-scale resolution. Annual-mean LHF in eddy-rich regions reaches $\\approx$ 215 W m$^{-2}$, approximately three times larger than in eddy-poor regions. Spectral analyses show that ocean mesoscale [$\\mathcal{O}$(100 km)] and submesoscale [$\\mathcal{O}$(1-10 km)] variability accounts for up to $\\approx$ 80% of the total LHF variance in eddy-rich sectors, but as little as 10% in eddy-poor regions, and increases proportionally with eddy kinetic energy and sea surface temperature (SST) variance. We also find that strong submesoscale SST fronts ($\\approx$ 5 $^\\circ$C over 10 km) force a localized secondary circulation that extends well above the marine boundary layer into the mid-troposphere. Comparison with ERA5 shows that fine ocean scales, responsible for about 17% of the ocean-driven LHF variance in the simulation, are largely unresolved in the reanalysis, leading to a muted atmospheric response lacking any secondary circulation. Despite a strong heterogeneity in LHF variability, the atmospheric dynamics are mostly uniform across the domain, suggesting a non local atmospheric response to ocean forcing. These results highlight the potential for ocean meso- and submesoscales, commonly under-resolved in climate models and reanalysis, to influence Southern Ocean air-sea coupling and atmosphere both locally and remotely.",
        "keywords": [
          "physics.ao-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15768v1",
        "authors": [
          "Lucie Reymondet",
          "Lia Siegelman",
          "Luc Lenain"
        ],
        "arxiv_categories": [
          "physics.ao-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Southern Ocean",
        "LHF",
        "SST",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.004202"
    },
    {
      "id": "arxiv-2602.15744v1",
      "title": "Effect of flexibility on the pitch-heave flutter instability of a flexible foil elastically supported on its leading edge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15744v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An analytical tool is presented to compute the parametric regions of flutter instabilities of a two-dimensional flexible foil elastically mounted. It is based on a new analytical formulation of the unsteady fluid-estructure interaction valid for small-amplitude oscillations and deformations of the foil immersed in an inviscid fluid. The formulation extends a previous analysis by including the effects of gravity and a second flexural mode, increasing its validity range to much smaller rigidities. The analytical results are validated with available numerical results, capturing the first two natural flexural modes down to values of the stiffness parameter $S$ of order $10^{-1}$. When only passive heave, or only passive pitch, is allowed, the rigid foil is stable, existing an upper stiffness bound for the flexural instabilities, wich become coupled with the spring instability mode for small spring constant increasing the growth rate. These coupled spring (linear or torsional) and flexural instability modes occur below a threshold value of $S$ and above a threshold value of $R$, both depending on the corresponding spring constant. Coupled pitch-heave flutter instabilities of a rigid foil occur in a region below a curve of the parametric plane of the two springs constants that depends on $R$, which shrinks to zero as $R$ decreases. For a flexible foil, the flexural unstable modes become coupled with the springs unstable mode as $S$ decreases from infinity, enlarging the mass ratio range for flutter instability and increasing its growth rate, the more so the smaller the springs constants. The parametric regions for flutter instabilities are easily characterized with the present analytical tool, providing the corresponding frequency and critical flutter velocity. The present results can be useful as a guide in the design of future turbines based on flexible oscillating foils.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15744v1",
        "authors": [
          "Ramon Fernandez-Feria"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.004936"
    },
    {
      "id": "arxiv-2602.15743v1",
      "title": "Physics-informed data-driven inference of an interpretable equivariant LES model of incompressible fluid turbulence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15743v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes.",
        "keywords": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15743v1",
        "authors": [
          "Matteo Ugliotti",
          "Brandon Choi",
          "Mateo Reynoso",
          "Daniel R. Gurevich",
          "Roman O. Grigoriev"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "RANS",
        "MIT",
        "LES",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.005353"
    },
    {
      "id": "arxiv-2602.15639v1",
      "title": "Equilibrium statistical mechanics of waves in inhomogeneous moving media",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15639v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We adapt the microcanonical framework of equilibrium statistical mechanics to predict the statistics of short waves in inhomogeneous moving media. For steady inhomogeneities and background flow, we compute the wave spectrum at any location in the domain based on an ergodic prescription for the action density in phase space, constrained by conservation of absolute frequency. We illustrate the method for shallow-water waves subject to a background flow or to topographic inhomogeneities, and for deep-water surface capillary waves over a background flow, validating the predicted maps of rms surface elevation and interfacial slope against numerical simulations.",
        "keywords": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15639v1",
        "authors": [
          "Alexandre Tlili",
          "Basile Gallet"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.005646"
    },
    {
      "id": "arxiv-2602.15626v1",
      "title": "Deformation and orientation of a capsule with viscosity contrast in linear flows: a theoretical study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15626v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a perturbation theory to study the shape and the orientation of an initially spherical capsule of radius R with a viscosity contrast, a surface tension σ and a bending rigidity $κ$ in linear flows. The elastic mechanical response of membrane to deformations is described by three elastic constitutive law which are either Hookean, Neohookean or Skalak type leading to the introduction of a surface shear elastic modulus $G_s$ and the Poisson ratio (or analog quantities). At the leading order, the deformation, i.e. the so-called Taylor parameter is proportional to the elastic capillary number Ca which evaluates the ratio between the external viscous stress and the elastic membrane response. In this linear regime, the results do not depend on the elastic constitutive law as expected. Without surface tension and bending rigidity, we recover the results of Barthes-Biesel & Rallison (1981) and notably the fact that the Taylor parameter does not depend on the viscosity contrast $λ$ contrary to the case of a viscous droplet. In our more general model, the deformation does no longer depend on $λ$ at the upper order. Now, the Taylor parameter also depends on two other dimensionless numbers: the surface elastocapillary ratio $σ/G_s$ and the dimensionless bending rigidity $B= κ/G_sR^2$. At the further order, the angle of inclination of the capsule with the direction of the shear flow, the analog of the Chaffey and Brenner equation for droplets is determined in each case. The results are in excellent agreement with the numerical ones performed with a code based on the boundary integral method providing an useful method to valid numerical developments.",
        "keywords": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15626v1",
        "authors": [
          "Paul Regazzi",
          "Marc Leonetti"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "DOE",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:38.006780"
    },
    {
      "id": "arxiv-2602.15599v1",
      "title": "Influence of the Inhalation Route on Tracheal Flow Structures in Patient-Specific Airways using 3D PTV",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15599v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The tracheal flow field shapes particle transport into the lower airways and thus influences both the spread of inhaled pathogens and the effectiveness of aerosol-based therapies. Identifying how different inhalation routes modify the flow field is therefore crucial for understanding lower-airway disease transmission and for guiding targeted drug delivery. To gain a detailed understanding of the influence of the inhalation route on the flow structures in the human trachea, the flow field in the trachea is investigated in vitro in a non-compliant, refractive-index matched silicone model of the human respiratory tract. The investigations comprise steady inhalation, and oscillatory flow to simulate calm breathing. A realistic breathing pattern is approximated by a sinusoidal waveform for two Reynolds numbers of $Re_{Tr} = [400, 1200]$, based on the bulk velocity at maximum volume flux and the hydraulic diameter of the trachea and two Womersley numbers of $Wo = [3, 4.5]$, representing the oscillation time scales. To capture the inherently three-dimensional and asymmetric nature of the flow field, 3D particle-tracking velocimetry measurements are performed using the Shake-The-Box algorithm. Using a refractive-index matched fluid consisting of water and glycerin, the complex flow structures inside the trachea are fully resolved. The PTV measurements confirm that the nasal and/or oral cavity must be considered when analyzing the flow field in the lower respiratory tract. In particular, we find that the presence of both cavities significantly alters the flow field compared to idealised, fully developed inflow conditions. However, velocity profiles in the sagittal and coronal plane in the trachea as well as contour plots of the of the normalized velocity magnitude evidence nearly identical flow structures for oral and nasal inhalation, indicating minimal influence of the inhalation route.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15599v1",
        "authors": [
          "Benedikt H. Johanning-Meiners",
          "Luca Mayolle",
          "Dominik Krug",
          "Michael Klaas"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Tracheal Flow Structures",
        "Inhalation Route",
        "Specific Airways",
        "NASA",
        "PTV",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.007342"
    },
    {
      "id": "arxiv-2602.15536v1",
      "title": "Novel distance-based masking and adaptive alpha-shape methods for CNN-ready reconstruction of arbitrary 2D CFD flow domains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15536v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Interpolating scattered CFD datasets onto a uniform Cartesian grid can distort the true geometry, producing a convex-hull type envelope and activating nonphysical regions. This work presents a reconstruction framework that recovers physically consistent masks before exporting CNN-ready fields. It introduces two novel strategies, distance-based masking and an adaptive alpha-shape formulation that normalizes alpha using local data resolution, and evaluates them against classical alpha-shape boundary recovery. A quantitative, topology-aware metric suite is introduced to assess retention, suppression of unsupported regions, overlap consistency, and connectivity. The novel distance-based method is robust across the geometries considered under the same threshold rule, with tau set to the minimum CFD grid spacing, and achieves 500-800 times speedups over classical alpha-shapes. The adaptive alpha-shape remains stable when its control parameter is set to 1 and is 1.7-2.6 times faster than the classical variant, which requires geometry-specific alpha tuning. A lightweight boundary inflation post-process using a minimal dilation further improves retention by up to 2.96% with negligible unsupported activation (less than 0.08%). Overall, the distance-based method is recommended as the default due to its accuracy, stability, minimal tuning, and low cost, while the adaptive alpha-shape is a strong alternative when grid-spacing information for threshold selection is unavailable. A companion web application operationalizes the workflow end to end, enabling 2D ASCII dataset upload, parameter tuning, mask and boundary generation, and export of CNN-ready outputs.",
        "keywords": [
          "physics.flu-dyn",
          "math.MG",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15536v1",
        "authors": [
          "Mehran Sharifi",
          "Gorka S. Larraona",
          "Alejandro Rivas"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "math.MG",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "ASCII",
        "CFD",
        "CNN",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.007913"
    },
    {
      "id": "arxiv-2602.15472v1",
      "title": "Fluids You Can Trust: Property-Preserving Operator Learning for Incompressible Flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15472v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a novel property-preserving kernel-based operator learning method for incompressible flows governed by the incompressible Navier-Stokes equations. Traditional numerical solvers incur significant computational costs to respect incompressibility. Operator learning offers efficient surrogate models, but current neural operators fail to exactly enforce physical properties such as incompressibility, periodicity, and turbulence. Our method maps input functions to expansion coefficients of output functions in a property-preserving kernel basis, ensuring that predicted velocity fields analytically and simultaneously preserve the aforementioned physical properties. We evaluate the method on challenging 2D and 3D, laminar and turbulent, incompressible flow problems. Our method achieves up to six orders of magnitude lower relative $\\ell_2$ errors upon generalization and trains up to five orders of magnitude faster compared to neural operators. Moreover, while our method enforces incompressibility analytically, neural operators exhibit very large deviations. Our results show that our method provides an accurate and efficient surrogate for incompressible flows.",
        "keywords": [
          "physics.flu-dyn",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15472v1",
        "authors": [
          "Ramansh Sharma",
          "Matthew Lowery",
          "Houman Owhadi",
          "Varun Shankar"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Preserving Operator Learning",
        "Incompressible Flows We",
        "Fluids You Can Trust",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.008289"
    },
    {
      "id": "arxiv-2602.15440v1",
      "title": "The First Instrumentally Documented Fall of an Iron Meteorite: atmospheric trajectory and ground impact",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15440v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Iron meteorite falls are rare compared to stony meteorites, and until recently no iron meteorite had a reliably determined pre-atmospheric orbit. This changed on 2020 November 7, when a bright fireball was observed across Sweden and neighboring regions, with optical, acoustic, and seismic detections extending up to 665 km from the trajectory. After a month-long recovery effort, a 13.8 kg iron meteorite was discovered near Ådalen, representing the first instrumentally recorded and recovered fall of its type and the first iron meteorite with a derivable heliocentric orbit; the event also exhibited the lowest terminal height measured for a well-documented fireball. We combine optical, infrasound, and seismic data to reconstruct the luminous trajectory and employ a Monte Carlo model to simulate the dark flight phase and predicted strewn field, while also investigating the plausibility of a ricochet prior to final deposition. Our analysis identifies distinct aerodynamic properties of iron meteoroids compared to stony bodies, including the influence of streamlined shapes and deep regmaglypts on drag and flight stability, underscoring the need to incorporate iron-specific parameters into entry models to constrain atmospheric dynamics and improve recovery predictions for future events.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.IM",
          "physics.geo-ph",
          "physics.ins-det",
          "physics.pop-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15440v1",
        "authors": [
          "Jarmo Moilanen",
          "Maria Gritsevich",
          "Jaakko Visuri"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.IM",
          "physics.geo-ph",
          "physics.ins-det",
          "physics.pop-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Iron Meteorite",
        "Monte Carlo",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.009210"
    },
    {
      "id": "arxiv-2602.15416v1",
      "title": "A Robust Truncated-Domain Approach for Cone--Jet Simulations in Electrospinning and Electrospraying",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15416v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Direct numerical simulations of electrospinning and electrospraying are computationally demanding due to large-scale separation between the needle and the tip-to-collector distance. The cone-jet mode that occurs in the vicinity of the needle arises from a delicate balance between surface tension, viscous stresses, inertia, and electric stresses. This mode has a central role in determining the subsequent instabilities of the jet and the eventual outcomes on the collector. Truncated-domain simulations offer a viable alternative but depend critically on the accuracy of far-field electrostatic boundary conditions. Existing truncated-domain approaches based on analytical expressions for the electric potential systematically underestimate the electric field near the needle tip and require empirical tuning informed by prior experiments or full-domain simulations, thereby limiting their predictive capability. Here, we present a general truncated-domain framework for electrohydrodynamic (EHD) simulations of the cone-jet mode that avoids these limitations. Our approach exploits inexpensive full-domain electrostatic simulations to obtain the exact electric field and potential distributions near the needle, which are then imposed as boundary conditions in an EHD simulation carried out on a truncated domain. Comparisons with full-domain EHD simulations and experimental data demonstrate that the proposed approach accurately reproduces cone-jet shapes as well as key physical quantities, including electric currents, charge distributions, velocity fields, and Maxwell stresses, while converging at substantially smaller domain sizes. The formulation eliminates tunable parameters, does not require prior knowledge of the cone-jet configuration, and significantly reduces computational cost, providing a reliable and predictive framework for studying electrohydrodynamic cone-jet flows.",
        "keywords": [
          "physics.flu-dyn",
          "cond-mat.soft",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15416v1",
        "authors": [
          "Ghanashyam K. C.",
          "Satyavrata Samavedi",
          "Harish N Dixit"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cond-mat.soft",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Electrospraying Direct",
        "Robust Truncated",
        "Jet Simulations",
        "Domain Approach",
        "Framework",
        "DOE",
        "EPA",
        "MIT",
        "EHD",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:38.009764"
    },
    {
      "id": "arxiv-2602.15806v1",
      "title": "Tunable microwave frequency synthesis with optically-derived spectral purity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15806v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Microwave synthesizers are central to test and measurement systems across applications including wireless communications, radar, spectroscopy, and time and frequency metrology. State-of-the-art microwave sources, however, are fundamentally constrained by trade-offs between frequency tunability and spectral purity. Electro-optic frequency division (eOFD) is an emerging technique for dividing down the purity of optical sources to the microwave domain. Previously reported eOFD-based synthesizers generally have limited tunability due to feedback stabilization requirements. Here we demonstrate a feed-forward eOFD architecture in which the frequency tunability of a microwave source is preserved while optical spectral purity is divided through feed-forward cancellation, without any downstream electronic frequency synthesis. By canceling the phase noise of the microwave source without feedback, this eOFD approach removes loop bandwidth and source noise constraints observed in prior eOFD architectures. We achieve octave-spanning tunability, including the entire X-band, with phase noise below -140 dBc/Hz at kilohertz offsets and a high-frequency noise floor between -155 dBc/Hz and -145 dBc/Hz for carrier frequencies from 8 to 16 GHz. This performance corresponds to single-femtosecond integrated timing jitter, enabling, to our knowledge, the first demonstration of coherent, optically referenced microwave synthesis under wide tuning with this level of spectral purity.",
        "keywords": [
          "physics.optics",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15806v1",
        "authors": [
          "James Greenberg",
          "Scott C. Egbert",
          "William F. McGrew",
          "Brendan M. Heffernan",
          "Antoine Rolland"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.432696"
    },
    {
      "id": "arxiv-2602.15780v1",
      "title": "Deep Learning for Point Spread Function Modeling in Cosmology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15780v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, \"PSF in the Full Field-of-View'' (PIFF). PIFF is widely used in leading weak-lensing surveys, including the Dark Energy Survey (DES), the Hyper Suprime-Cam (HSC) Survey, and the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST). The PSF characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the \"blurred fingerprint'' of the entire imaging system. Accurate PSF modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the Universe and the growth of large-scale structure for dark energy studies. To address the limitations of PIFF, which constructs PSF models independently for each CCD and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for PSF reconstruction. In this approach, an autoencoder is trained on stellar images obtained with the Hyper Suprime-Cam (HSC) of the Subaru Telescope and combined with a Gaussian process to interpolate the PSF across the telescope's full field of view. This hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \\times 10^{-6}$ compared to PIFF's $3.7 \\times 10^{-6}$, laying the foundation for integration into the LSST Science Pipelines.",
        "keywords": [
          "astro-ph.IM",
          "astro-ph.CO",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15780v1",
        "authors": [
          "Dayana Andrea Henao Arbeláez",
          "Pierre-François Léget",
          "Andrés Alejandro Plazas Malagón"
        ],
        "arxiv_categories": [
          "astro-ph.IM",
          "astro-ph.CO",
          "physics.data-an"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rubin Observatory Legacy Survey",
        "Point Spread Function Modeling",
        "Point Spread Function",
        "Dark Energy Survey",
        "Science Pipelines",
        "Subaru Telescope",
        "Hyper Suprime",
        "Deep Learning",
        "Cosmology We",
        "Full Field",
        "Framework",
        "LSST",
        "PIFF",
        "PSF",
        "DES"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.433501"
    },
    {
      "id": "arxiv-2602.15777v1",
      "title": "New Challenges in Plasma Accelerators: Final Focusing for Wakefield Colliders",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15777v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The focusing of particle beams for collider experiments is crucial for maximizing the luminosity and thus the discovery potential of these machines. In recent years, plasma wakefield acceleration has emerged as a leading candidate for achieving higher energy collisions with smaller facility footprints due to the large accelerating gradients in the plasma. This higher beam energy poses significant challenges for the final focusing system of the collider. Here, we discuss the various challenges of final focusing for TeV-scale plasma accelerators and propose possible solutions. Finally, we present the first design of a final focusing system for a 10 TeV linear wakefield collider, evaluate its performance, and discuss its shortcomings as well as improvements for future designs.",
        "keywords": [
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15777v1",
        "authors": [
          "Keegan Downham",
          "Spencer Gessner",
          "Lewis Kennedy",
          "Rogelio Tomás",
          "Andrei Seryi"
        ],
        "arxiv_categories": [
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Plasma Accelerators",
        "Final Focusing",
        "New Challenges"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.433875"
    },
    {
      "id": "arxiv-2602.15760v1",
      "title": "Polarization-resolved measurement of forward volume spin waves by micro-focused Brillouin light scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15760v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We show how the micro-focused BLS signal of forward volume spin waves is formed and why it remains observable despite symmetry-based \"suppression\" expectations. A reciprocity-theorem based model with vectorial diffraction-limited focusing identifies the nonnegligible longitudinal focal-field component as the key element responsible for BLS sensitivity in the forward volume geometry. We further demonstrate that full polarization analysis, implemented through polarizer-analyzer maps of coherently excited spin waves, provides information beyond the conventional crossed polarizer-analyzer readout. In a BiYIG thin film, the measured maps exhibit Stokes/anti-Stokes polarization asymmetries and nontrivial patterns that stem from quadratic magneto-optical coupling terms. Fitting the data with a model including Voigt and Cotton-Mouton contributions yields an effective Cotton-Mouton constant and shows that the quadratic response is comparable to the linear Voigt contribution.",
        "keywords": [
          "cond-mat.mes-hall",
          "physics.app-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15760v1",
        "authors": [
          "Krzysztof Szulc",
          "Mengying Guo",
          "Ondřej Wojewoda",
          "Hongyu Wang",
          "Dominik Pavelka"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "physics.app-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BLS",
        "Act",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.434394"
    },
    {
      "id": "arxiv-2602.15759v1",
      "title": "Three-Dimensional Optical-Electrical Simulation of Cs2AgBiBr6 Double Perovskite Solar Cells",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15759v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Despite significant advances in lead-free perovskite photovoltaics, achieving a balance among environmental safety and high optoelectronic performance remains challenging. The inorganic double perovskite Cs2AgBiBr6 has emerged as a promising candidate owing to its robust three-dimensional crystal structure and suitable visible-range bandgap. However, best power conversion efficiencies (PCEs) for Cs2AgBiBr6 solar cells reported so far - 6.37% experimentally and 27.78% in numerical studies - remain below the theoretical performance potential, largely due to suboptimal charge transport layers, and interface-related recombination losses. Here, we address this gap using a 3D finite-element method (FEM) implemented in COMSOL Multiphysics, which couples optical simulations with semiconductor drift-diffusion transport. To our knowledge, this work represents the first comprehensive 3D FEM-based study of a double halide perovskite solar cell. Screening of 25 electron transport layer (ETL)-hole transport layer (HTL) combinations identifies CeO2 and P3HT as the optimal ETL and HTL respectively. Device performance is further analyzed through systematic variation of layer thicknesses, doping concentrations and defect densities within the FTO/CeO2/Cs2AgBiBr6/P3HT/Au architecture. Under optimized parameters, the simulated device achieves a PCE of 31.76%, representing the theoretical upper bound predicted by the model. Overall, this work demonstrates 3D physics-based device engineering as a decisive pathway for overcoming efficiency bottlenecks in lead-free double perovskite photovoltaics.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15759v1",
        "authors": [
          "Md Shanian Moed",
          "Adnan Amin Siddiquee",
          "Md Tashfiq Bin Kashem"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Double Perovskite Solar Cells",
        "Electrical Simulation",
        "Dimensional Optical",
        "Fusion",
        "COMSOL",
        "Solar",
        "ETL",
        "FTO",
        "FEM",
        "HTL",
        "PCE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.434991"
    },
    {
      "id": "arxiv-2602.15741v1",
      "title": "Singular value decomposition to describe bound states in the continuum in periodic metasurfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15741v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding how bound states in the continuum (BICs) emerge in periodic metasurfaces is essential for the controlled design of high-Q resonances and their systematic manipulation. Here, we investigate the singular value decomposition (SVD) of the effective transition matrix and the scattering matrix of periodic metasurfaces within a parameter range where the metasurface sustains a BIC. Our analysis yields general and practically applicable conditions on the singular values and singular vectors that enable BIC formation. At the BIC eigenfrequency, the inverse of the largest singular value of both matrices vanishes, and the corresponding left (right) singular vector is orthogonal to outgoing (incoming) plane waves that propagate in the directions of open diffraction orders. Our SVD-based approach predicts the spectral position of the BIC and provides detailed information about its properties, including the expansion coefficients in the multipole and plane-wave bases, as well as its behavior under perturbations that transform the BIC into a quasi-BIC. The approach is numerically validated by considering both symmetry-protected and accidental BICs in arrays of scatterers supporting electromagnetic or acoustic multipole resonances. The presented SVD framework offers a broadly applicable foundation for engineering BICs and quasi-BICs in complex metasurfaces, potentially enabling new routes for wave-based devices with tailored radiative properties.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15741v1",
        "authors": [
          "Nikita Ustimenko",
          "Ivan Fernandez-Corbaton",
          "Carsten Rockstuhl"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Meta",
        "SVD",
        "NSF",
        "Act",
        "BIC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.435603"
    },
    {
      "id": "arxiv-2602.15723v1",
      "title": "Microscopic Rydberg electron orbit manipulation with optical tweezers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15723v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Laser cooling and trapping of atomic matter waves in optical potentials has enabled rapid progress in quantum science, particularly when combined with Rydberg excitation of the atoms to induce long-range interactions. Here, we propose the local manipulation and spatio-temporal sculpting of the electronic matter wave of a Rydberg atom by a laser field focused so that its beam width is smaller than the Rydberg electron orbit. We compute the electronic eigenstates in the presence of a sharply focused Gaussian laser beam, and find strong Rydberg state mixing leading to large kilo-Debye dipole moments. These can be modulated with high bandwidth controlled by the local tweezer intensity. Oscillations in the position-dependent level shifts, analogous to the potential wells allowing ultralong-range Rydberg molecules to form, provide opportunities to trap the Rydberg atom in an eccentric way via ponderomotive forces acting on sub-orbital length scales.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15723v1",
        "authors": [
          "Homar Rivera-Rodríguez",
          "Matthew T. Eiles",
          "Tilman Pfau",
          "Florian Meinert"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Microscopic Rydberg",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.436000"
    },
    {
      "id": "arxiv-2602.15668v1",
      "title": "State-selected preparation of molecular ions for precision measurements in radio-frequency traps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15668v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The application of mass-analyzed threshold ionization (MATI) for the state-selective preparation of molecular ions is presented. Based on photoexcitation of long-lived high-$n$ Rydberg states, molecular ions are prepared in a single rovibronic level by pulsed-field ionization. We present a theoretical analysis and a recipe for obtaining an optimal energy ratio between such selected ions and molecular ions in unwanted rovibronic states, created by direct photoionization. It is shown that the second-order chromatic aberration of a dc quadrupole bender can be used to isolate the state-selectively prepared molecular ions. The phase-space properties of ions prepared by MATI are ideally suited for axial injection into a linear radio-frequency trap. A modified approach for carrying out MATI within such an ion trap is also described.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15668v1",
        "authors": [
          "Daniel Y. Knapp",
          "Maximilian Beyer"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MATI",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.436338"
    },
    {
      "id": "arxiv-2602.15655v1",
      "title": "Generating quantum entanglement from sunlight",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15655v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Energy consumption is becoming a serious bottleneck for integrating quantum technologies within the existing global information infrastructure. In photonic architectures, considerable energy overheads stem from using lasers, whose high coherence was long considered indispensable for quantum state preparation. Here, we demonstrate that natural, incoherent sunlight can successfully produce quantum-entangled states via spontaneous parametric down-conversion. We detect polarization-entangled photon pairs with a concurrence of $0.905\\pm0.053$ and a Bell state fidelity of $0.939\\pm0.027$. Importantly, the system violates Bell's inequality with $S=2.5408\\pm0.2171$, exceeding the classical threshold of 2, while maintaining generation rates comparable to laser-based setups. These findings pave the way for sustainable quantum applications in resource-limited environments like interplanetary missions.",
        "keywords": [
          "quant-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15655v1",
        "authors": [
          "Cheng Li",
          "Jasvinder Brar",
          "Michael Küblböck",
          "Jeremy Upham",
          "Hanieh Fattahi"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.436644"
    },
    {
      "id": "arxiv-2602.15652v1",
      "title": "The COHERENT Experiment: 2026 Update",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15652v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The COHERENT experiment measures neutrino-induced recoils from coherent elastic neutrino-nucleus scattering (CEvNS) with multiple nuclear targets at the Spallation Neutron Source (SNS) at the Oak Ridge National Laboratory (ORNL), USA. Several successful CEvNS measurements have been achieved in recent years with tens-of-kg detector masses, with a CsI scintillating crystal, a liquid argon single-phase detector, and high-purity germanium spectrometers. For the next phase, COHERENT aims at high-statistics detection of CEvNS events for precision tests of the standard model of particle physics, and to probe new physics beyond-the-standard model. Percent-level precision can be achieved by lowering thresholds, reducing backgrounds, and by scaling up the detector masses. It goes hand in hand with benchmarking the neutrino flux from the SNS. Further detectors will measure CEvNS in additional nuclei, including lighter target nuclei such as sodium and neon, to continue to test the expected neutron-number-squared dependence of the cross section. COHERENT can furthermore study charged-current and neutral-current inelastic neutrino-nucleus cross sections on various nuclei at neutrino energies below $\\sim$50 MeV. Many of these cross sections have never been measured before, but are critical input for the interpretation of core-collapse supernova detection in large-scale neutrino experiments such as DUNE, Super-K, Hyper-K, and HALO.",
        "keywords": [
          "hep-ex",
          "hep-ph",
          "nucl-ex",
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15652v1",
        "authors": [
          "M. Adhikari",
          "M. Ahn",
          "D. Amaya Matamoros",
          "P. S. Barbeau",
          "V. Belov"
        ],
        "arxiv_categories": [
          "hep-ex",
          "hep-ph",
          "nucl-ex",
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oak Ridge National Laboratory",
        "Spallation Neutron Source",
        "Laboratory",
        "Standard",
        "Nuclear",
        "ORNL",
        "HALO",
        "DUNE",
        "SNS",
        "USA",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.437372"
    },
    {
      "id": "arxiv-2602.15616v1",
      "title": "Relativistic nuclear recoil effects in hyperfine splitting of hydrogenic systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15616v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The finite nuclear mass $(Z\\,α)^2\\,m/M\\,E_F$ correction to the hyperfine splitting in hydrogenic systems is calculated using a combined relativistic heavy particle and nonrelativistic quantum electrodynamics. The obtained results are in disagreement with previous calculations by Bodwin and Yennie [Phys. Rev. D {\\bf 37}, 498 (1988)]. The comparison of improved theoretical predictions with the corresponding measurements in hydrogen reveals $5σ$ discrepancy, which indicates problems with the proton structure corrections.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15616v1",
        "authors": [
          "Jakub Hevler",
          "Andrzej Maroń",
          "Krzysztof Pachucki"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "Hydrogen",
        "Nuclear",
        "EPA",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.437922"
    },
    {
      "id": "arxiv-2602.15598v1",
      "title": "Stability of Bose-Fermi mixtures in two dimensions: a lowest-order constrained variational approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15598v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the problem of mechanical stability in two-dimensional Bose-Fermi mixtures at zero temperature, focusing on systems with a tunable Bose-Fermi (BF) interaction and a weak but finite boson-boson (BB) repulsion. The analysis is carried out within the framework of the lowest-order constrained variational (LOCV) approach, which allows for a non-perturbative treatment of strong interspecies correlations while retaining analytical transparency. The BF interaction is modeled by a properly regularized attractive contact potential, enabling the exploration of both the attractive and repulsive energy branches. We determine the minimal BB repulsion required to ensure mechanical stability of the mixture by evaluating the inverse compressibility matrix over the full range of BF coupling strengths, within the domain of validity of the LOCV approximation. The interaction contribution to the energy is benchmarked against available experimental data and Quantum Monte Carlo results in the single-impurity limit, showing good agreement. Our analysis reveals how the critical BB coupling depends on interaction strength, density imbalance, and mass ratio. In particular, we find that mixtures with equal boson and fermion masses exhibit enhanced stability, requiring the smallest BB repulsion to prevent mechanical instability. In this case, a relatively small BB interaction is sufficient to stabilize attractive mixtures for all values of the BF interaction. These results provide a theoretical framework for assessing stability conditions in experimentally realizable two-dimensional Bose-Fermi mixtures with tunable interactions.",
        "keywords": [
          "cond-mat.quant-gas",
          "physics.atm-clus"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15598v1",
        "authors": [
          "Pietro Cordioli",
          "Leonardo Pisani",
          "Pierbiagio Pieri"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "physics.atm-clus"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Monte Carlo",
        "Framework",
        "Agreement",
        "LOCV",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.438495"
    },
    {
      "id": "arxiv-2602.15573v1",
      "title": "Theory of temporal three-photon interference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15573v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The recent demonstrations of cascaded PDC (CPDC) and the hopeful prospects of realizing third-order PDC (TOPDC) for the generation of three-photon entangled states are paving the way for experimental studies on genuine three-photon interference. In this article, we formulate three-photon interference in terms of ``each three-photon interfering only with itself.'' We show that although a generalized two-alternative three-photon interference setup based on CPDC or TOPDC involves eight different length parameters, the interference can be fully characterized in terms of only three independent parameters. The first parameter is the three-photon path-length difference, which has a direct analog in the one-photon and two-photon cases, and the other two parameters quantify the path-asymmetry length. Unlike two-photon interference, which requires only one parameter to quantify path-asymmetry, two independent parameters are needed in three-photon interference. This results in a broader class of nonclassical three-photon effects, including three-photon HOM-type effects. Our work provides the theoretical basis for existing and future three-photon interference experiments exploring the rich and complex quantum correlations associated with three-particle entanglement and potentially enabling the development of novel protocols for harnessing those correlations.",
        "keywords": [
          "quant-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15573v1",
        "authors": [
          "Nilakshi Senapati",
          "Girish Kulkarni",
          "Anand K. Jha"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "TOPDC",
        "CPDC",
        "HOM",
        "PDC",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.438997"
    },
    {
      "id": "arxiv-2602.15500v1",
      "title": "From Coils to Surface Recession: Fully Coupled Simulation of Ablation in ICP Wind Tunnels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15500v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This work presents a fully coupled, multiphysics computational framework for predicting the thermo-chemical material response of thermal protection systems in inductively coupled plasma (ICP) wind tunnels. The framework integrates a high-fidelity Navier-Stokes plasma solver, an electromagnetic field solver, and a discontinuous-Galerkin material response solver using a partitioned coupling strategy. This enables an ab initio, end-to-end simulation of the 350 kW Plasmatron X facility at the University of Illinois Urbana-Champaign (UIUC), including plasma generation, electromagnetic heating, near-wall thermochemistry, and time-accurate material ablation. The model captures key ICP physics such as vortex-mode recirculation, Joule-heating-driven plasma formation, and Lorentz-force-induced flow confinement, and accurately predicts the transition from subsonic to supersonic jet behavior at low pressures. Validation against cold-wall calorimetry and graphite ablation experiments shows that predicted stagnation-point heat fluxes fall well within experimental uncertainty, while fully coupled simulations accurately reproduce measured stagnation temperature histories and recession rates with errors below 12% and 10%, respectively. Remaining discrepancies during early transient heating are attributed to uncertainties in power-coupling efficiency, equilibrium ablation modeling, and material property datasets. Overall, the framework demonstrates strong predictive capability for ICP wind tunnel environments and provides a foundation for improved design, interpretation, and planning of hypersonic material testing campaigns.",
        "keywords": [
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15500v1",
        "authors": [
          "Sanjeev Kumar",
          "Alessandro Munafo",
          "Blaine Vollmer",
          "Daniel J. Bodony",
          "Gregory S. Elliott"
        ],
        "arxiv_categories": [
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fully Coupled Simulation",
        "Surface Recession",
        "Illinois Urbana",
        "From Coils",
        "University",
        "Framework",
        "UIUC",
        "Wind",
        "EPA",
        "ICP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.439592"
    },
    {
      "id": "arxiv-2602.15464v1",
      "title": "Fractional optical skyrmions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15464v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Optical topologies in the form of Skyrmions have attracted significant interest of late, where their integer Skyrmion number has been shown to be robust to complex media. Here we create the first fractional Skyrmions by structuring light as a vectorial superposition of non-integer orbital angular momentum. We unravel the map structure to reveal a new phenomenon, the abrupt transition jumps in skyrmion number, which serves to reinforce the integer nature of skyrmion topologies. Our experimental demonstration agrees well with simulation, opening a new spectrum of optical topologies to explore, with exciting possibilities in optical communication and sensing.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15464v1",
        "authors": [
          "Yuancong Cao",
          "Ram Nandan Kumar",
          "Hadrian Bezuidenhout",
          "Mingjian Cheng",
          "Lixin Guo"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.439840"
    },
    {
      "id": "arxiv-2602.15450v1",
      "title": "Impact of front-end parameters of the ARCADIA MD3 on charged particle detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15450v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The ARCADIA INFN R&D project developed a Fully Depleted Monolithic Active Pixel Sensor (FD-MAPS) using a customized LFoundry 110 nm CIS process. The first in-beam characterization of the ARCADIA Main Demonstrator 3 (MD3) sensor with 200 $μ$m active thickness has been performed at the Fermilab Test Beam Facility with a 120 GeV proton beam. The Device Under Test (DUT) is tested with a trigger-less telescope composed of two ARCADIA MD3 tracking planes. This early study investigates the effect of the front-end parameters on the tracking performance.",
        "keywords": [
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15450v1",
        "authors": [
          "C. Pantouvakis",
          "S. Garbolino",
          "M. Rignanese",
          "P. Affleck",
          "A. Apresyan"
        ],
        "arxiv_categories": [
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fully Depleted Monolithic Active",
        "Fermilab Test Beam Facility",
        "Main Demonstrator",
        "Pixel Sensor",
        "INFN",
        "MAPS",
        "DUT",
        "CIS",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.440382"
    },
    {
      "id": "arxiv-2602.15442v1",
      "title": "Virtual ultrasound machine operating in a GHz to MHz frequency range for particle-based biomedical simulations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15442v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Ultrasound-matter interactions underpin numerous biomedical and soft-matter applications, yet simulating these phenomena is challenging due to the large separation of viscous and sonic time scales. Continuum methods capture large-scale wave propagation but cannot resolve microscale interactions, while particle-based approaches offer molecular resolution but struggle with efficiency and stability at larger scales. We introduce a particle-based virtual ultrasound machine that uses a novel smoothed dissipative particle dynamics variant with an implicit pressure solver and a negative-pressure stabilization scheme, required to mimic acoustic propagation across MHz-GHz frequencies. We demonstrate its capabilities by modeling the acoustophoresis of encapsulated microbubbles, a key mechanism in ultrasound-mediated drug delivery. Beyond this application, the approach establishes a generalizable platform for simulating wave-matter interactions in soft and biological materials, opening new directions for computational studies of acoustics-driven phenomena in science and engineering.",
        "keywords": [
          "cond-mat.soft",
          "cond-mat.mes-hall",
          "physics.bio-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15442v1",
        "authors": [
          "Urban Čoko",
          "Tilen Potisk",
          "Matej Praprotnik"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "cond-mat.mes-hall",
          "physics.bio-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.440746"
    },
    {
      "id": "arxiv-2602.15437v1",
      "title": "Isotope effect in the work function of lithium",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15437v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The work functions of 7Li and 6Li metals have been measured as a function of temperature, by using photoionization of pure isolated metal nanoparticles in a beam. These data reveal a marked isotope effect in the temperature variation of these work functions. Furthermore, for both isotopes the curvature of this temperature variation is found to be significantly larger than may be ascribed purely to a change in the electron gas density. These findings enhance the characterization of lithium as a quantum material in which the interplay between electronic and ionic degrees of freedom is nontrivial, and call for a microscopic understanding beyond simple models. Additionally, the slope of the work function curves was observed to vanish in the low temperature limit, as had been predicted on the basis of the Third Law of thermodynamics.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15437v1",
        "authors": [
          "Atef A. Sheekhoon",
          "Abdelrahman O. Haridy",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Third Law",
        "Meta",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.441112"
    },
    {
      "id": "arxiv-2602.15434v1",
      "title": "Temperature-dependent photoionization thresholds of alkali-metal nanoparticles reveal thermal expansion and the melting transition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15434v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A precision measurement of the photoionization of pure sodium and potassium nanoparticles isolated in a beam enabled an accurate determination of their work functions as a function of temperature. In addition to resolving and quantifying the initial gradual decrease of the work function with temperature, which is associated with thermal expansion, the experiment revealed that the work function then undergoes a distinct drop both in magnitude and in slope that signifies the onset of nanoparticle melting. This establishes that a structural phase transition can be detected via a high-resolution measurement of the photoemission threshold. The melting temperature of nanoparticles with diameters of 7-9 nm is reduced by nearly 100 K relative to the bulk value. This suppression aligns with predictions from the Gibbs-Thomson equation which describes finite-size phase transitions.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15434v1",
        "authors": [
          "Abdelrahman O. Haridy",
          "Atef A. Sheekhoon",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.441439"
    },
    {
      "id": "arxiv-2602.15431v1",
      "title": "Flux pumping and bifurcated relaxations of helical core in 3D magnetohydrodynamic modelling of ASDEX Upgrade plasmas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15431v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Flux pumping was achieved in recent hybrid scenario experiments in the ASDEX Upgrade (AUG) tokamak, which is characterized by a sawtooth-free helical quiescent state and the anomalous radial redistribution of toroidal current density and poloidal magnetic flux. In this article, the self-regulation mechanism of the AUG core plasma during flux pumping is investigated at realistic parameters using the JOREK code based on the two-temperature, nonlinear, full magnetohydrodynamic (MHD) model. A key milestone in AUG flux pumping modelling is achieved by quantitatively reproducing the clamped current density and safety factor profiles in the plasma core, demonstrating the effectiveness of the dynamo effect in sustaining the flux pumping state. The dynamo term, that is of particular interest, is primarily generated by the pressure-gradient driven m/n = 1/1 quasi-interchange-like MHD instability. The work systematically extrapolates the parameter regimes of flux pumping from the above AUG base case by scanning dissipation coefficients and plasma beta. The simulation results reveal bifurcated plasma behaviours at different Hartmann numbers, including distinct states such as flux pumping (helical core with a flat current density), sawteeth (periodic kink-cycling), single crash (without subsequent cycle), and quasi-stationary magnetic island (peaked current density). Transitions from marginal flux pumping state to sawteeth are observed in long-term simulations. The relationships between system dissipation, plasma beta, and different plasma states are carefully analyzed. For practical purposes, the potential operational window for flux pumping, as determined by plasma density and temperature, is estimated. The modelling efforts advance the understanding of flux pumping and facilitate the development of a fast surrogate model for efficient evaluation of flux pumping.",
        "keywords": [
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15431v1",
        "authors": [
          "H. Zhang",
          "M. Hoelzl",
          "I. Krebs",
          "A. Burckhart",
          "A. Bock"
        ],
        "arxiv_categories": [
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Regulation",
        "ASDEX",
        "JOREK",
        "Wind",
        "WTO",
        "MHD",
        "Act",
        "AUG",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.442047"
    },
    {
      "id": "arxiv-2602.15426v1",
      "title": "Photoionization of temperature-controlled nanoparticles in a beam: Accurate and efficient determination of ionization energies and work functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15426v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A beam of free alkali metal nanoparticles is produced by a condensation source, passed through a thermalizing tube adjustable over a broad temperature range, and ionized by tunable light. High stability of the particle flux and an automated data acquisition routine allow efficient collection of photoionization yield curves. A careful fit of the data to the universal Fowler function makes it possible to obtain nanoparticle ionization energies, and from those, the metal work functions, with $\\sim$0.2% precision. The experimental arrangement, nanoparticle thermalization rates, and ionization threshold analysis are described in detail. The use of ultrapure and temperature-controlled gas-phase nanoparticles facilitates the analysis of electronic properties, such as work functions, and of their interplay with thermal lattice dynamics.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15426v1",
        "authors": [
          "Atef A. Sheekhoon",
          "Abdelrahman O. Haridy",
          "Sebastian Pedalino",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.442349"
    },
    {
      "id": "arxiv-2602.15404v1",
      "title": "Development and validation of a sharp interface immersed boundary method for high-speed flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15404v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study presents an advanced sharp-interface immersed boundary method (IBM) integrated with the blastFOAM library on the OpenFOAM platform for high-speed compressible flow simulations. The developed solver extends the existing IBM techniques available in OpenFOAM to compressible regimes, tackling challenges such as shock waves, expansions, and dynamic geometries without needing body-fitted meshes. A novel contribution of this work is the implementation of a slip boundary condition for velocity at immersed surfaces, specifically designed to handle inviscid highspeed flows. The method also combines the second-order polynomial IBM reconstruction with multiple flux schemes such as Kurganov, Tadmor, HLL (Harten-Lax-van Leer), and AUSM+up (Advection Upstream Splitting Method Plus Upwind). The technique achieves significant accuracy across diverse high-speed flow conditions. Extensive validation is performed through supersonic flow cases over a wedge, a cylinder, an aerofoil, a sphere, and a moving piston. Results show excellent agreement with analytical and body-fitted solutions, with sharp resolution of shocks, minimal numerical oscillations, and shock reflections. A grid convergence study confirms the solver's reliability across varying mesh resolutions, while three-dimensional simulations highlight its capability for scaled-up applications. This solver provides a flexible, efficient, and accurate tool for capturing high-speed flow phenomena across various Mach numbers and geometries. It offers significant advantages in mesh handling, particularly for dynamic or intricate configurations, making it ideal for aerospace and engineering applications involving compressible flows.",
        "keywords": [
          "physics.class-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15404v1",
        "authors": [
          "Punit Pandey",
          "Ankit Bansal",
          "Krishna Mohan Singh",
          "Yannick Hoarau"
        ],
        "arxiv_categories": [
          "physics.class-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Advection Upstream Splitting Method",
        "Plus Upwind",
        "Agreement",
        "Wind",
        "AUSM",
        "IBM",
        "HLL",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.442873"
    },
    {
      "id": "arxiv-2602.15366v1",
      "title": "Tailoring multiple scattering acoustic media with perfect transmission for non-Abelian braiding and beyond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15366v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Multiple scattering of waves in complex media can be harnessed and tailored for diverse phenomena in sound and light. Despite the tremendous progress enabled by technologies such as time-reversal propagation and wavefront shaping, the full control of transmission matrix remains a significant challenge. In this work, we propose a multi-scattering-based approach to design reflectionless complex media with a unitary transmission matrix of arbitrary structures. As such, the perfect transmission of waves through such a medium performs a unitary operation. Based on this principle, we experimentally demonstrated braiding of multiple waveguide modes in an acoustic waveguide via multiple scattering and showed non-Abelian characteristics arising from the concatenation of distinct complex media. Furthermore, we show that the principle can be extended for realizing arbitrary unitary operations beyond braiding. Our scheme uses generalized Wigner-Smith operators to design the optimal acoustic complex media with near-arbitrary targeted functionalities. The scheme is generally applicable beyond acoustics, with broad implications to other wave types. Our results demonstrate unprecedented control over multiple-scattering waves and are relevant to applications that require precise control over propagation, such as multiplexed communications, wave-based logic operations, and computations.",
        "keywords": [
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15366v1",
        "authors": [
          "Hongkuan Zhang",
          "Guancong Ma"
        ],
        "arxiv_categories": [
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.443251"
    },
    {
      "id": "arxiv-2602.15363v1",
      "title": "Optofluidic light routing via analytically configuring streamlines of micro-flow",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15363v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Transformation optics (TO) is a new method to design metamaterials that can manipulate electromagnetic fields. Inspired by the traditional TO techniques which is mostly based on the solid metamaterials with a limited range of tunability, a novel streamline tracing-based transformation optofluidics (STTOF) method is proposed to manipulate the light path by analytically designating the light-carrying streamlines of the flow in a two-dimensional circular bounded domain. A dipole flow model is built to analytically calculate the streamlines of the flow field inside the domain which allocates the optical/fluidic source and sink pairs at arbitrary positions. Liquid core/liquid cladding (L2) configuration is used in the experiment to trace the light via a specific streamline. Experimental results verify that the light paths agree well with the theoretical predictions, and demonstrate that a good range of tunability can be achieved by adjusting the flow rates and the source-sink positions of optical/fluidic source and sink pairs.",
        "keywords": [
          "physics.optics",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15363v1",
        "authors": [
          "Y. Ruo",
          "Y. Yang",
          "X. Tu",
          "T. Huang",
          "Y. Liu"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "STTOF",
        "Meta",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.443561"
    },
    {
      "id": "arxiv-2602.15345v1",
      "title": "Machine learning electronic structure and atomistic properties from the external potential",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15345v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electronic structure calculations remain a major bottleneck in atomistic simulations and, not surprisingly, have attracted significant attention in machine learning (ML). Most existing approaches learn a direct map from molecular geometries, typically represented as graphs or encoded local environments, to molecular properties or use ML as a surrogate for electronic structure theory by targeting quantities such as Fock or density matrices expressed in an atomic orbital (AO) basis. Inspired by the Hohenberg-Kohn theorem, in this work, we propose an operator-centered framework in which the external (nuclear) potential, expressed in an AO basis, serves as the model input. From this operator, we construct hierarchical, body-ordered representations of atomic configurations that closely mirror the principles underlying several popular atom-centered descriptors. At the same time, the matrix-valued nature of the external potential provides a natural connection to equivariant message-passing neural networks. In particular, we show that successive products of the external potential provide a scalable route to equivariant message passing and enable an efficient description of long-range effects. We demonstrate that this approach can be used to model molecular properties, such as energies and dipole moments, from the external potential, or learn effective operator-to-operator maps, including mappings to the Fock matrix and the reduced density matrix from which multiple molecular observables can be simultaneously derived.",
        "keywords": [
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15345v1",
        "authors": [
          "Jigyasa Nigam",
          "Tess Smidt",
          "Geneviève Dusson"
        ],
        "arxiv_categories": [
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "Framework",
        "Nuclear",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.443973"
    },
    {
      "id": "arxiv-2602.15343v1",
      "title": "Transition radiation in helical metamaterials with strong spatial dispersion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15343v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The theory of transition radiation in helical metamaterials with strong spatial dispersion is developed in the framework of an effective field theory approach. The average number of photons radiated by a charged particle passing through a plate made of this metamaterial is obtained. Given the positions of the transition radiation maxima in momentum space for different velocities of a charged particle, the method for reconstruction of the dispersion law of plasmon-polaritons in metamaterials is proposed. Applying this method conversely, one can predict the radiation spectrum and polarization properties of transition radiation by means of the dispersion law of plasmon-polaritons in the metamaterial known, for example, from the effective model. It is shown that the strong spatial dispersion alters qualitatively the properties of transition radiation from a charged particle traversing normally a plate made of the helical metamaterial along its symmetry axis in the paraxial regime, viz., there is a nonzero forward radiation in contrast to transition radiation in media without strong spatial dispersion. Vavilov-Cherenkov radiation and the anomalous Doppler effect in helical metamaterials with strong spatial dispersion are described.",
        "keywords": [
          "cond-mat.mes-hall",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15343v1",
        "authors": [
          "P. O. Kazinski",
          "P. S. Korolev"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Meta",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.444316"
    },
    {
      "id": "arxiv-2602.15310v1",
      "title": "Compton imaging of undepleted volumes of germanium detectors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15310v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The shape of the undepleted volume of a p-type high-purity Broad Energy Germanium detector, dependent on the bias voltage, has been imaged by measuring spatially-resolved Compton-scattering efficiency. The bias voltage was raised stepwise from $-50\\,\\text{V}$ to the full-depletion voltage. The geometric acceptance was determined at full depletion. Below full depletion, the relative acceptance observed for $2\\times2\\times2\\,\\text{mm}^3$ voxels was used to create the image of the undepleted volume for each bias voltage. The images were used to extract the impurity density profile of the detector by fitting predictions of the open-source software package SolidStateDetectors$.$jl to the images. The result is shown and compared to the impurity density profile deduced from capacitance measurements. This is the first time that three-dimensional images of the undepleted volumes of a germanium detector have become available and have been used to deduce an impurity density profile.",
        "keywords": [
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15310v1",
        "authors": [
          "Iris Abt",
          "Arthur Butorev",
          "Felix Hagemann",
          "David Hervas Aguilar",
          "Johanna Lührs"
        ],
        "arxiv_categories": [
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Broad Energy Germanium",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.444630"
    },
    {
      "id": "arxiv-2602.15296v1",
      "title": "GPS constellation search for exotic physics messengers coincident with the binary neutron star merger GW170817",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15296v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Global Positioning System (GPS) includes a continuously operating, planet-scale network of atomic clocks that, beyond navigation and time dissemination, enables precision tests of fundamental physics. Here we use GPS carrier phase archival data to perform a retrospective search for exotic low-mass fields (ELFs) that might be emitted by the binary neutron-star merger GW170817, complementing gravitational wave and electromagnetic modalitiesnin multi-messenger astronomy. Such ultra-relativistic fields would imprint a dispersive, anti-chirp signature in clock-frequency time series, delayed with respect to the LIGO-Virgo gravitational wave detection. We construct network-median pseudo-frequency data from eighteen Rb satellite clocks referenced to a terrestrial hydrogen maser and conduct a template-bank search spanning ELF pulse duration, arrival delay, and characteristic frequency. No statistically significant signal is observed after accounting for noise statistics and template-bank trials. We derive 95\\% confidence-level lower bounds on the interaction energy scale $Λ_α$ of quadratic couplings driving variations in electromagnetic fine-structure constant. These limits improve upon existing astrophysical and gravity-test constraints across the ELF-energy range $\\approx10^{-18}$--$10^{-14}\\,\\mathrm{eV}$. This demonstrates that mature global satellite-clock networks provide an observational capability for retrospective, multi-messenger searches for new physics using decades of archival timing data.",
        "keywords": [
          "astro-ph.IM",
          "astro-ph.HE",
          "physics.atom-ph",
          "physics.data-an",
          "physics.ins-det"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15296v1",
        "authors": [
          "Arko P. Sen",
          "Geoffrey Blewitt",
          "Andrey Sarantsev",
          "Paul Ries",
          "Andrei Derevianko"
        ],
        "arxiv_categories": [
          "astro-ph.IM",
          "astro-ph.HE",
          "physics.atom-ph",
          "physics.data-an",
          "physics.ins-det"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite",
        "Hydrogen",
        "LIGO",
        "ELF",
        "MIT",
        "Act",
        "GPS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.445632"
    },
    {
      "id": "arxiv-2602.15284v1",
      "title": "Highly correlated electronic bounding and spin effect: confirmation of an autodetaching state of O$^-$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15284v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The existence of an auto-detaching state of O$^-$ with a lifetime on the scale of a hundred nanoseconds is demonstrated both experimentally and theoretically. The O$^-$ lifetime values are determined using two recently developed methods. The experimental approach is based on a derivation from measured electron-loss cross sections combined with time-of-flight spectrometry. For the theoretical approach, the continued Green's function within the formalism of Fano-Feshbach is applied. We present the measured lifetime value of $100 \\pm 10 \\text{ ns}$. The calculated lifetime value is 75 ns, and is associated with the (2p$^3$3s$^2$)$^4$S state of O$^-$. We discuss how the existence of a 100-ns-lifetime oxygen metastable anion can impact the modeling of oxygen-containing systems.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15284v1",
        "authors": [
          "Marcelo M. Sant'Anna",
          "Aldo A. Martínes-Calderón",
          "Ginette Jalbert",
          "A. B. Rocha",
          "Guillermo Hinojosa"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:43.445902"
    },
    {
      "id": "arxiv-2602.15793v1",
      "title": "Extending numerical simulations in SIMPSON: Electron paramagnetic resonance, dynamic nuclear polarisation, propagator splitting, pulse transients, and quadrupolar cross terms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15793v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Aimed at the simulation, design, and interpretation of advanced pulse experiments crossing the boundaries between nuclear magnetic resonance (NMR) and electron paramagnetic resonance (EPR), including the rapidly emerging, hybrid discipline of pulsed dynamic nuclear polarisation (DNP), we present a host of novel features in the widely used SIMPSON software package addressing these aspects. Along with this come new features for advanced pulse sequence evaluation in terms of propagator splitting, high-order spin operator cross terms, and pulse phase transients. These fundamental new tools are introduced in a C++-based next generation of the SIMPSON software, which improves calculations speed in some aspects, is better prepared for further developments, and facilitates easier community contributions to the open-source software package.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15793v1",
        "authors": [
          "David L. Goodwin",
          "Jose P. Carvalho",
          "Anders B. Nielsen",
          "Nino Wili",
          "Thomas Vosegaard"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nuclear",
        "DNP",
        "EPA",
        "NMR",
        "EPR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.872526"
    },
    {
      "id": "arxiv-2602.15747v1",
      "title": "How to Train a Shallow Ensemble",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15747v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Shallow ensembles provide a convenient strategy for uncertainty quantification in machine learning interatomic potentials, that is computationally efficient because the different ensemble members share a large part of the model weights. In this work, we systematically investigate training strategies for shallow ensembles to balance calibration performance with computational cost. We first demonstrate that explicit optimization of a negative log-likelihood (NLL) loss improves calibration with respect to approaches based on ensembles of randomly initialized models, or on a last-layer Laplace approximation. However, models trained solely on energy objectives yield miscalibrated force estimates. We show that explicitly modeling force uncertainties via an NLL objective is essential for reliable calibration, though it typically incurs a significant computational overhead. To address this, we validate an efficient protocol: full-model fine-tuning of a shallow ensemble originally trained with a probabilistic energy loss, or one sampled from the Laplace posterior. This approach results in negligible reduction in calibration quality compared to training from scratch, while reducing training time by up to 96%. We evaluate this protocol across a diverse range of materials, including amorphous carbon, ionic liquids (BMIM), liquid water (H$_2$O), barium titanate (BaTiO$_3$), and a model tetrapeptide (Ac-Ala3-NHMe), establishing practical guidelines for reliable uncertainty quantification in atomistic machine learning.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15747v1",
        "authors": [
          "Moritz Schäfer",
          "Matthias Kellner",
          "Johannes Kästner",
          "Michele Ceriotti"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Shallow Ensemble Shallow",
        "Machine Learning",
        "Guideline",
        "Protocol",
        "BMIM",
        "NLL",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.873076"
    },
    {
      "id": "arxiv-2602.15700v1",
      "title": "Analytical Nuclear Gradients of State-Averaged Configuration Interaction Singles Variants: Application to Conical Intersections",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15700v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We derive analytical nuclear gradients for state-averaged configuration interaction singles (SACIS) and its spin-projected extension (SAECIS), enabling efficient geometry optimization and minimum-energy conical intersection (MECX) searches within a low-cost CIS-based framework. The formulation employs a Lagrangian approach and explicitly removes null-space contributions in the coupled perturbed equations to ensure numerically stable gradients. For twisted-pyramidalized ethylene, both SACIS and SAECIS qualitatively reproduce the correct conical intersection topology, in sharp contrast to conventional CIS and ECIS. Benchmark calculations on twelve MECXs demonstrate that both methods reproduce geometries with mean RMSDs below 0.1~Å relative to high-level reference methods. SACIS captures the essential degeneracy through variational orbital relaxation, which alleviates ground-state Hartree--Fock (HF) orbital bias and effectively incorporates static correlation through localization effects; notably, spin projection is found to be non-essential for the qualitative description of these intersections. Overall, SACIS and SAECIS provide qualitatively reliable CX descriptions at mean-field computational cost in a black-box manner. Given their comparable accuracy and the additional overhead associated with spin projection, SACIS offers a more favorable cost-performance balance for general applications, whereas SAECIS may become advantageous when higher excited states with significant double-excitation character are involved.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15700v1",
        "authors": [
          "Takashi Tsuchimochi"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Averaged Configuration Interaction Singles",
        "Analytical Nuclear Gradients",
        "Conical Intersections We",
        "Framework",
        "Nuclear",
        "SAECIS",
        "SACIS",
        "MECX",
        "ECIS",
        "CIS",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.874496"
    },
    {
      "id": "arxiv-2602.15672v1",
      "title": "Dosimetric Study of Lung Modulation and Motion Effects in Carbon ion Therapy for Lung Cancer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15672v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Carbon-ion radiotherapy provides high dose conformity for lung cancer, but its benefit is limited by two sources of uncertainties: interplay between scanned beam delivery and tumor motion, and dose modulation from heterogeneous lung tissue. This study quantifies the separate and combined dosimetric impact of these effects using the GSI TRiP4D treatment planning system. Eighteen lung cancer 4DCT datasets from TCIA were analyzed. A modulation power ($P_{\\mathrm{mod}}$) was assigned to lung voxels. Three values were sampled from a Gaussian distribution ($200μ\\mathrm{m} \\pm 67μ\\mathrm{m}$), and an extreme value of $750μ\\mathrm{m}$ was tested. Interplay doses were computed by combining scanned-beam delivery with patient-specific respiratory motion. Four scenarios were studied: static, static with modulation, interplay, and interplay with modulation. Metrics included $D95\\%$, $V95\\%$, homogeneity index (HI), lung $V16\\mathrm{Gy}$, and heart $V20\\mathrm{Gy}$. Interplay reduced target coverage by $5.2 \\pm 1.5$ pp ($D95\\%$), $12.1 \\pm 5.9$ pp ($V95\\%$), and $8.3 \\pm 2.4$ pp (HI). Extreme $P_{\\mathrm{mod}}$ alone caused small degradations. When combined with interplay, it partially compensated the loss. This effect decreased with 4D optimization. Fractionation mitigated interplay, leaving lung modulation as the main residual effect.",
        "keywords": [
          "physics.med-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15672v1",
        "authors": [
          "Maria Chiara Martire",
          "Lennart Volz",
          "Marco Durante",
          "Christian Graeff"
        ],
        "arxiv_categories": [
          "physics.med-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Lung Cancer Carbon",
        "Dosimetric Study",
        "Lung Modulation",
        "Motion Effects",
        "TCIA",
        "GSI",
        "EPA",
        "IoT",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:48.875741"
    },
    {
      "id": "arxiv-2602.15646v1",
      "title": "Planar Structures of Medium-Sized Gold Clusters Become Ground States upon Ionization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15646v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study investigates the structural stability of ionized gold clusters of sizes ranging from 22 to 100 atoms, contrasting compact, cage and planar structures. While it is well known that neutral clusters in the upper part of this size range predominantly favor compact structures, our results reveal that positively ionized gold clusters exhibit structural transitions in which planar structures become energetically preferred once the charge is sufficiently large. In addition, we study the finite-temperature stability of the structures and find that thermodynamic effects further stabilize planar configurations relative to their compact counterparts. To explore the potential energy surface, we use the Minima Hopping algorithm combined with a machine-learned potential. Since the machine-learned potential does not apply to ionized clusters, we introduce a charge-correction term to incorporate Coulomb interactions and charge screening.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15646v1",
        "authors": [
          "Mohammad Ismaeil Safa",
          "Ehsan Rahmatizad Khajehpasha",
          "Stefan Goedecker"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sized Gold Clusters Become",
        "Planar Structures",
        "Minima Hopping",
        "Ground States",
        "DOE",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.876109"
    },
    {
      "id": "arxiv-2602.15627v1",
      "title": "Fastest first-passage time for multiple searchers with finite speed",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15627v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study analytically and numerically the mean fastest first-passage time (fFPT) to an immobile target for an ensemble of $N$ independent finite-speed random searchers driven by dichotomous noise and described by the telegrapher's equation. In stark contrast to the well-studied case of Brownian particles -- for which the mean fFPT vanishes logarithmically with $N$ -- we uncover that the mean fFPT is bounded from below by the minimal ballistic travel time, with an exponentially fast convergence to this bound as $N \\to \\infty$. This behavior reveals a dramatic efficiency advantage of physically realistic, finite-speed searchers over Brownian ones and illustrates how diffusive macroscopic models may be conceptually misleading in predicting the short-time behavior of a physical system. We extend our analysis to anomalous diffusion generated by Riemann-Liouville-type dichotomous noises and find that target detection is more efficient in the superdiffusive regime, followed by normal and then subdiffusive regimes, in agreement with physical intuition and contrary to earlier predictions.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15627v1",
        "authors": [
          "Denis S. Grebenkov",
          "Ralf Metzler",
          "Gleb Oshanin"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "Fusion",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.876474"
    },
    {
      "id": "arxiv-2602.15534v1",
      "title": "Reactive Coarse Grained Force Field for Metal-Organic Frameworks applied to Modeling ZIF-8 Self-Assembly",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15534v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Decoding the self-assembly mechanism of metal-organic frameworks is a crucial step in reducing trial-and-error tests in their synthesis protocols. Atomistic simulations have proven essential in revealing molecular-level features of MOF nucleation, but they still exhibit limitations in the simulation setups due to size constraints (inability of reaching realistic concentrations or exploring non-stoichiometric metal:ligand ratios). In this contribution, we develop a methodology to derive reactive coarse grained force fields based on multiscale coarse graining methods. We apply our novel methodology to the case of the archetypal zeolitic-imidazolate framework ZIF-8. Our coarse grained force field, which we call nb-CG-ZIF-FF, does not contain any explicit connectivity information, but learns the tetrahedral Zn-connectivity from many body correlations within an atomistic benchmark. nb-CG-ZIF-FF quantitatively reproduces the features of bulk, crystalline ZIF-8 as well as the structural evolution of pre-nucleation species in terms of Zn n-fold coordination populations from the atomistic benchmark. While the range of rings that are formed along the synthesis process are well captured by nb-CG-ZIF-FF, the model cannot exactly reproduce ring populations. Our reactive CG force field fitting approach can be applied to any MOF, opening new research avenues in modeling MOF formation, decomposition, defect dynamics and phase transition processes.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15534v1",
        "authors": [
          "Sangita Mondal",
          "Cecilia M. S. Alvares",
          "Rocio Semino"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reactive Coarse Grained Force",
        "Organic Frameworks",
        "Assembly Decoding",
        "Framework",
        "Protocol",
        "ZIF-8",
        "Meta",
        "DOE",
        "MOF",
        "MIT",
        "ZIF",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:48.877022"
    },
    {
      "id": "arxiv-2602.15470v1",
      "title": "The Skeletal Trap: Mapping Spatial Inequality and Ghost Stops in Ankara's Transit Network",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15470v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Ankara's public transport crisis is commonly framed as a shortage of buses or operational inefficiency. This study argues that the problem is fundamentally morphological and structural. The city's leapfrog urban expansion has produced fragmented peripheral clusters disconnected from a rigid, center-oriented bus network. As a result, demand remains intensely concentrated along the Kizilay-Ulus axis and western corridors, while peripheral districts experience either chronic under-service or enforced transfer dependency. The deficiency is therefore not merely quantitative but rooted in the misalignment between urban macroform and network architecture. The empirical analysis draws on a 173-day operational dataset derived from route-level passenger and trip reports published by EGO under the former \"Transparent Ankara\" initiative. To overcome the absence of stop-level geospatial data, a Connectivity-Based Weighted Distribution Model reallocates passenger volumes to 1 km x 1 km grid cells using network centrality. The findings reveal persistent center-periphery asymmetries, structural bottlenecks, and spatially embedded accessibility inequalities.",
        "keywords": [
          "physics.soc-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15470v1",
        "authors": [
          "Elifnaz Kancan"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.LG"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Based Weighted Distribution Model",
        "Mapping Spatial Inequality",
        "Transit Network Ankara",
        "Transparent Ankara",
        "Ghost Stops",
        "NSF",
        "EGO",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:48.877491"
    },
    {
      "id": "arxiv-2602.15468v1",
      "title": "Students' understanding of the 2D Heat Equation: An APOS approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15468v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we use the APOS theoretical framework to validate a hypothetical learning trajectory of the 2D heat equation, a preliminary genetic decomposition that stresses the conceptual understanding of its mathematical formulation. We design questions to probe specific mental constructions of the preliminary genetic decomposition. We interview 8 students in the second year of the B.Sc. enrolled in either engineering, physics or twin (mathematics and physics) majors. Our findings indicate that students engage with many predicted mental constructions. In particular, coordination and encapsulation of two process conceptions of the Laplacian of the temperature improve understanding although it is challenging. Other parts of the genetic decomposition require refinements. These include mental constructions related to the temperature distribution function, heat flow, and the temperature gradient.",
        "keywords": [
          "physics.ed-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15468v1",
        "authors": [
          "Maria Al Dehaybes",
          "Johan Deprez",
          "Paul van Kampen",
          "Mieke De Cock"
        ],
        "arxiv_categories": [
          "physics.ed-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Heat Equation",
        "Framework",
        "APOS",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-18T13:58:48.877807"
    },
    {
      "id": "arxiv-2602.15825v1",
      "title": "Hubble-Scale Tachyonic Shocks from Low-Scale Inflation -- A New Gravitational-Wave Window on Inflation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15825v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Current bounds on the tensor-to-scalar ratio imply that the energy scale of inflation may lie below the grand-unified scale. In this paper, we show that in a broad class of single-field inflation models with sufficiently small energy scales, an extremely efficient tachyonic instability develops at the end of inflation. This instability rapidly drives the system into a nonlinear regime before coherent oscillations can be established, leading to a first-order phase-transition--like phenomenon without tunneling or barrier crossing. The resulting ultra-relativistic shock fronts surrounding the bubble interiors expand to near the Hubble scale, corresponding to the most strongly enhanced tachyonic modes, and collide with one another, producing energetic inflaton particles and gravitational waves. As a result, the post-inflationary dynamics can differ significantly from the conventional high-scale inflationary scenario. Interestingly, inflation at MeV--EeV energy scales can be probed via gravitational-wave observations, including pulsar timing arrays, ground-based detectors, and future space-based experiments. Recent limits from the LIGO--KAGRA--Virgo collaboration already constrain EeV-scale inflation, while pulsar timing array results may be interpreted as evidence for gravitational waves generated by GeV-scale inflation. We also briefly discuss further implications of the resulting tachyonic shocks.",
        "keywords": [
          "hep-ph",
          "astro-ph.CO",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15825v1",
        "authors": [
          "Haruto Masubuchi",
          "Yuma Narita",
          "Wen Yin"
        ],
        "arxiv_categories": [
          "hep-ph",
          "astro-ph.CO",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scale Tachyonic Shocks",
        "Inflation Current",
        "New Gravitational",
        "Scale Inflation",
        "Wave Window",
        "KAGRA",
        "LIGO",
        "Wind",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.388064"
    },
    {
      "id": "arxiv-2602.15818v1",
      "title": "Radial oscillations of pulsating neutron stars: The UCIa equation-of-state case",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15818v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Radial oscillations provide a clean dynamical test of the high-density stiffness of neutron-star equations of state. We study spherically symmetric pulsations of nonrotating relativistic stars built from cold, charge-neutral, $β$-equilibrated pure nucleonic matter described within relativistic mean-field theory. As a baseline we adopt the UCIa parameter set [Astron. Astro-phys. 689, A242 (2024)], and we implement high-density stiffening via the $σ$-cut scheme by adding a regulator potential $U_{\\rm cut}(σ)$ [Phys. Rev. C 92, no.5, 052801 (2015), Phys. Rev. C 106, no.5, 055806 (2022)]. For representative choices $f_s=0$ (no cutoff) and $f_s=0.58$ (stiffened), we solve the Tolman-Oppenheimer-Volkoff and tidal perturbation equations to obtain equilibrium sequences, mass-radius relations, and tidal deformabilities. We then derive and solve the linear general-relativistic radial pulsation equations to compute the eigenfrequencies and eigenfunctions of the fundamental and overtone modes. The $σ$-cutoff suppresses the growth of the scalar field at supranuclear density, increases the pressure, and shifts the maximum mass, radii, and $Λ_{1.4}$ accordingly, while systematically raising the radial-mode frequencies at fixed mass. Using the sign change of $ω_0^2$ as a stability criterion, we identify stiffened models that remain radially stable up to the observed $\\sim 2M_\\odot$ mass scale and are consistent with current multimessenger constraints, demonstrating how radial spectra complement static EoS tests.",
        "keywords": [
          "nucl-th",
          "astro-ph.SR",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15818v1",
        "authors": [
          "G. Panotopoulos",
          "A. Övgün",
          "T. Iqbal",
          "Y. Kumaran",
          "B. K. Sharma"
        ],
        "arxiv_categories": [
          "nucl-th",
          "astro-ph.SR",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nuclear",
        "UN",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.389055"
    },
    {
      "id": "arxiv-2602.15803v1",
      "title": "Nearest Neighbour-Based Statistics for 21cm-Galaxy Cross-Correlations in the Epoch of Reionization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15803v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "21cm radiation from neutral hydrogen serves as a direct probe of the Epoch of Reionization. However, both its detection and physical interpretation are severely hindered by contamination from astrophysical foreground emission and instrumental noise that are several orders of magnitude brighter than the signal of interest. A promising way to tackle these challenges is to cross-correlate the 21cm signal with other independent tracers of large-scale structure, most notably high-redshift galaxies. Besides validating putative 21cm detections, such joint analyses are expected to provide independent insights into the properties of ionizing sources and the evolving morphology of ionized regions during reionization. The 21cm signal, however, is intrinsically highly non-Gaussian, limiting the effectiveness of conventional two-point cross-correlation statistics, which capture information only up to the second order. In this work, we therefore investigate the utility of k-nearest-neighbour cumulative distribution functions (kNN CDF), which encode information from the joint clustering at all orders, as an alternative framework for probing 21cm-galaxy cross-correlations. Using self-consistently simulated mock 21cm fields and a catalog of line-emitting galaxies at z = 7, we conducted a proof-of-concept study comparing the kNN CDF formalism and the two-point cross-correlation approach. We find that the kNN CDF statistics outperform the two-point statistics in detecting 21cm-galaxy cross-correlations, even in the presence of instrumental noise and aggressive foreground filtering. Moreover, at a fixed global ionized fraction, it is even able to differentiate between reionization models that remain indistinguishable using two-point statistics. These results demonstrate the power and unexplored potential of exploiting higher-order statistics for extracting maximal information from 21cm-galaxy synergies.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15803v1",
        "authors": [
          "Anirban Chakraborty",
          "Kwanit Gangopadhyay",
          "Arka Banerjee",
          "Tirthankar Roy Choudhury"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nearest Neighbour",
        "Based Statistics",
        "Galaxy Cross",
        "Framework",
        "Hydrogen",
        "MIT",
        "CDF",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.389570"
    },
    {
      "id": "arxiv-2602.15792v1",
      "title": "WISDOM Project - XXVII. Giant molecular clouds of the lenticular galaxy NGC 1387: similarities with spiral galaxy clouds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15792v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Molecular gas is crucial to understanding star formation and galaxy evolution, but the giant molecular clouds (GMCs) of early-type galaxies (ETGs) have rarely been studied. Here, we present analyses of the spatially resolved GMCs of the lenticular galaxy NGC 1387, exploiting high spatial resolution (0.15\" or 14 pc) 12CO(2-1) line observations from the Atacama Large Millimeter/submillimeter Array. We identify 1285 individual GMCs and measure the fundamental properties (radius, velocity dispersion, and molecular gas mass) of each with a modified version of the CPROPStoo package. Unusually for an ETG, the GMCs of NGC 1387 follow scaling relations very similar to those of the Milky Way disc and Local Group galaxy clouds, and most are virialised. GMCs with large masses and radii and/or small galactocentric distances have their angular momenta aligned with the large-scale galactic rotation, while other GMCs do not. These results show that ETGs have more diversified GMC properties than previously thought. We discuss potential reasons for such diversity, and viewing-angle dependency is a plausible candidate.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15792v1",
        "authors": [
          "Fu-Heng Liang",
          "Martin Bureau",
          "Lijie Liu",
          "Pandora Dominiak",
          "Woorak Choi"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Atacama Large Millimeter",
        "Local Group",
        "Milky Way",
        "WISDOM",
        "XXVII",
        "NGC",
        "GMC",
        "ETG",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.389939"
    },
    {
      "id": "arxiv-2602.15788v1",
      "title": "Between Plateaus and Slopes: A Data-Driven Exploration of Spectral Diversity Across Type IIP/L Supernovae",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15788v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Type II supernovae (SNe II) have been traditionally separated into several subgroups based on their photometric and spectroscopic properties, but whether these represent distinct progenitors or a continuous distribution remains debated. Over the past decade, growing observational evidence has suggested a possible continuity between slow- (IIP) and fast-declining (IIL) SNe. We investigate the continuity of the SNe IIP/L subclasses through a data-driven statistical analysis of spectral time series, aiming to determine whether significant correlations exist between overall spectral shapes and light-curve decline rates. We introduce a novel standardization method for SN II spectra. After empirically flattening the spectra via continuum normalization, we interpolate the resulting \"feature spectra\" onto a fixed grid of epochs using Gaussian Process regression. The interpolated spectra are then analyzed using Principal Component Analysis to explore correlations. We find that SNe IIP and IIL form a continuum spectroscopically, though some clustering remains. The spectral diversity is characterized mainly by two components: one continuous group with well-defined P-Cygni profiles and another with \"less-regular\" features likely driven by enhanced circumstellar material (CSM) interaction. Our results reveal that the spectral diversity of SNe IIP/L diminishes over time. We confirm observational correlations: steeper light-curve declines correspond to weaker spectral features, indicating that SNe IIL tend to show weaker emission and, in some cases, a lack of distinct absorption lines. These trends seemingly break down by enhanced CSM interaction that affects the P-Cygni profiles. Our data-driven method reveals underlying spectral correlations and supports a continuous distribution between IIP and IIL subtypes. This method paves the way for more refined classification algorithms.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15788v1",
        "authors": [
          "Géza Csörnyei",
          "Claudia P. Gutiérrez"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spectral Diversity Across Type",
        "Principal Component Analysis",
        "Driven Exploration",
        "Between Plateaus",
        "Gaussian Process",
        "Supernovae Type",
        "Standard",
        "EPA",
        "IIP",
        "IIL",
        "CSM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.390453"
    },
    {
      "id": "arxiv-2602.15746v1",
      "title": "Slow focus sensor for the Keck I laser guide star adaptive optics system using focal plane wavefront sensing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15746v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Laser guide stars (LGSs) have been deployed for the last 20-30 years in ground-based astronomical telescopes to overcome the limited sky coverage of classical adaptive optics (AO) systems. Unfortunately, slow altitude drifts of the sodium layer compromise focus measurements, generating the so-called slow focus error, and, consequently, a natural guide star (NGS) is needed to compensate for that error. Our goal is to develop and operationalize a focal plane wavefront sensing (FPWFS) technique for slow focus tracking for the Keck I telescope, which can significantly increase sky coverage and allow slow focus tracking at higher frequencies, reducing the lag error. We develop, characterize, and compare three different FPWFS algorithms, namely Gerchberg-Saxton (GS), linearized focal plane technique (LiFT), and Gaussian fit (Gf). These algorithms were studied for the specific purpose of slow focus sensing in the NIR (H and K bands) using numerical simulations and data collected at Keck in 2025 (bench and on-sky). The three algorithms were studied and characterized against different criteria such as linearity, computational costs, and resistance to low signal-to-noise ratio and/or residuals. From the results obtained, the main candidate for an on-sky deployment was GS. On-sky tests showed promising results, with GS successfully compensating for purposely introduced focus errors, even under the presence of high turbulence conditions. This work can also be extrapolated to other existing 8-10 m class telescopes, or even future 30-40 m class telescopes, where the use of FPWFS can significantly improve sky coverage and reduce the lag error.",
        "keywords": [
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15746v1",
        "authors": [
          "Rafael M. Salgueiro",
          "Carlos M. Correia",
          "Benoit Neichel",
          "Antonin Bouchez",
          "Peter Wizinowich"
        ],
        "arxiv_categories": [
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "FPWFS",
        "NGS",
        "MIT",
        "NIR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.390984"
    },
    {
      "id": "arxiv-2602.15735v1",
      "title": "Impact of rotation on the amplitude of acoustic modes in solar-like stars: Insights from hydrodynamical simulations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15735v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In solar-like stars, acoustic modes provide the main way of probing their internal structure and dynamics. Although these modes are expected to be ubiquitous in stars with convective envelopes, Kepler observations reveal that a significant fraction of solar-like stars show no detectable acoustic modes, particularly among rapidly rotating and magnetically active stars. Recent theoretical work by Bessila et al. (2025) has proposed that rotation tends to inhibit convective motions, thereby reducing the power available for stochastic mode excitation. Here, we test this prediction using fully compressible hydrodynamical simulations of a solar-like star. We perform a series of 2.5D simulations, which consider longitudinal symmetry, using the MUSIC code spanning rotation rates from 0 to 8 $Ω_{\\odot}$. We find a clear and systematic decline of acoustic mode amplitudes with increasing rotation rate. In the most rapidly rotating models, mode damping rates are also enhanced. The combined reduction in excitation and increase in damping with increasing rotation rate provide a physical explanation for the observed decrease in mode detectability in rapidly rotating solar-like stars. Our results demonstrate that rotation can significantly modify oscillation properties and must be accounted for when interpreting asteroseismic observations.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15735v1",
        "authors": [
          "Arthur Le Saux",
          "Leïla Bessila",
          "Stéphane Mathis"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Solar",
        "MUSIC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.391863"
    },
    {
      "id": "arxiv-2602.15695v1",
      "title": "The Montreal Open Clusters and Associations (MOCA) Database: A Census of Nearby Associations, Open Clusters, and Young Substellar Objects within 500 pc of the Sun",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15695v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present the Montreal Open Clusters and Associations database (MOCAdb), a public MySQL database with a Python interface. MOCAdb provides a census of memberships for 10259 associations and open clusters within 500 pc of the Sun, with a comprehensive compilation of literature measurements such as spectral types, kinematics, rotation periods, activity indices, spectral indices, and photometry. All known substellar objects are cataloged in MOCAdb, along with 2943 public spectra, to enable the characterization of substellar association members. MOCAdb also features periodically updated calculations such as Galactic UVW space velocities. We use this compilation to construct mappings between independent association definitions, and to update the BANYAN $Σ$ membership classification tool, which now includes 8125 associations. The BANYAN $Σ$ model construction is improved to account for heterogeneous and correlated errors and to capture complex association shapes using Gaussian mixture models. Combined with Gaia DR3, this enabled us to identify 11535 yet unrecognized candidate members of young associations within 500 pc, mostly M dwarfs. Our results corroborate a recent observation that systematics up to $\\approx$4 km/s remain in Gaia DR3 radial velocities for A-type stars. We present an updated census of age-calibrated exoplanets and substellar objects: 134 age-calibrated exoplanet systems (plus 121 TESS exoplanet candidates), 99 of which did not appear to have known memberships so far, and 455 substellar (L0 or later) candidate members of young associations, 196 of which appear newly recognized. We bring the total of candidate isolated planetary-mass objects to 101, 53 of which are newly recognized candidate members.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.EP",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15695v1",
        "authors": [
          "Jonathan Gagné",
          "Leslie Moranta",
          "Jacqueline K. Faherty",
          "Jason Lee Curtis",
          "Thomas P. Bickle"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.EP",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Young Substellar Objects",
        "Montreal Open Clusters",
        "Nearby Associations",
        "Open Clusters",
        "BANYAN",
        "Sun We",
        "TESS",
        "MOCA",
        "UVW",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.393011"
    },
    {
      "id": "arxiv-2602.15692v1",
      "title": "Hot subdwarf stars from the Hamburg Quasar Survey",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15692v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Hot subluminous stars (sdO/B) are evolved low mass stars originating from red giants that lost their envelope almost entirely. The multitude of observed phenomena imply that several pathways may form hot subdwarfs, most involving close binary channels. The Hamburg Quasar Survey (HQS) led to the discovery of many faint blue stars including hot subdwarf. Many of the HQS-sdB stars have been studied in detail, but analyses of the helium-rich sdOB and sdO stars are lacking. The recent development of hybrid LTE/non-LTE model spectra 2nd generation Bamberg model grids enables us to improve the spectroscopic analyses of the sdB stars as well as of the previously unstudied sdO stars allowing precise atmospheric parameters to be derived, while consistently accounting for parameter correlations and systematic uncertainties. ... We use spectral energy distributions to identify composite-colour sdB binaries and present the result of detailed spectroscopic analyses of 122 non-composite subdwarfs from the HQS to identify potential evolutionary pathways. ...Their derived mass distribution and median mass of 0.45 Msun is consistent with the canonical EHB mass. ... The helium-rich sdOB and sdO stars, are found near the helium main-sequence (He-MS). The derived mass distribution of the extremely He-rich subdwarfs is broader (0.48 to 1.05 Msun) and peaks at a median of 0.70 Msun, significantly larger than those of the hydrogen-rich stars. Intermediate He-rich subdwarfs are also He-MS stars, but of lower mass (0.55 Msun) than the extremely He-rich. This strongly supports the merger scenario for the origin of He-rich sdO stars, in which two helium white dwarfs merge following orbital decay driven by gravitational-wave emission, producing a He-rich sdO or sdOB star. From comparison to the results of similar studies we speculate that older populations produce more massive He-WD mergers.(abbreviated)",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15692v1",
        "authors": [
          "Ulrich Heber",
          "Lennard Kufleitner",
          "Matti Dorsch",
          "Marilyn Latour",
          "Harry Dawson"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hamburg Quasar Survey Hot",
        "Intermediate He",
        "Hydrogen",
        "LTE",
        "HQS",
        "EHB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.393517"
    },
    {
      "id": "arxiv-2602.15688v1",
      "title": "Detecting the neutrino mass via the cross-correlation between matter tracers and the ISWRS effect?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15688v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This work explores the potential to detect the nonlinear Integrated Sachs Wolfe effect, namely the Rees-Sciama effect (ISWRS), by cross-correlating current and future Cosmic Microwave Background (CMB) experiments -- Simons Observatory, CMB-S4, CMB-HD, and PICO -- with ongoing Large Scale Structure (LSS) surveys, such as Euclid and the Vera Rubin Observatory (LSST). We model the cross-correlation of the ISWRS effect with gravitational potential tracers like galaxy clustering, cosmic shear, and CMB-lensing potential, to forecast results from these experiments. Our analysis also accounts for the presence of massive neutrinos to assess the feasibility of identifying the $ν$$Λ$CDM model and constraining the neutrino mass sum, M$ν$. Our findings indicate that the CMB-lensing potential reconstructed by CMB-HD is expected to provide the most promising results, achieving $\\gtrsim$ 5$σ$ detections even under conservative assumptions for detector noise and foregrounds, thereby allowing differentiation between $ν$$Λ$CDM models. Galaxy clustering can also yield significant detections, whereas cosmic shear can provide valuable results only if non-linearities are accurately modelled, beyond the capabilities of currently available analytical approaches. These latter LSS probes do not provide strong constraining power on M$ν$. While our findings suggest that future CMB experiments and LSS surveys will enable the detection of the ISWRS effect, they do not imply significant prospects for imposing new constraints on neutrino masses in the near future.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15688v1",
        "authors": [
          "Viviana Cuozzo",
          "Marina Migliaccio",
          "Matteo Calabrese",
          "Carmelita Carbone"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cosmic Microwave Background",
        "Vera Rubin Observatory",
        "Integrated Sachs Wolfe",
        "Large Scale Structure",
        "Simons Observatory",
        "ISWRS",
        "LSST",
        "PICO",
        "CMB",
        "CDM",
        "LSS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.394502"
    },
    {
      "id": "arxiv-2602.15658v1",
      "title": "Spectroscopic analysis and RHD modeling of the first Ca II H and H-epsilon flare spectra from DKIST/ViSP",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15658v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We analyze decay phase observations of the GOES class C6.7 flare SOL2022-08-19T20:31 by the Visible Spectropolarimeter (ViSP) on the National Science Foundation's Daniel K. Inouye Solar Telescope (DKIST). The data include the first flare-time DKIST observations of the chromospheric Ca II H 396.8 nm and H-epsilon 397.0 nm spectral lines. These diagnostics have rarely been studied together during the modern era of high-resolution solar flare observations, and never at the spectral and spatial resolution of the DKIST. We directly compare DKIST spectra to state-of-the-art RADYN+RH simulations, including one heated by a nonthermal electron beam and one by in-situ thermal conduction. While certain salient properties of the spectra such as the width of H-epsilon are reproduced, the models severely underestimate the width of Ca II H in the red wing and fail to reproduce the exact relative intensity of Ca II H to H-epsilon. The models exhibit a range of condensation electron densities spanning over an order of magnitude. Unlike the modeled lower-order Balmer-series lines, we find that the width of H-epsilon is not solely related to the condensation properties; the widths and intensities are also sensitive to the deeper flare layers. We outline possible avenues towards improvement of flare models, such as a comprehensive evaluation of flare heating mechanisms in the context of both impulsive and decay phase high-resolution data.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15658v1",
        "authors": [
          "Cole Tamburri",
          "Adam Kowalski",
          "Gianna Cauzzi",
          "Maria Kazachenko",
          "Alexandra Tritschler"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "National Science Foundation",
        "Visible Spectropolarimeter",
        "Inouye Solar Telescope",
        "SOL2022-08",
        "Solar",
        "DKIST",
        "RADYN",
        "GOES",
        "RHD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.394929"
    },
    {
      "id": "arxiv-2602.15644v1",
      "title": "Bayesian parameter study of the Seyfert-starburst composite galaxies NGC 1068 and NGC 7469",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15644v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Multimessenger observation of the Seyfert-starburst composite galaxies NGC 1068 and NGC 7469 indicate a characteristic feature in the radio band (the so-called mm-bump) as well as indication of high-energy neutrinos by the AGN corona. Moreover, also the starburst ring of these sources is bright in the radio and hence, a potential source of $γ$-rays and neutrinos. We aim to explain the non-thermal features of these two sources with our homogeneous steady-state Seyfert-starburst composite model, which we refined in this work. Hereby, we account for stochastic diffuse acceleration and energy losses within the corona and $γγ$-pair attenuation of the escaping $γ$-rays. Since the non-thermal features of Seyfert sources contribute only marginally to the electromagnetic spectrum, only few data points can be assigned to the starburst ring or the AGN corona. Hence, prior information on the physical parameters is incorporated within a Markov Chain Monte Carlo approach to avoid overfitting. Based on this Bayesian parameter study we show, that the non-thermal features of NGC 1068 can be explained well. Still a more detailed treatment of the spatial inhomogeneities in the central region of the AGN could further improve the fit results. This manifests itself even more clearly in the case of NGC 7469, where the mm-bump needs to emerge from a coronal size $R_{\\rm c}>100\\,\\mathcal{R}_{\\rm s}$, whereas (TeV-PeV)-neutrino emission requires $R_{\\rm c}< 10\\,\\mathcal{R}_{\\rm s}$. Similar to what has previously been shown in other wavebands, our analysis highlights that the spatial extension of the so-called AGN corona depends the considered energy of the messenger. Hence, it seems that there is not a unique edge of the corona and a substantial progress in the understanding of these phenomena is expected if future analysis account for these spatial inhomogeneities.",
        "keywords": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15644v1",
        "authors": [
          "Björn Eichmann",
          "Silvia Salvatore",
          "Santiago del Palacio",
          "Giacomo Sommani",
          "Crystal Mele"
        ],
        "arxiv_categories": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Markov Chain Monte Carlo",
        "AGN",
        "NGC",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.396001"
    },
    {
      "id": "arxiv-2602.15611v1",
      "title": "Searching for Axion-like particle Dark Matter with Time-domain Polarization: Constraints from a protoplanetary disk",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15611v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Axion-like particles (ALPs) can induce a birefringence effect that rotates the polarization angle of light, offering a probe of ultralight dark matter. We analyze archival near-infrared polarimetric data of the protoplanetary disk (PPD) around HD 163296. Whereas previous studies considered only single-epoch snapshots, we perform a consistent multi-epoch time-series analysis, extracting the polarization angle and its uncertainty from the polarized images. The resulting six-epoch time series is consistent with a constant polarization angle within the measurement uncertainties, while being sensitive to timescales of $\\sim 170-400$ days. The typical polarization angle uncertainties are $1.6$--$6.4$ degrees, partly driven by multiple scattering in the optically thick disk, which broadens the intrinsic polarization angle distribution and introduces additional dispersion in the representative polarization angle. Based on these data, we derive the first upper limits on the ALP-photon coupling from PPD polarization variability, $g_{aγ} \\lesssim 7.5 \\times 10^{-12} (m_a / 10^{-22}\\,{\\rm eV})\\,{\\rm GeV}^{-1}$. Furthermore, we forecast that achieving a polarization angle uncertainty of $σ\\sim 0.1$ degrees would enable world-leading sensitivity to ALP-induced birefringence.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.EP",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15611v1",
        "authors": [
          "Kanako Narita",
          "Tomohiro Fujita",
          "Ryo Tazaki",
          "Bunyo Hatsukade"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.EP",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dark Matter",
        "MIT",
        "PPD",
        "ALP",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.396744"
    },
    {
      "id": "arxiv-2602.15605v1",
      "title": "Fast computation of temperature and polarization coupling matrices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15605v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a fast and exact method for computing CMB mode-coupling matrices based on an optimised evaluation of Wigner-3j symbols. The method exploits analytic structure in the relevant Wigner-3j symbol configurations appearing in temperature and polarization coupling matrices, expressing all required quantities in terms of a small set of recurrence-generated values which are precomputed and stored in lookup tables. This approach reduces the computational cost of constructing the full coupling matrices whilst maintaining numerical accuracy. We demonstrate the performance of the threej_cosmo implementation using realistic survey masks from current CMB experiments. Relative to standard recursion-based approaches used in existing pseudo-C_l pipelines, the method achieves speedups of 6-25x in practical coupling-matrix constructions, with the largest gains occurring at high multipoles. The algorithm admits efficient parallelisation on both CPUs and GPUs, the latter providing additional acceleration, up to a further order of 50 on modern hardware, without altering the underlying formalism. Beyond full matrix construction, the approach is naturally suited to applications in which only a restricted set of l3 modes is required for each (l1,l2) pair, such as in the computation of band-limited coupling matrices and analytic covariance terms. These features make threej_cosmo a practical backend for pseudo-C_l estimation and related calculations in next-generation CMB analysis pipelines.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15605v1",
        "authors": [
          "Georgia Kiddier",
          "Steven Gratton"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "MIT",
        "CMB",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.397096"
    },
    {
      "id": "arxiv-2602.15604v1",
      "title": "Aligned and misaligned metallicity gradients in young stars and star-forming regions in the EAGLE discs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15604v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Disc galaxies exhibit radial metallicity gradients in both their stellar and gaseous components. The star-forming gas (SFG) in HII regions and young stars (YSs) trace the recent evolutionary history of the galaxy. We aim to assess the extent to which the joint analysis of metallicity gradient alignment in YSs and SFG can constrain the recent evolutionary history of galaxies. Using the high-resolution run of the EAGLE project, we derived radial, azimuthally averaged oxygen abundance profiles for YSs (age < 2 Gyr) and SFG and measured their gradients as the slopes of linear fits to these profiles. We classified galaxies into four groups based on the signs (N for negative and P for positive) of the slopes: NN, NP, PP, and PN (the first letter is for YSs and the second for SFG). We found that galaxies with NN, NP, PP, and PN combinations of metallicity profiles reflect different evolutionary paths over the past ~ 2 Gyr. NN galaxies exhibit sustained inside-out growth accompanied by high star formation efficiency, whereas NP and PP systems show evidence of recent or ongoing feedback-driven disruption, with PP galaxies likely being predominantly shaped by supernova feedback. PN galaxies, by contrast, show evidence of past violent events followed by gradient recovery, highlighting the interplay between inflows, feedback, and gas cooling in shaping metallicity distributions. The degree of alignment between the stellar and gas metallicity gradients provides a way to time the occurrence of significant events in the evolutionary history of galaxies, which contribute through a combination of gas inflows, star formation triggering, and metal mixing. They could also serve as probes of sub-grid physics when observations provide suitable comparison datasets. [Abridged]",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15604v1",
        "authors": [
          "Isha Shailesh",
          "Patricia B. Tissera",
          "Emanuel Sillero"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EAGLE",
        "Meta",
        "SFG",
        "HII",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.397520"
    },
    {
      "id": "arxiv-2602.15590v1",
      "title": "Morphological variations of solar granules in the presence of magnetic fields",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15590v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Solar granulation consists of dynamic convective plasma cells that rise from the solar interior to the surface. The interaction between these plasma cells and the Sun's magnetic field provides valuable insights into plasma dynamics near the solar surface and how they evolve in the presence of magnetic fields. This study analyses the morphological characteristics of solar convective cells, investigating the relationship between magnetic field properties and granule dynamics - specifically how granule area, shape, and brightness vary under different magnetic field conditions. Observations of the active region NOAA 11768 were taken with the Swedish 1-m Solar Telescope (SST). A segmentation algorithm was applied to continuum intensity images to identify individual granules and determine their sizes, shapes, and mean brightness. The magnetic field vector and line-of-sight velocity were derived from CRISP spectropolarimetric data to investigate their role in shaping granule properties. We find that granular area decreases systematically with increasing magnetic field strength, with the largest granules occurring in non-magnetic regions and a mean granule area of approximately 1.58 arcsec$^2$ (effective diameter of 1.42 arcseconds). Both mean continuum intensity and granule size decrease with stronger fields, confirming the suppression of convective energy transport in magnetised regions. No correlation was found between mean granule brightness and mean up-flow velocity. Highly elongated granules appear in both magnetic and non-magnetic regions, while near-circular granules are exclusive to non-magnetic areas. An alignment between granule major axes and magnetic field azimuth is observed where the horizontal field component is strong, confirming that granules are highly sensitive to magnetic fields, which inhibit the lateral expansion of convective cells.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15590v1",
        "authors": [
          "J. I. Campos Rozo",
          "J. Jurčák",
          "S. M. Díaz Castillo",
          "M. van Noort"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Solar Telescope",
        "Solar",
        "CRISP",
        "NOAA",
        "SST",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.397955"
    },
    {
      "id": "arxiv-2602.15576v1",
      "title": "Dust measurements with the Mars Dust Counter on board Nozomi (PLANET-B)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15576v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nozomi was Japan's first space mission to Mars, launched on 3 July 1998 UT. It was equipped with the Mars Dust Counter (MDC) which was an impact ionisation dust detector. MDC detected 96 dust particle impacts when the spacecraft was in Earth orbit and later in interplanetary space, before its operation ended in April 2002 due to a technical failure on board. We compare the Nozomi dust measurements with the dust measurements obtained with the dust detector on board the Ulysses spacecraft. Impact speeds and masses of dust particles measured by Nozomi MDC are overall consistent with the measurements obtained by Ulysses in the same region of interplanetary space. Based on the impact speeds measured while Nozomi was in Earth orbit, MDC detected neither dust particles of natural origin that were bound to the Earth nor space debris. The dust impact rate measured in interplanetary space varied by approximately a factor of 2, consistent with theoretical predictions by the Interplanetary Meteoroid Engineering Model. The particle impact direction was concentrated towards the ecliptic plane, in agreement with an interplanetary origin of the majority of the measured dust particles. No impacts of cometary trail particles could positively be identified during known cometary trail crossings of Nozomi. The Nozomi dust data may become a valuable reference for the dust measurements to be obtained in the same region of interplanetary space with future space missions like, for example, MMX and DESTINY$^+$.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15576v1",
        "authors": [
          "Harald Krüger",
          "Masanori Kobayashi",
          "Hiroshi Kimura",
          "Tomoko Arai",
          "Hakan Svedhem"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Interplanetary Meteoroid Engineering Model",
        "Mars Dust Counter",
        "Agreement",
        "PLANET",
        "Meta",
        "MDC",
        "MMX",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:54.398329"
    },
    {
      "id": "arxiv-2602.15561v1",
      "title": "Inference of horizontal velocity fields from the induction equation in the solar atmosphere. I. Analytical and numerical solutions in 2D",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15561v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Spectroscopic and spectropolarimetric observations, which rely on the Doppler effect, only provide access to the line-of-sight component of the solar plasma velocity (vz). However, many dynamic processes in the solar atmosphere involve strong horizontal motions (in the plane perpendicular to the line-of-sight: vx, vy). Existing methods for estimating horizontal velocities are generally insensitive to variations in height (the z-coordinate), providing them only on a single plane perpendicular to the line-of-sight: vx(x,y), vy(x,y). Motivated by the fact that modern analysis techniques allow us to retrieve the height dependence of vz and B, our goal is to infer also this height dependence for the horizontal velocity field in the solar atmosphere. As a first step, we present, and test a method for the two-dimensional case on the (y,z) plane so as to show that the z dependence can be successfully retrieved. The components of the two-dimensional magnetic induction equation are discretized via finite differences, leading to an overdetermined system whose solution provides vy. The method assumes that B, its time variation, as well as vz are known. This is currently possible through modern Stokes inversion techniques applied to spatially and temporally resolved spectropolarimetric observations. Using analytically prescribed values and two-dimensional magneto-hydrodynamic simulations of the solar surface, we demonstrate that, in these idealized cases, the horizontal velocity component in a two-dimensional domain, can be successfully recovered with a mean error of about 1 %. The proposed method successfully retrieves the horizontal velocity field in the (y,z) plane, thereby establishing the foundation for future extensions to three-dimensional reconstructions of the horizontal velocity field.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15561v1",
        "authors": [
          "H. Vila Crespo",
          "J. M. Borrero",
          "I. Milić",
          "G. Vigeesh",
          "A. Asensio Ramos"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Solar",
        "WHO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.398765"
    },
    {
      "id": "arxiv-2602.15560v1",
      "title": "Bridging Scales in Black Hole Accretion and Feedback: Subgrid Prescription from First Principles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15560v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding how supermassive black holes (BHs) couple to their host galaxies across a vast spatial and temporal dynamic range remains a central challenge in galaxy evolution. Using the multizone framework -- designed to capture bidirectional inflow--outflow from the event horizon to the Bondi scale -- we present a suite of long-duration GRMHD simulations spanning BH spins $|a_\\ast|=0$--0.9 and Bondi radii $R_B/r_g=4\\times10^2$--$2\\times10^6$. From these simulations we derive spin-dependent subgrid prescriptions from first principles, applicable to hot accretion flows with low-Eddington ratios ($f_{\\rm Edd}\\lesssim10^{-3}$), for adoption in cosmological simulations and semi-analytic models. We provide compact analytic fits for the time-averaged accretion rate $\\dot M(R_B,a_\\ast)$ and feedback power $\\dot E_{\\rm fb}(R_B,a_\\ast)$ with respect to the Bondi rate $\\dot{M}_B$, which are largely insensitive to the initial gas configuration and magnetic field strength. To capture intrinsic time-variability, we also quantify the full distributions of $\\dot M$ and feedback efficiency $η$, both well described by lognormal statistics, with widths that increase toward larger $R_B$. We further measure self-consistent spin evolution in the hot accretion mode, finding that the spin-up parameter varies as $s(a_\\ast)\\simeq -3.7\\,a_\\ast$, which implies a very long spindown timescale $t_s\\simeq 12(10^{-3}/f_{\\rm Edd})\\,{\\rm Gyr}$. Thus, BH spins are effectively frozen during phases of quiescent accretion. Compared to conventional small-domain GRMHD calculations, our simulations, which reach dynamical equilibrium across horizon-to-galaxy scales, yield systematically different long-term accretion, feedback, and spin properties, cautioning against direct extrapolation from small-scale GRMHD simulations when constructing galactic-scale subgrid models.",
        "keywords": [
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15560v1",
        "authors": [
          "Hyerin Cho",
          "Ben S. Prather",
          "Ramesh Narayan",
          "Kung-Yi Su",
          "Angelo Ricarte"
        ],
        "arxiv_categories": [
          "astro-ph.GA",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "First Principles Understanding",
        "Black Hole Accretion",
        "Subgrid Prescription",
        "Bridging Scales",
        "Framework",
        "GRMHD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.399785"
    },
    {
      "id": "arxiv-2602.15558v1",
      "title": "An observational test of the plasma lensing effect using QSOs with and without MgII absorption",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15558v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Radio wave propagation can be perturbed by compact ionized gas clumps through plasma lensing, which induces frequency dependent magnification and may distort the observed number counts of background sources. The quasar (QSO) number densities are a powerful probe for understanding the effects of intervening material. Absorption lines in QSO spectra reveal the presence of interstellar and intergalactic gas, which can change observed fluxes through dust extinction and plasma lensing. By combining observations from radio (VLASS), infrared (WISE), and optical bands (DESI), we assembled a sample of QSOs: ~4000 sources with MgII absorbers, and ~12, 000 non-absorbers. In the radio band, the MgII sample shows a moderate excess at the bright end of the flux distribution, which is broadly consistent with plasma lensing predications. In the optical, the MgII sample turns over at higher g-band fluxes and exhibits a steeper decline at the faint end than the non-MgII sample. Control samples were constructed by matching in redshift, infrared (W1), and optical (g) luminosities. In these comparisons, the radio excess becomes less prominent, suggesting that the apparent magnification may not be robust evidence for plasma lensing. Nevertheless, a weak contribution cannot be ruled out, especially given residual excess observed at the bright end relative to the non-MgII sample. Dust extinction along the line-of-sight remains a plausible alternative. Regardless of the dominant mechanism, the multi-wavelength differences offer a valuable probe of the physical state of the intervening medium.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15558v1",
        "authors": [
          "Xinzhong Er",
          "Yiping Shu",
          "Chenxu Liu"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "VLASS",
        "WISE",
        "DESI",
        "QSO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.400170"
    },
    {
      "id": "arxiv-2602.15551v1",
      "title": "Some phenomenological aspects of a quantum-corrected Reissner-Nordström black hole: quasi-periodic oscillations, scalar perturbations and thermal fluctuations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15551v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work, we investigate several phenomenological aspects of a covariant quantum-corrected Reissner-Nordström black hole characterized by the mass $M$, electric charge $Q$, and the quantum correction parameter $ζ$. We first study the motion of neutral test particles and derive the fundamental orbital and epicyclic frequencies, which are then employed to analyze different quasi-periodic oscillation (QPO) models. Using observational QPO data from stellar-mass, intermediate-mass, and supermassive black hole candidates, we perform a Bayesian parameter estimation through a Markov Chain Monte Carlo (MCMC) analysis and obtain constraints on the black hole parameters. The results show that the presence of the quantum correction significantly affects the location of the QPO radii and the separation between the QPO orbit and the ISCO. We then examine the scalar perturbations by deriving the Schrödinger-like radial equation and the corresponding effective potential. The influence of the parameters $Q$ and $ζ$ on the perturbation potential and stability of the spacetime is discussed. Furthermore, we compute the greybody factor and the energy emission rate in the high-frequency (geometric-optics) regime, showing how the quantum correction modifies the absorption probability and radiation spectrum. Finally, we study the effect of thermal fluctuations on the black hole entropy and obtain the logarithmic corrections to the Bekenstein-Hawking area law. We show that these corrections become important for small black holes, while for large horizon radius the standard thermodynamic behavior is recovered. Our analysis demonstrates that the quantum correction parameter leaves observable imprints on both dynamical and thermodynamical properties of the spacetime and can be constrained through QPO observations.",
        "keywords": [
          "gr-qc",
          "astro-ph.HE",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15551v1",
        "authors": [
          "Faizuddin Ahmed",
          "Ahmad Al-Badawi",
          "Mohsen Fathi"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.HE",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Markov Chain Monte Carlo",
        "Standard",
        "ISCO",
        "MCMC",
        "EPA",
        "QPO",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.401195"
    },
    {
      "id": "arxiv-2602.15550v1",
      "title": "A homogeneous view of asymptotic giant branch carbon stars as seen by Gaia",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15550v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Carbon stars on the asymptotic giant branch are major contributors to galactic dust enrichment, with gas mass-loss rates up to 1e-4 Msun/yr. We present a homogeneous spectral energy distribution analysis of the Gaia DR3 Golden Sample of carbon stars in the Milky Way and Magellanic Clouds. Our dataset includes 14,747 sources with multi-band photometry from Gaia, 2MASS, and WISE, combined with recent distance and extinction estimates. For a subsample of 2,494 Mira variables, we model multi-band light curves to derive accurate mean magnitudes. Stellar and circumstellar parameters are obtained by fitting observations with a large grid of synthetic spectra computed with the DUSTY radiative transfer code using COMARCS atmospheres. We derive effective temperature, optical depth, and gas mass-loss rate for each source. The distributions peak around Teff = 3150 K, with mass-loss rates spanning 1e-11 to 1e-4 Msun/yr and inner dust temperatures near 1000 K. We find a correlation between variability amplitude and mass-loss rate. This framework provides a statistically robust view of carbon stars across environments with different metallicities. Apparent environmental dependencies are influenced by luminosity distributions and selection effects rather than purely intrinsic metallicity differences. The combined Gaia and WISE selection limits the detection of both highly obscured and faint Magellanic Cloud sources, but the observed trends remain significant within the sampled populations.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15550v1",
        "authors": [
          "Alessio Liberatori",
          "Despina Hatzidimitriou",
          "Konstantinos Antoniadis",
          "Giada Pastorelli",
          "Michele Trabucchi"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Magellanic Clouds",
        "Magellanic Cloud",
        "Golden Sample",
        "Gaia Carbon",
        "Milky Way",
        "Framework",
        "DUSTY",
        "Meta",
        "WISE",
        "NSF",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.401540"
    },
    {
      "id": "arxiv-2602.15527v1",
      "title": "Cosmic topology. Part IIc. Detectability with non-standard primordial power spectrum",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15527v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Non-trivial spatial topology of the Universe can imprint potentially observable signatures on the cosmic microwave background (CMB). In this study, we investigate how deviations from the standard nearly-scale-free primordial power spectrum impact observables for the fully compact, orientable Euclidean topologies ($E_1$--$E_6$). We examine how such deviations modify the detectability of the underlying topology, depending on whether they are an intrinsic consequence of non-trivial topology or independent of it. We compute CMB temperature correlation matrices across a range of topologies, fundamental domain sizes, and observer locations for both standard and modified primordial power spectra. The impact of these modifications on the detectability of topology is quantified using the Kullback-Leibler divergence, providing an estimate of the distinguishability of non-trivial and simply-connected topologies based solely on CMB temperature observations. In addition, we employ the CatBoost machine learning algorithm to classify harmonic-space realizations of CMB temperature maps and thereby assess the observational prospects for topology detection. Signatures of non-trivial topology are encoded in the off-diagonal structure of the CMB temperature correlation matrices and are most prominent on the largest angular scales. Deviations from the simple power-law primordial spectrum at these scales can substantially alter the detectability of topology, either enhancing its characteristic CMB imprints or suppressing them below observational sensitivity. Our results demonstrate that uncertainties in the primordial power spectrum must be carefully accounted for in robust searches for cosmic topology using the CMB.",
        "keywords": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15527v1",
        "authors": [
          "Joline Noltmann",
          "Andrius Tamosiunas",
          "Deyan P. Mihaylov",
          "Yashar Akrami",
          "Javier Carrón Duque"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Standard",
        "CMB",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.401920"
    },
    {
      "id": "arxiv-2602.15507v1",
      "title": "Upper atmosphere dynamics and drivers of volatiles loss from terrestrial-type (exo)planets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15507v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Volatile loss from exoplanetary atmospheres and its possible implications for the longevity of habitable surface conditions is a topic of vigorous debate currently. The vast majority of the habitable zone terrestrial-like exoplanets known to date orbit low-mass M- and K-dwarf stars and are subject to the conditions drastically different to those of terrestrial planets in the Solar System. In particular, they orbit far closer to their host stars than similar planets around G-dwarfs similar to the Sun. Therefore they receive higher X-ray and UV fluxes, even though luminosities of M- and K-dwarfs are lower than those of heavier stars. Furthermore, due to their slower evolution, M-dwarfs retain high activity on the gigayear timescales. The combination of these two effects has led to claims that most terrestrial planets orbiting M-dwarfs may have their atmospheres stripped from the higher X-ray and UV fluxes of their host stars. Opposing this are researchers who point out that volatile inventories for terrestrial exoplanets are ill-constrained, and hence, they may be able to \"weather the storm\" of these higher X-ray and UV fluxes. In this chapter, we focus on exploring volatile loss in the upper atmospheres of terrestrial planets in our solar system and applications to those in exoplanetary systems around stars of different types.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15507v1",
        "authors": [
          "Daria Kubyshkina",
          "Michael J. Way",
          "Iannis Dandouras",
          "Helmut Lammer",
          "Antonino Francesco Lanza"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Solar System",
        "Solar",
        "WHO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:54.402232"
    },
    {
      "id": "arxiv-2602.15501v1",
      "title": "Precise measurement of WASP-31 b's Rossiter-McLaughlin effect and characterization of the planet transmission spectra",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15501v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Context. Hot Jupiters are ideal natural laboratories to investigate atmospheric composition and dynamics. However, high-resolution transmission spectroscopy is currently limited by our capability of removing planet-occulted line-distortion (POLD) contamination from the signal. Aims. In this paper, we aim to characterize the transmission spectrum of WASP-31 b from two and a half transits observed with the ESPRESSO spectrograph at the VLT. Methods. The Rossiter-McLaughlin (RM) signature was analyzed using the RM \"revolutions\" method. Before extracting the transmission spectrum of the planet, we corrected the dataset for telluric lines using molecfit and further modeled the POLD deformations using EvE. Results. We confirm the planet low sky-projected spin-orbit angle from previous studies and further refine its value to $λ= -0.09^{+0.31}_{-0.32}$ deg. We do not detect any species (including previously detected species such as K or CrH) in the planetary atmosphere. In most cases the non-detections are due to the strong POLDs contamination or lack of observable lines in the ESPRESSO wavelength range, and so previous detections cannot be ruled out. Conclusions. Planet-occulted line-distortion contamination continues to be the main limitation of high-resolution transmission spectroscopy for species present in both the star and the planet, hindering atmospheric detections even with state-of-the-art models, in particular for planets with a low sky-projected spin-orbit angle. Developing advanced techniques to isolate planetary signatures is of utmost importance in the advent of ELT-like observations.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15501v1",
        "authors": [
          "M. Steiner",
          "V. Bourrier",
          "D. Ehrenreich",
          "W. Dethier",
          "H. Chakraborty"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Hot Jupiters",
        "WASP-31",
        "WASP",
        "POLD",
        "ELT",
        "MIT",
        "VLT",
        "Act",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:58:54.403105"
    },
    {
      "id": "arxiv-2602.15498v1",
      "title": "Scaling solutions in three-form cosmology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15498v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A hybrid three-form model of dark energy is developed in order to identify scaling solutions, a long-sought feature in three-form cosmology. Exploiting Hodge dualities, the theory is formulated in terms of two scalar functions that are associated with the conjugate momentum, and the three-form dual vector in an isotropic background. The resulting Lagrangian yields a stable scaling attractor where the three-form energy density tracks the dominant background fluid. A dynamical mechanism is also identified that naturally drives the system out of this regime toward a late-time accelerated phase distinguishable from a cosmological constant. This constitutes the first realization of scaling behavior within a three-form dark energy framework.",
        "keywords": [
          "astro-ph.CO",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15498v1",
        "authors": [
          "Vitor da Fonseca",
          "Bruno J. Barros",
          "Tiago Barreiro",
          "Nelson J. Nunes"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Exploiting Hodge",
        "Framework",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.403290"
    },
    {
      "id": "arxiv-2602.15475v1",
      "title": "Coronal Non-Thermal and Doppler Plasma Flows Driven by Photospheric Flux in 28 Active Regions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15475v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Magnetohydrodynamic (MHD) waves and/or the braiding of magnetic field lines are largely thought to be responsible for heating the solar corona, both being mechanisms which are driven by the Sun's photospheric magnetic field. Recent modelling work leads us to expect that such heating mechanisms would be seen in the excess broadening (non-thermal velocity) of coronal spectral emission lines and that larger magnitudes of photospheric magnetic flux would generate more heating, but a direct connection between magnetic flux and spectral line broadening has been difficult to establish. We combine measurements of the photospheric magnetic field from SDO/HMI and non-thermal velocity in log T~6.2 coronal plasma from Hinode/EIS for 28 active regions and find a moderate correlation between the two exists in quiescent active regions, consistent with the photospheric field injecting upward Poynting flux into the solar corona and causing coronal heating. We find that no strong correlation with coronal composition makes it difficult to distinguish between MHD wave heating and magnetic field braiding heating using these diagnostics with current instrumentation.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15475v1",
        "authors": [
          "James McKevitt",
          "Sarah Matthews",
          "Deborah Baker",
          "Hamish A. S. Reid",
          "David H. Brooks"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Active Regions Magnetohydrodynamic",
        "Doppler Plasma Flows Driven",
        "Photospheric Flux",
        "Coronal Non",
        "Solar",
        "EIS",
        "HMI",
        "SDO",
        "MHD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.403572"
    },
    {
      "id": "arxiv-2602.15459v1",
      "title": "A Quantum Genetic Algorithm with application to Cosmological Parameters Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15459v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An Amplitude-Encoded Quantum Genetic Algorithm (AEQGA) has been developed to minimize $χ^2$ functions of different cosmological probes (Supernovae Type Ia, Baryon Acoustic Oscillations, Cosmic Microwave Background Radiation), to find the best-fit value for two cosmological parameters, namely the Hubble Constant and the density matter content of the Universe today. Our main aim is to pave the way to testing the adoption of quantum optimization in the inference of the cosmological parameters that describe the universe evolution. AEQGA computes the merit function classically, and then uses a quantum circuit to entangle the population and perform crossover and mutation operations. The results show consistency with the isocontours of the objective functions. We then tested the general behavior of AEQGA as a function of its hyperparameters and compared it with a second quantum genetic algorithm found in the literature as well as with classical algorithms, finding consistent results.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15459v1",
        "authors": [
          "Giuseppe Sarracino",
          "Vincenzo Fabrizio Cardone",
          "Roberto Scaramella",
          "Giuseppe Riccio",
          "Andrea Bulgarelli"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cosmological Parameters Estimation An",
        "Cosmic Microwave Background Radiation",
        "Encoded Quantum Genetic Algorithm",
        "Baryon Acoustic Oscillations",
        "Quantum Genetic Algorithm",
        "Supernovae Type Ia",
        "Hubble Constant",
        "AEQGA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.404136"
    },
    {
      "id": "arxiv-2602.15448v1",
      "title": "Cosmological Averaging in Nonminimally Coupled Gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15448v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We address the challenge, commonly referred to as the cosmological averaging problem, of relating the large-scale evolution of an inhomogeneous Universe to that predicted by a homogeneous matter distribution in theories of gravity with nonminimal matter-gravity couplings. To this end, we focus on the class of $f(R,T)$ models defined by $f(R,T)=R+F(T)$, which provide a simple yet theoretically consistent realization of nonminimal matter-gravity interactions and can be reformulated as general relativity minimally coupled to a modified matter Lagrangian. Using nonstandard global monopole solutions as a toy model for realistic particles, we show that the spatial average of $F$ typically differs significantly from $F$ evaluated at the spatially averaged trace of $T$, implying that homogeneous cosmological models generally fail to capture the correct large-scale dynamics of the Universe. We further show that dust in these theories generally exhibits a non-vanishing proper pressure. Our results underscore the necessity of properly accounting for spatial averaging when modeling cosmology in theories with nonminimal matter-gravity couplings.",
        "keywords": [
          "astro-ph.CO",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15448v1",
        "authors": [
          "S. R. Pinto",
          "P. P. Avelino"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonminimally Coupled Gravity We",
        "Cosmological Averaging",
        "Standard",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.404392"
    },
    {
      "id": "arxiv-2602.15441v1",
      "title": "Primordial black hole evaporation in a thermal bath and gravitational waves",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15441v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Primordial black holes (PBHs) formed in the early Universe evaporate via Hawking radiation and constitute a generic source of stochastic gravitational waves. Existing studies of gravitational wave production from evaporating PBHs typically assume vacuum evaporation, neglecting the fact that PBHs in the early Universe are embedded in a hot thermal plasma. In this work, we investigate gravitational wave production from primordial black holes whose evaporation is thermally influenced by their surrounding environment. We adopt a thermal evaporation framework in which interactions with the ambient plasma modify the effective decay rate of the black hole, leading to enhanced mass loss at early times and a redistribution of the evaporation history compared to the standard non-thermal vacuum case. Since graviton emission is intrinsically tied to the evaporation history of PBHs, these thermal effects play a crucial role in determining the timing and spectral properties of the resulting stochastic gravitational wave background. Our results provide a consistent framework for incorporating thermal effects into gravitational wave production from evaporating primordial black holes and set the stage for a detailed analysis of their observational signatures.",
        "keywords": [
          "hep-ph",
          "astro-ph.CO",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15441v1",
        "authors": [
          "Arnab Chaudhuri",
          "Kousik Loho"
        ],
        "arxiv_categories": [
          "hep-ph",
          "astro-ph.CO",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "WHO",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.404666"
    },
    {
      "id": "arxiv-2602.15421v1",
      "title": "Calibrating the Tip of the Red Giant Branch and measuring Magellanic Cloud distances to 2% exclusively with Gaia",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15421v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We have calibrated the Tip of the Red Giant Branch (TRGB) using our recent catalog of homogeneous, high-accuracy Globular Cluster (GC) distances. The GC distances were determined by a global joint fit to optical period-Wesenheit relations of their member RR Lyrae stars and type-II Cepheids, anchored by trigonometric parallaxes; all data taken from the ESA Gaia mission's (early) third data release (GDR3). Using I-band measurements in 48 GCs from P. Stetson's database, we determined $M_{I,0} = -3.948^{+0.037}_{-0.034}$ mag (1.6% in distance). Calibrating the TRGB using Gaia's homogeneous, space-based RP photometry of 53 GCs, we found $M_{RP,0} = -3.807^{+0.041}_{-0.035}$ mag (1.8%). The stated uncertainties include statistical and systematic effects, including the correlated nature of the GC distances. The robustness of our calibrations is demonstrated via tests against small-number statistics and analysis choices. Specifically, we found no significant metallicity effect for our sample of old, low-metallicity GCs. We measured $\\sim 2\\%$ distances to the Large (LMC) and Small Magellanic Clouds (SMC), $18.447^{+0.036}_{-0.042}$ mag ($48.9 \\pm 0.9$ kpc) and $18.898^{+0.049}_{-0.054}$ mag ($60.2 \\pm 1.4$ kpc), respectively, using a single well calibrated photometric system: RP (spectro-)photometry from GDR3. Our new TRGB distances, whose absolute scale derives from Gaia parallaxes, are fully independent of the well-known detached eclipsing binary (DEB) distances and agree with them to within the uncertainties. Combining our new TRGB and existing DEB distances, we illustrate how additional constraints may be incorporated in the Local Distance Network and obtain $H_0 = 73.52 \\pm 0.80$ km/s/Mpc. Expected improvements due to the upcoming fourth Gaia data release are discussed.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15421v1",
        "authors": [
          "Mauricio Cruz Reyes",
          "Richard I. Anderson",
          "Bastian Lengen"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Small Magellanic Clouds",
        "Local Distance Network",
        "Globular Cluster",
        "Magellanic Cloud",
        "Red Giant Branch",
        "Gaia We",
        "Meta",
        "TRGB",
        "SMC",
        "DEB",
        "ESA",
        "WHO",
        "LMC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.405110"
    },
    {
      "id": "arxiv-2602.15401v1",
      "title": "On the dynamics, thermodynamics and fine structure of virtual erupting filaments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15401v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It is not fully understood why some solar filaments erupt while others do not. Those that do typically undergo a slow rise followed by an acceleration phase, though this transition requires further investigation. Erupting prominences have been observed to heat up during the acceleration phase, but the origin of this heating remains unclear. Moreover, some coronal mass ejections possess additional fine structure in white-light observations beyond the classical three-part morphology. We aim to elaborate on the dynamics of erupting prominences, investigate the heating during the acceleration phase, and correlate our findings with observations. We employ the open-source MPI-AMRVAC code to solve the 2.5D MHD equations on a coronal domain extending to 300 Mm, using adaptive mesh refinement to attain high resolution. Controlled combinations of footpoint shearing and converging motions applied to an initial magnetic arcade produce erupting flux ropes with self-consistent prominence and coronal rain formation due to thermal instability. We find both non-erupting and erupting cases related to the system energization. Comparison with observations from the AIA Filament Eruption Catalog shows that the slow-rise and impulsive phases are modulated by magnetic reconnection. The transition to acceleration corresponds to an increase in the inflow Alfvén Mach number. Thermal conduction and compressional heating can lead to prominence evaporation. We obtain nested circular fine structure in EUV images of the ejected flux ropes, partly resulting from plasmoid interactions. We conclude that internal heating processes and magnetic reconnection play key roles in the early evolution of CMEs.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15401v1",
        "authors": [
          "Dion Donné",
          "Yuhao Zhou",
          "Hebe Cremades",
          "Rony Keppens"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Filament Eruption Catalog",
        "AMRVAC",
        "Solar",
        "EUV",
        "AIA",
        "MPI",
        "MHD",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.405828"
    },
    {
      "id": "arxiv-2602.15321v1",
      "title": "New Insights from Revisiting the Rotation Period of the Strongly Magnetic O Star, NGC 1624-2",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15321v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "NGC 1624-2 hosts the strongest surface magnetic field found on an O star thus far. When applied across several epochs of observations, the star's currently accepted rotation period (157.99 d) does not coherently characterize the variations of spectral lines of magnetospheric origin. We analyze Lomb-Scargle periodograms produced with new and archival, multi-instrument spectroscopic time series of Balmer H and He spectral lines. We find that 153.17 $\\pm$ 0.42 d and 306.56 $\\pm$ 1.19 d are both equally suitable periods at phasing the spectral and magnetic time series data in a manner consistent with the Oblique Rotator Model. The 306.56 d period implies a magnetic geometry for NGC 1624-2 that is quite different from the previously accepted one, for which both magnetic poles should be observed during a full rotational cycle. If this is the case, the star's magnetic South pole has yet to be observed, and additional spectropolarimetric observations should be acquired in order to confirm whether or not the south pole is in fact observable.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15321v1",
        "authors": [
          "S. Seadrow",
          "V. Petit",
          "G. A. Wade",
          "D. Bohlender",
          "J. Maíz Apellániz"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oblique Rotator Model",
        "Strongly Magnetic",
        "Rotation Period",
        "New Insights",
        "DOE",
        "NGC",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:54.406085"
    },
    {
      "id": "arxiv-2602.15795v1",
      "title": "Surface Block Identity Controls Transport of Symmetric Diblock Copolymer Through Nanopores",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15795v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding how polymer architecture governs transport through nanopores is essential for nanocomposite fabrication, membrane design, and polymer upcycling. However, the effect of the nanoscale structure of copolymers on chain transport through nanoporous media remains poorly understood. In this study, we demonstrate that simply inverting the surface orientation of lamellar poly(styrene-block-2-vinylpyridine) (PS-b-P2VP) diblock copolymers, composed of two monomers with strongly contrasting affinities for SiO2, at the entrance of nanoporous silica significantly alters the kinetics of capillary rise infiltration. Using in situ spectroscopic ellipsometry, we find that infiltration of symmetric PS-b-P2VP into silica nanoparticle (SiO2 NP) packings is significantly faster when the P2VP domain is the top layer of the film and first contacts the nanoparticles, compared to when the PS domain is the top layer. Coarse-grained molecular dynamics simulations reveal that this difference originates from block-specific adsorption pathways that reorganize the nanophase structure around nanoparticles: P2VP-first infiltration forms thin adsorbed layers that drive PS into the pore interiors, generating continuous interfacial pathways that enable rapid, interface-mediated transport. In contrast, PS-first infiltration produces thicker P2VP layers that isolate PS domains and disrupt pathway connectivity, forcing chains to rely on a slower, connectivity-limited transport mechanism through P2VP-rich interstitial regions. Above the order-disorder transition, or upon silanizing nanoparticles to neutralize surface affinity, the rate difference disappears. These findings demonstrate how the interplay between nanoscale domain configuration and polymer-surface affinity governs infiltration dynamics, providing mechanistic insight into tuning transport in nanostructured block copolymers.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15795v1",
        "authors": [
          "Sang Yup Lee",
          "Tae-Young Heo",
          "Uiseok Hwang",
          "Theophile Ienn",
          "Julien Bernard"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Symmetric Diblock Copolymer Through",
        "Surface Block Identity Controls",
        "Nanopores Understanding",
        "NIST",
        "MIT",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.860065"
    },
    {
      "id": "arxiv-2602.15789v1",
      "title": "Displacement general solutions in strain gradient elasticity: review and analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15789v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work, we provide an overview of general solutions for displacement fields in static problems of isotropic strain gradient elasticity (SGE). We not only review existing solutions but also derive new representations, showing that all classical elasticity solutions - including those of Boussinesq-Galerkin, Papkovich-Neuber, Naghdi, Lame, Love and Boussinesq - can be simply generalized to SGE framework. In general, it is shown that SGE enables the use of any classical general solution representation combined with a Helmholtz decomposition for the gradient part of the displacement field. Consistency is also established between the presented Papkovich-Neuber representation and the general solutions of SGE proposed previously by Mindlin (1964), Lurie et al. (2006) and Charalambopoulos et al. (2020). Furthermore, we establish the relationships between the stress functions of different general solutions and show their completeness.",
        "keywords": [
          "cond-mat.other",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15789v1",
        "authors": [
          "Y. Solyaev",
          "E. Hamouda",
          "S. Sherbakov"
        ],
        "arxiv_categories": [
          "cond-mat.other",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "SGE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.860589"
    },
    {
      "id": "arxiv-2602.15774v1",
      "title": "Correlated electronic states at a ferromagnetic oxide interface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15774v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose a minimal tight-binding model for the electronic interface layer of the LaAlO$_3$/SrTiO$_3$ heterostructure with oxygen vacancies. In this model, the effective carriers are subject to oxygen vacancy induced magnetic impurities. Both the effects of random on-site potentials and Zeeman-like exchange interactions between correlated carriers and magnetic impurities are taken into account. By applying the combined coherent potential approximation (CPA) and dynamical mean-field theory (DMFT) for a ferromagnetic state, we uncover a disordered Fermi-liquid regime for the majority-spins and a low energy scale which controls the transport of the minority-spin carriers, both induced by the magnetic impurities.",
        "keywords": [
          "cond-mat.str-el",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15774v1",
        "authors": [
          "D. Jones",
          "A. Weh",
          "A. Östlin",
          "D. Braak",
          "T. Kopp"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "cond-mat.dis-nn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "DMFT",
        "CPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.860940"
    },
    {
      "id": "arxiv-2602.15742v1",
      "title": "Temperley-Lieb modules and local operators for critical ADE models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15742v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate critical restricted solid-on-solid models associated to Dynkin diagrams of type $A$, $D$ and $E$, with fixed, periodic and twisted periodic boundary conditions. These models are endowed with an action of the diagrams of the Temperley-Lieb category. For each model, we obtain the decomposition of the state space as a direct sum of irreducible modules over the Temperley-Lieb algebra $\\mathsf{TL}_N(β)$ or its periodic incarnation $\\mathsf{\\mathcal EPTL}_N(β)$. This allows us to recover the known conformal partition functions for these models in the continuum scaling limit. For each irreducible factor arising in the decompositions, we define an associated local operator on the lattice, which behaves like a connectivity operator. Using knowledge from the Temperley-Lieb representation theory at roots of unity, we show that these operators satisfy certain linear difference relations, which are lattice counterparts of the singular-vector relations in conformal field theory.",
        "keywords": [
          "math-ph",
          "cond-mat.stat-mech",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15742v1",
        "authors": [
          "Yacine Ikhlef",
          "Alexi Morin-Duchesne"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.stat-mech",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPTL",
        "ADE",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.861922"
    },
    {
      "id": "arxiv-2602.15732v1",
      "title": "A sequence of elastic patterns in a sheared bent sheet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15732v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We document a sequence of bifurcations and elastic patterns in sheared bent sheets of intermediate aspect ratio. The sheets undergo inversion of curvature through the passage of localized features, often in S-shaped pairs. Nested force-displacement hysteresis loops provide experimental evidence for snaking. Several mechanisms for coarsening and refinement of the patterns are observed, including splitting, merging, and escape through open boundaries. While most forces, including that required for full snap-through, scale with the length of the sheet, the initial drop in force upon pattern nucleation decreases rapidly with length.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15732v1",
        "authors": [
          "D. Gimeno",
          "B. K. Meghwar",
          "G. Fisher",
          "R. S. Hutton",
          "E. Hamm"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.862089"
    },
    {
      "id": "arxiv-2602.15729v1",
      "title": "Revealing 3D Strain and Carbide Architectures in Additively Manufactured Ni Superalloys",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15729v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Fast directional solidification during Laser Additive Manufacturing (LAM) produces a complex microstructure in nickel-based superalloys, comprising columnar grains with cellular sub-grain structures and carbides. Using non-destructive Scanning 3D X-ray Diffraction (S3DXRD), we reveal spatially complex orientation and intergranular strain relationships that couple strongly to processing-induced cellular sub-grain networks and a primary cubic metal carbide (MC) phase. We have examined 3D orientation and elastic strain tensor fields across 82 $γ$ grains together with the spatial distribution of over 37,000 MC carbides in an ABD-900AM alloy sample manufactured by the Directed Energy Deposition (DED) LAM process. Carbides are spatially associated with the cellular sub-grain network with a weak but present orientation relationship with their parent $γ$ grains. The MC carbides, known to be Ti, Ta and Nb rich, form in regions of high solute segregation, resulting in a significant volumetric lattice parameter patterning in the associated $γ$ phase regions. These chemically distinct solute-rich regions possess a higher associated elastic modulus compared to intercellular regions and determine the local residual stress patterning. These results provide the first non-destructive 3D study of the relationship between rapid solidification-induced segregation, deformation heterogeneity and carbide architectures in an additively manufactured Ni-based superalloy. The insights provide crucial detail to rationalise LAM process parameter optimisation and the coupled spatially governed structural performance.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15729v1",
        "authors": [
          "James A. D. Ball",
          "David M. Collins",
          "Yuanbo T. Tang",
          "Jonathan P. Wright",
          "Can Yildirim"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Additively Manufactured Ni Superalloys",
        "Laser Additive Manufacturing",
        "Directed Energy Deposition",
        "Carbide Architectures",
        "Meta",
        "LAM",
        "ABD",
        "DED",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.862832"
    },
    {
      "id": "arxiv-2602.15687v1",
      "title": "Flexoelectricity-driven softening of bend elasticity leads to spontaneous chiral symmetry breaking in a polar fluid",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15687v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The origin of recently observed spontaneous chiral symmetry breaking in polar fluids is an unsolved problem, and poses fundamental questions as to how heliconical structures emerge in systems composed of achiral molecules. We report on the softening of bend elasticity close to such phase transition, showing that flexoelectric coupling between the electric polarization and the bend deformation is the responsible mechanism, presumably arising from the bent shape of the constituent highly polar molecules.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15687v1",
        "authors": [
          "Aitor Erkoreka",
          "Josu Martinez-Perdiguero",
          "Luka Cmok",
          "Ema Hanžel",
          "Jordan Hobbs"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.862989"
    },
    {
      "id": "arxiv-2602.15664v1",
      "title": "Generalized GMP Algebra for Three-Dimensional Quantum Hall Fluids of Extended Objects",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15664v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a geometric framework for three-dimensional quantum Hall fluids of extended objects (quasi-strings) in the presence of a strong three-form background field associated with a bundle gerbe. In the strong-field regime, fast internal dynamics is frozen and the low-energy kinematics is governed by generalized guiding-center variables consisting of vectorial and tensorial coordinates. We show that these guiding-center variables obey a noncommutative geometry giving rise to a three-dimensional generalization of the Girvin-MacDonald-Platzman (GMP) algebra for projected density operators. Moreover, we relate this algebra to the canonical quantization of a topological BF+BB theory whose level is identified with the Dixmier-Douady invariant. Our results clarify the structure of incompressible quantum Hall-type phases and their geometric and topological features in three spatial dimensions.",
        "keywords": [
          "hep-th",
          "cond-mat.mes-hall",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15664v1",
        "authors": [
          "Giandomenico Palumbo"
        ],
        "arxiv_categories": [
          "hep-th",
          "cond-mat.mes-hall",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Quantum Hall Fluids",
        "Extended Objects We",
        "Framework",
        "WHO",
        "GMP",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.863191"
    },
    {
      "id": "arxiv-2602.15663v1",
      "title": "Entropy production reveals hidden dynamical constraints rather than stochastic disorder",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15663v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Entropy production is often interpreted as a proxy for microscopic disorder or environmental roughness in stochastic systems. We test this interpretation using controlled simulations of overdamped stochastic dynamics on curved surfaces in which local noise, geometry, and forces are held fixed while global constraints are varied. Trajectories are generated for particles evolving toward a central attractor, and entropy production is quantified using both a continuum probability-current estimator and coarse-grained Markov transition statistics across multiple spatial and temporal resolutions. Across systematic sweeps of timestep size, domain extent, and boundary topology, entropy production is governed primarily by constraint-induced probability flow rather than local stochastic variability. Periodic domains that permit sustained circulation yield substantially higher entropy production than reflecting domains despite identical local stochastic structure, with the magnitude of the separation depending on domain extent. In contrast, coarse-grained estimates decrease as temporal resolution increases and rise with finer spatial binning, demonstrating that discrete estimates depend strongly on observation scale and may fail to resolve topology-induced irreversible structure. Ergo, entropy production is not a direct measure of environmental roughness or randomness. Instead, it quantifies how strongly system dynamics are driven away from reversibility by global constraints, geometry, and the space of allowed trajectories. Interpreted in this way, entropy production maps function as diagnostics of organized probability flow and provide a principled method for detecting hidden dynamical constraints from trajectory data alone.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15663v1",
        "authors": [
          "Patrick Romanescu"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.863519"
    },
    {
      "id": "arxiv-2602.15662v1",
      "title": "Quantum Coulomb Liquids of Different Rank in the Breathing Pyrochlore Antiferromagnet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15662v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Emergent gauge fields and Coulomb liquids have long been central to the physics of frustrated pyrochlore magnets, yet their realization beyond conventional, i.e. rank-1 $U(1)$, spin ice and into fully quantum higher-rank regimes has remained elusive. Here we provide a controlled demonstration of this physics in the spin-$\\tfrac{1}{2}$ quantum Heisenberg antiferromagnet on the breathing pyrochlore lattice with symmetry-allowed Dzyaloshinskii--Moriya interactions, using the pseudofermion functional renormalization group. We show that tuning the breathing asymmetry stabilizes extended quantum analogues of both rank-1 and rank-2 $U(1)$ Coulomb liquids within a single microscopic model, directly distinguished by their characteristic pinch-point morphologies in momentum space. This provides the first controlled quantum realization in three dimensions where gauge theories of different rank emerge within a single microscopic spin Hamiltonian. In addition, quantum fluctuations qualitatively reshape the classical nearest-neighbor atlas of phases, causing an incommensurate spiral instability and an extended quantum-disordered regime without dipolar order, both absent from the classical model. Our results establish the breathing pyrochlore as a timely and experimentally relevant platform where higher-rank gauge constraints, conventional magnetic order, and fluctuation-driven quantum phases compete on equal footing, opening a direct route to diagnosing emergent gauge structure in three-dimensional quantum magnets.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15662v1",
        "authors": [
          "Lasse Gresista",
          "Daniel Lozano-Gómez",
          "Matthias Vojta",
          "Simon Trebst",
          "Yasir Iqbal"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Breathing Pyrochlore Antiferromagnet Emergent",
        "Quantum Coulomb Liquids",
        "Different Rank",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.863820"
    },
    {
      "id": "arxiv-2602.15657v1",
      "title": "Self-phoretic oscillatory motion in a one-dimensional channel",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15657v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study a simple model for a particle that is active due to self-phoresis and that has been proposed to model symmetric camphor grains. The particle generates a concentration field through the continuous emission of a chemical substance, and its motion is driven by gradients of this field as it diffuses within a confined channel whose ends perfectly reflect the chemical. The reflection of the chemical field leads to an effective confinement of the particle, which itself is reflected before encountering the channel ends. The system displays a transition from a passive state, where the particle rests at the channel midpoint, to an active state characterized by highly regular, non-chaotic oscillations. We analytically construct the phase diagram and derive the oscillation frequency and amplitude in the vicinity of the transition. A perturbative analysis perfectly describes the dynamics of the particle even for oscillations as large as half the channel size. Furthermore, we develop an analysis which explains the mechanism of particle reflection close to the channel edges in the regime of large activity.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15657v1",
        "authors": [
          "Leah Anderson",
          "David S. Dean"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.864050"
    },
    {
      "id": "arxiv-2602.15624v1",
      "title": "Generalized local potential functional embedding theory of localized orbitals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15624v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work we introduce a generalized flavor, in the sense of generalized Kohn-Sham density functional theory (gKS-DFT), of the recently derived local potential functional embedding theory (LPFET) [J. Chem. Theory Comput. 2025, 21, 20, 10293], where the in-principle exact formalism of DFT is combined with that of density matrix embedding theory (DMET). In generalized LPFET (gLPFET), the embedding clusters are designed from a full-size gKS system where the (in-principle non-local) Hartree-Fock exchange potential is combined with a local (in the localized orbital representation) correlation potential. The latter is optimized self-consistently such that gKS and local embedding cluster's densities match. Unlike in DMET, which uses the same (global) chemical potential value in all clusters, each embedded orbital has its own chemical potential in gLPFET. We show analytically that, when electron correlation is strongly local, the latter potential becomes a simple functional of the correlation potential. Numerical calculations on model systems confirm the high accuracy of gLPFET in this regime, in contrast to DMET. Moreover, we show that gLPFET completely fixes the flaw of LPFET in weaker correlation regimes, through its appropriate description of the Hartree-exchange potential.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15624v1",
        "authors": [
          "Wafa Makhlouf",
          "Bruno Senjean",
          "Emmanuel Fromager"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "LPFET",
        "DMET",
        "DFT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.864434"
    },
    {
      "id": "arxiv-2602.15610v1",
      "title": "Ambipolar doping-induced surface in-gap state on Mott-insulating Ca$_2$RuO$_4$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15610v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We report an x-ray photoemission spectroscopy study of Ca$_2$RuO$_4$ surface-dosed with Cs alkali atoms and C$_{60}$ molecules. Due to its small ionization energy (large electron affinity), deposited Cs atoms (C$_{60}$ molecules) are expected to provide a solid surface with electrons (holes). Upon dosing the dopants to Mott-insulating Ca$_2$RuO$_4$, we found a new Ru $3d$ photoemission peak emerging on the lower binding-energy side, suggesting the creation of a core-hole screening channel associated with coherent Ru $4d$ states around the Fermi level. For both the Cs and C$_{60}$ dosing, this change occurred without an appreciable chemical potential jump. The coherent state, therefore, develops within the Mott gap through hybridization with the impurity level of the dopants. The present work highlights the flexibility of Mott-insulator surfaces as a playground for metal-insulator transitions.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15610v1",
        "authors": [
          "M. Horio",
          "T. Wada",
          "V. Granata",
          "R. Fittipaldi",
          "A. Vecchione"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.864640"
    },
    {
      "id": "arxiv-2602.15606v1",
      "title": "Neel temperature and helical spin order of altermagnetic RuO2",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15606v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The magnetic groundstate of RuO$_2$ remains controversial, with experimental evidence for a nonmagnetic groundstate of ideal bulk material and indications of a magnetic state in strained thin films. Here, I investigate the Néel temperature of the (hypothetical) altermagnetic state of bulk RuO$_2$, stabilized via the DFT$+U$ technique, by mapping on a Heisenberg Hamiltonian. The Néel temperature scales monotonously with the magnetic moment up to the point where a large $+U$ term opens a band gap and turns RuO$_2$ semiconducting. The maximum Néel temperature obtained by this procedure is 408\\,K at $U=3$\\,eV, and much smaller values for smaller $U$. A reciprocal-space eigenvalue analysis reveals a helimagnetic groundstate of the spin model due to intra-sublattice antiferromagnetic coupling. This situation resembles the isostructural $β$-MnO$_2$, which is a prototype helimagnet. Further comparison with calculations on CrO$_2$ and altermagnetic MnF$_2$ taking $U$ as an adjustable parameter supports the validity of the spin model analysis.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15606v1",
        "authors": [
          "Markus Meinert"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Heisenberg Hamiltonian",
        "DFT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.865133"
    },
    {
      "id": "arxiv-2602.15588v1",
      "title": "Origin of a shallow electron pocket: $β$-band in Co$_{1/3}$TaS$_2$ studied by angle-resolved photoemission spectroscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15588v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigated the electronic structure of Co-intercalated 2H-TaS$_2$ using angle-resolved photoemission spectroscopy (ARPES). In the compound Co$_{1/3}$TaS$_2$, the main electronic bands closely resemble those of pristine 2H-TaS$_2$, with no clear signs of band folding. However, a shallow electron pocket, referred to as the $β$-feature, was detected at the Fermi level near the corner of the superlattice Brillouin zone. The surface vs bulk origin of this feature is debated, as it cannot be reproduced using standard DFT calculations. To resolve this, we employed cluster perturbation theory (CPT) to incorporating an exact treatment of strong electron correlations (U) on the cobalt sites, going beyond DFT+U approximation. To further substantiate this, we studied an underdoped sample, Co$_{0.22}$TaS$_2$, where a reduced charge transfer leads to different Co orbital character near the Fermi level. We find that its electronic structure closely resembles that of undoped 2H-TaS$_2$, and crucially, lacks the $β$-feature. Our results demonstrate that the $β$-feature is of the bulk origin emerging from the strong electronic correlations where both the Co charge state and long-range crystallographic order play an important role. This work highlights the need for accurate treatment of electron correlations when studying intercalated transition metal dichalcogenides.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15588v1",
        "authors": [
          "Wojciech Sas",
          "Yuki Utsumi Boucher",
          "Seyed Ashkan Moghadam Ziabari",
          "Gaurav Pransu",
          "Trpimir Ivšić"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "ARPES",
        "Meta",
        "CPT",
        "NSF",
        "Act",
        "DFT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.865880"
    },
    {
      "id": "arxiv-2602.15582v1",
      "title": "Engineering interactions shape in resonantly driven bosonic gas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15582v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In systems with fast periodic driving, there are special subsets of (resonant) states, which behavior can be described with effective, time-independent Hamiltonian in a rotating reference frame. Here, we show that experimentally feasible system of ultracold bosonic atoms on a ring with rapidly oscillating scattering length can be used to simulate time-independent two-component atomic mixture with exotic, long-range interactions.",
        "keywords": [
          "cond-mat.quant-gas",
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15582v1",
        "authors": [
          "Damian Włodzyński",
          "Krzysztof Sacha"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.866021"
    },
    {
      "id": "arxiv-2602.15575v1",
      "title": "Topological Scaling of Nonlinear Injection current and the Quantized Circular Photogalvanic Effect (CPGE)in tilted multi Weyl semimetals(mWSMs)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15575v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a microscopic theory of nonlinear magneto-optical injection currents in multi-Weyl semimetals subjected to a uniform magnetic field. Using the Landau-level spectrum of a tilted multi-Weyl Hamiltonian with arbitrary monopole charge $ν$ as a starting point, we formulate a Kubo-type nonlinear response theory in the Landau-level basis and derive the second-order conductivity tensor. We identify distinct contributions originating from chiral-chiral, chiral-bulk, and bulk-bulk optical transitions, revealing characteristic monopole-charge scaling and sharp resonant structures governed by Landau-level selection rules and tilt-induced asymmetry. In the untilted limit, closed-form analytical expressions emerge that expose universal frequency thresholds and provide clear experimental signatures of higher-order Weyl topology. Our results establish nonlinear magneto-optical injection currents as a direct transport probe of chiral Landau levels and multi-Weyl topological charge.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15575v1",
        "authors": [
          "Deepannita Das",
          "Alestin Mawrie"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantized Circular Photogalvanic Effect",
        "Nonlinear Injection",
        "Topological Scaling",
        "Weyl Hamiltonian",
        "Meta",
        "CPGE",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.866522"
    },
    {
      "id": "arxiv-2602.15574v1",
      "title": "The physics of crêpes: Elasto-gravity control of soft folding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15574v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Like a crêpe resting on a plate, a thin elastic sheet can fold smoothly under its own weight, forming reversible shapes without creases or imposed hinges. Such soft folds arise from a balance between elastic bending and gravity, yet their stability, packing limits, and dynamics remain poorly understood. Here we show that these behaviors are governed by a single physical length scale, the elasto-gravity length $\\ell_{eg}$. Using experiments and heavy-elastica theory, we demonstrate that $\\ell_{eg}$ sets the characteristic fold geometry, determines when a fold becomes unstable and unfolds, and limits how many reversible folds can be stacked in rectangular and circular sheets. In particular, when lengths are rescaled by $\\ell_{eg}$, fold shapes and stability thresholds collapse across materials and thicknesses. We further show that unfolding follows a universal speed scaling $v \\sim \\sqrt{g\\,\\ell_{eg}}$, revealing a gravity-controlled time scale for the release of stored bending energy. Together, these results establish a unified physical framework for reversible folding, compact storage, and gravity-assisted deployment of thin elastic sheets.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15574v1",
        "authors": [
          "Tom Marzin",
          "Barath Venkateswaran",
          "Yuchen Xi",
          "Sunghwan Jung",
          "P. -T. Brun"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.867154"
    },
    {
      "id": "arxiv-2602.15524v1",
      "title": "Observing quantum many-body dynamics in emergent curved spacetime using programmable quantum processors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15524v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We digitally simulate quantum many-body dynamics in emergent curved backgrounds using 80 superconducting qubits on IBM Heron processors. By engineering spatially varying couplings in the spin-$\\frac12$ XXZ chain, consistent with the low energy description of the model in terms of an inhomogeneous Tomonaga-Luttinger liquid, we realize excitations that follow geodesics of an effective metric inherited from the underlying spatial deformation. Following quenches from Néel and few-spin-flip states, we observe curved light-cone propagation, horizon-induced freezing in the local magnetization, and position-dependent oscillation frequencies set by the engineered spatial deformation. Despite strong spatial inhomogeneity, unequal-time correlators reveal ballistic quasiparticle propagation in the spin chain. These results establish large-scale digital quantum processors as a flexible platform for detailed and controlled exploration of many-body dynamics in tunable and synthetic curved spacetimes.",
        "keywords": [
          "quant-ph",
          "cond-mat.stat-mech",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15524v1",
        "authors": [
          "Brendan Rhyno",
          "Bastien Lapierre",
          "Smitha Vishveshwara",
          "Khadijeh Najafi",
          "Ramasubramanian Chitra"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.stat-mech",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "XXZ",
        "IBM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.867902"
    },
    {
      "id": "arxiv-2602.15512v1",
      "title": "Anomalous transport in the Fermi-Pasta-Ulam-Tsingou model: a review and open problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15512v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This review provides an up-to-date account of energy transport in Fermi-Pasta-Ulam-Tsingou (FPUT) chains, a key testbed for nonequilibrium statistical physics. We discuss the transition from the historical puzzle of thermalization to the discovery of anomalous heat transport, where the effective thermal conductivity $κ$ diverges with system size $L$ as $κ\\propto L^δ$. The article clarifies the distinction between two universality classes: the FPUT-$αβ$ model, characterized by $δ= 1/3$ and linked to Kardar-Parisi-Zhang (KPZ) physics, and the symmetric FPUT-$β$ model, where numerical and theoretical evidence support $δ= 2/5$. We investigate how finite-size effects - unavoidably induced by the thermostatting protocols - can disguise the asymptotic scaling. Additionally, we analyze the role of conservative noise in preserving hydrodynamic properties and examine how proximity to integrable limits leads to long-lived quasi-particles and, thereby, to diffusive regimes over intermediate spatial scales.",
        "keywords": [
          "cond-mat.stat-mech",
          "nlin.CD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15512v1",
        "authors": [
          "Stefano Lepri",
          "Roberto Livi",
          "Antonio Politi"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "nlin.CD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "FPUT",
        "KPZ",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.868675"
    },
    {
      "id": "arxiv-2602.15495v1",
      "title": "Ising Model with Power Law Resetting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15495v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the nonequilibrium dynamics of the nearest-neighbour Ising model subjected to stochastic resetting, where the system is intermittently returned to an initial configuration with magnetisation $m_0$, with the inter-reset times drawn from the power law distribution $ατ_0^α/ τ^{α+1}$. The heavy-tailed resets generate magnetisation distributions that differ significantly from both equilibrium dynamics and the previously studied Ising model with exponentially distributed reset times. In two dimensions, for $T > T_C$, we find a quasi-ferro state for all $α$, marked by a double-peaked distribution that diverges at $m=0$ and $m=m_0$; no steady state exists for $α< 1$, while a stationary state emerges for $α> 1$. For $T < T_C$, power law resetting produces two distinct regimes separated by a crossover exponent $α^* = 1-c$: a single-peak ferromagnetic phase localised at $m_{eq}$ for $α< α^*$, and a dual-peak ferromagnetic phase with divergences at $m_{eq}$ and $m_0$ for $α> α^*$. Analytic results in one and two dimensions, supported by simulations, yield a rich phase diagram in the $(T,α)$ plane and reveal how heavy-tailed resetting generates nonequilibrium phases very different from those seen in the case of exponential resetting.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15495v1",
        "authors": [
          "Anagha V K",
          "Apoorva Nagar"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Power Law Resetting We",
        "Ising Model",
        "EPA",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.869530"
    },
    {
      "id": "arxiv-2602.15494v1",
      "title": "Generalized Geometric Brownian motion and the Infinite Ergodicity concept",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15494v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate stochastic processes that generalize geometric Brownian motion, focusing on cases where the standard invariant measure, i.e. the solution of the stationary Fokker-Planck equation does not necessarily exist. We demonstrate that the existence of such a measure depends sensitively on the structure of the drift and diffusion terms, as well as on the chosen discretization scheme of the underlying stochastic dynamics. To ground our discussion, we draw motivation from phenomenological models in statistical theories of turbulence, where geometric Brownian motion serves as a classical example. To address situations where the standard invariant measure fails to exist, we heuristically explore the concept of infinite ergodicity, a notion recently introduced in the context of statistical physics for drift-diffusion stochastic processes.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15494v1",
        "authors": [
          "S. Giordano",
          "R. Blossey"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalized Geometric Brownian",
        "Infinite Ergodicity",
        "Standard",
        "Fusion",
        "DOE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.869789"
    },
    {
      "id": "arxiv-2602.15482v1",
      "title": "Uniform Narrow Excitonic Spectrum in Large-Area Suspended WSe2 Monolayers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15482v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Uniformity in the excitonic spectrum is a key requirement for accessing intrinsic excitonic physics in two-dimensional semiconductors; however, in supported transition-metal dichalcogenide (TMD) monolayers, exciton energies and linewidths can vary spatially due to inhomogeneities created by contact with other materials or contamination left by fabrication procedures. Suspended TMD monolayers provide an effective route to minimizing substrate-induced disorder. Here we demonstrate the spatially uniform excitonic spectrum from high-quality WSe2 suspended monolayers fabricated by gold-assisted exfoliation directly onto an Au contact electrode of a gate-tunable device. The resulting membranes span narrow suspended regions up to ~80 um and show spatially uniform photoluminescence at cryogenic temperatures with neutral-exciton linewidths as low as ~4.5 meV, comparable to the narrowest values reported for high-quality monolayers. Spectral reproducibility across the suspended regions supports an intrinsic optical response, while gate-dependent measurements resolve multiple excitonic species. This approach provides a practical route to electrically tunable potential landscapes in suspended TMD monolayers with a highly uniform excitonic response.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15482v1",
        "authors": [
          "Giacomo Mariani",
          "Riccardo Lodo",
          "Keigo Matsuyama",
          "Yoji Kunihashi",
          "Taro Wakamura"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Uniform Narrow Excitonic Spectrum",
        "Monolayers Uniformity",
        "Area Suspended",
        "Meta",
        "TMD",
        "MIT",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.870149"
    },
    {
      "id": "arxiv-2602.15474v1",
      "title": "Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15474v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.",
        "keywords": [
          "quant-ph",
          "cond-mat.supr-con",
          "q-fin.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15474v1",
        "authors": [
          "J. J. Prieto-Garcia",
          "A. G. del Pozo-Martín",
          "M. Pino"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.supr-con",
          "q-fin.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superconducting Quantum Circuit We",
        "Quantum Reservoir Computing",
        "Statistical Classification",
        "Standard",
        "BERT",
        "MIT",
        "QRC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.870398"
    },
    {
      "id": "arxiv-2602.15467v1",
      "title": "Cluster Ising quantum batteries can mimic super-extensive charging power",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15467v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantum batteries, miniaturized devices able to store and release energy on demand, are promising both because their intrinsic energy and time scales can match those of other quantum technologies and due to the intriguing possibility of achieving super-extensive charging power. While this enhanced scaling is known to appear in several settings, it is generally believed to be forbidden in Wigner-Jordan integrable spin chains charged via quantum-quench protocols. Here, we show that an extended cluster-Ising model, despite belonging to the above category, exhibits super-extensive charging power over wide ranges of system sizes, reaching up to a thousand spins, in proper parameter regimes. This remarkable anomalous scaling is due to a corresponding super-extensive growth of the stored energy, implying that it occurs at large but finite size and cannot persist in the thermodynamic limit. This phenomenon appears robust against finite-temperature effects.",
        "keywords": [
          "quant-ph",
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15467v1",
        "authors": [
          "Anna Pavone",
          "Federico Luigi Cavagnaro",
          "Matteo Carrega",
          "Riccardo Grazi",
          "Dario Ferraro"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cluster Ising",
        "Protocol",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.870630"
    },
    {
      "id": "arxiv-2602.15466v1",
      "title": "Electric-field-tuned consecutive topological phase transitions between distinct correlated insulators in moire MoTe2/WSe2 heterobilayer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15466v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Consecutive topological phase transitions (TPTs) between strongly correlated electronic phases that differ simultaneously in symmetry breaking and topological order are of fundamental interest in condensed matter physics, yet are rarely realized experimentally. We report two consecutive electric-field-driven TPTs at half filling (nu = 1) in angle-aligned MoTe2/WSe2 moire heterobilayers. With increasing out-of-plane displacement field, a geometrically frustrated Mott insulator evolves into a ferromagnetic quantum anomalous Hall (QAH) Mott insulator, i.e., a spin-polarized topological Mott insulator without an observable charge-gap closure, and subsequently into an antiferromagnetic, valley-coherent Mott insulator (VC-AFM) accompanied by a continuous charge-gap collapse and the emergence of a critical metallic state. Layer-resolved magnetic circular dichroism (MCD), magneto-transport, and compressibility measurements jointly determine the phase diagram. The high-field evolution of the antiferromagnetic state reveals a metamagnetic-like transition at a critical field B*, above which a Chern insulating transport response reappears. Our results establish the MoTe2/WSe2 moire platform as a tunable realization of an extended Kane-Mele-Hubbard model hosting sequential correlation-topology-intertwined transitions.",
        "keywords": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15466v1",
        "authors": [
          "Xumin Chang",
          "Zui Tao",
          "Bowen Shen",
          "Wanghao Tian",
          "Jenny Hu"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "AFM",
        "QAH",
        "MCD",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.871029"
    },
    {
      "id": "arxiv-2602.15465v1",
      "title": "Hydrostatic Pressure-enhanced correlated magnetism and Chern insulator in moir'e WSe2",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15465v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Moiré semiconductors offer flat bands where Coulomb interactions and band topology intertwine, while interlayer coupling plays a central role in forming the moiré potential. However, limited interlayer coupling strength and the lack of efficient tuning methods hinder further exploration of correlated phenomena in moiré semiconductors. Here we introduce a cryogenic dual-gated diamond-anvil platform using helium as a pressure medium, enabling reversible hydrostatic tuning together with magneto-optical spectroscopy in twisted bilayer WSe2. Pressure enhances the moiré potential, redshifts excitons, and stabilizes Stoner ferromagnetism otherwise absent at a 3.1-degree twist. Simultaneously, the half-filled C = 1 Chern insulating state strengthens, exhibiting a reduced saturation field. Moreover, we observe a topological phase transition from a Chern insulator to a Mott insulator at around 2 GPa. First-principles calculations reveal that a Gamma-to-K valence-band-maximum switching drives this transition by converting an Ising-like topological K-valley miniband into a spin-degenerate trivial Gamma miniband. Our findings demonstrate hydrostatic pressure as a powerful, continuous control axis for correlated magnetism and topological band engineering in moiré materials.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15465v1",
        "authors": [
          "Pengfei Jiao",
          "Chenghao Qian",
          "Ning Mao",
          "Xumin Chang",
          "Jiayong Xiao"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hydrostatic Pressure",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.871637"
    },
    {
      "id": "arxiv-2602.15446v1",
      "title": "On the origin of in-gap states in amorphous Ge$_2$Sb$_2$Te$_5$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15446v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The localized states in the band gap of amorphous phase change alloys like Ge$_2$Sb$_2$Te$_5$ control the electrical conduction via the Poole-Frenkel mechanism. Understanding the origin of in-gap states and their evolution in time during aging of the glass is therefore important for the control of the resistance drift in phase change memory devices. Here, we use a machine learning interatomic potential to generate several models of Ge$_2$Sb$_2$Te$_5$ whose electronic structure is then analyzed within density functional theory with a hybrid functional. A detailed statistical analysis of the structural motifs on which the in-gap states are localized, reveals that the vast majority of in-gap states involve wrong bonds (homopolar or Ge-Sb bonds) often accompanied by Ge in tetrahedral configurations or overcoordinated Ge and Sb atoms. Metadynamics simulations mimicking glass aging support the picture that structural relaxations lead to the depletion of in-gap states and then to an increase of resistance. The simulations thus provide important insights for the mitigation of the resistance drift in phase change memory devices.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.dis-nn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15446v1",
        "authors": [
          "Omar Abou El Kheir",
          "Marco Bernasconi"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.dis-nn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Meta",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.871926"
    },
    {
      "id": "arxiv-2602.15444v1",
      "title": "Resonant inelastic x-ray scattering in layered trimer iridate Ba4Ir3 O10 : the density functional approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15444v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We have investigated the electronic structure of Ba4Ir3O10 within the density-functional theory (DFT) using the generalized gradient approximation while considering strong Coulomb correlations (GGA+U) in the framework of the fully relativistic spin-polarized Dirac linear muffin-tin orbital band-structure method. Ba4Ir3O10 has a quasi-2D structure composed of buckled sheets, which constitute corner-connected Ir3O12 trimers containing three distorted face-sharing IrO6 octahedra. The Ir atoms are distributed over two symmetrically inequivalent sites: the center of the trimer (Ir1) and its two tips (Ir2). The Ir1 - Ir2 distance within the trimer is quite small and equals to 2.58 A at low temperature. As a result, the clear formation of bonding and antibonding states at the Ir1 site occurs. The large bonding-antibonding splitting stabilizes the dyz-orbital-dominant antibonding state of t2g holes and produces a wide energy gap at the Fermi level. However, the energy gap opens up only with taking into account strong Coulomb correlations at the Ir2 site. Therefore, we have quite a unique situation when the insulating state is driven by both the dimerization at the Ir1 site and Mott insulating behavior at the Ir2 one. We have investigated resonant inelastic x-ray scattering (RIXS) spectra at the Ir L3 edge. The calculated results are in good agreement with experimental data. The RIXS spectrum possesses several sharp features below 2.1 eV corresponding to transitions within the Ir t2g levels. The excitation located from 2.1 to 4.6 eV is due to t2g to eg and O2p to t2g transitions. The wide structure situated at 6.2-12 eV appears due to charge transfer and O2p to eg transitions. We have also presented comprehensive theoretical calculations of the RIXS spectrum at the oxygen K edge.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15444v1",
        "authors": [
          "D. A. Kukusta",
          "L. V. Bekenov",
          "V. N. Antonov"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Agreement",
        "RIXS",
        "GGA",
        "NSF",
        "DFT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.872320"
    },
    {
      "id": "arxiv-2602.15425v1",
      "title": "Optimal conditions for detecting optical dichroism at the nanoscale by electron energy-loss spectroscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15425v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The emergence of optical circular dichroism in chiral nanoscale and molecular systems provides not only a way for analyzing the sample chirality itself but also additional degrees of freedom in manipulating light. Such manipulation can be reached even at the nanoscale level; however, probing and understanding the properties of optical fields well below the diffraction limit requires an adequate technique. Electron energy-loss spectroscopy (EELS) with orbital angular momentum (OAM)-based electron state sorting has been suggested as a suitable candidate, but to date, no conclusive experiments have been performed. We, therefore, theoretically explore the emergence of dichroism in EELS for a canonical single-twist helix nanostructure and present a detailed analysis of the optimal parameters to obtain a robust signal. Our work offers novel insights into the interpretation and volatility of the OAM-resolved EELS signal, which can inspire and guide future experimental efforts.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15425v1",
        "authors": [
          "Marek Zálešák",
          "Martin Ošmera",
          "Martin Hrtoň",
          "Andrea Konečná"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EELS",
        "MIT",
        "OAM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.872768"
    },
    {
      "id": "arxiv-2602.15418v1",
      "title": "Effects of quenched disorder in three-dimensional lattice ${\\mathbb Z}_2$ gauge Higgs models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15418v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the effects of uncorrelated quenched disorder to the phase diagram and continuous transitions of three-dimensional lattice ${\\mathbb Z}_2$ gauge Higgs models. For this purpose, we consider two types of quenched disorder, associated with the sites and plaquettes of the cubic lattice. In both cases, for sufficiently weak disorder, the phase diagram remains similar to that of the pure system, showing two different phases (one of them being a topologically ordered phase), separated by two different continuous transition lines. However, the quenched disorder changes the universality classes of the critical behaviors along some of the transition lines. The random-plaquette disorder turns out to be relevant along the topological ${\\mathbb Z}_2$ gauge transition line, so the critical behaviors belong to the different random-plaquette $\\mathbb{Z}_2$ gauge (RP${\\mathbb Z}_2$G) universality class with length-scale exponent $ν=ν_{\\rm rp}\\approx 0.82$; on the other hand, it turns out to be irrelevant along the other Ising$^\\times$ transition line (a variant of the Ising transitions with a gauge-dependent order parameter), leaving unchanged its asymptotic critical behaviors with $ν=ν_{\\cal I}\\approx 0.63$. The random-site disorder leads to a substantially different scenario: it destabilizes the Ising$^\\times$ critical behaviors of the pure model, changing them into those of the randomly-dilute Ising$^{\\times}$ (RDI$^{\\times}$) universality class with $ν=ν_{\\rm rdi}\\approx 0.68$, while the critical behaviors along the other ${\\mathbb Z}_2$ gauge topological transition line remains stable, with $ν=ν_{\\cal I}\\approx 0.63$.",
        "keywords": [
          "cond-mat.dis-nn",
          "cond-mat.stat-mech",
          "hep-lat"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15418v1",
        "authors": [
          "Claudio Bonati",
          "Ettore Vicari"
        ],
        "arxiv_categories": [
          "cond-mat.dis-nn",
          "cond-mat.stat-mech",
          "hep-lat"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "RDI",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.873763"
    },
    {
      "id": "arxiv-2602.15406v1",
      "title": "Quantum Pontus--Mpemba Effect in Dissipative Quasiperiodic Chains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15406v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate how quasiperiodic spatial structure enables protocol-induced acceleration in open quantum systems by analyzing the Pontus-Mpemba effect in one-dimensional chains subject to Markovian dephasing. The dynamics are governed by a Lindblad superoperator that drives all initial states toward a maximally mixed infinite-temperature steady state, isolating dynamical mechanisms from static equilibrium properties. Considering two representative quasiperiodic models, namely a tight-binding chain with a mosaic potential and its extension with power-law long-range hopping, we show that a properly engineered two-step protocol, in which the system is first steered to a finite temperature intermediate state, yields a strictly shorter overall relaxation time than direct evolution from the same initial configuration. This protocol-induced acceleration persists for both initially localized and extended eigenstates and remains robust in the presence of long-range hopping. A Liouvillian spectral analysis reveals that the mechanism originates from a redistribution of spectral weight that suppresses overlap with the slowest decay modes, rather than from any modification of the decay spectrum itself. Our results establish quasiperiodic chains as a controlled setting for engineering relaxation pathways through Liouvillian spectral structure.",
        "keywords": [
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15406v1",
        "authors": [
          "Yefeng Song",
          "Junxiao Chen",
          "Xiangyu Yang",
          "Mingdi Xu",
          "Xiang-Ping Jiang"
        ],
        "arxiv_categories": [
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dissipative Quasiperiodic Chains We",
        "Quantum Pontus",
        "Mpemba Effect",
        "Protocol",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.874119"
    },
    {
      "id": "arxiv-2602.15392v1",
      "title": "Dual thermodynamic ensembles, relative entropies, and excess free energy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15392v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It has long been known that the relative entropy of a non-equilibrium ensemble to the corresponding equilibrium ensemble is the excess free energy. We show that the reverse relative entropy also has a thermodynamic interpretation: it is the excess free energy of a dual ensemble in which the roles of energy and entropy are interchanged.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15392v1",
        "authors": [
          "Gavin E. Crooks"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.874229"
    },
    {
      "id": "arxiv-2602.15369v1",
      "title": "Entropy Has No Direction: A Mirror-State Paradox Against Universal Monotonic Entropy Increase and a First-Principles Proof that Constraints Reshape the Entropy Distribution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15369v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a purely theoretical, self-contained argument that the Second Law of Thermodynamics cannot be a universal fundamental law in the form ``entropy does not decrease'' (whether asserted trajectory-wise or as a universal statistical principle) when the underlying microscopic dynamics are time-reversal invariant. The core is a mirror-state construction: for any microstate $A$ one constructs its time-reversed partner $B$ (momenta inverted). If a universal monotonicity statement is applied to both $A$ and $B$, it implies that $A$ is a local minimum of entropy at every moment, which forces entropy to be constant and destroys any entropic arrow of time. The consistent replacement is that entropy is a stochastic variable described by a probability distribution $P(S)$, whose shape depends on constraints and boundary conditions. We then prove from first principles that constraints necessarily reshape the long-time entropy distribution $P_{\\infty}(S;λ)$ by altering the invariant measure through changes in the Hamiltonian and/or the accessible phase space. A sharp criterion is given: in the microcanonical setting, the \\emph{only} way $P_{\\infty}^{(E)}(S;λ)$ can remain the same up to translation is when all accessible macrostate volumes are scaled by a common factor; otherwise the distribution changes structurally.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15369v1",
        "authors": [
          "Ting Peng"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "State Paradox Against Universal",
        "Monotonic Entropy Increase",
        "Entropy Has No Direction",
        "Entropy Distribution We",
        "Constraints Reshape",
        "Principles Proof",
        "Second Law",
        "DOE",
        "WHO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.874976"
    },
    {
      "id": "arxiv-2602.15361v1",
      "title": "Intrinsic low-spin state and strain-tunable anomalous Hall scaling in high-quality SrRuO3 (111) films",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15361v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The (111)-oriented 4d ferromagnetic perovskite SrRuO3 (SRO) offers a unique triangular-lattice geometry, making it a promising platform for exploring Berry-curvature-driven and spin-orbit-coupled transport. Here, we present a systematic study of the structure, magnetism, and magnetotransport of high-quality SRO (111) thin films with thicknesses t = 1.2-60 nm grown on SrTiO3 (111) substrates by machine-learning-assisted molecular beam epitaxy. We achieved a residual resistivity ratio of 45.5 in a 60 nm-thick film, the highest reported for this orientation, enabling access to intrinsic electronic and magnetic behavior. Temperature-dependent resistivity confirms Fermi-liquid transport below 15 K in both coherently strained (t = 10, 20 nm) and strain-relaxed (t = 60 nm) films, thereby enabling detailed magnetotransport and magnetic measurements. The linear, non-saturating positive magnetoresistance persists up to 14 T, while Hall-effect measurements and temperature scaling separate intrinsic (Karplus-Luttinger) and extrinsic (side-jump) contributions to the anomalous Hall effect, with the relative weight tuned by (111) epitaxial strain. X-ray magnetic circular dichroism at the Ru M2,3 and O K edges, together with SQUID magnetometry, demonstrates an intrinsically low-spin Ru ground state for both coherently strained and relaxed films, resolving ambiguities among prior reports. These detailed crystalline, electrical, and magnetic characterizations provide a rigorous foundation for understanding and engineering quantum transport in SRO (111).",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15361v1",
        "authors": [
          "Harunori Shiratani",
          "Yuki K. Wakabayashi",
          "Yoshiharu Krockenberger",
          "Masaki Kobayashi",
          "Kohei Yamagami"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SQUID",
        "EPA",
        "SRO",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.875415"
    },
    {
      "id": "arxiv-2602.15348v1",
      "title": "Hidden Structural Control of Solvent Transport under Soft Jamming",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15348v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Transport in soft jammed materials is often described as fluid motion through a fixed structure, leading naturally to capillary based descriptions. This picture appears particularly appropriate in strongly jammed systems, where structural rearrangements are suppressed and little visible motion is observed. Here we investigate solvent transport in foam and show that this intuition fails to capture key aspects of the transport process. By directly observing both liquid penetration and bubble motion under controlled boundary conditions, we demonstrate that solvent transport is strongly influenced by the mechanical response of the foam structure, even though the intrinsic imbibition relative to the foam matrix remains purely capillary-driven. In closed systems, the jammed structure resists penetration and leads to a pronounced slowdown that cannot be accounted for by purely capillary descriptions. In contrast, in open systems, collective bubble motion accompanies solvent invasion, resulting in an apparent acceleration of transport. These results indicate that the lack of structural motion does not guarantee a purely capillary description of transport. Our findings reveal a boundary controlled coupling between flow and structure, and highlight the need to reconsider transport processes in soft jammed systems, including foams, dense colloids, and biological tissues.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15348v1",
        "authors": [
          "Kento Tamaki",
          "Naoya Yanagisawa",
          "Rei Kurita"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hidden Structural Control",
        "Soft Jamming Transport",
        "Solvent Transport",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:58:59.875793"
    },
    {
      "id": "arxiv-2602.15801v1",
      "title": "Deformed Heisenberg algebra and its Hilbert space representations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15801v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A deformation of Heisenberg algebra induces among other consequences a loss of Hermiticity of some operators that generate this algebra. Therefore, these operators are not Hermitian, nor is the Hamiltonian operator built from them. In the present paper, we propose a position deformation of Heisenberg algebra with both maximal length and minimal momentum uncertainties. By using a pseudo-similarity transformation to the non-Hermitian operators, we prove their Hermiticity with a suitable positive-definite pseudo-metric operator. We then construct Hilbert space representations associated with these pseudo-Hermitian operators. Finally, we study the eigenvalue problem of a free particle in this deformed space and we show that this deformation curved the quantum levels allowing particles to jump from one state to another with low energy transitions.",
        "keywords": [
          "math-ph",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15801v1",
        "authors": [
          "Latévi M. Lawson",
          "Ibrahim Nonkané",
          "Kinvi Kangni"
        ],
        "arxiv_categories": [
          "math-ph",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deformed Heisenberg",
        "BERT",
        "NSF",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.648898"
    },
    {
      "id": "arxiv-2602.15770v1",
      "title": "More uses for Thermal Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15770v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We explore combinations of particle and anti-particle yields which can be used to test thermal models in a parameter free way. We also explore combinations which can be used to extract $μ_B/T$, $μ_S/T$ and $μ_Q/T$. We use experimentally measured particle-antiparticle specific ratios for proton $p$, $Λ$, and cascade $Ξ$, for $\\sqrt{s_{NN}} = $ 7.7-39 GeV from RHIC BES phase-1 to extract the $μ_{B,S,Q}/T$. These compared well with published STAR freeze-out parameters. These combinations are verified to predict a similar combination of $Ω$ and $\\overlineΩ$ yields. We also extend this idea to predict (anti-)nuclei yields at energies where they are not measured. We also update parametrizations for the $\\sqrt{s_{NN}}$ dependence of freeze-out parameters $T$ and $μ_B$, and present for the first time a similar parametrization of $μ_S$.",
        "keywords": [
          "hep-ph",
          "nucl-ex",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15770v1",
        "authors": [
          "Natasha Sharma",
          "Lokesh Kumar",
          "Sourendu Gupta"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-ex",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "RHIC",
        "STAR",
        "BES",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.649742"
    },
    {
      "id": "arxiv-2602.15765v1",
      "title": "Development of an accurate formalism to predict properties of two-neutron halo nuclei: case study of $^{22}$C",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15765v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "When moving away from stability or in loosely-bound systems, few-body clusterized structures like two-neutron halo nuclei appear. These emerge from the interplay between the many- and few-body degrees of freedom, and/or strong coupling between bound and continuum states. This motivates the development of models that can accurately describe few-body dynamics while enforcing shell effects. This work has two goals: understanding how to accurately enforce the Pauli principle in few-body models, as well as presenting new technical developments that allow for more robust and cheaper three-body calculations. We focus on properties of the two-neutron halo 22C, but expect the conclusions to apply to other few-body systems. We use a three-body, hyperspherical harmonics formalism combined with the R-matrix method. We compare predictions for properties of 22C starting from phenomenological interactions and using two methods to remove Pauli-forbidden states, the projection and supersymmetric methods. We also present the algorithms and derivations used. Additionally, we explore model space truncations that allow for reduced computational time. We show convergence of the calculation of both bound and scattering states for $K_{max}\\sim 40$. The two methods to enforce the Pauli-exclusion principle lead to different predictions of 22C properties; the projection method is more accurate. We find one efficient channel truncation that reduces the computational cost of our calculations by 20%. Our study clarifies that the projection method is more accurate than the supersymmetric one to enforce the Pauli-exclusion principle. Technical and algorithmic developments enable accurate and efficient computation of two-neutron halo properties. This development paves the way to robust uncertainty quantification in three-body predictions, and is a useful starting point to tackle more complex systems and observables.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15765v1",
        "authors": [
          "Patrick McGlynn",
          "Chloë Hebborn"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.650304"
    },
    {
      "id": "arxiv-2602.15714v1",
      "title": "Thermodynamic Topology of 4D Charged AdS Black Holes with $F^{αβ}F^{γλ}R_{αγβλ}$ Coupling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15714v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the thermodynamic phase transitions of a four-dimensional charged anti-de Sitter black hole endowed with a non-minimal coupling of the form $F^{αβ}F^{γλ}R_{αγβλ}$. Using perturbative methods, we derive a consistent black hole solution and analyze its thermodynamics through both conventional equilibrium techniques and a topological defect classification approach. The system displays van der Waals-like critical behavior, with a swallow-tail structure in the free energy and distinct phase branches. The topological analysis independently confirms the existence of critical points and classifies the system within the universal topological scheme for black hole thermodynamics.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15714v1",
        "authors": [
          "Mehdi Sadeghi",
          "Faramarz Rahmani"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Black Holes",
        "Coupling We",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.651064"
    },
    {
      "id": "arxiv-2602.15694v1",
      "title": "Charm and strange meson fragmentation functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15694v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quark fragmentation functions describe the hadronization process of a quark where any of the final-state hadrons carries a fraction of its initial momentum. We compute these fragmentation functions for a cascade that includes pions, kaons, and the charmed $D$ and $D_s$ mesons, starting from the elementary quark-to-meson fragmentation process. The latter is obtained from the relevant cut diagram, and employs Poincaré covariant Bethe-Salpeter wave functions and quark propagators. We derive a set of twenty-five coupled jet equations that describe the cascade of emitted mesons in the fragmentation process. Their solutions yield full fragmentation functions that offer a consistent picture of the quark fragmentations across the light and heavy sectors.",
        "keywords": [
          "hep-ph",
          "hep-ex",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15694v1",
        "authors": [
          "Roberto C. da Silveira",
          "Ian C. Cloët",
          "Bruno El-Bennich",
          "Fernando E. Serna"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.651644"
    },
    {
      "id": "arxiv-2602.15680v1",
      "title": "Decompactification Limits of Non-Compact Gauge Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15680v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The required absence of global symmetries in quantum gravity has been used to imply that all non-compact gauge theories are in the swampland. This argument stems from the idea that non-compact gauge symmetries always seem to be accompanied by global symmetries that cannot be broken with a finite number of fields. In this work, we investigate whether these symmetries can be broken by an uncountable infinity of fields. We find that the symmetries can be broken, but as soon as we add these fields the EFT breaks down and in some cases decompactifies to a higher-dimensional theory without the non-compact gauge symmetry, akin to undoing a Kaluza-Klein reduction on a non-compact space. We make various comments on the species scale, free parameters, and the Weak Gravity Conjecture along the way.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15680v1",
        "authors": [
          "Finn Gagliano",
          "Christopher Tudball"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Decompactification Limits",
        "Weak Gravity Conjecture",
        "MIT",
        "EFT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.651946"
    },
    {
      "id": "arxiv-2602.15628v1",
      "title": "Expansion operators in spherically symmetric loop quantum gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15628v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The ingoing and outgoing null expansions associated to a spatial 2-sphere are quantized in the spherically symmetric model of loop quantum gravity. It is shown that the resulting expansion operators are self-adjoint in the kinematical Hilbert space with generalized eigenstates. It turns out that the outgoing and ingoing expansion operators share the common continuous part of their spectra but have different additional isolated eigenvalues. These results provide new insights on the avoidance of the singularities in classical general relativity and the establishment of certain notion of quantum horizons.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15628v1",
        "authors": [
          "Xiaotian Fei",
          "Gaoping Long",
          "Yongge Ma",
          "Cong Zhang"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.652317"
    },
    {
      "id": "arxiv-2602.15625v1",
      "title": "Inclusive Flavour Tagging at LHCb",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15625v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A new algorithm based on a deep neural network, DeepSets, for tagging the production flavour of neutral $B^0$ and $B^0_s$ mesons in proton-proton collisions is presented. Exploiting a comprehensive set of tracks associated with the hadronization process, the algorithm is calibrated on data collected by the LHCb experiment at a centre-of-mass energy of $13$ TeV. This inclusive approach enhances the flavour tagging performance beyond the established same-side and opposite-side tagging methods. The observed gains in tagging power of $35\\%$ for $B^0$ mesons and $20\\%$ for $B_s^0$ mesons relative to the combined performance of the existing LHCb flavour-tagging algorithms offer significant benefits for precision measurements of $C\\!P$ violation and mixing in the neutral $B$ meson systems.",
        "keywords": [
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15625v1",
        "authors": [
          "J. E. Blank"
        ],
        "arxiv_categories": [
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inclusive Flavour Tagging",
        "Neural Network",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.652583"
    },
    {
      "id": "arxiv-2602.15609v1",
      "title": "Periodic orbits and gravitational waveforms of spinning particles in nonlocal Gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15609v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we investigate the dynamics and gravitational-wave signatures of periodic orbits of spinning test particles moving in the equatorial plane around static, spherically symmetric black holes within the framework of Deser-Woodard nonlocal gravity. Based on the Mathisson-Papapetrou-Dixon equations, combined with the Tulczyjew spin supplementary condition, we derive the orbital dynamic equations for spinning particles moving in the equatorial plane and impose a timelike constraint to exclude unphysical superluminal trajectories. By comparing with the classical Schwarzschild black hole, we systematically analyze the effects of the nonlocal gravitational parameters $ζ$ and $b$ on the effective potential governing the radial motion of particles and the innermost stable circular orbit. In addition, gravitational waveforms exhibit significant phase differences: an increase in $ζ$ induces a phase delay, whereas an increase in $b$ results in a phase advance. A one-year simulation of the orbital evolution of an extreme mass ratio inspiral demonstrates that when $b=2$ and $ζ\\approx10^{-6}$, the mismatch between the gravitational waveforms predicted for the nonlocal gravity black hole and those for the Schwarzschild black hole reaches the distinguishable threshold ($\\mathcal{M}=0.0125$), providing a basis for observational discrimination between general relativity and nonlocal gravity.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15609v1",
        "authors": [
          "Moisés Bravo-Gaete",
          "Jianhui Lin",
          "Yunlong Liu",
          "Xiangdong Zhang"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gravity In",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.653758"
    },
    {
      "id": "arxiv-2602.15589v1",
      "title": "Four fermion soft emission in QCD hard scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15589v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider the radiation of two distinguishable soft quark-antiquark pairs ($\\mathrm{q}\\bar{\\mathrm{q}}\\mathrm{Q}\\bar{\\mathrm{Q}}$) in a generic process for multiparton hard scattering in QCD. We evaluate the corresponding soft current at tree level in terms of an independent-emission contribution and an irreducible correlation component, which includes strictly non-abelian terms and also terms with an abelian character. The squared current for soft $\\mathrm{q}\\bar{\\mathrm{q}}\\mathrm{Q}\\bar{\\mathrm{Q}}$ emission produces colour dipole and colour tripole interactions between the hard-scattering partons, with structures similar to soft gluon-quark-antiquark emission. The colour tripole interactions are odd under charge conjugation and lead to charge asymmetry effects. We extend our analysis by including QED interactions, the emission of two distinguishable soft lepton-antilepton pairs, and mixed quark-antiquark-lepton-antilepton soft emission.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15589v1",
        "authors": [
          "Leandro Cieri",
          "Dimitri Colferai"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "QCD",
        "QED",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.654139"
    },
    {
      "id": "arxiv-2602.15570v1",
      "title": "ModMax-AdS Black Hole with Global Monopole as Source in Kalb-Ramond Gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15570v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work, we investigate in detail the thermodynamic properties of a spherically symmetric ModMax-AdS black hole sourced by a global monopole within the Kalb-Ramond gravity. We derive the key thermodynamic quantities, including the Hawking temperature, Gibbs free energy, and specific heat capacity, and analyze how the geometric parameters influence these physical quantities. The first law of thermodynamics and the corresponding Smarr formula are explicitly verified. Furthermore, we study the thermodynamic criticality of the system by deriving the critical points and examining the effects of the space-time geometric parameters. We also obtain the inversion temperature and demonstrate that the minimum inversion temperature is modified by the space-time parameters. In addition, the sparsity of Hawking radiation and thermal fluctuations of the system are investigated, highlighting the effects of the parameters on the entropy corrections. Finally, we analyze the optical properties of the black hole, in particular the photon sphere and shadow radius, showing how these parameters influence these features.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15570v1",
        "authors": [
          "Faizuddin Ahmed",
          "Ahmad Al-Badawi",
          "Edilberto O. Silva"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ramond Gravity In",
        "Global Monopole",
        "Black Hole",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.654602"
    },
    {
      "id": "arxiv-2602.15523v1",
      "title": "Displacement memory in regular black hole spacetimes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15523v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Displacement memory, induced by a wave pulse in a regular black hole spacetime, is studied using geodesic (timelike) separation and geodesic deviation. The presence of the wave pulse in such a black hole is modeled via a function $H(u)$ appearing in a restricted version of a generic Bondi-Sachs type line element. Choosing a sech-squared profile for $H(u)$, we first study (numerically) geodesic separation and geodesic deviation in a flat background. Thereafter, similar investigations are carried out in the presence of the black hole, but in regions far away from the vicinity of the horizon. Our results suggest the presence of a distinct displacement memory effect, which depends on the value of the regularisation parameter $g$ as well as the pulse height. Between different types of regular black holes, one notices parameter-dependent changes in the net displacement memory. Further, a clear difference in the magnitude of displacement memory (at large $u$) in regular and singular black holes is also visible in our numerical results.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15523v1",
        "authors": [
          "Ritwik Acharyya",
          "Sayan Kar"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.655180"
    },
    {
      "id": "arxiv-2602.15492v1",
      "title": "Description of nucleon elastic scattering off $^6$Li with the four-body continuum-discretized coupled-channels method",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15492v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Background: Neutron reactions off lithium isotopes up to 50 MeV are important for nuclear data science, around the International Fusion Material Irradiation Facility (IFMIF) facility in particular. Purpose: We aim at constructing a semi-microscopic reaction model that describes neutron elastic scattering off $^6$Li up to 50 MeV taking the breakup channels of $^6$Li into account. Methods: We adopt the continuum-discretized coupled-channels method (CDCC) with an $α+p+n$ three-body model of $^6$Li. We employ the $g$-matrix effective interaction by Jeukenne, Lejeune, and Mahaux (JLM). The renormalization factors of the real and imaginary parts of the JLM interaction are treated as free parameters. Results: The renormalization parameter of the real part of the JLM interaction is found to be constant ($=1.1$), whereas that for the imaginary part has a smooth energy dependence. The four-body CDCC calculation with these parameters well describes the angular distributions of both proton and neutron elastic scatterings as well as the neutron total cross section and proton total reaction cross section. The applicable energy range is found to be from 7 MeV to 50 MeV. Conclusions: We have constructed a reliable reaction model for describing nucleon-$^6$Li scattering between 7 MeV and 50 MeV. This model can directly be applied to inelastic scattering and break reactions for $^6$Li with the help of the complex scaling method.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15492v1",
        "authors": [
          "Kazuyuki Ogata",
          "Shoya Ogawa"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "International Fusion Material Irradiation",
        "Nuclear",
        "Fusion",
        "IFMIF",
        "CDCC",
        "JLM",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.656431"
    },
    {
      "id": "arxiv-2602.15486v1",
      "title": "On the Limitations of Karmarkar's Condition in Static, Conformally Flat Spacetimes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15486v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "For a static and spherically symmetric spacetime, we investigate the class of exact solutions that arise when two fundamental geometric constraints are imposed simultaneously: the Karmarkar's condition and the vanishing of the Weyl tensor. These conditions restrict the curvature in such a way that the spacetime becomes conformally flat and belongs to the family of embedding class-I solutions. Even though the subsequent solutions namely, the Schwarzschild interior solution and the de Sitter solution are well known, the novelty of our presentation is that these solutions are shown to be a direct consequence of the imposed geometric constraints. The physical matter composition becomes highly constrained by the associated geometry under such conditions. The Schwarzschild interior solution describes the spacetime of an incompressible fluid sphere while the de Sitter solution corresponds to a vacuum energy dominated configuration. Interestingly, pressure anisotropy as well as `complexity factor' vanish identically once the Karmarkar's condition and the conformal flatness conditions are applied simultaneously. As these two geometric constraints alone are sufficient to determine the background spacetime uniquely, Karmarkar's condition might not be a suitable method for the development of realistic stellar models in a conformally flat spacetime unless one invokes other factors into consideration such as time-dependent metric potentials.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15486v1",
        "authors": [
          "Samstuti Chanda",
          "Ranjan Sharma",
          "Sunil D. Maharaj"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Conformally Flat Spacetimes For",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.657074"
    },
    {
      "id": "arxiv-2602.15469v1",
      "title": "A fresh look at boundary terms in Einstein-Hilbert gravity via an initial value variational principle",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15469v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A key tenet of general relativity is the dynamical nature of space-time, ideally represented as an initial value problem. Here we explore the variational formulation of classical Einstein-Hilbert gravity as initial value problem by constructing its Schwinger-Keldysh-Galley (SKG) action, including a careful treatment of boundary terms. The construction is based on a doubling of degrees of freedom and independent of a foliation. The action naturally decomposes into a bulk term furnishing Einstein's equations and a boundary term, which is related to conserved quantities, such as the Komar mass. We find that since only trivial connecting conditions must be specified on boundaries, the variational action principle for gravity as an initial value problem is rendered well-posed without the need to add additional boundary terms. The SKG approach to gravity offers a novel and complementary avenue to solve for the metric of spacetime directly from the action, bypassing the governing equations.",
        "keywords": [
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15469v1",
        "authors": [
          "Songmin Ha",
          "Alexander Rothkopf"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "SKG",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.657510"
    },
    {
      "id": "arxiv-2602.15462v1",
      "title": "Static black holes in an external uniform electromagnetic field: Reissner-Nordstrom accelerating in Bertotti-Robinson",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15462v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We provide a detailed analysis of the non-twisting subcase of the large class of type D black holes with a non-aligned electromagnetic field, presented recently in [H. Ovcharenko and J. Podolsky, Phys. Rev. D 112 (2025) 064076]. We show that such exact solutions split into two main subclasses that (after a suitable re-parametrization) can be interpreted as either the uncharged Schwarzschild or C-metric in the external Bertotti-Robinson (BR) spacetime with geometry ${\\mathrm{AdS}_2\\times\\mathrm{S}_2}$, or as the charged Reissner-Nordstrom black hole accelerating in the external BR electromagnetic field. The distinction between these two subclasses is determined by the parameter $r_0$ that encodes relations between the external Maxwell field (given by the non-aligned components of the Faraday tensor ${Φ_0=Φ_2}$) and the Maxwell field created by the charge of the black hole (given by the aligned component $Φ_1$). Namely, if ${r_0=0}$ then the electromagnetic field is fully determined by ${Φ_0=Φ_2}$, and one gets the C-metric in the BR universe (including also the non-accelerating Schwarzschild-BR black hole). But if ${r_0\\neq 0}$ then the electromagnetic field is independently determined by both the external BR field and the field of a black hole itself, and this can be interpreted as the Reissner-Nordstrom black hole accelerating in the Bertotti-Robinson spacetime. Even though such an interpretation of the spacetime family is quite simple, it contains a lot of subtleties (e.g. the no-charge limit of the RN-BR spacetime, the non-trivial dependence on the signs of the mass and charge of a black hole, extreme black holes, and others) which we carefully investigate in this work. We also show the explicit relation to solutions previously found by Van den Bergh and Carminati, and we discuss the connection to the Alekseev-Garcia and Alexeev solutions.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15462v1",
        "authors": [
          "Hryhorii Ovcharenko",
          "Jiri Podolsky"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robinson We",
        "BERT",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.658766"
    },
    {
      "id": "arxiv-2602.15453v1",
      "title": "Perturbative calculations of nucleon-deuteron elastic scattering in chiral effective field theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15453v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a framework for calculating nucleon-deuteron scattering using strict perturbation theory for treating subleading interactions in chiral effective field theory (ChEFT). Rather than using direct evaluations in the distorted-wave expansion, our approach solves a hierarchy of integral equations to obtain subleading scattering amplitudes. A benchmark with the wave packet continuum-discretization is performed. This framework benefits from the fact that the renormalization-group invariance chiral forces involves only a limited number of two-body partial waves at leading order. We use it to calculate nucleon-deuteron elastic scattering differential cross sections and analyzing powers up to next-to-leading order.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15453v1",
        "authors": [
          "Lin Zuo",
          "Wendi Chen",
          "Dan-Yang Pang",
          "Bingwei Long"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "MIT",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.659011"
    },
    {
      "id": "arxiv-2602.15420v1",
      "title": "Particle production, absorption, scattering, and geodesics in a Schwarzschild--Hernquist black hole",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15420v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate quantum and classical signatures of a Schwarzschild black hole embedded in a Hernquist dark matter halo. Starting from the exact spherically symmetric solution describing this composite system, we analyze particle production for both bosonic and fermionic fields using semiclassical techniques. Hawking radiation is derived through Bogoliubov transformations and independently via the tunneling method with energy conservation, allowing us to identify the effective temperature, emission spectrum, and the role of dark matter parameters in suppressing particle creation. The evaporation process is examined in the high-frequency regime, leading to modified evaporation times and emission rates relative to the vacuum Schwarzschild case. We further study absorption and scattering of massless scalar waves employing a partial-wave analysis, computing phase shifts, partial and total cross sections, and assessing the impact of the Hernquist scale radius and density on these observables. Finally, null and timelike geodesics are explored to characterize light propagation and particle motion in the presence of the dark matter halo.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15420v1",
        "authors": [
          "N. Heidari",
          "A. A. Araújo Filho",
          "P. H. M. Barros"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.659513"
    },
    {
      "id": "arxiv-2602.15410v1",
      "title": "Residue-Enhanced Pion-Rho Mixing as the Origin of Nonmonotonic Charged Pion Mass in Magnetic Fields",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15410v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We identify the dynamical origin of the non-monotonic magnetic field dependence of the charged pion mass observed in lattice QCD. Using a near-pole effective action derived from the SU(2) Nambu--Jona-Lasinio model, we show that the lowest Landau level charged pion mixes with the longitudinally polarized charged rho meson, which shares the same quantum numbers in a magnetic background. This mixing, generated by quark-loop polarization and a gauge-invariant tree-level operator matched to the vacuum decay $ρ^\\pm\\rightarrowπ^\\pmγ$, induces strong level repulsion. Crucially, this effect is dynamically amplified by a rapid suppression of the rho-meson wave function renormalization near the pole. As a result, the lower eigenmode exhibits a turnover as the magnetic field increases. The mechanism is analogous to singlet-triplet mixing in positronium and provides a natural explanation for the lattice results. Such effects are expected to be generic for charged mesons in magnetic fields when symmetry allowed mixing and near-pole residue suppression are present.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15410v1",
        "authors": [
          "Ziyue Wang"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonmonotonic Charged Pion Mass",
        "Magnetic Fields We",
        "Enhanced Pion",
        "Rho Mixing",
        "QCD",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.660415"
    },
    {
      "id": "arxiv-2602.15386v1",
      "title": "Potassium influence on Earth's mantle convection and Borexino data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15386v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "High flux of geoantineutrinos $^{40}$K and geoneutrinos $^{40}$K ($^{40}$K-geo-($\\barν + ν$)) can be obtained from reanalysis of the Borexino Phase III data. Large amounts of $^{40}$K should produce a significant heat flow that should affect Earth's internal processes. We present the results of the modeling of mantle convection taking into account the excess heat from $^{40}$K.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15386v1",
        "authors": [
          "Ivan Karpikov"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Borexino Phase",
        "III",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.660767"
    },
    {
      "id": "arxiv-2602.15331v1",
      "title": "Higher-twist effect in inclusive electron-positron annihilation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15331v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We establish a comprehensive theoretical framework for the electron-positron single-inclusive annihilation (SIA) process that incorporates higher-twist contributions up to twist-4 and demonstrate that these effects should be considered in low-energy reactions. Through a systematic collinear expansion of the hadronic tensor, we derive the complete set of structure functions in terms of collinear fragmentation functions (FFs), explicitly including multi-parton correlators up to the four-parton level. To evaluate the impact of these power corrections, we estimate the twist-4 unpolarized FF using a spectator model and compute the normalized differential cross section for $π^0$ production. Our numerical analysis reveals that the interplay between kinematic hadron mass corrections and dynamical twist-4 effects improves the theoretical description of recent BESIII data at relatively low-$z$ region. Furthermore, the $Q$-dependence confirms that higher-twist corrections are dominant at intermediate energy scales. These findings indicate that standard leading-twist global analyses must be extended to include these power corrections for precise studies of hadronization dynamics.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15331v1",
        "authors": [
          "Jing Zhao",
          "Yongjie Deng",
          "Tianbo Liu",
          "Weihua Yang"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "BESIII",
        "SIA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.661549"
    },
    {
      "id": "arxiv-2602.15320v1",
      "title": "The Roper Resonance: Still Controversial 60 Years Later",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15320v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Few baryon resonances have generated as much discussion, even controversy, as the first positive parity excited state with nucleon quantum numbers. We re-examine the issue using insight gained from lattice QCD, complemented by Hamiltonian effective field theory. In doing so, we also examine the distinction between a state that can be naturally described as a quark model state and one that is dynamically generated.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15320v1",
        "authors": [
          "Anthony W Thomas"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Still Controversial",
        "Years Later Few",
        "QCD",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.661695"
    },
    {
      "id": "arxiv-2602.15305v1",
      "title": "Distinguishing Schwinger effect from Hawking radiation in Reissner-Nordstr{ö}m black holes via entanglement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15305v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A charged black hole can emit charged particles via two independent mechanisms: the Hawking radiation and the Schwinger effect, which are intertwined in the radiation spectrum. In this paper, we will show that the two effects can be distinguished by analyzing the entanglement entropy carried by the produced particle pairs. Explicitly, we apply the island formula to the near extremal Reissner-Nordstr{ö}m (RN) black hole to calculate the total entanglement entropy of the radiation. Meanwhile we use the heat kernel method to calculate the entanglement entropy of charged particle pairs produced solely from the Schwinger effect. By comparing with the total entanglement entropy, we obtain the entanglement entropy produced purely from the Hawking radiation. Consequently, the two effects are distinguishable in near extremal RN black holes after the Page time. Furthermore, we also employ the brick wall model and the Pauli-Villars regularization to derive the entanglement entropy from the Schwinger effect, which gives a slightly different result with that obtained from the heat kernel method.",
        "keywords": [
          "hep-th",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15305v1",
        "authors": [
          "Ruo-Han Wang",
          "Jia-Rui Sun"
        ],
        "arxiv_categories": [
          "hep-th",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distinguishing Schwinger",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.662295"
    },
    {
      "id": "arxiv-2602.15295v1",
      "title": "Update to the U.S. National Input to the European Strategy Update for Particle Physics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15295v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this document we update the status of U.S. community inputs for the European Strategy for Particle Physics Update (ESPPU) since April 1, 2025, and offer responses to the revised questions. Major new inputs include a long-term strategy report from the National Academies of Sciences, Engineering, and Medicine and the formal formation of a U.S. Muon Collider Collaboration.",
        "keywords": [
          "hep-ex",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15295v1",
        "authors": [
          "André de Gouvêa",
          "Hitoshi Murayama",
          "Mark Palmer",
          "Heidi Schellman"
        ],
        "arxiv_categories": [
          "hep-ex",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Muon Collider Collaboration",
        "European Strategy Update",
        "Particle Physics Update",
        "Particle Physics In",
        "National Academies",
        "European Strategy",
        "National Input",
        "ESPPU",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.662448"
    },
    {
      "id": "arxiv-2602.15276v1",
      "title": "Compact Q-balls and Q-shells within a $CP^N$ Skyrme-Faddeev type model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15276v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "While $CP^N$ models with analytic potentials are known to support finite-energy compact Q-ball and Q-shell solutions, their behavior in more complex Lagrangian frameworks remains a subject of active research. This work explores these non-topological structures within an extended Skyrme-Faddeev-type model that incorporates quartic derivative terms. In this context, harmonic time dependence and the presence of quartic terms constitute two independent stabilization mechanisms that allow the configurations to circumvent Derrick's scaling argument. We investigate the necessary conditions for the existence of these solutions and analyze the influence of quartic terms on the properties of the resulting compactons, specifically examining the $E(Q)$ relationship between energy and Noether charge. Our findings provide valuable insights into the stability and characteristics of compact boson stars within $CP^N$ models featuring higher-order derivative terms.",
        "keywords": [
          "hep-th",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15276v1",
        "authors": [
          "E. L. Colaço",
          "P. Klimas",
          "L. R. Livramento",
          "N. Sawado",
          "S. Yanai"
        ],
        "arxiv_categories": [
          "hep-th",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.662818"
    },
    {
      "id": "arxiv-2602.15275v1",
      "title": "To boost or not to boost, that's the question",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15275v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Or should we talk about dS/CFT correspondence or dS/SFT correspondence in cosmological correlators? In non-unitary field theories -- which are conjectured to be dual to cosmological correlators -- scale invariance does not necessarily imply full conformal invariance. While general relativity predicts the emergence of conformal invariance (or boost symmetry in the bulk), various modified theories of gravity suggest only scale invariance, characterized by the absence of bulk boost symmetry. We demonstrate this distinction using Einstein-Aether theory as a canonical example.",
        "keywords": [
          "hep-th",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15275v1",
        "authors": [
          "Yu Nakayama"
        ],
        "arxiv_categories": [
          "hep-th",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "DOE",
        "SFT",
        "CFT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:05.663094"
    },
    {
      "id": "arxiv-2602.15826v1",
      "title": "QwaveMPS: An efficient open-source Python package for simulating non-Markovian waveguide-QED using matrix product states",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15826v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "QwaveMPS is an open-source Python library for simulating one-dimensional quantum many-body waveguide systems using matrix product states (MPS). It provides a user-friendly interface for constructing, evolving, and analyzing quantum states and operators, facilitating studies in quantum physics and quantum information with waveguide QED systems. This approach enables efficient, scalable simulations by focusing computational resources on the most relevant parts of the quantum system. Thus, one can study a wide range of complex dynamical interactions, including time-delayed feedback effects in the non-Markovian regime and deeply non-linear systems, at a highly reduced computational cost compared to full Hilbert space approaches, making it both practical and convenient to model a variety of open waveguide-QED systems (in Markovian and non-Markovian regimes), treating quantized atoms and quantized photons on an equal footing.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15826v1",
        "authors": [
          "Sofia Arranz Regidor",
          "Matthew Kozma",
          "Stephen Hughes"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "MPS",
        "QED",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.151227"
    },
    {
      "id": "arxiv-2602.15800v1",
      "title": "Entanglement in the Dicke subspace",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15800v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we provide a complete mathematical theory for the entanglement of mixtures of Dicke states. These quantum states form an important subclass of bosonic states arising in the study of indistinguishable particles. We introduce a tensor-based parametrization where the diagonal entries of these states are encoded as a symmetric tensor, enabling a direct translation between entanglement properties and well-studied convex cones of tensors. Our results bridge multipartite entanglement theory with semialgebraic geometry and the theory of completely positive and copositive tensors. This dictionary maps separability to completely positive tensors, the PPT property to moment tensors, entanglement witnesses to copositive tensors, and decomposable witnesses to sum of squares tensors. Using this framework, we construct explicit PPT entangled states in three or more qutrits. In this class of states, we establish that PPT entanglement exists for all multipartite systems with three qutrits or more, disproving a recent conjecture in [J. Math. Phys. 66, 022203 (2025)]. We also show that, for mixtures of Dicke states, the PPT condition with respect to the most balanced bipartition implies PPT with respect to any other bipartition. We further connect bosonic extendibility of mixtures of Dicke states to the duals of known hierarchies for non-negative polynomials, such as the ones by Reznick and Polya. We thus provide semidefinite programming relaxations for separability and entanglement testing in the Dicke subspace.",
        "keywords": [
          "quant-ph",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15800v1",
        "authors": [
          "Aabhas Gulati",
          "Ion Nechita",
          "Clément Pellegrini"
        ],
        "arxiv_categories": [
          "quant-ph",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "PPT",
        "EPA",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.151703"
    },
    {
      "id": "arxiv-2602.15790v1",
      "title": "Steady state coherence in a qubit is incompatible with a quantum map",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15790v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider the issue of steady state coherences in a single qubit in the case of a composite system-bath interaction as proposed in \\cite{Guarnieri18}. Based on a field theoretical approach we reanalyse the issue within a Redfield description. We find that the Redfield approach in accordance with \\cite{Guarnieri18} yields steady state coherences but violating the properties of a quantum map also gives rise to negative populations. The issue is resolved by applying the Lindblad equation which is in accordance with a proper quantum map. The Lindblad equation, however, also implies the absence of steady state coherence. We conclude that steady state coherence in a a qubit is incompatible with a quantum map.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15790v1",
        "authors": [
          "Hans C. Fogedby"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.151945"
    },
    {
      "id": "arxiv-2602.15706v1",
      "title": "Meta-Learning for GPU-Accelerated Quantum Many-Body Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15706v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We explore the industrial and scientific applicability of the VQE-LSTM framework by integrating meta-learning with GPU accelerated quantum simulation using NVIDIA's CUDA-Q (CUDAQ) platform. This work demonstrates how an LSTM-FC meta-initialization module can extend the practical reach of the Variational Quantum Eigensolver (VQE) in both chemistry and physics domains. In the chemical regime, the framework predicts ground-state energies of molecular Hamiltonians derived from PySCF, achieving near FCI accuracy while maintaining favorable O(N^2) scaling with molecular size. In the physical counterpart, we applied the same model to quantized Simple Harmonic Motion systems (SHM), successfully reproducing its ground and excited states through VQE and Variational Quantum Deflation (VQD) methods. Benchmark results on NVIDIA GPUs reveal significant speedups over CPU-based implementations, validating CUDAQ's capability to handle large-scale variational workloads efficiently. Overall, this study establishes VQE-LSTM as a viable and scalable approach for GPU accelerated quantum simulation, bridging quantum chemistry and condensed-matter physics through a unified, meta-learned initialization strategy.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15706v1",
        "authors": [
          "Yun-Hsuan Chen",
          "Jen-Yu Chang",
          "Tsung-Wei Huang",
          "En-Jui Kuo"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variational Quantum Eigensolver",
        "Variational Quantum Deflation",
        "Accelerated Quantum Many",
        "Simple Harmonic Motion",
        "Body Problems We",
        "Framework",
        "NVIDIA",
        "CUDAQ",
        "Meta",
        "LSTM",
        "CUDA",
        "CPU",
        "VQE",
        "FCI",
        "GPU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.152294"
    },
    {
      "id": "arxiv-2602.15653v1",
      "title": "High-rate Scalable Entanglement Swapping Between Remote Entanglement Sources on Deployed New York City Fibers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15653v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Entanglement swapping between photon pairs generated at physically separated nodes over telecommunication fiber infrastructure is an essential step towards the quantum internet, enabling applications such as quantum repeaters, blind quantum computing, distributed quantum computing, and distributed quantum sensing. However, successful networked entanglement swapping relies on generating indistinguishable pairs of photons and preserving them over deployed fibers. This has limited most previous demonstrations to laboratory settings or relied on sophisticated methods to maintain the necessary indistinguishability. Here, we demonstrate a scalable entanglement swapping experiment using naturally indistinguishable entanglement sources based on warm atomic vapor cells. Without sharing lasers or optical frequency references between nodes, nor the need for pulsing the sources, we achieve a swapping rate of nearly 500 pairs/s while maintaining the CHSH parameter above 2. Additionally, we demonstrate the scalability of our method by maintaining the quality of the entanglement swapping on 17.6-km of deployed fibers in NYC, relying on commercially available SPADs at the spoke nodes, SNSPDs at the hub and standard time-synchronization techniques. Our work paves the way for the practical deployment of large-scale hub-and-spoke quantum networks within cities and data centers.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15653v1",
        "authors": [
          "Alexander N. Craddock",
          "Tyler Cowan",
          "Niccolò Bigagli",
          "Suresh Yekasiri",
          "Dylan Robinson"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Entanglement Swapping Between",
        "Remote Entanglement Sources",
        "Deployed New York City",
        "Fibers Entanglement",
        "Quantum Computing",
        "Laboratory",
        "Standard",
        "CHSH",
        "EPA",
        "NYC",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.152738"
    },
    {
      "id": "arxiv-2602.15630v1",
      "title": "Controlling correlations of a polaritonic Luttinger liquid by engineered cross-Kerr nonlinearity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15630v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study correlation properties of polaritons at zero temperature in a multiconnected Jaynes--Cummings (MCJC) lattice on a superconducting circuit quantum electrodynamics platform with engineered cross-Kerr nonlinearity that mimics attractive nearest-neighbour interaction. A multi-connected Jaynes--Cummings lattice is a one-dimensional lattice constructed from alternating qubits and resonators with different left and right couplings. The nearest-neighbour interaction or cross-Kerr coupling is implemented dispersively through ladder-type qutrits between each nearest neighboring pair of resonator modes. Projecting onto the lower-polaritonic manifold, we derive an extended two-mode (bipartite) Bose--Hubbard-like model featuring on-site and attractive nearest-neighbor interactions. Employing a continuum bosonization approach, we express the Hamiltonian in terms of symmetric ($+$) and antisymmetric ($-$) collective modes. In the regime where the ($-$) sector acquires a finite gap, one can reduce the system to an effective single-component Luttinger liquid model for the $+$ sector. The cross-Kerr term reduces the compressibility of the ($+$) mode, thereby enhancing the corresponding Luttinger parameter $K_{+}$, resulting in the slower algebraic decay of single-particle correlations, $G(x)\\propto|x|^{-1/(4K_{+})}$.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15630v1",
        "authors": [
          "Nabaneet Sharma",
          "Anushree Dey",
          "Bimalendu Deb"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MCJC",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.153107"
    },
    {
      "id": "arxiv-2602.15619v1",
      "title": "Nonlinear Phase Gates Beyond the Lamb-Dicke Regime",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15619v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nonlinear phase gates are essential to achieve the universality of continuous-variable quantum processing and its applications. We present a deterministic protocol for generating nonlinear phase gates in trapped ion systems using simultaneous two-tone sideband drives beyond the Lamb-Dicke regime. Our approach harnesses higher-order interaction terms typically neglected or suppressed to construct nonlinear phase gates. This methodology enables high-fidelity gate engineering with a near three-fold reduction in control pulses compared to state-of-the-art theoretical proposals.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15619v1",
        "authors": [
          "Akram Kasri",
          "Kimin Park",
          "Radim Filip"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlinear Phase Gates Beyond",
        "Dicke Regime Nonlinear",
        "Protocol",
        "NIST",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.153301"
    },
    {
      "id": "arxiv-2602.15615v1",
      "title": "Magnetically assisted spin-resolved electron diffraction: Coherent control of spin population and spatial filtering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15615v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electron diffraction from nanogratings provides a platform for free-electron interferometry, yet controlled manipulation of electron spin in such geometries remains largely unexplored. In particular, the role of the self-generated magnetic field arising from electron motion and the feasibility of coherent spin control without disrupting diffraction coherence have not been quantitatively investigated. In this article, a self-consistent Maxwell-Pauli framework is developed to study spin-resolved electron diffraction from nanogratings in the presence of magnetic fields. The model incorporates geometric confinement, image-charge interactions, self-generated magnetostatic fields, and externally applied magnetic fields. Numerical simulations show that the intrinsic magnetic self-field produced by the electron probability current is several orders of magnitude too weak to induce measurable spin mixing, demonstrating that nanogratings act as spin-conserving beam splitters under field-free conditions. When a uniform magnetic field is applied upstream of the nanograting, coherent Larmor precession enables controlled spin rotation without modifying the diffraction geometry or degrading coherence. The magnetic field required for a $π$ spin rotation scales inversely with the interaction length and electron de Broglie wavelength $λ_{dB}$. Furthermore, a downstream nonuniform magnetic field applied after the nanograting imparts a spatially varying Zeeman phase, producing opposite transverse momentum shifts for the two spin components. The spin-dependent transverse dynamics is analyzed using Husimi Q-function phase-space maps, which visualize spin-dependent population redistribution and momentum separation. The proposed approach enables tunable spatial separation of spin-resolved free electron beams and establishes an all-magnetic route for coherent spin rotation, control, and interferometry.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15615v1",
        "authors": [
          "Sushanta Barman",
          "Kuldeep Godara",
          "Sudeep Bhattacharjee"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.154536"
    },
    {
      "id": "arxiv-2602.15545v1",
      "title": "Optimal Classification of Three-Qubit Entanglement with Cascaded Support Vector Machine",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15545v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a systematic framework for three-qubit entanglement classification using a cascaded architecture of Support Vector Machine (SVM) classifiers. Leveraging the well defined three-qubit structure with the four nested entanglement classes (S, B, W, and GHZ), we construct three distinct witness models ($\\mathcal{M}_{B}$, $\\mathcal{M}_{W}$, and $\\mathcal{M}_{GHZ}$) that sequentially discriminate between these classes. The proposed Cascaded model achieves an overall classification accuracy of $95\\%$ on a comprehensive dataset of mixed states. The framework's robustness and generalization capabilities are confirmed through rigorous testing against out-of-distribution (OOD) entangled states and various quantum noise channels, where the model maintains high performance. A key contribution of this research is an optimization protocol based on systematic feature importance analysis. This approach yields a tunable framework that significantly reduces the number of required features, while maintaining reliable model accuracy.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15545v1",
        "authors": [
          "Fatemeh Sadat Lajevardi",
          "Azam Mani",
          "Ali Fahim"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cascaded Support Vector Machine",
        "Support Vector Machine",
        "Optimal Classification",
        "Qubit Entanglement",
        "Framework",
        "Protocol",
        "OOD",
        "GHZ",
        "SVM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.154962"
    },
    {
      "id": "arxiv-2602.15520v1",
      "title": "Universal entanglement-inspired correlations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15520v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantum correlations, crucial for the advantage and advancement of quantum science and technology, arise from the impossibility of expressing a quantum state as a tensor product over a given set of parties. In this work, a generalized notion of correlations via arbitrary products is formulated. Remarkably, as a universal property, the connection between such general products and tensor products is established, allowing one to relate generic non-product states to the common notion of entangled states. We construct the set of free operations for general types of products by extending the local-operation-and-classical-communication paradigm, familiar from standard entanglement theory, thereby establishing a resource theory of correlations for general products. A generalization is provided beyond two factors that can be universally related to multipartite entanglement. Applications that highlight the usefulness of the approach are discussed, such as the factorization of fermionic states, the non-local factorization of multi-photon states into single-photon states, and the interesting possibility of understanding prime numbers as a form of single-party entanglement.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15520v1",
        "authors": [
          "Elizabeth Agudelo",
          "Laura Ares",
          "Jan Sperling"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.155474"
    },
    {
      "id": "arxiv-2602.15487v1",
      "title": "Drone delivery packing problem on a neutral-atom quantum computer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15487v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantum architectures based on neutral atoms have gained significant attention in recent years as specialized computational machines due to their ability to directly encode the independent set constraint on graphs, exploiting the Rydberg blockade mechanism. In this work, we address the Drone Delivery Packing Problem via a hybrid quantum-classical framework leveraging a neutral-atom quantum processing unit (QPU). We reformulate the optimization task as a graph-partitioning problem based on the independent sets (ISs) of a scheduling graph that encodes delivery incompatibilities. Each partition corresponds to deliveries assigned to a single drone, with the objective of minimizing the total number of partitions. While the ISs represent time-feasible schedules, battery-duration constraints are enforced through a classical post-processing routine. This methodology enables the recovery of optimal delivery schedules, provided a sufficient number of samples is collected from the QPU to resolve the solution space. We benchmark the hybrid workflow through numerical emulations and demonstrate its effectiveness on Pasqal's Fresnel QPU, reporting hardware experiments with configurations of up to 100 atoms.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15487v1",
        "authors": [
          "Sara Tarquini",
          "Matteo Vandelli",
          "Francesco Ferrari",
          "Daniele Dragoni",
          "Francesco Tudisco"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Drone Delivery Packing Problem",
        "Framework",
        "Battery",
        "Drone",
        "QPU",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.155860"
    },
    {
      "id": "arxiv-2602.15452v1",
      "title": "Nonlocality without entanglement in exclusion of quantum states",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15452v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the task of quantum state exclusion, focusing on antidistinguishability and its generalization to $x$-antidistinguishability, under global measurements and local operations with classical communication (LOCC). We also introduce weak and strong notions of antidistinguiahbaility ($x$-antidistinguishability) depending on whether all states or all $x$-tuples are exhaustively eliminated. Our results reveal striking differences between state exclusion and the more familiar task of state discrimination. In particular, we show that LOCC antidistinguishability of multipartite product states is symmetric with respect to the initiating party but this symmetry breaks down for higher-order $x$-antidistinguishability. Most notably, we establish a manifestation of \\emph{nonlocality without entanglement} in the context of state exclusion: we prove that three bipartite product states can be globally antidistinguishable while failing to be LOCC antidistinguishable, demonstrating that three is the minimal number of states required for this phenomenon. We further extend this separation to $2$-antidistinguishability and present example exhibiting the same type of nonlocality. At last, we provide an antidistinguishable tripartite product states that are not LOCC antidistinguishable across any bipartition, which ensures the phenomenon of \\emph{genuine nonlocality without entanglement} in this framework.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15452v1",
        "authors": [
          "Satyaki Manna",
          "Anandamay Das Bhowmik"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "LOCC",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.156386"
    },
    {
      "id": "arxiv-2602.15451v1",
      "title": "Molecular Design beyond Training Data with Novel Extended Objective Functionals of Generative AI Models Driven by Quantum Annealing Computer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15451v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Deep generative modeling to stochastically design small molecules is an emerging technology for accelerating drug discovery and development. However, one major issue in molecular generative models is their lower frequency of drug-like compounds. To resolve this problem, we developed a novel framework for optimization of deep generative models integrated with a D-Wave quantum annealing computer, where our Neural Hash Function (NHF) presented herein is used both as the regularization and binarization schemes simultaneously, of which the latter is for transformation between continuous and discrete signals of the classical and quantum neural networks, respectively, in the error evaluation (i.e., objective) function. The compounds generated via the quantum-annealing generative models exhibited higher quality in both validity and drug-likeness than those generated via the fully-classical models, and was further indicated to exceed even the training data in terms of drug-likeness features, without any restraints and conditions to deliberately induce such an optimization. These results indicated an advantage of quantum annealing to aim at a stochastic generator integrated with our novel neural network architectures, for the extended performance of feature space sampling and extraction of characteristic features in drug design.",
        "keywords": [
          "q-bio.QM",
          "cs.AI",
          "cs.LG",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15451v1",
        "authors": [
          "Hayato Kunugi",
          "Mohsen Rahmani",
          "Yosuke Iyama",
          "Yutaro Hirono",
          "Akira Suma"
        ],
        "arxiv_categories": [
          "q-bio.QM",
          "cs.AI",
          "cs.LG",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Novel Extended Objective Functionals",
        "Quantum Annealing Computer Deep",
        "Neural Hash Function",
        "Molecular Design",
        "Neural Network",
        "Training Data",
        "Models Driven",
        "Framework",
        "NSF",
        "Act",
        "NHF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.156849"
    },
    {
      "id": "arxiv-2602.15430v1",
      "title": "Non-Markovian environment induced Schrödinger cat state transfer in an optical Newton's cradle",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15430v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this manuscript, we study the Schrödinger cat state transfer in a quantum optical version of Newton's cradle in non-Markovian environment. Based on a non-Markovian master equation, we show that the cat state can be transferred purely through the memory effect of the non-Markovian common environment, even without any direct couplings between neighbor cavities. The mechanism of the environment induced cat state transfer is analyzed both analytically and numerically to demonstrate that the transfer is a unique phenomenon in non-Markovian regime. From this example, the non-Markovian environment is shown to be qualitatively different from the Markovian environment reflected by the finite versus zero residue coherence. Besides, we also show the influence of environmental parameters are crucial for the transfer. We hope the cat state transfer studied in this work may shed more light on the fundamental difference between non-Markovian and Markovian environments.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15430v1",
        "authors": [
          "Xinyu Zhao",
          "Yan Xia"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "WTO",
        "NSF",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.157500"
    },
    {
      "id": "arxiv-2602.15402v1",
      "title": "Non-Markovian environment induced chaos in optomechanical system",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15402v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In traditional research, chaos is frequently accompanied by non-linearity, which typically stems from non-linear interactions or external driving forces. However, in this paper, we present the chaotic behavior that is completely attributed to the non-linear back-reaction of non-Markovian environment. To be specific, we derive the dynamical equations of an optomechanical system and demonstrate that the non-linearity (cause of chaos) in the equations arises entirely from the time-domain convolutions (TDCs) induced by non-Markovian corrections. Under Markovian conditions, these TDCs are reduced into constants, thereby losing the nonlinearity and ultimately leading to the disappearance of chaos. Furthermore, we also observe chaos generation in the absence of optomechanical couplings, which further confirms that the non-Markovian effect is the sole inducement of chaos and the environmental parameters play important roles in the generation of chaos. We hope these results may open a new direction to investigate chaotic dynamics purely caused by non-Markovian environments.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15402v1",
        "authors": [
          "You-Lin Xiang",
          "Xinyu Zhao",
          "Yan Xia"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Under Markovian",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.157870"
    },
    {
      "id": "arxiv-2602.15389v1",
      "title": "Giant atoms coupled to waveguide: Continuous coupling and multiple excitations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15389v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose a stochastic Schrödinger equation (SSE) approach to investigate the dynamics of giant atoms coupled to a waveguide, addressing two critical gaps in existing research, namely insufficient exploration on continuous coupling and multiple excitations. A key finding is that continuous coupling, unlike discrete coupling at finite points, breaks the constant phase difference condition, thereby weakening the interference effects in giant atom-waveguide systems. In addition, a key technical advantage of the SSE approach is that auto- and cross-correlation functions can directly reflect the complex photon emission/absorption processes and time-delay effects in giant atom-waveguide systems. Moreover, the SSE approach also naturally handles multiple excitations, without increasing equation complexity as the number of excitations grows. This feature enables the investigation of multi-excitation initial states of the waveguide, such as thermal and squeezed initial states. Overall, our approach provides a powerful tool for studying the dynamics of giant atoms coupled to waveguide, particularly for continuous coupling and multi-excitation systems.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15389v1",
        "authors": [
          "Shiying Lin",
          "Xinyu Zhao",
          "Yan Xia"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SSE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.158468"
    },
    {
      "id": "arxiv-2602.15324v1",
      "title": "Realizing a Universal Quantum Gate Set via Double-Braiding of SU(2)k Anyon Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15324v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We systematically investigate the implementation of a universal gate set via double-braiding within SU(2)k anyon models. The explicit form of the double elementary braiding matrices (DEBMs) in these models are derived from the F-matrices and R-symbols obtained via the q-deformed representation theory of SU(2). Using these EBMs, standard single-qubit gates are synthesized up to a global phase by a Genetic Algorithm-enhanced Solovay-Kitaev Algorithm (GA-enhanced SKA), achieving the accuracy required for fault-tolerant quantum computation with only 2-level decomposition. For two-qubit entangling gates, Genetic Algorithm (GA) yields braidwords of 30 braiding operations that approximate the local equivalence class [CNOT]. Theoretically, we demonstrate that performing double-braiding in a three-anyon (six-anyon) encoding of single-qubit (two-qubit) is topologically equivalent to a protocol requiring the physical manipulation of only one (three) anyons to execute arbitrary braids. Our numerical results provide strong evidence that double-braiding in SU(2)k anyons models is capable of universal quantum computation. Moreover, the proposed protocol offers a potential new strategy for significantly reducing the number of non-Abelian anyons that need to be physically manipulated in future braiding-based topological quantum computations (TQC).",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15324v1",
        "authors": [
          "Jiangwei Long",
          "Zihui Liu",
          "Yizhi Li",
          "Jianxin Zhong",
          "Lijun Meng"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universal Quantum Gate Set",
        "Genetic Algorithm",
        "Kitaev Algorithm",
        "Anyon Models We",
        "Standard",
        "Protocol",
        "CNOT",
        "SKA",
        "TQC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:11.158854"
    },
    {
      "id": "arxiv-2602.15623v1",
      "title": "Passive Imaging with Ambient Noise Under Wave Speed Mismatch: Mathematical Analysis and Wave Speed Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15623v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It is known that waves generated by ambient noise sources and recorded by passive receivers can be used to image the reflectivities of an unknown medium. However, reconstructing the reflectivity of the medium from partial boundary measurements remains a challenging problem, particularly when the background wave speed is unknown. In this paper, we investigate passive correlation-based imaging in the daylight configuration, where uncontrolled noise sources illuminate the medium and only ambient fields are recorded by a sensor array. We first analyze daylight migration for a point reflector embedded in a homogeneous background. By introducing a searching wave speed into the migration functional, we derive an explicit characterization of the deterministic shift and defocusing effects induced by wave-speed mismatch. We show that the maximum of the envelope of the resulting functional provides a reliable estimator of the true wave speed. We then extend the analysis to a random medium with correlation length smaller than the wavelength. Leveraging the shift formula obtained in the homogeneous case, we introduce a virtual guide star that remains fixed under migration with different searching speeds. This property enables an effective wave-speed estimation strategy based on spatial averaging around the virtual guide star. For both homogeneous and random media, we establish resolution analyses for the proposed wave-speed estimators. Numerical experiments are conducted to validate the theoretical result.",
        "keywords": [
          "eess.SP",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15623v1",
        "authors": [
          "Zetao Fei",
          "Josselin Garnier"
        ],
        "arxiv_categories": [
          "eess.SP",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ambient Noise Under Wave",
        "Wave Speed Estimation It",
        "Mathematical Analysis",
        "Passive Imaging",
        "Speed Mismatch",
        "NIST",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:16.625358"
    },
    {
      "id": "arxiv-2602.15522v1",
      "title": "Universality of the Hall conductivity for a weakly interacting magnetic fermionic gas in the Hartree-Fock approximation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15522v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider a two-dimensional gas of interacting fermions in presence of an external constant magnetic field: the system is extended and homogeneous, and thus assumed to be invariant under magnetic translations. Working within the Hartree-Fock approximation, we analyze the system directly in the thermodynamic limit by solving a self-consistent fixed-point equation for the one-particle density matrix. We prove that, provided that the interactions among fermions are sufficiently weak, there exists a unique one-particle density matrix that solves the self-consistency condition. By choosing the Fermi-Dirac distribution as the function in the fixed-point equation, this approach can describe both positive and zero-temperature cases. At zero temperature and when the chemical potential of the non-interacting system lies in a spectral gap of the free Landau operator, our self-consistent solution is an orthogonal projection (an \"interacting\" effective Fermi projection). We prove that its integrated density of states varies linearly with the external magnetic field, provided the interaction is weak enough: the slope of this variation is quantized and independent of the interaction. According to the Středa formula, this can be seen as yet another expression of the universality of the quantum Hall effect in weakly interacting systems, at least within the Hartree-Fock approximation.",
        "keywords": [
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15522v1",
        "authors": [
          "Horia D. Cornean",
          "Emanuela Laura Giacomelli",
          "Domenico Monaco",
          "Mikkel Hviid Thorn"
        ],
        "arxiv_categories": [
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:16.626431"
    },
    {
      "id": "arxiv-2602.15279v1",
      "title": "On the efficiency of pairwise Hamiltonian control to desynchronize the higher-order Kuramoto model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15279v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Synchronization of coupled oscillators is observed in many natural and engineered systems and emerges due to the interactions within the system. It can be both beneficial, e.g., in power grids, and harmful, e.g., in epileptic seizures. In the latter case, efficient control methods to desynchronize the systems are crucial. Recent studies have shown that interactions are not always pairwise, but higher-order, i.e., many-body, and this greatly affects the dynamics. For instance, higher-order interactions increase the linear stability of synchronized states but simultaneously shrink their attraction basin, with potentially opposite effects on control methods. Here, we use a minimally invasive pairwise control based on Hamiltonian control theory, and investigate its efficiency on phase oscillators with higher-order interactions. We show that, if the initial phases are close to the synchronized state, higher-order interactions make desynchronization more difficult to achieve. Otherwise, a non-monotonic effect appears: intermediate strengths of higher-order interactions impede desynchronization while larger ones facilitate it. In all cases, the control can desynchronize the system with a sufficient number of controlled nodes and intensity.",
        "keywords": [
          "nlin.AO",
          "math-ph",
          "math.DS",
          "math.OC",
          "nlin.PS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15279v1",
        "authors": [
          "Martin Moriamé",
          "Riccardo Muolo",
          "Timoteo Carletti",
          "Maxime Lucas"
        ],
        "arxiv_categories": [
          "nlin.AO",
          "math-ph",
          "math.DS",
          "math.OC",
          "nlin.PS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:16.626853"
    },
    {
      "id": "arxiv-2602.15699v1",
      "title": "Understanding Classical Decomposability of Inequality Measures: A Graphical Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15699v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper's objective is pedagogical and interpretive. Namely, it gives a simple geometric analysis of classical (by which I mean population-share-weighted or income-share-weighted) inequality decomposability in the simplest nontrivial setting of three individuals. Income distributions in this case can be represented as points on the two-dimensional income-share simplex. In this representation, classical decomposability translates into concrete geometric restrictions of within- and between-group components. The geometric framework makes it possible to localize and compare violations of decomposability across inequality measures. The analysis is applied to the Mean Log Deviation, the Gini coefficient, the coefficient of variation, and the Theil index.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15699v1",
        "authors": [
          "Tatiana Komarova"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Understanding Classical Decomposability",
        "Inequality Measures",
        "Mean Log Deviation",
        "Framework",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.038567"
    },
    {
      "id": "arxiv-2602.15690v1",
      "title": "Income Inequality and Economic Growth: A Meta-Analytic Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15690v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The empirical literature on the relationship between income inequality and economic growth has produced highly heterogeneous and often conflicting results. This paper investigates the sources of this heterogeneity using a meta-analytic approach that systematically combines and analyzes evidence from relevant studies published between 1994 and 2025. We find an economically small but statistically significant negative average effect of income inequality on subsequent economic growth, together with strong evidence of substantial heterogeneity and selective publication based on statistical significance, but no evidence of systematic directional bias. To explain the observed heterogeneity, we estimate a meta-regression. The results indicate that both real-world characteristics and research design choices shape reported effect sizes. In particular, inequality measured net of taxes and transfers is associated with more negative growth effects, and the adverse impact of inequality is weaker - or even reversed - in high-income economies relative to developing countries. Methodological choices also matter: cross-sectional studies tend to report more negative estimates, while fixed-effects, instrumental-variable, and GMM estimators are associated with more positive estimates in panel settings.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15690v1",
        "authors": [
          "Lisa Cpretti",
          "Lorenzo Tonni"
        ],
        "arxiv_categories": [
          "econ.EM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Income Inequality",
        "Economic Growth",
        "Meta",
        "NSF",
        "GMM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.039018"
    },
    {
      "id": "arxiv-2602.15686v1",
      "title": "Minimizing Volatility: Optimal Adjustment with Evolving Feasibility Constraints",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15686v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Minimizing volatility and adjustment costs is of central importance in many economic environments, yet it is often complicated by evolving feasibility constraints. We study a decision maker who repeatedly selects an action from a stochastically evolving interval of feasible actions in order to minimize either average adjustment costs or variance. We show that for strictly convex adjustment costs (such as quadratic variation), the optimal decision rule is a reference rule in which the decision maker minimizes the distance to a target action. In general, the optimal target depends both on the previous action and the expectation of future constraints; but for the special case where the constraints follow a random walk, the optimal mechanism is to simply target the previous action. If the decision maker minimizes variance, the optimal policy is also a reference rule, but the target is a constant, which is not necessarily equal to the long-term average action. Compared to mid-point heuristics, these optimal rules may substantially reduce quadratic variation and variance, in natural environments by $50\\%$ or more. Applied to stock market auctions, our results provide an explanation for the wide-spread use of reference price rules. We also apply our results to bilateral trade in over-the-counter markets, capacity planning in supply chains, and positioning in political agenda setting.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15686v1",
        "authors": [
          "Simon Jantschgi",
          "Heinrich H. Nax",
          "Bary S. R. Pradelski",
          "Marek Pycia"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Evolving Feasibility Constraints Minimizing",
        "Minimizing Volatility",
        "Optimal Adjustment",
        "Policy",
        "WHO",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.039513"
    },
    {
      "id": "arxiv-2602.15674v1",
      "title": "Complexity and Misspecification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15674v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose a tractable unified framework to study the evolution and interaction of model-misspecification concerns and complexity aversion in repeated decision problems. This aims to capture environments where decision makers worry that their models are misspecified while also disliking overly complex models. We find that pathological cycles caused by endogenous concerns for misspecification can be eliminated by penalizing complex models and show that such preferences for simplicity tend to favor safety, which can enhance welfare in the long run. We use our framework to provide new microfoundations for pervasive empirical phenomena such as \"scale heterogeneity\" in discrete-choice analysis, \"probability neglect\" in behavioral economics, and \"home bias\" in international finance.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15674v1",
        "authors": [
          "Drew Fudenberg",
          "Florian Mudekereza"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Misspecification We",
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.039812"
    },
    {
      "id": "arxiv-2602.15607v1",
      "title": "Agent-based macroeconomics for the UK's Seventh Carbon Budget",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15607v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In June 2026, the UK government will set its carbon budget for the period 2038 to 2042, the seventh such carbon budget (CB7) since the Climate Change Act became law in 2008. For the first time, this carbon budget will be accompanied by a macroeconomic assessment of its impact on growth, employment, inflation and inequality. Researchers from the Institute of New Economic Thinking (INET) Oxford are working in partnership with the Department for Energy Security and Net Zero to deliver this assessment using our data-driven macroeconomic agent-based model (ABM). This extended abstract presents the work in progress towards this pioneering policymaking using our data-driven macroeconomic ABM. We are conducting our work in three work packages. By the time of the workshop, we hope to be able to present preliminary findings from the first two work packages. In WP1, we adapt an existing macro-ABM prototype and build a UK macroeconomic baseline. The main task for this is initialising the model with suitable UK household microdata. We present the options considered and the approach settled upon. In WP2, we conduct preliminary modelling that represents UK decarbonisation as an external shock to financial flows and technical coefficients. In order to present results in time to influence the June 2026 policy decision, this second work package exogenously forces the ABM to follow the CB7 green investment and associated technological change projections provided by the Climate Change Committee. Finally, we will implement more sophisticated social and technological learning packages in WP3, building our own projections of likely decarbonisation pathways that may diverge from UK government plans. For the workshop, we will present the progress of WP1 and WP2.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15607v1",
        "authors": [
          "Tom Youngman",
          "Tim Lennox",
          "M. Lopes Alves",
          "Pirta Palola",
          "Brendon Tankwa"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Climate Change Committee",
        "Seventh Carbon Budget In",
        "New Economic Thinking",
        "Climate Change Act",
        "Energy Security",
        "Institute",
        "Net Zero",
        "Policy",
        "INET",
        "EPA",
        "MIT",
        "ABM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.040450"
    },
    {
      "id": "arxiv-2602.15312v1",
      "title": "Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15312v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.",
        "keywords": [
          "cs.CL",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15312v1",
        "authors": [
          "Stephan Ludwig",
          "Peter J. Danaher",
          "Xiaohao Yang",
          "Yu-Ting Lin",
          "Ehsan Abedin"
        ],
        "arxiv_categories": [
          "cs.CL",
          "econ.EM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Evaluation Measurement Accurately",
        "Large Language Model Approach",
        "Extracting Consumer Insight",
        "Amazon",
        "GPT-4",
        "BERT",
        "MIT",
        "GPT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:22.041145"
    },
    {
      "id": "arxiv-2602.15289v1",
      "title": "A Projection Approach to Nonparametric Significance and Conditional Independence Testing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15289v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper develops a novel nonparametric significance test based on a tailored nonparametric-type projected weighting function that exhibits appealing theoretical and numerical properties. We derive the asymptotic properties of the proposed test and show that it can detect local alternatives at the parametric rate. Using the nonparametric orthogonal projection, we construct a computationally convenient multiplier bootstrap to obtain critical values from the case-dependent asymptotic null distribution. Compared with the existing literature, our approach overcomes the need for a stronger compact support assumption on the density of covariates arising from random denominators. We also extend the tailor-made projection procedure to test the conditional independence assumption. The simulation experiments further illustrate the advantages of our proposed method in testing significance and conditional independence in finite samples.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15289v1",
        "authors": [
          "Xiaojun Song",
          "Jichao Yuan"
        ],
        "arxiv_categories": [
          "econ.EM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Nonparametric Significance",
        "Projection Approach",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-18T13:59:22.041553"
    },
    {
      "id": "arxiv-2602.15385v1",
      "title": "From Chain-Ladder to Individual Claims Reserving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15385v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.",
        "keywords": [
          "stat.AP",
          "q-fin.RM",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15385v1",
        "authors": [
          "Ronald Richman",
          "Mario V. Wüthrich"
        ],
        "arxiv_categories": [
          "stat.AP",
          "q-fin.RM",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "From Chain",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:30.398866"
    },
    {
      "id": "arxiv-2602.15731v1",
      "title": "Generalised Exponential Kernels for Nonparametric Density Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15731v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces a novel kernel density estimator (KDE) based on the generalised exponential (GE) distribution, designed specifically for positive continuous data. The proposed GE KDE offers a mathematically tractable form that avoids the use of special functions, for instance, distinguishing it from the widely used gamma KDE, which relies on the gamma function. Despite its simpler form, the GE KDE maintains similar flexibility and shape characteristics, aligning with distributions such as the gamma, which are known for their effectiveness in modelling positive data. We derive the asymptotic bias and variance of the proposed kernel density estimator, and formally demonstrate the order of magnitude of the remaining terms in these expressions. We also propose a second GE KDE, for which we are able to show that it achieves the optimal mean integrated squared error, something that is difficult to establish for the former. Through numerical experiments involving simulated and real data sets, we show that GE KDEs can be an important alternative and competitive to existing KDEs.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15731v1",
        "authors": [
          "Laura M. Craig",
          "Wagner Barreto-Souza"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalised Exponential Kernels",
        "KDE",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.211421"
    },
    {
      "id": "arxiv-2602.15697v1",
      "title": "Reproducibility and Statistical Methodology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15697v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In 2015 the Open Science Collaboration (OSC) (Nosek et al 2015) published a highly influential paper which claimed that a large fraction of published results in the psychological sciences were not reproducible. In this article we review this claim from several points of view. We first offer an extended analysis of the methods used in that study. We show that the OSC methodology induces a bias that is able by itself to explain the discrepancy between the OSC estimates of reproducibility and other more optimistic estimates made by similar studies. The article also offers a more general literature review and discussion of reproducibility in experimental science. We argue, for both scientific and ethical reasons, that a considered balance of false positive and false negative rates is preferable to a single-minded concentration on false positive rates alone.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15697v1",
        "authors": [
          "Anthony Almudevar",
          "Jacob Almudevar"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Open Science Collaboration",
        "Statistical Methodology In",
        "EPA",
        "OSC",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.211669"
    },
    {
      "id": "arxiv-2602.15679v1",
      "title": "Safe hypotheses testing with application to order restricted inference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15679v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Hypothesis tests under order restrictions arise in a wide range of scientific applications. By exploiting inequality constraints, such tests can achieve substantial gains in power and interpretability. However, these gains come at a cost: when the imposed constraints are misspecified, the resulting inferences may be misleading or even invalid, and Type III errors may occur, i.e., the null hypothesis may be rejected when neither the null nor the alternative is true. To address this problem, this paper introduces safe tests. Heuristically, a safe test is a testing procedure that is asymptotically free of Type III errors. The proposed test is accompanied by a certificate of validity, a pre--test that assesses whether the original hypotheses are consistent with the data, thereby ensuring that the null hypothesis is rejected only when warranted, enabling principled inference without risk of systematic error. Although the development in this paper focus on testing problems in order--restricted inference, the underlying ideas are more broadly applicable. The proposed methodology is evaluated through simulation studies and the analysis of well--known illustrative data examples, demonstrating strong protection against Type III errors while maintaining power comparable to standard procedures.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15679v1",
        "authors": [
          "Ori Davidov"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "III",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.212033"
    },
    {
      "id": "arxiv-2602.15673v1",
      "title": "Leicester's Tale: Another Perspective on the EPL 2015/16 Through Expected Goals (xG) Modelling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15673v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Probabilistic modeling is an effective tool for evaluating team performance and predicting outcomes in sports. However, an important question that hasn't been fully explored is whether these models can reliably reflect actual performance while assigning meaningful probabilities to rare results that differ greatly from expectations. In this study, we create an inference-based probabilistic framework built on expected goals (xG). This framework converts shot-level event data into season-level simulations of points, rankings, and outcome probabilities. Using the English Premier League 2015/16 season as a data, we demonstrate that the framework captures the overall structure of the league table. It correctly identifies the top-four contenders and relegation candidates while explaining a significant portion of the variance in final points and ranks. In a full-season evaluation, the model assigns a low probability to extreme outcomes, particularly Leicester City's historic title win, which stands out as a statistical anomaly. We then look at the ex ante inferential and early-diagnostic role of xG by only using mid-season information. With first-half data, we simulate the rest of the season and show that teams with stronger mid-season xG profiles tend to earn more points in the second half, even after considering their current league position. In this mid-season assessment, Leicester City ranks among the top teams by xG and is given a small but noteworthy chance of winning the league. This suggests that their ultimate success was unlikely but not entirely detached from their actual performance. Our analysis indicates that expected goals models work best as probabilistic baselines for analysis and early-warning diagnostics, rather than as certain predictors of rare season outcomes.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15673v1",
        "authors": [
          "Sheikh Badar Ud Din Tahir",
          "Leonardo Egidi",
          "Nicola Torelli"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Modelling Probabilistic",
        "English Premier League",
        "Through Expected Goals",
        "Another Perspective",
        "Leicester City",
        "Framework",
        "EPL",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.212512"
    },
    {
      "id": "arxiv-2602.15581v1",
      "title": "Confidence as Forecast: A Decision-Theoretic Interpretation of Confidence Intervals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15581v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "What, if anything, should a frequentist say about a single realized confidence interval (CI) and its chance of having covered the parameter? Jerzy Neyman's original answer was to refuse any nondegenerate probability for coverage ex post and, instead, to \"state that the interval covers\". In this paper I argue that the usual frequentist machinery already supports a different reading. I treat the coverage event as a Bernoulli random variable, with the nominal level 1-alpha as its design-based success probability, and view \"confidence\" as a probability forecast for that Bernoulli outcome. Using strictly proper scoring rules, I show that 1-alpha is the unique optimal constant forecast for coverage, both before and after observing the data, and that it remains optimal post-trial in common unbounded, translation-invariant models with pivot-based CIs. When the design yields a theta-free statistic--such as the relative width of the interval in a finite-window uniform model--the conditional coverage given that statistic provides a nonconstant, design-based refinement of 1-alpha that strictly improves predictive performance. Two thought experiments, a Monty Hall-style shell game and the \"lost submarine\" example of Morey et al. (2016), illustrate how this perspective resolves familiar interpretational puzzles about CIs without appealing to priors or single-case subjective degrees of belief. I conclude with simple \"what to do when you see an interval\" guidance for applied work and some implications for teaching confidence intervals as tools for forecasting long-run coverage. Keywords: Confidence intervals, coverage probability, proper scoring rules, probabilistic forecasting, frequentist inference Disclaimer: The findings and conclusions in this report are those of the author and do not necessarily represent the official position of the Centers for Disease Control and Prevention",
        "keywords": [
          "stat.OT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15581v1",
        "authors": [
          "Scott Lee"
        ],
        "arxiv_categories": [
          "stat.OT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Confidence Intervals What",
        "Disease Control",
        "Jerzy Neyman",
        "Monty Hall",
        "Wind",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.213094"
    },
    {
      "id": "arxiv-2602.15562v1",
      "title": "Either a Confidence Interval Covers, or It Doesn't (Or Does It?): A Model-Based View of Ex-Post Coverage Probability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15562v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In Neyman's original formulation, a 1-alpha confidence interval procedure is justified by its long-run coverage properties, and a single realized interval is to be described only by the slogan that it either covers the parameter or it does not. On this view, post-data probability statements about the coverage of an individual interval are taken to be conceptually out of bounds. In this paper, I present two kinds of arguments against treating that \"either-or\" reading as the only legitimate interpretation of confidence. The first is informal, via a set of thought experiments in which the same joint probability model is used to compute both forward-looking and backward-looking probabilities for occurred-but-unobserved events. The second is more formal, recasting the standard confidence-interval construction in terms of infinite sequences of trials and their associated 0/1 coverage indicators. In that representation, the design-level coverage probability 1-alpha and the degenerate conditional probabilities given the full data appear simply as different conditioning levels of the same model. I argue that a strict behavioristic reading that privileges only the latter is in tension with the very mathematical machinery used to define long-run error rates. I then sketch an alternative view of confidence as a predictive probability (or forecast) about the coverage indicator, together with a simple normative rule for when intermediate probabilities for single coverage events should be allowed. Keywords: confidence intervals; coverage probability; frequentist inference; single-case probability; predictive probability; Neyman. Disclaimer: The findings and conclusions in this report are those of the author and do not necessarily represent the official position of the Centers for Disease Control and Prevention.",
        "keywords": [
          "stat.OT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15562v1",
        "authors": [
          "Scott Lee"
        ],
        "arxiv_categories": [
          "stat.OT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Post Coverage Probability In",
        "Confidence Interval Covers",
        "Disease Control",
        "Or Does It",
        "Based View",
        "Standard",
        "It Doesn",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.213579"
    },
    {
      "id": "arxiv-2602.15503v1",
      "title": "Approximation Theory for Lipschitz Continuous Transformers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15503v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Stability and robustness are critical for deploying Transformers in safety-sensitive settings. A principled way to enforce such behavior is to constrain the model's Lipschitz constant. However, approximation-theoretic guarantees for architectures that explicitly preserve Lipschitz continuity have yet to be established. In this work, we bridge this gap by introducing a class of gradient-descent-type in-context Transformers that are Lipschitz-continuous by construction. We realize both MLP and attention blocks as explicit Euler steps of negative gradient flows, ensuring inherent stability without sacrificing expressivity. We prove a universal approximation theorem for this class within a Lipschitz-constrained function space. Crucially, our analysis adopts a measure-theoretic formalism, interpreting Transformers as operators on probability measures, to yield approximation guarantees independent of token count. These results provide a rigorous theoretical foundation for the design of robust, Lipschitz continuous Transformer architectures.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15503v1",
        "authors": [
          "Takashi Furuya",
          "Davide Murari",
          "Carola-Bibiane Schönlieb"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lipschitz Continuous Transformers Stability",
        "Transformer",
        "MLP",
        "NSF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.213920"
    },
    {
      "id": "arxiv-2602.15496v1",
      "title": "Confidence Distributions for FIC scores",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15496v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "When using the Focused Information Criterion (FIC) for assessing and ranking candidate models with respect to how well they do for a given estimation task, it is customary to produce a so-called FIC plot. This plot has the different point estimates along the y-axis and the root-FIC scores on the x-axis, these being the estimated root-mean-square scores. In this paper we address the estimation uncertainty involved in each of the points of such a FIC plot. This needs careful assessment of each of the estimators from the candidate models, taking also modelling bias into account, along with the relative precision of the associated estimated mean squared error quantities. We use confidence distributions for these endeavours. This leads to fruitful CD-FIC plots, helping the statistician to judge to what extent the seemingly best models really are better than other models, etc. These efforts also lead to two further developments. The first is a new tool for model selection, which we call the quantile FIC, which helps overcome certain difficulties associated with the usual FIC procedures, related to somewhat arbitrary schemes for handling estimated squared biases. A particular case is the median-FIC. The second development is to form model averaged estimators with fruitful weights determined by the relative sizes of the median- and quantile-FIC scores. And Mrs. Jones is pregnant.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15496v1",
        "authors": [
          "Céline Cunen",
          "Nils Lid Hjort"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Focused Information Criterion",
        "Confidence Distributions",
        "And Mrs",
        "FIC",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.214262"
    },
    {
      "id": "arxiv-2602.15438v1",
      "title": "Logit Distance Bounds Representational Similarity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15438v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogous conclusion holds approximately when the distributions are close instead of equal. Building on the observation of Nielsen et al. (2025) that closeness in KL divergence need not imply high linear representational similarity, we study a distributional distance based on logit differences and show that closeness in this distance does yield linear similarity guarantees. Specifically, we define a representational dissimilarity measure based on the models' identifiability class and prove that it is bounded by the logit distance. We further show that, when model probabilities are bounded away from zero, KL divergence upper-bounds logit distance; yet the resulting bound fails to provide nontrivial control in practice. As a consequence, KL-based distillation can match a teacher's predictions while failing to preserve linear representational properties, such as linear-probe recoverability of human-interpretable concepts. In distillation experiments on synthetic and image datasets, logit-distance distillation yields students with higher linear representational similarity and better preservation of the teacher's linearly recoverable concepts.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15438v1",
        "authors": [
          "Beatrix M. B. Nielsen",
          "Emanuele Marconato",
          "Luigi Gresele",
          "Andrea Dittadi",
          "Simon Buchholz"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Logit Distance Bounds Representational",
        "Similarity For",
        "DOE",
        "NSF",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.214606"
    },
    {
      "id": "arxiv-2602.15429v1",
      "title": "Deep description of static and dynamic network ties in Honduran villages",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15429v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We examine static and dynamic social network structure in 176 villages within the Copan Department of Honduras across two data waves (2016, 2019), using detailed data on multiplex networks for 20,232 individuals enrolled in a longitudinal survey. These networks capture friendship, health advice, financial help, and adversarial relationships, allowing us to show how cooperation and conflict jointly shape social structure. Using node-level network measures derived from near-census sociocentric village networks, we leverage mixed-effects zero-inflated negative binomial models to assess the influence of individual attributes, such as gender, marital status, education, religion, and indigenous status, and of village characteristics, on the dynamics of social networks over time. We complement these node-level models with dyadic assortativity (odds-ratio-based homophily) and community-level measures to describe how sorting by key attributes differs across network types and between waves. Our results demonstrate significant assortativity based on gender and religion, particularly within health and financial networks. Across networks, gender and religion exhibit the most consistent assortative mixing. Additionally, community-level assortativity metrics indicate that educational and financial factors increasingly influence social ties over time. Our findings provide insights into how personal attributes and community dynamics interact to shape network formation and socio-economic relationships in rural settings over time.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15429v1",
        "authors": [
          "Marios Papamichalis",
          "Nikolaos Nakis",
          "Nicholas A. Christakis"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Copan Department",
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.214965"
    },
    {
      "id": "arxiv-2602.15387v1",
      "title": "Bayesian Nonparametrics for Gene-Gene and Gene-Environment Interactions in Case-Control Studies: A Synthesis and Extension",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15387v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Gene-gene and gene-environment interactions are widely believed to play significant roles in explaining the variability of complex traits. While substantial research exists in this area, a comprehensive statistical framework that addresses multiple sources of uncertainty simultaneously remains lacking. In this article, we synthesize and propose extension of a novel class of Bayesian nonparametric approaches that account for interactions among genes, loci, and environmental factors while accommodating uncertainty about population substructure. Our contribution is threefold: (1) We provide a unified exposition of hierarchical Bayesian models driven by Dirichlet processes for genetic interactions, clarifying their conceptual advantages over traditional regression approaches; (2) We shed light on new computational strategies that combine transformation-based MCMC with parallel processing for scalable inference; and (3) We present enhanced hypothesis testing procedures for identifying disease-predisposing loci.Through applications to myocardial infarction data, we demonstrate how these methods offer biological insights not readily obtainable from standard approaches. Our synthesis highlights the advantages of Bayesian nonparametric thinking in genetic epidemiology while providing practical guidance for implementation.",
        "keywords": [
          "stat.ME",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15387v1",
        "authors": [
          "Durba Bhattacharya",
          "Sourabh Bhattacharya"
        ],
        "arxiv_categories": [
          "stat.ME",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Environment Interactions",
        "Bayesian Nonparametrics",
        "Control Studies",
        "Extension Gene",
        "Framework",
        "Standard",
        "MCMC",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.215337"
    },
    {
      "id": "arxiv-2602.15374v1",
      "title": "Joint Modeling of Longitudinal EHR Data with Shared Random Effects for Informative Visiting and Observation Processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15374v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Longitudinal electronic health record (EHR) data offer opportunities to study biomarker trajectories; however, association estimates-the primary inferential target-from standard models designed for regular observation times may be biased by a two-stage hierarchical missingness mechanism. The first stage is the visiting process (informative presence), where encounters occur at irregular times driven by patient health status; the second is the observation process (informative observation), where biomarkers are selectively measured during visits. To address these mechanisms, we propose a unified semiparametric joint modeling framework that simultaneously characterizes the visiting, biomarker observation, and longitudinal outcome processes. Central to this framework is a shared subject-specific Gaussian latent variable that captures unmeasured frailty and induces dependence across all components. We develop a three-stage estimation procedure and establish the consistency and asymptotic normality of our estimators. We also introduce a sequential procedure that imputes missing biomarkers prior to adjusting for irregular visiting and examine its performance. Simulation results demonstrate that our method yields unbiased estimates under this mechanism, whereas existing approaches can be substantially biased; notably, methods adjusting only for irregular visiting may exhibit even greater bias than those ignoring both mechanisms. We apply our framework to data from the All of Us Research Program to investigate associations between neighborhood-level socioeconomic status indicators and six blood-based biomarker trajectories, providing a robust tool for outpatient settings where irregular monitoring and selective measurement are prevalent.",
        "keywords": [
          "stat.ME",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15374v1",
        "authors": [
          "Cheng-Han Yang",
          "Xu Shi",
          "Bhramar Mukherjee"
        ],
        "arxiv_categories": [
          "stat.ME",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Observation Processes Longitudinal",
        "Shared Random Effects",
        "Informative Visiting",
        "Us Research Program",
        "Joint Modeling",
        "Framework",
        "Standard",
        "EHR",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.215767"
    },
    {
      "id": "arxiv-2602.15327v1",
      "title": "Prescriptive Scaling Reveals the Evolution of Language Model Capabilities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15327v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the field evolves? Using large scale observational evaluations with 5k observational and 2k newly sampled data on model performance, we estimate capability boundaries, high conditional quantiles of benchmark scores as a function of log pre training FLOPs, via smoothed quantile regression with a monotone, saturating sigmoid parameterization. We validate the temporal reliability by fitting on earlier model generations and evaluating on later releases. Across various tasks, the estimated boundaries are mostly stable, with the exception of math reasoning that exhibits a consistently advancing boundary over time. We then extend our approach to analyze task dependent saturation and to probe contamination related shifts on math reasoning tasks. Finally, we introduce an efficient algorithm that recovers near full data frontiers using roughly 20% of evaluation budget. Together, our work releases the Proteus 2k, the latest model performance evaluation dataset, and introduces a practical methodology for translating compute budgets into reliable performance expectations and for monitoring when capability boundaries shift across time.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CL",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15327v1",
        "authors": [
          "Hanlin Zhang",
          "Jikai Jin",
          "Vasilis Syrgkanis",
          "Sham Kakade"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Language Model Capabilities For",
        "Prescriptive Scaling Reveals",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.216074"
    },
    {
      "id": "arxiv-2602.15319v1",
      "title": "Bayesian Inference for Joint Tail Risk in Paired Biomarkers via Archimedean Copulas with Restricted Jeffreys Priors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15319v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose a Bayesian copula-based framework to quantify clinically interpretable joint tail risks from paired continuous biomarkers. After converting each biomarker margin to rank-based pseudo-observations, we model dependence using one-parameter Archimedean copulas and focus on three probability-scale summaries at tail level $α$: the lower-tail joint risk $R_L(θ)=C_θ(α,α)$, the upper-tail joint risk $R_U(θ)=2α-1+C_θ(1-α,1-α)$, and the conditional lower-tail risk $R_C(θ)=R_L(θ)/α$. Uncertainty is quantified via a restricted Jeffreys prior on the copula parameter and grid-based posterior approximation, which induces an exact posterior for each tail-risk functional. In simulations from Clayton and Gumbel copulas across multiple dependence strengths, posterior credible intervals achieve near-nominal coverage for $R_L$, $R_U$, and $R_C$. We then analyze NHANES 2017--2018 fasting glucose (GLU) and HbA1c (GHB) ($n=2887$) at $α=0.05$, obtaining tight posterior credible intervals for both the dependence parameter and induced tail risks. The results reveal markedly elevated extremal co-movement relative to independence; under the Gumbel model, the posterior mean joint upper-tail risk is $R_U(α)=0.0286$, approximately $11.46\\times$ the independence benchmark $α^2=0.0025$. Overall, the proposed approach provides a principled, dependence-aware method for reporting joint and conditional extremal-risk summaries with Bayesian uncertainty quantification in biomedical applications.",
        "keywords": [
          "stat.ME",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15319v1",
        "authors": [
          "Agnideep Aich",
          "Md. Monzur Murshed",
          "Sameera Hewage",
          "Ashit Baran Aich"
        ],
        "arxiv_categories": [
          "stat.ME",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Restricted Jeffreys Priors We",
        "Archimedean Copulas",
        "Bayesian Inference",
        "Paired Biomarkers",
        "Joint Tail Risk",
        "Framework",
        "NHANES",
        "GLU",
        "GHB",
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.216844"
    },
    {
      "id": "arxiv-2602.15315v1",
      "title": "Training-Free Zero-Shot Anomaly Detection in 3D Brain MRI with 2D Foundation Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15315v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Zero-shot anomaly detection (ZSAD) has gained increasing attention in medical imaging as a way to identify abnormalities without task-specific supervision, but most advances remain limited to 2D datasets. Extending ZSAD to 3D medical images has proven challenging, with existing methods relying on slice-wise features and vision-language models, which fail to capture volumetric structure. In this paper, we introduce a fully training-free framework for ZSAD in 3D brain MRI that constructs localized volumetric tokens by aggregating multi-axis slices processed by 2D foundation models. These 3D patch tokens restore cubic spatial context and integrate directly with distance-based, batch-level anomaly detection pipelines. The framework provides compact 3D representations that are practical to compute on standard GPUs and require no fine-tuning, prompts, or supervision. Our results show that training-free, batch-based ZSAD can be effectively extended from 2D encoders to full 3D MRI volumes, offering a simple and robust approach for volumetric anomaly detection.",
        "keywords": [
          "cs.CV",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15315v1",
        "authors": [
          "Tai Le-Gia",
          "Jaehyun Ahn"
        ],
        "arxiv_categories": [
          "cs.CV",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Foundation Models Zero",
        "Shot Anomaly Detection",
        "Free Zero",
        "Framework",
        "Standard",
        "ZSAD",
        "MIT",
        "MRI",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.217091"
    },
    {
      "id": "arxiv-2602.15306v1",
      "title": "Sparse Additive Model Pruning for Order-Based Causal Structure Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15306v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Causal structure learning, also known as causal discovery, aims to estimate causal relationships between variables as a form of a causal directed acyclic graph (DAG) from observational data. One of the major frameworks is the order-based approach that first estimates a topological order of the underlying DAG and then prunes spurious edges from the fully-connected DAG induced by the estimated topological order. Previous studies often focus on the former ordering step because it can dramatically reduce the search space of DAGs. In practice, the latter pruning step is equally crucial for ensuring both computational efficiency and estimation accuracy. Most existing methods employ a pruning technique based on generalized additive models and hypothesis testing, commonly known as CAM-pruning. However, this approach can be a computational bottleneck as it requires repeatedly fitting additive models for all variables. Furthermore, it may harm estimation quality due to multiple testing. To address these issues, we introduce a new pruning method based on sparse additive models, which enables direct pruning of redundant edges without relying on hypothesis testing. We propose an efficient algorithm for learning sparse additive models by combining the randomized tree embedding technique with group-wise sparse regression. Experimental results on both synthetic and real datasets demonstrated that our method is significantly faster than existing pruning methods while maintaining comparable or superior accuracy.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15306v1",
        "authors": [
          "Kentaro Kanamori",
          "Hirofumi Suzuki",
          "Takuya Takagi"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Causal Structure Learning",
        "Sparse Additive Model Pruning",
        "Framework",
        "DAG",
        "CAM",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.217416"
    },
    {
      "id": "arxiv-2602.15293v1",
      "title": "The Information Geometry of Softmax: Probing and Steering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15293v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should reflect the way models use representations to produce behavior. We focus on the important special case of representations that define softmax distributions. In this case, we argue that the natural geometry is information geometry. Our focus is on the role of information geometry on semantic encoding and the linear representation hypothesis. As an illustrative application, we develop \"dual steering\", a method for robustly steering representations to exhibit a particular concept using linear probes. We prove that dual steering optimally modifies the target concept while minimizing changes to off-target concepts. Empirically, we find that dual steering enhances the controllability and stability of concept manipulation.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CL",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15293v1",
        "authors": [
          "Kiho Park",
          "Todd Nief",
          "Yo Joong Choe",
          "Victor Veitch"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CL",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.217644"
    },
    {
      "id": "arxiv-2602.15291v1",
      "title": "Structural grouping of extreme value models via graph fused lasso",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15291v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The generalized Pareto distribution (GPD) is a fundamental model for analyzing the tail behavior of a distribution. In particular, the shape parameter of the GPD characterizes the extremal properties of the distribution. As described in this paper, we propose a method for grouping shape parameters in the GPD for clustered data via graph fused lasso. The proposed method simultaneously estimates the model parameters and identifies which clusters can be grouped together. We establish the asymptotic theory of the proposed estimator and demonstrate that its variance is lower than that of the cluster-wise estimator. This variance reduction not only enhances estimation stability but also provides a principled basis for identifying homogeneity and heterogeneity among clusters in terms of their tail behavior. We assess the performance of the proposed estimator through Monte Carlo simulations. As an illustrative example, our method is applied to rainfall data from 996 clustered sites across Japan.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15291v1",
        "authors": [
          "Takuma Yoshida",
          "Koki Momoki",
          "Shuichi Kawano"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "GPD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:39.217873"
    },
    {
      "id": "arxiv-2602.15787v1",
      "title": "Energy budgets govern synaptic precision and its regulation during plasticity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15787v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Synaptic transmission must balance the need for reliable signalling against the metabolic cost of achieving that reliability. How energetic constraints shape synaptic precision and its regulation during plasticity remains unclear. Here we develop an energy--constrained framework in which synapses minimise postsynaptic response variance subject to a fixed mean and an effective energy budget. Combinations of candidate physiological costs are used to estimate an energy cost for synaptic transmission; this cost is then inferred from quantal statistics. Analysing five published pre- and post-plasticity datasets, we find that observed synaptic mean--variance pairs cluster near a minimal-energy boundary, indicating that precision is limited by energetic availability. Model comparison identifies a dominant calcium pump-like cost paired with a smaller vesicle turnover-like cost, yielding a separable precision--energy relationship, $σ^{-2} \\propto E^5$. We further show that plasticity systematically updates synaptic energy budgets according to the scale-free magnitude of mean change, enabling accurate prediction of post-plasticity variance from energy allocation alone. These results provide direct experimental support for the hypothesis that synaptic precision is governed by energy budgets, establishing energy allocation as a fundamental principle linking metabolic constraints, synaptic reliability, and plasticity.",
        "keywords": [
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15787v1",
        "authors": [
          "James Malkin",
          "Cian O'Donnell",
          "Conor Houghton"
        ],
        "arxiv_categories": [
          "q-bio.NC"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Regulation",
        "Framework",
        "Meta",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-18T13:59:45.138329"
    },
    {
      "id": "arxiv-2602.15691v1",
      "title": "Relating biomarkers and phenotypes using dynamical trap spaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15691v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Connecting the dynamics of biomolecular networks to experimentally measurable cell phenotypes remains a central challenge in systems biology. Here we introduce a model-based definition of phenotype as a partial steady state that is committed to a certain dynamical outcome while otherwise being minimally constrained. We focus on Boolean models and define \\emph{dynamical phenotypes} as complete trap spaces that maximally specify a chosen set of phenotype-determining nodes that correspond to biomarkers while keeping external inputs unconstrained. We show that dynamical phenotypes can be efficiently identified without full attractor enumeration. Using four published models, including a 70-node Boolean model of T cell differentiation, we show that dynamical phenotypes recover known cell types and activation states, and indicate the environmental conditions ensuring their existence. We also propose a method to identify informative phenotype-determining nodes based on the canalization of the Boolean functions. This method reveals biologically relevant cell state information that is complementary to the phenotypes manually defined by model creators and is validated by two attractor-based approaches. Our results demonstrate that dynamical phenotypes provide a scalable framework for linking model structure, external inputs, and phenotypic outcomes, and offer a principled tool for model-guided biomarker selection.",
        "keywords": [
          "q-bio.MN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15691v1",
        "authors": [
          "Samuel Pastva",
          "Kyu Hyong Park",
          "Jordan C. Rozum",
          "Van-Giang Trinh",
          "Réka Albert"
        ],
        "arxiv_categories": [
          "q-bio.MN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:45.138719"
    },
    {
      "id": "arxiv-2602.15808v1",
      "title": "Measurement-Based Validation of Geometry-Driven RIS Beam Steering in Industrial Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15808v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reconfigurable intelligent surfaces (RISs) offer programmable control of radio propagation for future wireless systems. For configuration, geometry-driven analytical approaches are appealing for their simplicity and real-time operation, but their performance in challenging environments such as industrial halls with dense multipath and metallic scattering is not well established. To this end, we present a measurement-based evaluation of geometry-driven RIS beam steering in a large industrial hall using a 5 GHz RIS prototype. A novel RIS configuration is proposed in which four patch antennas are mounted in close proximity in front of the RIS to steer the incident field and enable controlled reflection. For this setup, analytically computed, quantized configurations are implemented. Two-dimensional received power maps from two measurement areas reveal consistent, spatially selective focusing. Configurations optimized near the receiver produce clear power maxima, while steering to offset locations triggers a rapid 20-30 dB reduction. With increasing RIS-receiver distance, elevation selectivity broadens due to finite-aperture and geometric constraints, while azimuth steering remains robust. These results confirm the practical viability of geometry-driven RIS beam steering in industrial environments and support its use for spatial field control and localization under non-ideal propagation.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15808v1",
        "authors": [
          "Adam Umra",
          "Simon Tewes",
          "Niklas Beckmann",
          "Niels König",
          "Aydin Sezgin"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Industrial Environments Reconfigurable",
        "Based Validation",
        "Beam Steering",
        "Intel",
        "Meta",
        "MIT",
        "RIS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.069050"
    },
    {
      "id": "arxiv-2602.15779v1",
      "title": "Rate-Distortion Optimization for Ensembles of Non-Reference Metrics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15779v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Non-reference metrics (NRMs) can assess the visual quality of images and videos without a reference, making them well-suited for the evaluation of user-generated content. Nonetheless, rate-distortion optimization (RDO) in video coding is still mainly driven by full-reference metrics, such as the sum of squared errors, which treat the input as an ideal target. A way to incorporate NRMs into RDO is through linearization (LNRM), where the gradient of the NRM with respect to the input guides bit allocation. While this strategy improves the quality predicted by some metrics, we show that it can yield limited gains or degradations when evaluated with other NRMs. We argue that NRMs are highly non-linear predictors with locally unstable gradients that can compromise the quality of the linearization; furthermore, optimizing a single metric may exploit model-specific biases that do not generalize across quality estimators. Motivated by this observation, we extend the LNRM framework to optimize ensembles of NRMs and, to further improve robustness, we introduce a smoothing-based formulation that stabilizes NRM gradients prior to linearization. Our framework is well-suited to hybrid codecs, and we advocate for its use with overfitted codecs, where it avoids iterative evaluations and backpropagation of neural network-based NRMs, reducing encoder complexity relative to direct NRM optimization. We validate the proposed approach on AVC and Cool-chic, using the YouTube UGC dataset. Experiments demonstrate consistent bitrate savings across multiple NRMs with no decoder complexity overhead and, for Cool-chic, a substantial reduction in encoding runtime compared to direct NRM optimization.",
        "keywords": [
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15779v1",
        "authors": [
          "Xin Xiong",
          "Samuel Fernández-Menduiña",
          "Eduardo Pavez",
          "Antonio Ortega",
          "Neil Birkbeck"
        ],
        "arxiv_categories": [
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distortion Optimization",
        "Reference Metrics Non",
        "Neural Network",
        "Framework",
        "LNRM",
        "MIT",
        "RDO",
        "NRM",
        "UGC",
        "AVC",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.069780"
    },
    {
      "id": "arxiv-2602.15737v1",
      "title": "NYUSIM: A Roadmap to AI-Enabled Statistical Channel Modeling and Simulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15737v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Integrating artificial intelligence (AI) into wireless channel modeling requires large, accurate, and physically consistent datasets derived from real measurements. Such datasets are essential for training and validating models that learn spatio-temporal channel behavior across frequencies and environments. NYUSIM, introduced by NYU WIRELESS in 2016, generates realistic spatio-temporal channel data using extensive outdoor and indoor measurements between 28 and 142 GHz. To improve scalability and support 6G research, we migrated the complete NYUSIM framework from MATLAB to Python, and are incorporating new statistical model generation capabilities from extensive field measurements in the new 6G upper mid-band spectrum at 6.75 GHz (FR1(C)) and 16.95 GHz (FR3) [1]. The NYUSIM Python also incorporates a 3D antenna data format, referred to as Ant3D, which is a standardized, full-sphere format for defining canonical, commercial, or measured antenna patterns for any statistical or site-specific ray tracing modeling tool. Migration from MATLAB to Python was rigorously validated through Kolmogorov-Smirnov (K-S) tests, moment analysis, and end-to-end testing with unified randomness control, confirming statistical consistency and reproduction of spatio-temporal channel statistics, including spatial consistency with the open-source MATLAB NYUSIM v4.0 implementation. The NYUSIM Python version is designed to integrate with modern AI workflows and enable large-scale parallel data generation, establishing a robust, verified, and extensible foundation for future AI-enabled channel modeling.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15737v1",
        "authors": [
          "Isha Jariwala",
          "Xinquan Wang",
          "Bridget Meier",
          "Guanyue Qian",
          "Dipankar Shakya"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enabled Statistical Channel Modeling",
        "Artificial Intelligence",
        "Simulation Integrating",
        "Framework",
        "Standard",
        "NYUSIM",
        "MATLAB",
        "Intel",
        "NYU",
        "6G",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.070469"
    },
    {
      "id": "arxiv-2602.15618v1",
      "title": "Physics-Informed Anomaly Detection of Terrain Material Change in Radar Imagery",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15618v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper we consider physics-informed detection of terrain material change in radar imagery (e.g., shifts in permittivity, roughness or moisture). We propose a lightweight electromagnetic (EM) forward model to simulate bi-temporal single-look complex (SLC) images from labelled material maps. On these data, we derive physics-aware feature stacks that include interferometric coherence, and evaluate unsupervised detectors: Reed-Xiaoli (RX)/Local-RX with robust scatter (Tyler's M-estimator), Coherent Change Detection (CCD), and a compact convolutional auto-encoder. Monte Carlo experiments sweep dielectric/roughness/moisture changes, number of looks and clutter regimes (gamma vs K-family) at fixed probability of false alarm. Results on synthetic but physically grounded scenes show that coherence and robust covariance markedly improve anomaly detection of material changes; a simple score-level fusion achieves the best F1 in heavy-tailed clutter.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15618v1",
        "authors": [
          "Abdel Hakiem Mohamed Abbas Mohamed Ahmed",
          "Beth Jelfs",
          "Airlie Chapman",
          "Eric Schoof",
          "Christopher Gilliam"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Informed Anomaly Detection",
        "Coherent Change Detection",
        "Terrain Material Change",
        "Radar Imagery In",
        "Monte Carlo",
        "Fusion",
        "CCD",
        "MIT",
        "SLC",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.071272"
    },
    {
      "id": "arxiv-2602.15596v1",
      "title": "Time-Certified and Efficient NMPC via Koopman Operator",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15596v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Certifying and accelerating execution times of nonlinear model predictive control (NMPC) implementations are two core requirements. Execution-time certificate guarantees that the NMPC controller returns a solution before the next sampling time, and achieving faster worst-case and average execution times further enables its use in a wider set of applications. However, NMPC produces a nonlinear program (NLP) for which it is challenging to derive its execution time certificates. Our previous works, \\citep{wu2025direct,wu2025time} provide data-independent execution time certificates (certified number of iterations) for box-constrained quadratic programs (BoxQP). To apply the time-certified BoxQP algorithm \\citep{wu2025time} for state-input constrained NMPC, this paper i) learns a linear model via Koopman operator; ii) proposes a dynamic-relaxation construction approach yields a structured BoxQP rather than a general QP; iii) exploits the structure of BoxQP, where the dimension of the linear system solved in each iteration is reduced from $5N(n_u+n_x)$ to $Nn_u$ (where $n_u, n_x, N$ denote the number of inputs, states, and length of prediction horizon), yielding substantial speedups (when $n_x \\gg n_u$, as in PDE control).",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15596v1",
        "authors": [
          "Liang Wu",
          "Yunhong Che",
          "Bo Yang",
          "Kangyu Lin",
          "Ján Drgoňa"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Koopman Operator Certifying",
        "NMPC",
        "NLP",
        "PDE",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.071679"
    },
    {
      "id": "arxiv-2602.15555v1",
      "title": "Tracking Time-Varying Multipath Channels forActive Sonar Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15555v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reliable detection and tracking in active sonar require accurate and efficient learning of the acoustic multipath background environment. Conventionally, background learning is performed after transforming measurements into the range-Doppler domain, a step that is computationally expensive and can obscure phase-coherent structure useful for monitoring and tracking. This paper proposes a framework for learning and tracking the multipath background directly in the raw measurement domain. Starting from a wideband Doppler linearization of the impulse response of a time-varying multipath channel, a state-space model with a heteroscedastic measurement equation is derived. This model enables channel tracking using an extended Kalman filter (EKF), and unknown model parameters are learned from the marginalized likelihood. The statistical adequacy of the proposed models is assessed via a p-value significance test. Finally, this paper integrates the learned channel model into a sequential likelihood-ratio test for target detection. BELLHOP-based simulations show that the proposed model better captures channel dynamics induced by sea-surface fluctuations and transmitter and receiver drift, yielding more reliable detection in time-varying shallow-water environments",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15555v1",
        "authors": [
          "Ashwani Koul",
          "Gustaf Hendeby",
          "Isaac Skog"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sonar Applications Reliable",
        "Varying Multipath Channels",
        "Tracking Time",
        "Framework",
        "EKF",
        "NSF",
        "MIT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.072143"
    },
    {
      "id": "arxiv-2602.15544v1",
      "title": "Waveform Design for ISAC System: A Consensus ADMM Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15544v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study joint transmit-waveform and receive-filter design for a multi-user downlink integrated sensing and communication (ISAC) system under practical constant-modulus and similarity constraints. We cast the design as a unified multi-objective program that balances communication sum rate and sensing signal-to-interference-plus-noise ratio (SINR). To address this, we introduce an efficient algorithm that use consensus alternating direction method of multipliers (ADMM) framework to alternately update the transmit waveform and radar filter. The proposed method effectively handles the non-convex fractional sensing's SINR formulation and ensures fast convergence. Simulation results demonstrate that the proposed approach achieves better trade-offs between communication sum rate and sensing's SINR compared to existing benchmark schemes.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15544v1",
        "authors": [
          "Ngoc-Son Duong",
          "Huyen-Trang Ta",
          "Quang-Tang Ngo",
          "Thi-Hue Duong",
          "Van-Lap Nguyen"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Waveform Design",
        "Approach We",
        "Framework",
        "SINR",
        "ADMM",
        "ISAC",
        "MIT",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.072447"
    },
    {
      "id": "arxiv-2602.15530v1",
      "title": "Adaptive Selection of Codebook Using Assistance Information and Artificial Intelligence for 6G Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15530v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper addresses the problem of adaptive codebook (CB) selection for downlink (DL) precoder quantization in channel state information (CSI) reporting. The accuracy of precoder quantization depends on propagation conditions, requiring independent parameter adaptation for each user equipment (UE). To enable optimal CB selection, this paper proposes UE-assisted CB selection at the base station (BS) using reported by the UE statistical channel properties across time, frequency, and spatial domains. The reported assistance information serves as input to a neural network (NN), which predicts the quantization accuracy of various CB types for each served user. The predicted accuracy is then used to select the optimal CB while considering the associated CSI reporting overhead and precoding performance. System-level simulations demonstrate that the proposed approach reduces total CSI overhead while maintaining the target system throughput performance.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15530v1",
        "authors": [
          "Denis Esiunin",
          "Alexei Davydov"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Codebook Using Assistance Information",
        "Artificial Intelligence",
        "Adaptive Selection",
        "Neural Network",
        "Intel",
        "CSI",
        "EU",
        "6G",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.072825"
    },
    {
      "id": "arxiv-2602.15526v1",
      "title": "The role of VSG parameters in shaping small-signal SG dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15526v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We derive a small-signal transfer function for a system comprising a virtual synchronous generator (VSG), a synchronous generator (SG), and a load, capturing voltage and frequency dynamics. Using this model, we analyze the sensitivity of SG dynamics to VSG parameters, highlighting trade-offs in choosing virtual inertia and governor lag, the limited effect of damper-winding emulation, and several others.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15526v1",
        "authors": [
          "Ferdinand Geuss",
          "Orcun Karaca",
          "Mario Schweizer",
          "Ognjen Stanojev"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wind",
        "NSF",
        "MIT",
        "VSG",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.072913"
    },
    {
      "id": "arxiv-2602.15484v1",
      "title": "Bottleneck Transformer-Based Approach for Improved Automatic STOI Score Prediction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15484v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this study, we have presented a novel approach to predict the Short-Time Objective Intelligibility (STOI) metric using a bottleneck transformer architecture. Traditional methods for calculating STOI typically requires clean reference speech, which limits their applicability in the real world. To address this, numerous deep learning-based nonintrusive speech assessment models have garnered significant interest. Many studies have achieved commendable performance, but there is room for further improvement. We propose the use of bottleneck transformer, incorporating convolution blocks for learning frame-level features and a multi-head self-attention (MHSA) layer to aggregate the information. These components enable the transformer to focus on the key aspects of the input data. Our model has shown higher correlation and lower mean squared error for both seen and unseen scenarios compared to the state-of-the-art model using self-supervised learning (SSL) and spectral features as inputs.",
        "keywords": [
          "eess.AS",
          "cs.LG",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15484v1",
        "authors": [
          " Amartyaveer",
          "Murali Kadambi",
          "Chandra Mohan Sharma",
          "Anupam Mondal",
          "Prasanta Kumar Ghosh"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.LG",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Objective Intelligibility",
        "Bottleneck Transformer",
        "Score Prediction In",
        "Improved Automatic",
        "Based Approach",
        "Deep Learning",
        "Transformer",
        "Intel",
        "STOI",
        "MHSA",
        "NSF",
        "MIT",
        "SSL",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.073117"
    },
    {
      "id": "arxiv-2602.15422v1",
      "title": "Generalized bilinear Koopman realization from input-output data for multi-step prediction with metaheuristic optimization of lifting function and its application to real-world industrial system",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15422v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces an input-output bilinear Koopman realization with an optimization algorithm of lifting functions. For nonlinear systems with inputs, Koopman-based modeling is effective because the Koopman operator enables a high-dimensional linear representation of nonlinear dynamics. However, traditional approaches face significant challenges in industrial applications. Measuring all system states is often impractical due to constraints on sensor installation. Moreover, the predictive performance of a Koopman model strongly depends on the choice of lifting functions, and their design typically requires substantial manual effort. In addition, although a linear time-invariant (LTI) Koopman model is the most commonly used model structure in the Koopman framework, such model exhibit limited predictive accuracy. To address these limitations, we propose an input-output bilinear Koopman modeling in which the design parameters of radial basis function (RBF)-based lifting functions are optimized using a global metaheuristic algorithm to improve long-term prediction performance. Consideration of the long-term prediction performance enhances the reliability of the resulting model. The proposed methodology is validated in simulations and experimental tests, with the airpath control system of a diesel engine as the plant to be modeled. This plant represents a challenging industrial application because it exhibits strong nonlinearities and coupled multi-input multi-output (MIMO) dynamics. These results demonstrate that the proposed input-output bilinear Koopman model significantly outperforms traditional linear Koopman models in predictive accuracy.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15422v1",
        "authors": [
          "Shuichi Yahagi",
          "Ansei Yonezawa",
          "Heisei Yonezawa",
          "Hiroki Seto",
          "Itsuro Kajiwara"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Meta",
        "MIMO",
        "RBF",
        "MIT",
        "LTI",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.073412"
    },
    {
      "id": "arxiv-2602.15368v1",
      "title": "GMAIL: Generative Modality Alignment for generated Image Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15368v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Generative models have made it possible to synthesize highly realistic images, potentially providing an abundant data source for training machine learning models. Despite the advantages of these synthesizable data sources, the indiscriminate use of generated images as real images for training can even cause mode collapse due to modality discrepancies between real and synthetic domains. In this paper, we propose a novel framework for discriminative use of generated images, coined GMAIL, that explicitly treats generated images as a separate modality from real images. Instead of indiscriminately replacing real images with generated ones in the pixel space, our approach bridges the two distinct modalities in the same latent space through a multi-modal learning approach. To be specific, we first fine-tune a model exclusively on generated images using a cross-modality alignment loss and then employ this aligned model to further train various vision-language models with generated images. By aligning the two modalities, our approach effectively leverages the benefits of recent advances in generative models, thereby boosting the effectiveness of generated image learning across a range of vision-language tasks. Our framework can be easily incorporated with various vision-language models, and we demonstrate its efficacy throughout extensive experiments. For example, our framework significantly improves performance on image captioning, zero-shot image retrieval, zero-shot image classification, and long caption retrieval tasks. It also shows positive generated data scaling trends and notable enhancements in the captioning performance of the large multimodal model, LLaVA.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.LG",
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15368v1",
        "authors": [
          "Shentong Mo",
          "Sukmin Yun"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG",
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generative Modality Alignment",
        "Image Learning Generative",
        "Machine Learning",
        "Framework",
        "GMAIL",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.073661"
    },
    {
      "id": "arxiv-2602.15350v1",
      "title": "Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15350v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \\emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility.",
        "keywords": [
          "eess.SY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15350v1",
        "authors": [
          "Mohamad Chehade",
          "Hao Zhu"
        ],
        "arxiv_categories": [
          "eess.SY",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Power Grid Public Safety",
        "Generate Economical",
        "Reliable Actions",
        "Power Shutoffs",
        "Standard",
        "Oracle",
        "Policy",
        "IEEE",
        "PSPS",
        "MILP",
        "MIT",
        "OPF",
        "LLM",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.073865"
    },
    {
      "id": "arxiv-2602.15339v1",
      "title": "Benchmarking Self-Supervised Models for Cardiac Ultrasound View Classification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15339v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reliable interpretation of cardiac ultrasound images is essential for accurate clinical diagnosis and assessment. Self-supervised learning has shown promise in medical imaging by leveraging large unlabelled datasets to learn meaningful representations. In this study, we evaluate and compare two self-supervised learning frameworks, USF-MAE, developed by our team, and MoCo v3, on the recently introduced CACTUS dataset (37,736 images) for automated simulated cardiac view (A4C, PL, PSAV, PSMV, Random, and SC) classification. Both models used 5-fold cross-validation, enabling robust assessment of generalization performance across multiple random splits. The CACTUS dataset provides expert-annotated cardiac ultrasound images with diverse views. We adopt an identical training protocol for both models to ensure a fair comparison. Both models are configured with a learning rate of 0.0001 and a weight decay of 0.01. For each fold, we record performance metrics including ROC-AUC, accuracy, F1-score, and recall. Our results indicate that USF-MAE consistently outperforms MoCo v3 across metrics. The average testing AUC for USF-MAE is 99.99% (+/-0.01% 95% CI), compared to 99.97% (+/-0.01%) for MoCo v3. USF-MAE achieves a mean testing accuracy of 99.33% (+/-0.18%), higher than the 98.99% (+/-0.28%) reported for MoCo v3. Similar trends are observed for the F1-score and recall, with improvements statistically significant across folds (paired t-test, p=0.0048 < 0.01). This proof-of-concept analysis suggests that USF-MAE learns more discriminative features for cardiac view classification than MoCo v3 when applied to this dataset. The enhanced performance across multiple metrics highlights the potential of USF-MAE for improving automated cardiac ultrasound classification.",
        "keywords": [
          "eess.IV",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15339v1",
        "authors": [
          "Youssef Megahed",
          "Salma I. Megahed",
          "Robin Ducharme",
          "Inok Lee",
          "Adrian D. C. Chan"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cardiac Ultrasound View Classification",
        "Supervised Models",
        "Benchmarking Self",
        "Framework",
        "Protocol",
        "CACTUS",
        "PSAV",
        "PSMV",
        "ROC",
        "AUC",
        "MAE",
        "USF",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.074106"
    },
    {
      "id": "arxiv-2602.15333v1",
      "title": "Noncooperative Coordination for Decentralized Air Traffic Management",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15333v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15333v1",
        "authors": [
          "Jaehan Im"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Decentralized Air Traffic Management",
        "Noncooperative Coordination",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.074266"
    },
    {
      "id": "arxiv-2602.15282v1",
      "title": "State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15282v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15282v1",
        "authors": [
          "Fen Wu"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "State Feedback Control",
        "Framework",
        "IQC",
        "LPV",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-18T13:59:51.074461"
    }
  ]
}