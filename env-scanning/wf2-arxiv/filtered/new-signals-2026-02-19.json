{
  "metadata": {
    "workflow_id": "wf2-arxiv",
    "scan_date": "2026-02-19",
    "scan_window": "2026-02-17T22:31 ~ 2026-02-19T22:31 UTC (48h)",
    "total_raw": 732,
    "total_after_dedup": 724,
    "dedup_removed": 8
  },
  "items": [
    {
      "id": "arxiv-2602.16711v1",
      "title": "TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16711v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16711v1",
        "authors": [
          "Namitha Padmanabhan",
          "Matthew Gwilliam",
          "Abhinav Shrivastava"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Videos Implicit Neural Representations",
        "Compressible Neural Representations",
        "Leveraging Temporal Coherence",
        "Framework",
        "HEVC",
        "PSNR",
        "EPA",
        "INR",
        "MIT",
        "JCV",
        "MCL",
        "UVG",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.409866"
    },
    {
      "id": "arxiv-2602.16709v1",
      "title": "Knowledge-Embedded Latent Projection for Robust Representation Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16709v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.",
        "keywords": [
          "cs.LG",
          "math.ST",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16709v1",
        "authors": [
          "Weijing Tang",
          "Ming Yuan",
          "Zongqi Xia",
          "Tianxi Cai"
        ],
        "arxiv_categories": [
          "cs.LG",
          "math.ST",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robust Representation Learning Latent",
        "Embedded Latent Projection",
        "BERT",
        "EHR",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.410399"
    },
    {
      "id": "arxiv-2602.16708v1",
      "title": "Policy Compiler for Secure Agentic Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16708v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement. Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. Instead, PCAS models the agentic system state as a dependency graph capturing causal relationships among events such as tool calls, tool results, and messages. Policies are expressed in a Datalog-derived language, as declarative rules that account for transitive information flow and cross-agent provenance. A reference monitor intercepts all actions and blocks violations before execution, providing deterministic enforcement independent of model reasoning. PCAS takes an existing agent implementation and a policy specification, and compiles them into an instrumented system that is policy-compliant by construction, with no security-specific restructuring required. We evaluate PCAS on three case studies: information flow policies for prompt injection defense, approval workflows in a multi-agent pharmacovigilance system, and organizational policies for customer service. On customer service tasks, PCAS improves policy compliance from 48% to 93% across frontier models, with zero policy violations in instrumented runs.",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16708v1",
        "authors": [
          "Nils Palumbo",
          "Sarthak Choudhary",
          "Jihye Choi",
          "Prasad Chalasani",
          "Mihai Christodorescu"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Secure Agentic Systems",
        "Policy Compiler",
        "Agentic Systems",
        "Protocol",
        "Policy",
        "PCAS",
        "NIST",
        "LLM",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.410893"
    },
    {
      "id": "arxiv-2602.16705v1",
      "title": "Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16705v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.",
        "keywords": [
          "cs.RO",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16705v1",
        "authors": [
          "Runpei Dong",
          "Ziyan Li",
          "Xialin He",
          "Saurabh Gupta"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vocabulary Visual Loco",
        "Learning Humanoid End",
        "Manipulation Visual",
        "Effector Control",
        "Machine Learning",
        "Policy",
        "Robot",
        "Apple",
        "HERO",
        "Act",
        "MIT",
        "RGB",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.411415"
    },
    {
      "id": "arxiv-2602.16704v1",
      "title": "Reinforced Fast Weights with Next-Sequence Prediction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16704v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Fast weight architectures offer a promising alternative to attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix. Consequently, fast weight models, which dynamically update their parameters to store contextual information, learn suboptimal representations that fail to capture long-range dependencies. We introduce REFINE (Reinforced Fast weIghts with Next sEquence prediction), a reinforcement learning framework that trains fast weight models under the next-sequence prediction (NSP) objective. REFINE selects informative token positions based on prediction entropy, generates multi-token rollouts, assigns self-supervised sequence-level rewards, and optimizes the model with group relative policy optimization (GRPO). REFINE is applicable throughout the training lifecycle of pre-trained language models: mid-training, post-training, and test-time training. Our experiments on LaCT-760M and DeltaNet-1.3B demonstrate that REFINE consistently outperforms supervised fine-tuning with NTP across needle-in-a-haystack retrieval, long-context question answering, and diverse tasks in LongBench. REFINE provides an effective and versatile framework for improving long-context modeling in fast weight architectures.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16704v1",
        "authors": [
          "Hee Seung Hwang",
          "Xindi Wu",
          "Sanghyuk Chun",
          "Olga Russakovsky"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sequence Prediction Fast",
        "Reinforced Fast Weights",
        "Reinforced Fast",
        "Transformer",
        "DeltaNet-1",
        "Framework",
        "Policy",
        "REFINE",
        "GRPO",
        "NSF",
        "Act",
        "NSP",
        "MIT",
        "NTP",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.411820"
    },
    {
      "id": "arxiv-2602.16703v1",
      "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16703v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a \"typical\" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.",
        "keywords": [
          "cs.CY",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16703v1",
        "authors": [
          "Shen Zhou Hong",
          "Alex Kleinman",
          "Alyssa Mathiowetz",
          "Adam Howes",
          "Julian Cohen"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Novice Performance",
        "Biology Large",
        "Measuring Mid",
        "Laboratory",
        "Mid-2025",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:46:56.412271"
    },
    {
      "id": "arxiv-2602.16702v1",
      "title": "Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16702v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \\emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16702v1",
        "authors": [
          "Mingjia Shi",
          "Yinhan He",
          "Yaochen Zhu",
          "Jundong Li"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Language Reasoning Vision",
        "Revisiting Vision",
        "Aware Principle",
        "Route Thinking",
        "Aware Multi",
        "LLM",
        "SAP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.412678"
    },
    {
      "id": "arxiv-2602.16699v1",
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16699v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16699v1",
        "authors": [
          "Wenxuan Ding",
          "Nicholas Tomlin",
          "Greg Durrett"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Exploration",
        "Framework",
        "LLM",
        "CTA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.413054"
    },
    {
      "id": "arxiv-2602.16698v1",
      "title": "Causality is Key for Interpretability Claims to Generalise",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16698v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies what an interpretability study can justify. Observations establish associations between model behaviour and internal components. Interventions (e.g., ablations or activation patching) support claims how these edits affect a behavioural metric (\\eg, average change in token probabilities) over a set of prompts. However, counterfactual claims -- i.e., asking what the model output would have been for the same prompt under an unobserved intervention -- remain largely unverifiable without controlled supervision. We show how causal representation learning (CRL) operationalises this hierarchy, specifying which variables are recoverable from activations and under what assumptions. Together, these motivate a diagnostic framework that helps practitioners select methods and evaluations matching claims to evidence such that findings generalise.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16698v1",
        "authors": [
          "Shruti Joshi",
          "Aaron Mueller",
          "David Klindt",
          "Wieland Brendel",
          "Patrik Reizinger"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalise Interpretability",
        "Interpretability Claims",
        "Framework",
        "LLM",
        "Act",
        "CRL",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.413430"
    },
    {
      "id": "arxiv-2602.16697v1",
      "title": "Protecting the Undeleted in Machine Unlearning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16697v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Machine unlearning aims to remove specific data points from a trained model, often striving to emulate \"perfect retraining\", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $ω(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.",
        "keywords": [
          "cs.LG",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16697v1",
        "authors": [
          "Aloni Cohen",
          "Refael Kohen",
          "Kobbi Nissim",
          "Uri Stemmer"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Unlearning Machine",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.414284"
    },
    {
      "id": "arxiv-2602.16696v1",
      "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16696v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
        "keywords": [
          "q-bio.GN",
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16696v1",
        "authors": [
          "Huan Souza",
          "Pankaj Mehta"
        ],
        "arxiv_categories": [
          "q-bio.GN",
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deep Learning",
        "Transformer",
        "SOTA",
        "RNA",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.414680"
    },
    {
      "id": "arxiv-2602.16690v1",
      "title": "Synthetic-Powered Multiple Testing with FDR Control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16690v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Multiple hypothesis testing with false discovery rate (FDR) control is a fundamental problem in statistical inference, with broad applications in genomics, drug screening, and outlier detection. In many such settings, researchers may have access not only to real experimental observations but also to auxiliary or synthetic data -- from past, related experiments or generated by generative models -- that can provide additional evidence about the hypotheses of interest. We introduce SynthBH, a synthetic-powered multiple testing procedure that safely leverages such synthetic data. We prove that SynthBH guarantees finite-sample, distribution-free FDR control under a mild PRDS-type positive dependence condition, without requiring the pooled-data p-values to be valid under the null. The proposed method adapts to the (unknown) quality of the synthetic data: it enhances the sample efficiency and may boost the power when synthetic data are of high quality, while controlling the FDR at a user-specified level regardless of their quality. We demonstrate the empirical performance of SynthBH on tabular outlier detection benchmarks and on genomic analyses of drug-cancer sensitivity associations, and further study its properties through controlled experiments on simulated data.",
        "keywords": [
          "stat.ME",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16690v1",
        "authors": [
          "Yonghoon Lee",
          "Meshi Bashari",
          "Edgar Dobriban",
          "Yaniv Romano"
        ],
        "arxiv_categories": [
          "stat.ME",
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Powered Multiple Testing",
        "Control Multiple",
        "PRDS",
        "FDR",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.415059"
    },
    {
      "id": "arxiv-2602.16689v1",
      "title": "Are Object-Centric Representations Better At Compositional Generalization?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16689v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.",
        "keywords": [
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16689v1",
        "authors": [
          "Ferdinand Kapl",
          "Amir Mohammad Karimi Mamaghan",
          "Maximilian Seitzer",
          "Karl Henrik Johansson",
          "Carsten Marr"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Centric Representations Better At",
        "Compositional Generalization",
        "Visual Question Answering",
        "Machine Learning",
        "Are Object",
        "CLEVR",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.415490"
    },
    {
      "id": "arxiv-2602.16688v1",
      "title": "On the Hardness of Approximation of the Fair k-Center Problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16688v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we study the hardness of approximation of the fair $k$-center problem. Here the data points are partitioned into groups and the task is to choose a prescribed number of data points from each group, called centers, while minimizing the maximum distance from any point to its closest center. Although a polynomial-time $3$-approximation is known for this problem in general metrics, it has remained open whether this approximation guarantee is tight or could be further improved, especially since the unconstrained $k$-center problem admits a polynomial-time factor-$2$ approximation. We resolve this open question by proving that, for every $ε>0$, achieving a $(3-ε)$-approximation is NP-hard, assuming $\\text{P} \\neq \\text{NP}$. Our inapproximability results hold even when only two disjoint groups are present and at least one center must be chosen from each group. Further, it extends to the canonical one-per-group setting with $k$-groups (for arbitrary $k$), where exactly one center must be selected from each group. Consequently, the factor-$3$ barrier for fair $k$-center in general metric spaces is inherent, and existing $3$-approximation algorithms are optimal up to lower-order terms even in these restricted regimes. This result stands in sharp contrast to the $k$-supplier formulation, where both the unconstrained and fair variants admit factor-$3$ approximation in polynomial time.",
        "keywords": [
          "cs.CC",
          "cs.DS",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16688v1",
        "authors": [
          "Suhas Thejaswi"
        ],
        "arxiv_categories": [
          "cs.CC",
          "cs.DS",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Center Problem In",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.416392"
    },
    {
      "id": "arxiv-2602.16687v1",
      "title": "Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16687v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Current audio language models are predominantly text-first, either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, limiting general audio modeling. This paper presents a systematic empirical study of native audio foundation models that apply next-token prediction to audio at scale, jointly modeling semantic content, acoustic details, and text to support both general audio generation and cross-modal capabilities. We provide comprehensive empirical insights for building such models: (1) We systematically investigate design choices -- data sources, text mixture ratios, and token composition -- establishing a validated training recipe. (2) We conduct the first scaling law study for discrete audio models via IsoFLOP analysis on 64 models spanning $3{\\times}10^{18}$ to $3{\\times}10^{20}$ FLOPs, finding that optimal data grows 1.6$\\times$ faster than optimal model size. (3) We apply these lessons to train SODA (Scaling Open Discrete Audio), a suite of models from 135M to 4B parameters on 500B tokens, comparing against our scaling predictions and existing models. SODA serves as a flexible backbone for diverse audio/text tasks -- we demonstrate this by fine-tuning for voice-preserving speech-to-speech translation, using the same unified architecture.",
        "keywords": [
          "cs.SD",
          "cs.CL",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16687v1",
        "authors": [
          "Potsawee Manakul",
          "Woody Haosheng Gan",
          "Martijn Bartelds",
          "Guangzhi Sun",
          "William Held"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.CL",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scaling Open Discrete Audio",
        "Interleaved Semantic",
        "Text Tokens Current",
        "Foundation Models",
        "SODA",
        "LLM",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.416773"
    },
    {
      "id": "arxiv-2602.16684v1",
      "title": "Retrieval-Augmented Foundation Models for Matched Molecular Pair Transformations to Recapitulate Medicinal Chemistry Intuition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16684v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Matched molecular pairs (MMPs) capture the local chemical edits that medicinal chemists routinely use to design analogs, but existing ML approaches either operate at the whole-molecule level with limited edit controllability or learn MMP-style edits from restricted settings and small models. We propose a variable-to-variable formulation of analog generation and train a foundation model on large-scale MMP transformations (MMPTs) to generate diverse variables conditioned on an input variable. To enable practical control, we develop prompting mechanisms that let the users specify preferred transformation patterns during generation. We further introduce MMPT-RAG, a retrieval-augmented framework that uses external reference analogs as contextual guidance to steer generation and generalize from project-specific series. Experiments on general chemical corpora and patent-specific datasets demonstrate improved diversity, novelty, and controllability, and show that our method recovers realistic analog structures in practical discovery scenarios.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16684v1",
        "authors": [
          "Bo Pan",
          "Peter Zhiping Zhang",
          "Hao-Wei Pang",
          "Alex Zhu",
          "Xiang Yu"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recapitulate Medicinal Chemistry Intuition",
        "Matched Molecular Pair Transformations",
        "Augmented Foundation Models",
        "Framework",
        "MMPT",
        "MMP",
        "NSF",
        "Act",
        "MIT",
        "WHO",
        "RAG",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.417097"
    },
    {
      "id": "arxiv-2602.16682v1",
      "title": "Learning Situated Awareness in the Real World",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16682v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16682v1",
        "authors": [
          "Chuhan Li",
          "Ruilin Han",
          "Joy Hsu",
          "Yongyuan Liang",
          "Rajiv Dhawan"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learning Situated Awareness",
        "Situated Awareness",
        "Real World",
        "Ban Meta",
        "Intel",
        "Meta",
        "Act",
        "SAW",
        "MFM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.417486"
    },
    {
      "id": "arxiv-2602.16681v1",
      "title": "VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16681v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16681v1",
        "authors": [
          "Yingyuan Yang",
          "Tian Lan",
          "Yifei Gao",
          "Yimeng Lu",
          "Wenjun He"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Anomaly Window Contrastive Learning",
        "Reversible Image Conversion",
        "Shot Time Series Anomaly",
        "Level Temporal Alignment",
        "Vision Enhanced Zero",
        "Context Anomalies",
        "Point Anomalies",
        "Detection Time",
        "Adaptive Multi",
        "Modal Fusion",
        "Framework",
        "Fusion",
        "TSAD",
        "Wind",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.417835"
    },
    {
      "id": "arxiv-2602.16673v1",
      "title": "Neighborhood Stability as a Measure of Nearest Neighbor Searchability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16673v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Clustering-based Approximate Nearest Neighbor Search (ANNS) organizes a set of points into partitions, and searches only a few of them to find the nearest neighbors of a query. Despite its popularity, there are virtually no analytical tools to determine the suitability of clustering-based ANNS for a given dataset -- what we call \"searchability.\" To address that gap, we present two measures for flat clusterings of high-dimensional points in Euclidean space. First is Clustering-Neighborhood Stability Measure (clustering-NSM), an internal measure of clustering quality -- a function of a clustering of a dataset -- that we show to be predictive of ANNS accuracy. The second, Point-Neighborhood Stability Measure (point-NSM), is a measure of clusterability -- a function of the dataset itself -- that is predictive of clustering-NSM. The two together allow us to determine whether a dataset is searchable by clustering-based ANNS given only the data points. Importantly, both are functions of nearest neighbor relationships between points, not distances, making them applicable to various distance functions including inner product.",
        "keywords": [
          "cs.LG",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16673v1",
        "authors": [
          "Thomas Vecchiato",
          "Sebastian Bruch"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nearest Neighbor Searchability Clustering",
        "Approximate Nearest Neighbor Search",
        "Neighborhood Stability Measure",
        "Neighborhood Stability",
        "ANNS",
        "NSM",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.418135"
    },
    {
      "id": "arxiv-2602.16671v1",
      "title": "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16671v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.",
        "keywords": [
          "cs.SE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16671v1",
        "authors": [
          "Jaid Monwar Chowdhury",
          "Chi-An Fu",
          "Reyhaneh Jabbarvand"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unit Test Generation Automated",
        "While Large Language Models",
        "Control Flow Graph",
        "Scenario Planning",
        "Operation Map",
        "Framework",
        "SPARC",
        "KLEE",
        "EPA",
        "LLM",
        "Act",
        "MIT",
        "CFG",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.418519"
    },
    {
      "id": "arxiv-2602.16669v1",
      "title": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16669v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16669v1",
        "authors": [
          "Bo Lang",
          "Nirav Savaliya",
          "Zhihao Zheng",
          "Jinglun Feng",
          "Zheng-Hang Yeh"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vectorized Map Construction High",
        "History Rasterized Map Memory",
        "Aware Query Generator",
        "Term Future Guidance",
        "Historical Reasoning",
        "Map Guidance Module",
        "Consistent Online",
        "Framework",
        "SOTA",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.418887"
    },
    {
      "id": "arxiv-2602.16666v1",
      "title": "Towards a Science of AI Agent Reliability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16666v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.",
        "keywords": [
          "cs.AI",
          "cs.CY",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16666v1",
        "authors": [
          "Stephan Rabanser",
          "Sayash Kapoor",
          "Peter Kirgis",
          "Kangheng Liu",
          "Saiteja Utpala"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CY",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Reliability",
        "Standard",
        "EPA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.419149"
    },
    {
      "id": "arxiv-2602.16664v1",
      "title": "Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16664v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16664v1",
        "authors": [
          "Jiaming Liu",
          "Felix Petersen",
          "Yunhe Gao",
          "Yabin Zhang",
          "Hyojin Kim"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Supervised Semantic Bridge Adversarial",
        "Supervised Semantic Bridge",
        "Image Translation",
        "Unpaired Image",
        "Framework",
        "Fusion",
        "SSB",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.419434"
    },
    {
      "id": "arxiv-2602.16660v1",
      "title": "Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16660v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16660v1",
        "authors": [
          "Yuyan Bu",
          "Xiaohao Liu",
          "ZhaoXing Ren",
          "Yaodong Yang",
          "Juntao Dai"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enforcing Multilingual Consistency",
        "Benefit Multilingually",
        "Lingual Consistency",
        "Align Once",
        "LLM",
        "MLC",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.419776"
    },
    {
      "id": "arxiv-2602.16656v1",
      "title": "Investigating Nonlinear Quenching Effects on Polar Field Buildup in the Sun Using Physics-Informed Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16656v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The solar dynamo relies on the regeneration of the poloidal magnetic field through processes strongly modulated by nonlinear feedbacks such as tilt quenching (TQ) and latitude quenching (LQ). These mechanisms play a decisive role in regulating the buildup of the Sun's polar field and, in turn, the amplitude of future solar cycles. In this work, we employ Physics-Informed Neural Networks (PINN) to solve the surface flux transport (SFT) equation, embedding physical constraints directly into the neural network framework. By systematically varying transport parameters, we isolate the relative contributions of TQ and LQ to polar dipole buildup. We use the residual dipole moment as a diagnostic for cycle-to-cycle amplification and show that TQ suppression strengthens with increasing diffusivity, while LQ dominates in advection-dominated regimes. The ratio $ΔD_{\\mathrm{LQ}}/ΔD_{\\mathrm{TQ}}$ exhibits a smooth inverse-square dependence on the dynamo effectivity range, refining previous empirical fits with improved accuracy and reduced scatter. The results further reveal that the need for a decay term is not essential for PINN set-up due to the training process. Compared with the traditional 1D SFT model, the PINN framework achieves significantly lower error metrics and more robust recovery of nonlinear trends. Our results suggest that the nonlinear interplay between LQ and TQ can naturally produce alternations between weak and strong cycles, providing a physical explanation for the observed even-odd cycle modulation. These findings demonstrate the potential of PINN as an accurate, efficient, and physically consistent tool for solar cycle prediction.",
        "keywords": [
          "astro-ph.SR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16656v1",
        "authors": [
          "Jithu J. Athalathil",
          "Mohammed H. Talafha",
          "Bhargav Vaidya"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Investigating Nonlinear Quenching Effects",
        "Informed Neural Networks",
        "Polar Field Buildup",
        "Sun Using Physics",
        "Neural Network",
        "Framework",
        "Solar",
        "PINN",
        "SFT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.420724"
    },
    {
      "id": "arxiv-2602.16653v1",
      "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16653v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16653v1",
        "authors": [
          "Yangjie Xu",
          "Lujun Li",
          "Lama Sleem",
          "Niccolo Gentile",
          "Yewei Song"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Industrial Environments Agent Skill",
        "Small Language Models",
        "Agent Skill Framework",
        "Agent Skills",
        "Agent Skill",
        "Framework",
        "OpenAI",
        "GPU",
        "Act",
        "MIT",
        "SLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.421106"
    },
    {
      "id": "arxiv-2602.16650v1",
      "title": "Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer Expert System",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16650v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Polymer literature contains a large and growing body of experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in isolation, failing to preserve the cross-study context required to answer broader scientific questions. Retrieval-augmented generation (RAG) offers a promising way to overcome this limitation by combining large language models (LLMs) with external retrieval, but its effectiveness depends strongly on how domain knowledge is represented. In this work, we develop two retrieval pipelines: a dense semantic vector-based approach (VectorRAG) and a graph-based approach (GraphRAG). Using over 1,000 polyhydroxyalkanoate (PHA) papers, we construct context-preserving paragraph embeddings and a canonicalized structured knowledge graph supporting entity disambiguation and multi-hop reasoning. We evaluate these pipelines through standard retrieval metrics, comparisons with general state-of-the-art systems such as GPT and Gemini, and qualitative validation by a domain chemist. The results show that GraphRAG achieves higher precision and interpretability, while VectorRAG provides broader recall, highlighting complementary trade-offs. Expert validation further confirms that the tailored pipelines, particularly GraphRAG, produce well-grounded, citation-reliable responses with strong domain relevance. By grounding every statement in evidence, these systems enable researchers to navigate the literature, compare findings across studies, and uncover patterns that are difficult to extract manually. More broadly, this work establishes a practical framework for building materials science assistants using curated corpora and retrieval design, reducing reliance on proprietary models while enabling trustworthy literature analysis at scale.",
        "keywords": [
          "cs.CE",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16650v1",
        "authors": [
          "Sonakshi Gupta",
          "Akhlak Mahmood",
          "Wei Xiong",
          "Rampi Ramprasad"
        ],
        "arxiv_categories": [
          "cs.CE",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Biodegradable Polymer Expert System",
        "Retrieval Augmented Generation",
        "Polymer Knowledge",
        "Framework",
        "Standard",
        "LLM",
        "GPT",
        "Act",
        "MIT",
        "RAG",
        "PHA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.421553"
    },
    {
      "id": "arxiv-2602.16643v1",
      "title": "Factorization Machine with Quadratic-Optimization Annealing for RNA Inverse Folding and Evaluation of Binary-Integer Encoding and Nucleotide Assignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16643v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The RNA inverse folding problem aims to identify nucleotide sequences that preferentially adopt a given target secondary structure. While various heuristic and machine learning-based approaches have been proposed, many require a large number of sequence evaluations, which limits their applicability when experimental validation is costly. We propose a method to solve the problem using a factorization machine with quadratic-optimization annealing (FMQA). FMQA is a discrete black-box optimization method reported to obtain high-quality solutions with a limited number of evaluations. Applying FMQA to the problem requires converting nucleotides into binary variables. However, the influence of integer-to-nucleotide assignments and binary-integer encoding on the performance of FMQA has not been thoroughly investigated, even though such choices determine the structure of the surrogate model and the search landscape, and thus can directly affect solution quality. Therefore, this study aims both to establish a novel FMQA framework for RNA inverse folding and to analyze the effects of these assignments and encoding methods. We evaluated all 24 possible assignments of the four nucleotides to the ordered integers (0-3), in combination with four binary-integer encoding methods. Our results demonstrated that one-hot and domain-wall encodings outperform binary and unary encodings in terms of the normalized ensemble defect value. In domain-wall encoding, nucleotides assigned to the boundary integers (0 and 3) appeared with higher frequency. In the RNA inverse folding problem, assigning guanine and cytosine to these boundary integers promoted their enrichment in stem regions, which led to more thermodynamically stable secondary structures than those obtained with one-hot encoding.",
        "keywords": [
          "cs.LG",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16643v1",
        "authors": [
          "Shuta Kikuchi",
          "Shu Tanaka"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optimization Annealing",
        "Factorization Machine",
        "Integer Encoding",
        "Machine Learning",
        "Inverse Folding",
        "Framework",
        "FMQA",
        "RNA",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.422069"
    },
    {
      "id": "arxiv-2602.16642v1",
      "title": "Optimizer choice matters for the emergence of Neural Collapse",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16642v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Neural Collapse (NC) refers to the emergence of highly symmetric geometric structures in the representations of deep neural networks during the terminal phase of training. Despite its prevalence, the theoretical understanding of NC remains limited. Existing analyses largely ignore the role of the optimizer, thereby suggesting that NC is universal across optimization methods. In this work, we challenge this assumption and demonstrate that the choice of optimizer plays a critical role in the emergence of NC. The phenomenon is typically quantified through NC metrics, which, however, are difficult to track and analyze theoretically. To overcome this limitation, we introduce a novel diagnostic metric, NC0, whose convergence to zero is a necessary condition for NC. Using NC0, we provide theoretical evidence that NC cannot emerge under decoupled weight decay in adaptive optimizers, as implemented in AdamW. Concretely, we prove that SGD, SignGD with coupled weight decay (a special case of Adam), and SignGD with decoupled weight decay (a special case of AdamW) exhibit qualitatively different NC0 dynamics. Also, we show the accelerating effect of momentum on NC (beyond convergence of train loss) when trained with SGD, being the first result concerning momentum in the context of NC. Finally, we conduct extensive empirical experiments consisting of 3,900 training runs across various datasets, architectures, optimizers, and hyperparameters, confirming our theoretical results. This work provides the first theoretical explanation for optimizer-dependent emergence of NC and highlights the overlooked role of weight-decay coupling in shaping the implicit biases of optimizers.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16642v1",
        "authors": [
          "Jim Zhao",
          "Tin Sum Cheng",
          "Wojciech Masarczyk",
          "Aurelien Lucchi"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Collapse Neural Collapse",
        "Neural Network",
        "SGD",
        "MIT",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.422512"
    },
    {
      "id": "arxiv-2602.16640v1",
      "title": "Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16640v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The rapid proliferation of Large Language Models (LLMs) has revolutionized Natural Language Processing (NLP) but has simultaneously created a \"resource divide.\" State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based inference, rendering them inaccessible to practitioners in resource-constrained environments and posing significant data sovereignty risks. This paper introduces Quecto-V1, a domain-specific Small Language Model (SLM) engineered to democratize access to Indian legal intelligence. Built upon a custom configuration of the GPT-2 architecture (124 million parameters), Quecto-V1 was trained from scratch exclusively on a corpus of Indian statutes, including the Indian Penal Code (IPC), the Code of Criminal Procedure (CrPC), and the Constitution of India. Unlike generalist models, which prioritize broad world knowledge, our approach maximizes \"lexical density\" within the legal domain. Furthermore, we address the deployment bottleneck by applying post-training 8-bit quantization (GGUF format), compressing the model to a memory footprint of under 150 MB. Our empirical analysis demonstrates that Quecto-V1 achieves high fidelity in retrieving statutory definitions and penal provisions, outperforming general-purpose SLMs in domain-specific exact match tasks while running entirely offline on consumer-grade CPUs. We further present an ablation study showing that 8-bit quantization yields a 74% reduction in model size with less than 3.5% degradation in retrieval accuracy compared to full-precision baselines. These findings suggest that for specialized, high-stakes domains like law, domain-specific training coupled with aggressive quantization offers a viable, privacy-preserving alternative to monolithic cloud models.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16640v1",
        "authors": [
          "Subrit Dikshit"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantized Small Language Models",
        "Natural Language Processing",
        "Large Language Models",
        "Small Language Model",
        "Criminal Procedure",
        "Empirical Analysis",
        "Indian Penal Code",
        "GPT-2",
        "Intel",
        "GGUF",
        "LLM",
        "GPT",
        "NLP",
        "IPC",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.422949"
    },
    {
      "id": "arxiv-2602.16639v1",
      "title": "AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16639v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Evaluating the social intelligence of Large Language Models (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across frontier models, AREG enables joint evaluation of offensive (persuasion) and defensive (resistance) capabilities within a single interactional framework. Our analysis provides evidence that these capabilities are weakly correlated ($ρ= 0.33$) and empirically dissociated: strong persuasive performance does not reliably predict strong resistance, and vice versa. Across all evaluated models, resistance scores exceed persuasion scores, indicating a systematic defensive advantage in adversarial dialogue settings. Further linguistic analysis suggests that interaction structure plays a central role in these outcomes. Incremental commitment-seeking strategies are associated with higher extraction success, while verification-seeking responses are more prevalent in successful defenses than explicit refusal. Together, these findings indicate that social influence in LLMs is not a monolithic capability and that evaluation frameworks focusing on persuasion alone may overlook asymmetric behavioral vulnerabilities.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16639v1",
        "authors": [
          "Adib Sakhawat",
          "Fardeen Sadab"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adversarial Resource Extraction Game",
        "Large Language Models Evaluating",
        "Evaluating Persuasion",
        "Large Language Models",
        "Framework",
        "Intel",
        "AREG",
        "LLM",
        "Act",
        "MIT",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.423771"
    },
    {
      "id": "arxiv-2602.16634v1",
      "title": "Enhanced Diffusion Sampling: Efficient Rare Event Sampling and Free Energy Calculation with Diffusion Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16634v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The rare-event sampling problem has long been the central limiting factor in molecular dynamics (MD), especially in biomolecular simulation. Recently, diffusion models such as BioEmu have emerged as powerful equilibrium samplers that generate independent samples from complex molecular distributions, eliminating the cost of sampling rare transition events. However, a sampling problem remains when computing observables that rely on states which are rare in equilibrium, for example folding free energies. Here, we introduce enhanced diffusion sampling, enabling efficient exploration of rare-event regions while preserving unbiased thermodynamic estimators. The key idea is to perform quantitatively accurate steering protocols to generate biased ensembles and subsequently recover equilibrium statistics via exact reweighting. We instantiate our framework in three algorithms: UmbrellaDiff (umbrella sampling with diffusion models), $Δ$G-Diff (free-energy differences via tilted ensembles), and MetaDiff (a batchwise analogue for metadynamics). Across toy systems, protein folding landscapes and folding free energies, our methods achieve fast, accurate, and scalable estimation of equilibrium properties within GPU-minutes to hours per system -- closing the rare-event sampling gap that remained after the advent of diffusion-model equilibrium samplers.",
        "keywords": [
          "stat.ML",
          "cs.AI",
          "cs.LG",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16634v1",
        "authors": [
          "Yu Xie",
          "Ludwig Winkler",
          "Lixin Sun",
          "Sarah Lewis",
          "Adam E. Foster"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.AI",
          "cs.LG",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Rare Event Sampling",
        "Enhanced Diffusion Sampling",
        "Free Energy Calculation",
        "Framework",
        "Protocol",
        "Fusion",
        "Meta",
        "GPU",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.424572"
    },
    {
      "id": "arxiv-2602.16629v1",
      "title": "Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16629v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16629v1",
        "authors": [
          "Ethan Blaser",
          "Jiuqi Wang",
          "Shangtong Zhang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Differential Temporal Difference Learning",
        "Average Reward Markov Decision",
        "Almost Sure Convergence",
        "Standard",
        "Policy",
        "Act",
        "MIT",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.424861"
    },
    {
      "id": "arxiv-2602.16626v1",
      "title": "A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16626v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16626v1",
        "authors": [
          "SungJun Cho",
          "Chetan Gohil",
          "Rukuang Huang",
          "Oiwi Parker Jones",
          "Mark W. Woolrich"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "q-bio.NC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Tokenization Strategies",
        "Foundation Models Recent",
        "Systematic Evaluation",
        "Transformer",
        "OHBA",
        "NSF",
        "Act",
        "MEG",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.425224"
    },
    {
      "id": "arxiv-2602.16612v1",
      "title": "Causal and Compositional Abstraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16612v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Abstracting from a low level to a more explanatory high level of description, and ideally while preserving causal structure, is fundamental to scientific practice, to causal inference problems, and to robust, efficient and interpretable AI. We present a general account of abstractions between low and high level models as natural transformations, focusing on the case of causal models. This provides a new formalisation of causal abstraction, unifying several notions in the literature, including constructive causal abstraction, Q-$τ$ consistency, abstractions based on interchange interventions, and `distributed' causal abstractions. Our approach is formalised in terms of category theory, and uses the general notion of a compositional model with a given set of queries and semantics in a monoidal, cd- or Markov category; causal models and their queries such as interventions being special cases. We identify two basic notions of abstraction: downward abstractions mapping queries from high to low level; and upward abstractions, mapping concrete queries such as Do-interventions from low to high. Although usually presented as the latter, we show how common causal abstractions may, more fundamentally, be understood in terms of the former. Our approach also leads us to consider a new stronger notion of `component-level' abstraction, applying to the individual components of a model. In particular, this yields a novel, strengthened form of constructive causal abstraction at the mechanism-level, for which we prove characterisation results. Finally, we show that abstraction can be generalised to further compositional models, including those with a quantum semantics implemented by quantum circuits, and we take first steps in exploring abstractions between quantum compositional circuit models and high-level classical causal models as a means to explainable quantum AI.",
        "keywords": [
          "cs.LO",
          "cs.AI",
          "math.CT",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16612v1",
        "authors": [
          "Robin Lorenz",
          "Sean Tull"
        ],
        "arxiv_categories": [
          "cs.LO",
          "cs.AI",
          "math.CT",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Compositional Abstraction Abstracting",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.426134"
    },
    {
      "id": "arxiv-2602.16611v1",
      "title": "Style-Aware Gloss Control for Generative Non-Photorealistic Rendering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16611v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Humans can infer material characteristics of objects from their visual appearance, and this ability extends to artistic depictions, where similar perceptual strategies guide the interpretation of paintings or drawings. Among the factors that define material appearance, gloss, along with color, is widely regarded as one of the most important, and recent studies indicate that humans can perceive gloss independently of the artistic style used to depict an object. To investigate how gloss and artistic style are represented in learned models, we train an unsupervised generative model on a newly curated dataset of painterly objects designed to systematically vary such factors. Our analysis reveals a hierarchical latent space in which gloss is disentangled from other appearance factors, allowing for a detailed study of how gloss is represented and varies across artistic styles. Building on this representation, we introduce a lightweight adapter that connects our style- and gloss-aware latent space to a latent-diffusion model, enabling the synthesis of non-photorealistic images with fine-grained control of these factors. We compare our approach with previous models and observe improved disentanglement and controllability of the learned factors.",
        "keywords": [
          "cs.GR",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16611v1",
        "authors": [
          "Santiago Jimenez-Navarro",
          "Belen Masia",
          "Ana Serrano"
        ],
        "arxiv_categories": [
          "cs.GR",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Photorealistic Rendering Humans",
        "Aware Gloss Control",
        "Generative Non",
        "Fusion",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.426425"
    },
    {
      "id": "arxiv-2602.16610v1",
      "title": "Who can we trust? LLM-as-a-jury for Comparative Assessment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16610v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models (LLMs) are increasingly applied as automatic evaluators for natural language generation assessment often using pairwise comparative judgements. Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment probabilities may be biased and inconsistent. Furthermore, human-labelled supervision for judge calibration may be unavailable. We first empirically demonstrate that inconsistencies in LLM comparison probabilities exist and show that it limits the effectiveness of direct probability-based ranking. To address this, we study the LLM-as-a-jury setting and propose BT-sigma, a judge-aware extension of the Bradley-Terry model that introduces a discriminator parameter for each judge to jointly infer item rankings and judge reliability from pairwise comparisons alone. Experiments on benchmark NLG evaluation datasets show that BT-sigma consistently outperforms averaging-based aggregation methods, and that the learned discriminator strongly correlates with independent measures of the cycle consistency of LLM judgments. Further analysis reveals that BT-sigma can be interpreted as an unsupervised calibration mechanism that improves aggregation by modelling judge reliability.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16610v1",
        "authors": [
          "Mengjie Qian",
          "Guangzhi Sun",
          "Mark J. F. Gales",
          "Kate M. Knill"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Comparative Assessment Large",
        "NLG",
        "LLM",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.426720"
    },
    {
      "id": "arxiv-2602.16609v1",
      "title": "ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16609v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Current state-of-the-art multi-vector models are obtained through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully ColBERT-pre-trained model, ColBERT-Zero, trained only on public data, outperforms GTE-ModernColBERT as well as its base model, GTE-ModernBERT, which leverages closed and much stronger data, setting new state-of-the-art for model this size. We also find that, although performing only a small KD step is not enough to achieve results close to full pre-training, adding a supervised step beforehand allows to achieve much closer performance while skipping the most costly unsupervised phase. Finally, we find that aligning the fine-tuning and pre-training setups is crucial when repurposing existing models. To enable exploration of our results, we release various checkpoints as well as code used to train them.",
        "keywords": [
          "cs.CL",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16609v1",
        "authors": [
          "Antoine Chaffin",
          "Luca Arnaboldi",
          "Amélie Chatelain",
          "Florent Krzakala"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Knowledge Distillation",
        "Or Not To Pre",
        "To Pre",
        "BERT",
        "GTE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.426976"
    },
    {
      "id": "arxiv-2602.16608v1",
      "title": "Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16608v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \\textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16608v1",
        "authors": [
          "Melkamu Abay Mersha",
          "Jugal Kalita"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Explaining Transformer Models Transformer",
        "Wise Integrated Gradients",
        "Integrated Gradients",
        "Masked Autoencoder",
        "Transformer",
        "Aware Layer",
        "Framework",
        "BERT",
        "XLM",
        "NSF",
        "Act",
        "MIT",
        "LIG",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.427363"
    },
    {
      "id": "arxiv-2602.16607v1",
      "title": "CitiLink-Summ: Summarization of Discussion Subjects in European Portuguese Municipal Meeting Minutes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16607v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Municipal meeting minutes are formal records documenting the discussions and decisions of local government, yet their content is often lengthy, dense, and difficult for citizens to navigate. Automatic summarization can help address this challenge by producing concise summaries for each discussion subject. Despite its potential, research on summarizing discussion subjects in municipal meeting minutes remains largely unexplored, especially in low-resource languages, where the inherent complexity of these documents adds further challenges. A major bottleneck is the scarcity of datasets containing high-quality, manually crafted summaries, which limits the development and evaluation of effective summarization models for this domain. In this paper, we present CitiLink-Summ, a new corpus of European Portuguese municipal meeting minutes, comprising 100 documents and 2,322 manually hand-written summaries, each corresponding to a distinct discussion subject. Leveraging this dataset, we establish baseline results for automatic summarization in this domain, employing state-of-the-art generative models (e.g., BART, PRIMERA) as well as large language models (LLMs), evaluated with both lexical and semantic metrics such as ROUGE, BLEU, METEOR, and BERTScore. CitiLink-Summ provides the first benchmark for municipal-domain summarization in European Portuguese, offering a valuable resource for advancing NLP research on complex administrative texts.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16607v1",
        "authors": [
          "Miguel Marques",
          "Ana Luísa Fernandes",
          "Ana Filipa Pacheco",
          "Rute Rebouças",
          "Inês Cantante"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "European Portuguese Municipal Meeting",
        "Discussion Subjects",
        "European Portuguese",
        "Minutes Municipal",
        "METEOR",
        "ROUGE",
        "BERT",
        "BART",
        "BLEU",
        "NIST",
        "LLM",
        "NLP",
        "MIT",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.427697"
    },
    {
      "id": "arxiv-2602.16603v1",
      "title": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16603v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The growing demand for large language models (LLMs) requires serving systems to handle many concurrent requests with diverse service level objectives (SLOs). This exacerbates head-of-line (HoL) blocking during the compute-intensive prefill phase, where long-running requests monopolize resources and delay higher-priority ones, leading to widespread time-to-first-token (TTFT) SLO violations. While chunked prefill enables interruptibility, it introduces an inherent trade-off between responsiveness and throughput: reducing chunk size improves response latency but degrades computational efficiency, whereas increasing chunk size maximizes throughput but exacerbates blocking. This necessitates an adaptive preemption mechanism. However, dynamically balancing execution granularity against scheduling overheads remains a key challenge. In this paper, we propose FlowPrefill, a TTFT-goodput-optimized serving system that resolves this conflict by decoupling preemption granularity from scheduling frequency. To achieve adaptive prefill scheduling, FlowPrefill introduces two key innovations: 1) Operator-Level Preemption, which leverages operator boundaries to enable fine-grained execution interruption without the efficiency loss associated with fixed small chunking; and 2) Event-Driven Scheduling, which triggers scheduling decisions only upon request arrival or completion events, thereby supporting efficient preemption responsiveness while minimizing control-plane overhead. Evaluation on real-world production traces shows that FlowPrefill improves maximum goodput by up to 5.6$\\times$ compared to state-of-the-art systems while satisfying heterogeneous SLOs.",
        "keywords": [
          "cs.DC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16603v1",
        "authors": [
          "Chia-chi Hsieh",
          "Zan Zong",
          "Xinyang Chen",
          "Jianjiang Li",
          "Jidong Zhai"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Prefill Scheduling Granularity",
        "Decoupling Preemption",
        "Driven Scheduling",
        "Level Preemption",
        "Mitigate Head",
        "Line Blocking",
        "TTFT",
        "LLM",
        "MIT",
        "SLO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.428057"
    },
    {
      "id": "arxiv-2602.16601v1",
      "title": "Error Propagation and Model Collapse in Diffusion Models: A Theoretical Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16601v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Machine learning models are increasingly trained or fine-tuned on synthetic data. Recursively training on such data has been observed to significantly degrade performance in a wide range of tasks, often characterized by a progressive drift away from the target distribution. In this work, we theoretically analyze this phenomenon in the setting of score-based diffusion models. For a realistic pipeline where each training round uses a combination of synthetic data and fresh samples from the target distribution, we obtain upper and lower bounds on the accumulated divergence between the generated and target distributions. This allows us to characterize different regimes of drift, depending on the score estimation error and the proportion of fresh data used in each generation. We also provide empirical results on synthetic data and images to illustrate the theory.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16601v1",
        "authors": [
          "Nail B. Khelifa",
          "Richard E. Turner",
          "Ramji Venkataramanan"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Error Propagation",
        "Machine Learning",
        "Diffusion Models",
        "Model Collapse",
        "Fusion",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.428270"
    },
    {
      "id": "arxiv-2602.16600v1",
      "title": "Predicting The Cop Number Using Machine Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16600v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cops and Robbers is a pursuit evasion game played on a graph, first introduced independently by Quilliot \\cite{quilliot1978jeux} and Nowakowski and Winkler \\cite{NOWAKOWSKI1983235} over four decades ago. A main interest in recent the literature is identifying the cop number of graph families. The cop number of a graph, $c(G)$, is defined as the minimum number of cops required to guarantee capture of the robber. Determining the cop number is computationally difficult and exact algorithms for this are typically restricted to small graph families. This paper investigates whether classical machine learning methods and graph neural networks can accurately predict a graph's cop number from its structural properties and identify which properties most strongly influence this prediction. Of the classical machine learning models, tree-based models achieve high accuracy in prediction despite class imbalance, whereas graph neural networks achieve comparable results without explicit feature engineering. The interpretability analysis shows that the most predictive features are related to node connectivity, clustering, clique structure, and width parameters, which aligns with known theoretical results. Our findings suggest that machine learning approaches can be used in complement with existing cop number algorithms by offering scalable approximations where computation is infeasible.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16600v1",
        "authors": [
          "Meagan Mann",
          "Christian Muise",
          "Erin Meger"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Using Machine Learning Cops",
        "Machine Learning",
        "Neural Network",
        "IoT",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.428579"
    },
    {
      "id": "arxiv-2602.16596v1",
      "title": "Sequential Membership Inference Attacks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16596v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Modern AI models are not static. They go through multiple updates in their lifecycles. Thus, exploiting the model dynamics to create stronger Membership Inference (MI) attacks and tighter privacy audits are timely questions. Though the literature empirically shows that using a sequence of model updates can increase the power of MI attacks, rigorous analysis of the `optimal' MI attacks is limited to static models with infinite samples. Hence, we develop an `optimal' MI attack, SeMI*, that uses the sequence of model updates to identify the presence of a target inserted at a certain update step. For the empirical mean computation, we derive the optimal power of SeMI*, while accessing a finite number of samples with or without privacy. Our results retrieve the existing asymptotic analysis. We observe that having access to the model sequence avoids the dilution of MI signals unlike the existing attacks on the final model, where the MI signal vanishes as training data accumulates. Furthermore, an adversary can use SeMI* to tune both the insertion time and the canary to yield tighter privacy audits. Finally, we conduct experiments across data distributions and models trained or fine-tuned with DP-SGD demonstrating that practical variants of SeMI* lead to tighter privacy audits than the baselines.",
        "keywords": [
          "cs.LG",
          "cs.CR",
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16596v1",
        "authors": [
          "Thomas Michel",
          "Debabrota Basu",
          "Emilie Kaufmann"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CR",
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sequential Membership Inference Attacks",
        "Membership Inference",
        "SGD",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.428867"
    },
    {
      "id": "arxiv-2602.16590v1",
      "title": "A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16590v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16590v1",
        "authors": [
          "Qi You",
          "Yitai Cheng",
          "Zichao Zeng",
          "James Haworth"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Contrastive Learning Framework Empowered",
        "View Image Classification Street",
        "Feature Adaptation",
        "Framework",
        "CLIP",
        "MLP",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.429147"
    },
    {
      "id": "arxiv-2602.16585v1",
      "title": "DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16585v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses this gap through the relational workflow model: tables represent workflow steps, rows represent artifacts, foreign keys prescribe execution order. The schema specifies not only what data exists but how it is derived -- a single formal system where data structure, computational dependencies, and integrity constraints are all queryable, enforceable, and machine-readable. Four technical innovations extend this foundation: object-augmented schemas integrating relational metadata with scalable object storage, semantic matching using attribute lineage to prevent erroneous joins, an extensible type system for domain-specific formats, and distributed job coordination designed for composability with external orchestration. By unifying data structure, data, and computational transformations, DataJoint creates a substrate for SciOps where agents can participate in scientific workflows without risking data corruption.",
        "keywords": [
          "cs.DB",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16585v1",
        "authors": [
          "Dimitri Yatsenko",
          "Thinh T. Nguyen"
        ],
        "arxiv_categories": [
          "cs.DB",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agentic Scientific Workflows Operational",
        "Computational Substrate",
        "Meta",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.429411"
    },
    {
      "id": "arxiv-2602.16579v1",
      "title": "AIFL: A Global Daily Streamflow Forecasting Model Using Deterministic LSTM Pre-trained on ERA5-Land and Fine-tuned on IFS",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16579v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Reliable global streamflow forecasting is essential for flood preparedness and water resource management, yet data-driven models often suffer from a performance gap when transitioning from historical reanalysis to operational forecast products. This paper introduces AIFL (Artificial Intelligence for Floods), a deterministic LSTM-based model designed for global daily streamflow forecasting. Trained on 18,588 basins curated from the CARAVAN dataset, AIFL utilises a novel two-stage training strategy to bridge the reanalysis-to-forecast domain shift. The model is first pre-trained on 40 years of ERA5-Land reanalysis (1980-2019) to capture robust hydrological processes, then fine-tuned on operational Integrated Forecasting System (IFS) control forecasts (2016-2019) to adapt to the specific error structures and biases of operational numerical weather prediction. To our knowledge, this is the first global model trained end-to-end within the CARAVAN ecosystem. On an independent temporal test set (2021-2024), AIFL achieves high predictive skill with a median modified Kling-Gupta Efficiency (KGE') of 0.66 and a median Nash-Sutcliffe Efficiency (NSE) of 0.53. Benchmarking results show that AIFL is highly competitive with current state-of-the-art global systems, achieving comparable accuracy while maintaining a transparent and reproducible forcing pipeline. The model demonstrates exceptional reliability in extreme-event detection, providing a streamlined and operationally robust baseline for the global hydrological community.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16579v1",
        "authors": [
          "Maria Luisa Taccari",
          "Kenza Tazi",
          "Oisín M. Morrison",
          "Andreas Grafberger",
          "Juan Colonese"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Global Daily Streamflow Forecasting",
        "Integrated Forecasting System",
        "Model Using Deterministic",
        "Artificial Intelligence",
        "Sutcliffe Efficiency",
        "Gupta Efficiency",
        "Intel",
        "AIFL",
        "LSTM",
        "NIST",
        "EPA",
        "IFS",
        "KGE",
        "NSE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.429764"
    },
    {
      "id": "arxiv-2602.16578v1",
      "title": "Creating a digital poet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16578v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.",
        "keywords": [
          "cs.AI",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16578v1",
        "authors": [
          "Vered Tohar",
          "Tsahi Hayat",
          "Amir Leshem"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.429985"
    },
    {
      "id": "arxiv-2602.16573v1",
      "title": "MoDE-Boost: Boosting Shared Mobility Demand with Edge-Ready Prediction Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16573v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Urban demand forecasting plays a critical role in optimizing routing, dispatching, and congestion management within Intelligent Transportation Systems. By leveraging data fusion and analytics techniques, traffic demand forecasting serves as a key intermediate measure for identifying emerging spatial and temporal demand patterns. In this paper, we tackle this challenge by proposing two gradient boosting model variations, one for classiffication and one for regression, both capable of generating demand forecasts at various temporal horizons, from 5 minutes up to one hour. Our overall approach effectively integrates temporal and contextual features, enabling accurate predictions that are essential for improving the efficiency of shared (micro-) mobility services. To evaluate its effectiveness, we utilize open shared mobility data derived from e-scooter and e-bike networks in five metropolitan areas. These real-world datasets allow us to compare our approach with state-of-the-art methods as well as a Generative AI-based model, demonstrating its effectiveness in capturing the complexities of modern urban mobility. Ultimately, our methodology offers novel insights on urban micro-mobility management, helping to tackle the challenges arising from rapid urbanization and thus, contributing to more sustainable, efficient, and livable cities.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16573v1",
        "authors": [
          "Antonios Tziorvas",
          "George S. Theodoropoulos",
          "Yannis Theodoridis"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Intelligent Transportation Systems",
        "Boosting Shared Mobility Demand",
        "Ready Prediction Models Urban",
        "Fusion",
        "Intel",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.430283"
    },
    {
      "id": "arxiv-2602.16571v1",
      "title": "Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16571v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large-scale sharing of dialogue-based data is instrumental for advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core instructional content and reduce dataset utility. This work asks how PII can be detected in math tutoring transcripts while preserving their educational utility. To address this challenge, we investigate the \"numeric ambiguity\" problem and introduce MathEd-PII, the first benchmark dataset for PII detection in math tutoring dialogues, created through a human-in-the-loop LLM workflow that audits upstream redactions and generates privacy-preserving surrogates. The dataset contains 1,000 tutoring sessions (115,620 messages; 769,628 tokens) with validated PII annotations. Using a density-based segmentation method, we show that false PII redactions are disproportionately concentrated in math-dense regions, confirming numeric ambiguity as a key failure mode. We then compare four detection strategies: a Presidio baseline and LLM-based approaches with basic, math-aware, and segment-aware prompting. Math-aware prompting substantially improves performance over the baseline (F1: 0.821 vs. 0.379) while reducing numeric false positives, demonstrating that de-identification must incorporate domain context to preserve analytic utility. This work provides both a new benchmark and evidence that utility-preserving de-identification for tutoring data requires domain-aware modeling.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16571v1",
        "authors": [
          "Zhuqian Zhou",
          "Kirk Vanacore",
          "Bakhtawar Ahtisham",
          "Jinsook Lee",
          "Doug Pietrzak"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Personally Identifiable Information",
        "Investigating Numeric Ambiguity",
        "Benchmark Dataset Large",
        "Math Tutoring",
        "Preserving De",
        "LLM",
        "PII",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.430655"
    },
    {
      "id": "arxiv-2602.16570v1",
      "title": "Steering diffusion models with quadratic rewards: a fine-grained analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16570v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Inference-time algorithms are an emerging paradigm in which pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of when these heuristics can be efficiently improved. In this paper, we consider the task of sampling from a reward-tilted diffusion model -- that is, sampling from $p^{\\star}(x) \\propto p(x) \\exp(r(x))$ -- given a reward function $r$ and pre-trained diffusion oracle for $p$. We provide a fine-grained analysis of the computational tractability of this task for quadratic rewards $r(x) = x^\\top A x + b^\\top x$. We show that linear-reward tilts are always efficiently sampleable -- a simple result that seems to have gone unnoticed in the literature. We use this as a building block, along with a conceptually new ingredient -- the Hubbard-Stratonovich transform -- to provide an efficient algorithm for sampling from low-rank positive-definite quadratic tilts, i.e. $r(x) = x^\\top A x$ where $A$ is positive-definite and of rank $O(1)$. For negative-definite tilts, i.e. $r(x) = - x^\\top A x$ where $A$ is positive-definite, we prove that the problem is intractable even if $A$ is of rank 1 (albeit with exponentially-large entries).",
        "keywords": [
          "cs.LG",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16570v1",
        "authors": [
          "Ankur Moitra",
          "Andrej Risteski",
          "Dhruv Rohatgi"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Oracle",
        "Fusion",
        "NSF",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.430960"
    },
    {
      "id": "arxiv-2602.16569v1",
      "title": "Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16569v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.",
        "keywords": [
          "cs.CV",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16569v1",
        "authors": [
          "Nicolò Di Domenico",
          "Annalisa Franco",
          "Matteo Ferrara",
          "Davide Maltoni"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Preserving Facial Morphing",
        "Deep Learning",
        "ONOT",
        "FEI",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.431228"
    },
    {
      "id": "arxiv-2602.16568v1",
      "title": "Separating Oblivious and Adaptive Models of Variable Selection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16568v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Sparse recovery is among the most well-studied problems in learning theory and high-dimensional statistics. In this work, we investigate the statistical and computational landscapes of sparse recovery with $\\ell_\\infty$ error guarantees. This variant of the problem is motivated by \\emph{variable selection} tasks, where the goal is to estimate the support of a $k$-sparse signal in $\\mathbb{R}^d$. Our main contribution is a provable separation between the \\emph{oblivious} (``for each'') and \\emph{adaptive} (``for all'') models of $\\ell_\\infty$ sparse recovery. We show that under an oblivious model, the optimal $\\ell_\\infty$ error is attainable in near-linear time with $\\approx k\\log d$ samples, whereas in an adaptive model, $\\gtrsim k^2$ samples are necessary for any algorithm to achieve this bound. This establishes a surprising contrast with the standard $\\ell_2$ setting, where $\\approx k \\log d$ samples suffice even for adaptive sparse recovery. We conclude with a preliminary examination of a \\emph{partially-adaptive} model, where we show nontrivial variable selection guarantees are possible with $\\approx k\\log d$ measurements.",
        "keywords": [
          "math.ST",
          "cs.DS",
          "cs.LG",
          "math.OC",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16568v1",
        "authors": [
          "Ziyun Chen",
          "Jerry Li",
          "Kevin Tian",
          "Yusong Zhu"
        ],
        "arxiv_categories": [
          "math.ST",
          "cs.DS",
          "cs.LG",
          "math.OC",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variable Selection Sparse",
        "Separating Oblivious",
        "Adaptive Models",
        "Standard",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.431465"
    },
    {
      "id": "arxiv-2602.16564v1",
      "title": "A Scalable Approach to Solving Simulation-Based Network Security Games",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16564v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.",
        "keywords": [
          "cs.LG",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16564v1",
        "authors": [
          "Michael Lanier",
          "Yevgeniy Vorobeychik"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Network Security Games",
        "Solving Simulation",
        "Scalable Approach",
        "Double Oracle",
        "Policy",
        "Oracle",
        "SOTA",
        "Meta",
        "PSRO",
        "Act",
        "LRU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.431703"
    },
    {
      "id": "arxiv-2602.16558v1",
      "title": "Illustration of Barren Plateaus in Quantum Computing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16558v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.",
        "keywords": [
          "cs.LG",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16558v1",
        "authors": [
          "Gerhard Stenzel",
          "Tobias Rohe",
          "Michael Kölle",
          "Leo Sünkel",
          "Jonas Stein"
        ],
        "arxiv_categories": [
          "cs.LG",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Computing Variational Quantum",
        "Quantum Computing",
        "Machine Learning",
        "Barren Plateaus",
        "Framework",
        "NISQ",
        "SGD",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.432014"
    },
    {
      "id": "arxiv-2602.16555v1",
      "title": "Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $α$-Potential Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16555v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We analyze independent policy-gradient (PG) learning in $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distributed policy that depends only on its own state and updates the policy independently using the gradient of its own objective. We establish global linear convergence of these methods to an equilibrium by showing that the LQ game admits an $α$-potential structure, with $α$ determined by the degree of pairwise interaction asymmetry. For pairwise-symmetric interactions, we construct an affine distributed equilibrium by minimizing the potential function and show that independent PG methods converge globally to this equilibrium, with complexity scaling linearly in the population size and logarithmically in the desired accuracy. For asymmetric interactions, we prove that independent projected PG algorithms converge linearly to an approximate equilibrium, with suboptimality proportional to the degree of asymmetry. Numerical experiments confirm the theoretical results across both symmetric and asymmetric interaction networks.",
        "keywords": [
          "math.OC",
          "cs.LG",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16555v1",
        "authors": [
          "Philipp Plank",
          "Yufei Zhang"
        ],
        "arxiv_categories": [
          "math.OC",
          "cs.LG",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quadratic Stochastic Differential Games",
        "Learning Distributed Equilibria",
        "Potential Approach We",
        "Policy",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.432537"
    },
    {
      "id": "arxiv-2602.16554v1",
      "title": "MerLean: An Agentic Framework for Autoformalization in Quantum Computation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16554v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \\LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \\LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.",
        "keywords": [
          "cs.LO",
          "cs.AI",
          "cs.ET",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16554v1",
        "authors": [
          "Yuanjie Ren",
          "Jinzheng Li",
          "Yidi Qi"
        ],
        "arxiv_categories": [
          "cs.LO",
          "cs.AI",
          "cs.ET",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Computation We",
        "An Agentic Framework",
        "Quantum Computing",
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.432746"
    },
    {
      "id": "arxiv-2602.16548v1",
      "title": "RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16548v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16548v1",
        "authors": [
          "Tianmeng Hu",
          "Yongzheng Cui",
          "Biao Luo",
          "Ke Li"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reinforcement Learning",
        "Inverse Design",
        "Deep Learning",
        "Framework",
        "Policy",
        "Fusion",
        "RIDER",
        "RNA",
        "MIT",
        "DOE",
        "GNN",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.432979"
    },
    {
      "id": "arxiv-2602.16545v1",
      "title": "Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16545v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.",
        "keywords": [
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16545v1",
        "authors": [
          "Kaiting Liu",
          "Hazel Doughty"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Grained Video Understanding Video",
        "Shot Classifier Edits",
        "Split Up",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.433210"
    },
    {
      "id": "arxiv-2602.16543v1",
      "title": "Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16543v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16543v1",
        "authors": [
          "Jialiang Fan",
          "Shixiong Jiang",
          "Mengyu Liu",
          "Fanxin Kong"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inverse Constrained Reinforcement Learning",
        "Safe Reinforcement Learning",
        "Vulnerability Analysis",
        "Framework",
        "Policy",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.433435"
    },
    {
      "id": "arxiv-2602.16537v1",
      "title": "Optimal training-conditional regret for online conformal prediction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16537v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study online conformal prediction for non-stationary data streams subject to unknown distribution drift. While most prior work studied this problem under adversarial settings and/or assessed performance in terms of gaps of time-averaged marginal coverage, we instead evaluate performance through training-conditional cumulative regret. We specifically focus on independently generated data with two types of distribution shift: abrupt change points and smooth drift. When non-conformity score functions are pretrained on an independent dataset, we propose a split-conformal style algorithm that leverages drift detection to adaptively update calibration sets, which provably achieves minimax-optimal regret. When non-conformity scores are instead trained online, we develop a full-conformal style algorithm that again incorporates drift detection to handle non-stationarity; this approach relies on stability - rather than permutation symmetry - of the model-fitting algorithm, which is often better suited to online learning under evolving environments. We establish non-asymptotic regret guarantees for our online full conformal algorithm, which match the minimax lower bound under appropriate restrictions on the prediction sets. Numerical experiments corroborate our theoretical findings.",
        "keywords": [
          "math.ST",
          "cs.IT",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16537v1",
        "authors": [
          "Jiadong Liang",
          "Zhimei Ren",
          "Yuxin Chen"
        ],
        "arxiv_categories": [
          "math.ST",
          "cs.IT",
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.433691"
    },
    {
      "id": "arxiv-2602.16531v1",
      "title": "Transfer Learning of Linear Regression with Multiple Pretrained Models: Benefiting from More Pretrained Models via Overparameterization Debiasing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16531v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study transfer learning for a linear regression task using several least-squares pretrained models that can be overparameterized. We formulate the target learning task as optimization that minimizes squared errors on the target dataset with penalty on the distance of the learned model from the pretrained models. We analytically formulate the test error of the learned target model and provide the corresponding empirical evaluations. Our results elucidate when using more pretrained models can improve transfer learning. Specifically, if the pretrained models are overparameterized, using sufficiently many of them is important for beneficial transfer learning. However, the learning may be compromised by overparameterization bias of pretrained models, i.e., the minimum $\\ell_2$-norm solution's restriction to a small subspace spanned by the training examples in the high-dimensional parameter space. We propose a simple debiasing via multiplicative correction factor that can reduce the overparameterization bias and leverage more pretrained models to learn a target predictor.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16531v1",
        "authors": [
          "Daniel Boharon",
          "Yehuda Dar"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Overparameterization Debiasing We",
        "Multiple Pretrained Models",
        "More Pretrained Models",
        "Transfer Learning",
        "Linear Regression",
        "NSF",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.433932"
    },
    {
      "id": "arxiv-2602.16530v1",
      "title": "FEKAN: Feature-Enriched Kolmogorov-Arnold Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16530v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc., suffer from high computational cost and slow convergence, limiting scalability and practical applicability. Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a simple yet effective extension that preserves all the advantages of KAN while improving computational efficiency and predictive accuracy through feature enrichment, without increasing the number of trainable parameters. By incorporating these additional features, FEKAN accelerates convergence, increases representation capacity, and substantially mitigates the computational overhead characteristic of state-of-the-art KAN architectures. We investigate FEKAN across a comprehensive set of benchmarks, including function-approximation tasks, physics-informed formulations for diverse partial differential equations (PDEs), and neural operator settings that map between input and output function spaces. For function approximation, we systematically compare FEKAN against a broad family of KAN variants, FastKAN, WavKAN, ReLUKAN, HRKAN, ChebyshevKAN, RBFKAN, and the original SplineKAN. Across all tasks, FEKAN demonstrates substantially faster convergence and consistently higher approximation accuracy than the underlying baseline architectures. We also establish the theoretical foundations for FEKAN, showing its superior representation capacity compared to KAN, which contributes to improved accuracy and efficiency.",
        "keywords": [
          "cs.LG",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16530v1",
        "authors": [
          "Sidharth S. Menon",
          "Ameya D. Jagtap"
        ],
        "arxiv_categories": [
          "cs.LG",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Arnold Networks Kolmogorov",
        "Enriched Kolmogorov",
        "Arnold Networks",
        "RBFKAN",
        "FEKAN",
        "HRKAN",
        "KAN",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.434244"
    },
    {
      "id": "arxiv-2602.16525v1",
      "title": "Capacity-constrained demand response in smart grids using deep reinforcement learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16525v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper presents a capacity-constrained incentive-based demand response approach for residential smart grids. It aims to maintain electricity grid capacity limits and prevent congestion by financially incentivising end users to reduce or shift their energy consumption. The proposed framework adopts a hierarchical architecture in which a service provider adjusts hourly incentive rates based on wholesale electricity prices and aggregated residential load. The financial interests of both the service provider and end users are explicitly considered. A deep reinforcement learning approach is employed to learn optimal real-time incentive rates under explicit capacity constraints. Heterogeneous user preferences are modelled through appliance-level home energy management systems and dissatisfaction costs. Using real-world residential electricity consumption and price data from three households, simulation results show that the proposed approach effectively reduces peak demand and smooths the aggregated load profile. This leads to an approximately 22.82% reduction in the peak-to-average ratio compared to the no-demand-response case.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16525v1",
        "authors": [
          "Shafagh Abband Pashaki",
          "Sepehr Maleki",
          "Amir Badiee"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.434474"
    },
    {
      "id": "arxiv-2602.16523v1",
      "title": "Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16523v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations \\(R_x\\), \\(R_y\\), and \\(R_z\\). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with \\(λ\\) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately \\(5\\times10^{-4}\\) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately \\(10^{-4}\\)). Both approaches reliably reconstruct computational basis states (between 83\\% and 99\\% success) and Bell states (between 61\\% and 77\\% success). However, scalability saturates for \\(λ\\) of approximately three to four and does not extend to ten-qubit targets even at \\(λ=2\\). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability.",
        "keywords": [
          "cs.LG",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16523v1",
        "authors": [
          "Gerhard Stenzel",
          "Isabella Debelic",
          "Michael Kölle",
          "Tobias Rohe",
          "Leo Sünkel"
        ],
        "arxiv_categories": [
          "cs.LG",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Parameterized Quantum State Preparation",
        "Proximal Policy Optimization",
        "Reinforcement Learning",
        "Comparative Study We",
        "Advantage Actor",
        "Using Gymnasium",
        "Policy",
        "DQCS",
        "EPA",
        "Act",
        "PPO",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.435212"
    },
    {
      "id": "arxiv-2602.16520v1",
      "title": "Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16520v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Jailbreak prompts are a practical and evolving threat to large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade single-pass guardrails. We present RLM-JB, an end-to-end jailbreak detection framework built on Recursive Language Models (RLMs), in which a root model orchestrates a bounded analysis program that transforms the input, queries worker models over covered segments, and aggregates evidence into an auditable decision. RLM-JB treats detection as a procedure rather than a one-shot classification: it normalizes and de-obfuscates suspicious inputs, chunks text to reduce context dilution and guarantee coverage, performs parallel chunk screening, and composes cross-chunk signals to recover split-payload attacks. On AutoDAN-style adversarial inputs, RLM-JB achieves high detection effectiveness across three LLM backends (ASR/Recall 92.5-98.0%) while maintaining very high precision (98.99-100%) and low false positive rates (0.0-2.0%), highlighting a practical sensitivity-specificity trade-off as the screening backend changes.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16520v1",
        "authors": [
          "Doron Shavit"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recursive Language Models",
        "Framework",
        "LLM",
        "ASR",
        "NSF",
        "Act",
        "RLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.435453"
    },
    {
      "id": "arxiv-2602.16516v1",
      "title": "Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based Classification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16516v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper introduces ParlaCAP, a large-scale dataset for analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and autonomous regions, we follow a teacher-student framework in which a high-performing large language model (LLM) annotates in-domain training data and a multilingual encoder model is fine-tuned on these annotations for scalable data annotation. We show that this approach produces a classifier tailored to the target domain. Agreement between the LLM and human annotators is comparable to inter-annotator agreement among humans, and the resulting model outperforms existing CAP classifiers trained on manually-annotated but out-of-domain data. In addition to the CAP annotations, the ParlaCAP dataset offers rich speaker and party metadata, as well as sentiment predictions coming from the ParlaSent multilingual transformer model, enabling comparative research on political attention and representation across countries. We illustrate the analytical potential of the dataset with three use cases, examining the distribution of parliamentary attention across policy topics, sentiment patterns in parliamentary speech, and gender differences in policy attention.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16516v1",
        "authors": [
          "Taja Kuzman Pungeršek",
          "Peter Rupnik",
          "Daniela Širinić",
          "Nikola Ljubešić"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Supercharging Agenda Setting Research",
        "Comparative Agendas Project",
        "Scalable Multilingual",
        "European Parliaments",
        "Transformer",
        "Agreement",
        "Framework",
        "Policy",
        "Meta",
        "LLM",
        "NSF",
        "CAP",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.435746"
    },
    {
      "id": "arxiv-2602.16512v1",
      "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16512v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16512v1",
        "authors": [
          "Felix Fricke",
          "Simon Malberg",
          "Georg Groh"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Foundation Framework",
        "Optimized Reasoning",
        "Graphs Prompting",
        "Framework",
        "Intel",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.435993"
    },
    {
      "id": "arxiv-2602.16507v1",
      "title": "Small molecule retrieval from tandem mass spectrometry: what are we optimizing for?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16507v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "One of the central challenges in the computational analysis of liquid chromatography-tandem mass spectrometry (LC-MS/MS) data is to identify the compounds underlying the output spectra. In recent years, this problem is increasingly tackled using deep learning methods. A common strategy involves predicting a molecular fingerprint vector from an input mass spectrum, which is then used to search for matches in a chemical compound database. While various loss functions are employed in training these predictive models, their impact on model performance remains poorly understood. In this study, we investigate commonly used loss functions, deriving novel regret bounds that characterize when Bayes-optimal decisions for these objectives must diverge. Our results reveal a fundamental trade-off between the two objectives of (1) fingerprint similarity and (2) molecular retrieval. Optimizing for more accurate fingerprint predictions typically worsens retrieval results, and vice versa. Our theoretical analysis shows this trade-off depends on the similarity structure of candidate sets, providing guidance for loss function and fingerprint selection.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16507v1",
        "authors": [
          "Gaetan De Waele",
          "Marek Wydmuch",
          "Krzysztof Dembczyński",
          "Wojciech Kotłowski",
          "Willem Waegeman"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deep Learning",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.436234"
    },
    {
      "id": "arxiv-2602.16505v1",
      "title": "Functional Decomposition and Shapley Interactions for Interpreting Survival Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16505v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Hazard and survival functions are natural, interpretable targets in time-to-event prediction, but their inherent non-additivity fundamentally limits standard additive explanation methods. We introduce Survival Functional Decomposition (SurvFD), a principled approach for analyzing feature interactions in machine learning survival models. By decomposing higher-order effects into time-dependent and time-independent components, SurvFD offers a previously unrecognized perspective on survival explanations, explicitly characterizing when and why additive explanations fail. Building on this theoretical decomposition, we propose SurvSHAP-IQ, which extends Shapley interactions to time-indexed functions, providing a practical estimator for higher-order, time-dependent interactions. Together, SurvFD and SurvSHAP-IQ establish an interaction- and time-aware interpretability approach for survival modeling, with broad applicability across time-to-event prediction tasks.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16505v1",
        "authors": [
          "Sophie Hanna Langbein",
          "Hubert Baniecki",
          "Fabian Fumagalli",
          "Niklas Koenen",
          "Marvin N. Wright"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interpreting Survival Models Hazard",
        "Survival Functional Decomposition",
        "Functional Decomposition",
        "Shapley Interactions",
        "Machine Learning",
        "Standard",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.436444"
    },
    {
      "id": "arxiv-2602.16503v1",
      "title": "Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16503v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generalized additive models (GAMs) offer interpretability through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model auditing. We propose \\emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs allow multiple univariate shape functions per feature, each active in different regions of the input space. These regions are defined independently for each feature as simple logical conditions (thresholds) on the features it interacts with. As a result, effects remain locally additive while varying across subregions to capture interactions. We further propose a principled distillation-based training pipeline that identifies homogeneous regions with limited interactions and fits interpretable shape functions via region-aware backfitting. Experiments on diverse classification and regression tasks show that CALMs consistently outperform GAMs and achieve accuracy comparable with GA$^2$Ms. Overall, CALMs offer a compelling trade-off between predictive accuracy and interpretability.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16503v1",
        "authors": [
          "Vasilis Gkolemis",
          "Loukas Kavouras",
          "Dimitrios Kyriakopoulos",
          "Konstantinos Tsopelas",
          "Dimitrios Rontogiannis"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Conditional Feature Effects Generalized",
        "Conditionally Additive Local Models",
        "Accurate Locally Additive Models",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.436702"
    },
    {
      "id": "arxiv-2602.16502v1",
      "title": "DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16502v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16502v1",
        "authors": [
          "Zeng Tao",
          "Ying Jiang",
          "Yunuo Chen",
          "Tianyi Xie",
          "Huamin Wang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agnostic Garment Sewing Pattern",
        "Wild Images Recent",
        "Forward Pose",
        "Transformer",
        "EPA",
        "NSF",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.436976"
    },
    {
      "id": "arxiv-2602.16500v1",
      "title": "Optimizing Soft Prompt Tuning via Structural Evolution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16500v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Soft prompt tuning leverages continuous embeddings to capture task-specific information in large pre-trained language models (LLMs), achieving competitive performance in few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we propose a soft prompt tuning optimization method based on topological morphological evolution. Specifically, we employ persistent homology from topological data analysis (TDA) to quantify the structural representations of soft prompts in continuous parameter space and their training process evolution. Quantitative analysis shows that topologically stable and compact soft prompts achieve better downstream performance. Based on this empirical observation, we construct a loss function for optimizing soft prompt tuning, termed Topological Soft Prompt Loss (TSLoss). TSLoss guides the model to learn structurally stable adaptations by quantifying inter-parameter connectivity and redundancy. Extensive experiments show that training with TSLoss accelerates convergence and improves tuning performance, providing an interpretable method to understand and optimize soft prompt tuning from structural and topological perspectives.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16500v1",
        "authors": [
          "Zhenzhen Huang",
          "Chaoning Zhang",
          "Haoyu Bian",
          "Songbo Zhang",
          "Chi-lok Andy Tai"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optimizing Soft Prompt Tuning",
        "Topological Soft Prompt Loss",
        "Structural Evolution Soft",
        "LLM",
        "TDA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.437241"
    },
    {
      "id": "arxiv-2602.16498v1",
      "title": "Fast and Scalable Analytical Diffusion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16498v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is necessary, uncovering the phenomenon of Posterior Progressive Concentration: the effective golden support of the denoising score is not static but shrinks asymptotically from the global manifold to a local neighborhood as the signal-to-noise ratio increases. Capitalizing on this, we propose Dynamic Time-Aware Golden Subset Diffusion (GoldDiff), a training-free framework that decouples inference complexity from dataset size. Instead of static retrieval, GoldDiff uses a coarse-to-fine mechanism to dynamically pinpoint the ''Golden Subset'' for inference. Theoretically, we derive rigorous bounds guaranteeing that our sparse approximation converges to the exact score. Empirically, GoldDiff achieves a $\\bf 71 \\times$ speedup on AFHQ while matching or achieving even better performance than full-scan baselines. Most notably, we demonstrate the first successful scaling of analytical diffusion to ImageNet-1K, unlocking a scalable, training-free paradigm for large-scale generative modeling.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16498v1",
        "authors": [
          "Xinyi Shang",
          "Peng Sun",
          "Jingyu Lin",
          "Zhiqiang Shen"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Analytical Diffusion Analytical",
        "Posterior Progressive Concentration",
        "Aware Golden Subset Diffusion",
        "Golden Subset",
        "Dynamic Time",
        "Framework",
        "Standard",
        "Fusion",
        "AFHQ",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.437532"
    },
    {
      "id": "arxiv-2602.16494v1",
      "title": "Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16494v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16494v1",
        "authors": [
          "Alexis Winter",
          "Jean-Vincent Martini",
          "Romaric Audigier",
          "Angelique Loesch",
          "Bertrand Luvison"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Benchmarking Adversarial Robustness",
        "Adversarial Training Strategies",
        "Convolutional Neural Networks",
        "Object Detection Object",
        "Vision Transformers",
        "Autonomous Vehicle",
        "Neural Network",
        "Transformer",
        "Framework",
        "Standard",
        "Robot",
        "NSF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.437854"
    },
    {
      "id": "arxiv-2602.16493v1",
      "title": "MMA: Multimodal Memory Agent",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16493v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often surfaces stale, low-credibility, or conflicting items, which can trigger overconfident errors. We propose Multimodal Memory Agent (MMA), which assigns each retrieved memory item a dynamic reliability score by combining source credibility, temporal decay, and conflict-aware network consensus, and uses this signal to reweight evidence and abstain when support is insufficient. We also introduce MMA-Bench, a programmatically generated benchmark for belief dynamics with controlled speaker reliability and structured text-vision contradictions. Using this framework, we uncover the \"Visual Placebo Effect\", revealing how RAG-based agents inherit latent visual biases from foundation models. On FEVER, MMA matches baseline accuracy while reducing variance by 35.2% and improving selective utility; on LoCoMo, a safety-oriented configuration improves actionable accuracy and reduces wrong answers; on MMA-Bench, MMA reaches 41.18% Type-B accuracy in Vision mode, while the baseline collapses to 0.0% under the same protocol. Code: https://github.com/AIGeeksGroup/MMA.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16493v1",
        "authors": [
          "Yihao Lu",
          "Wanru Cheng",
          "Zeyu Zhang",
          "Hao Tang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Memory Agent Long",
        "Multimodal Memory Agent",
        "Visual Placebo Effect",
        "Framework",
        "Protocol",
        "FEVER",
        "MMA",
        "Act",
        "RAG",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.438087"
    },
    {
      "id": "arxiv-2602.16490v1",
      "title": "From Growing to Looping: A Unified View of Iterative Computation in LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16490v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring patterns aligned with the looped or grown block. These shared signatures support the view that their gains stem from a common form of iterative computation. Building on this connection, we show that the two techniques are adaptable and composable: applying inference-time looping to the middle blocks of a depth-grown model improves accuracy on some reasoning primitives by up to $2\\times$, despite the model never being trained to loop. Both approaches also adapt better than the baseline when given more in-context examples or additional supervised fine-tuning data. Additionally, depth-grown models achieve the largest reasoning gains when using higher-quality, math-heavy cooldown mixtures, which can be further boosted by adapting a middle block to loop. Overall, our results position depth growth and looping as complementary, practical methods for inducing and scaling iterative computation to improve reasoning.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16490v1",
        "authors": [
          "Ferdinand Kapl",
          "Emmanouil Angelis",
          "Kaitlin Maile",
          "Johannes von Oswald",
          "Stefan Bauer"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Iterative Computation",
        "From Growing",
        "Unified View",
        "NIST",
        "LLM",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.438352"
    },
    {
      "id": "arxiv-2602.16488v1",
      "title": "Learning to Learn from Language Feedback with Social Meta-Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16488v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models (LLMs) often struggle to learn from corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning (SML) in humans - the process of learning how to learn from others. We formulate SML as a finetuning methodology, training LLMs to solicit and learn from language feedback in simulated pedagogical dialogues, where static tasks are converted into interactive social learning problems. SML effectively teaches models to use conversation to solve problems they are unable to solve in a single turn. This capability generalises across domains; SML on math problems produces models that better use feedback to solve coding problems and vice versa. Furthermore, despite being trained only on fully-specified problems, these models are better able to solve underspecified tasks where critical information is revealed over multiple turns. When faced with this ambiguity, SML-trained models make fewer premature answer attempts and are more likely to ask for the information they need. This work presents a scalable approach to developing AI systems that effectively learn from language feedback.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16488v1",
        "authors": [
          "Jonathan Cook",
          "Diego Antognini",
          "Martin Klissarov",
          "Claudiu Musat",
          "Edward Grefenstette"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Language Feedback",
        "Learning Large",
        "Social Meta",
        "Meta",
        "LLM",
        "SML",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.438628"
    },
    {
      "id": "arxiv-2602.16485v1",
      "title": "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16485v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16485v1",
        "authors": [
          "Jeffrey T. H. Wong",
          "Zixi Zhang",
          "Junyi Liu",
          "Yiren Zhao"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Orchestrated Tool Calling Existing",
        "Agentic Systems",
        "Efficient Test",
        "Agent Systems",
        "Framework",
        "Protocol",
        "MAS",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.438867"
    },
    {
      "id": "arxiv-2602.16481v1",
      "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16481v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.",
        "keywords": [
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16481v1",
        "authors": [
          "Zihao Li",
          "Fabrizio Russo"
        ],
        "arxiv_categories": [
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Leveraging Large Language Models",
        "Causal Assumption",
        "Causal Discovery",
        "Approach Causal",
        "Framework",
        "Standard",
        "Protocol",
        "LLM",
        "ABA",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.439087"
    },
    {
      "id": "arxiv-2602.16476v1",
      "title": "Learning Preference from Observed Rankings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16476v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Estimating consumer preferences is central to many problems in economics and marketing. This paper develops a flexible framework for learning individual preferences from partial ranking information by interpreting observed rankings as collections of pairwise comparisons with logistic choice probabilities. We model latent utility as the sum of interpretable product attributes, item fixed effects, and a low-rank user-item factor structure, enabling both interpretability and information sharing across consumers and items. We further correct for selection in which comparisons are observed: a comparison is recorded only if both items enter the consumer's consideration set, inducing exposure bias toward frequently encountered items. We model pair observability as the product of item-level observability propensities and estimate these propensities with a logistic model for the marginal probability that an item is observable. Preference parameters are then estimated by maximizing an inverse-probability-weighted (IPW), ridge-regularized log-likelihood that reweights observed comparisons toward a target comparison population. To scale computation, we propose a stochastic gradient descent (SGD) algorithm based on inverse-probability resampling, which draws comparisons in proportion to their IPW weights. In an application to transaction data from an online wine retailer, the method improves out-of-sample recommendation performance relative to a popularity-based benchmark, with particularly strong gains in predicting purchases of previously unconsumed products.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16476v1",
        "authors": [
          "Yu-Chang Chen",
          "Chen Chian Fuh",
          "Shang En Tsai"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Observed Rankings Estimating",
        "Learning Preference",
        "Framework",
        "SGD",
        "Act",
        "IPW",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.439358"
    },
    {
      "id": "arxiv-2602.16473v1",
      "title": "Synthesis and Verification of Transformer Programs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16473v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).",
        "keywords": [
          "cs.LG",
          "cs.FL",
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16473v1",
        "authors": [
          "Hongjian Jiang",
          "Matthew Hague",
          "Philipp Rümmer",
          "Anthony Widjaja Lin"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.FL",
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Transformer Programs",
        "Transformer",
        "RASP",
        "NSF",
        "SMT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.439532"
    },
    {
      "id": "arxiv-2602.16469v1",
      "title": "Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity Shape Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16469v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Machine-translated data is widely used in multilingual NLP, particularly when native text is scarce. However, translated text differs systematically from native text. This phenomenon is known as translationese, and it reflects both traces of the source language and characteristic properties of translation itself. In this paper, we study how training on machine-translated data affects small English language models, focusing on how translationese from different source languages shapes linguistic acceptability judgments and language modelling for different domains. We train models on English text translated from 24 typologically and resource-diverse source languages, enabling a systematic analysis of how source language and corpus properties influence what models learn. Our results show that the source language has a clear impact on model behavior: general perplexity is more driven by the lexical diversity of the translated corpus, while grammatical performance is strongly correlated to typological similarity to English, given enough data.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16469v1",
        "authors": [
          "Jenny Kunz"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Target Syntactic Similarity Shape",
        "Translationese Shows How Lexical",
        "Learning Machine",
        "Training Models",
        "NLP",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.439740"
    },
    {
      "id": "arxiv-2602.16468v1",
      "title": "HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16468v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16468v1",
        "authors": [
          "Jung Min Choi",
          "Vijaya Krishna Yalavarthi",
          "Lars Schmidt-Thieme"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Learnable Stationary Wavelet Transform",
        "Multivariate Time Series Forecasting",
        "Hierarchical Patching Mixer",
        "Hierarchical Patching",
        "Deep Learning",
        "Framework",
        "Standard",
        "LSWT",
        "NSF",
        "MLP",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.439952"
    },
    {
      "id": "arxiv-2602.16467v1",
      "title": "IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16467v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.",
        "keywords": [
          "cs.CL",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16467v1",
        "authors": [
          "Saurabh Bharti",
          "Gaurav Azad",
          "Abhinaw Jagtap",
          "Nachiket Tapas"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bilingual Indian Educational Evaluation",
        "Framework",
        "Standard",
        "GPT-4",
        "NEET",
        "STEM",
        "UPSC",
        "LLM",
        "JEE",
        "GPT",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.440238"
    },
    {
      "id": "arxiv-2602.16456v1",
      "title": "Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16456v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. In this work, we address the gap between training with full steps with low-rank projections (SVDLoRA) and LoRA fine-tuning. We propose LoRSum, a memory-efficient subroutine that closes this gap for gradient descent by casting LoRA optimization as a proximal sub-problem and solving it efficiently with alternating least squares updates, which we prove to be an implicit block power method. We recover several recently proposed preconditioning methods for LoRA as special cases, and show that LoRSum can also be used for updating a low-rank momentum. In order to address full steps with preconditioned gradient descent, we propose a scaled variant of LoRSum that uses structured metrics such as K-FAC and Shampoo, and we show that storing the diagonal of these metrics still allows them to perform well while remaining memory-efficient. Experiments on a synthetic task, CIFAR-100, and language-model fine-tuning on GLUE, SQuAD v2, and WikiText-103, show that our method can match or improve LoRA baselines given modest compute overhead, while avoiding full-matrix SVD projections and retaining LoRA-style parameter efficiency.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16456v1",
        "authors": [
          "Abdulla Jasem Almansoori",
          "Maria Ivanova",
          "Andrey Veprikov",
          "Aleksandr Beznosikov",
          "Samuel Horváth"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Proximal Subspace Iteration",
        "Diagonal Fractional",
        "Rank Adaptation",
        "WikiText-103",
        "CIFAR-100",
        "CIFAR",
        "GLUE",
        "Act",
        "SGD",
        "SVD",
        "FAC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.440487"
    },
    {
      "id": "arxiv-2602.16455v1",
      "title": "Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16455v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16455v1",
        "authors": [
          "Jinsong Li",
          "Xiaoyi Dong",
          "Yuhang Zang",
          "Yuhang Cao",
          "Jiaqi Wang"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Accurate Chart Parsing While",
        "Language Models",
        "Guided Paradigm",
        "Chart Parsing",
        "Refine Stage",
        "Decode Stage",
        "Large Vision",
        "Visual Self",
        "MIT",
        "VSR",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.440778"
    },
    {
      "id": "arxiv-2602.16449v1",
      "title": "GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16449v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generative model evaluation commonly relies on high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we introduce Generative ICDM (GICDM), a method to correct neighborhood estimation for both real and generated data. We introduce a multi-scale extension to improve empirical behavior. Extensive experiments on synthetic and real benchmarks demonstrate that GICDM resolves hubness-induced failures, restores reliable metric behavior, and improves alignment with human judgment.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16449v1",
        "authors": [
          "Nicolas Salvy",
          "Hugues Talbot",
          "Bertrand Thirion"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Iterative Contextual Dissimilarity Measure",
        "Based Generative Model Evaluation",
        "Mitigating Hubness",
        "Reliable Distance",
        "GICDM",
        "ICDM",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.440944"
    },
    {
      "id": "arxiv-2602.16444v1",
      "title": "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16444v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16444v1",
        "authors": [
          "Yixue Zhang",
          "Kun Wu",
          "Zhi Gao",
          "Zhen Zhao",
          "Pei Ren"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Agentic Framework",
        "Framework",
        "Robot",
        "GPT",
        "Act",
        "VLA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.441244"
    },
    {
      "id": "arxiv-2602.16442v1",
      "title": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16442v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16442v1",
        "authors": [
          "Kamil Jeziorek",
          "Piotr Wzorek",
          "Krzysztof Blachut",
          "Hiroshi Nakano",
          "Manon Dampfhoffer"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "FPGA",
        "KWS",
        "SSC",
        "SHD",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.441522"
    },
    {
      "id": "arxiv-2602.16438v1",
      "title": "Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16438v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Conventional large language model (LLM) fairness alignment largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While extensively studied in machine learning, bias spillover remains critically underexplored in LLM alignment. In this work, we investigate how targeted gender alignment affects fairness across nine sensitive attributes in three state-of-the-art LLMs (Mistral 7B, Llama 3.1 8B, Qwen 2.5 7B). Using Direct Preference Optimization and the BBQ benchmark, we evaluate fairness under ambiguous and disambiguous contexts. Our findings reveal noticeable bias spillover: while aggregate results show improvements, context-aware analysis exposes significant degradations in ambiguous contexts, particularly for physical appearance ($p< 0.001$ across all models), sexual orientation, and disability status. We demonstrate that improving fairness along one attribute can inadvertently worsen disparities in others under uncertainty, highlighting the necessity of context-aware, multi-attribute fairness evaluation frameworks.",
        "keywords": [
          "cs.LG",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16438v1",
        "authors": [
          "Eva Paraschou",
          "Line Harder Clemmensen",
          "Sneha Das"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Using Direct Preference Optimization",
        "Alignment Conventional",
        "Fairness Dynamics",
        "Machine Learning",
        "Framework",
        "LLM",
        "BBQ",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.441759"
    },
    {
      "id": "arxiv-2602.16436v1",
      "title": "Learning with Locally Private Examples by Inverse Weierstrass Private Stochastic Gradient Descent",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16436v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Releasing data once and for all under noninteractive Local Differential Privacy (LDP) enables complete data reusability, but the resulting noise may create bias in subsequent analyses. In this work, we leverage the Weierstrass transform to characterize this bias in binary classification. We prove that inverting this transform leads to a bias-correction method to compute unbiased estimates of nonlinear functions on examples released under LDP. We then build a novel stochastic gradient descent algorithm called Inverse Weierstrass Private SGD (IWP-SGD). It converges to the true population risk minimizer at a rate of $\\mathcal{O}(1/n)$, with $n$ the number of examples. We empirically validate IWP-SGD on binary classification tasks using synthetic and real-world datasets.",
        "keywords": [
          "cs.LG",
          "cs.CR",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16436v1",
        "authors": [
          "Jean Dufraiche",
          "Paul Mangold",
          "Michaël Perrot",
          "Marc Tommasi"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CR",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inverse Weierstrass Private Stochastic",
        "Inverse Weierstrass Private",
        "Local Differential Privacy",
        "Gradient Descent Releasing",
        "Locally Private Examples",
        "IWP",
        "NSF",
        "Act",
        "LDP",
        "SGD",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.441930"
    },
    {
      "id": "arxiv-2602.16435v1",
      "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16435v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.",
        "keywords": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16435v1",
        "authors": [
          "Arun Vignesh Malarkkan",
          "Wangyang Ying",
          "Yanjie Fu"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.LG",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Reinforcement Learning Automated",
        "Guided Automated Feature Engineering",
        "Framework",
        "CAFE",
        "NSF",
        "Act",
        "AFE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.442215"
    },
    {
      "id": "arxiv-2602.16430v1",
      "title": "Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16430v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Designing Optical Character Recognition (OCR) systems for India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder with a strong multilingual language model and training the system end-to-end for OCR. Alternatively, we explore fine-tuning an existing OCR model, despite not being trained for the target languages. Through extensive evaluation on multilingual Indic OCR benchmarks and deployment-oriented metrics, we find that the second strategy consistently achieves better accuracy-latency trade-offs. Chitrapathak-2 achieves 3-6x speedup over its predecessor with being state-of-the-art (SOTA) in Telugu (6.69 char ANLS) and second best in the rest. In addition, we present Parichay, an independent OCR model series designed specifically for 9 Indian government documents to extract structured key fields, achieving 89.8% Exact Match score with a faster inference. Together, these systems achieve SOTA performance and provide practical guidance for building production-scale OCR pipelines in the Indian context.",
        "keywords": [
          "cs.CV",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16430v1",
        "authors": [
          "Ali Faraz",
          "Raja Kolla",
          "Ashish Kulkarni",
          "Shubham Agarwal"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Specific Systems Designing Optical",
        "Character Recognition",
        "Designing Production",
        "Language Models",
        "Chitrapathak-2",
        "Exact Match",
        "SOTA",
        "ANLS",
        "Act",
        "OCR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.442461"
    },
    {
      "id": "arxiv-2602.16429v1",
      "title": "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16429v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Agentic systems, AI architectures that autonomously execute multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a framework for replacing generative decision components in closed-set selection tasks with a compact textual-tabular classifier trained on execution traces. TabAgent (i) extracts structured schema, state, and dependency features from trajectories (TabSchema), (ii) augments coverage with schema-aligned synthetic supervision (TabSynth), and (iii) scores candidates with a lightweight classifier (TabHead). On the long-horizon AppWorld benchmark, TabAgent maintains task-level success while eliminating shortlist-time LLM calls, reducing latency by approximately 95% and inference cost by 85-91%. Beyond tool shortlisting, TabAgent generalizes to other agentic decision heads, establishing a paradigm for learned discriminative replacements of generative bottlenecks in production agent architectures.",
        "keywords": [
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16429v1",
        "authors": [
          "Ido Levy",
          "Eilam Shapira",
          "Yinon Goldshtein",
          "Avi Yaeli",
          "Nir Mashkif"
        ],
        "arxiv_categories": [
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Replacing Agentic Generative Components",
        "Textual Classifiers Agentic",
        "Framework",
        "LLM",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.442691"
    },
    {
      "id": "arxiv-2602.16424v1",
      "title": "Verifiable Semantics for Agent-to-Agent Communication",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16424v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms (\"core-guarded reasoning\") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.",
        "keywords": [
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16424v1",
        "authors": [
          "Philipp Schoenegger",
          "Matt Carlson",
          "Chris Schneider",
          "Chris Daly"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Communication Multiagent",
        "Verifiable Semantics",
        "Agreement",
        "Framework",
        "Protocol",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.442882"
    },
    {
      "id": "arxiv-2602.16422v1",
      "title": "Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16422v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.",
        "keywords": [
          "eess.IV",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16422v1",
        "authors": [
          "Ahmet Halici",
          "Ece Tugba Cebeci",
          "Musa Balci",
          "Mustafa Cini",
          "Serkan Sokmen"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Automated Histopathology Report Generation",
        "Pyramidal Feature Extraction",
        "Foundation Model Generating",
        "Vision Transformer",
        "Transformer",
        "Framework",
        "BERT",
        "UNI",
        "GPT",
        "WSI",
        "NSF",
        "Act",
        "HSV",
        "WHO",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.443094"
    },
    {
      "id": "arxiv-2602.16412v1",
      "title": "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16412v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.",
        "keywords": [
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16412v1",
        "authors": [
          "Daichi Yashima",
          "Shuhei Kurita",
          "Yusuke Oda",
          "Komei Sugiura"
        ],
        "arxiv_categories": [
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Large Language Model",
        "Refined Motion Representation",
        "Video Understanding While",
        "MLVU",
        "MLLM",
        "LLM",
        "Act",
        "RGB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.443349"
    },
    {
      "id": "arxiv-2602.16400v1",
      "title": "Easy Data Unlearning Bench",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16400v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Evaluating machine unlearning methods remains technically challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and streamlined infrastructure for running evaluations out of the box. By standardizing setup and metrics, it enables reproducible, scalable, and fair comparison across unlearning methods. We aim for this benchmark to serve as a practical foundation for accelerating research and promoting best practices in machine unlearning. Our code and data are publicly available.",
        "keywords": [
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16400v1",
        "authors": [
          "Roy Rinberg",
          "Pol Puigdemont",
          "Martin Pawelczyk",
          "Volkan Cevher"
        ],
        "arxiv_categories": [
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Easy Data Unlearning Bench",
        "Framework",
        "Standard",
        "Oracle",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.443501"
    },
    {
      "id": "arxiv-2602.16399v1",
      "title": "Multi-Channel Replay Speech Detection using Acoustic Maps",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16399v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Replay attacks remain a critical vulnerability for automatic speaker verification systems, particularly in real-time voice assistant applications. In this work, we propose acoustic maps as a novel spatial feature representation for replay speech detection from multi-channel recordings. Derived from classical beamforming over discrete azimuth and elevation grids, acoustic maps encode directional energy distributions that reflect physical differences between human speech radiation and loudspeaker-based replay. A lightweight convolutional neural network is designed to operate on this representation, achieving competitive performance on the ReMASC dataset with approximately 6k trainable parameters. Experimental results show that acoustic maps provide a compact and physically interpretable feature space for replay attack detection across different devices and acoustic environments.",
        "keywords": [
          "eess.AS",
          "cs.LG",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16399v1",
        "authors": [
          "Michael Neri",
          "Tuomas Virtanen"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.LG",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Channel Replay Speech Detection",
        "Acoustic Maps Replay",
        "Neural Network",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:46:56.443681"
    },
    {
      "id": "arxiv-2602.16712v1",
      "title": "One Hand to Rule Them All: Canonical Representations for Unified Dexterous Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16712v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Dexterous manipulation policies today largely assume fixed hand designs, severely restricting their generalization to new embodiments with varied kinematic and structural layouts. To overcome this limitation, we introduce a parameterized canonical representation that unifies a broad spectrum of dexterous hand architectures. It comprises a unified parameter space and a canonical URDF format, offering three key advantages. 1) The parameter space captures essential morphological and kinematic variations for effective conditioning in learning algorithms. 2) A structured latent manifold can be learned over our space, where interpolations between embodiments yield smooth and physically meaningful morphology transitions. 3) The canonical URDF standardizes the action space while preserving dynamic and functional properties of the original URDFs, enabling efficient and reliable cross-embodiment policy learning. We validate these advantages through extensive analysis and experiments, including grasp policy replay, VAE latent encoding, and cross-embodiment zero-shot transfer. Specifically, we train a VAE on the unified representation to obtain a compact, semantically rich latent embedding, and develop a grasping policy conditioned on the canonical representation that generalizes across dexterous hands. We demonstrate, through simulation and real-world tasks on unseen morphologies (e.g., 81.9% zero-shot success rate on 3-finger LEAP Hand), that our framework unifies both the representational and action spaces of structurally diverse hands, providing a scalable foundation for cross-hand learning toward universal dexterous manipulation.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16712v1",
        "authors": [
          "Zhenyu Wei",
          "Yunchao Yao",
          "Mingyu Ding"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Dexterous Manipulation Dexterous",
        "Canonical Representations",
        "Framework",
        "One Hand",
        "Standard",
        "Policy",
        "LEAP",
        "URDF",
        "NSF",
        "Act",
        "MIT",
        "VAE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.553764"
    },
    {
      "id": "arxiv-2602.16710v1",
      "title": "EgoScale: Scaling Dexterous Manipulation with Diverse Egocentric Human Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16710v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Human behavior is among the most scalable sources of data for learning physical intelligence, yet how to effectively leverage it for dexterous manipulation remains unclear. While prior work demonstrates human to robot transfer in constrained settings, it is unclear whether large scale human data can support fine grained, high degree of freedom dexterous manipulation. We present EgoScale, a human to dexterous manipulation transfer framework built on large scale egocentric human data. We train a Vision Language Action (VLA) model on over 20,854 hours of action labeled egocentric human video, more than 20 times larger than prior efforts, and uncover a log linear scaling law between human data scale and validation loss. This validation loss strongly correlates with downstream real robot performance, establishing large scale human data as a predictable supervision source. Beyond scale, we introduce a simple two stage transfer recipe: large scale human pretraining followed by lightweight aligned human robot mid training. This enables strong long horizon dexterous manipulation and one shot task adaptation with minimal robot supervision. Our final policy improves average success rate by 54% over a no pretraining baseline using a 22 DoF dexterous robotic hand, and transfers effectively to robots with lower DoF hands, indicating that large scale human motion provides a reusable, embodiment agnostic motor prior.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16710v1",
        "authors": [
          "Ruijie Zheng",
          "Dantong Niu",
          "Yuqi Xie",
          "Jing Wang",
          "Mengda Xu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scaling Dexterous Manipulation",
        "Diverse Egocentric Human Data",
        "Vision Language Action",
        "Framework",
        "Policy",
        "Robot",
        "Intel",
        "NSF",
        "Act",
        "VLA",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.554302"
    },
    {
      "id": "arxiv-2602.16700v1",
      "title": "The Role of Common Randomness Replication in Symmetric PIR on Graph-Based Replicated Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16700v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In symmetric private information retrieval (SPIR), a user communicates with multiple servers to retrieve from them a message in a database, while not revealing the message index to any individual server (user privacy), and learning no additional information about the database (database privacy). We study the problem of SPIR on graph-replicated database systems, where each node of the graph represents a server and each link represents a message. Each message is replicated at exactly two servers; those at which the link representing the message is incident. To ensure database privacy, the servers share a set of common randomness, independent of the database and the user's desired message index. We study two cases of common randomness distribution to the servers: i) graph-replicated common randomness, and ii) fully-replicated common randomness. Given a graph-replicated database system, in i), we assign one randomness variable independently to every pair of servers sharing a message, while in ii), we assign an identical set of randomness variable to all servers, irrespective of the underlying graph. In both settings, our goal is to characterize the SPIR capacity, i.e., the maximum number of desired message symbols retrieved per downloaded symbol, and quantify the minimum amount of common randomness required to achieve the capacity. To this goal, in setting i), we derive a general lower bound on the SPIR capacity, and show it to be tight for path and regular graphs through a matching converse. Moreover, we establish that the minimum size of common randomness required for SPIR is equal to the message size. In setting ii), the SPIR capacity improves over the first, more restrictive setting. We show this through capacity lower bounds for a class of graphs, by constructing SPIR schemes from PIR schemes.",
        "keywords": [
          "cs.IT",
          "cs.CR",
          "cs.NI",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16700v1",
        "authors": [
          "Shreya Meel",
          "Sennur Ulukus"
        ],
        "arxiv_categories": [
          "cs.IT",
          "cs.CR",
          "cs.NI",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Common Randomness Replication",
        "Based Replicated Systems In",
        "SPIR",
        "Act",
        "PIR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.554948"
    },
    {
      "id": "arxiv-2602.16686v1",
      "title": "Fast-MCS: A Scalable Open-Source Tool to Find Minimal Cut Sets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16686v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A network is represented as a graph consisting of nodes and edges. A cut set for a source-destination pair in a network is a set of elements that, when failed, cause the source-destination pair to lose connectivity. A Minimal Cut Set (MCS) is a cut set that cannot be further reduced while maintaining its status as a cut set. MCSs are crucial in identifying the critical elements in the network that have the most significant impact on failure. This work introduces Fast-MCS, an open-source, scalable tool for evaluating MCSs in large, complex networks. Additionally, we compare the computation time of Fast-MCS with the state-of-the-art.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16686v1",
        "authors": [
          "Shakthivelu Janardhanan",
          "Yaxuan Chen",
          "Wolfgang Kellerer",
          "Carmen Mas-Machuca"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Find Minimal Cut Sets",
        "Minimal Cut Set",
        "Scalable Open",
        "Source Tool",
        "Act",
        "MCS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.555207"
    },
    {
      "id": "arxiv-2602.16675v1",
      "title": "Learning to unfold cloth: Scaling up world models to deformable object manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16675v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Learning to manipulate cloth is both a paradigmatic problem for robotic research and a problem of immediate relevance to a variety of applications ranging from assistive care to the service industry. The complex physics of the deformable object makes this problem of cloth manipulation nontrivial. In order to create a general manipulation strategy that addresses a variety of shapes, sizes, fold and wrinkle patterns, in addition to the usual problems of appearance variations, it becomes important to carefully consider model structure and their implications for generalisation performance. In this paper, we present an approach to in-air cloth manipulation that uses a variation of a recently proposed reinforcement learning architecture, DreamerV2. Our implementation modifies this architecture to utilise surface normals input, in addition to modiying the replay buffer and data augmentation procedures. Taken together these modifications represent an enhancement to the world model used by the robot, addressing the physical complexity of the object being manipulated by the robot. We present evaluations both in simulation and in a zero-shot deployment of the trained policies in a physical robot setup, performing in-air unfolding of a variety of different cloth types, demonstrating the generalisation benefits of our proposed architecture.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16675v1",
        "authors": [
          "Jack Rome",
          "Stephen James",
          "Subramanian Ramamoorthy"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Robot",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.555634"
    },
    {
      "id": "arxiv-2602.16641v1",
      "title": "Towards Autonomous Robotic Kidney Ultrasound: Spatial-Efficient Volumetric Imaging via Template Guided Optimal Pivoting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16641v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Medical ultrasound (US) imaging is a frontline tool for the diagnosis of kidney diseases. However, traditional freehand imaging procedure suffers from inconsistent, operator-dependent outcomes, lack of 3D localization information, and risks of work-related musculoskeletal disorders. While robotic ultrasound (RUS) systems offer the potential for standardized, operator-independent 3D kidney data acquisition, the existing scanning methods lack the ability to determine the optimal imaging window for efficient imaging. As a result, the scan is often blindly performed with excessive probe footprint, which frequently leads to acoustic shadowing and incomplete organ coverage. Consequently, there is a critical need for a spatially efficient imaging technique that can maximize the kidney coverage through minimum probe footprint. Here, we propose an autonomous workflow to achieve efficient kidney imaging via template-guided optimal pivoting. The system first performs an explorative imaging to generate partial observations of the kidney. This data is then registered to a kidney template to estimate the organ pose. With the kidney localized, the robot executes a fixed-point pivoting sweep where the imaging plane is aligned with the kidney long axis to minimize the probe translation. The proposed method was validated in simulation and in-vivo. Simulation results indicate that a 60% exploration ratio provides optimal balance between kidney localization accuracy and scanning efficiency. In-vivo evaluation on two male subjects demonstrates a kidney localization accuracy up to 7.36 mm and 13.84 degrees. Moreover, the optimal pivoting approach shortened the probe footprint by around 75 mm when compared with the baselines. These results valid our approach of leveraging anatomical templates to align the probe optimally for volumetric sweep.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16641v1",
        "authors": [
          "Xihan Ma",
          "Haichong Zhang"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Towards Autonomous Robotic Kidney",
        "Template Guided Optimal Pivoting",
        "Efficient Volumetric Imaging",
        "Standard",
        "Robot",
        "Wind",
        "RUS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.556200"
    },
    {
      "id": "arxiv-2602.16598v1",
      "title": "Sensor Query Schedule and Sensor Noise Covariances for Accuracy-constrained Trajectory Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16598v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Trajectory estimation involves determining the trajectory of a mobile robot by combining prior knowledge about its dynamic model with noisy observations of its state obtained using sensors. The accuracy of such a procedure is dictated by the system model fidelity and the sensor parameters, such as the accuracy of the sensor (as represented by its noise covariance) and the rate at which it can generate observations, referred to as the sensor query schedule. Intuitively, high-rate measurements from accurate sensors lead to accurate trajectory estimation. However, cost and resource constraints limit the sensor accuracy and its measurement rate. Our work's novel contribution is the estimation of sensor schedules and sensor covariances necessary to achieve a specific estimation accuracy. Concretely, we focus on estimating: (i) the rate or schedule with which a sensor of known covariance must generate measurements to achieve specific estimation accuracy, and alternatively, (ii) the sensor covariance necessary to achieve specific estimation accuracy for a given sensor update rate. We formulate the problem of estimating these sensor parameters as semidefinite programs, which can be solved by off-the-shelf solvers. We validate our approach in simulation and real experiments by showing that the sensor schedules and the sensor covariances calculated using our proposed method achieve the desired trajectory estimation accuracy. Our method also identifies scenarios where certain estimation accuracy is unachievable with the given system and sensor characteristics.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16598v1",
        "authors": [
          "Abhishek Goudar",
          "Angela P. Schoellig"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Trajectory Estimation Trajectory",
        "Sensor Noise Covariances",
        "Sensor Query Schedule",
        "Robot",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.556760"
    },
    {
      "id": "arxiv-2602.16594v1",
      "title": "Decentralized and Fully Onboard: Range-Aided Cooperative Localization and Navigation on Micro Aerial Vehicles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16594v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Controlling a team of robots in a coordinated manner is challenging because centralized approaches (where all computation is performed on a central machine) scale poorly, and globally referenced external localization systems may not always be available. In this work, we consider the problem of range-aided decentralized localization and formation control. In such a setting, each robot estimates its relative pose by combining data only from onboard odometry sensors and distance measurements to other robots in the team. Additionally, each robot calculates the control inputs necessary to collaboratively navigate an environment to accomplish a specific task, for example, moving in a desired formation while monitoring an area. We present a block coordinate descent approach to localization that does not require strict coordination between the robots. We present a novel formulation for formation control as inference on factor graphs that takes into account the state estimation uncertainty and can be solved efficiently. Our approach to range-aided localization and formation-based navigation is completely decentralized, does not require specialized trajectories to maintain formation, and achieves decimeter-level positioning and formation control accuracy. We demonstrate our approach through multiple real experiments involving formation flights in diverse indoor and outdoor environments.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16594v1",
        "authors": [
          "Abhishek Goudar",
          "Angela P. Schoellig"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Micro Aerial Vehicles Controlling",
        "Aided Cooperative Localization",
        "Fully Onboard",
        "Robot",
        "Act",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.557205"
    },
    {
      "id": "arxiv-2602.16511v1",
      "title": "VIGOR: Visual Goal-In-Context Inference for Unified Humanoid Fall Safety",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16511v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Reliable fall recovery is critical for humanoids operating in cluttered environments. Unlike quadrupeds or wheeled robots, humanoids experience high-energy impacts, complex whole-body contact, and large viewpoint changes during a fall, making recovery essential for continued operation. Existing methods fragment fall safety into separate problems such as fall avoidance, impact mitigation, and stand-up recovery, or rely on end-to-end policies trained without vision through reinforcement learning or imitation learning, often on flat terrain. At a deeper level, fall safety is treated as monolithic data complexity, coupling pose, dynamics, and terrain and requiring exhaustive coverage, limiting scalability and generalization. We present a unified fall safety approach that spans all phases of fall recovery. It builds on two insights: 1) Natural human fall and recovery poses are highly constrained and transferable from flat to complex terrain through alignment, and 2) Fast whole-body reactions require integrated perceptual-motor representations. We train a privileged teacher using sparse human demonstrations on flat terrain and simulated complex terrains, and distill it into a deployable student that relies only on egocentric depth and proprioception. The student learns how to react by matching the teacher's goal-in-context latent representation, which combines the next target pose with the local terrain, rather than separately encoding what it must perceive and how it must act. Results in simulation and on a real Unitree G1 humanoid demonstrate robust, zero-shot fall safety across diverse non-flat environments without real-world fine-tuning. The project page is available at https://vigor2026.github.io/",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16511v1",
        "authors": [
          "Osher Azulay",
          "Zhengjie Xu",
          "Andrew Scheffer",
          "Stella X. Yu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Humanoid Fall Safety",
        "Context Inference",
        "Visual Goal",
        "Robot",
        "VIGOR",
        "EPA",
        "NSF",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.557767"
    },
    {
      "id": "arxiv-2602.16480v1",
      "title": "SRFed: Mitigating Poisoning Attacks in Privacy-Preserving Federated Learning with Heterogeneous Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16480v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Federated Learning (FL) enables collaborative model training without exposing clients' private data, and has been widely adopted in privacy-sensitive scenarios. However, FL faces two critical security threats: curious servers that may launch inference attacks to reconstruct clients' private data, and compromised clients that can launch poisoning attacks to disrupt model aggregation. Existing solutions mitigate these attacks by combining mainstream privacy-preserving techniques with defensive aggregation strategies. However, they either incur high computation and communication overhead or perform poorly under non-independent and identically distributed (Non-IID) data settings. To tackle these challenges, we propose SRFed, an efficient Byzantine-robust and privacy-preserving FL framework for Non-IID scenarios. First, we design a decentralized efficient functional encryption (DEFE) scheme to support efficient model encryption and non-interactive decryption. DEFE also eliminates third-party reliance and defends against server-side inference attacks. Second, we develop a privacy-preserving defensive model aggregation mechanism based on DEFE. This mechanism filters poisonous models under Non-IID data by layer-wise projection and clustering-based analysis. Theoretical analysis and extensive experiments show that SRFed outperforms state-of-the-art baselines in privacy protection, Byzantine robustness, and efficiency.",
        "keywords": [
          "cs.CR",
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16480v1",
        "authors": [
          "Yiwen Lu"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Heterogeneous Data Federated Learning",
        "Preserving Federated Learning",
        "Mitigating Poisoning Attacks",
        "Framework",
        "DEFE",
        "IID",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.558219"
    },
    {
      "id": "arxiv-2602.16462v1",
      "title": "Reactive Motion Generation With Particle-Based Perception in Dynamic Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16462v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Reactive motion generation in dynamic and unstructured scenarios is typically subject to essentially static perception and system dynamics. Reliably modeling dynamic obstacles and optimizing collision-free trajectories under perceptive and control uncertainty are challenging. This article focuses on revealing tight connection between reactive planning and dynamic mapping for manipulators from a model-based perspective. To enable efficient particle-based perception with expressively dynamic property, we present a tensorized particle weight update scheme that explicitly maintains obstacle velocities and covariance meanwhile. Building upon this dynamic representation, we propose an obstacle-aware MPPI-based planning formulation that jointly propagates robot-obstacle dynamics, allowing future system motion to be predicted and evaluated under uncertainty. The model predictive method is shown to significantly improve safety and reactivity with dynamic surroundings. By applying our complete framework in simulated and noisy real-world environments, we demonstrate that explicit modeling of robot-obstacle dynamics consistently enhances performance over state-of-the-art MPPI-based perception-planning baselines avoiding multiple static and dynamic obstacles.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16462v1",
        "authors": [
          "Xiyuan Zhao",
          "Huijun Li",
          "Lifeng Zhu",
          "Zhikai Wei",
          "Xianyi Zhu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reactive Motion Generation With",
        "Dynamic Environments Reactive",
        "Based Perception",
        "Framework",
        "Robot",
        "MPPI",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.558623"
    },
    {
      "id": "arxiv-2602.16432v1",
      "title": "Bibby AI -- AI Latex Editor writing assistant for researchers vs Overleaf Alternative vs OpenAI Prism. (Bibby AI Latex Editor)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16432v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models are increasingly integrated into academic writing workflows; however, the most widely used \\LaTeX\\ editors remain AI-peripheral -- offering compilation and collaboration, but no native intelligence. This separation forces researchers to leave their editing environment for AI assistance, fragmenting document context and interrupting writing flow. We present Bibby AI (trybibby.com), a native, AI-first \\LaTeX\\ editor that unifies the complete research writing lifecycle within a single interface. Bibby embeds an AI writing assistant, smart citation search, AI table and equation generation, an AI paper reviewer, abstract generator, literature review drafting, a deep research assistant, and real-time \\LaTeX\\ error detection and auto-fix -- all natively, without plugins or copy-paste workflows. We introduce LaTeXBench-500, a benchmark of 500 real-world compilation errors across six categories. Bibby achieves 91.4\\% detection accuracy and 83.7\\% one-click fix accuracy, outperforming Overleaf's native diagnostics (61.2\\%) and OpenAI Prism (78.3 / 64.1\\%) by large margins. Bibby demonstrates that a privacy-preserving, research-first AI editor can meaningfully accelerate every stage of academic manuscript preparation. We found that Bibby AI is a far superior alternative to overleaf latex and better than OpenAI Prism functionalities and AI.",
        "keywords": [
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16432v1",
        "authors": [
          "Nilesh jain",
          "Rohit Yadav",
          "Andrej Karpathy"
        ],
        "arxiv_categories": [
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Overleaf Alternative",
        "LaTeXBench-500",
        "Latex Editor",
        "OpenAI",
        "Intel",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.559136"
    },
    {
      "id": "arxiv-2602.16386v1",
      "title": "Towards Secure and Interoperable Data Spaces for 6G: The 6G-DALI Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16386v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The next generation of mobile networks, 6G, is expected to enable data-driven services at unprecedented scale and complexity, with stringent requirements for trust, interoperability, and automation. Central to this vision is the ability to create, manage, and share high-quality datasets across distributed and heterogeneous environments. This paper presents the data architecture of the 6G-DALI project, which implements a federated dataspace and DataOps infrastructure to support secure, compliant, and scalable data sharing for AI-driven experimentation and service orchestration. Drawing from principles defined by GAIA-X and the International Data Spaces Association (IDSA), the architecture incorporates components such as federated identity management, policy-based data contracts, and automated data pipelines. We detail how the 6G-DALI architecture aligns with and extends GAIA-X and IDSA reference models to meet the unique demands of 6G networks, including low-latency edge processing, dynamic trust management, and cross-domain federation. A comparative analysis highlights both convergence points and necessary innovations.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16386v1",
        "authors": [
          "Dimitrios Amaxilatis",
          "Themistoklis Sarantakos",
          "Nikolaos Tsironis",
          "Vasileios Theodorou",
          "Christos Verikoukis"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "International Data Spaces Association",
        "Interoperable Data Spaces",
        "Towards Secure",
        "Policy",
        "DALI",
        "GAIA",
        "IDSA",
        "Act",
        "6G",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.559516"
    },
    {
      "id": "arxiv-2602.16378v1",
      "title": "Scalable Base Station Configuration via Bayesian Optimization with Block Coordinate Descent",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16378v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper proposes a scalable Bayesian optimization (BO) framework for dense base-station (BS) configuration design. BO can find an optimal BS configuration by iterating parameter search, channel simulation, and probabilistic modeling of the objective function. However, its performance is severely affected by the curse of dimensionality, thereby reducing its scalability. To overcome this limitation, the proposed method sequentially optimizes per-BS parameters based on block coordinate descent while fixing the remaining BS configurations, thereby reducing the effective dimensionality of each optimization step. Numerical results demonstrate that the proposed approach significantly outperforms naive optimization in dense deployment scenarios.",
        "keywords": [
          "cs.IT",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16378v1",
        "authors": [
          "Kakeru Takamori",
          "Koya Sato"
        ],
        "arxiv_categories": [
          "cs.IT",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Base Station Configuration",
        "Bayesian Optimization",
        "Framework",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.559790"
    },
    {
      "id": "arxiv-2602.16371v1",
      "title": "Dynamic Modeling and MPC for Locomotion of Tendon-Driven Soft Quadruped",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16371v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "SLOT (Soft Legged Omnidirectional Tetrapod), a tendon-driven soft quadruped robot with 3D-printed TPU legs, is presented to study physics-informed modeling and control of compliant legged locomotion using only four actuators. Each leg is modeled as a deformable continuum using discrete Cosserat rod theory, enabling the capture of large bending deformations, distributed elasticity, tendon actuation, and ground contact interactions. A modular whole-body modeling framework is introduced, in which compliant leg dynamics are represented through physically consistent reaction forces applied to a rigid torso, providing a scalable interface between continuum soft limbs and rigid-body locomotion dynamics. This formulation allows efficient whole-body simulation and real-time control without sacrificing physical fidelity. The proposed model is embedded into a convex model predictive control framework that optimizes ground reaction forces over a 0.495 s prediction horizon and maps them to tendon actuation through a physics-informed force-angle relationship. The resulting controller achieves asymptotic stability under diverse perturbations. The framework is experimentally validated on a physical prototype during crawling and walking gaits, achieving high accuracy with less than 5 mm RMSE in center of mass trajectories. These results demonstrate a generalizable approach for integrating continuum soft legs into model-based locomotion control, advancing scalable and reusable modeling and control methods for soft quadruped robots.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16371v1",
        "authors": [
          "Saumya Karan",
          "Neerav Maram",
          "Suraj Borate",
          "Madhu Vadali"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Soft Legged Omnidirectional Tetrapod",
        "Driven Soft Quadruped",
        "Dynamic Modeling",
        "Framework",
        "Robot",
        "RMSE",
        "SLOT",
        "TPU",
        "MPC",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.560224"
    },
    {
      "id": "arxiv-2602.16367v1",
      "title": "A Multihop Rendezvous Protocol for Cognitive Radio-based Emergency Response Network",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16367v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This letter proposes a novel Multihop Dual Modular Clock Algorithm (M-DMCA) for efficient node discovery in cognitive radio-based emergency response networks. M-DMCA supports dual-channel selection per timeslot and incorporates a three-way handshake mechanism to significantly reduce rendezvous time. Performance evaluation under a worst-case scenario with 20 nodes, asymmetric channel sets of size 20, channel similarity index (m) as 2, and high primary radio activity shows that M-DMCA achieves a 24% reduction in rendezvous time compared to the multihop Extended Modular Clock Algorithm (EMCA), outperforming existing rendezvous protocols.",
        "keywords": [
          "cs.NI",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16367v1",
        "authors": [
          "Zahid Ali",
          "Saritha Unnikrishnan",
          "Eoghan Furey",
          "Ian McLoughlin",
          "Saim Ghafoor"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Extended Modular Clock Algorithm",
        "Multihop Rendezvous Protocol",
        "Multihop Dual Modular Clock",
        "Cognitive Radio",
        "Protocol",
        "EMCA",
        "DMCA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.560447"
    },
    {
      "id": "arxiv-2602.16365v1",
      "title": "Markerless 6D Pose Estimation and Position-Based Visual Servoing for Endoscopic Continuum Manipulators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16365v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Continuum manipulators in flexible endoscopic surgical systems offer high dexterity for minimally invasive procedures; however, accurate pose estimation and closed-loop control remain challenging due to hysteresis, compliance, and limited distal sensing. Vision-based approaches reduce hardware complexity but are often constrained by limited geometric observability and high computational overhead, restricting real-time closed-loop applicability. This paper presents a unified framework for markerless stereo 6D pose estimation and position-based visual servoing of continuum manipulators. A photo-realistic simulation pipeline enables large-scale automatic training with pixel-accurate annotations. A stereo-aware multi-feature fusion network jointly exploits segmentation masks, keypoints, heatmaps, and bounding boxes to enhance geometric observability. To enforce geometric consistency without iterative optimization, a feed-forward rendering-based refinement module predicts residual pose corrections in a single pass. A self-supervised sim-to-real adaptation strategy further improves real-world performance using unlabeled data. Extensive real-world validation achieves a mean translation error of 0.83 mm and a mean rotation error of 2.76° across 1,000 samples. Markerless closed-loop visual servoing driven by the estimated pose attains accurate trajectory tracking with a mean translation error of 2.07 mm and a mean rotation error of 7.41°, corresponding to 85% and 59% reductions compared to open-loop control, together with high repeatability in repeated point-reaching tasks. To the best of our knowledge, this work presents the first fully markerless pose-estimation-driven position-based visual servoing framework for continuum manipulators, enabling precise closed-loop control without physical markers or embedded sensing.",
        "keywords": [
          "cs.RO",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16365v1",
        "authors": [
          "Junhyun Park",
          "Chunggil An",
          "Myeongbo Park",
          "Ihsan Ullah",
          "Sihyeong Park"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Endoscopic Continuum Manipulators Continuum",
        "Based Visual Servoing",
        "Pose Estimation",
        "Framework",
        "Fusion",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.561414"
    },
    {
      "id": "arxiv-2602.16362v1",
      "title": "How Reliable is Your Service at the Extreme Edge? Analytical Modeling of Computational Reliability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16362v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Extreme Edge Computing (XEC) distributes streaming workloads across consumer-owned devices, exploiting their proximity to users and ubiquitous availability. Many such workloads are AI-driven, requiring continuous neural network inference for tasks like object detection and video analytics. Distributed Inference (DI), which partitions model execution across multiple edge devices, enables these streaming services to meet strict throughput and latency requirements. Yet consumer devices exhibit volatile computational availability due to competing applications and unpredictable usage patterns. This volatility poses a fundamental challenge: how can we quantify the probability that a device, or ensemble of devices, will maintain the processing rate required by a streaming service? This paper presents an analytical framework for computational reliability in XEC, defined as the probability that instantaneous capacity meets demand at a specified Quality of Service (QoS) threshold. We derive closed-form reliability expressions under two information regimes: Minimal Information (MI), requiring only declared operational bounds, and historical data, which refines estimates via Maximum Likelihood Estimation from past observations. The framework extends to multi-device deployments, providing reliability expressions for series, parallel, and partitioned workload configurations. We derive optimal workload allocation rules and analytical bounds for device selection, equipping orchestrators with tractable tools to evaluate deployment feasibility and configure distributed streaming systems. We validate the framework using real-time object detection with YOLO11m model as a representative DI streaming workload; experiments on emulated XED environments demonstrate close agreement between analytical predictions, Monte Carlo sampling, and empirical measurements across diverse capacity and demand configurations.",
        "keywords": [
          "cs.DC",
          "cs.NI",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16362v1",
        "authors": [
          "MHD Saria Allahham",
          "Hossam S. Hassanein"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.NI",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Computational Reliability Extreme Edge",
        "Maximum Likelihood Estimation",
        "Distributed Inference",
        "Analytical Modeling",
        "Minimal Information",
        "Edge Computing",
        "Neural Network",
        "Extreme Edge",
        "How Reliable",
        "Your Service",
        "Monte Carlo",
        "Agreement",
        "Framework",
        "XED",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.561907"
    },
    {
      "id": "arxiv-2602.16360v1",
      "title": "Docking and Persistent Operations for a Resident Underwater Vehicle",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16360v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Our understanding of the oceans remains limited by sparse and infrequent observations, primarily because current methods are constrained by the high cost and logistical effort of underwater monitoring, relying either on sporadic surveys across broad areas or on long-term measurements at fixed locations. To overcome these limitations, monitoring systems must enable persistent and autonomous operations without the need for continuous surface support. Despite recent advances, resident underwater vehicles remain uncommon due to persistent challenges in autonomy, robotic resilience, and mechanical robustness, particularly under long-term deployment in harsh and remote environments. This work addresses these problems by presenting the development, deployment, and operation of a resident infrastructure using a docking station with a mini-class Remotely Operated Vehicle (ROV) at 90m depth. The ROVis equipped with enhanced onboard processing and perception, allowing it to autonomously navigate using USBL signals, dock via ArUco marker-based visual localisation fused through an Extended Kalman Filter, and carry out local inspection routines. The system demonstrated a 90% autonomous docking success rate and completed full inspection missions within four minutes, validating the integration of acoustic and visual navigation in real-world conditions. These results show that reliable, untethered operations at depth are feasible, highlighting the potential of resident ROV systems for scalable, cost-effective underwater monitoring.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16360v1",
        "authors": [
          "Leonard Günzel",
          "Gabrielė Kasparavičiūtė",
          "Ambjørn Grimsrud Waldum",
          "Bjørn-Magnus Moslått",
          "Abubakar Aliyu Badawi"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Resident Underwater Vehicle Our",
        "Remotely Operated Vehicle",
        "Extended Kalman Filter",
        "Persistent Operations",
        "Robot",
        "USBL",
        "ROV",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.562323"
    },
    {
      "id": "arxiv-2602.16358v1",
      "title": "System Identification under Constraints and Disturbance: A Bayesian Estimation Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16358v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce a Bayesian system identification (SysID) framework for jointly estimating robot's state trajectories and physical parameters with high accuracy. It embeds physically consistent inverse dynamics, contact and loop-closure constraints, and fully featured joint friction models as hard, stage-wise equality constraints. It relies on energy-based regressors to enhance parameter observability, supports both equality and inequality priors on inertial and actuation parameters, enforces dynamically consistent disturbance projections, and augments proprioceptive measurements with energy observations to disambiguate nonlinear friction effects. To ensure scalability, we derive a parameterized equality-constrained Riccati recursion that preserves the banded structure of the problem, achieving linear complexity in the time horizon, and develop computationally efficient derivatives. Simulation studies on representative robotic systems, together with hardware experiments on a Unitree B1 equipped with a Z1 arm, demonstrate faster convergence, lower inertial and friction estimation errors, and improved contact consistency compared to forward-dynamics and decoupled identification baselines. When deployed within model predictive control frameworks, the resulting models yield measurable improvements in tracking performance during locomotion over challenging environments.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16358v1",
        "authors": [
          "Sergi Martinez",
          "Steve Tonneau",
          "Carlos Mastalli"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bayesian Estimation Approach We",
        "System Identification",
        "Framework",
        "Robot",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.562688"
    },
    {
      "id": "arxiv-2602.16356v1",
      "title": "Articulated 3D Scene Graphs for Open-World Mobile Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16356v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16356v1",
        "authors": [
          "Martin Büchner",
          "Adrian Röfer",
          "Tim Engelbracht",
          "Tim Welschehold",
          "Zuria Bauer"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.CV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "World Mobile Manipulation Semantics",
        "Scene Graphs",
        "Framework",
        "Robot",
        "Act",
        "MIT",
        "RGB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.563140"
    },
    {
      "id": "arxiv-2602.16353v1",
      "title": "Dual-Quadruped Collaborative Transportation in Narrow Environments via Safe Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16353v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Collaborative transportation, where multiple robots collaboratively transport a payload, has garnered significant attention in recent years. While ensuring safe and high-performance inter-robot collaboration is critical for effective task execution, it is difficult to pursue in narrow environments where the feasible region is extremely limited. To address this challenge, we propose a novel approach for dual-quadruped collaborative transportation via safe reinforcement learning (RL). Specifically, we model the task as a fully cooperative constrained Markov game, where collision avoidance is formulated as constraints. We introduce a cost-advantage decomposition method that enforces the sum of team constraints to remain below an upper bound, thereby guaranteeing task safety within an RL framework. Furthermore, we propose a constraint allocation method that assigns shared constraints to individual robots to maximize the overall task reward, encouraging autonomous task-assignment among robots, thereby improving collaborative task performance. Simulation and real-time experimental results demonstrate that the proposed approach achieves superior performance and a higher success rate in dual-quadruped collaborative transportation compared to existing methods.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16353v1",
        "authors": [
          "Zhezhi Lei",
          "Zhihai Bi",
          "Wenxin Wang",
          "Jun Ma"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Safe Reinforcement Learning Collaborative",
        "Quadruped Collaborative Transportation",
        "Narrow Environments",
        "Framework",
        "Robot",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.563494"
    },
    {
      "id": "arxiv-2602.16349v1",
      "title": "SCAR: Satellite Imagery-Based Calibration for Aerial Recordings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16349v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.",
        "keywords": [
          "cs.CV",
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16349v1",
        "authors": [
          "Henry Hölzemann",
          "Michael Schleiss"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aerial Recordings We",
        "Satellite Imagery",
        "Based Calibration",
        "Satellite",
        "COLMAP",
        "SCAR",
        "VINS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.563822"
    },
    {
      "id": "arxiv-2602.16347v1",
      "title": "Load Balanced Parallel Node Generation for Meshless Numerical Methods",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16347v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Meshless methods are used to solve partial differential equations by approximating differential operators at a node as a weighted sum of values at its neighbours. One of the algorithms for generating nodes suitable for meshless numerical analysis is an n-dimensional Poisson disc sampling based method. It can handle complex geometries and supports variable node density, a crucial feature for adaptive analysis. We modify this method for parallel execution using coupled spatial indexing and work distribution hypertrees. The latter is prebuilt according to the node density function, ensuring that each leaf represents a balanced work unit. Threads advance separate fronts and claim work hypertree leaves as needed while avoiding leaves neighbouring those claimed by other threads. Node placement constraints and the partially prebuilt spatial hypertree are combined to eliminate the need to lock the tree while it is being modified. Thread collision handling is managed by the work hypertree at the leaf level, drastically reducing the number of required mutex acquisitions for point insertion collision checks. We explore the behaviour of the proposed algorithm and compare the performance with existing attempts at parallelisation and consider the requirements for adapting the developed algorithm to distributed systems.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16347v1",
        "authors": [
          "Jon Vehovar",
          "Miha Rot",
          "Matjaž Depolli",
          "Gregor Kosec"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meshless Numerical Methods Meshless",
        "Load Balanced Parallel Node",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.564187"
    },
    {
      "id": "arxiv-2602.16345v1",
      "title": "Multi-Agent Meta-Advisor for UAV Fleet Trajectory Design in Vehicular Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16345v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Future vehicular networks require continuous connectivity to serve highly mobile users in urban environments. To mitigate the coverage limitations of fixed terrestrial macro base stations (MBS) under non line-of-sight (NLoS) conditions, fleets of unmanned aerial base stations (UABSs) can be deployed as aerial base stations, dynamically repositioning to track vehicular users and traffic hotspots in coordination with the terrestrial network. This paper addresses cooperative multi-agent trajectory design under different service areas and takeoff configurations, where rapid and safe adaptation across scenarios is essential. We formulate the problem as a multi-task decentralized partially observable Markov decision process and solve it using centralized training and decentralized execution with double dueling deep Q-network (3DQN), enabling online training for real-world deployments. However, efficient exploration remains a bottleneck, with conventional strategies like $ε$-greedy requiring careful tuning. To overcome this, we propose the multi-agent meta-advisor with advisor override (MAMO). This framework guides agent exploration through a meta-policy learned jointly across tasks. It uses a dynamic override mechanism that allows agents to reject misaligned guidance when the advisor fails to generalize to a specific scenario. Simulation results across three realistic urban scenarios and multiple takeoff configurations show that MAMO achieves faster convergence and higher returns than tuned $ε$-greedy baselines, outperforming both an advisor-only ablation and a single generalized policy. Finally, we demonstrate that the learned UABS fleet significantly improves network performance compared to deployments without aerial support.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16345v1",
        "authors": [
          "Leonardo Spampinato",
          "Lorenzo Mario Amorosa",
          "Enrico Testi",
          "Chiara Buratti",
          "Riccardo Marini"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Vehicular Networks Future",
        "Fleet Trajectory Design",
        "Agent Meta",
        "Framework",
        "Policy",
        "Meta",
        "MAMO",
        "UABS",
        "UAV",
        "MIT",
        "MBS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.565262"
    },
    {
      "id": "arxiv-2602.16338v1",
      "title": "push0: Scalable and Fault-Tolerant Orchestration for Zero-Knowledge Proof Generation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16338v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Zero-knowledge proof generation imposes stringent timing and reliability constraints on blockchain systems. For ZK-rollups, delayed proofs cause finality lag and economic loss; for Ethereum's emerging L1 zkEVM, proofs must complete within the 12-second slot window to enable stateless validation. The Ethereum Foundation's Ethproofs initiative coordinates multiple independent zkVMs across proving clusters to achieve real-time block proving, yet no principled orchestration framework addresses the joint challenges of (i) strict head-of-chain ordering, (ii) sub-slot latency bounds, (iii) fault-tolerant task reassignment, and (iv) prover-agnostic workflow composition. We present push0, a cloud-native proof orchestration system that decouples prover binaries from scheduling infrastructure. push0 employs an event-driven dispatcher--collector architecture over persistent priority queues, enforcing block-sequential proving while exploiting intra-block parallelism. We formalize requirements drawn from production ZK-rollup operations and the Ethereum real-time proving specification, then demonstrate via production Kubernetes cluster experiments that push0 achieves 5 ms median orchestration overhead with 99--100% scaling efficiency at 32 dispatchers for realistic workloads--overhead negligible (less than 0.1%) relative to typical proof computation times of 7+ seconds. Controlled Docker experiments validate these results, showing comparable performance (3--10 ms P50) when network variance is eliminated. Production deployment on the Zircuit zkrollup (14+ million mainnet blocks since March 2025) provides ecological validity for these controlled experiments. Our design enables seamless integration of heterogeneous zkVMs, supports automatic task recovery via message persistence, and provides the scheduling primitives necessary for both centralized rollup operators and decentralized multi-prover networks.",
        "keywords": [
          "cs.DC",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16338v1",
        "authors": [
          "Mohsen Ahmadvand",
          "Rok Pajnič",
          "Ching-Lun Chiu"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Knowledge Proof Generation Zero",
        "Tolerant Orchestration",
        "Controlled Docker",
        "Blockchain",
        "Framework",
        "Wind",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.565748"
    },
    {
      "id": "arxiv-2602.16330v1",
      "title": "Machine Learning Driven Prediction of the Behavior of Biohybrid Actuators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16330v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Skeletal muscle-based biohybrid actuators have proved to be a promising component in soft robotics, offering efficient movement. However, their intrinsic biological variability and nonlinearity pose significant challenges for controllability and predictability. To address these issues, this study investigates the application of supervised learning, a form of machine learning, to model and predict the behavior of biohybrid machines (BHMs), focusing on a muscle ring anchored on flexible polymer pillars. First, static prediction models (i.e., random forest and neural network regressors) are trained to estimate the maximum exerted force achieved from input variables such as muscle sample, electrical stimulation parameters, and baseline exerted force. Second, a dynamic modeling framework, based on Long Short-Term Memory networks, is developed to serve as a digital twin, replicating the time series of exerted forces observed in response to electrical stimulation. Both modeling approaches demonstrate high predictive accuracy. The best performance of the static models is characterized by R2 of 0.9425, whereas the dynamic model achieves R2 of 0.9956. The static models can enable optimization of muscle actuator performance for targeted applications and required force outcomes, while the dynamic model provides a foundation for developing robustly adaptive control strategies in future biohybrid robotic systems.",
        "keywords": [
          "cs.RO",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16330v1",
        "authors": [
          "Michail-Antisthenis Tsompanas",
          "Marco Perez Hernandez",
          "Faisal Abdul-Fattah",
          "Karim Elhakim",
          "Mostafa Ibrahim"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning Driven Prediction",
        "Biohybrid Actuators Skeletal",
        "Machine Learning",
        "Neural Network",
        "Term Memory",
        "Long Short",
        "Framework",
        "Robot",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.566106"
    },
    {
      "id": "arxiv-2602.16308v1",
      "title": "Markerless Robot Detection and 6D Pose Estimation for Multi-Agent SLAM",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16308v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The capability of multi-robot SLAM approaches to merge localization history and maps from different observers is often challenged by the difficulty in establishing data association. Loop closure detection between perceptual inputs of different robotic agents is easily compromised in the context of perceptual aliasing, or when perspectives differ significantly. For this reason, direct mutual observation among robots is a powerful way to connect partial SLAM graphs, but often relies on the presence of calibrated arrays of fiducial markers (e.g., AprilTag arrays), which severely limits the range of observations and frequently fails under sharp lighting conditions, e.g., reflections or overexposure. In this work, we propose a novel solution to this problem leveraging recent advances in Deep-Learning-based 6D pose estimation. We feature markerless pose estimation as part of a decentralized multi-robot SLAM system and demonstrate the benefit to the relative localization accuracy among the robotic team. The solution is validated experimentally on data recorded in a test field campaign on a planetary analogous environment.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16308v1",
        "authors": [
          "Markus Rueggeberg",
          "Maximilian Ulmer",
          "Maximilian Durner",
          "Wout Boerdijk",
          "Marcus Gerhard Mueller"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Markerless Robot Detection",
        "Pose Estimation",
        "Robot",
        "SLAM",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.566398"
    },
    {
      "id": "arxiv-2602.16235v1",
      "title": "Collaborative Safe Bayesian Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16235v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Mobile networks require safe optimization to adapt to changing conditions in traffic demand and signal transmission quality, in addition to improving service performance metrics. With the increasing complexity of emerging mobile networks, traditional parameter tuning methods become too conservative or complex to evaluate. For the first time, we apply safe Bayesian optimization to mobile networks. Moreover, we develop a new safe collaborative optimization algorithm called CoSBO, leveraging information from multiple optimization tasks in the network and considering multiple safety constraints. The resulting algorithm is capable of safely tuning the network parameter online with very few iterations. We demonstrate that the proposed method improves sample efficiency in the early stages of the optimization process by comparing it against the SafeOpt-MC algorithm in a mobile network scenario.",
        "keywords": [
          "eess.SY",
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16235v1",
        "authors": [
          "Alina Castell Blasco",
          "Maxime Bouton"
        ],
        "arxiv_categories": [
          "eess.SY",
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Collaborative Safe Bayesian Optimization",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.566627"
    },
    {
      "id": "arxiv-2602.16233v1",
      "title": "DistributedEstimator: Distributed Training of Quantum Neural Networks via Circuit Cutting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16233v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Circuit cutting decomposes a large quantum circuit into a collection of smaller subcircuits. The outputs of these subcircuits are then classically reconstructed to recover the original expectation values. While prior work characterises cutting overhead largely in terms of subcircuit counts and sampling complexity, its end-to-end impact on iterative, estimator-driven training pipelines remains insufficiently measured from a systems perspective. In this paper, we propose a cut-aware estimator execution pipeline that treats circuit cutting as a staged distributed workload and instruments each estimator query into partitioning, subexperiment generation, parallel execution, and classical reconstruction phases. Using logged runtime traces and learning outcomes on two binary classification workloads (Iris and MNIST), we quantify cutting overheads, scaling limits, and sensitivity to injected stragglers, and we evaluate whether accuracy and robustness are preserved under matched training budgets. Our measurements show that cutting introduces substantial end-to-end overheads that grow with the number of cuts, and that reconstruction constitutes a dominant fraction of per-query time, bounding achievable speed-up under increased parallelism. Despite these systems costs, test accuracy and robustness are preserved in the measured regimes, with configuration-dependent improvements observed in some cut settings. These results indicate that practical scaling of circuit cutting for learning workloads hinges on reducing and overlapping reconstruction and on scheduling policies that account for barrier-dominated critical paths.",
        "keywords": [
          "cs.DC",
          "cs.LG",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16233v1",
        "authors": [
          "Prabhjot Singh",
          "Adel N. Toosi",
          "Rajkumar Buyya"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.LG",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Neural Networks",
        "Circuit Cutting Circuit",
        "Distributed Training",
        "Neural Network",
        "MNIST",
        "NIST",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.567002"
    },
    {
      "id": "arxiv-2602.16222v1",
      "title": "Near-optimal population protocols on bounded-degree trees",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16222v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We investigate space-time trade-offs for population protocols in sparse interaction graphs. In complete interaction graphs, optimal space-time trade-offs are known for the leader election and exact majority problems. However, it has remained open if other graph families exhibit similar space-time complexity trade-offs, as existing lower bound techniques do not extend beyond highly dense graphs. In this work, we show that -- unlike in complete graphs -- population protocols on bounded-degree trees do not exhibit significant asymptotic space-time trade-offs for leader election and exact majority. For these problems, we give constant-space protocols that have near-optimal worst-case expected stabilisation time. These new protocols achieve a linear speed-up compared to the state-of-the-art. Our results are based on two novel protocols, which we believe are of independent interest. First, we give a new fast self-stabilising 2-hop colouring protocol for general interaction graphs, whose stabilisation time we bound using a stochastic drift argument. Second, we give a self-stabilising tree orientation algorithm that builds a rooted tree in optimal time on any tree. As a consequence, we can use simple constant-state protocols designed for directed trees to solve leader election and exact majority fast. For example, we show that ``directed'' annihilation dynamics solve exact majority in $O(n^2 \\log n)$ steps on directed trees.",
        "keywords": [
          "cs.DC",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16222v1",
        "authors": [
          "Joel Rybicki",
          "Jakob Solnerzik",
          "Robin Vacus"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.567339"
    },
    {
      "id": "arxiv-2602.16206v1",
      "title": "Nonplanar Model Predictive Control for Autonomous Vehicles with Recursive Sparse Gaussian Process Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16206v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper proposes a nonplanar model predictive control (MPC) framework for autonomous vehicles operating on nonplanar terrain. To approximate complex vehicle dynamics in such environments, we develop a geometry-aware modeling approach that learns a residual Gaussian Process (GP). By utilizing a recursive sparse GP, the framework enables real-time adaptation to varying terrain geometry. The effectiveness of the learned model is demonstrated in a reference-tracking task using a Model Predictive Path Integral (MPPI) controller. Validation within a custom Isaac Sim environment confirms the framework's capability to maintain high tracking accuracy on challenging 3D surfaces.",
        "keywords": [
          "cs.RO",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16206v1",
        "authors": [
          "Ahmad Amine",
          "Kabir Puri",
          "Viet-Anh Le",
          "Rahul Mangharam"
        ],
        "arxiv_categories": [
          "cs.RO",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonplanar Model Predictive Control",
        "Recursive Sparse Gaussian Process",
        "Model Predictive Path Integral",
        "Autonomous Vehicles",
        "Autonomous Vehicle",
        "Gaussian Process",
        "Framework",
        "Isaac Sim",
        "MPPI",
        "MPC",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.567546"
    },
    {
      "id": "arxiv-2602.16187v1",
      "title": "SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16187v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Robots executing iterative tasks in complex, uncertain environments require control strategies that balance robustness, safety, and high performance. This paper introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive control algorithm to address a constrained infinite-horizon optimal control problem for discrete-time nonlinear stochastic systems. An adaptive penalty method is developed to ensure safety while balancing optimality. Trajectories from previous iterations are utilized to learn a value function using normalizing flows, which enables richer uncertainty modeling compared to Gaussian priors. SIT-LMPC is designed for highly parallel execution on graphics processing units, allowing efficient real-time optimization. Benchmark simulations and hardware experiments demonstrate that SIT-LMPC iteratively improves system performance while robustly satisfying system constraints.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16187v1",
        "authors": [
          "Zirui Zang",
          "Ahmad Amine",
          "Nick-Marios T. Kokolakis",
          "Truong X. Nghiem",
          "Ugo Rosolia"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Iterative Tasks Robots",
        "Safe Information",
        "Framework",
        "Robot",
        "LMPC",
        "SIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.567828"
    },
    {
      "id": "arxiv-2602.16182v1",
      "title": "World Model Failure Classification and Anomaly Detection for Autonomous Inspection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16182v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Autonomous inspection robots for monitoring industrial sites can reduce costs and risks associated with human-led inspection. However, accurate readings can be challenging due to occlusions, limited viewpoints, or unexpected environmental conditions. We propose a hybrid framework that combines supervised failure classification with anomaly detection, enabling classification of inspection tasks as a success, known failure, or anomaly (i.e., out-of-distribution) case. Our approach uses a world model backbone with compressed video inputs. This policy-agnostic, distribution-free framework determines classifications based on two decision functions set by conformal prediction (CP) thresholds before a human observer does. We evaluate the framework on gauge inspection feeds collected from office and industrial sites and demonstrate real-time deployment on a Boston Dynamics Spot. Experiments show over 90% accuracy in distinguishing between successes, failures, and OOD cases, with classifications occurring earlier than a human observer. These results highlight the potential for robust, anticipatory failure detection in autonomous inspection tasks or as a feedback signal for model training to assess and improve the quality of training data. Project website: https://autoinspection-classification.github.io",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16182v1",
        "authors": [
          "Michelle Ho",
          "Muhammad Fadhil Ginting",
          "Isaac R. Ward",
          "Andrzej Reinke",
          "Mykel J. Kochenderfer"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "World Model Failure Classification",
        "Autonomous Inspection Autonomous",
        "Boston Dynamics Spot",
        "Anomaly Detection",
        "Framework",
        "Policy",
        "Robot",
        "OOD",
        "MIT",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.568156"
    },
    {
      "id": "arxiv-2602.16178v1",
      "title": "Image Measurement Method for Automatic Insertion of Forks into Inclined Pallet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16178v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In order to insert a fork into a hole of a pallet by a forklift located in front of a pallet, it is necessary to control the height position, reach position, and tilt angle of the fork to match the position and orientation of the hole of the pallet. In order to make AGF (Autonomous Guided Forklift) do this automatically, we propose an image measurement method to measure the pitch inclination of the pallet in the camera coordinate system from an image obtained by using a wide-angle camera. In addition, we propose an image measurement method to easily acquire the calibration information between the camera coordinate system and the fork coordinate system necessary to apply the measurements in the camera coordinate system to the fork control. In the experiment space, a wide-angle camera was fixed at the backrest of a reach type forklift. The wide-angle images taken by placing a pallet in front of the camera were processed. As a result of evaluating the error by comparing the image measurement value with the hand measurement value when changing the pitch inclination angle of the pallet, the relative height of the pallet and the fork, and whether the pallet is loaded or not, it was confirmed that the error was within the allowable range for safely inserting the fork.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16178v1",
        "authors": [
          "Nobuyuki Kita",
          "Takuro Kato"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Autonomous Guided Forklift",
        "Image Measurement Method",
        "Automatic Insertion",
        "Inclined Pallet In",
        "AGF",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.568478"
    },
    {
      "id": "arxiv-2602.16174v1",
      "title": "Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16174v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Mobile edge computing (MEC) based wireless metaverse services offer an untethered, immersive experience to users, where the superior quality of experience (QoE) needs to be achieved under stringent latency constraints and visual quality demands. To achieve this, MEC-based intelligent resource allocation for virtual reality users needs to be supported by coordination across MEC servers to harness distributed data. Federated learning (FL) is a promising solution, and can be combined with reinforcement learning (RL) to develop generalized policies across MEC-servers. However, conventional FL incurs transmitting the full model parameters across the MEC-servers and the cloud, and suffer performance degradation due to naive global aggregation, especially in heterogeneous multi-radio access technology environments. To address these challenges, this paper proposes Federated Split Decision Transformer (FSDT), an offline RL framework where the transformer model is partitioned between MEC servers and the cloud. Agent-specific components (e.g., MEC-based embedding and prediction layers) enable local adaptability, while shared global layers in the cloud facilitate cooperative training across MEC servers. Experimental results demonstrate that FSDT enhances QoE for up to 10% in heterogeneous environments compared to baselines, while offloadingnearly 98% of the transformer model parameters to the cloud, thereby reducing the computational burden on MEC servers.",
        "keywords": [
          "cs.NI",
          "cs.AI",
          "cs.MM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16174v1",
        "authors": [
          "Fatih Temiz",
          "Shavbo Salehi",
          "Melike Erol-Kantarci"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.AI",
          "cs.MM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Federated Split Decision Transformers",
        "Federated Split Decision Transformer",
        "Metaverse Resource Allocation Mobile",
        "Edge Computing",
        "Edge Learning",
        "Transformer",
        "Framework",
        "Intel",
        "Meta",
        "FSDT",
        "MEC",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.568827"
    },
    {
      "id": "arxiv-2602.16163v1",
      "title": "Collection: UAV-Based Wireless Multi-modal Measurements from AERPAW Autonomous Data Mule (AADM) Challenge in Digital Twin and Real-World Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16163v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we present an unmanned aerial vehicle (UAV) wireless dataset collected as part of the AERPAW Autonomous Aerial Data Mule (AADM) challenge, organized by the NSF Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW) project. The AADM challenge was the second competition in which an autonomous UAV acted as a data mule, where the UAV downloaded data from multiple base stations (BSs) in a dynamic wireless environment. Participating teams designed flight control and decision-making algorithms for choosing which BSs to communicate with and how to plan flight trajectories to maximize data download within a mission completion time. The competition was conducted in two stages: Stage 1 involved development and experimentation using a digital twin (DT) environment, and in Stage 2, the final test run was conducted on the outdoor testbed. The total score for each team was compiled from both stages. The resulting dataset includes link quality and data download measurements, both in DT and physical environments. Along with the USRP measurements used in the contest, the dataset also includes UAV telemetry, Keysight RF sensors position estimates, link quality measurements from LoRa receivers, and Fortem radar measurements. It supports reproducible research on autonomous UAV networking, multi-cell association and scheduling, air-to-ground propagation modeling, DT-to-real-world transfer learning, and integrated sensing and communication, which serves as a benchmark for future autonomous wireless experimentation.",
        "keywords": [
          "cs.NI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16163v1",
        "authors": [
          "Md Sharif Hossen",
          "Cole Dickerson",
          "Ozgur Ozdemir",
          "Anil Gurses",
          "Mohamed Rabeek Sarbudeen"
        ],
        "arxiv_categories": [
          "cs.NI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Autonomous Aerial Data Mule",
        "Aerial Experimentation",
        "World Environments In",
        "Autonomous Data Mule",
        "Based Wireless Multi",
        "Research Platform",
        "Advanced Wireless",
        "Digital Twin",
        "AERPAW",
        "AADM",
        "USRP",
        "NSF",
        "Act",
        "UAV",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.569279"
    },
    {
      "id": "arxiv-2602.16143v1",
      "title": "Energy-Efficient p-Bit-Based Fully-Connected Quantum-Inspired Simulated Annealer with Dual BRAM Architecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16143v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Probabilistic bits (p-bits) offer an energy-efficient hardware abstraction for stochastic optimization; however, existing p-bit-based simulated annealing accelerators suffer from poor scalability and limited support for fully connected graphs due to fan-out and memory overhead. This paper presents an energy-efficient FPGA architecture for stochastic simulated quantum annealing (SSQA) that addresses these challenges. The proposed design combines a spin-serial and replica-parallel update schedule with a dual-BRAM delay-line architecture, enabling scalable support for fully connected Ising models while eliminating fan-out growth in logic resources. By exploiting SSQA, the architecture achieves fast convergence using only final replica states, significantly reducing memory requirements compared to conventional p-bit-based annealers. Implemented on a Xilinx ZC706 FPGA, the proposed system solves an 800-node MAX-CUT benchmark and achieves up to 50% reduction in energy consumption and over 90\\% reduction in logic resources compared with prior FPGA-based p-bit annealing architectures. These results demonstrate the practicality of quantum-inspired, p-bit-based annealing hardware for large-scale combinatorial optimization under strict energy and resource constraints.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16143v1",
        "authors": [
          "Naoya Onizawa",
          "Taiga Kubuta",
          "Duckgyu Shin",
          "Takahiro Hanyu"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inspired Simulated Annealer",
        "Architecture Probabilistic",
        "Connected Quantum",
        "Based Fully",
        "SSQA",
        "BRAM",
        "FPGA",
        "Act",
        "CUT",
        "MIT",
        "MAX",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.569601"
    },
    {
      "id": "arxiv-2602.16130v1",
      "title": "Managing Credible Anonymous Identities in Web 3.0 Services: A Scalable On-Chain Admission Framework with Recursive Proof Aggregation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16130v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Open Web 3.0 platforms increasingly operate as \\emph{service ecosystems} (e.g., DeFi, DAOs, and decentralized social applications) where \\emph{admission control} and \\emph{account provisioning} must be delivered as an always-on service under bursty demand. Service operators face a fundamental tension: enforcing Sybil resistance (one-person-one-account) while preserving user privacy, yet keeping on-chain verification cost and admission latency predictable at scale. Existing credential-based ZK admission approaches typically require per-request on-chain verification, making the provisioning cost grow with the number of concurrent joiners. We present \\textbf{ZK-AMS}, a scalable admission and provisioning layer that bridges real-world \\emph{Personhood Credentials} to anonymous on-chain service accounts. ZK-AMS combines (i) zero-knowledge credential validation, (ii) a \\emph{permissionless} batch submitter model, and (iii) a decentralized, privacy-preserving folding pipeline that uses Nova-style recursive aggregation together with multi-key homomorphic encryption, enabling batch settlement with \\emph{constant} on-chain verification per batch. We implement ZK-AMS end-to-end on an Ethereum testbed and evaluate admission throughput, end-to-end latency, and gas consumption. Results show stable verification cost across batch sizes and substantially improved admission efficiency over non-recursive baselines, providing a practical and cost-predictable admission service for large-scale Web 3.0 communities.",
        "keywords": [
          "cs.NI",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16130v1",
        "authors": [
          "Zibin Lin",
          "Taotao Wang",
          "Shengli Zhang",
          "Long Shi",
          "Shui Yu"
        ],
        "arxiv_categories": [
          "cs.NI",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Managing Credible Anonymous Identities",
        "Recursive Proof Aggregation Open",
        "Chain Admission Framework",
        "Personhood Credentials",
        "Scalable On",
        "Framework",
        "Act",
        "MIT",
        "AMS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.569974"
    },
    {
      "id": "arxiv-2602.16127v1",
      "title": "Reactive Slip Control in Multifingered Grasping: Hybrid Tactile Sensing and Internal-Force Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16127v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a hybrid learning and model-based approach that adapts internal grasp forces to halt in-hand slip on a multifingered robotic gripper. A multimodal tactile stack combines piezoelectric (PzE) sensing for fast slip cues with piezoresistive (PzR) arrays for contact localization, enabling online construction of the grasp matrix. Upon slip, we update internal forces computed in the null space of the grasp via a quadratic program that preserves the object wrench while enforcing actuation limits. The pipeline yields a theoretical sensing-to-command latency of 35-40 ms, with 5 ms for PzR-based contact and geometry updates and about 4 ms for the quadratic program solve. In controlled trials, slip onset is detected at 20ms. We demonstrate closed-loop stabilization on multifingered grasps under external perturbations. Augmenting efficient analytic force control with learned tactile cues yields both robustness and rapid reactions, as confirmed in our end-to-end evaluation. Measured delays are dominated by the experimental data path rather than actual computation. The analysis outlines a clear route to sub-50 ms closed-loop stabilization.",
        "keywords": [
          "cs.RO",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16127v1",
        "authors": [
          "Théo Ayral",
          "Saifeddine Aloui",
          "Mathieu Grossard"
        ],
        "arxiv_categories": [
          "cs.RO",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multifingered Grasping",
        "Hybrid Tactile Sensing",
        "Force Optimization We",
        "Reactive Slip Control",
        "Robot",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.570274"
    },
    {
      "id": "arxiv-2602.16100v1",
      "title": "LLM-Driven Intent-Based Privacy-Aware Orchestration Across the Cloud-Edge Continuum",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16100v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "With the rapid advancement of large language models (LLMs), efficiently serving LLM inference under limited GPU resources has become a critical challenge. Recently, an increasing number of studies have explored applying serverless computing paradigms to LLM serving in order to maximize resource utilization. However, LLM inference workloads are highly diverse, and modern GPU clusters are inherently heterogeneous, making it necessary to dynamically adjust deployment configurations online to better adapt to the elastic and dynamic nature of serverless environments. At the same time, enabling such online reconfiguration is particularly challenging due to the stateful nature of LLM inference and the massive size of model parameters. In this paper, we propose a dynamic pipeline reconfiguration approach that enables online adjustment of pipeline configurations while minimizing service downtime and performance degradation. Our method allows the system to select the optimal pipeline configuration in response to changing workloads. Experimental results on heterogeneous GPU platforms, including NVIDIA A100 and L40s, demonstrate that our migration mechanism incurs less than 50 ms of service downtime, while introducing under 10% overhead on both time-to-first-token (TTFT) and time-per-output-token (TPOT).",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16100v1",
        "authors": [
          "Zijie Su",
          "Muhammed Tawfiqul Islam",
          "Mohammad Goudarzi",
          "Adel N. Toosi"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Orchestration Across",
        "Edge Continuum With",
        "Based Privacy",
        "Driven Intent",
        "NVIDIA",
        "TTFT",
        "TPOT",
        "LLM",
        "GPU",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.570602"
    },
    {
      "id": "arxiv-2602.16075v1",
      "title": "DARTH-PUM: A Hybrid Processing-Using-Memory Architecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16075v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Analog processing-using-memory (PUM; a.k.a. in-memory computing) makes use of electrical interactions inside memory arrays to perform bulk matrix-vector multiplication (MVM) operations. However, many popular matrix-based kernels need to execute non-MVM operations, which analog PUM cannot directly perform. To retain its energy efficiency, analog PUM architectures augment memory arrays with CMOS-based domain-specific fixed-function hardware to provide complete kernel functionality, but the difficulty of integrating such specialized CMOS logic with memory arrays has largely limited analog PUM to being an accelerator for machine learning inference, or for closely related kernels. An opportunity exists to harness analog PUM for general-purpose computation: recent works have shown that memory arrays can also perform Boolean PUM operations, albeit with very different supporting hardware and electrical signals than analog PUM. We propose DARTH-PUM, a general-purpose hybrid PUM architecture that tackles key hardware and software challenges to integrating analog PUM and digital PUM. We propose optimized peripheral circuitry, coordinating hardware to manage and interface between both types of PUM, an easy-to-use programming interface, and low-cost support for flexible data widths. These design elements allow us to build a practical PUM architecture that can execute kernels fully in memory, and can scale easily to cater to domains ranging from embedded applications to large-scale data-driven computing. We show how three popular applications (AES encryption, convolutional neural networks, large-language models) can map to and benefit from DARTH-PUM, with speedups of 59.4x, 14.8x, and 40.8x over an analog+CPU baseline.",
        "keywords": [
          "cs.AR",
          "cs.CR",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16075v1",
        "authors": [
          "Ryan Wong",
          "Ben Feinberg",
          "Saugata Ghose"
        ],
        "arxiv_categories": [
          "cs.AR",
          "cs.CR",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Memory Architecture Analog",
        "Hybrid Processing",
        "Machine Learning",
        "Neural Network",
        "DARTH",
        "CMOS",
        "CPU",
        "AES",
        "Act",
        "MIT",
        "PUM",
        "MVM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.571001"
    },
    {
      "id": "arxiv-2602.16073v1",
      "title": "ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16073v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Developing autonomous driving systems for complex traffic environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit priority relations naturally arise. Also, driving rules require context, so it is important to formally model the environment scenarios within which such rules apply. Existing benchmarks for evaluating autonomous vehicles lack such combinations of multi-objective prioritized rules and formal environment models. In this work, we introduce ScenicRules, a benchmark for evaluating autonomous driving systems in stochastic environments under prioritized multi-objective specifications. We first formalize a diverse set of objectives to serve as quantitative evaluation metrics. Next, we design a Hierarchical Rulebook framework that encodes multiple objectives and their priority relations in an interpretable and adaptable manner. We then construct a compact yet representative collection of scenarios spanning diverse driving contexts and near-accident situations, formally modeled in the Scenic language. Experimental results show that our formalized objectives and Hierarchical Rulebooks align well with human driving judgments and that our benchmark effectively exposes agent failures with respect to the prioritized objectives. Our benchmark can be accessed at https://github.com/BerkeleyLearnVerify/ScenicRules/.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.LO",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16073v1",
        "authors": [
          "Kevin Kai-Chun Chang",
          "Ekin Beyazit",
          "Alberto Sangiovanni-Vincentelli",
          "Tichakorn Wongpiromsarn",
          "Sanjit A. Seshia"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.LO",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "An Autonomous Driving Benchmark",
        "Abstract Scenarios Developing",
        "Objective Specifications",
        "Hierarchical Rulebooks",
        "Hierarchical Rulebook",
        "Autonomous Vehicle",
        "Framework",
        "Berkeley",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.571362"
    },
    {
      "id": "arxiv-2602.16063v1",
      "title": "MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16063v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces a novel, open-source MARL simulation framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery storage), a realistic grid network, and a comprehensive analytics suite to evaluate emergent coordination. The main contribution is a novel method to foster implicit cooperation, where agents' observations and rewards are enhanced with system-level key performance indicators to enable them to independently learn strategies that benefit the entire system and aim for collectively beneficial outcomes without explicit communication. Through representative case studies (available in a dedicated GitHub repository in https://github.com/salazarna/marlem, we show the framework's ability to analyze how different market configurations (such as varying storage deployment) impact system performance. This illustrates its potential to facilitate emergent coordination, improve market efficiency, and strengthen grid stability. The proposed simulation framework is a flexible, extensible, and reproducible tool for researchers and practitioners to design, test, and validate strategies for future intelligent, decentralized energy systems.",
        "keywords": [
          "eess.SY",
          "cs.CE",
          "cs.ET",
          "cs.LG",
          "stat.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16063v1",
        "authors": [
          "Nelson Salazar-Pena",
          "Alejandra Tabares",
          "Andres Gonzalez-Mancera"
        ],
        "arxiv_categories": [
          "eess.SY",
          "cs.CE",
          "cs.ET",
          "cs.LG",
          "stat.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Reinforcement Learning Simulation",
        "Decentralized Local Energy Markets",
        "Implicit Cooperation",
        "Framework",
        "Battery",
        "MARLEM",
        "Intel",
        "MARL",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.571712"
    },
    {
      "id": "arxiv-2602.16035v1",
      "title": "The Impact of Class Uncertainty Propagation in Perception-Based Motion Planning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16035v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Autonomous vehicles (AVs) are being increasingly deployed in urban environments. In order to operate safely and reliably, AVs need to account for the inherent uncertainty associated with perceiving the world through sensor data and incorporate that into their decision-making process. Uncertainty-aware planners have recently been developed to account for upstream perception and prediction uncertainty. However, such planners may be sensitive to prediction uncertainty miscalibration, the magnitude of which has not yet been characterized. Towards this end, we perform a detailed analysis on the impact that perceptual uncertainty propagation and calibration has on perception-based motion planning. We do so by comparing two novel prediction-planning pipelines with varying levels of uncertainty propagation on the recently-released nuPlan planning benchmark. We study the impact of upstream uncertainty calibration using closed-loop evaluation on the nuPlan challenge scenarios. We find that the method incorporating upstream uncertainty propagation demonstrates superior generalization to complex closed-loop scenarios.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16035v1",
        "authors": [
          "Jibran Iqbal Shah",
          "Andrei Ivanovic",
          "Kelly Zhu",
          "Masha Itkina",
          "Rowan McAllister"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Motion Planning Autonomous",
        "Class Uncertainty Propagation",
        "Autonomous Vehicle",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.571995"
    },
    {
      "id": "arxiv-2602.16024v1",
      "title": "Bit-Width-Aware Design Environment for Few-Shot Learning on Edge AI Hardware",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16024v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this study, we propose an implementation methodology of real-time few-shot learning on tiny FPGA SoCs such as the PYNQ-Z1 board with arbitrary fixed-point bit-widths. Tensil-based conventional design environments limited hardware implementations to fixed-point bit-widths of 16 or 32 bits. To address this, we adopt the FINN framework, enabling implementations with arbitrary bit-widths. Several customizations and minor adjustments are made, including: 1.Optimization of Transpose nodes to resolve data format mismatches, 2.Addition of handling for converting the final reduce mean operation to Global Average Pooling (GAP). These adjustments allow us to reduce the bit-width while maintaining the same accuracy as the conventional realization, and achieve approximately twice the throughput in evaluations using CIFAR-10 dataset.",
        "keywords": [
          "cs.AR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16024v1",
        "authors": [
          "R. Kanda",
          "H. L. Blevec",
          "N. Onizawa",
          "M. Leonardon",
          "V. Gripon"
        ],
        "arxiv_categories": [
          "cs.AR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Design Environment",
        "Global Average Pooling",
        "Shot Learning",
        "Hardware In",
        "Framework",
        "CIFAR-10",
        "CIFAR",
        "PYNQ",
        "FINN",
        "FPGA",
        "GAP",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.572231"
    },
    {
      "id": "arxiv-2602.16018v1",
      "title": "Edge-Local and Qubit-Efficient Quantum Graph Learning for the NISQ Era",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16018v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Graph neural networks (GNNs) are a powerful framework for learning representations from graph-structured data, but their direct implementation on near-term quantum hardware remains challenging due to circuit depth, multi-qubit interactions, and qubit scalability constraints. In this work, we introduce a fully quantum graph convolutional architecture designed explicitly for unsupervised learning in the noisy intermediate-scale quantum (NISQ) regime. Our approach combines a variational quantum feature extraction layer with an edge-local and qubit-efficient quantum message-passing mechanism inspired by the Quantum Alternating Operator Ansatz (QAOA) framework. Unlike prior models that rely on global operations or multi-controlled unitaries, our model decomposes message passing into pairwise interactions along graph edges using only hardware-native single- and two-qubit gates. This design reduces the qubit requirement from $O(Nn)$ to $O(n)$ for a graph with $N$ nodes and $n$-qubit feature registers, enabling implementation on current quantum devices regardless of graph size. We train the model using the Deep Graph Infomax objective to perform unsupervised node representation learning. Experiments on the Cora citation network and a large-scale genomic SNP dataset demonstrate that our model remains competitive with prior quantum and hybrid approaches.",
        "keywords": [
          "quant-ph",
          "cs.ET",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16018v1",
        "authors": [
          "Armin Ahmadkhaniha",
          "Jake Doliskani"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.ET",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Alternating Operator Ansatz",
        "Efficient Quantum Graph Learning",
        "Deep Graph Infomax",
        "Neural Network",
        "Framework",
        "Era Graph",
        "NISQ",
        "QAOA",
        "Act",
        "SNP",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.572553"
    },
    {
      "id": "arxiv-2602.16010v1",
      "title": "Scrutinizing Variables for Checkpoint Using Automatic Differentiation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16010v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Checkpoint/Restart (C/R) saves the running state of the programs periodically, which consumes considerable system resources. We observe that not every piece of data is involved in the computation in typical HPC applications; such unused data should be excluded from checkpointing for better storage/compute efficiency. To find out, we propose a systematic approach that leverages automatic differentiation (AD) to scrutinize every element within variables (e.g., arrays) for checkpointing allowing us to identify critical/uncritical elements and eliminate uncritical elements from checkpointing. Specifically, we inspect every single element within a variable for checkpointing with an AD tool to determine whether the element has an impact on the application output or not. We empirically validate our approach with eight benchmarks from the NAS Parallel Benchmark (NPB) suite. We successfully visualize critical/uncritical elements/regions within a variable with respect to its impact (yes or no) on the application output. We find patterns/distributions of critical/uncritical elements/regions quite interesting and follow the physical formulation/logic of the algorithm.The evaluation on NPB benchmarks shows that our approach saves storage for checkpointing by up to 20%.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16010v1",
        "authors": [
          "Xin Huang",
          "Weiping Zhang",
          "Shiman Meng",
          "Wubiao Xu",
          "Xiang Fu"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Checkpoint Using Automatic Differentiation",
        "Scrutinizing Variables",
        "Parallel Benchmark",
        "NAS",
        "HPC",
        "NPB",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.572879"
    },
    {
      "id": "arxiv-2602.16005v1",
      "title": "ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16005v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce ODYN, a novel all-shifted primal-dual non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence of the constraints. It exhibits strong warm-start performance and is well suited to both general-purpose optimization, and robotics and AI applications, including model-based control, estimation, and kernel-based learning methods. We provide an open-source implementation and benchmark ODYN on the Maros-Mészáros test set, demonstrating state-of-the-art convergence performance in small-to-high-scale problems. The results highlight ODYN's superior warm-starting capabilities, which are critical in sequential and real-time settings common in robotics and AI. These advantages are further demonstrated by deploying ODYN as the backend of an SQP-based predictive control framework (OdynSQP), as the implicitly differentiable optimization layer for deep learning (ODYNLayer), and the optimizer of a contact-dynamics simulation (ODYNSim).",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16005v1",
        "authors": [
          "Jose Rojas",
          "Aristotelis Papatheodorou",
          "Sergi Martinez",
          "Ioannis Havoutis",
          "Carlos Mastalli"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quadratic Programming",
        "Deep Learning",
        "Point Method",
        "Shifted Non",
        "Framework",
        "An All",
        "Robot",
        "ODYN",
        "Act",
        "NCP",
        "SQP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.573484"
    },
    {
      "id": "arxiv-2602.15995v1",
      "title": "Distributed Order Recording Techniques for Efficient Record-and-Replay of Multi-threaded Programs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15995v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "After all these years and all these other shared memory programming frameworks, OpenMP is still the most popular one. However, its greater levels of non-deterministic execution makes debugging and testing more challenging. The ability to record and deterministically replay the program execution is key to address this challenge. However, scalably replaying OpenMP programs is still an unresolved problem. In this paper, we propose two novel techniques that use Distributed Clock (DC) and Distributed Epoch (DE) recording schemes to eliminate excessive thread synchronization for OpenMP record and replay. Our evaluation on representative HPC applications with ReOMP, which we used to realize DC and DE recording, shows that our approach is 2-5x more efficient than traditional approaches that synchronize on every shared-memory access. Furthermore, we demonstrate that our approach can be easily combined with MPI-level replay tools to replay non-trivial MPI+OpenMP applications. We achieve this by integrating \\toolname into ReMPI, an existing scalable MPI record-and-replay tool, with only a small MPI-scale-independent runtime overhead.",
        "keywords": [
          "cs.DC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15995v1",
        "authors": [
          "Xiang Fu",
          "Shiman Meng",
          "Weiping Zhang",
          "Luanzheng Guo",
          "Kento Sato"
        ],
        "arxiv_categories": [
          "cs.DC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distributed Order Recording Techniques",
        "Distributed Clock",
        "Distributed Epoch",
        "Efficient Record",
        "Programs After",
        "Framework",
        "NIST",
        "HPC",
        "MPI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.573787"
    },
    {
      "id": "arxiv-2602.15985v1",
      "title": "Decomposing Large-Scale Ising Problems on FPGAs: A Hybrid Hardware Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15985v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Emerging analog computing substrates, such as oscillator-based Ising machines, offer rapid convergence times for combinatorial optimization but often suffer from limited scalability due to physical implementation constraints. To tackle real-world problems involving thousands of variables, problem decomposition is required; however, performing this step on standard CPUs introduces significant latency, preventing the high-speed solver from operating at full capacity. This work presents a heterogeneous system that offloads the decomposition workload to an FPGA, tightly integrated with a custom 28nm Ising solver. By migrating the decomposition logic to reconfigurable hardware and utilizing parallel processing elements, the system minimizes the communication latency typically associated with host-device interactions. Our evaluation demonstrates that this co-design approach effectively bridges the speed gap between digital preprocessing and analog solving, achieving nearly 2$\\times$ speedup and an energy efficiency improvement of over two orders of magnitude compared to optimized software baselines running on modern CPUs.",
        "keywords": [
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15985v1",
        "authors": [
          "Ruihong Yin",
          "Yue Zheng",
          "Chaohui Li",
          "Ahmet Efe",
          "Abhimanyu Kumar"
        ],
        "arxiv_categories": [
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hybrid Hardware Approach Emerging",
        "Scale Ising Problems",
        "Decomposing Large",
        "Standard",
        "FPGA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.574046"
    },
    {
      "id": "arxiv-2602.15963v1",
      "title": "The human intention. A taxonomy attempt and its applications to robotics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15963v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Despite a surge in robotics research dedicated to inferring and understanding human intent, a universally accepted definition remains elusive since existing works often equate human intention with specific task-related goals. This article seeks to address this gap by examining the multifaceted nature of intention. Drawing on insights from psychology, it attempts to consolidate a definition of intention into a comprehensible framework for a broader audience. The article classifies different types of intention based on psychological and communication studies, offering guidance to researchers shifting from pure technical enhancements to a more human-centric perspective in robotics. It then demonstrates how various robotics studies can be aligned with these intention categories. Finally, through in-depth analyses of collaborative search and object transport use cases, the article underscores the significance of considering the diverse facets of human intention.",
        "keywords": [
          "cs.RO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15963v1",
        "authors": [
          "J. E. Domínguez-Vidal",
          "Alberto Sanfeliu"
        ],
        "arxiv_categories": [
          "cs.RO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Robot",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.574265"
    },
    {
      "id": "arxiv-2602.15954v1",
      "title": "Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15954v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reliable spacecraft attitude control depends on accurate prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC) are employed, where performance is limited by the quality of the internal system model. For spacecraft with complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally heavy. Learning-based system identification presents a compelling alternative; however, models trained exclusively on data frequently exhibit fragile stability properties and limited extrapolation capability. This work explores Physics-Informed Neural Networks (PINNs) for modeling spacecraft attitude dynamics and contrasts it with a conventional data-driven approach. A comprehensive dataset is generated using high-fidelity numerical simulations, and two learning methodologies are investigated: a purely data-driven pipeline and a physics-regularized approach that incorporates prior knowledge into the optimization process. The results indicate that embedding physical constraints during training leads to substantial improvements in predictive reliability, achieving a 68.17% decrease in mean relative error relative. When deployed within an MPC architecture, the physics-informed models yield superior closed-loop tracking performance and improved robustness to uncertainty. Furthermore, a hybrid control formulation that merges the learned nonlinear dynamics with a nominal linear model enables consistent steady-state convergence and significantly faster response, reducing settling times by 61.52%-76.42% under measurement noise and reaction wheel friction.",
        "keywords": [
          "cs.RO",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15954v1",
        "authors": [
          "Carlo Cena",
          "Mauro Martini",
          "Marcello Chiaberge"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Satellite Attitude Control Reliable",
        "Hybrid Model Predictive Control",
        "Informed Neural Networks",
        "Model Predictive Control",
        "Informed Neural Network",
        "Neural Network",
        "Satellite",
        "MPC",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.574608"
    },
    {
      "id": "arxiv-2602.15828v1",
      "title": "Dex4D: Task-Agnostic Point Track Policy for Sim-to-Real Dexterous Manipulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15828v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Learning generalist policies capable of accomplishing a plethora of everyday tasks remains an open challenge in dexterous manipulation. In particular, collecting large-scale manipulation data via real-world teleoperation is expensive and difficult to scale. While learning in simulation provides a feasible alternative, designing multiple task-specific environments and rewards for training is similarly challenging. We propose Dex4D, a framework that instead leverages simulation for learning task-agnostic dexterous skills that can be flexibly recomposed to perform diverse real-world manipulation tasks. Specifically, Dex4D learns a domain-agnostic 3D point track conditioned policy capable of manipulating any object to any desired pose. We train this 'Anypose-to-Anypose' policy in simulation across thousands of objects with diverse pose configurations, covering a broad space of robot-object interactions that can be composed at test time. At deployment, this policy can be zero-shot transferred to real-world tasks without finetuning, simply by prompting it with desired object-centric point tracks extracted from generated videos. During execution, Dex4D uses online point tracking for closed-loop perception and control. Extensive experiments in simulation and on real robots show that our method enables zero-shot deployment for diverse dexterous manipulation tasks and yields consistent improvements over prior baselines. Furthermore, we demonstrate strong generalization to novel objects, scene layouts, backgrounds, and trajectories, highlighting the robustness and scalability of the proposed framework.",
        "keywords": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15828v1",
        "authors": [
          "Yuxuan Kuang",
          "Sungjae Park",
          "Katerina Fragkiadaki",
          "Shubham Tulsiani"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Real Dexterous Manipulation Learning",
        "Agnostic Point Track Policy",
        "Framework",
        "Policy",
        "Robot",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:01.574943"
    },
    {
      "id": "arxiv-2602.16707v1",
      "title": "E-Graphs as a Persistent Compiler Abstraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16707v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recent algorithmic advances have made equality saturation an appealing approach to program optimization because it avoids the phase-ordering problem. Existing work uses external equality saturation libraries, or custom implementations that are deeply tied to the specific application. However, these works only apply equality saturation at a single level of abstraction, or discard the discovered equalities when code is transformed by other compiler passes. We propose an alternative approach that represents an e-graph natively in the compiler's intermediate representation, facilitating the application of constructive compiler passes that maintain the e-graph state throughout the compilation flow. We build on a Python-based MLIR framework, xDSL, and introduce a new MLIR dialect, eqsat, that represents e-graphs in MLIR code. We show that this representation expands the scope of equality saturation in the compiler, allowing us to interleave pattern rewriting with other compiler transformations. The eqsat dialect provides a unified abstraction for compilers to utilize equality saturation across various levels of intermediate representations concurrently within the same MLIR flow.",
        "keywords": [
          "cs.PL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16707v1",
        "authors": [
          "Jules Merckx",
          "Alexandre Lopoukhine",
          "Samuel Coward",
          "Jianyi Cheng",
          "Bjorn De Sutter"
        ],
        "arxiv_categories": [
          "cs.PL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Persistent Compiler Abstraction Recent",
        "Framework",
        "MLIR",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.635414"
    },
    {
      "id": "arxiv-2602.16602v1",
      "title": "A type theory for invertibility in weak $ω$-categories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16602v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a conservative extension ICaTT of the dependent type theory CaTT for weak $ω$-categories with a type witnessing coinductive invertibility of cells. This extension allows for a concise description of the \"walking equivalence\" as a context, and of a set of maps characterising $ω$-equifibrations as substitutions. We provide an implementation of our theory, which we use to formalise basic properties of invertible cells. These properties allow us to give semantics of ICaTT in marked weak $ω$-categories, building a fibrant marked $ω$-category out of every model of ICaTT.",
        "keywords": [
          "math.CT",
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16602v1",
        "authors": [
          "Thibaut Benjamin",
          "Camil Champin",
          "Ioannis Markakis"
        ],
        "arxiv_categories": [
          "math.CT",
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.636362"
    },
    {
      "id": "arxiv-2602.16522v1",
      "title": "Disproving (Positive) Almost-Sure Termination of Probabilistic Term Rewriting via Random Walks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16522v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In recent years, numerous techniques were developed to automatically prove termination of different kinds of probabilistic programs. However, there are only few automated methods to disprove their termination. In this paper, we present the first techniques to automatically disprove (positive) almost-sure termination of probabilistic term rewrite systems. Disproving termination of non-probabilistic systems requires finding a finite representation of an infinite computation, e.g., a loop of the rewrite system. We extend such qualitative techniques to probabilistic term rewriting, where a quantitative analysis is required. In addition to the existence of a loop, we have to count the number of such loops in order to embed suitable random walks into a computation, thereby disproving termination. To evaluate their power, we implemented all our techniques in the tool AProVE.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16522v1",
        "authors": [
          "Jan-Christoph Kassing",
          "Henri Nagel",
          "Alexander Schlecht",
          "Jürgen Giesl"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Probabilistic Term Rewriting",
        "Sure Termination",
        "Random Walks In",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.637369"
    },
    {
      "id": "arxiv-2602.16499v1",
      "title": "Software-heavy Asset Administration Shells: Classification and Use Cases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16499v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Asset Administration Shell (AAS) is an emerging technology for the implementation of digital twins in the field of manufacturing. Software is becoming increasingly important, not only in general but specifically in relation to manufacturing, especially with regard to digital manufacturing and a shift towards the usage of artificial intelligence. This increases the need not only to model software, but also to integrate services directly into the AAS. The existing literature contains individual solutions to implement such software-heavy AAS. However, there is no systematic analysis of software architectures that integrate software services directly into the AAS. This paper aims to fill this research gap and differentiate architectures based on software quality criteria as well as typical manufacturing use cases. This work may be considered as an interpretation guideline for software-heavy AAS, both in academia and for practitioners.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16499v1",
        "authors": [
          "Carsten Ellwein",
          "David Dietrich",
          "Jessica Roth",
          "Rozana Cvitkovic",
          "Andreas Wortmann"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Asset Administration Shells",
        "Artificial Intelligence",
        "Administration Shell",
        "Guideline",
        "Intel",
        "NIST",
        "Act",
        "AAS",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.637856"
    },
    {
      "id": "arxiv-2602.16489v1",
      "title": "Phase-Based Bit Commitment Protocol",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16489v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "With the rise of artificial intelligence and machine learning, a new wave of private information is being flushed into applications. This development raises privacy concerns, as private datasets can be stolen or abused for non-authorized purposes. Secure function computation aims to solve such problems by allowing a service provider to compute functions of datasets in the possession of a a data provider without reading the data itself. A foundational primitive for such tasks is Bit Commitment (BC), which is known to be impossible to realize without added assumptions. Given the pressing nature of the topic, it is thus important to develop BC systems and prove their security under reasonable assumptions. In this work, we provide a novel quantum optical BC protocol that uses the added assumption that the network provider will secure transmission lines against eavesdropping. Under this added assumption, we prove security of our protocol in the honest but curious setting and discuss the hardness of Mayer's attack in the context of our protocol.",
        "keywords": [
          "cs.CR",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16489v1",
        "authors": [
          "Janis Nötzel",
          "Anshul Singhal",
          "Peter van Loock"
        ],
        "arxiv_categories": [
          "cs.CR",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Bit Commitment Protocol",
        "Artificial Intelligence",
        "Machine Learning",
        "Bit Commitment",
        "Protocol",
        "Intel",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.638594"
    },
    {
      "id": "arxiv-2602.16445v1",
      "title": "Pitts and Intuitionistic Multi-Succedent: Uniform Interpolation for KM",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16445v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Pitts' proof-theoretic technique for uniform interpolation, which generates uniform interpolants from terminating sequent calculi, has only been applied to logics on an intuitionistic basis through single-succedent sequent calculi. We adapt the technique to the intuitionistic multi-succedent setting by focusing on the intuitionistic modal logic KM. To do this, we design a novel multi-succedent sequent calculus for this logic which terminates, eliminates cut, and provides a decidability argument for KM. Then, we adapt Pitts' technique to our calculus to construct uniform interpolants for KM, while highlighting the hurdles we overcame. Finally, by (re)proving the algebraisability of KM, we deduce the coherence of the class of KM-algebras. All our results are fully mechanised in the Rocq proof assistant, ensuring correctness and enabling effective computation of interpolants.",
        "keywords": [
          "cs.LO",
          "math.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16445v1",
        "authors": [
          "Hugo Férée",
          "Ian Shillito"
        ],
        "arxiv_categories": [
          "cs.LO",
          "math.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Uniform Interpolation",
        "Intuitionistic Multi",
        "NIST",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.639003"
    },
    {
      "id": "arxiv-2602.16427v1",
      "title": "Formalized Run-Time Analysis of Active Learning -- Coalgebraically in Agda",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16427v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The objective of automata learning is to reconstruct the implementation of a hidden automaton, to which only a teacher has access. The learner can ask certain kinds of queries to the teacher to gain more knowledge about the hidden automaton. The run-time of such a learning algorithm is then measured in the number of queries it takes until the hidden automaton is successfully reconstructed, which is usually parametric in the number of states of that hidden automaton. How can we prove such a run-time complexity of learning algorithms in a proof assistant if we do not have the hidden automaton and the number of states available? In the present paper, we solve this by considering learning algorithms themselves as generalized automata, more specifically as coalgebras. We introduce formal and yet compact definitions of what a learner and a teacher is, which make it easy to prove upper and lower bounds of different kinds of learning games in the proof assistant Agda. As a running example, we discuss the common number guessing game where a teacher thinks of a natural number and answers guesses by the learner with `correct', `too high', or `too low'. To demonstrate our framework, we formally prove in Agda that both the lower and upper bound on number of guesses by the learner is $\\mathcal{O}(\\log n)$, where $n$ is the teacher's secret number.",
        "keywords": [
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16427v1",
        "authors": [
          "Thorsten Wißmann"
        ],
        "arxiv_categories": [
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Active Learning",
        "Formalized Run",
        "Time Analysis",
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.639442"
    },
    {
      "id": "arxiv-2602.16410v1",
      "title": "Reintroducing the Second Player in EPR",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16410v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work we investigate the computational complexity of the satisfiability problem of sub-fragments of the Bernays-Schoenfinkel class of first-order logic, also known as EPR (Effectively Propositional). While Bernays-Schoenfinkel is NEXPTIME-complete, we already can obtain fragments that are PSPACE-complete by restricting our clauses to DET-HORN or KROM. However such restrictions yield very different formulas to the canonical PSPACE-complete language of Quantified Boolean Formulas (QBF). This is despite Bernays-Schoenfinkel having a natural connection to an extension of QBF known as Dependency QBF. Our main contribution is the definition of a PSPACE-complete sub-fragment of Bernays-Schoenfinkel that extends from a translation of QBF, retains a similar two-player game evaluation for its semantics and can be restricted in various ways to obtain other complete problems, particularly those at different levels in the polynomial hierarchy. We use this definition to identify problems in the TPTP library that fall into this fragment and their level in the polynomial hierarchy.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16410v1",
        "authors": [
          "Leroy Chew",
          "Mikoláš Janota",
          "Miroslav Olšák",
          "Martin Suda"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantified Boolean Formulas",
        "Effectively Propositional",
        "Second Player",
        "While Bernays",
        "PSPACE",
        "KROM",
        "TPTP",
        "HORN",
        "DET",
        "QBF",
        "EPR",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.639823"
    },
    {
      "id": "arxiv-2602.16335v1",
      "title": "Inductive Satisfiability Certification for Universal Quantifiers and Uninterpreted Function Symbols",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16335v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The combination of uninterpreted function symbols and universal quantification occurs in many applications of automated reasoning, for example, due to their ability to reason about arrays. Yet the satisfiability of such formulas is, in general, undecidable. In practice, SMT solvers are often successful in the unsatisfiable case, using heuristics. However, in the satisfiable case, they rely on explicit model construction, which fails for formulas whose smallest model is not small enough. We introduce an alternative approach that certifies satisfiability using induction arguments, and apply it to the case of linear integer arithmetic. The resulting algorithm is able to prove satisfiability of formulas that are out of reach for current SMT solvers.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16335v1",
        "authors": [
          "Stefan Ratschan",
          "Anggha Nugraha",
          "Mikoláš Janota",
          "Marek Dančo"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inductive Satisfiability Certification",
        "Universal Quantifiers",
        "Act",
        "SMT",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.640233"
    },
    {
      "id": "arxiv-2602.16324v1",
      "title": "Case Study: Saturations as Explicit Models in Equational Theories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16324v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Automated theorem provers (ATPs) can disprove conjectures by saturating a set of clauses, but the resulting saturated sets are opaque certificates. In the unit equational fragment, a saturated set can in fact be read as a convergent rewrite system defining an explicit, possibly infinite, model -- but this is not widely known, even amongst frequent users of ATPs. Moreover, ATPs do not emit these explicit certificates for infinite (counter-)models. We present such a certificate construction in full, implement it in Vampire and E, and apply it to the recent Equational Theories Project, where hundreds of implications do not admit finite countermodels. The resulting rewrite systems can be checked for confluence and termination by existing certified tools, yielding trustworthy countermodels.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16324v1",
        "authors": [
          "Mikoláš Janota",
          "Michael Rawson",
          "Stephan Schulz"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Explicit Models",
        "Case Study",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.640741"
    },
    {
      "id": "arxiv-2602.16318v1",
      "title": "Interpolation in Proof Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16318v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This chapter provides a comprehensive overview of proof-theoretic methods for establishing interpolation properties across a range of logics, including classical, intuitionistic, modal, and substructural logics. Central to the discussion are two foundational techniques: Maehara's method for Craig interpolation and Pitts' method for uniform interpolation. The chapter demonstrates how these methods lead to results on the existence of well-behaved proof systems in the contemporary framework of universal proof theory and how they provide a road map for constructing interpolation proofs using modern proof formalisms. The emphasis of the chapter is on constructive, modular, and syntax-driven techniques that illuminate deeper connections between interpolation properties and proof systems.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16318v1",
        "authors": [
          "Iris van der Giessen",
          "Raheleh Jalali",
          "Roman Kuznets"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "NIST",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.641104"
    },
    {
      "id": "arxiv-2602.16309v1",
      "title": "The Weight of a Bit: EMFI Sensitivity Analysis of Embedded Deep Learning Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16309v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Fault injection attacks on embedded neural network models have been shown as a potent threat. Numerous works studied resilience of models from various points of view. As of now, there is no comprehensive study that would evaluate the influence of number representations used for model parameters against electromagnetic fault injection (EMFI) attacks. In this paper, we investigate how four different number representations influence the success of an EMFI attack on embedded neural network models. We chose two common floating-point representations (32-bit, and 16-bit), and two integer representations (8-bit, and 4-bit). We deployed four common image classifiers, ResNet-18, ResNet-34, ResNet-50, and VGG-11, on an embedded memory chip, and utilized a low-cost EMFI platform to trigger faults. Our results show that while floating-point representations exhibit almost a complete degradation in accuracy (Top-1 and Top-5) after a single fault injection, integer representations offer better resistance overall. Especially, when considering the the 8-bit representation on a relatively large network (VGG-11), the Top-1 accuracies stay at around 70% and the Top-5 at around 90%.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16309v1",
        "authors": [
          "Jakub Breier",
          "Štefan Kučerák",
          "Xiaolu Hou"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Embedded Deep Learning Models",
        "Sensitivity Analysis",
        "Neural Network",
        "Deep Learning",
        "ResNet-18",
        "ResNet-34",
        "ResNet-50",
        "VGG-11",
        "Top-1",
        "Top-5",
        "EMFI",
        "VGG",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.641592"
    },
    {
      "id": "arxiv-2602.16304v1",
      "title": "Mind the Gap: Evaluating LLMs for High-Level Malicious Package Detection vs. Fine-Grained Indicator Identification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16304v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The prevalence of malicious packages in open-source repositories, such as PyPI, poses a critical threat to the software supply chain. While Large Language Models (LLMs) have emerged as a promising tool for automated security tasks, their effectiveness in detecting malicious packages and indicators remains underexplored. This paper presents a systematic evaluation of 13 LLMs for detecting malicious software packages. Using a curated dataset of 4,070 packages (3,700 benign and 370 malicious), we evaluate model performance across two tasks: binary classification (package detection) and multi-label classification (identification of specific malicious indicators). We further investigate the impact of prompting strategies, temperature settings, and model specifications on detection accuracy. We find a significant \"granularity gap\" in LLMs' capabilities. While GPT-4.1 achieves near-perfect performance in binary detection (F1 $\\approx$ 0.99), performance degrades by approximately 41\\% when the task shifts to identifying specific malicious indicators. We observe that general models are best for filtering out the majority of threats, while specialized coder models are better at detecting attacks that follow a strict, predictable code structure. Our correlation analysis indicates that parameter size and context width have negligible explanatory power regarding detection accuracy. We conclude that while LLMs are powerful detectors at the package level, they lack the semantic depth required for precise identification at the granular indicator level.",
        "keywords": [
          "cs.CR",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16304v1",
        "authors": [
          "Ahmed Ryan",
          "Ibrahim Khalil",
          "Abdullah Al Jahid",
          "Md Erfan",
          "Akond Ashfaque Ur Rahman"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Level Malicious Package Detection",
        "While Large Language Models",
        "GPT-4.1",
        "LLM",
        "GPT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.642191"
    },
    {
      "id": "arxiv-2602.16291v1",
      "title": "A Calculus of Overlays",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16291v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Just as the $λ$-calculus uses three primitives (abstraction, application, variable) as the foundation of functional programming, Overlay-Calculus uses three primitives (record, definition, inheritance) as the foundation of declarative programming. It trivially embeds the $λ$-calculus, although the entire semantics builds on only naive set theory; as a consequence, all constructs including inheritance are inherently commutative, idempotent, and associative; the linearization problem of multiple inheritance simply does not arise. This induces a fully abstract semantics of the lazy $λ$-calculus with respect to Böhm tree equivalence. Overlay-Calculus is distilled from the Overlay language, a practical implementation in which we observed further emergent phenomena: the Expression Problem dissolves, programs are CPS-agnostic, records natively encode random-access memory, and self-reference resolves to multiple targets. These properties suggest applications to configuration languages, dependency injection, object-oriented programming, composable effect systems, modular software architectures, file-system-as-compiler, general-purpose programming, and no-code development.",
        "keywords": [
          "cs.PL",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16291v1",
        "authors": [
          "Bo Yang"
        ],
        "arxiv_categories": [
          "cs.PL",
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Expression Problem",
        "Overlays Just",
        "CPS",
        "Act",
        "MIT",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.643198"
    },
    {
      "id": "arxiv-2602.16268v1",
      "title": "Quantum Oracle Distribution Switching and its Applications to Fully Anonymous Ring Signatures",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16268v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Ring signatures are a powerful primitive that allows a member to sign on behalf of a group, without revealing their identity. Recently, ring signatures have received additional attention as an ingredient for post-quantum deniable authenticated key exchange, e.g., for a post-quantum version of the Signal protocol, employed by virtually all end-to-end-encrypted messenger services. While several ring signature constructions from post-quantum assumptions offer suitable security and efficiency for use in deniable key exchange, they are currently proven secure in the random oracle model (ROM) only, which is insufficient for post-quantum security. In this work, we provide four security reductions in the quantum-accessible random oracle model (QROM) for two generic ring signature constructions: two for the AOS framework and two for a construction paradigm based on ring trapdoors, whose generic backbone we formalize. The two security proofs for AOS ring signatures differ in their requirements on the underlying sigma protocol and their tightness. The two reductions for the ring-trapdoor-based ring signatures exhibit various differences in requirements and the security they provide. We employ the measure-and-reprogram technique, QROM straightline extraction tools based on the compressed oracle, history-free reductions and QROM reprogramming tools. To make use of Rényi divergence properties in the QROM, we study the behavior of quantum algorithms that interact with an oracle whose distribution is based on one of two different distributions over the set of outputs. We provide tight bounds for the statistical distance, show that the Rényi divergence can not be used to replace the entire oracle and provide a workaround.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16268v1",
        "authors": [
          "Marvin Beckmann",
          "Christian Majenz"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Oracle Distribution Switching",
        "Fully Anonymous Ring Signatures",
        "Framework",
        "Protocol",
        "Oracle",
        "QROM",
        "Act",
        "AOS",
        "MIT",
        "ROM",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.644431"
    },
    {
      "id": "arxiv-2602.16156v1",
      "title": "Weak Zero-Knowledge and One-Way Functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16156v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the implications of the existence of weak Zero-Knowledge (ZK) protocols for worst-case hard languages. These are protocols that have completeness, soundness, and zero-knowledge errors (denoted $ε_c$, $ε_s$, and $ε_z$, respectively) that might not be negligible. Under the assumption that there are worst-case hard languages in NP, we show the following: 1. If all languages in NP have NIZK proofs or arguments satisfying $ ε_c+ε_s+ ε_z < 1 $, then One-Way Functions (OWFs) exist. This covers all possible non-trivial values for these error rates. It additionally implies that if all languages in NP have such NIZK proofs and $ε_c$ is negligible, then they also have NIZK proofs where all errors are negligible. Previously, these results were known under the more restrictive condition $ ε_c+\\sqrt{ε_s}+ε_z < 1 $ [Chakraborty et al., CRYPTO 2025]. 2. If all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ ε_c+ε_s+(2k-1).ε_z < 1 $, then OWFs exist. 3. If, for some constant $k$, all languages in NP have $k$-round public-coin ZK proofs or arguments satisfying $ ε_c+ε_s+k.ε_z < 1 $, then infinitely-often OWFs exist.",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16156v1",
        "authors": [
          "Rohit Chatterjee",
          "Yunqi Li",
          "Prashant Nalini Vasudevan"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Way Functions We",
        "Way Functions",
        "Weak Zero",
        "Protocol",
        "CRYPTO",
        "NIZK",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.645304"
    },
    {
      "id": "arxiv-2602.16152v1",
      "title": "The Smallest String Attractors of Fibonacci and Period-Doubling Words",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16152v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A string attractor of a string $T[1..|T|]$ is a set of positions $Γ$ of $T$ such that any substring $w$ of $T$ has an occurrence that crosses a position in $Γ$, i.e., there is a position $i$ such that $w = T[i..i+|w|-1]$ and the intersection $[i,i+|w|-1]\\cap Γ$ is nonempty. The size of the smallest string attractor of Fibonacci words is known to be $2$. We completely characterize the set of all smallest string attractors of Fibonacci words, and show a recursive formula describing the $2^{n-4} + 2^{\\lceil n/2 \\rceil - 2}$ distinct position pairs that are the smallest string attractors of the $n$th Fibonacci word for $n \\geq 7$. Similarly, the size of the smallest string attractor of period-doubling words is known to be $2$. We also completely characterize the set of all smallest string attractors of period-doubling words, and show a formula describing the two distinct position pairs that are the smallest string attractors of the $n$th period-doubling word for $n\\geq 2$. Our results show that strings with the same smallest attractor size can have a drastically different number of distinct smallest attractors.",
        "keywords": [
          "math.CO",
          "cs.DM",
          "cs.FL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16152v1",
        "authors": [
          "Mutsunori Banbara",
          "Hideo Bannai",
          "Peaker Guo",
          "Dominik Köppl",
          "Takuya Mieno"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM",
          "cs.FL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Doubling Words",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.646161"
    },
    {
      "id": "arxiv-2602.16109v1",
      "title": "Federated Graph AGI for Cross-Border Insider Threat Intelligence in Government Financial Schemes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16109v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cross-border insider threats pose a critical challenge to government financial schemes, particularly when dealing with distributed, privacy-sensitive data across multiple jurisdictions. Existing approaches face fundamental limitations: they cannot effectively share intelligence across borders due to privacy constraints, lack reasoning capabilities to understand complex multi-step attack patterns, and fail to capture intricate graph-structured relationships in financial networks. We introduce FedGraph-AGI, a novel federated learning framework integrating Artificial General Intelligence (AGI) reasoning with graph neural networks for privacy-preserving cross-border insider threat detection. Our approach combines: (1) federated graph neural networks preserving data sovereignty; (2) Mixture-of-Experts (MoE) aggregation for heterogeneous jurisdictions; and (3) AGI-powered reasoning via Large Action Models (LAM) performing causal inference over graph data. Through experiments on a 50,000-transaction dataset across 10 jurisdictions, FedGraph-AGI achieves 92.3% accuracy, significantly outperforming federated baselines (86.1%) and centralized approaches (84.7%). Our ablation studies reveal AGI reasoning contributes 6.8% improvement, while MoE adds 4.4%. The system maintains epsilon = 1.0 differential privacy while achieving near-optimal performance and scales efficiently to 50+ clients. This represents the first integration of AGI reasoning with federated graph learning for insider threat detection, opening new directions for privacy-preserving cross-border intelligence sharing.",
        "keywords": [
          "cs.CR",
          "cs.AI",
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16109v1",
        "authors": [
          "Srikumar Nayak",
          "James Walmesley"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI",
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Border Insider Threat Intelligence",
        "Government Financial Schemes Cross",
        "Artificial General Intelligence",
        "Large Action Models",
        "Federated Graph",
        "Neural Network",
        "Framework",
        "Intel",
        "LAM",
        "Act",
        "AGI",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.646719"
    },
    {
      "id": "arxiv-2602.16106v1",
      "title": "Algorithm-Based Pipeline for Reliable and Intent-Preserving Code Translation with LLMs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16106v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Code translation, the automatic conversion of programs between languages, is a growing use case for Large Language Models (LLMs). However, direct one-shot translation often fails to preserve program intent, leading to errors in control flow, type handling, and I/O behavior. We propose an algorithm-based pipeline that introduces a language-neutral intermediate specification to capture these details before code generation. This study empirically evaluates the extent to which structured planning can improve translation accuracy and reliability relative to direct translation. We conduct an automated paired experiment - direct and algorithm-based to translate between Python and Java using five widely used LLMs on the Avatar and CodeNet datasets. For each combination (model, dataset, approach, and direction), we compile and execute the translated program and run the tests provided. We record compilation results, runtime behavior, timeouts (e.g., infinite loop), and test outcomes. We compute accuracy from these tests, counting a translation as correct only if it compiles, runs without exceptions or timeouts, and passes all tests. We then map every failed compile-time and runtime case to a unified, language-aware taxonomy and compare subtype frequencies between the direct and algorithm-based approaches. Overall, the Algorithm-based approach increases micro-average accuracy from 67.7% to 78.5% (10.8% increase). It eliminates lexical and token errors by 100%, reduces incomplete constructs by 72.7%, and structural and declaration issues by 61.1%. It also substantially lowers runtime dependency and entry-point failures by 78.4%. These results demonstrate that algorithm-based pipelines enable more reliable, intent-preserving code translation, providing a foundation for robust multilingual programming assistants.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16106v1",
        "authors": [
          "Shahriar Rumi Dipto",
          "Saikat Mondal",
          "Chanchal K. Roy"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Preserving Code Translation",
        "Large Language Models",
        "Based Pipeline",
        "LLM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.647276"
    },
    {
      "id": "arxiv-2602.16098v1",
      "title": "Collaborative Zone-Adaptive Zero-Day Intrusion Detection for IoBT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16098v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Internet of Battlefield Things (IoBT) relies on heterogeneous, bandwidth-constrained, and intermittently connected tactical networks that face rapidly evolving cyber threats. In this setting, intrusion detection cannot depend on continuous central collection of raw traffic due to disrupted links, latency, operational security limits, and non-IID traffic across zones. We present Zone-Adaptive Intrusion Detection (ZAID), a collaborative detection and model-improvement framework for unseen attack types, where \"zero-day\" refers to previously unobserved attack families and behaviours (not vulnerability disclosure timing). ZAID combines a universal convolutional model for generalisable traffic representations, an autoencoder-based reconstruction signal as an auxiliary anomaly score, and lightweight adapter modules for parameter-efficient zone adaptation. To support cross-zone generalisation under constrained connectivity, ZAID uses federated aggregation and pseudo-labelling to leverage locally observed, weakly labelled behaviours. We evaluate ZAID on ToN_IoT using a zero-day protocol that excludes MITM, DDoS, and DoS from supervised training and introduces them during zone-level deployment and adaptation. ZAID achieves up to 83.16% accuracy on unseen attack traffic and transfers to UNSW-NB15 under the same procedure, with a best accuracy of 71.64%. These results indicate that parameter-efficient, zone-personalised collaboration can improve the detection of previously unseen attacks in contested IoBT environments.",
        "keywords": [
          "cs.CR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16098v1",
        "authors": [
          "Amirmohammad Pasdar",
          "Shabnam Kasra Kermanshahi",
          "Nour Moustafa",
          "Van-Thuan Pham"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Adaptive Intrusion Detection",
        "Day Intrusion Detection",
        "Battlefield Things",
        "Collaborative Zone",
        "Adaptive Zero",
        "Framework",
        "Protocol",
        "UNSW",
        "ZAID",
        "MITM",
        "IID",
        "IoT",
        "NSF",
        "Act",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.647748"
    },
    {
      "id": "arxiv-2602.16091v1",
      "title": "Can Causality Cure Confusion Caused By Correlation (in Software Analytics)?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16091v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Background: Symbolic models, particularly decision trees, are widely used in software engineering for explainable analytics in defect prediction, configuration tuning, and software quality assessment. Most of these models rely on correlational split criteria, such as variance reduction or information gain, which identify statistical associations but cannot imply causation between X and Y. Recent empirical studies in software engineering show that both correlational models and causal discovery algorithms suffer from pronounced instability. This instability arises from two complementary issues: 1-Correlation-based methods conflate association with causation. 2-Causal discovery algorithms rely on heuristic approximations to cope with the NP-hard nature of structure learning, causing their inferred graphs to vary widely under minor input perturbations. Together, these issues undermine trust, reproducibility, and the reliability of explanations in real-world SE tasks. Objective: This study investigates whether incorporating causality-aware split criteria into symbolic models can improve their stability and robustness, and whether such gains come at the cost of predictive or optimization performance. We additionally examine how the stability of human expert judgments compares to that of automated models. Method: Using 120+ multi-objective optimization tasks from the MOOT repository of multi-objective optimization tasks, we evaluate stability through a preregistered bootstrap-ensemble protocol that measures variance with win-score assignments. We compare the stability of human causal assessments with correlation-based decision trees (EZR). We would also compare the causality-aware trees, which leverage conditional-entropy split criteria and confounder filtering. Stability and performance differences are analyzed using statistical methods (variance, Gini Impurity, KS test, Cliff's delta)",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16091v1",
        "authors": [
          "Amirali Rayegan",
          "Tim Menzies"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Can Causality Cure Confusion",
        "Caused By Correlation",
        "Software Analytics",
        "Gini Impurity",
        "Protocol",
        "Fusion",
        "MOOT",
        "EZR",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.648311"
    },
    {
      "id": "arxiv-2602.16069v1",
      "title": "The Limits of Long-Context Reasoning in Automated Bug Fixing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16069v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Rapidly increasing context lengths have led to the assumption that large language models (LLMs) can directly reason over entire codebases. Concurrently, recent advances in LLMs have enabled strong performance on software engineering benchmarks, particularly when paired with agentic workflows. In this work, we systematically evaluate whether current LLMs can reliably perform long-context code debugging and patch generation. Using SWE-bench Verified as a controlled experimental setting, we first evaluate state-of-the-art models within an agentic harness (mini-SWE-agent), where performance improves substantially: GPT-5-nano achieves up to a 31\\% resolve rate on 100 samples, and open-source models such as Deepseek-R1-0528 obtain competitive results. However, token-level analysis shows that successful agentic trajectories typically remain under 20k tokens, and that longer accumulated contexts correlate with lower success rates, indicating that agentic success primarily arises from task decomposition into short-context steps rather than effective long-context reasoning. To directly test long-context capability, we construct a data pipeline where we artificially inflate the context length of the input by placing the relevant files into the context (ensuring perfect retrieval recall); we then study single-shot patch generation under genuinely long contexts (64k-128k tokens). Despite this setup, performance degrades sharply: Qwen3-Coder-30B-A3B achieves only a 7\\% resolve rate at 64k context, while GPT-5-nano solves none of the tasks. Qualitative analysis reveals systematic failure modes, including hallucinated diffs, incorrect file targets, and malformed patch headers. Overall, our findings highlight a significant gap between nominal context length and usable context capacity in current LLMs, and suggest that existing agentic coding benchmarks do not meaningfully evaluate long-context reasoning.",
        "keywords": [
          "cs.SE",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16069v1",
        "authors": [
          "Ravi Raju",
          "Mengmeng Ji",
          "Shubhangi Upasani",
          "Bo Li",
          "Urmish Thakker"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Automated Bug Fixing Rapidly",
        "Context Reasoning",
        "R1-0528",
        "GPT-5",
        "LLM",
        "GPT",
        "SWE",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.649030"
    },
    {
      "id": "arxiv-2602.16047v1",
      "title": "A Unified, Cross-Platform Framework for Automatic GUI and Plugin Generation in Structural Bioinformatics and Beyond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16047v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a workflow and associated toolkit to automate the creation of graphical user interfaces (GUI) for executables run from command line interfaces (CLI). The workflow consists of three phases, namely (Step 1) the plugin design, (Step 2) the formal (platform independent) specification of the GUI, and (Step 3) the plugin code generation for the targeted platforms. Our architecture is aligned with the Model--View--Presenter (MVP) pattern: steps one and two build the Model and View descriptions, while step three implements the Presenter layer that binds inputs, invokes the CLI, and updates outputs. Once Step one has been (manually) completed, steps two and three are fully automated. The decoupled MVP design and platform-specific generator modules enable reuse of logic, portability across ecosystems, and significant reductions in engineering effort for complex interactive applications. We primarily use our workflow to generate GUI in structural bioinformatics for CLI executables from the Structural Bioinformatics Library (SBL), targeting three platforms, namely VMD, Pymol and Web servers. The workflow can be used as a guideline, while its implementation available in the package Plugin_manager from the SBL, see https://sbl.inria.fr/doc/Plugin_manager-user-manual.html.",
        "keywords": [
          "cs.HC",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16047v1",
        "authors": [
          "Sikao Guo",
          "Edoardo Sarti",
          "Frédéric Cazals"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.SE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Structural Bioinformatics Library",
        "Structural Bioinformatics",
        "Platform Framework",
        "Plugin Generation",
        "Framework",
        "Once Step",
        "Guideline",
        "Beyond We",
        "CLI",
        "SBL",
        "GUI",
        "Act",
        "MVP",
        "VMD",
        "EU"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:06.649469"
    },
    {
      "id": "arxiv-2602.15983v1",
      "title": "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15983v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large language models (LLMs) can translate natural language into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90 percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two complementary directions. Structured generation decomposes code production into a four-stage reasoning chain (understand, formalize, synthesize, verify) that mirrors expert modeling practice, with explicit variable-type reasoning and self-verification to prevent formulation errors at their source. Behavioral verification detects errors that survive generation by testing whether the formulation responds correctly to solver-based parameter perturbation, without requiring ground truth -- an external semantic signal that bypasses the self-consistency problem inherent in LLM-based code review. The two mechanisms are complementary: structured generation dominates on complex compositional problems, while behavioral verification becomes the largest single contributor on problems with localized formulation defects. Together with execution recovery via IIS-enhanced diagnostics, ReLoop raises correctness from 22.6% to 31.1% and execution from 72.1% to 100.0% on the strongest model, with consistent gains across five models spanning three paradigms (foundation, SFT, RL) and three benchmarks. We additionally release RetailOpt-190, 190 compositional retail optimization scenarios targeting the multi-constraint interactions where LLMs most frequently fail.",
        "keywords": [
          "cs.SE",
          "cs.AI",
          "cs.LG",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15983v1",
        "authors": [
          "Junbo Jacob Lian",
          "Yujun Sun",
          "Huiling Chen",
          "Chaoyu Zhang",
          "Chung-Piaw Teo"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI",
          "cs.LG",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Optimization Large",
        "Behavioral Verification",
        "Structured Modeling",
        "RetailOpt-190",
        "LLM",
        "IIS",
        "SFT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.649975"
    },
    {
      "id": "arxiv-2602.15981v1",
      "title": "A Theoretical Approach to Stablecoin Design via Price Windows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15981v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we explore the short- and long-term stability of backed stablecoins offering constant mint and redeem prices to all agents. We refer to such designs as price window-based, since the mint and redeem prices constrain the stablecoin's market equilibrium. We show that, without secondary stabilization mechanisms, price window designs cannot achieve both short- and long-term stability unless they are backed by already-stable reserves. In particular, the mechanism faces a tradeoff: either risk eventual reserve depletion through persistent arbitrage by a speculator, or widen the distance between mint and redeem prices enough to disincentivize arbitrage. In the latter case, however, the market price of the stablecoin inherits the volatility of its backing asset, with fluctuations that can be proportional to the backing asset's own volatility.",
        "keywords": [
          "cs.GT",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15981v1",
        "authors": [
          "Katherine Molinet",
          "Aris Filos-Ratsikas"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.CR"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Stablecoin Design",
        "Price Windows In",
        "Wind",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:06.650260"
    },
    {
      "id": "arxiv-2602.15975v1",
      "title": "Hybrid Tabletop Exercise (TTX) based on a Mathematical Simulation-based Model for the Maritime Sector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15975v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "As cyber threats grow in complexity and scale, many security incidents remain poorly managed due to the lack of proper training among C-level executives. Thus, there is a need for targeted cybersecurity education to enhance executive decision-making and crisis response. Traditional training methods, such as cyber wargames and Tabletop Exercises (TTX), aim to develop abilities to face critical incidents, however, they often lack the interactive and dynamic elements required to prepare individuals for real-world cyber incidents. This paper presents a novel approach to cybersecurity and cyberdefense education through the design of a specialized hybrid TTX for the maritime domain, which uses a framework to model mathematically how a cyberattack spreads along multiple nodes and impacts infrastructure. Our proposal was validated through exercises in Argentina and the United States, demonstrating a positive impact in developing the comprehension and projection levels of Cyber Situational Awareness (CSA), and reinforcing governance. Documentation about the Hybrid TTX, scenario, datasets and implementation of the SERDUX-MARCIM model, is available at the project repository at https://github.com/diegocabuya/SERDUX-MARCIM",
        "keywords": [
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15975v1",
        "authors": [
          "Diego Cabuya-Padilla",
          "Daniel Díaz-López",
          "Carlos Castaneda-Marroquín"
        ],
        "arxiv_categories": [
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cyber Situational Awareness",
        "Hybrid Tabletop Exercise",
        "Mathematical Simulation",
        "Maritime Sector As",
        "Tabletop Exercises",
        "United States",
        "Framework",
        "SERDUX",
        "MARCIM",
        "EPA",
        "CSA",
        "Act",
        "TTX",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.650614"
    },
    {
      "id": "arxiv-2602.15968v1",
      "title": "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15968v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors conceptualize documentation practices, and how these tools connect to existing systems, regulations, and cultural norms. Our analysis shows four persistent patterns in dataset documentation conceptualization that potentially impede adoption and standardization: unclear operationalizations of documentation's value, decontextualized designs, unaddressed labor demands, and a tendency to treat integration as future work. Building on these findings, we propose a shift in Responsible AI tool design toward institutional rather than individual solutions, and outline actions the HCI community can take to enable sustainable documentation practices.",
        "keywords": [
          "cs.SE",
          "cs.AI",
          "cs.CY",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15968v1",
        "authors": [
          "Pedro Reynolds-Cuéllar",
          "Marisol Wong-Villacres",
          "Adriana Alvarado Garcia",
          "Heila Precel"
        ],
        "arxiv_categories": [
          "cs.SE",
          "cs.AI",
          "cs.CY",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dataset Documentation Tools Dataset",
        "From Reflection",
        "Scoping Review",
        "Regulation",
        "Standard",
        "EPA",
        "HCI",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.650941"
    },
    {
      "id": "arxiv-2602.15966v1",
      "title": "Hardware-Agnostic Modeling of Quantum Side-Channel Leakage via Conditional Dynamics and Learning from Full Correlation Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15966v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study a sequential coherent side-channel model in which an adversarial probe qubit interacts with a target qubit during a hidden gate sequence. Repeating the same hidden sequence for $N$ shots yields an empirical full-correlation record: the joint histogram $\\widehat{P}_g(b)$ over probe bit-strings $b\\in\\{0,1\\}^k$, which is a sufficient statistic for classical post-processing under identically and independently distributed (i.i.d.) shots but grows exponentially with circuit depth. We first describe this sequential probe framework in a coupling- and measurement-agnostic form, emphasizing the scaling of the observation space and why exact analytic distinguishability becomes intractable with circuit depth. We then specialize to a representative instantiation (a controlled-rotation probe coupling with fixed projective readout and a commuting $R_x$ gate alphabet) where we (i) derive a depth-dependent leakage envelope whose maximizer predicts a \"Goldilocks\" coupling band as a function of depth, and (ii) provide an operational decoder, via machine learning, a single parameter-conditioned map from $\\widehat{P}_g$ to Alice's per-step gate labels, generalizing across coupling and noise settings without retraining. Experiments over broad coupling and noise grids show that strict sequence recovery concentrates near the predicted coupling band and degrades predictably under decoherence and finite-shot estimation.",
        "keywords": [
          "quant-ph",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15966v1",
        "authors": [
          "Brennan Bell",
          "Andreas Trügler",
          "Konstantin Beyer",
          "Paul Erker"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Full Correlation Data We",
        "Conditional Dynamics",
        "Agnostic Modeling",
        "Machine Learning",
        "Channel Leakage",
        "Quantum Side",
        "Framework",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.651343"
    },
    {
      "id": "arxiv-2602.15945v1",
      "title": "From Tool Orchestration to Code Execution: A Study of MCP Design Choices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15945v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Model Context Protocols (MCPs) provide a unified platform for agent systems to discover, select, and orchestrate tools across heterogeneous execution environments. As MCP-based systems scale to incorporate larger tool catalogs and multiple concurrently connected MCP servers, traditional tool-by-tool invocation increases coordination overhead, fragments state management, and limits support for wide-context operations. To address these scalability challenges, recent MCP designs have incorporated code execution as a first-class capability, an approach called Code Execution MCP (CE-MCP). This enables agents to consolidate complex workflows, such as SQL querying, file analysis, and multi-step data transformations, into a single program that executes within an isolated runtime environment. In this work, we formalize the architectural distinction between context-coupled (traditional) and context-decoupled (CE-MCP) models, analyzing their fundamental scalability trade-offs. Using the MCP-Bench framework across 10 representative servers, we empirically evaluate task behavior, tool utilization patterns, execution latency, and protocol efficiency as the scale of connected MCP servers and available tools increases, demonstrating that while CE-MCP significantly reduces token usage and execution latency, it introduces a vastly expanded attack surface. We address this security gap by applying the MAESTRO framework, identifying sixteen attack classes across five execution phases-including specific code execution threats such as exception-mediated code injection and unsafe capability synthesis. We validate these vulnerabilities through adversarial scenarios across multiple LLMs and propose a layered defense architecture comprising containerized sandboxing and semantic gating. Our findings provide a rigorous roadmap for balancing scalability and security in production-ready executable agent workflows.",
        "keywords": [
          "cs.CR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15945v1",
        "authors": [
          "Yuval Felendler",
          "Parth A. Gandhi",
          "Idan Habler",
          "Yuval Elovici",
          "Asaf Shabtai"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Design Choices Model Context",
        "From Tool Orchestration",
        "Code Execution",
        "Framework",
        "Protocol",
        "LLM",
        "SQL",
        "NSF",
        "MIT",
        "MCP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.651835"
    },
    {
      "id": "arxiv-2602.15821v1",
      "title": "Computation and Size of Interpolants for Hybrid Modal Logics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15821v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent research has established complexity results for the problem of deciding the existence of interpolants in logics lacking the Craig Interpolation Property (CIP). The proof techniques developed so far are non-constructive, and no meaningful bounds on the size of interpolants are known. Hybrid modal logics (or modal logics with nominals) are a particularly interesting class of logics without CIP: in their case, CIP cannot be restored without sacrificing decidability and, in applications, interpolants in these logics can serve as definite descriptions and separators between positive and negative data examples in description logic knowledge bases. In this contribution we show, using a new hypermosaic elimination technique, that in many standard hybrid modal logics Craig interpolants can be computed in fourfold exponential time, if they exist. On the other hand, we show that the existence of uniform interpolants is undecidable, which is in stark contrast to modal or intuitionistic logic where uniform interpolants always exist.",
        "keywords": [
          "cs.LO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15821v1",
        "authors": [
          "Jean Christoph Jung",
          "Jędrzej Kołodziejski",
          "Frank Wolter"
        ],
        "arxiv_categories": [
          "cs.LO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Craig Interpolation Property",
        "Hybrid Modal Logics Recent",
        "Standard",
        "NIST",
        "EPA",
        "CIP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.652135"
    },
    {
      "id": "arxiv-2602.15815v1",
      "title": "Natural Privacy Filters Are Not Always Free: A Characterization of Free Natural Filters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15815v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study natural privacy filters, which enable the exact composition of differentially private (DP) mechanisms with adaptively chosen privacy characteristics. Earlier privacy filters consider only simple privacy parameters such as Rényi-DP or Gaussian DP parameters. Natural filters account for the entire privacy profile of every query, promising greater utility for a given privacy budget. We show that, contrary to other forms of DP, natural privacy filters are not free in general. Indeed, we show that only families of privacy mechanisms that are well-ordered when composed admit free natural privacy filters.",
        "keywords": [
          "cs.CR",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15815v1",
        "authors": [
          "Matthew Regehr",
          "Bingshan Hu",
          "Ethan Leeman",
          "Pasin Manurangsi",
          "Pierre Tholoniat"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Natural Privacy Filters Are",
        "Free Natural Filters We",
        "Not Always Free",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.652537"
    },
    {
      "id": "arxiv-2602.15802v1",
      "title": "Local Node Differential Privacy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15802v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We initiate an investigation of node differential privacy for graphs in the local model of private data analysis. In our model, dubbed LNDP, each node sees its own edge list and releases the output of a local randomizer on this input. These outputs are aggregated by an untrusted server to obtain a final output. We develop a novel algorithmic framework for this setting that allows us to accurately answer arbitrary linear queries on a blurry approximation of the input graph's degree distribution. For some natural problems, the resulting algorithms match the accuracy achievable with node privacy in the central model, where data are held and processed by a trusted server. We also prove lower bounds on the error required by LNDP that imply the optimality of our algorithms for several fundamental graph statistics. We then lift these lower bounds to the interactive LNDP setting, demonstrating the optimality of our algorithms even when constantly many rounds of interaction are permitted. Obtaining our lower bounds requires new approaches, since those developed for the usual local model do not apply to the inherently overlapping inputs that arise from graphs. Finally, we prove structural results that reveal qualitative differences between local node privacy and the standard local model for tabular data.",
        "keywords": [
          "cs.DS",
          "cs.CR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15802v1",
        "authors": [
          "Sofya Raskhodnikova",
          "Adam Smith",
          "Connor Wagaman",
          "Anatoly Zavyalov"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.CR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Local Node Differential Privacy",
        "Framework",
        "Standard",
        "LNDP",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.652895"
    },
    {
      "id": "arxiv-2602.15761v1",
      "title": "A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15761v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.",
        "keywords": [
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15761v1",
        "authors": [
          "Simantika Bhattacharjee Dristi",
          "Matthew B. Dwyer"
        ],
        "arxiv_categories": [
          "cs.SE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generated Code Refactorings With",
        "Functional Equivalence",
        "Differential Fuzzing",
        "Based Evaluation",
        "Qwen-2.5",
        "Olmo-3",
        "LLM",
        "GPT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.653254"
    },
    {
      "id": "arxiv-2602.15756v1",
      "title": "A Note on Non-Composability of Layerwise Approximate Verification for Neural Inference",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15756v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A natural and informal approach to verifiable (or zero-knowledge) ML inference over floating-point data is: ``prove that each layer was computed correctly up to tolerance $δ$; therefore the final output is a reasonable inference result''. This short note gives a simple counterexample showing that this inference is false in general: for any neural network, we can construct a functionally equivalent network for which adversarially chosen approximation-magnitude errors in individual layer computations suffice to steer the final output arbitrarily (within a prescribed bounded range).",
        "keywords": [
          "cs.CR",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15756v1",
        "authors": [
          "Or Zamir"
        ],
        "arxiv_categories": [
          "cs.CR",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Layerwise Approximate Verification",
        "Neural Inference",
        "Neural Network",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:06.653691"
    },
    {
      "id": "arxiv-2602.16638v1",
      "title": "An $n^{2+o(1)}$ Time Algorithm for Single-Source Negative Weight Shortest Paths",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16638v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a randomized algorithm for the single-source shortest paths (SSSP) problem on directed graphs with arbitrary real-valued edge weights that runs in $n^{2+o(1)}$ time with high probability. This result yields the first almost linear-time algorithm for the problem on dense graphs ($m = Θ(n^2)$) and improves upon the best previously known bounds for moderately dense graphs ($m = ω(n^{1.306})$). Our approach builds on the hop-reduction via shortcutting framework introduced by Li, Li, Rao, and Zhang (2025), which iteratively augments the graph with shortcut edges to reduce the negative hop count of shortest paths. The central computational bottleneck in prior work is the cost of explicitly constructing these shortcuts in dense regions. We overcome this by introducing a new compression technique using auxiliary Steiner vertices. Specifically, we construct these vertices to represent large neighborhoods compactly in a structured manner, allowing us to efficiently generate and propagate shortcuts while strictly controlling the growth of vertex degrees and graph size.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16638v1",
        "authors": [
          "Sanjeev Khanna",
          "Junkai Song"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Source Negative Weight Shortest",
        "Time Algorithm",
        "Framework",
        "Paths We",
        "SSSP",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.739636"
    },
    {
      "id": "arxiv-2602.16605v1",
      "title": "Fast Shortest Path in Graphs With Sparse Signed Tree Models and Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16605v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A signed tree model of a graph $G$ is a compact binary structure consisting of a rooted binary tree whose leaves are bijectively mapped to the vertices of $G$, together with 2-colored edges $xy$, called transversal pairs, interpreted as bicliques or anti-bicliques whose sides are the leaves of the subtrees rooted at $x$ and at $y$. We design an algorithm that, given such a representation of an $n$-vertex graph $G$ with $p$ transversal pairs and a source $v \\in V(G)$, computes a shortest-path tree rooted at $v$ in $G$ in time $O(p \\log n)$. A wide variety of graph classes are such that for all $n$, their $n$-vertex graphs admit signed tree models with $O(n)$ transversal pairs: for instance, those of bounded symmetric difference, more generally of bounded sd-degeneracy, as well as interval graphs. As applications of our Single-Source Shortest Path algorithm and new techniques, we - improve the runtime of the fixed-parameter algorithm for first-order model checking on graphs given with a witness of low merge-width from cubic [Dreier and Toruńczyk, STOC '25] to quadratic; - give an $O(n^2 \\log n)$-time algorithm for All-Pairs Shortest Path (APSP) on graphs given with a witness of low merge-width, generalizing a result known on twin-width [Twin-Width III, SICOMP '24]; - extend and simplify an $O(n^2 \\log n)$-time algorithm for multiplying two $n \\times n$ matrices $A, B$ of bounded twin-width in [Twin-Width V, STACS '23]: now $A$ solely has to be an adjacency matrix of a graph of bounded twin-width and $B$ can be arbitrary; - give an $O(n^2 \\log^2 n)$-time algorithm for APSP on graphs of bounded twin-width, bypassing the need for contraction sequences in [Twin-Width III, SICOMP '24; Bannach et al. STACS '24]; - give an $O(n^{7/3} \\log^2 n)$-time algorithm for APSP on graphs of symmetric difference $O(n^{1/3})$.",
        "keywords": [
          "cs.DS",
          "cs.DM",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16605v1",
        "authors": [
          "Édouard Bonnet",
          "Colin Geniet",
          "Eun Jung Kim",
          "Sungmin Moon"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.DM",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Graphs With Sparse Signed",
        "Source Shortest Path",
        "Pairs Shortest Path",
        "Fast Shortest Path",
        "Tree Models",
        "SICOMP",
        "STACS",
        "APSP",
        "STOC",
        "Act",
        "MIT",
        "WHO",
        "III",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.740933"
    },
    {
      "id": "arxiv-2602.16532v1",
      "title": "The S-Hamiltonian Cycle Problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16532v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Determining if an input undirected graph is Hamiltonian, i.e., if it has a cycle that visits every vertex exactly once, is one of the most famous NP-complete problems. We consider the following generalization of Hamiltonian cycles: for a fixed set $S$ of natural numbers, we want to visit each vertex of a graph $G$ exactly once and ensure that any two consecutive vertices can be joined in $k$ hops for some choice of $k \\in S$. Formally, an $S$-Hamiltonian cycle is a permutation $(v_0,\\ldots,v_{n-1})$ of the vertices of $G$ such that, for $0 \\leq i \\leq n-1$, there exists a walk between $v_i$ and $v_{i+1 \\bmod n}$ whose length is in $S$. (We do not impose any constraints on how many times vertices can be visited as intermediate vertices of walks.) Of course Hamiltonian cycles in the standard sense correspond to $S=\\{1\\}$. We study the $S$-Hamiltonian cycle problem of deciding whether an input graph $G$ has an $S$-Hamiltonian cycle. Our goal is to determine the complexity of this problem depending on the fixed set $S$. It is already known that the problem remains NP-complete for $S=\\{1,2\\}$, whereas it is trivial for $S=\\{1,2,3\\}$ because any connected graph contains a $\\{1,2,3\\}$-Hamiltonian cycle. Our work classifies the complexity of this problem for most kinds of sets $S$, with the key new results being the following: we have NP-completeness for $S = \\{2\\}$ and for $S = \\{2, 4\\}$, but tractability for $S = \\{1, 2, 4\\}$, for $S = \\{2, 4, 6\\}$, for any superset of these two tractable cases, and for $S$ the infinite set of all odd integers. The remaining open cases are the non-singleton finite sets of odd integers, in particular $S = \\{1, 3\\}$. Beyond cycles, we also discuss the complexity of finding $S$-Hamiltonian paths, and show that our problems are all tractable on graphs of bounded cliquewidth.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16532v1",
        "authors": [
          "Antoine Amarilli",
          "Arthur Lombardo",
          "Mikaël Monet"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hamiltonian Cycle Problem Determining",
        "Standard",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.741625"
    },
    {
      "id": "arxiv-2602.16518v1",
      "title": "Improved Bounds for Discrete Voronoi Games",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16518v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In the planar one-round discrete Voronoi game, two players $\\mathcal{P}$ and $\\mathcal{Q}$ compete over a set $V$ of $n$ voters represented by points in $\\mathbb{R}^2$. First, $\\mathcal{P}$ places a set $P$ of $k$ points, then $\\mathcal{Q}$ places a set $Q$ of $\\ell$ points, and then each voter $v\\in V$ is won by the player who has placed a point closest to $v$. It is well known that if $k=\\ell=1$, then $\\mathcal{P}$ can always win $n/3$ voters and that this is worst-case optimal. We study the setting where $k>1$ and $\\ell=1$. We present lower bounds on the number of voters that $\\mathcal{P}$ can always win, which improve the existing bounds for all $k\\geq 4$. As a by-product, we obtain improved bounds on small $\\varepsilon$-nets for convex ranges. These results are for the $L_2$ metric. We also obtain lower bounds on the number of voters that $\\mathcal{P}$ can always win when distances are measured in the $L_1$ metric.",
        "keywords": [
          "cs.CG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16518v1",
        "authors": [
          "Mark de Berg",
          "Geert van Wordragen"
        ],
        "arxiv_categories": [
          "cs.CG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Discrete Voronoi Games In",
        "Improved Bounds",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.741941"
    },
    {
      "id": "arxiv-2602.16465v1",
      "title": "The Complexity Landscape of Two-Stage Robust Selection Problems with Budgeted Uncertainty",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16465v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A standard type of uncertainty set in robust optimization is budgeted uncertainty, where an interval of possible values for each parameter is given and the total deviation from their lower bounds is bounded. In the two-stage setting, discrete and continuous budgeted uncertainty have to be distinguished. The complexity of such problems is largely unexplored, in particular if the underlying nominal optimization problem is simple, such as for selection problems. In this paper, we give a comprehensive answer to long-standing open complexity questions for three types of selection problems and three types of budgeted uncertainty sets. In particular, we demonstrate that the two-stage selection problem with continuous budgeted uncertainty is NP-hard, while the corresponding two-stage representative selection problem is solvable in polynomial time. Our hardness result implies that also the two-stage assignment problem with continuous budgeted uncertainty is NP-hard.",
        "keywords": [
          "math.OC",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16465v1",
        "authors": [
          "Marc Goerigk",
          "Dorothee Henke",
          "Lasse Wulf"
        ],
        "arxiv_categories": [
          "math.OC",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stage Robust Selection Problems",
        "Budgeted Uncertainty",
        "Standard",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.742269"
    },
    {
      "id": "arxiv-2602.16387v1",
      "title": "Computing Tarski Fixed Points in Financial Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16387v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Modern financial networks are highly connected and result in complex interdependencies of the involved institutions. In the prominent Eisenberg-Noe model, a fundamental aspect is clearing -- to determine the amount of assets available to each financial institution in the presence of potential defaults and bankruptcy. A clearing state represents a fixed point that satisfies a set of natural axioms. Existence can be established (even in broad generalizations of the model) using Tarski's theorem. While a maximal fixed point can be computed in polynomial time, the complexity of computing other fixed points is open. In this paper, we provide an efficient algorithm to compute a minimal fixed point that runs in strongly polynomial time. It applies in a broad generalization of the Eisenberg-Noe model with any monotone, piecewise-linear payment functions and default costs. Moreover, in this scenario we provide a polynomial-time algorithm to compute a maximal fixed point. For networks without default costs, we can efficiently decide the existence of fixed points in a given range. We also study claims trading, a local network adjustment to improve clearing, when networks are evaluated with minimal clearing. We provide an efficient algorithm to decide existence of Pareto-improving trades and compute optimal ones if they exist.",
        "keywords": [
          "cs.DS",
          "cs.GT",
          "q-fin.RM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16387v1",
        "authors": [
          "Leander Besting",
          "Martin Hoefer",
          "Lars Huth"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.GT",
          "q-fin.RM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Computing Tarski Fixed Points",
        "Financial Networks Modern",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.742691"
    },
    {
      "id": "arxiv-2602.16311v1",
      "title": "When to Identify Is to Control: On the Controllability of Combinatorial Optimization Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16311v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Consider a finite ground set $E$, a set of feasible solutions $X \\subseteq \\mathbb{R}^{E}$, and a class of objective functions $\\mathcal{C}$ defined on $X$. We are interested in subsets $S$ of $E$ that control $X$ in the sense that we can induce any given solution $x \\in X$ as an optimum for any given objective function $c \\in \\mathcal{C}$ by adding linear terms to $c$ on the coordinates corresponding to $S$. This problem has many applications, e.g., when $X$ corresponds to the set of all traffic flows, the ability to control implies that one is able to induce all target flows by imposing tolls on the edges in $S$. Our first result shows the equivalence between controllability and identifiability. If $X$ is convex, or if $X$ consists of binary vectors, then $S$ controls $X$ if and only if the restriction of $x$ to $S$ uniquely determines $x$ among all solutions in $X$. In the convex case, we further prove that the family of controlling sets forms a matroid. This structural insight yields an efficient algorithm for computing minimum-weight controlling sets from a description of the affine hull of $X$. While the equivalence extends to matroid base families, the picture changes sharply for other discrete domains. We show that when $X$ is equal to the set of $s$-$t$-paths in a directed graph, deciding whether an identifying set of a given cardinality exists is $Σ\\mathsf{_2^P}$-complete. The problem remains $\\mathsf{NP}$-hard even on acyclic graphs. For acyclic instances, however, we obtain an approximation guarantee by proving a tight bound on the gap between the smallest identifying sets for $X$ and its convex hull, where the latter corresponds to the $s$-$t$-flow polyhedron.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16311v1",
        "authors": [
          "Max Klimm",
          "Jannik Matuschke"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Combinatorial Optimization Problems Consider",
        "Identify Is",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.743982"
    },
    {
      "id": "arxiv-2602.16306v1",
      "title": "Dynamic and Streaming Algorithms for Union Volume Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16306v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The union volume estimation problem asks to $(1\\pm\\varepsilon)$-approximate the volume of the union of $n$ given objects $X_1,\\ldots,X_n \\subset \\mathbb{R}^d$. In their seminal work in 1989, Karp, Luby, and Madras solved this problem in time $O(n/\\varepsilon^2)$ in an oracle model where each object $X_i$ can be accessed via three types of queries: obtain the volume of $X_i$, sample a random point from $X_i$, and test whether $X_i$ contains a given point $x$. This running time was recently shown to be optimal [Bringmann, Larsen, Nusser, Rotenberg, and Wang, SoCG'25]. In another line of work, Meel, Vinodchandran, and Chakraborty [PODS'21] designed algorithms that read the objects in one pass using polylogarithmic time per object and polylogarithmic space; this can be phrased as a dynamic algorithm supporting insertions of objects for union volume estimation in the oracle model. In this paper, we study algorithms for union volume estimation in the oracle model that support both insertions and deletions of objects. We obtain the following results: - an algorithm supporting insertions and deletions in polylogarithmic update and query time and linear space (this is the first such dynamic algorithm, even for 2D triangles); - an algorithm supporting insertions and suffix queries (which generalizes the sliding window setting) in polylogarithmic update and query time and space; - an algorithm supporting insertions and deletions of convex bodies of constant dimension in polylogarithmic update and query time and space.",
        "keywords": [
          "cs.CG",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16306v1",
        "authors": [
          "Sujoy Bhore",
          "Karl Bringmann",
          "Timothy M. Chan",
          "Yanheng Wang"
        ],
        "arxiv_categories": [
          "cs.CG",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Streaming Algorithms",
        "Oracle",
        "Wind",
        "PODS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.744458"
    },
    {
      "id": "arxiv-2602.16300v1",
      "title": "Randomized Zero Forcing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16300v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce randomized zero forcing (RZF), a stochastic color-change process on directed graphs in which a white vertex turns blue with probability equal to the fraction of its incoming neighbors that are blue. Unlike probabilistic zero forcing, RZF is governed by in-neighborhood structure and can fail to propagate globally due to directionality. The model extends naturally to weighted directed graphs by replacing neighbor counts with incoming weight proportions. We study the expected propagation time of RZF, establishing monotonicity properties with respect to enlarging the initial blue set and increasing weights on edges out of initially blue vertices, as well as invariances that relate weighted and unweighted dynamics. Exact values and sharp asymptotics are obtained for several families of directed graphs, including arborescences, stars, paths, cycles, and spiders, and we derive tight extremal bounds for unweighted directed graphs in terms of basic parameters such as order, degree, and radius. We conclude with an application to an empirical input-output network, illustrating how expected propagation time under RZF yields a dynamic, process-based notion of centrality in directed weighted systems.",
        "keywords": [
          "math.CO",
          "cs.DM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16300v1",
        "authors": [
          "Jesse Geneson",
          "Illya Hicks",
          "Noah Lichtenberg",
          "Alvin Moon",
          "Nicolas Robles"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Randomized Zero Forcing We",
        "RZF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.744831"
    },
    {
      "id": "arxiv-2602.16289v1",
      "title": "Condorcet Dimension and Pareto Optimality for Matchings and Beyond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16289v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study matching problems in which agents form one side of a bipartite graph and have preferences over objects on the other side. A central solution concept in this setting is popularity: a matching is popular if it is a (weak) Condorcet winner, meaning that no other matching is preferred by a strict majority of agents. It is well known, however, that Condorcet winners need not exist. We therefore turn to a natural and prominent relaxation. A set of matchings is a Condorcet-winning set if, for every competing matching, a majority of agents prefers their favorite matching in the set over the competitor. The Condorcet dimension is the smallest cardinality of a Condorcet-winning set. Our main results reveal a connection between Condorcet-winning sets and Pareto optimality. We show that any Pareto-optimal set of two matchings is, in particular, a Condorcet-winning set. This implication continues to hold when we impose matroid constraints on the set of matched objects, and even when agents' valuations are given as partial orders. The existence picture, however, changes sharply with partial orders. While for weak orders a Pareto-optimal set of two matchings always exists, this is -- surprisingly -- not the case under partial orders. Consequently, although the Condorcet dimension for matchings is 2 under weak orders (even under matroid constraints), this guarantee fails for partial orders: we prove that the Condorcet dimension is $Θ(\\sqrt{n})$, and rises further to $Θ(n)$ when matroid constraints are added. On the computational side, we show that, under partial orders, deciding whether there exists a Condorcet -- winning set of a given fixed size is NP-hard. The same holds for deciding the existence of a Pareto-optimal matching, which we believe to be of independent interest. Finally, we also show that the Condorcet dimension for a related problem on arborescences is also 2.",
        "keywords": [
          "cs.GT",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16289v1",
        "authors": [
          "Telikepalli Kavitha",
          "Jannik Matuschke",
          "Ulrike Schmidt-Kraepelin"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.DS"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Condorcet Dimension",
        "Pareto Optimality",
        "Beyond We",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:11.745848"
    },
    {
      "id": "arxiv-2602.16240v1",
      "title": "Submodular Maximization under Supermodular Constraint: Greedy Guarantees",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16240v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Motivated by a wide range of applications in data mining and machine learning, we consider the problem of maximizing a submodular function subject to supermodular cost constraints. In contrast to the well-understood setting of cardinality and matroid constraints, where greedy algorithms admit strong guarantees, the supermodular constraint regime remains poorly understood -- guarantees for greedy methods and other efficient algorithmic paradigms are largely open. We study this family of fundamental optimization problems under an upper-bound constraint on a supermodular cost function with curvature parameter $γ$. Our notion of supermodular curvature is less restrictive than prior definitions, substantially expanding the class of admissible cost functions. We show that our greedy algorithm that iteratively includes elements maximizing the ratio of the objective and constraint functions, achieves a $\\left(1 - e^{-(1-γ)}\\right)$-approximation before stopping. We prove that this approximation is indeed tight for this algorithm. Further, if the objective function has a submodular curvature $c$, then we show that the bound further improves to $\\left(1 - (1- (1-c)(1-γ))^{1/(1-c)}\\right)$, which can be further improved by continuing to violate the constraint. Finally, we show that the Greedy-Ratio-Marginal in conjunction with binary search leads to a bicriteria approximation for the dual problem -- minimizing a supermodular function under a lower bound constraint on a submodular function. We conduct a number of experiments on a simulation of LLM agents debating over multiple rounds -- the task is to select a subset of agents to maximize correctly answered questions. Our algorithm outperforms all other greedy heuristics, and on smaller problems, it achieves the same performance as the optimal set found by exhaustive search.",
        "keywords": [
          "cs.DS",
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16240v1",
        "authors": [
          "Ajitesh Srivastava",
          "Shanghua Teng"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.CC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Greedy Guarantees Motivated",
        "Supermodular Constraint",
        "Submodular Maximization",
        "Machine Learning",
        "LLM",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.746600"
    },
    {
      "id": "arxiv-2602.16153v1",
      "title": "Bellman-Ford in Almost-Linear Time for Dense Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16153v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the single-source shortest paths problem on a directed graph with real-valued (possibly negative) edge weights and solve this problem in $n^{2+o(1)}$ time by refining the shortcutting procedure introduced in Li, Li, Rao, and Zhang (2026).",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16153v1",
        "authors": [
          "George Z. Li",
          "Jason Li",
          "Junkai Zhang"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dense Graphs We",
        "Linear Time",
        "LLM"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.746720"
    },
    {
      "id": "arxiv-2602.16142v1",
      "title": "Ratio Covers of Convex Sets and Optimal Mixture Density Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16142v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study density estimation in Kullback-Leibler divergence: given an i.i.d. sample from an unknown density $p$, the goal is to construct an estimator $\\widehat p$ such that $\\mathrm{KL}(p,\\widehat p)$ is small with high probability. We consider two settings involving a finite dictionary of $M$ densities: (i) model aggregation, where $p$ belongs to the dictionary, and (ii) convex aggregation (mixture density estimation), where $p$ is a mixture of densities from the dictionary. Crucially, we make no assumption on the base densities: their ratios may be unbounded and their supports may differ. For both problems, we identify the best possible high-probability guarantees in terms of the dictionary size, sample size, and confidence level. These optimal rates are higher than those achievable when density ratios are bounded by absolute constants; for mixture density estimation, they match existing lower bounds in the special case of discrete distributions. Our analysis of the mixture case hinges on two new covering results. First, we provide a sharp, distribution-free upper bound on the local Hellinger entropy of the class of mixtures of $M$ distributions. Second, we prove an optimal ratio covering theorem for convex sets: for every convex compact set $K\\subset \\mathbb{R}_+^d$, there exists a subset $A\\subset K$ with at most $2^{8d}$ elements such that each element of $K$ is coordinate-wise dominated by an element of $A$ up to a universal constant factor. This geometric result is of independent interest; notably, it yields new cardinality estimates for $\\varepsilon$-approximate Pareto sets in multi-objective optimization when the attainable set of objective vectors is convex.",
        "keywords": [
          "math.ST",
          "cs.CG",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16142v1",
        "authors": [
          "Spencer Compton",
          "Gábor Lugosi",
          "Jaouad Mourtada",
          "Jian Qian",
          "Nikita Zhivotovskiy"
        ],
        "arxiv_categories": [
          "math.ST",
          "cs.CG",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optimal Mixture Density Estimation",
        "Ratio Covers",
        "Convex Sets",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.747035"
    },
    {
      "id": "arxiv-2602.16028v1",
      "title": "Markov Chains with Rewinding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16028v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Motivated by techniques developed in recent progress on lower bounds for sublinear time algorithms (Behnezhad, Roghani and Rubinstein, STOC 2023, FOCS 2023, and STOC 2024) we introduce and study a new class of randomized algorithmic processes that we call Markov Chains with Rewinding. In this setting, an algorithm interacts with a (partially observable) Markovian random evolution by strategically rewinding the Markov chain to previous states. Depending on the application, this may lead the evolution to desired states faster, or allow the agent to efficiently learn or test properties of the underlying Markov chain that may be infeasible or inefficient with passive observation. We study the task of identifying the initial state in a given partially observable Markov chain. Analysis of this question in specific Markov chains is the central ingredient in the above cited works and we aim to systematize the analysis in our work. Our first result is that any pair of states distinguishable with any rewinding strategy can also be distinguished with a non-adaptive rewinding strategy (one whose rewinding choices are determined before observing any outcomes of the chain). Therefore, while rewinding strategies can be shown to be strictly more powerful than passive strategies (those that do not rewind back to previous states), adaptivity does not give additional power to a rewinding strategy in the absence of efficiency considerations. The difference becomes apparent however when we introduce a natural efficiency measure, namely the query complexity (i.e., the number of observations they need to identify distinguishable states). Our second main contribution is to quantify this efficiency gap. We present a non-adaptive rewinding strategy whose query complexity is within a polynomial of that of the optimal (adaptive) strategy, and show that such a polynomial loss is necessary in general.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16028v1",
        "authors": [
          "Amir Azarmehr",
          "Soheil Behnezhad",
          "Alma Ghafari",
          "Madhu Sudan"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rewinding Motivated",
        "Markov Chains",
        "Wind",
        "STOC",
        "FOCS",
        "Act",
        "WHO",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.747330"
    },
    {
      "id": "arxiv-2602.16016v1",
      "title": "Nash-convergence of Game Dynamics and Complexity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16016v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Does the failure of learning dynamics to converge globally to Nash equilibria stem from the geometry of the game or the complexity of computation? Previous impossibility results relied on game degeneracy, leaving open the case for generic, nondegenerate games. We resolve this by proving that while Nash-convergent dynamics theoretically exist for all nondegenerate games, computing them is likely intractable. We formulate the Impossibility Conjecture: if a locally efficient Nash-convergent dynamic exists for nondegenerate games, then $P=PPAD$. We validate this for three specific families of dynamics, showing their tractability would imply collapses such as $NP=RP$ or $CLS=PPAD$. En route, we settle the complexity of finding Nash equilibria of a given game that lie on a given affine subspace. Finally, we explain why the general conjecture remains open: we introduce a Proving Game to demonstrate that black-box reductions cannot distinguish between convergent and non-convergent dynamics in polynomial time. Our results suggest the barrier to Nash learning is not the non-existence of a vector field, but the intractability of computing it.",
        "keywords": [
          "cs.GT",
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16016v1",
        "authors": [
          "Oliver Biggar",
          "Christos Papadimitriou",
          "Georgios Piliouras"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.CC"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Impossibility Conjecture",
        "Complexity Does",
        "Game Dynamics",
        "Proving Game",
        "PPAD",
        "CLS",
        "Act",
        "DOE",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:11.747530"
    },
    {
      "id": "arxiv-2602.15977v1",
      "title": "Universally Optimal Decremental Tree Minima",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15977v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An algorithm on weighted graphs is called universally optimal if it is optimal for every input graph, in the worst case taken over all weight assignments. Informally, this means the algorithm is competitive even with algorithms that are optimized for only one specific input graph. Universal optimality was recently introduced [Haeupler et al. 2024] as an alternative to the stronger, but often unachievable instance optimality. In this paper, we extend the concept of universal optimality to data structures. In particular, we investigate the following dynamic graph problem: Given a vertex-weighted forest, maintain the minimum-weight vertex of every tree under edge deletions. The problem requires $Θ(\\log n)$ amortized time per operation in general, but only $O(1)$ time if the initial forest is a path. We present a data structure that has optimal total running time for every fixed initial forest and every fixed number of operations/queries $m$, when taking the worst case over all weight assignments and operation sequences of length $m$. This definition of universal optimality is easily adapted to other data structure problems. Our result combines two techniques: (1) A decomposition of the input into paths, to take advantage of the $O(1)$-time path-specific data structure; and (2) splay trees [Sleator and Tarjan 1985], which, informally speaking, are used to optimally handle a certain sorting-related subproblem. We apply our data structure to solve problems related to Cartesian trees, path minimum queries, and bottleneck vertex/edge queries, each with a certain universal optimality guarantee. Our data structure also can be modified to support edge weights instead of vertex weights. Further, it generalizes to support semigroup sum queries instead of minimum queries, in universally optimal time.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15977v1",
        "authors": [
          "Benjamin Aram Berendsohn"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universally Optimal Decremental Tree",
        "Minima An",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.748186"
    },
    {
      "id": "arxiv-2602.15965v1",
      "title": "FLoPS: Semantics, Operations, and Properties of P3109 Floating-Point Representations in Lean",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15965v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The upcoming IEEE-P3109 standard for low-precision floating-point arithmetic can become the foundation of future machine learning hardware and software. Unlike the fixed types of IEEE-754, P3109 introduces a parametric framework defined by bitwidth, precision, signedness, and domain. This flexibility results in a vast combinatorial space of formats -- some with as little as one bit of precision -- alongside novel features such as stochastic rounding and saturation arithmetic. These deviations create a unique verification gap that this paper intends to address. This paper presents FLoPS, Formalization in Lean of the P3109 Standard, which is a comprehensive formal model of P3109 in Lean. Our work serves as a rigorous, machine-checked specification that facilitates deep analysis of the standard. We demonstrate the model's utility by verifying foundational properties and analyzing key algorithms within the P3109 context. Specifically, we reveal that FastTwoSum exhibits a novel property of computing exact \"overflow error\" under saturation using any rounding mode, whereas previously established properties of the ExtractScalar algorithm fail for formats with one bit of precision. This work provides a verified foundation for reasoning about P3109 and enables formal verification of future numerical software. Our Lean development is open source and publicly available.",
        "keywords": [
          "cs.MS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15965v1",
        "authors": [
          "Tung-Che Chang",
          "Sehyeok Park",
          "Jay P Lim",
          "Santosh Nagarakatte"
        ],
        "arxiv_categories": [
          "cs.MS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Point Representations",
        "Machine Learning",
        "Framework",
        "Standard",
        "IEEE-754",
        "Our Lean",
        "IEEE",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.748420"
    },
    {
      "id": "arxiv-2602.15964v1",
      "title": "Computing Approximate Pareto Frontiers for Submodular Utility and Cost Tradeoffs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15964v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In many data-mining applications, including recommender systems, influence maximization, and team formation, the goal is to pick a subset of elements (e.g., items, nodes in a network, experts to perform a task) to maximize a monotone submodular utility function while simultaneously minimizing a cost function. Classical formulations model this tradeoff via cardinality or knapsack constraints, or by combining utility and cost into a single weighted objective. However, such approaches require committing to a specific tradeoff in advance and return only a single solution, offering limited insight into the space of viable utility-cost tradeoffs. In this paper, we depart from the single-solution paradigm and examine the problem of computing representative sets of high-quality solutions that expose different tradeoffs between submodular utility and cost. For this, we introduce $(α_1,α_2)$-approximate Pareto frontiers that provably approximate the achievable tradeoffs between submodular utility and cost. Specifically, we formalize the Pareto-$\\langle f,c \\rangle$ problem and develop efficient algorithms for multiple instantiations arising from different combinations of submodular utility $f$ and cost functions $c$. Our results offer a principled and practical framework for understanding and exploiting utility-cost tradeoffs in submodular optimization. Experiments on datasets from diverse application domains demonstrate that our algorithms efficiently compute approximate Pareto frontiers in practice.",
        "keywords": [
          "cs.DS",
          "cs.DM",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15964v1",
        "authors": [
          "Karan Vombatkere",
          "Evimaria Terzi"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.DM",
          "cs.SI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Computing Approximate Pareto Frontiers",
        "Submodular Utility",
        "Cost Tradeoffs In",
        "Framework",
        "EPA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.748994"
    },
    {
      "id": "arxiv-2602.15797v1",
      "title": "On Graham's rearrangement conjecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15797v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Graham conjectured in 1971 that for any prime $p$, any subset $S\\subseteq \\mathbb{Z}_p\\setminus \\{0\\}$ admits an ordering $s_1,s_2,\\dots,s_{|S|}$ where all partial sums $s_1, s_1+s_2,\\dots,s_1+s_2+\\dots+s_{|S|}$ are distinct. We prove this conjecture for all subsets $S\\subseteq \\mathbb{Z}_p\\setminus \\{0\\}$ with $|S|\\le p^{1-α}$ and $|S|$ sufficiently large with respect to $α$, for any $α\\in (0,1)$. Combined with earlier results, this gives a complete resolution of Graham's rearrangement conjecture for all sufficiently large primes $p$.",
        "keywords": [
          "math.CO",
          "cs.DM",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15797v1",
        "authors": [
          "Huy Tuan Pham",
          "Lisa Sauermann"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "On Graham",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.749275"
    },
    {
      "id": "arxiv-2602.15702v1",
      "title": "A Weighted-to-Unweighted Reduction for Matroid Intersection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15702v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Given two matroids $\\mathcal{M}_1$ and $\\mathcal{M}_2$ over the same ground set, the matroid intersection problem is to find the maximum cardinality common independent set. In the weighted version of the problem, the goal is to find a maximum weight common independent set. It has been a matter of interest to find efficient approximation algorithms for this problem in various settings. In many of these models, there is a gap between the best known results for the unweighted and weighted versions. In this work, we address the question of closing this gap. Our main result is a reduction which converts any $α$-approximate unweighted matroid intersection algorithm into an $α(1-\\varepsilon)$-approximate weighted matroid intersection algorithm, while increasing the runtime of the algorithm by a $\\log W$ factor, where $W$ is the aspect ratio. Our framework is versatile and translates to settings such as streaming and one-way communication complexity where matroid intersection is well-studied. As a by-product of our techniques, we derive new results for weighted matroid intersection in these models.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15702v1",
        "authors": [
          "Aditi Dudeja",
          "Mara Grilnberger"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Matroid Intersection Given",
        "Unweighted Reduction",
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.749697"
    },
    {
      "id": "arxiv-2602.15683v1",
      "title": "Fair Correlation Clustering Meets Graph Parameters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15683v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study the generalization of Correlation Clustering which incorporates fairness constraints via the notion of fairlets. The corresponding Fair Correlation Clustering problem has been studied from several perspectives to date, but has so far lacked a detailed analysis from the parameterized complexity paradigm. We close this gap by providing tractability results for the problem under a variety of structural graph parameterizations, including treewidth, treedepth and the vertex cover number; our results lie at the very edge of tractability given the known NP-hardness of the problem on severely restricted inputs.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15683v1",
        "authors": [
          "Johannes Blaha",
          "Robert Ganian",
          "Katharina Gillig",
          "Jonathan S. Højlev",
          "Simon Wietheger"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fair Correlation Clustering Meets",
        "Fair Correlation Clustering",
        "Correlation Clustering",
        "Graph Parameters We",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.749824"
    },
    {
      "id": "arxiv-2602.15613v1",
      "title": "Algorithmic differentiation for domain specific languages in C++ with expression templates",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15613v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The application of operator overloading algorithmic differentiation (AD) to computer programs in order to compute the derivative is quite common. But, the replacement of the underlying computational floating point type with the specialized type of an AD tool has two problems. First, the memory structure of the program is changed and floating-point data is interleaved with identifiers from AD. This prevents the compiler from performing optimizations such as SIMD optimizations. Second, the AD tool does not see any domain-specific operations, e.,g. linear algebra operations, that the program uses. This prevents the AD tool from using specialized algorithms in such places. We propose a new AD tool that is tailored to such situations. The memory structure of the primal data is retained by associating an identifier with each entity, e.,g. matrix, and not with each floating point value, e.,g. element of the matrix. Operations on such entities can then be annotated and a generator is used to create the AD overloads. We demonstrate that this approach provides performance comparable to that of other specializations. In addition, the run-time factor is below the theoretical 4.5 of reverse AD for programs that are written purely with linear algebra entities and operations.",
        "keywords": [
          "cs.MS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15613v1",
        "authors": [
          "Max Sagebaum",
          "Nicolas R. Gauger"
        ],
        "arxiv_categories": [
          "cs.MS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SIMD",
        "Act",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.750042"
    },
    {
      "id": "arxiv-2602.15603v1",
      "title": "Symbolic recovery of PDEs from measurement data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15603v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Models based on partial differential equations (PDEs) are powerful for describing a wide range of complex relationships in the natural sciences. Accurately identifying the PDE model, which represents the underlying physical law, is essential for a proper understanding of the problem. This reconstruction typically relies on indirect and noisy measurements of the system's state and, without specifically tailored methods, rarely yields symbolic expressions, thereby hindering interpretability. In this work, we address this issue by considering existing neural network architectures based on rational functions for the symbolic representation of physical laws. These networks leverage the approximation power of rational functions while also benefiting from their flexibility in representing arithmetic operations. Our main contribution is an identifiability result, showing that, in the limit of noiseless, complete measurements, such symbolic networks can uniquely reconstruct the simplest physical law within the PDE model. Specifically, reconstructed laws remain expressible within the symbolic network architecture, with regularization-minimizing parameterizations promoting interpretability and sparsity in case of $L^1$-regularization. In addition, we provide regularity results for symbolic networks. Empirical validation using the ParFam architecture supports these theoretical findings, providing evidence for the practical reconstructibility of physical laws.",
        "keywords": [
          "cs.LG",
          "cs.SC",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15603v1",
        "authors": [
          "Erion Morina",
          "Philipp Scholl",
          "Martin Holler"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.SC",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "Act",
        "PDE",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.750272"
    },
    {
      "id": "arxiv-2602.15539v1",
      "title": "Dynamic Training-Free Fusion of Subject and Style LoRAs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15539v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent studies have explored the combination of multiple LoRAs to simultaneously generate user-specified subjects and styles. However, most existing approaches fuse LoRA weights using static statistical heuristics that deviate from LoRA's original purpose of learning adaptive feature adjustments and ignore the randomness of sampled inputs. To address this, we propose a dynamic training-free fusion framework that operates throughout the generation process. During the forward pass, at each LoRA-applied layer, we dynamically compute the KL divergence between the base model's original features and those produced by subject and style LoRAs, respectively, and adaptively select the most appropriate weights for fusion. In the reverse denoising stage, we further refine the generation trajectory by dynamically applying gradient-based corrections derived from objective metrics such as CLIP and DINO scores, providing continuous semantic and stylistic guidance. By integrating these two complementary mechanisms-feature-level selection and metric-guided latent adjustment-across the entire diffusion timeline, our method dynamically achieves coherent subject-style synthesis without any retraining. Extensive experiments across diverse subject-style combinations demonstrate that our approach consistently outperforms state-of-the-art LoRA fusion methods both qualitatively and quantitatively.",
        "keywords": [
          "cs.CV",
          "cs.AI",
          "cs.SC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15539v1",
        "authors": [
          "Qinglong Cao",
          "Yuntian Chen",
          "Chao Ma",
          "Xiaokang Yang"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.AI",
          "cs.SC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Training",
        "Free Fusion",
        "Framework",
        "Fusion",
        "CLIP",
        "DINO",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.750495"
    },
    {
      "id": "arxiv-2602.15921v1",
      "title": "Latent Objective Induction and Diversity-Constrained Selection: Algorithms for Multi-Locale Retrieval Pipelines",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15921v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present three algorithms with formal correctness guarantees and complexity bounds for the problem of selecting a diverse, multi-locale set of sources from ranked search results. First, we formulate weighted locale allocation as a constrained integer partition problem and give an $O(n \\log n)$ algorithm that simultaneously satisfies minimum-representation, budget-exhaustion, and proportionality-bound constraints; we prove all three hold with a tight deviation bound of $< 1$. Second, we define a cascaded country-code inference function as a deterministic priority chain over heterogeneous signals (TLD structure, model-inferred metadata, language fallback) and prove it satisfies both determinism and graceful degradation. Third, we introduce a $κ$-domain diversity constraint for source selection and give an $O(|K| \\cdot R)$ algorithm that maintains the invariant via hash-map lookup, eliminating the aggregator monopolization pathology present in URL-level deduplication. We further formalize Latent Objective Induction (LOI), an environment-shaping operator over prompt spaces that steers downstream model behavior without restricting the feasible output set, and prove its convergence under mild assumptions. Applied to a multi-locale retrieval pipeline, these algorithms yield 62% improvement in first-party source ratio and 89% reduction in same-domain duplication across 120 multilingual queries.",
        "keywords": [
          "cs.DS",
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15921v1",
        "authors": [
          "Faruk Alpay",
          "Levent Sarioglu"
        ],
        "arxiv_categories": [
          "cs.DS",
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Locale Retrieval Pipelines We",
        "Latent Objective Induction",
        "Constrained Selection",
        "Meta",
        "NIST",
        "URL",
        "LOI",
        "TLD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.751041"
    },
    {
      "id": "arxiv-2602.15497v1",
      "title": "Polynomial-time isomorphism test for $k$-generated extensions of abelian groups",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15497v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The group isomorphism problem asks whether two finite groups given by their Cayley tables are isomorphic or not. Although there are polynomial-time algorithms for some specific group classes, the best known algorithm for testing isomorphism of arbitrary groups of order $ n $ has time complexity $ n^{O(\\log n)} $. We consider the group isomorphism problem for some extensions of abelian groups by $ k $-generated groups for bounded $ k $. In particular, we prove that one can decide isomorphism of abelian-by-cyclic extensions in polynomial time, generalizing a 2009 result of Le Gall for coprime extensions. As another application, we give a polynomial-time isomorphism test for abelian-by-simple group extensions, generalizing a 2017 result of Grochow and Qiao for central extensions. The main novelty of the proof is a polynomial-time algorithm for computing the unit group of a finite ring, which might be of independent interest.",
        "keywords": [
          "math.GR",
          "cs.CC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15497v1",
        "authors": [
          "Saveliy V. Skresanov"
        ],
        "arxiv_categories": [
          "math.GR",
          "cs.CC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Le Gall",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.751207"
    },
    {
      "id": "arxiv-2602.15417v1",
      "title": "Memory Reallocation with Polylogarithmic Overhead",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15417v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Memory Reallocation problem asks to dynamically maintain an assignment of given objects of various sizes to non-overlapping contiguous chunks of memory, while supporting updates (insertions/deletions) in an online fashion. The total size of live objects at any time is guaranteed to be at most a $1-ε$ fraction of the total memory. To handle an online update, the allocator may rearrange the objects in memory to make space, and the overhead for this update is defined as the total size of moved objects divided by the size of the object being inserted/deleted. Our main result is an allocator with worst-case expected overhead $\\mathrm{polylog}(ε^{-1})$. This exponentially improves the previous worst-case expected overhead $\\tilde O(ε^{-1/2})$ achieved by Farach-Colton, Kuszmaul, Sheffield, and Westover (2024), narrowing the gap towards the $Ω(\\logε^{-1})$ lower bound. Our improvement is based on an application of the sunflower lemma previously used by Erdős and Sárközy (1992) in the context of subset sums. Our allocator achieves polylogarithmic overhead only in expectation, and sometimes performs expensive rebuilds. Our second technical result shows that this is necessary: it is impossible to achieve subpolynomial overhead with high probability.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15417v1",
        "authors": [
          "Ce Jin"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Memory Reallocation",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.751682"
    },
    {
      "id": "arxiv-2602.15375v1",
      "title": "Asymptotic Tightness of the Pigeonhole Bound for Large-Order Davenport-Schinzel Sequences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15375v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We prove that the pigeonhole upper bound $λ(s,m) \\leq \\binom{m}{2}(s+1)$ is asymptotically tight whenever $s/\\!\\sqrt{m} \\to \\infty$. In particular, $λ(s,m) \\sim \\binom{m}{2}\\,s$ in this regime. As corollaries: $λ(n,n)/n^3 \\to \\frac{1}{2}$, resolving the leading constant from the previously known interval $[\\frac{1}{3}, \\frac{1}{2}]$; and more generally $λ(an,bn) \\sim \\frac{ab^2}{2}\\,n^3$ for any constants $a,b > 0$.",
        "keywords": [
          "math.CO",
          "cs.DM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15375v1",
        "authors": [
          "Jesse Geneson"
        ],
        "arxiv_categories": [
          "math.CO",
          "cs.DM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Schinzel Sequences We",
        "Asymptotic Tightness",
        "Pigeonhole Bound",
        "Order Davenport",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.751888"
    },
    {
      "id": "arxiv-2602.15372v1",
      "title": "Self-dual Stacked Quantum Low-Density Parity-Check Codes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15372v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Quantum low-density parity-check (qLDPC) codes are promising candidates for fault-tolerant quantum computation due to their high encoding rates and distances. However, implementing logical operations using qLDPC codes presents significant challenges. Previous research has demonstrated that self-dual qLDPC codes facilitate the implementation of transversal Clifford gates. Here we introduce a method for constructing self-dual qLDPC codes by stacking non-self-dual qLDPC codes. Leveraging this methodology, we develop double-chain bicycle codes, double-layer bivariate bicycle (BB) codes, double-layer twisted BB codes, and double-layer reflection codes, many of which exhibit favorable code parameters. Additionally, we conduct numerical calculations to assess the performance of these codes as quantum memory under the circuit-level noise model, revealing that the logical failure rate can be significantly reduced with high pseudo-thresholds.",
        "keywords": [
          "quant-ph",
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15372v1",
        "authors": [
          "Ze-Chuan Liu",
          "Chong-Yuan Xu",
          "Yong Xu"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Check Codes Quantum",
        "Stacked Quantum Low",
        "Density Parity",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.752055"
    },
    {
      "id": "arxiv-2602.15341v1",
      "title": "Testing Monotonicity of Real-Valued Functions on DAGs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15341v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study monotonicity testing of real-valued functions on directed acyclic graphs (DAGs) with $n$ vertices. For every constant $δ>0$, we prove a $Ω(n^{1/2-δ}/\\sqrt{\\varepsilon})$ lower bound against non-adaptive two-sided testers on DAGs, nearly matching the classical $O(\\sqrt{n/\\varepsilon})$-query upper bound. For constant $\\varepsilon$, we also prove an $Ω(\\sqrt n)$ lower bound for randomized adaptive one-sided testers on explicit bipartite DAGs, whereas previously only an $Ω(\\log n)$ lower bound was known. A key technical ingredient in both lower bounds is positive-matching Ruzsa--Szemerédi families. On the algorithmic side, we give simple non-adaptive one-sided testers with query complexity $O(\\sqrt{m\\,\\ell}/(\\varepsilon n))$ and $O(m^{1/3}/\\varepsilon^{2/3})$, where $m$ is the number of edges in the transitive reduction and $\\ell$ is the number of edges in the transitive closure. For constant $\\varepsilon>0$, these improve over the previous $O(\\sqrt{n/\\varepsilon})$ bound when $m\\ell=o(n^3)$ and $m=o(n^{3/2})$, respectively.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15341v1",
        "authors": [
          "Yuichi Yoshida"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Testing Monotonicity",
        "Valued Functions",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.752458"
    },
    {
      "id": "arxiv-2602.15314v1",
      "title": "Revisiting the Sparse Matrix Compression Problem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15314v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The sparse matrix compression problem asks for a one-dimensional representation of a binary $n \\times \\ell$ matrix, formed by an integer array of row indices and a shift function for each row, such that accessing a matrix entry is possible in constant time by consulting this representation. It has been shown that the decision problem for finding an integer array of length $\\ell+ρ$ or restricting the shift function up to values of $ρ$ is NP-complete (cf. the textbook of Garey and Johnson). As a practical heuristic, a greedy algorithm has been proposed to shift the $i$-th row until it forms a solution with its predecessor rows. Despite that this greedy algorithm is cherished for its good approximation in practice, we show that it actually exhibits an approximation ratio of $Θ(\\sqrt{\\ell+ρ})$. We give further hardness results for parameterizations such as the number of distinct rows or the maximum number of non-zero entries per row. Finally, we devise a DP-algorithm that solves the problem for double-logarithmic matrix widths or logarithmic widths for further restrictions. We study all these findings also under a new perspective by introducing a variant of the problem, where we wish to minimize the length of the resulting integer array by trimming the non-zero borders, which has not been studied in the literature before but has practical motivations.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15314v1",
        "authors": [
          "Vincent Jugé",
          "Dominik Köppl",
          "Vincent Limouzy",
          "Andrea Marino",
          "Jannik Olblich"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sparse Matrix Compression Problem",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.752951"
    },
    {
      "id": "arxiv-2602.15311v1",
      "title": "Near-real-time Solutions for Online String Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15311v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Based on the Breslauer-Italiano online suffix tree construction algorithm (2013) with double logarithmic worst-case guarantees on the update time per letter, we develop near-real-time algorithms for several classical problems on strings, including the computation of the longest repeating suffix array, the (reversed) Lempel-Ziv 77 factorization, and the maintenance of minimal unique substrings, all in an online manner. Our solutions improve over the best known running times for these problems in terms of the worst-case time per letter, for which we achieve a poly-log-logarithmic time complexity, within a linear space. Best known results for these problems require a poly-logarithmic time complexity per letter or only provide amortized complexity bounds. As a result of independent interest, we give conversions between the longest previous factor array and the longest repeating suffix array in space and time bounds based on their irreducible representations, which can have sizes sublinear in the length of the input string.",
        "keywords": [
          "cs.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15311v1",
        "authors": [
          "Dominik Köppl",
          "Gregory Kucherov"
        ],
        "arxiv_categories": [
          "cs.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Online String Problems Based",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:11.753117"
    },
    {
      "id": "arxiv-2602.16587v1",
      "title": "Why Thinking Hurts? Diagnosing and Rectifying the Reasoning Shift in Foundation Recommender Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16587v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Integrating Chain-of-Thought (CoT) reasoning into Semantic ID-based recommendation foundation models (such as OpenOneRec) often paradoxically degrades recommendation performance. We identify the root cause as textual inertia from the General Subspace, where verbose reasoning dominates inference and causes the model to neglect critical Semantic ID. To address this, we propose a training-free Inference-Time Subspace Alignment framework. By compressing reasoning chains and applying bias-subtracted contrastive decoding, our approach mitigates ungrounded textual drift. Experiments show this effectively calibrates inference, allowing foundation models to leverage reasoning without sacrificing ID-grounded accuracy.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16587v1",
        "authors": [
          "Luankang Zhang",
          "Yonghao Huang",
          "Hang Lv",
          "Mingjia Yin",
          "Liangyue Li"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Foundation Recommender Models Integrating",
        "Time Subspace Alignment",
        "Why Thinking Hurts",
        "General Subspace",
        "Reasoning Shift",
        "Framework",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.812968"
    },
    {
      "id": "arxiv-2602.16551v1",
      "title": "Automated Extraction of Mechanical Constitutive Models from Scientific Literature using Large Language Models: Applications in Cultural Heritage Conservation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16551v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The preservation of cultural heritage is increasingly transitioning towards data-driven predictive maintenance and \"Digital Twin\" construction. However, the mechanical constitutive models required for high-fidelity simulations remain fragmented across decades of unstructured scientific literature, creating a \"Data Silo\" that hinders conservation engineering. To address this, we present an automated, two-stage agentic framework leveraging Large Language Models (LLMs) to extract mechanical constitutive equations, calibrated parameters, and metadata from PDF documents. The workflow employs a resource-efficient \"Gatekeeper\" agent for relevance filtering and a high-capability \"Analyst\" agent for fine-grained extraction, featuring a novel Context-Aware Symbolic Grounding mechanism to resolve mathematical ambiguities. Applied to a corpus of over 2,000 research papers, the system successfully isolated 113 core documents and constructed a structured database containing 185 constitutive model instances and over 450 calibrated parameters. The extraction precision reached 80.4\\%, establishing a highly efficient \"Human-in-the-loop\" workflow that reduces manual data curation time by approximately 90\\%. We demonstrate the system's utility through a web-based Knowledge Retrieval Platform, which enables rapid parameter discovery for computational modeling. This work transforms scattered literature into a queryable digital asset, laying the data foundation for the \"Digital Material Twin\" of built heritage.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16551v1",
        "authors": [
          "Rui Hu",
          "Yue Wu",
          "Tianhao Su",
          "Yin Wang",
          "Shunbo Hu"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mechanical Constitutive Models",
        "Knowledge Retrieval Platform",
        "Aware Symbolic Grounding",
        "Digital Material Twin",
        "Large Language Models",
        "Scientific Literature",
        "Automated Extraction",
        "Digital Twin",
        "Framework",
        "Data Silo",
        "Meta",
        "LLM",
        "PDF",
        "NSF",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.813568"
    },
    {
      "id": "arxiv-2602.16541v1",
      "title": "From Latent to Observable Position-Based Click Models in Carousel Interfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16541v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Click models are a central component of learning and evaluation in recommender systems, yet most existing models are designed for single ranked-list interfaces. In contrast, modern recommender platforms increasingly use complex interfaces such as carousels, which consist of multiple swipeable lists that enable complex user browsing behaviors. In this paper, we study position-based click models in carousel interfaces and examine optimization methods, model structure, and alignment with user behavior. We propose three novel position-based models tailored to carousels, including the first position-based model without latent variables that incorporates observed examination signals derived from eye tracking data, called the Observed Examination Position-Based Model (OEPBM). We develop a general implementation of these carousel click models, supporting multiple optimization techniques and conduct experiments comparing gradient-based methods with classical approaches, namely expectation-maximization and maximum likelihood estimation. Our results show that gradient-based optimization consistently achieve better click likelihoods. Among the evaluated models, the OEPBM achieves the strongest performance in click prediction and produces examination patterns that most closely align to user behavior. However, we also demonstrate that strong click fit does not imply realistic modeling of user examination and browsing patterns. This reveals a fundamental limitation of click-only models in complex interfaces and the need for incorporating additional behavioral signals when designing click models for carousel-based recommender systems.",
        "keywords": [
          "cs.IR",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16541v1",
        "authors": [
          "Santiago de Leon-Martinez",
          "Robert Moro",
          "Branislav Kveton",
          "Maria Bielikova"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Observed Examination Position",
        "Carousel Interfaces Click",
        "Observable Position",
        "Based Click Models",
        "Based Model",
        "From Latent",
        "OEPBM",
        "MIT",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.814101"
    },
    {
      "id": "arxiv-2602.16536v1",
      "title": "Spectral Conditions for the Ingleton Inequality",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16536v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Ingleton inequality is a classical linear information inequality that holds for representable matroids but fails to be universally valid for entropic vectors. Understanding the extent to which this inequality can be violated has been a longstanding problem in information theory. In this paper, we show that for a broad class of jointly distributed random variables $(X,Y)$ the Ingleton inequality holds up to a small additive error, even even though the mutual information between $X$ and $Y$ is far from being extractable. Contrary to common intuition, strongly non-extractable mutual information does not lead to large violations of the Ingleton inequality in this setting. More precisely, we consider pairs $(X,Y)$ that are uniformly distributed on their joint support and whose associated biregular bipartite graph is an expander. For all auxiliary random variables $A$ and $B$ jointly distributed with $(X,Y)$, we establish a lower bound on the Ingleton quantity $I(X:Y | A) + I(X:Y | B) + I(A:B) - I(X:Y)$ in terms of the spectral parameters of the underlying graph. Our proof combines the expander mixing lemma with a partitioning technique for finite sets.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16536v1",
        "authors": [
          "Rostislav Matveev",
          "Andrei Romashchenko"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spectral Conditions",
        "Act",
        "WHO",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.814625"
    },
    {
      "id": "arxiv-2602.16459v1",
      "title": "Continuous Fluid Antenna Sampling for Channel Estimation in Cell-Free Massive MIMO",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16459v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this letter, we develop a continuous fluid antenna (FA) framework for uplink channel estimation in cell-free massive multiple-input and multiple-output (CF-mMIMO) systems. By modeling the wireless channel as a spatially correlated Gaussian random field, channel estimation is formulated as a Gaussian process (GP) regression problem with motion-constrained spatial sampling. Closed-form expressions for the linear minimum mean squared error (LMMSE) estimator and the corresponding estimation error are derived. A fundamental comparison with discrete port-based architectures is established under identical position constraints, showing that continuous FA sampling achieves equal or lower estimation error for any finite pilot budget, with strict improvement for non-degenerate spatial correlation models. Numerical results validate the analysis and show the performance gains of continuous FA sampling over discrete baselines.",
        "keywords": [
          "cs.IT",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16459v1",
        "authors": [
          "Masoud Kaveh",
          "Farshad Rostami Ghadi",
          "Francisco Hernando-Gallego",
          "Diego Martin",
          "Riku Jantti"
        ],
        "arxiv_categories": [
          "cs.IT",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Continuous Fluid Antenna Sampling",
        "Channel Estimation",
        "Free Massive",
        "Framework",
        "LMMSE",
        "MIMO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.815025"
    },
    {
      "id": "arxiv-2602.16446v1",
      "title": "Enhanced Connectivity in Ambient Backscatter Communications via Fluid Antenna Readers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16446v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Ambient backscatter communication (AmBC) enables ultra-low-power connectivity by allowing passive backscatter devices (BDs) to convey information through reflection of ambient signals. However, the cascaded AmBC channel suffers from severe double path loss and multiplicative fading, while accurate channel state information (CSI) acquisition is highly challenging due to the weak backscattered signal and the resource-limited nature of BDs. To address these challenges, this paper considers an AmBC system in which the reader is equipped with a pixel-based fluid antenna system (FAS). By dynamically selecting one antenna position from a dense set of pixels within a compact aperture, the FAS-enabled reader exploits spatial diversity through measurement-driven port selection, without requiring explicit CSI acquisition or multiple RF chains. The intrinsic rate-energy tradeoff at the BD is also incorporated by jointly optimizing the backscatter modulation coefficient under an energy harvesting (EH) neutrality constraint. To efficiently solve this problem, a particle swarm optimization (PSO)-based framework is developed to jointly determine the FAS port selection and modulation coefficient on an optimize-then-average (OTA) basis. Simulation results show that the proposed scheme significantly improves the achievable rate compared with conventional single-antenna readers, with gains preserved under imperfect observations, stringent EH constraints, and different pixel spacings.",
        "keywords": [
          "cs.IT",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16446v1",
        "authors": [
          "Masoud Kaveh",
          "Farshad Rostami Ghadi",
          "Riku Jantti",
          "Kai-Kit Wong",
          "F. Javier Lopez-Martinez"
        ],
        "arxiv_categories": [
          "cs.IT",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ambient Backscatter Communications",
        "Fluid Antenna Readers Ambient",
        "Enhanced Connectivity",
        "Framework",
        "CSI",
        "PSO",
        "OTA",
        "Act",
        "MIT",
        "FAS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.815580"
    },
    {
      "id": "arxiv-2602.16421v1",
      "title": "SELEBI: Percussion-aware Time Stretching via Selective Magnitude Spectrogram Compression by Nonstationary Gabor Transform",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16421v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Phase vocoder-based time-stretching is a widely used technique for the time-scale modification of audio signals. However, conventional implementations suffer from ``percussion smearing,'' a well-known artifact that significantly degrades the quality of percussive components. We attribute this artifact to a fundamental time-scale mismatch between the temporally smeared magnitude spectrogram and the localized, newly generated phase. To address this, we propose SELEBI, a signal-adaptive phase vocoder algorithm that significantly reduces percussion smearing while preserving stability and the perfect reconstruction property. Unlike conventional methods that rely on heuristic processing or component separation, our approach leverages the nonstationary Gabor transform. By dynamically adapting analysis window lengths to assign short windows to intervals containing significant energy associated with percussive components, we directly compute a temporally localized magnitude spectrogram from the time-domain signal. This approach ensures greater consistency between the temporal structures of the magnitude and phase. Furthermore, the perfect reconstruction property of the nonstationary Gabor transform guarantees stable, high-fidelity signal synthesis, in contrast to previous heuristic approaches. Experimental results demonstrate that the proposed method effectively mitigates percussion smearing and yields natural sound quality.",
        "keywords": [
          "eess.AS",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16421v1",
        "authors": [
          "Natsuki Akaishi",
          "Nicki Holighaus",
          "Kohei Yatabe"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Selective Magnitude Spectrogram Compression",
        "Nonstationary Gabor Transform Phase",
        "Time Stretching",
        "SELEBI",
        "Wind",
        "EPA",
        "NSF",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.816104"
    },
    {
      "id": "arxiv-2602.16416v1",
      "title": "Online Single-Channel Audio-Based Sound Speed Estimation for Robust Multi-Channel Audio Control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16416v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Robust spatial audio control relies on accurate acoustic propagation models, yet environmental variations, especially changes in the speed of sound, cause systematic mismatches that degrade performance. Existing methods either assume known sound speed, require multiple microphones, or rely on separate calibration, making them impractical for systems with minimal sensing. We propose an online sound speed estimator that operates during general multichannel audio playback and requires only a single observation microphone. The method exploits the structured effect of sound speed on the reproduced signal and estimates it by minimizing the mismatch between the measured audio and a parametric acoustic model. Simulations show accurate tracking of sound speed for diverse input signals and improved spatial control performance when the estimates are used to compensate propagation errors in a sound zone control framework.",
        "keywords": [
          "eess.AS",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16416v1",
        "authors": [
          "Andreas Jonas Fuglsig",
          "Mads Græsbøll Christensen",
          "Jesper Rindom Jensen"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Channel Audio Control Robust",
        "Based Sound Speed Estimation",
        "Channel Audio",
        "Online Single",
        "Robust Multi",
        "Framework",
        "EPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.816426"
    },
    {
      "id": "arxiv-2602.16406v1",
      "title": "Bounds and Constructions of Codes for Ordered Composite DNA Sequences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16406v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper extends the foundational work of Dollma \\emph{et al}. on codes for ordered composite DNA sequences. We consider the general setting with an alphabet of size $q$ and a resolution parameter $k$, moving beyond the binary ($q=2$) case primarily studied previously. We investigate error-correcting codes for substitution errors and deletion errors under several channel models, including $(e_1,\\ldots,e_k)$-composite error/deletion, $e$-composite error/deletion, and the newly introduced $t$-$(e_1,\\ldots,e_t)$-composite error/deletion model. We first establish equivalence relations among families of composite-error correcting codes (CECCs) and among families of composite-deletion correcting codes (CDCCs). This significantly reduces the number of distinct error-parameter sets that require separate analysis. We then derive novel and general upper bounds on the sizes of CECCs using refined sphere-packing arguments and probabilistic methods. These bounds together cover all values of parameters $q$, $k$, $(e_1,\\ldots,e_k)$ and $e$. In contrast, previous bounds were only established for $q=2$ and limited choices of $k$, $(e_1,\\ldots,e_k)$ and $e$. For CDCCs, we generalize a known non-asymptotic upper bound for $(1,0,\\ldots,0)$-CDCCs and then provide a cleaner asymptotic bound. On the constructive side, for any $q\\ge2$, we propose $(1,0,\\ldots,0)$-CDCCs, $1$-CDCCs and $t$-$(1,\\ldots,1)$-CDCCs with near-optimal redundancies. These codes have efficient and systematic encoders. For substitution errors, we design the first explicit encoding and decoding algorithms for the binary $(1,0,\\ldots,0)$-CECC constructed by Dollma \\emph{et al}, and extend the approach to general $q$. Furthermore, we give an improved construction of binary $1$-CECCs, a construction of nonbinary $1$-CECCs, and a construction of $t$-$(1,\\ldots,1)$-CECCs. These constructions are also systematic.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16406v1",
        "authors": [
          "Zuo Ye",
          "Yuling Li",
          "Zhaojun Lan",
          "Gennian Ge"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ordered Composite",
        "CECC",
        "EPA",
        "LLM",
        "DNA",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.817003"
    },
    {
      "id": "arxiv-2602.16375v1",
      "title": "Variable-Length Semantic IDs for Recommender Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16375v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem. However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems. In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.",
        "keywords": [
          "cs.IR",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16375v1",
        "authors": [
          "Kirill Khrylchenko"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recommender Systems Generative",
        "Length Semantic",
        "Framework",
        "Protocol",
        "EPA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.817588"
    },
    {
      "id": "arxiv-2602.16374v1",
      "title": "Experimental and Numerical Study of the Transient Response of a Cantilever Beam with a Piezoelectric Disc Sensor",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16374v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Online and real-time sensing and monitoring of the health state of complex structures, such as aircraft and critical components of power stations, are essential aspects of research in dynamics. Several types of sensors are used to capture dynamic responses and monitor changes during the operation of critical parts of complex systems. Piezoelectric (PZ) materials belong to a class of electroactive materials that convert mechanical deformation into an electrical response. For example, PZ ceramics or PVDF foils are employed for online sensing of the time history of mechanical deformation. This paper focuses on the dynamical response of a cantilever beam structure equipped with a glued PZ sensor and combines experimental and modelling approaches to achieve accurate and reliable results. The time history of the normal velocity at a point on the beam surface was recorded with a laser vibrometer during transient vibrations of the beam, triggered by the sudden removal of a mass load at the beam's free end. Simultaneously, the output voltage of the PZ sensor was measured with an electronic device. An elastodynamic model of a cantilever beam coupled with a piezoelectric sensor is introduced, along with its discretization using the finite element method. The mathematical model includes additional terms that enforce a floating-potential boundary condition to maintain a constant charge on one of the sensor's electrodes and is presented in an extended form suitable for sensitivity analysis or parameter identification. The model implementation is validated using a numerical example corresponding to the experimental setup. The computed results show good agreement with the experimental data. Furthermore, values of the Rayleigh damping parameters were identified based on the experimental measurements.",
        "keywords": [
          "cs.CE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16374v1",
        "authors": [
          "Radek Kolman",
          "Robert Cimrman",
          "Ladislav Musil",
          "Moritz Frey",
          "Jaromir Kylar"
        ],
        "arxiv_categories": [
          "cs.CE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Piezoelectric Disc Sensor Online",
        "Transient Response",
        "Numerical Study",
        "Cantilever Beam",
        "Agreement",
        "PVDF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.818173"
    },
    {
      "id": "arxiv-2602.16343v1",
      "title": "How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16343v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Since Text-to-Speech systems typically don't produce waveforms directly, recent spoof detection studies use resynthesized waveforms from vocoders and neural audio codecs to simulate an attacker. Unlike vocoders, which are specifically designed for speech synthesis, neural audio codecs were originally developed for compressing audio for storage and transmission. However, their ability to discretize speech also sparked interest in language-modeling-based speech synthesis. Owing to this dual functionality, codec resynthesized data may be labeled as either bonafide or spoof. So far, very little research has addressed this issue. In this study, we present a challenging extension of the ASVspoof 5 dataset constructed for this purpose. We examine how different labeling choices affect detection performance and provide insights into labeling strategies.",
        "keywords": [
          "cs.SD",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16343v1",
        "authors": [
          "Yixuan Xiao",
          "Florian Lux",
          "Alejandro Pérez-González-de-Martos",
          "Ngoc Thang Vu"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Audio Deepfake Detection Since",
        "Label Resynthesized Audio",
        "Neural Audio Codecs",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.818489"
    },
    {
      "id": "arxiv-2602.16334v1",
      "title": "Spatial Audio Question Answering and Reasoning on Dynamic Source Movements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16334v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Spatial audio understanding aims to enable machines to interpret complex auditory scenes, particularly when sound sources move over time. In this work, we study Spatial Audio Question Answering (Spatial AQA) with a focus on movement reasoning, where a model must infer object motion, position, and directional changes directly from stereo audio. First, we introduce a movement-centric spatial audio augmentation framework that synthesizes diverse motion patterns from isolated mono audio events, enabling controlled and scalable training data generation. Second, we propose an end-to-end multimodal finetuning approach with a thinking mode, which allows audio-language models to produce explicit intermediate reasoning steps before predicting an answer. Third, we investigate the impact of query-conditioned source separation as a preprocessing stage and compare three inference regimes: no masking, an audio grounding model (AGM), and ground-truth masks. Our results show that reasoning amplifies the benefits of source separation, with thinking mode showing significant improvement of +5.1% when a single event is present in the question. These findings highlight the interplay between movement modeling, reasoning, and separation quality, offering new insights for advancing spatial audio understanding.",
        "keywords": [
          "cs.SD",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16334v1",
        "authors": [
          "Arvind Krishna Sridhar",
          "Yinyi Guo",
          "Erik Visser"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spatial Audio Question Answering",
        "Dynamic Source Movements Spatial",
        "Framework",
        "EPA",
        "AQA",
        "AGM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.818903"
    },
    {
      "id": "arxiv-2602.16317v1",
      "title": "CADEvolve: Creating Realistic CAD via Program Evolution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16317v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Computer-Aided Design (CAD) delivers rapid, editable modeling for engineering and manufacturing. Recent AI progress now makes full automation feasible for various CAD tasks. However, progress is bottlenecked by data: public corpora mostly contain sketch-extrude sequences, lack complex operations, multi-operation composition and design intent, and thus hinder effective fine-tuning. Attempts to bypass this with frozen VLMs often yield simple or invalid programs due to limited 3D grounding in current foundation models. We present CADEvolve, an evolution-based pipeline and dataset that starts from simple primitives and, via VLM-guided edits and validations, incrementally grows CAD programs toward industrial-grade complexity. The result is 8k complex parts expressed as executable CadQuery parametric generators. After multi-stage post-processing and augmentation, we obtain a unified dataset of 1.3m scripts paired with rendered geometry and exercising the full CadQuery operation set. A VLM fine-tuned on CADEvolve achieves state-of-the-art results on the Image2CAD task across the DeepCAD, Fusion 360, and MCB benchmarks.",
        "keywords": [
          "cs.GR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16317v1",
        "authors": [
          "Maksim Elistratov",
          "Marina Barannikov",
          "Gregory Ivanov",
          "Valentin Khrulkov",
          "Anton Konushin"
        ],
        "arxiv_categories": [
          "cs.GR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Program Evolution Computer",
        "Creating Realistic",
        "Aided Design",
        "Fusion",
        "Act",
        "MCB",
        "MIT",
        "CAD",
        "VLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.819287"
    },
    {
      "id": "arxiv-2602.16315v1",
      "title": "The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16315v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recommender systems shape individual choices through feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies. We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of recommendations, and heterogeneous recommender systems. We apply the framework on online retail and music streaming data and analyze systemic effects of the feedback loop. We find that increasing recommender adoption may lead to a progressive diversification of individual consumption, while collective demand is redistributed in model- and domain-dependent ways, often amplifying popularity concentration. Temporal analyses further reveal that apparent increases in individual diversity observed in static evaluations are illusory: when adoption is fixed and time unfolds, individual diversity consistently decreases across all models. Our results highlight the need to move beyond static evaluations and explicitly account for feedback-loop dynamics when designing recommender systems.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16315v1",
        "authors": [
          "Gabriele Barlacchi",
          "Margherita Lalli",
          "Emanuele Ferragina",
          "Fosca Giannotti",
          "Dino Pedreschi"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recommender Systems Recommender",
        "Systemic Effects",
        "Feedback Loops",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.819690"
    },
    {
      "id": "arxiv-2602.16305v1",
      "title": "BAT: Better Audio Transformer Guided by Convex Gated Probing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16305v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Probing is widely adopted in computer vision to faithfully evaluate self-supervised learning (SSL) embeddings, as fine-tuning may misrepresent their inherent quality. In contrast, audio SSL models still rely on fine-tuning because simple probing fails to unlock their full potential and alters their rankings when competing for SOTA on AudioSet. Hence, a robust and efficient probing mechanism is required to guide the trajectory of audio SSL towards reliable and reproducible methods. We introduce Convex Gated Probing (CGP), a prototype-based method that drastically closes the gap between fine-tuning and probing in audio. CGP efficiently utilizes all frozen layers via a gating mechanism and exposes the location of latent task-relevant information. Guided by CGP, we rework the entire SSL pipeline of current SOTA audio models that use legacy implementations of prior SSL methods. By refining data preprocessing, model architecture, and pre-training recipe, we introduce Better Audio Transformer (BAT), and establish new SOTA on audio benchmarks.",
        "keywords": [
          "cs.SD",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16305v1",
        "authors": [
          "Houtan Ghaffari",
          "Lukas Rauch",
          "Christoph Scholz",
          "Paul Devos"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Better Audio Transformer Guided",
        "Convex Gated Probing Probing",
        "Better Audio Transformer",
        "Convex Gated Probing",
        "Transformer",
        "SOTA",
        "NSF",
        "SSL",
        "BAT",
        "CGP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.820047"
    },
    {
      "id": "arxiv-2602.16299v1",
      "title": "MICE: Minimal Interaction Cross-Encoders for efficient Re-ranking",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16299v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cross-encoders deliver state-of-the-art ranking effectiveness in information retrieval, but have a high inference cost. This prevents them from being used as first-stage rankers, but also incurs a cost when re-ranking documents. Prior work has addressed this bottleneck from two largely separate directions: accelerating cross-encoder inference by sparsifying the attention process or improving first-stage retrieval effectiveness using more complex models, e.g. late-interaction ones. In this work, we propose to bridge these two approaches, based on an in-depth understanding of the internal mechanisms of cross-encoders. Starting from cross-encoders, we show that it is possible to derive a new late-interaction-like architecture by carefully removing detrimental or unnecessary interactions. We name this architecture MICE (Minimal Interaction Cross-Encoders). We extensively evaluate MICE across both in-domain (ID) and out-of-domain (OOD) datasets. MICE decreases fourfold the inference latency compared to standard cross-encoders, matching late-interaction models like ColBERT while retaining most of cross-encoder ID effectiveness and demonstrating superior generalization abilities in OOD.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16299v1",
        "authors": [
          "Mathias Vast",
          "Victor Morand",
          "Basile van Cooten",
          "Laure Soulier",
          "Josiane Mothe"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Minimal Interaction Cross",
        "Standard",
        "BERT",
        "MICE",
        "EPA",
        "OOD",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.820446"
    },
    {
      "id": "arxiv-2602.16256v1",
      "title": "Color-based Emotion Representation for Speech Emotion Recognition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16256v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Speech emotion recognition (SER) has traditionally relied on categorical or dimensional labels. However, this technique is limited in representing both the diversity and interpretability of emotions. To overcome this limitation, we focus on color attributes, such as hue, saturation, and value, to represent emotions as continuous and interpretable scores. We annotated an emotional speech corpus with color attributes via crowdsourcing and analyzed them. Moreover, we built regression models for color attributes in SER using machine learning and deep learning, and explored the multitask learning of color attribute regression and emotion classification. As a result, we demonstrated the relationship between color attributes and emotions in speech, and successfully developed color attribute regression models for SER. We also showed that multitask learning improved the performance of each task.",
        "keywords": [
          "eess.AS",
          "cs.AI",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16256v1",
        "authors": [
          "Ryotaro Nagase",
          "Ryoichi Takashima",
          "Yoichi Yamashita"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.AI",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Speech Emotion Recognition Speech",
        "Emotion Representation",
        "Machine Learning",
        "Deep Learning",
        "MIT",
        "SER"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.820761"
    },
    {
      "id": "arxiv-2602.16253v1",
      "title": "How Much Does Machine Identity Matter in Anomalous Sound Detection at Test Time?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16253v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Anomalous sound detection (ASD) benchmarks typically assume that the identity of the monitored machine is known at test time and that recordings are evaluated in a machine-wise manner. However, in realistic monitoring scenarios with multiple known machines operating concurrently, test recordings may not be reliably attributable to a specific machine, and requiring machine identity imposes deployment constraints such as dedicated sensors per machine. To reveal performance degradations and method-specific differences in robustness that are hidden under standard machine-wise evaluation, we consider a minimal modification of the ASD evaluation protocol in which test recordings from multiple machines are merged and evaluated jointly without access to machine identity at inference time. Training data and evaluation metrics remain unchanged, and machine identity labels are used only for post hoc evaluation. Experiments with representative ASD methods show that relaxing this assumption reveals performance degradations and method-specific differences in robustness that are hidden under standard machine-wise evaluation, and that these degradations are strongly related to implicit machine identification accuracy.",
        "keywords": [
          "eess.AS",
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16253v1",
        "authors": [
          "Kevin Wilkinghoff",
          "Keisuke Imoto",
          "Zheng-Hua Tan"
        ],
        "arxiv_categories": [
          "eess.AS",
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Anomalous Sound Detection",
        "How Much Does Machine",
        "Identity Matter",
        "Test Time",
        "Standard",
        "Protocol",
        "ASD",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.821154"
    },
    {
      "id": "arxiv-2602.16236v1",
      "title": "Online Prediction of Stochastic Sequences with High Probability Regret Bounds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16236v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We revisit the classical problem of universal prediction of stochastic sequences with a finite time horizon $T$ known to the learner. The question we investigate is whether it is possible to derive vanishing regret bounds that hold with high probability, complementing existing bounds from the literature that hold in expectation. We propose such high-probability bounds which have a very similar form as the prior expectation bounds. For the case of universal prediction of a stochastic process over a countable alphabet, our bound states a convergence rate of $\\mathcal{O}(T^{-1/2} δ^{-1/2})$ with probability as least $1-δ$ compared to prior known in-expectation bounds of the order $\\mathcal{O}(T^{-1/2})$. We also propose an impossibility result which proves that it is not possible to improve the exponent of $δ$ in a bound of the same form without making additional assumptions.",
        "keywords": [
          "cs.LG",
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16236v1",
        "authors": [
          "Matthias Frey",
          "Jonathan H. Manton",
          "Jingge Zhu"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "High Probability Regret Bounds",
        "Stochastic Sequences",
        "Online Prediction",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.821821"
    },
    {
      "id": "arxiv-2602.16207v1",
      "title": "Cryptographic Applications of Twisted Goppa Codes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16207v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This article defines multi-twisted Goppa (MTG) codes as subfield subcodes of duals of multi-twisted Reed-Solomon (MTRS) codes and examines their properties. We show that if $t$ is the degree of the MTG polynomial defining an MTG code, its minimum distance is at least $t + 1$ under certain conditions. Extending earlier methods limited to single twist at last position, we use the extended Euclidean algorithm to efficiently decode MTG codes with a single twist at any position, correcting up to $\\left\\lfloor \\tfrac{t}{2} \\right\\rfloor$ errors. This decoding method highlights the practical potential of these codes within the Niederreiter public key cryptosystem (PKC). Furthermore, we establish that the Niederreiter PKC based on MTG codes is secure against partial key recovery attacks. Additionally, we also reduce the public key size by constructing quasi-cyclic MTG codes using a non-trivial automorphism group.",
        "keywords": [
          "cs.IT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16207v1",
        "authors": [
          "Harshdeep Singh",
          "Anuj Kumar Bhagat",
          "Ritumoni Sarma",
          "Indivar Gupta"
        ],
        "arxiv_categories": [
          "cs.IT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cryptographic Applications",
        "MTRS",
        "MTG",
        "PKC",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.822101"
    },
    {
      "id": "arxiv-2602.16197v1",
      "title": "ModalImmune: Immunity Driven Unlearning via Self Destructive Training",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16197v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Multimodal systems are vulnerable to partial or complete loss of input channels at deployment, which undermines reliability in real-world settings. This paper presents ModalImmune, a training framework that enforces modality immunity by intentionally and controllably collapsing selected modality information during training so the model learns joint representations that are robust to destructive modality influence. The framework combines a spectrum-adaptive collapse regularizer, an information-gain guided controller for targeted interventions, curvature-aware gradient masking to stabilize destructive updates, and a certified Neumann-truncated hyper-gradient procedure for automatic meta-parameter adaptation. Empirical evaluation on standard multimodal benchmarks demonstrates that ModalImmune improves resilience to modality removal and corruption while retaining convergence stability and reconstruction capacity.",
        "keywords": [
          "cs.LG",
          "cs.CL",
          "cs.MM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16197v1",
        "authors": [
          "Rong Fu",
          "Jia Yee Tan",
          "Wenxin Zhang",
          "Zijian Zhang",
          "Ziming Wang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.CL",
          "cs.MM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Self Destructive Training Multimodal",
        "Immunity Driven Unlearning",
        "Framework",
        "Standard",
        "Meta",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.822382"
    },
    {
      "id": "arxiv-2602.16186v1",
      "title": "Modeling Trust and Liquidity Under Payment System Stress: A Multi-Agent Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16186v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Operational disruptions in retail payments can induce behavioral responses that outlast technical recovery and may amplify liquidity stress. We propose a multi-agent model linking card payment outages to trust dynamics, channel avoidance, and threshold-gated withdrawals. Customers and merchants interact through repeated payment attempts, while customers additionally influence one another on a Watts-Strogatz small-world network. Customers update bounded memory variables capturing accumulated negative experience (scar) and perceived systemic risk (rumor), with merchants contributing persistent broadcast signals that may lag operational recovery. We prove that, under mild conditions on memory persistence and threshold gating, aggregate withdrawal pressure can peak strictly after the outage nadir, including during the recovery phase. Simulations reproduce behavioral hysteresis and confirm delayed peaks of outflows. We further study payment substitution via instant transfer: substitution consistently reduces peak avoidance, yet its effect on cumulative outflows is non-monotonic under realistic merchant broadcast persistence. Robustness experiments across random seeds show stable qualitative behavior. The model highlights why \"status green\" is not equivalent to risk resolution and motivates incident response strategies that address perception, merchant messaging, and post-recovery communication in addition to technical remediation.",
        "keywords": [
          "cs.GT",
          "cs.CE",
          "cs.MA",
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16186v1",
        "authors": [
          "Masoud Amouzgar"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.CE",
          "cs.MA",
          "cs.SI"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Liquidity Under Payment System",
        "Agent Approach Operational",
        "Modeling Trust",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:16.822764"
    },
    {
      "id": "arxiv-2602.16161v1",
      "title": "Emotion Collider: Dual Hyperbolic Mirror Manifolds for Sentiment Recovery via Anti Emotion Reflection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16161v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Emotional expression underpins natural communication and effective human-computer interaction. We present Emotion Collider (EC-Net), a hyperbolic hypergraph framework for multimodal emotion and sentiment modeling. EC-Net represents modality hierarchies using Poincare-ball embeddings and performs fusion through a hypergraph mechanism that passes messages bidirectionally between nodes and hyperedges. To sharpen class separation, contrastive learning is formulated in hyperbolic space with decoupled radial and angular objectives. High-order semantic relations across time steps and modalities are preserved via adaptive hyperedge construction. Empirical results on standard multimodal emotion benchmarks show that EC-Net produces robust, semantically coherent representations and consistently improves accuracy, particularly when modalities are partially available or contaminated by noise. These findings indicate that explicit hierarchical geometry combined with hypergraph fusion is effective for resilient multimodal affect understanding.",
        "keywords": [
          "cs.MM",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16161v1",
        "authors": [
          "Rong Fu",
          "Ziming Wang",
          "Shuo Yin",
          "Wenxin Zhang",
          "Haiyun Wei"
        ],
        "arxiv_categories": [
          "cs.MM",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Anti Emotion Reflection Emotional",
        "Dual Hyperbolic Mirror Manifolds",
        "Sentiment Recovery",
        "Emotion Collider",
        "Framework",
        "Standard",
        "Fusion",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.823135"
    },
    {
      "id": "arxiv-2602.16136v1",
      "title": "Retrieval Collapses When AI Pollutes the Web",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16136v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The rapid proliferation of AI-generated content on the Web presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG) systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates search results, eroding source diversity, and (2) low-quality or adversarial content infiltrates the retrieval pipeline. We analyzed this dynamic through controlled experiments involving both high-quality SEO-style content and adversarially crafted content. In the SEO scenario, a 67\\% pool contamination led to over 80\\% exposure contamination, creating a homogenized yet deceptively healthy state where answer accuracy remains stable despite the reliance on synthetic sources. Conversely, under adversarial contamination, baselines like BM25 exposed $\\sim$19\\% of harmful content, whereas LLM-based rankers demonstrated stronger suppression capabilities. These findings highlight the risk of retrieval pipelines quietly shifting toward synthetic evidence and the need for retrieval-aware strategies to prevent a self-reinforcing cycle of quality decline in Web-grounded systems.",
        "keywords": [
          "cs.IR",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16136v1",
        "authors": [
          "Hongyeon Yu",
          "Dongchan Kim",
          "Young-Bum Kim"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Retrieval Collapses When",
        "Large Language Models",
        "Augmented Generation",
        "Retrieval Collapse",
        "RAG",
        "LLM",
        "Act",
        "SEO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.823483"
    },
    {
      "id": "arxiv-2602.16124v1",
      "title": "Rethinking ANN-based Retrieval: Multifaceted Learnable Index for Large-scale Recommendation System",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16124v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Approximate nearest neighbor (ANN) search is widely used in the retrieval stage of large-scale recommendation systems. In this stage, candidate items are indexed using their learned embedding vectors, and ANN search is executed for each user (or item) query to retrieve a set of relevant items. However, ANN-based retrieval has two key limitations. First, item embeddings and their indices are typically learned in separate stages: indexing is often performed offline after embeddings are trained, which can yield suboptimal retrieval quality-especially for newly created items. Second, although ANN offers sublinear query time, it must still be run for every request, incurring substantial computation cost at industry scale. In this paper, we propose MultiFaceted Learnable Index (MFLI), a scalable, real-time retrieval paradigm that learns multifaceted item embeddings and indices within a unified framework and eliminates ANN search at serving time. Specifically, we construct a multifaceted hierarchical codebook via residual quantization of item embeddings and co-train the codebook with the embeddings. We further introduce an efficient multifaceted indexing structure and mechanisms that support real-time updates. At serving time, the learned hierarchical indices are used directly to identify relevant items, avoiding ANN search altogether. Extensive experiments on real-world data with billions of users show that MFLI improves recall on engagement tasks by up to 11.8\\%, cold-content delivery by up to 57.29\\%, and semantic relevance by 13.5\\% compared with prior state-of-the-art methods. We also deploy MFLI in the system and report online experimental results demonstrating improved engagement, less popularity bias, and higher serving efficiency.",
        "keywords": [
          "cs.IR",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16124v1",
        "authors": [
          "Jiang Zhang",
          "Yubo Wang",
          "Wei Chang",
          "Lu Han",
          "Xingying Cheng"
        ],
        "arxiv_categories": [
          "cs.IR",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Recommendation System Approximate",
        "Multifaceted Learnable Index",
        "Learnable Index",
        "Framework",
        "MFLI",
        "Bill",
        "EPA",
        "ANN",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.823980"
    },
    {
      "id": "arxiv-2602.16118v1",
      "title": "Real time fault detection in 3D printers using Convolutional Neural Networks and acoustic signals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16118v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The reliability and quality of 3D printing processes are critically dependent on the timely detection of mechanical faults. Traditional monitoring methods often rely on visual inspection and hardware sensors, which can be both costly and limited in scope. This paper explores a scalable and contactless method for the use of real-time audio signal analysis for detecting mechanical faults in 3D printers. By capturing and classifying acoustic emissions during the printing process, we aim to identify common faults such as nozzle clogging, filament breakage, pully skipping and various other mechanical faults. Utilizing Convolutional neural networks, we implement algorithms capable of real-time audio classification to detect these faults promptly. Our methodology involves conducting a series of controlled experiments to gather audio data, followed by the application of advanced machine learning models for fault detection. Additionally, we review existing literature on audio-based fault detection in manufacturing and 3D printing to contextualize our research within the broader field. Preliminary results demonstrate that audio signals, when analyzed with machine learning techniques, provide a reliable and cost-effective means of enhancing real-time fault detection.",
        "keywords": [
          "eess.SP",
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16118v1",
        "authors": [
          "Muhammad Fasih Waheed",
          "Shonda Bernadin"
        ],
        "arxiv_categories": [
          "eess.SP",
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Convolutional Neural Networks",
        "Utilizing Convolutional",
        "Machine Learning",
        "Neural Network",
        "Act",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.824328"
    },
    {
      "id": "arxiv-2602.16062v1",
      "title": "Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local Energy Markets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16062v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper proposes implicit cooperation, a framework enabling decentralized agents to approximate optimal coordination in local energy markets without explicit peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals (key performance indicators at the system level) to infer and react to global states. Through a 3x3 factorial design on an IEEE 34-node topology, we evaluated three training paradigms (CTCE, CTDE, DTDE) and three algorithms (PPO, APPO, SAC). Results identify APPO-DTDE as the optimal configuration, achieving a coordination score of 91.7% relative to the theoretical centralized benchmark (CTCE). However, a critical trade-off emerges between efficiency and stability: while the centralized benchmark maximizes allocative efficiency with a peer-to-peer trade ratio of 0.6, the fully decentralized approach (DTDE) demonstrates superior physical stability. Specifically, DTDE reduces the variance of grid balance by 31% compared to hybrid architectures, establishing a highly predictable, import-biased load profile that simplifies grid regulation. Furthermore, topological analysis reveals emergent spatial clustering, where decentralized agents self-organize into stable trading communities to minimize congestion penalties. While SAC excelled in hybrid settings, it failed in decentralized environments due to entropy-driven instability. This research proves that stigmergic signaling provides sufficient context for complex grid coordination, offering a robust, privacy-preserving alternative to expensive centralized communication infrastructure.",
        "keywords": [
          "eess.SY",
          "cs.CE",
          "cs.LG",
          "cs.MA",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16062v1",
        "authors": [
          "Nelson Salazar-Pena",
          "Alejandra Tabares",
          "Andres Gonzalez-Mancera"
        ],
        "arxiv_categories": [
          "eess.SY",
          "cs.CE",
          "cs.LG",
          "cs.MA",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Reinforcement Learning Approach",
        "Towards Decentralized Local Energy",
        "Harnessing Implicit Cooperation",
        "Regulation",
        "Framework",
        "CTCE",
        "DTDE",
        "CTDE",
        "IEEE",
        "APPO",
        "Act",
        "PPO",
        "SAC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.824903"
    },
    {
      "id": "arxiv-2602.16034v1",
      "title": "FeDecider: An LLM-Based Framework for Federated Cross-Domain Recommendation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16034v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Federated cross-domain recommendation (Federated CDR) aims to collaboratively learn personalized recommendation models across heterogeneous domains while preserving data privacy. Recently, large language model (LLM)-based recommendation models have demonstrated impressive performance by leveraging LLMs' strong reasoning capabilities and broad knowledge. However, adopting LLM-based recommendation models in Federated CDR scenarios introduces new challenges. First, there exists a risk of overfitting with domain-specific local adapters. The magnitudes of locally optimized parameter updates often vary across domains, causing biased aggregation and overfitting toward domain-specific distributions. Second, unlike traditional recommendation models (e.g., collaborative filtering, bipartite graph-based methods) that learn explicit and comparable user/item representations, LLMs encode knowledge implicitly through autoregressive text generation training. This poses additional challenges for effectively measuring the cross-domain similarities under heterogeneity. To address these challenges, we propose an LLM-based framework for federated cross-domain recommendation, FeDecider. Specifically, FeDecider tackles the challenge of scale-specific noise by disentangling each client's low-rank updates and sharing only their directional components. To handle the need for flexible and effective integration, each client further learns personalized weights that achieve the data-aware integration of updates from other domains. Extensive experiments across diverse datasets validate the effectiveness of our proposed FeDecider.",
        "keywords": [
          "cs.IR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16034v1",
        "authors": [
          "Xinrui He",
          "Ting-Wei Li",
          "Tianxin Wei",
          "Xuying Ning",
          "Xinyu He"
        ],
        "arxiv_categories": [
          "cs.IR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Domain Recommendation Federated",
        "Federated Cross",
        "Based Framework",
        "Framework",
        "LLM",
        "CDR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.825339"
    },
    {
      "id": "arxiv-2602.16008v1",
      "title": "MAEB: Massive Audio Embedding Benchmark",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16008v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce the Massive Audio Embedding Benchmark (MAEB), a large-scale benchmark covering 30 tasks across speech, music, environmental sounds, and cross-modal audio-text reasoning in 100+ languages. We evaluate 50+ models and find that no single model dominates across all tasks: contrastive audio-text models excel at environmental sound classification (e.g., ESC50) but score near random on multilingual speech tasks (e.g., SIB-FLEURS), while speech-pretrained models show the opposite pattern. Clustering remains challenging for all models, with even the best-performing model achieving only modest results. We observe that models excelling on acoustic understanding often perform poorly on linguistic tasks, and vice versa. We also show that the performance of audio encoders on MAEB correlates highly with their performance when used in audio large language models. MAEB is derived from MAEB+, a collection of 98 tasks. MAEB is designed to maintain task diversity while reducing evaluation cost, and it integrates into the MTEB ecosystem for unified evaluation across text, image, and audio modalities. We release MAEB and all 98 tasks along with code and a leaderboard at https://github.com/embeddings-benchmark/mteb.",
        "keywords": [
          "cs.SD",
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16008v1",
        "authors": [
          "Adnan El Assadi",
          "Isaac Chung",
          "Chenghao Xiao",
          "Roman Solomatin",
          "Animesh Jha"
        ],
        "arxiv_categories": [
          "cs.SD",
          "cs.AI",
          "cs.CL",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Massive Audio Embedding Benchmark",
        "FLEURS",
        "MAEB",
        "MTEB",
        "SIB",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.825709"
    },
    {
      "id": "arxiv-2602.15973v1",
      "title": "LAND: A Longitudinal Analysis of Neuromorphic Datasets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15973v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Neuromorphic engineering has a data problem. Despite the meteoric rise in the number of neuromorphic datasets published over the past ten years, the conclusion of a significant portion of neuromorphic research papers still states that there is a need for yet more data and even larger datasets. Whilst this need is driven in part by the sheer volume of data required by modern deep learning approaches, it is also fuelled by the current state of the available neuromorphic datasets and the difficulties in finding them, understanding their purpose, and determining the nature of their underlying task. This is further compounded by practical difficulties in downloading and using these datasets. This review starts by capturing a snapshot of the existing neuromorphic datasets, covering over 423 datasets, and then explores the nature of their tasks and the underlying structure of the presented data. Analysing these datasets shows the difficulties arising from their size, the lack of standardisation, and difficulties in accessing the actual data. This paper also highlights the growth in the size of individual datasets and the complexities involved in working with the data. However, a more important concern is the rise of synthetic datasets, created by either simulation or video-to-events methods. This review explores the benefits of simulated data for testing existing algorithms and applications, highlighting the potential pitfalls for exploring new applications of neuromorphic technologies. This review also introduces the concepts of meta-datasets, created from existing datasets, as a way of both reducing the need for more data, and to remove potential bias arising from defining both the dataset and the task.",
        "keywords": [
          "cs.CV",
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15973v1",
        "authors": [
          "Gregory Cohen",
          "Alexandre Marcireau"
        ],
        "arxiv_categories": [
          "cs.CV",
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neuromorphic Datasets Neuromorphic",
        "Longitudinal Analysis",
        "Deep Learning",
        "Standard",
        "Meta",
        "LAND",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.826154"
    },
    {
      "id": "arxiv-2602.15773v1",
      "title": "Efficient Densest Flow Queries in Transaction Flow Networks (Complete Version)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15773v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Transaction flow networks are crucial in detecting illicit activities such as wash trading, credit card fraud, cashback arbitrage fraud, and money laundering. \\revise{Our collaborator, Grab, a leader in digital payments in Southeast Asia, faces increasingly sophisticated fraud patterns in its transaction flow networks. In industry settings such as Grab's fraud detection pipeline, identifying fraudulent activities heavily relies on detecting dense flows within transaction networks. Motivated by this practical foundation,} we propose the \\emph{\\(S\\)-\\(T\\) densest flow} (\\SDMF{}) query. Given a transaction flow network \\( G \\), a source set \\( \\Src \\), a sink set \\( \\Dst \\), and a size threshold \\( k \\), the query outputs subsets \\( \\Src' \\subseteq \\Src \\) and \\( \\Dst' \\subseteq \\Dst \\) such that the maximum flow from \\( \\Src' \\) to \\( \\Dst' \\) is densest, with \\(|\\Src' \\cup \\Dst'| \\geq k\\). Recognizing the NP-hardness of the \\SDMF{} query, we develop an efficient divide-and-conquer algorithm, CONAN. \\revise{Driven by industry needs for scalable and efficient solutions}, we introduce an approximate flow-peeling algorithm to optimize the performance of CONAN, enhancing its efficiency in processing large transaction networks. \\revise{Our approach has been integrated into Grab's fraud detection scenario, resulting in significant improvements in identifying fraudulent activities.} Experiments show that CONAN outperforms baseline methods by up to three orders of magnitude in runtime and more effectively identifies the densest flows. We showcase CONAN's applications in fraud detection on transaction flow networks from our industry partner, Grab, and on non-fungible tokens (NFTs).",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15773v1",
        "authors": [
          "Jiaxin Jiang",
          "Yunxiang Zhao",
          "Lyu Xu",
          "Byron Choi",
          "Bingsheng He"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Efficient Densest Flow Queries",
        "Transaction Flow Networks",
        "Complete Version",
        "Southeast Asia",
        "CONAN",
        "SDMF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.826616"
    },
    {
      "id": "arxiv-2602.15766v1",
      "title": "TAC: Timestamped Audio Captioning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15766v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Large Audio Language Models struggle to disentangle overlapping events in complex acoustic scenes, yielding temporally inconsistent captions and frequent hallucinations. We introduce Timestamped Audio Captioner (TAC), a model that produces temporally grounded audio descriptions at varying degrees of detail and resolution. TAC is trained with a synthetic data pipeline that constructs challenging and dynamic mixtures from real-world audio sources, enabling robust learning under realistic polyphonic conditions. Across event detection and dense captioning, TAC outperforms all competing methods, with a low hallucination rate and accurate temporal grounding. We also introduce TAC-V, an audio-visual pipeline to generate semantically rich audio-visual descriptions. We then show that TAC and TAC-V serves as a \"semantic bridge\" for a text-only reasoner: a simple TAC$\\rightarrow$LLM and TAC-V$\\rightarrow$LLM cascade achieves state-of-the-art scores on benchmarks for both audio (MMAU-Pro, MMSU, MMAR) and audio-visual (DailyOmni, VideoHolmes) understanding and reasoning respectively.",
        "keywords": [
          "cs.SD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15766v1",
        "authors": [
          "Sonal Kumar",
          "Prem Seetharaman",
          "Ke Chen",
          "Oriol Nieto",
          "Jiaqi Su"
        ],
        "arxiv_categories": [
          "cs.SD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Timestamped Audio Captioning Large",
        "Timestamped Audio Captioner",
        "Audio Language Models",
        "MMSU",
        "MMAR",
        "MMAU",
        "LLM",
        "TAC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.826934"
    },
    {
      "id": "arxiv-2602.15749v1",
      "title": "A Generative-First Neural Audio Autoencoder",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15749v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Neural autoencoders underpin generative models. Practical, large-scale use of neural autoencoders for generative modeling necessitates fast encoding, low latent rates, and a single model across representations. Existing approaches are reconstruction-first: they incur high latent rates, slow encoding, and separate architectures for discrete vs. continuous latents and for different audio channel formats, hindering workflows from preprocessing to inference conditioning. We introduce a generative-first architecture for audio autoencoding that increases temporal downsampling from 2048x to 3360x and supports continuous and discrete representations and common audio channel formats in one model. By balancing compression, quality, and speed, it delivers 10x faster encoding, 1.6x lower rates, and eliminates channel-format-specific variants while maintaining competitive reconstruction quality. This enables applications previously constrained by processing costs: a 60-second mono signal compresses to 788 tokens, making generative modeling more tractable.",
        "keywords": [
          "cs.SD",
          "eess.AS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15749v1",
        "authors": [
          "Jonah Casebeer",
          "Ge Zhu",
          "Zhepei Wang",
          "Nicholas J. Bryan"
        ],
        "arxiv_categories": [
          "cs.SD",
          "eess.AS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "First Neural Audio Autoencoder",
        "EPA",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.827230"
    },
    {
      "id": "arxiv-2602.15739v1",
      "title": "Hierarchical Decomposition of Separable Workflow-Nets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15739v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Partially Ordered Workflow Language (POWL) has recently emerged as a process modeling notation, offering strong quality guarantees and high expressiveness. While early versions of POWL relied on strict block-structured operators for choices and loops, the language has recently evolved into POWL 2.0, introducing choice graphs to enable the modeling of non-block-structured decisions and cycles. To bridge the gap between the theoretical advantages of POWL and the practical need for compatibility with established notations, robust model transformations are required. This paper presents a novel algorithm for transforming safe and sound workflow nets (WF-nets) into equivalent POWL 2.0 models. The algorithm recursively identifies structural patterns within the WF-net and translates them into their POWL representation. Unlike the previous approach that required separate detection strategies for exclusive choices and loops, our new algorithm utilizes choice graphs to capture generalized decision and cyclic patterns. We formally prove the correctness of our approach, showing that the generated POWL model preserves the language of the input WF-net. Furthermore, we prove the completeness of our algorithm on the class of separable WF-nets, which corresponds to nets constructed via the hierarchical nesting of state machines and marked graphs. We evaluate our algorithm on large-scale process models to demonstrate its high scalability. Furthermore, to test its practical expressiveness, we applied it to a benchmark of 1,493 industrial and synthetic process models. Our algorithm successfully transformed all models in this benchmark, suggesting that POWL 2.0's expressive power is generally sufficient to capture the complex logic found in real-world business processes. This work paves the way for broader adoption of POWL in practical process analysis and improvement applications.",
        "keywords": [
          "cs.DB"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15739v1",
        "authors": [
          "Humam Kourani",
          "Gyunam Park",
          "Wil M. P. van der Aalst"
        ],
        "arxiv_categories": [
          "cs.DB"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hierarchical Decomposition",
        "Separable Workflow",
        "Workflow Language",
        "POWL",
        "EPA",
        "NSF",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:16.827694"
    },
    {
      "id": "arxiv-2602.16695v1",
      "title": "Fairness Dynamics in Digital Economy Platforms with Biased Ratings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16695v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The digital services economy consists of online platforms that facilitate interactions between service providers and consumers. This ecosystem is characterized by short-term, often one-off, transactions between parties that have no prior familiarity. To establish trust among users, platforms employ rating systems which allow users to report on the quality of their previous interactions. However, while arguably crucial for these platforms to function, rating systems can perpetuate negative biases against marginalised groups. This paper investigates how to design platforms around biased reputation systems, reducing discrimination while maintaining incentives for all service providers to offer high quality service for users. We introduce an evolutionary game theoretical model to study how digital platforms can perpetuate or counteract rating-based discrimination. We focus on the platforms' decisions to promote service providers who have high reputations or who belong to a specific protected group. Our results demonstrate a fundamental trade-off between user experience and fairness: promoting highly-rated providers benefits users, but lowers the demand for marginalised providers against which the ratings are biased. Our results also provide evidence that intervening by tuning the demographics of the search results is a highly effective way of reducing unfairness while minimally impacting users. Furthermore, we show that even when precise measurements on the level of rating bias affecting marginalised service providers is unavailable, there is still potential to improve upon a recommender system which ignores protected characteristics. Altogether, our model highlights the benefits of proactive anti-discrimination design in systems where ratings are used to promote cooperative behaviour.",
        "keywords": [
          "cs.MA",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16695v1",
        "authors": [
          "J. Martin Smit",
          "Fernando P. Santos"
        ],
        "arxiv_categories": [
          "cs.MA",
          "cs.CY"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Digital Economy Platforms",
        "Fairness Dynamics",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-19T14:47:22.005671"
    },
    {
      "id": "arxiv-2602.16678v1",
      "title": "Consensus Based Task Allocation for Angles-Only Local Catalog Maintenance of Satellite Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16678v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In order for close proximity satellites to safely perform their missions, the relative states of all satellites and pieces of debris must be well understood. This presents a problem for ground based tracking and orbit determination since it may not be practical to achieve the required accuracy. Using space-based sensors allows for more accurate relative state estimates, especially if multiple satellites are allowed to communicate. Of interest to this work is the case where several communicating satellites each need to maintain a local catalog of communicating and non-communicating objects using angles-only limited field of view (FOV) measurements. However, this introduces the problem of efficiently scheduling and coordinating observations among the agents. This paper presents a decentralized task allocation algorithm to address this problem and quantifies its performance in terms of fuel usage and overall catalog uncertainty via numerical simulation. It was found that the new method significantly outperforms the uncertainty-fuel Pareto frontier formed by current approaches.",
        "keywords": [
          "cs.MA",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16678v1",
        "authors": [
          "Harrison Perone",
          "Christopher W. Hays"
        ],
        "arxiv_categories": [
          "cs.MA",
          "eess.SY"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Consensus Based Task Allocation",
        "Only Local Catalog Maintenance",
        "Satellite Systems In",
        "Satellite",
        "FOV",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-19T14:47:22.006039"
    },
    {
      "id": "arxiv-2602.16662v1",
      "title": "Evaluating Collective Behaviour of Hundreds of LLM Agents",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16662v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "As autonomous agents powered by LLM are increasingly deployed in society, understanding their collective behaviour in social dilemmas becomes critical. We introduce an evaluation framework where LLMs generate strategies encoded as algorithms, enabling inspection prior to deployment and scaling to populations of hundreds of agents -- substantially larger than in previous work. We find that more recent models tend to produce worse societal outcomes compared to older models when agents prioritise individual gain over collective benefits. Using cultural evolution to model user selection of agents, our simulations reveal a significant risk of convergence to poor societal equilibria, particularly when the relative benefit of cooperation diminishes and population sizes increase. We release our code as an evaluation suite for developers to assess the emergent collective behaviour of their models.",
        "keywords": [
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16662v1",
        "authors": [
          "Richard Willis",
          "Jianing Zhao",
          "Yali Du",
          "Joel Z. Leibo"
        ],
        "arxiv_categories": [
          "cs.MA"
        ],
        "steeps_mapping": "P_Political"
      },
      "entities": [
        "Evaluating Collective Behaviour",
        "Framework",
        "Agents As",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "P",
      "collected_at": "2026-02-19T14:47:22.006406"
    },
    {
      "id": "arxiv-2602.16561v1",
      "title": "Hidden in Plain Sight: Detecting Illicit Massage Businesses from Mobility Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16561v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Illicit massage businesses (IMBs) masquerade as legitimate massage parlors while facilitating commercial sex and human trafficking. Law enforcement must identify these businesses within a dense population of lawful establishments, but investigative resources are limited and the illicit status of each location is unknown until inspection. Detection methods based on online reviews offer some insight, yet operators can manipulate these signals, leaving covert establishments undetected. IMBs constitute one of the largest segments of indoor sex trafficking in the United States, with an estimated 9,000 establishments. Mobility data offers an alternative to online signals, covering establishments that avoid digital visibility entirely. We derive features from mobility data spanning temporal visitation patterns, dwell times, visitor catchment areas, and demand stability. Because confirmed labels exist only for establishments identified through advertising platforms, we employ positive-unlabeled learning to address the label asymmetry in ground truth. The model achieves 0.97 AUC and 0.84 Average Precision. Four operational signatures characterize high-risk establishments: demand consistency, evening-concentrated visits, compressed service durations, and locally drawn clientele. The model produces risk scores for each business-week observation. Aggregating to the business level, prioritizing the highest-risk 10% of massage establishments captures 53% of known illicit operations, a 5.3-fold improvement over uninformed inspection. We develop a decision-support system that produces calibrated prioritization scores for law enforcement, enabling investigators to concentrate inspections on the highest-risk venues. The operational signatures may resist strategic manipulation because they reflect actual operations rather than online signals that operators can control.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16561v1",
        "authors": [
          "Roya Shomali",
          "Nick Freeman",
          "Greg Bott",
          "Iman Dayarian",
          "Jason Parton"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Detecting Illicit Massage Businesses",
        "Mobility Data Illicit",
        "Average Precision",
        "United States",
        "Plain Sight",
        "Act",
        "MIT",
        "AUC",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.007366"
    },
    {
      "id": "arxiv-2602.16553v1",
      "title": "Agentic AI, Medical Morality, and the Transformation of the Patient-Physician Relationship",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16553v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The emergence of agentic AI marks a new phase in the digital transformation of healthcare. Distinct from conventional generative AI, agentic AI systems are capable of autonomous, goal-directed actions and complex task coordination. They promise to support or even collaborate with clinicians and patients in increasingly independent ways. While agentic AI raises familiar moral concerns regarding safety, accountability, and bias, this article focuses on a less explored dimension: its capacity to transform the moral fabric of healthcare itself. Drawing on the framework of techno-moral change and the three domains of decision, relation and perception, we investigate how agentic AI might reshape the patient-physician relationship and reconfigure core concepts of medical morality. We argue that these shifts, while not fully predictable, demand ethical attention before widespread deployment. Ultimately, the paper calls for integrating ethical foresight into the design and use of agentic AI.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16553v1",
        "authors": [
          "Robert Ranisch",
          "Sabine Salloch"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Medical Morality",
        "Framework",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.007767"
    },
    {
      "id": "arxiv-2602.16352v1",
      "title": "Machine Learning in Epidemiology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16352v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In the age of digital epidemiology, epidemiologists are faced by an increasing amount of data of growing complexity and dimensionality. Machine learning is a set of powerful tools that can help to analyze such enormous amounts of data. This chapter lays the methodological foundations for successfully applying machine learning in epidemiology. It covers the principles of supervised and unsupervised learning and discusses the most important machine learning methods. Strategies for model evaluation and hyperparameter optimization are developed and interpretable machine learning is introduced. All these theoretical parts are accompanied by code examples in R, where an example dataset on heart disease is used throughout the chapter.",
        "keywords": [
          "stat.ML",
          "cs.CY",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16352v1",
        "authors": [
          "Marvin N. Wright",
          "Lukas Burk",
          "Pegah Golchian",
          "Jan Kapar",
          "Niklas Koenen"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.CY",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Epidemiology In",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.008382"
    },
    {
      "id": "arxiv-2602.16326v1",
      "title": "Individual Fairness in Community Detection: Quantitative Measure and Comparative Evaluation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16326v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Community detection is a fundamental task in complex network analysis. Fairness-aware community detection seeks to prevent biased node partitions, typically framed in terms of individual fairness, which requires similar nodes to be treated similarly, and group fairness, which aims to avoid disadvantaging specific groups of nodes. While existing literature on fair community detection has primarily focused on group fairness, we introduce a novel measure to quantify individual fairness in community detection methods. The proposed measure captures unfairness as the vectorial distance between a node's true and predicted community representations, computed using the community co-occurrence matrix. We provide a comprehensive empirical investigation of a broad set of community detection algorithms from the literature on both synthetic networks, with varying levels of community explicitness, and real-world networks. We particularly investigate the fairness-performance trade-off using standard quality metrics and compare individual fairness outcomes with existing group fairness measures. The results show that individual unfairness can occur even when group fairness or clustering accuracy is high, underscoring that individual and group fairness are not interchangeable. Moreover, fairness depends critically on the detectability of community structure. However, we find that Significance and Surprise for denser graphs, and Combo, Leiden, and SBMDL for sparser graphs result in a better trade-off between individual fairness and community quality. Overall, our findings, together with the fact that community detection is an important step in many network analysis downstream tasks, highlight the necessity of developing fairness-aware community detection methods.",
        "keywords": [
          "cs.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16326v1",
        "authors": [
          "Fabrizio Corriera",
          "Frank W. Takes",
          "Akrati Saxena"
        ],
        "arxiv_categories": [
          "cs.SI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Comparative Evaluation Community",
        "Quantitative Measure",
        "Community Detection",
        "Individual Fairness",
        "Standard",
        "SBMDL",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.008893"
    },
    {
      "id": "arxiv-2602.16323v1",
      "title": "Wearable AR for Restorative Breaks: How Interactive Narrative Experiences Support Relaxation for Young Adults",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16323v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Young adults often take breaks from screen-intensive work by consuming digital content on mobile phones, which undermines rest through visual fatigue and inactivity. We introduce a design framework that embeds light break activities into media content on AR smart glasses, balancing engagement and recovery. The framework employs three strategies: (1) seamlessly guiding users by embedding activity cues aligned with media elements; (2) transitioning to audio-centric formats to reduce visual load while sustaining immersion; and (3) structuring sessions with \"rise-peak-closure\" pacing for smooth transitions. In a within-subjects study (N = 16) comparing passive viewing, reminder-based breaks, and non-narrative activities, InteractiveBreak instantiated from our framework seamlessly guided activities, sustained engagement, and enhanced break quality. These findings demonstrate wearable AR's potential to support restorative relaxation by transforming breaks into engaging and meaningful experiences.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16323v1",
        "authors": [
          "Jindu Wang",
          "Runze Cai",
          "Shuchang Xu",
          "Tianrui Hu",
          "Huamin Qu"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "How Interactive Narrative Experiences",
        "Young Adults Young",
        "Support Relaxation",
        "Restorative Breaks",
        "Framework",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.009245"
    },
    {
      "id": "arxiv-2602.16307v1",
      "title": "Generative AI Usage of University Students: Navigating Between Education and Business",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16307v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This study investigates generative artificial intelligence (GenAI) usage of university students who study alongside their professional career. Previous literature has paid little attention to part-time students and the intersectional use of GenAI between education and business. This study examines with a grounded theory approach the characteristics of GenAI usage of part-time students. Eleven students from a distance learning university were interviewed. Three causal and four intervening conditions, as well as strategies were identified, to influence the use of GenAI. The study highlights both the potential and challenges of GenAI usage in education and business. While GenAI can significantly enhance productivity and learning outcomes, concerns about ethical implications, reliability, and the risk of academic misconduct persist. The developed grounded model offers a comprehensive understanding of GenAI usage among students, providing valuable insights for educators, policymakers, and developers of GenAI tools seeking to bridge the gap between education and business.",
        "keywords": [
          "cs.CY",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16307v1",
        "authors": [
          "Fabian Walke",
          "Veronika Föller"
        ],
        "arxiv_categories": [
          "cs.CY",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Navigating Between Education",
        "Artificial Intelligence",
        "University Students",
        "University",
        "Policy",
        "Intel",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.009642"
    },
    {
      "id": "arxiv-2602.16302v1",
      "title": "\"What I'm Interested in is Something that Violates the Law\": Regulatory Practitioner Views on Automated Detection of Deceptive Design Patterns",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16302v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Although deceptive design patterns are subject to growing regulatory oversight, enforcement races to keep up with the scale of the problem. One promising solution is automated detection tools, many of which are developed within academia. We interviewed nine experienced practitioners working within or alongside regulatory bodies to understand their work against deceptive design patterns, including the use of supporting tools and the prospect of automation. Computing technologies have their place in regulatory practice, but not as envisioned in research. For example, investigations require utmost transparency and accountability in all the activities we identify as accompanying dark pattern detection, which many existing tools cannot provide. Moreover, tools need to map interfaces to legal violations to be of use. We thus recommend conducting user requirement research to maximize research impact, supporting ancillary activities beyond detection, and establishing practical tech adoption pathways that account for the needs of both scientific and regulatory activities.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16302v1",
        "authors": [
          "Arianna Rossi",
          "Simon Parkin"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Deceptive Design Patterns Although",
        "Regulatory Practitioner Views",
        "Automated Detection",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.010042"
    },
    {
      "id": "arxiv-2602.16279v1",
      "title": "Flow on Social Media? Rarer Than You'd Think",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16279v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Researchers often attribute social media's appeal to its ability to elicit flow experiences of deep absorption and effortless engagement. Yet prolonged use has also been linked to distraction, fatigue, and lower mood. This paradox remains poorly understood, in part because prior studies rely on habitual or one-shot reports that ask participants to directly attribute flow to social media. To address this gap, we conducted a five-day field study with 40 participants, combining objective smartphone app tracking with daily reconstructions of flow-inducing activities. Across 673 reported flow occurrences, participants rarely associated flow with social media (2 percent). Instead, heavier social media use predicted fewer daily flow occurrences. We further examine this relationship through the effects of social media use on fatigue, mood, and motivation. Altogether, our findings suggest that flow and social media may not align as closely as assumed - and might even compete - underscoring the need for further research.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16279v1",
        "authors": [
          "Michael T. Knierim",
          "Thimo Schulz",
          "Moritz Schiller",
          "Jwan Shaban",
          "Mario Nadj"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Think Researchers",
        "Rarer Than You",
        "Social Media",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.010511"
    },
    {
      "id": "arxiv-2602.16251v1",
      "title": "RelianceScope: An Analytical Framework for Examining Students' Reliance on Generative AI Chatbots in Problem Solving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16251v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generative AI chatbots enable personalized problem-solving, but effective learning requires students to self-regulate both how they seek help and how they use AI-generated responses. Considering engagement modes across these two actions reveals nuanced reliance patterns: for example, a student may actively engage in help-seeking by clearly specifying areas of need, yet engage passively in response-use by copying AI outputs, or vice versa. However, existing research lacks systematic tools for jointly capturing engagement across help-seeking and response-use, limiting the analysis of such reliance behaviors. We introduce RelianceScope, an analytical framework that characterizes students' reliance on chatbots during problem-solving. RelianceScope (1) operationalizes reliance into nine patterns based on combinations of engagement modes in help-seeking and response-use, and (2) situates these patterns within a knowledge-context lens that accounts for students' prior knowledge and the instructional significance of knowledge components. Rather than prescribing optimal AI use, the framework enables fine-grained analysis of reliance in open-ended student-AI interactions. As an illustrative application, we applied RelianceScope to analyze chat and code-edit logs from 79 college students in a web programming course. Results show that active help-seeking is associated with active response-use, whereas reliance patterns remain similar across knowledge mastery levels. Students often struggled to articulate their knowledge gaps and to adapt AI responses. Using our annotated dataset as a benchmark, we further demonstrate that large language models can reliably detect reliance during help-seeking and response-use. We conclude by discussing the implications of RelianceScope and the design guidelines for AI-supported educational systems.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16251v1",
        "authors": [
          "Hyoungwook Jin",
          "Minju Yoo",
          "Jieun Han",
          "Zixin Chen",
          "So-Yeon Ahn"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Problem Solving Generative",
        "An Analytical Framework",
        "Examining Students",
        "Framework",
        "Guideline",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.011061"
    },
    {
      "id": "arxiv-2602.16234v1",
      "title": "Computing Equilibria in Games with Stochastic Action Sets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16234v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The study of learning in games typically assumes that each player always has access to all of their actions. However, in many practical scenarios, arbitrary restrictions induced by exogenous stochasticity might be placed on a player's action set. To model this setting, for a game $\\mathcal{G}_{\\mathrm{orig}}$ with action set $A_i$ for each player $i$, we introduce the corresponding Game with Stochastic Action Sets (GSAS) which is parametrized by a probability distribution over the players' set of possible action subsets $\\mathcal{S}_i \\subseteq 2^{\\vert A_i\\vert}\\backslash\\{\\varnothing\\}$. In a GSAS, players' strategies and Nash equilibria (NE) admit prohibitively large representations, thus existing algorithms for NE computation scale poorly. Under the assumption that action availabilities are independent between players, we show that NE in two-player zero-sum (2p0s) GSAS can be compactly represented by a vector of size $\\vert A_i\\vert$, overcoming naive exponential sized representation of equilibria. Computationally, we introduce an efficient approach based on sleeping internal regret minimization and show that it converges to approximate NE in 2p0s-GSAS at a rate $O(\\sqrt{\\log\\vert A_i\\vert/T})$ with appropriate choice of stepsizes, avoiding the exponential blow-up of game-dependent constants.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16234v1",
        "authors": [
          "Thomas Schwarz",
          "Ryann Sim",
          "Chun Kai Ling"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Stochastic Action Sets",
        "Computing Equilibria",
        "GSAS",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.011468"
    },
    {
      "id": "arxiv-2602.16201v1",
      "title": "Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16201v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models (LLMs) are trained on web-scale corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This paper develops a structured taxonomy and analysis of long-Tail Knowledge in large language models, synthesizing prior work across technical and sociotechnical perspectives. We introduce a structured analytical framework that synthesizes prior work across four complementary axes: how long-Tail Knowledge is defined, the mechanisms by which it is lost or distorted during training and inference, the technical interventions proposed to mitigate these failures, and the implications of these failures for fairness, accountability, transparency, and user trust. We further examine how existing evaluation practices obscure tail behavior and complicate accountability for rare but consequential failures. The paper concludes by identifying open challenges related to privacy, sustainability, and governance that constrain long-Tail Knowledge representation. Taken together, this paper provides a unifying conceptual framework for understanding how long-Tail Knowledge is defined, lost, evaluated, and manifested in deployed language model systems.",
        "keywords": [
          "cs.CL",
          "cs.AI",
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16201v1",
        "authors": [
          "Sanket Badhe",
          "Deep Shah",
          "Nehal Kathrotia"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.AI",
          "cs.CY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Language Models",
        "Implications Large",
        "Tail Knowledge",
        "Framework",
        "LLM",
        "IoT",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.011897"
    },
    {
      "id": "arxiv-2602.16196v1",
      "title": "Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16196v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Coordinating large populations of interacting agents is a central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture heterogeneity, but are computationally expensive as the number of agents grows. Therefore, we introduce $\\texttt{GMFS}$, a $\\textbf{G}$raphon $\\textbf{M}$ean-$\\textbf{F}$ield $\\textbf{S}$ubsampling framework for scalable cooperative MARL with heterogeneous agent interactions. By subsampling $κ$ agents according to interaction strength, we approximate the graphon-weighted mean-field and learn a policy with sample complexity $\\mathrm{poly}(κ)$ and optimality gap $O(1/\\sqrtκ)$. We verify our theory with numerical simulations in robotic coordination, showing that $\\texttt{GMFS}$ achieves near-optimal performance.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16196v1",
        "authors": [
          "Emile Anand",
          "Richard Hoffmann",
          "Sarah Liaw",
          "Adam Wierman"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agent Reinforcement Learning Coordinating",
        "Cooperative Heterogeneous Multi",
        "Field Subsampling",
        "Graphon Mean",
        "Framework",
        "Policy",
        "Robot",
        "GMFS",
        "MARL",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.012669"
    },
    {
      "id": "arxiv-2602.16194v1",
      "title": "Temporal Panel Selection in Ongoing Citizens' Assemblies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16194v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Permanent citizens' assemblies are ongoing deliberative bodies composed of randomly selected citizens, organized into panels that rotate over time. Unlike one-off panels, which represent the population in a single snapshot, permanent assemblies enable shifting participation across multiple rounds. This structure offers a powerful framework for ensuring that different groups of individuals are represented over time across successive panels. In particular, it allows smaller groups of individuals that may not warrant representation in every individual panel to be represented across a sequence of them. We formalize this temporal sortition framework by requiring proportional representation both within each individual panel and across the sequence of panels. Building on the work of Ebadian and Micha (2025), we consider a setting in which the population lies in a metric space, and the goal is to achieve both proportional representation, ensuring that every group of citizens receives adequate representation, and individual fairness, ensuring that each individual has an equal probability of being selected. We extend the notion of representation to a temporal setting by requiring that every initial segment of the panel sequence, viewed as a cumulative whole, proportionally reflects the structure of the population. We present algorithms that provide varying guarantees of proportional representation, both within individual panels and across any sequence of panels, while also maintaining individual fairness over time.",
        "keywords": [
          "cs.GT",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16194v1",
        "authors": [
          "Yusuf Hakan Kalayci",
          "Evi Micha"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.AI"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Temporal Panel Selection",
        "Assemblies Permanent",
        "Ongoing Citizens",
        "Framework",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.013112"
    },
    {
      "id": "arxiv-2602.16183v1",
      "title": "Multi-Agent Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16183v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the \\emph{Submodular Welfare Problem} (SWP), where items are partitioned among agents with monotone submodular utilities to maximize the total welfare under \\emph{bandit feedback}. Classical SWP assumes full value-oracle access, achieving $(1-1/e)$ approximations via continuous-greedy algorithms. We extend this to a \\emph{multi-agent combinatorial bandit} framework (\\textsc{MA-CMAB}), where actions are partitions under full-bandit feedback with non-communicating agents. Unlike prior single-agent or separable multi-agent CMAB models, our setting couples agents through shared allocation constraints. We propose an explore-then-commit strategy with randomized assignments, achieving $\\tilde{\\mathcal{O}}(T^{2/3})$ regret against a $(1-1/e)$ benchmark, the first such guarantee for partition-based submodular welfare problem under bandit feedback.",
        "keywords": [
          "cs.GT",
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16183v1",
        "authors": [
          "Subham Pokhriyal",
          "Shweta Jain",
          "Vaneet Aggarwal"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Submodular Welfare Problem",
        "Agent Combinatorial",
        "Bandit Feedback We",
        "Framework",
        "Oracle",
        "CMAB",
        "EPA",
        "Act",
        "MIT",
        "SWP",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.013351"
    },
    {
      "id": "arxiv-2602.16157v1",
      "title": "Peeking Ahead of the Field Study: Exploring VLM Personas as Support Tools for Embodied Studies in HCI",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16157v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Field studies are irreplaceable but costly, time-consuming, and error-prone, which need careful preparation. Inspired by rapid-prototyping in manufacturing, we propose a fast, low-cost evaluation method using Vision-Language Model (VLM) personas to simulate outcomes comparable to field results. While LLMs show human-like reasoning and language capabilities, autonomous vehicle (AV)-pedestrian interaction requires spatial awareness, emotional empathy, and behavioral generation. This raises our research question: To what extent can VLM personas mimic human responses in field studies? We conducted parallel studies: 1) one real-world study with 20 participants, and 2) one video-study using 20 VLM personas, both on a street-crossing task. We compared their responses and interviewed five HCI researchers on potential applications. Results show that VLM personas mimic human response patterns (e.g., average crossing times of 5.25 s vs. 5.07 s) lack the behavioral variability and depth. They show promise for formative studies, field study preparation, and human data augmentation.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16157v1",
        "authors": [
          "Xinyue Gui",
          "Ding Xia",
          "Mark Colley",
          "Yuan Li",
          "Vishal Chauhan"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Autonomous Vehicle",
        "Embodied Studies",
        "Language Model",
        "Support Tools",
        "Peeking Ahead",
        "Field Study",
        "EPA",
        "LLM",
        "HCI",
        "Act",
        "VLM",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.013525"
    },
    {
      "id": "arxiv-2602.16151v1",
      "title": "Queer NLP: A Critical Survey on Literature Gaps, Biases and Trends",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16151v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Natural language processing (NLP) technologies are rapidly reshaping how language is created, processed, and analyzed by humans. With current and potential applications in hiring, law, healthcare, and other areas that impact people's lives, understanding and mitigating harms towards marginalized groups is critical. In this survey, we examine NLP research papers that explicitly address the relationship between LGBTQIA+ communities and NLP technologies. We systematically review all such papers published in the ACL Anthology, to answer the following research questions: (1) What are current research trends? (2) What gaps exist in terms of topics and methods? (3) What areas are open for future work? We find that while the number of papers on queer NLP has grown within the last few years, most papers take a reactive rather than a proactive approach, pointing out bias more often than mitigating it, and focusing on shortcomings of existing systems rather than creating new solutions. Our survey uncovers many opportunities for future work, especially regarding stakeholder involvement, intersectionality, interdisciplinarity, and languages other than English. We also offer an outlook from a queer studies perspective, highlighting understudied topics and gaps in the harms addressed in NLP papers. Beyond being a roadmap of what has been done, this survey is a call to action for work towards more just and inclusive NLP technologies.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16151v1",
        "authors": [
          "Sabine Weber",
          "Angelina Wang",
          "Ankush Gupta",
          "Arjun Subramonian",
          "Dennis Ulmer"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Critical Survey",
        "Literature Gaps",
        "Trends Natural",
        "ACL",
        "NLP",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.013761"
    },
    {
      "id": "arxiv-2602.16147v1",
      "title": "ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16147v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cross-subject generalization in EEG-based brain-computer interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features exhibit consistently higher cross-subject similarity than temporal signals. Motivated by this observation, we introduce ASPEN, a hybrid architecture that combines spectral and temporal feature streams via multiplicative fusion, requiring cross-modal agreement for features to propagate. Experiments across six benchmark datasets reveal that ASPEN is able to dynamically achieve the optimal spectral-temporal balance depending on the paradigm. ASPEN achieves the best unseen-subject accuracy on three of six datasets and competitive performance on others, demonstrating that multiplicative multimodal fusion enables effective cross-subject generalization.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.HC",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16147v1",
        "authors": [
          "Megan Lee",
          "Seung Ha Hwang",
          "Inhyeok Choi",
          "Shreyas Darade",
          "Mengchun Zhang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.HC",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Subject Brain Decoding Cross",
        "Temporal Fusion",
        "Motor Imagery",
        "Agreement",
        "Fusion",
        "SSVEP",
        "ASPEN",
        "EEG",
        "NSF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.013934"
    },
    {
      "id": "arxiv-2602.16140v1",
      "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16140v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced generative pre-trained transformer (OpenAI GPT-4o). Participants were tasked with identifying the top five behavioral changes that could reduce home energy use with the GPT model that functioned as an LLM-integrated BEMS. Then, the collected prompt-response data and participant conclusions were analyzed using an analytical framework that hierarchically assessed and scored human-AI interactions and their home energy analysis approaches. Also, participants were classified into four groups based on their self-evaluated domain knowledge of building energy use and AI literacy, and Kruskal-Wallis H tests with post-hoc pairwise comparisons were conducted across 20 quantifiable metrics. Key takeaways include: most participants employed concise prompts (median: 16.2 words) and relied heavily on GPT's analytical capabilities; and notably, only 1 of 20 metrics, appliance identification rate, showed statistically significant group differences (p=0.037), driven by AI literacy rather than domain knowledge, suggesting an equalizing effect of LLMs across expertise levels. This study provides foundational insights into human-AI collaboration dynamics and promising development directions in the context of LLM-integrated BEMS and contributes to realizing human-centric LLM-integrated energy systems.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16140v1",
        "authors": [
          "Wooyoung Jung",
          "Kahyun Jeon",
          "Prosper Babon-Ayeng"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Integrated Building Energy Management",
        "Artificial Intelligence",
        "User Domain Knowledge",
        "Large Language Model",
        "Transformer",
        "Framework",
        "OpenAI",
        "Intel",
        "BEMS",
        "LLM",
        "GPT",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.014194"
    },
    {
      "id": "arxiv-2602.16123v1",
      "title": "\"You Can Actually Do Something\": Shifts in High School Computer Science Teachers' Conceptions of AI/ML Systems and Algorithmic Justice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16123v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The recent proliferation of artificial intelligence and machine learning (AI/ML) systems highlights the need for all people to develop effective competencies to interact with and examine AI/ML systems. We study shifts in five experienced high school CS teachers' understanding of AI/ML systems after one year of participatory design, where they co-developed lessons on AI auditing, a systematic method to query AI/ML systems. Drawing on individual and group interviews, we found that teachers' perspectives became more situated, grounding their understanding in everyday contexts; more critical, reflecting growing awareness of harms; and more agentic, highlighting possibilities for action. Further, across all three perspectives, teachers consistently framed algorithmic justice through their role as educators, situating their concerns within their school communities. In the discussion, we consider the ways teachers' perspectives shifted, how AI auditing can shape these shifts, and the implications of these findings on AI literacy for both teachers and students.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16123v1",
        "authors": [
          "Daniel J. Noh",
          "Deborah A. Fields",
          "Yasmin B. Kafai",
          "Danaé Metaxa"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "High School Computer Science",
        "Artificial Intelligence",
        "You Can Actually Do",
        "Machine Learning",
        "Intel",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.014352"
    },
    {
      "id": "arxiv-2602.16112v1",
      "title": "Hiding in Plain Sight: Understanding the Everyday Practices and Challenges of Car Dwellers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16112v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Vehicle dwelling has increased significantly in recent years. While HCI research has explored vehicle dwelling through the lens of digital nomadism and vanlife, it has largely overlooked the complexities of vehicle dwelling as a form of housing insecurity, as well as the unique constraints of living in smaller vehicles. Drawing on a qualitative analysis of posts and comments from an online community, we examine car dwellers' infrastructuring work to manage daily life under social, spatial, and infrastructural constraints. We further explore the motivations and identity negotiations of car dwellers, whose experiences fall between homelessness and nomadism, and highlight how developing infrastructural competence can shape identity. We discuss implications for future HCI research on mobility and dwelling under conditions of uneven access to infrastructure and provide design recommendations for technologies that better account for car dwellers' diverse needs, circumstances, and identities.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16112v1",
        "authors": [
          "Rachael Zehrung",
          "Yunan Chen"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Car Dwellers Vehicle",
        "Everyday Practices",
        "Plain Sight",
        "HCI",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.014490"
    },
    {
      "id": "arxiv-2602.16080v1",
      "title": "Surgical Activation Steering via Generative Causal Mediation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16080v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Where should we intervene in a language model (LM) to control behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of contrasting inputs and responses. Then, we quantify how individual model components mediate the contrastive concept and select the strongest mediators for steering. We evaluate GCM on three tasks--refusal, sycophancy, and style transfer--across three language models. GCM successfully localizes concepts expressed in long-form responses and consistently outperforms correlational probe-based baselines when steering with a sparse set of attention heads. Together, these results demonstrate that GCM provides an effective approach for localizing and controlling the long-form responses of LMs.",
        "keywords": [
          "cs.CL",
          "cs.CY",
          "cs.HC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16080v1",
        "authors": [
          "Aruna Sankaranarayanan",
          "Amir Zur",
          "Atticus Geiger",
          "Dylan Hadfield-Menell"
        ],
        "arxiv_categories": [
          "cs.CL",
          "cs.CY",
          "cs.HC",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generative Causal Mediation Where",
        "Surgical Activation Steering",
        "Generative Causal Mediation",
        "GCM",
        "NSF",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.014629"
    },
    {
      "id": "arxiv-2602.16071v1",
      "title": "A Theory of Network Games Part 1: Utility Representation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16071v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We demonstrate that a ubiquitous feature of network games, bilateral strategic interactions, is equivalent to having player utilities that are additively separable across opponents. We distinguish two formal notions of bilateral strategic interactions. Opponent independence means that player i's preferences over opponent j's action do not depend on what other opponents do. Strategic independence means that how opponent j's choice influences i's preference between any two actions does not depend on what other opponents do. If i's preferences jointly satisfy both conditions, then we can represent her preferences over strategy profiles using an additively separable utility. If i's preferences satisfy only strategic independence, then we can still represent her preferences over just her own actions using an additively separable utility. Common utilities based on a linear aggregate of opponent actions satisfy strategic independence and are therefore strategically equivalent to additively separable utilities--in fact, we can assume a utility that is linear in opponent actions.",
        "keywords": [
          "econ.TH",
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16071v1",
        "authors": [
          "Joseph Root",
          "Evan Sadler"
        ],
        "arxiv_categories": [
          "econ.TH",
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Utility Representation We",
        "Network Games Part",
        "EPA",
        "Act",
        "DOE"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.014792"
    },
    {
      "id": "arxiv-2602.16070v1",
      "title": "Access in the Shadow of Ableism: An Autoethnography of a Blind Student's Higher Education Experience in China",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16070v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The HCI research community has witnessed a growing body of research on accessibility and disability driven by efforts to improve access. Yet, the concept of access reveals its limitations when examined within broader ableist structures. Drawing on an autoethnographic method, this study shares the co-first author Zhang's experiences at two higher-education institutions in China, including a specialized program exclusively for blind and low-vision students and a mainstream university where he was the first blind student admitted. Our analysis revealed tensions around access in both institutions: they either marginalized blind students within society at large or imposed pressures to conform to sighted norms. Both institutions were further constrained by systemic issues, including limited accessible resources, pervasive ableist cultures, and the lack of formalized policies. In response to these tensions, we conceptualize access as a contradictory construct and argue for understanding accessibility as an ongoing, exploratory practice within ableist structures.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16070v1",
        "authors": [
          "Weijun Zhang",
          "Xinru Tang"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Higher Education Experience",
        "An Autoethnography",
        "Blind Student",
        "University",
        "HCI",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.014959"
    },
    {
      "id": "arxiv-2602.16037v1",
      "title": "Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16037v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Autonomous agentic workflows that iteratively refine their own behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating three clinical symptoms with varying prevalence (shortness of breath at 23%, chest pain at 12%, and Long COVID brain fog at 3%), we observed that validation sensitivity oscillated between 1.0 and 0.0 across iterations, with severity inversely proportional to class prevalence. At 3% prevalence, the system achieved 95% accuracy while detecting zero positive cases, a failure mode obscured by standard evaluation metrics. We evaluated two interventions: a guiding agent that actively redirected optimization, amplifying overfitting rather than correcting it, and a selector agent that retrospectively identified the best-performing iteration successfully prevented catastrophic failure. With selector agent oversight, the system outperformed expert-curated lexicons on brain fog detection by 331% (F1) and chest pain by 7%, despite requiring only a single natural language term as input. These findings characterize a critical failure mode of autonomous AI systems and demonstrate that retrospective selection outperforms active intervention for stabilization in low-prevalence classification tasks.",
        "keywords": [
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16037v1",
        "authors": [
          "Cameron Cagan",
          "Pedram Fard",
          "Jiazi Tian",
          "Jingya Cheng",
          "Shawn N. Murphy"
        ],
        "arxiv_categories": [
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Clinical Symptom Detection Autonomous",
        "Autonomous Agentic Workflows",
        "Optimization Instability",
        "Framework",
        "Standard",
        "COVID",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.015240"
    },
    {
      "id": "arxiv-2602.16033v1",
      "title": "Transforming GenAI Policy to Prompting Instruction: An RCT of Scalable Prompting Interventions in a CS1 Course",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16033v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Despite universal GenAI adoption, students cannot distinguish task performance from actual learning and lack skills to leverage AI for learning, leading to worse exam performance when AI use remains unreflective. Yet few interventions teaching students to prompt AI as a tutor rather than solution provider have been validated at scale through randomized controlled trials (RCTs). To bridge this gap, we conducted a semester-long RCT (N=979) with four ICAP framework-based instructional conditions varying in engagement intensity with a pre-test, immediate and delayed post-test and surveys. Mixed methods analysis results showed: (1) All conditions significantly improved prompting skills, with gains increasing progressively from Condition 1 to Condition 4, validating ICAP's cognitive engagement hierarchy; (2) for students with similar pre-test scores, higher learning gain in immediate post-test predict higher final exam score, though no direct between-group differences emerged; (3) Our interventions are suitable and scalable solutions for diverse educational contexts, resources and learners. Together, this study makes empirical and theoretical contributions: (1) theoretically, we provided one of the first large-scale RCTs examining how cognitive engagement shapes learning in prompting literacy and clarifying the relationship between learning-oriented prompting skills and broader academic performance; (2) empirically, we offered timely design guidance for transforming GenAI classroom policies into scalable, actionable prompting literacy instruction to advance learning in the era of Generative AI.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16033v1",
        "authors": [
          "Ruiwei Xiao",
          "Runlong Ye",
          "Xinying Hou",
          "Jessica Wen",
          "Harsh Kumar"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Scalable Prompting Interventions",
        "Prompting Instruction",
        "Course Despite",
        "Framework",
        "Policy",
        "ICAP",
        "RCT",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.015478"
    },
    {
      "id": "arxiv-2602.16013v1",
      "title": "Punchlines Unbound: Comedy Practices in Social Virtual Reality",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16013v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Social VR platforms serve as an emergent venue for live performance, enabling co-presence and real-time interaction among distributed performers and audiences within shared virtual environments. Live performances, such as comedy, rely on subtle social cues between performers and audiences, which are missing in VR. However, it remains unclear how comedians utilize avatar-mediated cues in social VR. We conducted semi-structured interviews and observations with 23 virtual comedians on VRChat. Results revealed that virtual comedians transformed their limited nonverbal expressiveness into performative opportunities through intentional control and exaggeration. Additionally, a distinctive culture emerged around context-appropriate emoji reactions from audiences, while challenges such as audio latency and moderation against trolling were highlighted. Our findings advance understanding of how performers creatively adapt to expressive constraints in avatar-mediated settings. We further demonstrate how challenges in performer-audience interaction and moderation provide design insights for systems enhancing feedback visibility and sustain community norms without restricting creative expression.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16013v1",
        "authors": [
          "Ryo Ohara",
          "Chi-Lan Yang",
          "Yuji Hatada",
          "Takuji Narumi",
          "Hideaki Kuzuoka"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Social Virtual Reality Social",
        "Punchlines Unbound",
        "Comedy Practices",
        "NSF",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.015681"
    },
    {
      "id": "arxiv-2602.15988v1",
      "title": "Automated Assessment of Kidney Ureteroscopy Exploration for Training",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15988v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Purpose: Kidney ureteroscopic navigation is challenging with a steep learning curve. However, current clinical training has major deficiencies, as it requires one-on-one feedback from experts and occurs in the operating room (OR). Therefore, there is a need for a phantom training system with automated feedback to greatly \\revision{expand} training opportunities. Methods: We propose a novel, purely ureteroscope video-based scope localization framework that automatically identifies calyces missed by the trainee in a phantom kidney exploration. We use a slow, thorough, prior exploration video of the kidney to generate a reference reconstruction. Then, this reference reconstruction can be used to localize any exploration video of the same phantom. Results: In 15 exploration videos, a total of 69 out of 74 calyces were correctly classified. We achieve < 4mm camera pose localization error. Given the reference reconstruction, the system takes 10 minutes to generate the results for a typical exploration (1-2 minute long). Conclusion: We demonstrate a novel camera localization framework that can provide accurate and automatic feedback for kidney phantom explorations. We show its ability as a valid tool that enables out-of-OR training without requiring supervision from an expert.",
        "keywords": [
          "eess.IV",
          "cs.CV",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15988v1",
        "authors": [
          "Fangjie Li",
          "Nicholas Kavoussi",
          "Charan Mohan",
          "Matthieu Chabanas",
          "Jie Ying Wu"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.CV",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Kidney Ureteroscopy Exploration",
        "Automated Assessment",
        "Training Purpose",
        "Framework",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.015854"
    },
    {
      "id": "arxiv-2602.15986v1",
      "title": "Convergence rates of random-order best-response dynamics in public good games on networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15986v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study convergence rates of random-order best-response dynamics in games on networks with linear best responses and strategic substitutes. Combining formal analysis with numerical simulations we identify phenomena that lead to slow convergence. One of the key such phenomena is convergence to stable strategy profiles in parts of the network neighboring sets of nodes which remain inactive until the dynamics is close to converging and then switch to activity, initiating convergence to profiles with a new set of active agents and possibly leading to another iteration of such behavior. We identify structural properties of graphs which make such phenomena more likely. These properties go beyond the spectrum of a graph, which we demonstrate analyzing convergence rates on co-spectral mates.",
        "keywords": [
          "cs.GT",
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15986v1",
        "authors": [
          "Wojciech Misiak",
          "Marcin Dziubiński"
        ],
        "arxiv_categories": [
          "cs.GT",
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.015970"
    },
    {
      "id": "arxiv-2602.15784v2",
      "title": "Stability in Distance Preservation Games on Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15784v2",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We introduce a new class of network allocation games called graphical distance preservation games. Here, we are given a graph, called a topology, and a set of agents that need to be allocated to its vertices. Moreover, every agent has an ideal (and possibly different) distance in which to be from some of the other agents. Given an allocation of agents, each one of them suffers a cost that is the sum of the differences from the ideal distance for each agent in their subset. The goal is to decide whether there is a stable allocation of the agents, i.e., no agent would like to deviate from their location. Specifically, we consider three different stability notions: envy-freeness, swap stability, and jump stability. We perform a comprehensive study of the (parameterized) complexity of the problem in three different dimensions: the topology of the graph, the number of agents, and the structure of preferences of the agents.",
        "keywords": [
          "cs.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15784v2",
        "authors": [
          "Argyrios Deligkas",
          "Eduard Eiben",
          "Tiger-Lily Goldsmith",
          "Dušan Knop",
          "Šimon Schierreich"
        ],
        "arxiv_categories": [
          "cs.GT"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Distance Preservation Games",
        "Graphs We"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.016175"
    },
    {
      "id": "arxiv-2602.15767v1",
      "title": "Robot-Assisted Social Dining as a White Glove Service",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15767v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Robot-assisted feeding enables people with disabilities who require assistance eating to enjoy a meal independently and with dignity. However, existing systems have only been tested in-lab or in-home, leaving in-the-wild social dining contexts (e.g., restaurants) largely unexplored. Designing a robot for such contexts presents unique challenges, such as dynamic and unsupervised dining environments that a robot needs to account for and respond to. Through speculative participatory design with people with disabilities, supported by semi-structured interviews and a custom AI-based visual storyboarding tool, we uncovered ideal scenarios for in-the-wild social dining. Our key insight suggests that such systems should: embody the principles of a white glove service where the robot (1) supports multimodal inputs and unobtrusive outputs; (2) has contextually sensitive social behavior and prioritizes the user; (3) has expanded roles beyond feeding; (4) adapts to other relationships at the dining table. Our work has implications for in-the-wild and group contexts of robot-assisted feeding.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15767v1",
        "authors": [
          "Atharva S Kashyap",
          "Ugne Aleksandra Morkute",
          "Patricia Alves-Oliveira"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.HC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "White Glove Service Robot",
        "Assisted Social Dining",
        "Robot",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.016320"
    },
    {
      "id": "arxiv-2602.15745v1",
      "title": "Unraveling Entangled Feeds: Rethinking Social Media Design to Enhance User Well-being",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15745v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Social media platforms have rapidly adopted algorithmic curation with little consideration for the potential harm to users' mental well-being. We present findings from design workshops with 21 participants diagnosed with mental illness about their interactions with social media platforms. We find that users develop cause-and-effect explanations, or folk theories, to understand their experiences with algorithmic curation. These folk theories highlight a breakdown in algorithmic design that we explain using the framework of entanglement, a phenomenon where there is a disconnect between users' actions and platform outcomes on an emotional level. Participants' designs to address entanglement and mitigate harms centered on contextualizing their engagement and restoring explicit user control on social media. The conceptualization of entanglement and the resulting design recommendations have implications for social computing and recommender systems research, particularly in evaluating and designing social media platforms that support users' mental well-being.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15745v1",
        "authors": [
          "Ashlee Milton",
          "Dan Runningen",
          "Loren Terveen",
          "Harmanpreet Kaur",
          "Stevie Chancellor"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Rethinking Social Media Design",
        "Unraveling Entangled Feeds",
        "Enhance User Well",
        "Framework",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.016466"
    },
    {
      "id": "arxiv-2602.15738v1",
      "title": "Beyond Labels: Information-Efficient Human-in-the-Loop Learning using Ranking and Selection Queries",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15738v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Integrating human expertise into machine learning systems often reduces the role of experts to labeling oracles, a paradigm that limits the amount of information exchanged and fails to capture the nuances of human judgment. We address this challenge by developing a human-in-the-loop framework to learn binary classifiers with rich query types, consisting of item ranking and exemplar selection. We first introduce probabilistic human response models for these rich queries motivated by the relationship experimentally observed between the perceived implicit score of an item and its distance to the unknown classifier. Using these models, we then design active learning algorithms that leverage the rich queries to increase the information gained per interaction. We provide theoretical bounds on sample complexity and develop a tractable and computationally efficient variational approximation. Through experiments with simulated annotators derived from crowdsourced word-sentiment and image-aesthetic datasets, we demonstrate significant reductions on sample complexity. We further extend active learning strategies to select queries that maximize information rate, explicitly balancing informational value against annotation cost. This algorithm in the word sentiment classification task reduces learning time by more than 57\\% compared to traditional label-only active learning.",
        "keywords": [
          "cs.HC",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15738v1",
        "authors": [
          "Belén Martín-Urcelay",
          "Yoonsang Lee",
          "Matthieu R. Bloch",
          "Christopher J. Rozell"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.LG"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Selection Queries Integrating",
        "Machine Learning",
        "Efficient Human",
        "Loop Learning",
        "Beyond Labels",
        "Framework",
        "Oracle",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.016645"
    },
    {
      "id": "arxiv-2602.15736v1",
      "title": "SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15736v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs.",
        "keywords": [
          "cs.SI",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15736v1",
        "authors": [
          "Jorge Luiz Franco",
          "Thomas Peron",
          "Alcebiades Dal Col",
          "Fabiano Petronetto",
          "Filipe Alves Neto Verri"
        ],
        "arxiv_categories": [
          "cs.SI",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Unified Spectral Framework",
        "Hypergraphs Identifying",
        "Incidence Centrality",
        "Directed Networks",
        "Hodge Laplacians",
        "Edge Analysis",
        "Regulation",
        "Framework",
        "SVD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.016823"
    },
    {
      "id": "arxiv-2602.15708v1",
      "title": "Outer Diversity of Structured Domains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15708v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An ordinal preference domain is a subset of preference orders that the voters are allowed to cast in an election. We introduce and study the notion of outer diversity of a domain and evaluate its value for a number of well-known structured domains, such as the single-peaked, single-crossing, group-separable, and Euclidean ones.",
        "keywords": [
          "cs.GT",
          "cs.AI",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15708v1",
        "authors": [
          "Piotr Faliszewski",
          "Krzysztof Sornat",
          "Stanisław Szufa",
          "Tomasz Wąs"
        ],
        "arxiv_categories": [
          "cs.GT",
          "cs.AI",
          "cs.MA"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Structured Domains An",
        "Outer Diversity",
        "EPA",
        "EU",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:22.016888"
    },
    {
      "id": "arxiv-2602.15698v1",
      "title": "How to Disclose? Strategic AI Disclosure in Crowdfunding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15698v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "As artificial intelligence (AI) increasingly integrates into crowdfunding practices, strategic disclosure of AI involvement has become critical. Yet, empirical insights into how different disclosure strategies influence investor decisions remain limited. Drawing on signaling theory and Aristotle's rhetorical framework, we examine how mandatory AI disclosure affects crowdfunding performance and how substantive signals (degree of AI involvement) and rhetorical signals (logos/explicitness, ethos/authenticity, pathos/emotional tone) moderate these effects. Leveraging Kickstarter's mandatory AI disclosure policy as a natural experiment and four supplementary online experiments, we find that mandatory AI disclosure significantly reduces crowdfunding performance: funds raised decline by 39.8% and backer counts by 23.9% for AI-involved projects. However, this adverse effect is systematically moderated by disclosure strategy. Greater AI involvement amplifies the negative effects of AI disclosure, while high authenticity and high explicitness mitigate them. Interestingly, excessive positive emotional tone (a strategy creators might intuitively adopt to counteract AI skepticism) backfires and exacerbates negative outcomes. Supplementary randomized experiments identify two underlying mechanisms: perceived creator competence and AI washing concerns. Substantive signals primarily affect competence judgments, whereas rhetorical signals operate through varied pathways: either mediator alone or both in sequence. These findings provide theoretical and practical insights for entrepreneurs, platforms, and policymakers strategically managing AI transparency in high-stakes investment contexts.",
        "keywords": [
          "cs.HC",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15698v1",
        "authors": [
          "Ning Wang",
          "Chen Liang"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.AI"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Artificial Intelligence",
        "Leveraging Kickstarter",
        "Crowdfunding As",
        "Framework",
        "Policy",
        "Intel",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.017090"
    },
    {
      "id": "arxiv-2602.15684v1",
      "title": "Estimating Human Muscular Fatigue in Dynamic Collaborative Robotic Tasks with Learning-Based Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15684v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Assessing human muscle fatigue is critical for optimizing performance and safety in physical human-robot interaction(pHRI). This work presents a data-driven framework to estimate fatigue in dynamic, cyclic pHRI using arm-mounted surface electromyography(sEMG). Subject-specific machine-learning regression models(Random Forest, XGBoost, and Linear Regression predict the fraction of cycles to fatigue(FCF) from three frequency-domain and one time-domain EMG features, and are benchmarked against a convolutional neural network(CNN) that ingests spectrograms of filtered EMG. Framing fatigue estimation as regression (rather than classification) captures continuous progression toward fatigue, supporting earlier detection, timely intervention, and adaptive robot control. In experiments with ten participants, a collaborative robot under admittance control guided repetitive lateral (left-right) end-effector motions until muscular fatigue. Average FCF RMSE across participants was 20.8+/-4.3% for the CNN, 23.3+/-3.8% for Random Forest, 24.8+/-4.5% for XGBoost, and 26.9+/-6.1% for Linear Regression. To probe cross-task generalization, one participant additionally performed unseen vertical (up-down) and circular repetitions; models trained only on lateral data were tested directly and largely retained accuracy, indicating robustness to changes in movement direction, arm kinematics, and muscle recruitment, while Linear Regression deteriorated. Overall, the study shows that both feature-based ML and spectrogram-based DL can estimate remaining work capacity during repetitive pHRI, with the CNN delivering the lowest error and the tree-based models close behind. The reported transfer to new motion patterns suggests potential for practical fatigue monitoring without retraining for every task, improving operator protection and enabling fatigue-aware shared autonomy, for safer fatigue-adaptive pHRI control.",
        "keywords": [
          "cs.RO",
          "cs.AI",
          "cs.HC",
          "eess.SP",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15684v1",
        "authors": [
          "Feras Kiki",
          "Pouya P. Niaz",
          "Alireza Madani",
          "Cagatay Basdogan"
        ],
        "arxiv_categories": [
          "cs.RO",
          "cs.AI",
          "cs.HC",
          "eess.SP",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Collaborative Robotic Tasks",
        "Estimating Human Muscular Fatigue",
        "Based Models Assessing",
        "Linear Regression",
        "Neural Network",
        "Random Forest",
        "Framework",
        "Robot",
        "RMSE",
        "FCF",
        "NSF",
        "Act",
        "MIT",
        "EMG",
        "CNN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.017329"
    },
    {
      "id": "arxiv-2602.15638v1",
      "title": "Who Is Doing the Thinking? AI as a Dynamic Cognitive Partner: A Learner-Informed Framework",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15638v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Artificial intelligence is increasingly embedded in education, yet there remains a need to explain how students conceptualize AI's role in their thinking and learning. This study proposes a framework positioning AI as a dynamic cognitive partner whose function shifts across learning situations. Using qualitative analysis of written responses from 133 secondary students in Hong Kong following completion of an AI literacy course, we identified nine interrelated dimensions through which learners described AI as partnering with their cognition: conceptual scaffolding for difficult ideas; feedback and error detection; idea stimulation; cognitive organization; adaptive tutoring support; metacognitive monitoring support; task and cognitive load regulation; learning continuity beyond classroom boundaries; and explanation reframing through representational flexibility during moments of being stuck or overwhelmed. Across these dimensions, students distinguished between productive support that extends understanding and unproductive reliance that replaces cognitive effort, indicating situational awareness of when AI should and should not be used. Grounded in sociocultural theory, distributed cognition, self-regulated learning, and cognitive load perspectives, the framework clarifies how AI becomes integrated into learners' cognitive activity while illuminating the boundary between cognitive extension and substitution.",
        "keywords": [
          "cs.CY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15638v1",
        "authors": [
          "C. K. Y Chan"
        ],
        "arxiv_categories": [
          "cs.CY"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Informed Framework Artificial",
        "Dynamic Cognitive Partner",
        "Artificial Intelligence",
        "Who Is Doing",
        "Regulation",
        "Hong Kong",
        "Framework",
        "Intel",
        "Meta",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.017509"
    },
    {
      "id": "arxiv-2602.15631v1",
      "title": "Meflex: A Multi-agent Scaffolding System for Entrepreneurial Ideation Iteration via Nonlinear Business Plan Writing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15631v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Business plan (BP) writing plays a key role in entrepreneurship education by helping learners construct, evaluate, and iteratively refine their ideas. However, conventional BP writing remains a rigid, linear process that often fails to reflect the dynamic and recursive nature of entrepreneurial ideation. This mismatch is particularly challenging for novice entrepreneurial students, who struggle with the substantial cognitive demands of developing and refining ideas. While reflection and meta-reflection are critical strategies for fostering divergent and convergent thinking, existing writing tools rarely scaffold these higher-order processes. To address this gap, we present the Meflex System, a large language model (LLM)-based writing tool that integrates BP writing scaffolding with a nonlinear idea canvas to support iterative ideation through reflection and meta-reflection. We report findings from an exploratory user study with 30 participants that examined the system's usability and cognitive impact. Results show that Meflex effectively scaffolds BP writing, promotes divergent thinking through LLM-supported reflection, and enhances meta-reflective awareness while reducing cognitive load during complex idea development. These findings highlight the potential of non-linear LLM-based writing tools to foster deeper and coherent entrepreneurial thinking.",
        "keywords": [
          "cs.HC",
          "cs.SE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15631v1",
        "authors": [
          "Lan Luo",
          "Dongyijie Primo Pan",
          "Junhua Zhu",
          "Muzhi Zhou",
          "Pan Hui"
        ],
        "arxiv_categories": [
          "cs.HC",
          "cs.SE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Entrepreneurial Ideation Iteration",
        "Nonlinear Business Plan Writing",
        "Scaffolding System",
        "Meflex System",
        "Meta",
        "LLM",
        "Act",
        "WHO",
        "EU",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.017692"
    },
    {
      "id": "arxiv-2602.15572v1",
      "title": "Neural Network-Based Parameter Estimation of a Labour Market Agent-Based Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15572v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Agent-based modelling (ABM) is a widespread approach to simulate complex systems. Advancements in computational processing and storage have facilitated the adoption of ABMs across many fields; however, ABMs face challenges that limit their use as decision-support tools. A significant issue is parameter estimation in large-scale ABMs, particularly due to computational constraints on exploring the parameter space. This study evaluates a state-of-the-art simulation-based inference (SBI) framework that uses neural networks (NN) for parameter estimation. This framework is applied to an established labour market ABM based on job transition networks. The ABM is initiated with synthetic datasets and the real U.S. labour market. Next, we compare the effectiveness of summary statistics derived from a list of statistical measures with that learned by an embedded NN. The results demonstrate that the NN-based approach recovers the original parameters when evaluating posterior distributions across various dataset scales and improves efficiency compared to traditional Bayesian methods.",
        "keywords": [
          "cs.LG",
          "cs.MA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15572v1",
        "authors": [
          "M Lopes Alves",
          "Joel Dyer",
          "Doyne Farmer",
          "Michael Wooldridge",
          "Anisoara Calinescu"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.MA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Parameter Estimation",
        "Labour Market Agent",
        "Based Model Agent",
        "Neural Network",
        "Framework",
        "SBI",
        "ABM",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:22.018079"
    },
    {
      "id": "arxiv-2602.15569v1",
      "title": "\"What Are You Doing?\": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15569v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Using a dual-task paradigm with an in-car voice assistant, we found that intermediate feedback significantly improved perceived speed, trust, and user experience while reducing task load - effects that held across varying task complexities and interaction contexts. Interviews further revealed user preferences for an adaptive approach: high initial transparency to establish trust, followed by progressively reducing verbosity as systems prove reliable, with adjustments based on task stakes and situational context. We translate our empirical findings into design implications for feedback timing and verbosity in agentic assistants, balancing transparency and efficiency.",
        "keywords": [
          "cs.HC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15569v1",
        "authors": [
          "Johannes Kirmayr",
          "Raphael Wennmacher",
          "Khanh Huynh",
          "Lukas Stappen",
          "Elisabeth André"
        ],
        "arxiv_categories": [
          "cs.HC"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Car Assistants During Multi",
        "Step Processing Agentic",
        "Intermediate Feedback",
        "What Are You Doing",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:22.018242"
    },
    {
      "id": "arxiv-2602.16692v1",
      "title": "Disjoint Correspondence Colorings for $K_5$-Minor-free Graphs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16692v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Thomassen famously proved that every planar graph is 5-choosable. We explore variants of this result, focusing on finding disjoint correspondence colorings, in the more general class of $K_5$-minor-free graphs. Correspondence colorings generalize list colorings as follows. Given a graph $G$ and a positive integer $t$, a correspondence $t$-cover $\\textbf{M}$ assigns to each $v\\in V(G)$ a set of allowable colors $\\{1_v,\\ldots,t_v\\}$ and to each edge $vw\\in E(G)$ a matching between $\\{1_v,\\ldots,t_v\\}$ and $\\{1_w,\\ldots,t_w\\}$. An $\\textbf{M}$-coloring $\\varphi$ picks for each vertex $v$ a color $\\varphi(v)$ (from the set $\\{1_v,\\ldots,t_v\\}$) such that for each edge $vw\\in E(G)$ the colors $\\varphi(v),\\varphi(w)$ are not matched to each other. Two $\\textbf{M}$-colorings $\\varphi_1,\\varphi_2$ of $G$ are called disjoint if $\\varphi_1(v)\\ne\\varphi_2(v)$ for all $v\\in V(G)$. For every $K_5$-minor-free graph $G$ and every correspondence 6-cover $\\textbf{M}$ of $G$, we construct 3 pairwise disjoint $\\textbf{M}$-colorings $\\varphi_1,\\varphi_2,\\varphi_3$. In contrast, we provide examples of $K_5$-minor-free graphs and correspondence 5-covers $\\textbf{M}$ that do not admit 3 disjoint $\\textbf{M}$-colorings.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16692v1",
        "authors": [
          "Wouter Cames van Batenburg",
          "Daniel W. Cranston",
          "František Kardoš"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Disjoint Correspondence Colorings",
        "Graphs Thomassen",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.063958"
    },
    {
      "id": "arxiv-2602.16691v1",
      "title": "Two-mode dominance and deterministic parameter bias bounds for equatorial Kerr-de Sitter ringdown",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16691v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study scalar waves on subextremal Kerr-de Sitter spacetimes in a compact slow-rotation regime and at a fixed overtone index. Working initially at a fixed cosmological constant $Λ>0$ and uniformly for $(M,a)$ in a compact slow-rotation set, using the meromorphic/Fredholm framework for quasinormal modes and a semiclassical equatorial labeling proved in a companion paper, we establish a quantitative two-mode dominance theorem in an equatorial high-frequency package: after exact azimuthal reduction, microlocal equatorial localization, and analytic pole selection by entire localization weights constructed from equatorial pseudopoles, the $k=\\pm\\ell$ sector signals are each governed by a single quasinormal exponential, up to an explicitly controlled tail and an $\\mathcal O(\\ell^{-\\infty})$ contribution from all other poles. We then develop a fully deterministic frequency-extraction stability estimate based on time-shift invariance, and combine it with the two-mode dominance result and the companion paper's inverse stability theorem to obtain an explicit parameter bias bound for ringdown-based recovery of $(M,a)$. Finally, using the companion paper's three-parameter inverse theorem and a damping observable based on the scaled imaginary part of one equatorial mode, we propagate the same deterministic error chain to a local bias bound for recovery of $(M,a,Λ)$ on compact parameter sets with $|a|$ bounded away from $0$. As a further consequence, we obtain a localized pseudospectral stability statement for the equatorial resolvent package, quantifying how large microlocalized resolvent norms enforce proximity to the labeled equatorial poles. The resulting estimates clarify the conditioning mechanisms (start time, window length, shift step, and detector nondegeneracy) and provide a rigorous PDE-to-data interface for high-frequency black-hole spectroscopy.",
        "keywords": [
          "math-ph",
          "gr-qc",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16691v1",
        "authors": [
          "Ruiliang Li"
        ],
        "arxiv_categories": [
          "math-ph",
          "gr-qc",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Wind",
        "NIST",
        "Act",
        "PDE",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.065226"
    },
    {
      "id": "arxiv-2602.16667v1",
      "title": "Cantor sets in higher dimensions II: Optimal dimension constraint for stable intersections",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16667v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "It is well known that a pair of compact sets in $\\mathbb{R}^d$ ($d \\in \\mathbb{N}$) can be separated by small deformations if the sum of their Hausdorff dimensions is less than $d$. In this paper, we demonstrate that this dimension constraint is optimal for regular Cantor sets. Specifically, for any prescribed Hausdorff dimensions whose sum is greater than $d$, we construct classes of pairs of regular Cantor sets that exhibit $C^{1+α}$-stable intersections. Our method is geometrically flexible, enabling the construction of examples with arbitrarily small thickness in both projectively hyperbolic and nearly conformal regimes. These results also extend to the complex setting for holomorphic Cantor sets in $\\mathbb{C}^d$. The proof relies on the ``covering criterion\" for stable intersection introduced in the first part of this series \\cite{NZ1}, which generalizes the ``recurrent compact set criterion\" of Moreira-Yoccoz to higher dimensions.",
        "keywords": [
          "math.DS",
          "math.CA",
          "math.MG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16667v1",
        "authors": [
          "Meysam Nassiri",
          "Mojtaba Zareh Bidaki"
        ],
        "arxiv_categories": [
          "math.DS",
          "math.CA",
          "math.MG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "Act",
        "WHO",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.066019"
    },
    {
      "id": "arxiv-2602.16644v1",
      "title": "Hierarchical paraproducts",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16644v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We outline an extension of paraproduct decompositions for compositions of the form $A(f)$ where $A \\in C^{d}(\\mathbb{R}), f \\in Λ_α([0,1]^d)$ developed in [arXiv:2503.12629] and [arXiv:2508.13322] to settings where $(A \\in C^1(\\mathbb{R}),f \\in Λ_α(X))$ and $ (A \\in C^2(\\mathbb{R}),f \\in Λ_α(X \\times Y))$. To do so, we construct partition trees on $X$ and $X \\times Y$ such that analysis with respect to scale is sensible. We obtain results resembling those of [arXiv:2503.12629] and [arXiv:2508.13322], but with the finite sets $X$ and $X \\times Y $ as support. In particular we construct the paraproduct $Π_{A',A''}^{L,S}: f \\to \\tilde{A}_{L,S}(f) + Δ_{L,S}(A,f)$ such that $Δ_{L,S}(A,f) \\in Λ_{2α}(X \\times Y)$ and $\\lVert Δ_{L,S}(A,f) \\rVert_{Λ_{2α}(X \\times Y)} \\leq C_A \\lVert f \\rVert_{Λ_α(X \\times Y)}$. Analogous results are obtained when the support is just one finite set, $X$. This extension is motivated by situations where one wishes to separate the singular and smooth components of such compositions in graph signal processing environments.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16644v1",
        "authors": [
          "Oluwadamilola Fasina"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.066717"
    },
    {
      "id": "arxiv-2602.16630v1",
      "title": "Symmetry properties for positive solutions of mixed boundary value problems in a sub-spherical sector",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16630v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, we investigate the symmetry properties of positive solutions $u$ to a semilinear elliptic equation under mixed Dirichlet-Neumann boundary conditions in symmetric domains. First, we establish a maximum principle tailored to mixed-boundary problems in domains of either small volume or narrow width, thereby enabling the application of the moving plane method. Secondly, in contrast to the purely Dirichlet case, a key challenge is to establish the non-vanishing of the tangential derivative of $u$ along the Neumann boundary. To address this, we employ local analysis techniques of angular derivatives, as introduced by Hartman and Wintner [Amer. J. Math., 1953]. Thirdly, we identify the signs of directional derivatives of $u$ along sections of the moving line. Using a planar sub-spherical sector as an example, we illustrate how these new innovative techniques and the moving plane method can be combined to derive symmetry and monotonicity results, particularly when the amplitude is less than or equal to $2π/3$.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16630v1",
        "authors": [
          "Ruofei Yao"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.067129"
    },
    {
      "id": "arxiv-2602.16625v1",
      "title": "Comparability of random permutations in the strong Bruhat order",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16625v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The (strong) Bruhat order for permutations provides a partial ordering defined as follows: two permutations are comparable if one can be obtained from the other by a sequence of adjacent transpositions that each increase the number of inversions by $1$. Given two random permutations, what is the probability that they are comparable in the Bruhat order? This problem was first considered in a 2006 work of Hammett and Pittel, which showed an exponential lower bound and a polynomial upper bound. The lower bound was very recently improved to the subexponential bound of $\\exp(-n^{1/2 + o(1)})$ by Boretsky, Cornejo, Hodges, Horn, Lesnevich, and McAllister. Hammett and Pittel predicted that the probability should decrease polynomially. We show that the probability decreases faster than any polynomial and is on the order of $\\exp(-Θ(\\log^2 n))$.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16625v1",
        "authors": [
          "Nicholas Christo",
          "Marcus Michelen"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.067443"
    },
    {
      "id": "arxiv-2602.16615v1",
      "title": "A Rough Functional Breuer-Major Theorem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16615v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We extend the functional Breuer-Major theorem by Nourdin and Nualart (2020) to the space of rough paths. The proof of tightness combines the multiplication formula for iterated Malliavin divergences, due to Furlan and Gubinelli (2019), with Meyer's inequality and a Kolmogorov-type criterion for the r-variation of cadlag rough paths, due to Chevyrev et al. (2022). Since martingale techniques do not apply, we obtain the convergence of the finite-dimensional distributions through a bespoke version of Slutsky's lemma: First, we overcome the lack of hypercontractivity by an iterated integration-by-parts scheme which reduces the remaining analysis to finite Wiener chaos; crucially, this argument relies on Malliavin differentiability of the nonlinearity but not on chaos decay and, as a consequence, encompasses the centred absolute value function. Second, in the spirit of the law of large numbers, we show that the diagonal of the second-order process converges to an explicit symmetric correction term. Finally, we compute all the moments of the remaining process and, through a fine combinatorial analysis, show that they converge to those of the Stratonovich Brownian rough path perturbed by an antisymmetric area correction, as computed by a suitable amendment of Fawcett's theorem. All of these steps benefit from a major combinatorial reduction that is implied by the original argument of Breuer and Major (1983).",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16615v1",
        "authors": [
          "Henri Elad Altman",
          "Tom Klose",
          "Nicolas Perkowski"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rough Functional Breuer",
        "Stratonovich Brownian",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.067659"
    },
    {
      "id": "arxiv-2602.16606v1",
      "title": "On Sharpened Convergence Rate of Generalized Sliced Inverse Regression for Nonlinear Sufficient Dimension Reduction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16606v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Generalized Sliced Inverse Regression (GSIR) is one of the most important methods for nonlinear sufficient dimension reduction. As shown in Li and Song (2017), it enjoys a convergence rate that is independent of the dimension of the predictor, thus avoiding the curse of dimensionality. In this paper we establish an improved convergence rate of GSIR under additional mild eigenvalue decay rate and smoothness conditions. Our convergence rate can be made arbitrarily close to $n^{-1/3}$ under appropriate decay rate and smoothness parameters. As a comparison, the rate of Li and Song (2017) is $n^{-1/4}$ under the best conditions. This improvement is significant because, for example, in a semiparametric estimation problem involving an infinite-dimensional nuisance parameter, the convergence rate of the estimator of the nuisance parameter is often required to be faster than $n^{-1/4}$ to guarantee desired semiparametric properties such as asymptotic efficiency. This can be achieved by the improved convergence rate, but not by the original rate. The sharpened convergence rate can also be established for GSIR in more general settings, such as functional sufficient dimension reduction.",
        "keywords": [
          "math.ST",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16606v1",
        "authors": [
          "Chak Fung Choi",
          "Yin Tang",
          "Bing Li"
        ],
        "arxiv_categories": [
          "math.ST",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlinear Sufficient Dimension Reduction",
        "Generalized Sliced Inverse Regression",
        "On Sharpened Convergence Rate",
        "GSIR",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.067854"
    },
    {
      "id": "arxiv-2602.16604v1",
      "title": "ERGMs on block models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16604v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We extend the classical edge-triangle Exponential Random Graph Model (ERGM) to an inhomogeneous setting in which vertices carry types determined by an underlying partition. This leads to a block-structured ERGM where interaction parameters depend on vertex types. We establish a large deviation principle for the associated sequence of measures and derive the corresponding variational formula for the limiting free energy. In the ferromagnetic regime, where the parameters governing triangle densities are nonnegative, we reduce the variational problem to a scalar optimization problem, thereby identifying the natural block counterpart of the replica symmetric regime. Under additional restrictions on the parameters, comparable to the classical Dobrushin's uniqueness region, we prove uniqueness of the maximizer and derive a law of large numbers for the edge density.",
        "keywords": [
          "math.PR",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16604v1",
        "authors": [
          "Elena Magnanini"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Exponential Random Graph Model",
        "ERGM",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.068033"
    },
    {
      "id": "arxiv-2602.16595v1",
      "title": "Anticoncentration of Random Sums in $\\mathbb{Z}_p$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16595v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper we investigate the probability distribution of the sum $Y$ of $\\ell$ independent identically distributed random variables taking values in $\\mathbb{Z}_p$. Our main focus is the regime of small values of $\\ell$, which is less explored compared to the asymptotic case $\\ell \\to \\infty$. Starting with the case $\\ell=3$, we prove that if the distributions of the $Y_i$ are uniformly bounded by $λ< 1$ and $p > 2/λ$, then there exists a constant $C_{3,λ} < 1$ such that \\[ \\max_{x \\in \\mathbb{Z}_p} \\mathbb{P}[Y = x] \\leq C_{3,λ}λ. \\] Moreover, when the distributions are uniformly separated from $1$, the constant $C_{3,λ}$ can be made explicit. By iterating this argument, we obtain effective anticoncentration bounds for larger values of $\\ell$, yielding nontrivial estimates already in small and moderate regimes where asymptotic results do not apply.",
        "keywords": [
          "math.PR",
          "math.CO",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16595v1",
        "authors": [
          "Simone Costa"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.CO",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Random Sums",
        "EPA",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.068363"
    },
    {
      "id": "arxiv-2602.16592v1",
      "title": "Hybrid Optimization Techniques for Multi-State Optimal Design Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16592v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper addresses optimal design problems governed by multi-state stationary diffusion equations, aiming at the simultaneous optimization of the domain shape and the distribution of two isotropic materials in prescribed proportions. Existence of generalized solutions is established via a hybrid approach combining homogenization-based relaxation in the interior with suitable restrictions on admissible domains. Based on this framework, we propose a numerical method that integrates homogenization and shape optimization. The domain boundary is evolved using a level set method driven by the shape derivative, while the interior material distribution is updated via an optimality criteria algorithm. The approach is demonstrated on a representative example.",
        "keywords": [
          "math.OC",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16592v1",
        "authors": [
          "Marko Erceg",
          "Petar Kunštek",
          "Marko Vrdoljak"
        ],
        "arxiv_categories": [
          "math.OC",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Hybrid Optimization Techniques",
        "State Optimal Design Problems",
        "Framework",
        "Fusion",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.068491"
    },
    {
      "id": "arxiv-2602.16591v1",
      "title": "Fast Ewald Summation using Prolate Spheroidal Wave Functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16591v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Fast Ewald summation efficiently evaluates Coulomb interactions and is widely used in molecular dynamics simulations. It is based on a split into a short-range and a long-range part, where evaluation of the latter is accelerated using the fast Fourier transform (FFT). The accuracy and computational cost depend critically on the mollifier in the Ewald split and the window function used in the spreading and interpolation steps that enable the use of the FFT. The first prolate spheroidal wavefunction (PSWF) has optimal concentration in real and Fourier space simultaneously, and is used when defining both a mollifier and a window function. We provide a complete description of the method and derive rigorous error estimates. In addition, we obtain closed-form approximations of the Fourier truncation and aliasing errors, yielding explicit parameter choices for the achieved error to closely match the prescribed tolerance. Numerical experiments confirm the analysis: PSWF-based Ewald summation achieves a given accuracy with significantly fewer Fourier modes and smaller window supports than Gaussian- and B-spline-based approaches, providing a superior alternative to existing Ewald methods for particle simulations.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16591v1",
        "authors": [
          "Erik Boström",
          "Anna-Karin Tornberg",
          "Ludvig af Klinteberg"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Prolate Spheroidal Wave Functions",
        "Fast Ewald Summation",
        "Fast Ewald",
        "Wind",
        "PSWF",
        "NSF",
        "Act",
        "FFT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.068673"
    },
    {
      "id": "arxiv-2602.16588v1",
      "title": "Discrete reliability for high-order Crouzeix--Raviart finite elements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16588v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, the adaptive numerical solution of a 2D Poisson model problem by Crouzeix-Raviart elements ($\\operatorname*{CR}_{k}$ $\\operatorname*{FEM}$) of arbitrary odd degree $k\\geq1$ is investigated. The analysis is based on an established, abstract theoretical framework: the \\textit{axioms of adaptivity} imply optimal convergence rates for the adaptive algorithm induced by a residual-type a posteriori error estimator. Here, we introduce the error estimator for the $\\operatorname*{CR}_{k}$ $\\operatorname*{FEM}$ discretization and our main theoretical result is the proof ot Axiom 3: \\textit{discrete reliability}. This generalizes results for adaptive lowest order $\\operatorname*{CR}_{1}$ $\\operatorname*{FEM}$ in the literature. For this analysis, we introduce and analyze new local quasi-interpolation operators for $\\operatorname*{CR}_{k}$ $\\operatorname*{FEM}$ which are key for our proof of discrete reliability. We present the results of numerical experiments for the adaptive version of $\\operatorname*{CR}_{k}$ $\\operatorname*{FEM}$ for some low and higher (odd) degrees $k\\geq1$ which illustrate the optimal convergence rates for all considered values of $k$.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16588v1",
        "authors": [
          "Nis-Erik Bohne",
          "Stefan A. Sauter"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "FEM",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.068852"
    },
    {
      "id": "arxiv-2602.16586v1",
      "title": "Nonparametric Kernel Regression for Coordinated Energy Storage Peak Shaving with Stacked Services",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16586v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Developing effective control strategies for behind-the-meter energy storage to coordinate peak shaving and stacked services is essential for reducing electricity costs and extending battery lifetime in commercial buildings. This work proposes an end-to-end, two-stage framework for coordinating peak shaving and energy arbitrage with a theoretical decomposition guarantee. In the first stage, a non-parametric kernel regression model constructs state-of-charge trajectory bounds from historical data that satisfy peak-shaving requirements. The second stage utilizes the remaining capacity for energy arbitrage via a transfer learning method. Case studies using New York City commercial building demand data show that our method achieves a 1.3 times improvement in performance over the state-of-the-art forecast-based method, achieving cost savings and effective peak management without relying on predictions.",
        "keywords": [
          "math.OC",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16586v1",
        "authors": [
          "Emily Logan",
          "Ning Qi",
          "Bolun Xu"
        ],
        "arxiv_categories": [
          "math.OC",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Coordinated Energy Storage Peak",
        "Nonparametric Kernel Regression",
        "Stacked Services Developing",
        "New York City",
        "Framework",
        "Battery",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.069134"
    },
    {
      "id": "arxiv-2602.16581v1",
      "title": "Whittle-Matérn Fields with Variable Smoothness",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16581v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce and analyze a nonlocal generalization of Whittle--Matérn Gaussian fields in which the smoothness parameter varies in space through the fractional order, $s=s(x)\\in[\\underline{s}\\,,\\bar{s}]\\subset(0,1)$. The model is defined via an integral-form operator whose kernel is constructed from the modified Bessel function of the second kind and whose local singularity is governed by the symmetric exponent $β(x,y)=(s(x)+s(y))/2$. This variable-order nonlocal formulation departs from the classical constant-order pseudodifferential setting and raises new analytic and numerical challenges. We develop a novel variational framework adapted to the kernel, prove existence and uniqueness of weak solutions on truncated bounded domains, and derive Sobolev regularity of the Gaussian (spectral) solution controlled by the minimal local order: realizations lie in $H^r(G)$ for every $r<2\\underline{s}-\\tfrac{d}{2}$ (here $H^r(G)$ denotes the Sobolev space on the bounded domain $G$), hence in $L_2(G)$ when $\\underline s>d/4$. We also present a finite-element sampling method for the integral model, derive error estimates, and provide numerical experiments in one dimension that illustrate the impact of spatially varying smoothness on samples covariances. Computational aspects and directions for scalable implementations are discussed.",
        "keywords": [
          "math.NA",
          "stat.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16581v1",
        "authors": [
          "Hamza Ruzayqat",
          "Wenyu Lei",
          "David Bolin",
          "George Turkiyyah",
          "Omar Knio"
        ],
        "arxiv_categories": [
          "math.NA",
          "stat.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variable Smoothness We",
        "Framework",
        "EPA",
        "DOD",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.069685"
    },
    {
      "id": "arxiv-2602.16574v1",
      "title": "Optimal bounds for numerical approximations of finite horizon problems based on dynamic programming approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16574v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper we provide optimal bounds for fully discrete approximations to finite horizon problems via dynamic programming. We adapt the error analysis in \\cite{nos} for the infinite horizon case to the finite horizon case. We prove an a priori bound of size $O(h+k)$ for the method, $h$ being the time discretization step and $k$ the spatial mesh size. Arguing with piecewise constants controls we are able to obtain first order of convergence in time and space under standard regularity assumptions, avoiding the more restrictive regularity assumptions on the controls required in \\cite{nos}. We show that the loss in the rate of convergence in time of the infinite case (obtained arguing with piece-wise controls) can be avoided in the finite horizon case",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16574v1",
        "authors": [
          "Javier de Frutos",
          "Julia Novo"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.069867"
    },
    {
      "id": "arxiv-2602.16556v1",
      "title": "A New Lower Bound for the Diagonal Poset Ramsey Numbers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16556v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Given two finite posets $\\mathcal P$ and $\\mathcal Q$, their Ramsey number, denoted by $R(\\mathcal P,\\mathcal Q)$, is defined to be the smallest integer $N$ such that any blue/red colouring of the vertices of the hypercube $Q_N$ has either a blue induced copy of $\\mathcal P$, or a red induced copy of $\\mathcal Q$. Axenovich and Walzer showed that, for fixed $\\mathcal P$, $R(\\mathcal P, Q_n)$ grows linearly with $n$. However, for the diagonal question, we do not even come close to knowing the order of growth of $R(Q_n,Q_n)$. The current upper bound is $R(Q_n,Q_n)\\leq n^2-(1-o(1))n\\log n$, due to Axenovich and Winter. What about lower bounds? It is trivial to see that $2n\\leq R(Q_n,Q_n)$, but surprisingly, even an incremental improvement required significant work. Recently, an elegant probabilistic argument of Winter gave that, for large enough $n$, $R(Q_n,Q_n)\\geq 2.02n$. In this paper we show that $R(Q_n,Q_n)\\geq 2.7n+k$, where $k$ is a constant. Our current techniques might in principle show that in fact, for every $ε>0$, for large enough $n$, $R(Q_n,Q_n)\\geq (3-ε)n$. Our methods exploit careful modifications of layered-colourings, for a large number of layers. These modifications are stronger than previous arguments as they are more constructive, rather than purely probabilistic.",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16556v1",
        "authors": [
          "Maria-Romina Ivan",
          "Bernardus Wessels"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Diagonal Poset Ramsey Numbers",
        "New Lower Bound",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.070348"
    },
    {
      "id": "arxiv-2602.16549v1",
      "title": "Well-posedness and stability of the self-similar profile for a thin-film equation with gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16549v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the thin-film equation with linear mobility and a stabilizing second-order porous-medium type term modeling gravity. The model admits self-similar solutions, and our goal is to analyze their stability. We reformulate the problem in mass-Lagrangian coordinates and exploit the underlying gradient-flow structure of the equation with respect to a weighted $L^2$ inner product, where the weight is given by the self-similar source-type profile. This framework allows us to establish a coercivity result for the Hessian (the linearization around the self-similar solution) in a suitably weighted inner product. As a consequence, we prove the convergence of perturbations toward the self-similar profile at an algebraic rate of order $t^{-\\frac 1 5}$, in arbitrary scales of weighted Sobolev norms. The analysis relies on maximal-regularity estimates for the linearized evolution, combined with appropriate estimates for the nonlinear terms. Notably, beyond perturbative regimes and in contrast to previous results for the thin-film equation (convergence to the Smyth-Hill profile) or the porous-medium equation (convergence to the Barenblatt-Pattle solution), our analysis does not rely on an explicit (algebraic) representation of the self-similar profile. Instead, it is based solely on a systematic use of the ordinary differential equation satisfied by the self-similar solution, together with a careful analysis of its boundary asymptotics. As a result, we expect that the approach developed here can serve as a flexible toolbox for the study of more general classes of equations and for the stability analysis of special solutions in future work.",
        "keywords": [
          "math.AP",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16549v1",
        "authors": [
          "Manuel V. Gnann",
          "Slim Ibrahim"
        ],
        "arxiv_categories": [
          "math.AP",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "MIT",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.070625"
    },
    {
      "id": "arxiv-2602.16547v1",
      "title": "A Lorentzian Equivariant Index Theorem",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16547v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We develop a formula for the equivariant index of a twisted Dirac operator on a compact globally hyperbolic spacetime with timelike boundary on which a group acts isometrically, subject to APS boundary conditions. The formula is the same as in the Riemannian case: the equivariant index for a group element is an integral over the fixed point set of that element plus some boundary terms. The proof uses a surprisingly simple technique for reducing from the equivariant to the non-equivariant regime in order to show an equivariant version of the Lorentzian \"index $=$ spectral flow\" formula.",
        "keywords": [
          "math.DG",
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16547v1",
        "authors": [
          "Onirban Islam",
          "Lennart Ronge"
        ],
        "arxiv_categories": [
          "math.DG",
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "APS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.070732"
    },
    {
      "id": "arxiv-2602.16544v1",
      "title": "The Quantum Symmetric Simple Exclusion Process in the Continuum and Free Processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16544v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The quantum symmetric simple exclusion process (QSSEP) is a recent extension of the symmetric simple exclusion process, designed to model quantum coherent fluctuating effects in noisy diffusive systems. It models stochastic nearest-neighbor fermionic hopping on a lattice, possibly driven out-of-equilibrium by boundary processes. We present a direct formulation in the continuum, and establish how this formulation captures the scaling limit of the discrete version. In the continuum, QSSEP emerges as a non-commutative process, driven by free increments, conditioned on the algebra of functions on the ambiant space to encode spatial correlations. We actually develop a more general framework dealing with conditioned orbits with free increments which may find applications beyond the present context. We view this construction as a preliminary step toward formulating a quantum extension of the macroscopic fluctuation theory.",
        "keywords": [
          "math-ph",
          "cond-mat.stat-mech",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16544v1",
        "authors": [
          "Denis Bernard"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.stat-mech",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Exclusion Process",
        "Framework",
        "QSSEP",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.070880"
    },
    {
      "id": "arxiv-2602.16540v1",
      "title": "Generalised Linear Models Driven by Latent Processes: Asymptotic Theory and Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16540v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper introduces a class of generalised linear models (GLMs) driven by latent processes for modelling count, real-valued, binary, and positive continuous time series. Extending earlier latent-process regression frameworks based on Poisson or one-parameter exponential family assumptions, we allow the conditional distribution of the response to belong to a bi-parameter exponential family, with the latent process entering the conditional mean multiplicatively. This formulation substantially broadens the scope of latent-process GLMs, for instance, it naturally accommodates gamma responses for positive continuous data, enables estimation of an unknown dispersion parameter via method of moments, and avoids restrictive conditions on link functions that arise under existing formulations. We establish the asymptotic normality of the GLM estimators obtained from the GLM likelihood that ignores the latent process, and we derive the correct information matrix for valid inference. In addition, we provide a principled approach to prediction and forecasting in GLMs driven by latent processes, a topic not previously addressed in the literature. We present two real data applications on measles infections in North Rhine-Westphalia (Germany) and paleoclimatic glacial varves, which highlight the practical advantages and enhanced flexibility of the proposed modelling framework.",
        "keywords": [
          "stat.ME",
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16540v1",
        "authors": [
          "Wagner Barreto-Souza",
          "Ngai Hang Chan"
        ],
        "arxiv_categories": [
          "stat.ME",
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalised Linear Models Driven",
        "Latent Processes",
        "North Rhine",
        "Framework",
        "Act",
        "GLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071082"
    },
    {
      "id": "arxiv-2602.16538v1",
      "title": "A higher order pressure-stabilized virtual element formulation for the Stokes-Poisson-Boltzmann equations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16538v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Electrokinetic phenomena in nanopore sensors and microfluidic devices require accurate simulation of coupled fluid-electrostatic interactions in geometrically complex domains with irregular boundaries and adaptive mesh refinement. We develop an equal-order virtual element method for the Stokes--Poisson--Boltzmann equations that naturally handles general polygonal meshes, including meshes with hanging nodes, without requiring special treatment or remeshing. The key innovation is a residual-based pressure stabilization scheme derived by reformulating the Laplacian drag force in the momentum equation as a weighted advection term involving the nonlinear Poisson--Boltzmann equation, thereby eliminating second-order derivative terms while maintaining theoretical rigor. Well-posedness of the coupled stabilized problem is established using the Banach and Brouwer fixed-point theorems under sufficiently small data assumptions, and optimal a priori error estimates are derived in the energy norm with convergence rates of order $\\mathcal{O}(h^k)$ for approximation degree $k \\geq 1$. Numerical experiments on diverse polygonal meshes -- including distorted elements, non-convex polygons, Voronoi tessellations, and configurations with hanging nodes -- confirm optimal convergence rates, validating theoretical predictions. Applications to electro-osmotic flows in nanopore sensors with complex obstacle geometries illustrate the method's practical utility for engineering simulations. Compared to Taylor--Hood finite element formulations, the equal-order approach simplifies implementation through uniform polynomial treatment of all fields and offers native support for general polygonal elements.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16538v1",
        "authors": [
          "Sudheer Mishra",
          "Sundararajan Natarajan",
          "E. Natarajan",
          "Gianmarco Manzini"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071331"
    },
    {
      "id": "arxiv-2602.16524v1",
      "title": "Nonlinear Schrödinger equations with a critical, inverse-square potential",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16524v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the existence of solutions of the following nonlinear Schrödinger equation $$ -Δu+V(x)u-\\frac{(N-2)^2}{4|x|^2}u=f(x,u) $$ where $V:\\mathbb{R}^N\\to\\mathbb{R}$ and $f:\\mathbb{R}^N\\times \\mathbb{R}\\to \\mathbb{R}$ are periodic with respect to $x\\in\\mathbb{R}^N.$ We assume that $V$ has positive essential infimum, $f$ satisfies weak growth conditions and $N\\geq 3$. The approach to the problem uses variational methods with nonstandard functional setting. We obtain the existence of the ground state solution using the new profile decomposition.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16524v1",
        "authors": [
          "Bartosz Bieganowski",
          "Adam Konysz",
          "Simone Secchi"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "N-2",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071577"
    },
    {
      "id": "arxiv-2602.16521v1",
      "title": "Scaling limits for some Mittag-Leffler queues",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16521v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, we consider five models of heavy-tailed queues involving Mittag-Leffler distributions that generalize the classical $M/M/1$ queues. These models are suitable modifications of previously defined models in such a way that the classical $M/M/1$ queue can be recovered by a suitable selection of parameters. We provide the distribution of inter-arrival and service times of both the original and modified queueing models. We then study the scaling limits of all the proposed models and we argue that the behaviour of the limiting processes can be used to characterise the traffic regime of the queues.",
        "keywords": [
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16521v1",
        "authors": [
          "Giacomo Ascione",
          "Luigia Caputo"
        ],
        "arxiv_categories": [
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071682"
    },
    {
      "id": "arxiv-2602.16517v1",
      "title": "PL conditions do not guarantee convergence of gradient descent-ascent dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16517v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We give an example of a function satisfying a two-sided Polyak-Lojasiewicz condition but for which a gradient descent-ascent flow line fails to converge to the saddle point, circling around it instead.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16517v1",
        "authors": [
          "Jean-Christophe Mourrat"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071739"
    },
    {
      "id": "arxiv-2602.16509v1",
      "title": "Entrance laws for coalescing and annihilating Brownian motions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16509v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Systems of instantaneously annihilating or coalescing Brownian motions on the line are considered. The extreme points of the set of entrance laws for this process are shown to be Pfaffian point processes at all times and their kernels are identified.",
        "keywords": [
          "math.PR",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16509v1",
        "authors": [
          "Roger Tribe",
          "Oleg Zaboronski"
        ],
        "arxiv_categories": [
          "math.PR",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071802"
    },
    {
      "id": "arxiv-2602.16508v1",
      "title": "A Fully Discrete Nonnegativity-Preserving FEM for a Stochastic Heat Equation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16508v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider a stochastic heat equation with nonlinear multiplicative finite-dimensional noise that admits a unique nonnegative solution when given nonnegative initial data. Inspired by existing results for fully discrete finite difference schemes and building on the convergence analysis of semi-discrete mass-lumped finite element approximations, a fully discrete numerical method is introduced that combines mass-lumped finite elements with a Lie-Trotter splitting strategy. This discretization preserves nonnegativity at the discrete level and is shown to be convergent under suitable regularity conditions. A rigorous convergence analysis is provided, highlighting the role of mass lumping in ensuring nonnegativity and of operator splitting in decoupling the deterministic and stochastic dynamics. Numerical experiments are presented to confirm the convergence rates and the preservation of nonnegativity. In addition, we examine several numerical examples outside the scope of the established theory, aiming to explore the range of applicability and potential limitations of the proposed method.",
        "keywords": [
          "math.NA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16508v1",
        "authors": [
          "Owen Hearder",
          "Claude Le Bris",
          "Ana Djurdjevac"
        ],
        "arxiv_categories": [
          "math.NA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fully Discrete Nonnegativity",
        "Stochastic Heat Equation We",
        "NIST",
        "FEM",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.071969"
    },
    {
      "id": "arxiv-2602.16506v1",
      "title": "Fully sign-changing Nehari constraint vs sign-changing solutions of a competitive Schrödinger system",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16506v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study a competitive nonlinear Schrödinger system in $\\mathbb{R}^N$ whose nonlinear potential is localized in small regions that shrink to isolated points. Within a variational framework based on a fully sign-changing Nehari constraint and Krasnosel'skii genus, we construct, for all $\\varepsilon>0$, a sequence of sign-changing solutions with increasing and unbounded energies, and after suitable translations they converge to a sequence of sign-changing solutions of the associated limiting system as $\\varepsilon\\to 0$ in $H^1$-norm. Moreover, these sign-changing solutions concentrate around the prescribed attraction points both in $H^1$-norm and $L^q$-norm for $q\\in [1,\\infty]$.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16506v1",
        "authors": [
          "Xuejiao Fu",
          "Fukun Zhao"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.072196"
    },
    {
      "id": "arxiv-2602.16482v1",
      "title": "Remarks on the inverse Littlewood conjecture",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16482v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Littlewood conjecture, proven by Konyagin and McGehee-Pigno-Smith in the 1980s, states that if $A\\subset \\mathbb{Z}$ is a finite set of integers with $\\lvert A\\rvert=N$ then $\\| \\widehat{1_A}\\|_1\\geq c\\log N$ for some absolute constant $c > 0$. We explore what structure $A$ must have if $\\| \\widehat{1_A}\\|_1\\leq K\\log N$ for some constant $K$. Under such an assumption we prove, for instance, that $A$ contains a subset $A'\\subseteq A$ with $\\lvert A\\rvert \\geq N^{0.99}$ such that $\\lvert A'+A'\\rvert \\ll K^{O(1)}\\lvert A'\\rvert$. As a consequence, for any $k\\geq 3$, if $N$ is sufficiently large depending on $k$ and $K$, then $A$ must contain an arithmetic progression of length $k$. A byproduct of our analysis is a (slightly) improved bound for the constant $c$.",
        "keywords": [
          "math.NT",
          "math.CA",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16482v1",
        "authors": [
          "Thomas F. Bloom",
          "Ben Green"
        ],
        "arxiv_categories": [
          "math.NT",
          "math.CA",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.072322"
    },
    {
      "id": "arxiv-2602.16479v1",
      "title": "Central limit theorem for random walk in degenerate divergence-free random environment: $\\mathcal H_{-1}$ reloaded with relaxed ellipticity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16479v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper enhances the result of the work [G. Kozma, B. Tóth, Ann. Probab. vol. 45 (2017) 4307-4347] . We prove the central limit theorem (in probability w.r.t. the environment) for the displacement of a random walker in divergence-free (or, doubly stochastic) random environment, with substantially relaxed ellipticity assumptions. Integrability of the reciprocal of the symmetric part of the jump rates is only assumed (rather than their boundedness, as in previous works on this type of RWRE). Relaxing ellipticity involves substantial changes in the proof, making it conceptually elementary in the sense that it does not rely on Nash's inequality in any disguise.",
        "keywords": [
          "math.PR",
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16479v1",
        "authors": [
          "Bálint Tóth"
        ],
        "arxiv_categories": [
          "math.PR",
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "RWRE",
        "DOE",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.072554"
    },
    {
      "id": "arxiv-2602.16478v1",
      "title": "Regularity and Pathwise bounds for probabilistic solutions of PDEs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16478v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, we build a procedure that allows to establish regularity and controls in time for probabilistic solutions to PDEs. Probabilistic approaches to global wellposedness problems usually provide ensemble bounds on the solutions. These bounds are the main tools to ensure convergence procedures yielding the existence and uniqueness of global solutions. A question of interest consists in transforming such ensemble bounds into individual controls on the flow ; this, among other uses, gives valuable information on the long-time behavior of the solutions. Toward such question of bounds transformation, Bourgain initiated a successful procedure that exploited the local wellposedness of the PDE, with an estimate of the time of size-doubling. In this note, we construct an estimation procedure which relies on a different local requirement. It turns out that this substitute is flexible enough to be possible to fulfill with the help of the ensemble bound itself. For applications of the procedure, we are able to provide new pathwise controls on solutions to NLS equations.",
        "keywords": [
          "math.AP",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16478v1",
        "authors": [
          "Mouhamadou Sy"
        ],
        "arxiv_categories": [
          "math.AP",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSF",
        "PDE",
        "NLS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.072714"
    },
    {
      "id": "arxiv-2602.16466v1",
      "title": "Estimation of Conformal Metrics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16466v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study deformations of the geodesic distances on a domain of R N induced by a function called conformal factor. We show that under a positive reach assumption on the domain (not necessarily a submanifold) and mild assumptions on the conformal factor, geodesics for the conformal metric have good regularity properties in the form of a lower bounded reach. This regularity allows for efficient estimation of the conformal metric from a random point cloud with a relative error proportional to the Hausdorff distance between the point cloud and the original domain. We then establish convergence rates of order n^(-1/d) that are close to sharp when the intrinsic dimension d of the domain is large, for an estimator that can be computed in O(n^2 ) time. Finally, this paper includes a useful equivalence result between ball graphs and nearest-neighbors graphs when assuming Ahlfors regularity of the sampling measure, allowing to transpose results from one setting to another.",
        "keywords": [
          "math.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16466v1",
        "authors": [
          "Jérôme Taupin"
        ],
        "arxiv_categories": [
          "math.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Conformal Metrics We",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.072858"
    },
    {
      "id": "arxiv-2602.16460v1",
      "title": "On the uniqueness and structural stability of Couette-Poiseuille flow in a channel for arbitrary values of the flux",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16460v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We establish uniqueness and structural stability of a class of parallel flows in a 2D straight, infinite channel, under perturbations with either globally or locally bounded Dirichlet integrals. The significant feature of our result is that it does not require any restriction on the size of the flux characterizing the flow. Precisely, by extending and refining an approach initially introduced by J.B. McLeod, we demonstrate the continuous invertibility of the linearized operator at a generic Couette-Poiseuille solution that does not exhibit flow reversal. We then deduce local uniqueness of these solutions as well as their nonlinear structural stability under small external forces. Moreover, we prove the uniqueness of certain class of Couette-Poiseuille solutions ``in the large,\" within the set of solutions possessing natural symmetry. Finally, we bring an example showing that, in general, if the flow reversal assumption is violated, the linearized operator is no longer invertible.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16460v1",
        "authors": [
          "Giovanni P. Galdi",
          "Filippo Gazzola",
          "Mikhail V. Korobkov",
          "Xiao Ren",
          "Gianmarco Sperone"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "DOE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073039"
    },
    {
      "id": "arxiv-2602.16440v1",
      "title": "Linear Landau equation as a limit of a tagged particle in mean field interaction with a free gas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16440v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider a tagged particle in mean field interaction with a free gas of density N at equilibrium. In dimensions $d\\geq4$, we prove the convergence of its trajectory, as N goes to infinity, to the one of a diffusion process associated with the linear Landau equation. The proof of the convergence of the martingale problem relies on two key ingredients: long time stability results of the microscopic dynamics, and controls on the probability of particle recollisions.",
        "keywords": [
          "math.PR",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16440v1",
        "authors": [
          "Thierry Bodineau",
          "Pierre Le Bris"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Linear Landau",
        "Fusion",
        "Act",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073134"
    },
    {
      "id": "arxiv-2602.16439v1",
      "title": "Multiscale Hyperbolic-Parabolic Models for Nonlinear Reactive Transport in Heterogeneously Fractured Porous Media",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16439v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study nonlinear reactive transport in a layered porous medium separated by an $\\varepsilon$-thin, highly heterogeneous fracture whose aperture and obstacle pattern vary periodically. Species transport in the bulk is governed by parabolic reaction--diffusion equations, coupled to a convection-diffusion-reaction problem in the fracture with nonlinear wall and obstacle reactions and Peclet number of order $O(\\varepsilon^{-1})$. Via multiscale analysis as $\\varepsilon \\to 0$, when the fracture collapses to a flat interface, we derive a new type of homogenized model consisting of bulk diffusion--reaction equations coupled through nonlinear interface conditions and a first-order semilinear hyperbolic system on the interface. We prove well-posedness and regularity of the limit system, construct a multiscale approximation with boundary-layer correctors, and derive quantitative error estimates in suitable energy norms.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16439v1",
        "authors": [
          "Taras Mel'nyk",
          "Sorin Pop",
          "Christian Rohde"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Heterogeneously Fractured Porous Media",
        "Nonlinear Reactive Transport",
        "Multiscale Hyperbolic",
        "Parabolic Models",
        "Fusion",
        "EPA",
        "Act",
        "MIT",
        "WHO",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073281"
    },
    {
      "id": "arxiv-2602.16414v1",
      "title": "Positive Charts of Toric Varieties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16414v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We construct affine charts of a smooth projective toric variety which contain its nonnegative points, and which admit a closed embedding into the total coordinate space of Cox's quotient construction. We show that such positive charts arise from smooth subcones of the nef cone. To each positive chart we associate an algebraic moment map, the fibers of which are the critical points of a monomial function in Cox coordinates. This work provides a toric framework for the theory of $u$-equations in positive geometry.",
        "keywords": [
          "math.AG",
          "hep-th",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16414v1",
        "authors": [
          "Veronica Calvo Cortes",
          "Simon Telen"
        ],
        "arxiv_categories": [
          "math.AG",
          "hep-th",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Toric Varieties We",
        "Positive Charts",
        "Framework",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073374"
    },
    {
      "id": "arxiv-2602.16407v1",
      "title": "A remark on staircase laminates in restricted sets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16407v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We slightly extend the convex integration via staircase laminate toolbox recently developed by Kleiner, Müller, Székelyhidi, and Xie. As an example we revisit the proof by Astala-Faraco-Székelyhidi on optimal Meyers' regularity theory via this framework.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16407v1",
        "authors": [
          "Igor Buchowiec",
          "Pholphum Kamthorntaksina",
          "Katarzyna Mazowiecka",
          "Armin Schikorra",
          "Akshara Vincent"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073480"
    },
    {
      "id": "arxiv-2602.16402v1",
      "title": "Primal-dual dynamical systems with closed-loop control for convex optimization in continuous and discrete time",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16402v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper develops a primal-dual dynamical system where the coefficients are designed in closed-loop way for solving a convex optimization problem with linear equality constraints. We first introduce a ``second-order primal\" + ``first-order dual'' continuous-time dynamical system, in which both the time scaling and Hessian-driven damping are governed by a feedback control of the gradient for the Lagrangian function. This system achieves the fast convergence rates for the primal-dual gap, the feasibility violation, and the objective residual along its trajectory. Subsequently, by time discretization of this system, we develop an accelerated primal-dual algorithm with a gradient-defined adaptive step size. We also obtain convergence rates for the primal-dual gap, the feasibility violation, and the objective residual. Furthermore, we provide numerical results to demonstrate the practical efficacy and superior performance of the proposed algorithm.",
        "keywords": [
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16402v1",
        "authors": [
          "Huan Zhang",
          "Xiangkai Sun",
          "Shengjie Li",
          "Kok Lay Teo"
        ],
        "arxiv_categories": [
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073632"
    },
    {
      "id": "arxiv-2602.16392v1",
      "title": "Partially observed controlled Markov chains and optimal control of the Wonham filter",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16392v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider a class of optimal control problems, with finite or infinite horizon, for a continuous-time Markov chain with finite state space. In this case, the control process affects the transition rates. We suppose that the controlled process can not be observed, and at any time the control actions are chosen based on the observation of a related stochastic process perturbed by an exogenous Brownian motion. We describe a construction of the controlled Markov chain, having stochastic transition rates adapted to the observation filtration. By a change of probability measure of Girsanov type, we introduce the so-called separated optimal control problem, where the state is the conditional (unnormalized) distribution of the controlled Markov chain and the observation process becomes a driving Brownian motion, and we prove the equivalence with the original control problem. The controlled equations for the separated problem are an instance of the Wonham filtering equations. Next we present an analysis of the separated problem: we characterize the value function as the unique viscosity solution to the dynamic programming equations (both in the parabolic and the elliptic case) we prove verifications theorems and a version of the stochastic maximum principle in the form of a necessary conditions for optimality.",
        "keywords": [
          "math.OC",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16392v1",
        "authors": [
          "Fulvia Confortola",
          "Marco Fuhrman"
        ],
        "arxiv_categories": [
          "math.OC",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073822"
    },
    {
      "id": "arxiv-2602.16366v1",
      "title": "Global Gevrey Hypoellipticity of Involutive Systems on Non-Compact Manifolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16366v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We investigate the global Gevrey hypoellipticity of a class of first-order differential operators associated with tube-type involutive structures on $M\\times\\mathbb{T}^m$, where $M$ is a non-compact manifold diffeomorphic to the interior of a compact manifold with boundary and $\\mathbb{T}^m$ is the $m$-dimensional torus. For $s>1$, we work in Gevrey classes of Roumieu and Beurling type. A key step is the construction, on $M$, of a scattering metric whose coefficients are Gevrey of order $s$ in every analytic chart; this allows us to use Hodge theory and obtain Gevrey regularity for the harmonic forms. Under a natural condition on the defining closed $1$-forms, we obtain a sharp criterion for global Gevrey hypoellipticity in terms of rationality and (Roumieu/Beurling) exponential Liouville behavior.",
        "keywords": [
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16366v1",
        "authors": [
          "Sandro Coriasco",
          "Alexandre Kirilov",
          "Wagner Augusto Almeida de Moraes",
          "Pedro Meyer Tokoro"
        ],
        "arxiv_categories": [
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Global Gevrey Hypoellipticity",
        "Compact Manifolds We",
        "Involutive Systems",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.073976"
    },
    {
      "id": "arxiv-2602.16361v1",
      "title": "On generating functions and automata associated to reflections in Coxeter systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16361v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this article, we study two combinatorial problems concerning the set of reflections of a Coxeter system. The first problem asks whether the language of palindromic reduced words for reflections is regular, and the second is about finding formulas for the Poincaré series of reflections, namely the generating function of reflection lengths. These two problems were inspired by a conjecture of Stembridge stating that the Poincaré series of reflections is rational and by the solution provided by de Man. To address the first problem, we introduce reflection-prefixes, arising naturally from palindromic reduced words. We study their connections with the root poset, dominance order on roots, and dihedral reflection subgroups. Using $m$-canonical automata associated with $m$-Shi arrangements, we prove that the language of reduced words for reflection-prefixes is regular. For the second problem, we focus on affine Coxeter groups. In this case, we derive a simple formula for the Poincaré series using symmetries of the Hasse diagram of the root poset.",
        "keywords": [
          "math.GR",
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16361v1",
        "authors": [
          "Riccardo Biagioli",
          "Christophe Hohlweg",
          "Elisa Sasso"
        ],
        "arxiv_categories": [
          "math.GR",
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.074307"
    },
    {
      "id": "arxiv-2602.16355v1",
      "title": "An assortment of problems in permutation patterns: unimodality, equivalence, derangements, and sorting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16355v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We collect open problems in permutation patterns on four themes: rank-unimodality in the permutation pattern poset, Wilf-equivalence and shape-Wilf-equivalence, the enumeration of derangements in permutation classes, and sorting by stacks in series, generalized stacks, and restricted containers (C-machines).",
        "keywords": [
          "math.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16355v1",
        "authors": [
          "Vincent Vatter"
        ],
        "arxiv_categories": [
          "math.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.074384"
    },
    {
      "id": "arxiv-2602.16354v1",
      "title": "Comet-type periodic motions and their out-of-plane bifurcations in the Earth-Moon CR3BP: a computational symplectic analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16354v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Comet-type periodic orbits of the circular restricted three-body problem (CR3BP) are periodic solutions that are generated from very large retrograde and direct circular Keplerian motions around the common center of mass of the primaries. In this paper we first provide an analytical proof of the existence of comet-type periodic orbits by using the classical Poincaré continuation method. Within this analytical approach, we also determine their Conley-Zehnder index, defined as a Maslov index using a crossing form. Then, by applying a standard corrector-predictor technique, we explore numerically the two families of comet orbits within the Earth-Moon CR3BP. We compute their stability indices, identify vertical self-resonant orbits up to multiplicity six, investigate the vertically bifurcated periodic solutions and discuss their orbital characteristics. Our main results we illustrate in form of bifurcation graphs, based on symplectic invariants, which provide a topological overview of the connections of the bifurcated branches, including bridge families.",
        "keywords": [
          "math.SG",
          "astro-ph.EP",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16354v1",
        "authors": [
          "Cengiz Aydin"
        ],
        "arxiv_categories": [
          "math.SG",
          "astro-ph.EP",
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:27.074712"
    },
    {
      "id": "arxiv-2602.16685v1",
      "title": "Generalized determinantal representation of hypersurfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16685v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this article we extend the notion of determinantal representation of hypersurfaces to the determinantal representation of sections of the determinant line bundle of a vector bundle. We give several examples, and prove some necessary conditions for existence of determinantal representation. As an application, we show that for any integer $d \\geq 1,$ there is an indecomposable vector bundle $E_d$ of rank $2$ on $\\mathbb{P}^2$ such that almost all curves of degree $d$ of $\\mathbb{P}^2$ arise as the degeneracy loci of a pair of holomorphic sections of $E_d$, upto an automorphism of $\\mathbb{P}^2$. We use this result to obtain a linear algebraic application.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16685v1",
        "authors": [
          "A. El Mazouni",
          "D. S. Nagaraj",
          "Supravat Sarkar"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.124434"
    },
    {
      "id": "arxiv-2602.16654v1",
      "title": "A.E. Convergence vs Boundedness",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16654v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We extend Stein's maximal theorem to the bilinear setting. Let $M$ be a homogeneous space with a transitive action of a compact abelian group, and let $1 \\le p,q \\le 2$ and $1/2 \\le r \\le 1$ satisfy $1/p + 1/q = 1/r$. For a family of translation-invariant bilinear operators \\[ T_m : L^p(M) \\times L^q(M) \\to L^r(M), \\qquad m \\in \\mathbb{N}, \\] that converge almost everywhere, we prove that the associated maximal operator \\[ T^*(f,g) = \\sup_m |T_m(f,g)| \\] is of weak type $L^p(M) \\times L^q(M) \\to L^{r,\\infty}(M)$. The proof relies on probabilistic methods and a bilinear extension of Stein's lemma for double Rademacher series. We also establish a bilinear analogue of Sawyer's extension of Stein's theorem for positive bilinear operators commuting with a mixing family of measure-preserving transformations. Applications include strong-type boundedness of maximal bilinear tail operators associated with ergodic transformations in the natural exponent range $r = (1/p + 1/q)^{-1}$ for $p,q > 1$, as well as almost everywhere convergence results for bilinear Bochner--Riesz means and other bilinear ergodic averages on the torus.",
        "keywords": [
          "math.CA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16654v1",
        "authors": [
          "Xinyu Gao",
          "Loukas Grafakos"
        ],
        "arxiv_categories": [
          "math.CA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Boundedness We",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.124831"
    },
    {
      "id": "arxiv-2602.16635v1",
      "title": "Existence of constant mean curvature surfaces with controlled topology in 3-manifolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16635v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We establish the existence of a non-trivial, branched immersion of a closed Riemann surface $Σ$ with constant mean curvature (CMC) $H$ into any closed, orientable 3-manifold $\\mathcal{M}$, for almost every prescribed value of $H$. The genus of the surface $Σ$ is bounded from above by the Heegaard genus $h$ of $\\mathcal{M}$. Starting from a family of sweep-outs of $\\mathcal{M}$ by surfaces of genus $h$, we apply a min-max construction for a family $\\{E_{H,σ}\\}_σ$ of perturbations of the energy involving the second fundamental form of the immersions to produce almost-critical points $u_k$ of $E_{H,σ}$. We then show, following ideas developed by Pigati and Rivière, that the maps $u_k$ converge to a \"CMC-parametrized varifold\". This limiting object is then shown to be a smooth, branched immersion with the prescribed mean curvature $H$.",
        "keywords": [
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16635v1",
        "authors": [
          "Filippo Gaia",
          "Xuanyu Li"
        ],
        "arxiv_categories": [
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "CMC",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.125151"
    },
    {
      "id": "arxiv-2602.16619v1",
      "title": "Macaulay Constants and Vanishing of Cohomology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16619v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Dubé introduced cone decompositions and their Macaulay constants and used them to obtain an upper bound on the degrees of the generators in a Gröbner basis of an ideal. Liang extended the theory to submodules of a free module. In this paper, Macaulay constants of any finitely generated graded module $M$ over a polynomial ring are introduced by adapting the concept of a cone decomposition to $M$. It is shown that these constants provide upper bounds for the degrees in which the local cohomology modules of $M$ are not zero. The results include an upper bound on the Castelnuovo-Mumford regularity of $M$ and a generalization of Gotzmann's Regularity Theorem from ideals to modules. As an application, an upper bound on the Castelnuovo-Mumford regularity of any coherent sheaf on projective space is established. The mentioned bounds are sharp even for cyclic modules. Furthermore, Macaulay constants are utilized to provide a characterization of Hilbert polynomials of finitely generated graded modules.",
        "keywords": [
          "math.AC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16619v1",
        "authors": [
          "Uwe Nagel"
        ],
        "arxiv_categories": [
          "math.AC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Macaulay Constants",
        "BERT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.125425"
    },
    {
      "id": "arxiv-2602.16599v1",
      "title": "Level structures on cyclic covers of $\\mathbb{P}^n$ and the homology of Fermat hypersurfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16599v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Let $Z'\\subset \\mathbb{P}^{n}$ be a smooth projective hypersurface of degree $d>1$ and let $Z\\to \\mathbb{P}^n$ be the $μ_d$-cover totally ramified along $Z'$. We relate full level $d$ structures on the primitive cohomology $Z'$ with full level $d$ structures on the primitive cohomology of $Z$. In the special case, $d=n=3$ this makes a marking of a smooth cubic surface determine a level $3$-structure on the associated cubic threefold, thereby answering a question by Beauville. We expect many more such applications.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16599v1",
        "authors": [
          "Eduard Looijenga"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.125686"
    },
    {
      "id": "arxiv-2602.16593v1",
      "title": "Convergent Twist Deformations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16593v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper establishes a functorial framework for convergence of Drinfeld's Universal Deformation Formula (UDF) on spaces of analytic vectors. This is accomplished by matching the order of the latter with an equicontinuity condition on the Drinfeld twist underlying the deformation. Throughout, we work with representations of finite-dimensional Lie algebras by continuous linear mappings on locally convex spaces. This allows us to establish not only convergence of the formal power series, but the continuity of the deformed bilinear mappings as well as the entire holomorphic dependence on the deformation parameter $\\hbar$. Finally, we demonstrate the effectiveness of our theory by applying it to the explicit Drinfeld twists constructed by Giaquinto and Zhang, where we establish both the equicontinuity condition and determine the corresponding spaces of analytic vectors for concrete representations. Thereby we answer a question posed by Giaquinto and Zhang whether a strict version of their formal twists is possible in the positive.",
        "keywords": [
          "math.QA",
          "math-ph",
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16593v1",
        "authors": [
          "Chiara Esposito",
          "Michael Heins",
          "Stefan Waldmann"
        ],
        "arxiv_categories": [
          "math.QA",
          "math-ph",
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Universal Deformation Formula",
        "Framework",
        "UDF",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.125863"
    },
    {
      "id": "arxiv-2602.16580v1",
      "title": "On the Coupled Cluster Doubles Truncation Variety of Four Electrons",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16580v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We extend recent algebro-geometric results for coupled cluster theory of quantum many-body systems to the truncation varieties arising from the doubles approximation (CCD), focusing on the first genuinely nonlinear doubles regime of four electrons. Since this doubles truncation variety does not coincide with previously studied varieties, we initiate a systematic investigation of its basic algebro-geometric invariants. Combining theoretical and numerical results, we show that for $4$ electrons on $n\\leq 12$ orbitals, the CCD truncation variety is a complete intersection of degree $2^{\\binom{n-4}{4}}$. Using representation-theoretic arguments, we uncover a Pfaffian structure governing the quadratic relations that define the truncation variety for any $n$, and show that an exact tensor product factorization holds in a distinguished limit of disconnected doubles. We connect these structural results to the computation of the beryllium insertion into molecular hydrogen ({Be$\\cdots$H$_2$ $\\to$ H--Be--H}), a small but challenging bond formation process where multiconfigurational effects become pronounced.",
        "keywords": [
          "math.AG",
          "physics.chem-ph",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16580v1",
        "authors": [
          "Fabian M. Faulstich",
          "Vincenzo Galgano",
          "Elke Neuhaus",
          "Irem Portakal"
        ],
        "arxiv_categories": [
          "math.AG",
          "physics.chem-ph",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Coupled Cluster Doubles Truncation",
        "Four Electrons We",
        "Hydrogen",
        "CCD",
        "Act",
        "MIT",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126016"
    },
    {
      "id": "arxiv-2602.16572v1",
      "title": "Quantum Cellular Automata: The Group, the Space, and the Spectrum",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16572v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Over an arbitrary commutative ring $R$, we develop a theory of quantum cellular automata. We then use algebraic K-theory to construct a space $\\mathbf{Q}(X)$ of quantum cellular automata (QCA) on a given metric space $X$. In most cases of interest, $π_0 \\mathbf{Q}(X)$ classifies QCA up to quantum circuits and stabilization. Notably, the QCA spaces are related by homotopy equivalences $\\mathbf{Q}(*) \\simeq Ω^n \\mathbf{Q}(\\mathbb{Z}^n)$ for all $n$, which shows that the classification of QCA on Euclidean lattices is given by an $Ω$-spectrum indexed by the dimension $n$. As a corollary, we also obtain a non-connective delooping of the K-theory of Azumaya $R$-algebras, which may be of independent interests. We also include a section leading to the $Ω$-spectrum for QCA over $C^*$-algebras with unitary circuits.",
        "keywords": [
          "math.AT",
          "math-ph",
          "math.OA",
          "math.RA",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16572v1",
        "authors": [
          "Mattie Ji",
          "Bowen Yang"
        ],
        "arxiv_categories": [
          "math.AT",
          "math-ph",
          "math.OA",
          "math.RA",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Cellular Automata",
        "Spectrum Over",
        "QCA",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126279"
    },
    {
      "id": "arxiv-2602.16510v1",
      "title": "Some rational subvarieties of moduli spaces of stable vector bundles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16510v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Let X be a smooth complex irreducible projective variety of dimension $n \\geq 2$ and $H$ be an ample line bundle on $X$. In this paper, we construct families of $μ_H$-stable vector bundles on $X$ having fixed determinant and rank $r$, which are generated by $r+1$ global sections, parametrized by Grassmanian varieties. This gives into the corresponding moduli spaces special subvarieties birational to Grassmannian.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16510v1",
        "authors": [
          "Sonia Brivio",
          "Federico Fallucca",
          "Filippo F. Favale"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126470"
    },
    {
      "id": "arxiv-2602.16492v1",
      "title": "Terminalizations of quotients of Fano varieties of lines on cubic fourfolds",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16492v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We classify projective terminalizations of quotients of Fano varieties of lines on smooth cubic fourfolds by finite groups of symplectic automorphisms of the underlying cubic. We compute the second Betti number and the fundamental group of the regular locus. As a consequence, we identify two new deformation classes of four-dimensional irreducible holomorphic symplectic varieties with second Betti number equal to four and simply connected regular locus.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16492v1",
        "authors": [
          "Enrica Mazzon"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126562"
    },
    {
      "id": "arxiv-2602.16491v1",
      "title": "Riemannian foliations on CROSSes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16491v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We classify Riemannian foliations of manifolds homeomorphic to CROSSes.",
        "keywords": [
          "math.GT",
          "math.DG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16491v1",
        "authors": [
          "Marco Radeschi",
          "Lorenzo Scoffone"
        ],
        "arxiv_categories": [
          "math.GT",
          "math.DG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126600"
    },
    {
      "id": "arxiv-2602.16484v1",
      "title": "The OU number and Reidemeister moves of type III for link diagrams",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16484v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce the non-self OU sequence and the OU number for link diagrams. Using these, we give a lower bound for the number of necessary Reidemeister moves of type III between two diagrams of the same link.",
        "keywords": [
          "math.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16484v1",
        "authors": [
          "Naoki Sakata",
          "Ayaka Shimizu",
          "Koya Shimokawa"
        ],
        "arxiv_categories": [
          "math.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "III",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126661"
    },
    {
      "id": "arxiv-2602.16472v1",
      "title": "Fit systolic groups, exactly",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16472v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A systolic complex/bridged graph is fit when its (metric) intervals are \"not too large\". We prove that uniformly locally finite fit systolic complexes have Yu's Property A. In particular, groups acting properly on such complexes have Property A, (equivalently) they are exact, and (equivalently) they are boundary amenable. As applications we show that groups from a class containing all large-type Artin groups, as well as all finitely presented graphical $C(3)$--$T(6)$ small cancellation groups, and finitely presented classical $C(6)$ small cancellation groups are exact. We also provide further examples. Our proof relies on a combinatorial criterion for Property~A due to Špakula and Wright.",
        "keywords": [
          "math.GR",
          "math.MG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16472v1",
        "authors": [
          "Martín Blufstein",
          "Victor Chepoi",
          "Huaitao Gui",
          "Damian Osajda"
        ],
        "arxiv_categories": [
          "math.GR",
          "math.MG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.126963"
    },
    {
      "id": "arxiv-2602.16458v1",
      "title": "Genus two Goeritz equivalence in lens spaces $L(p,1)$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16458v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, we consider the action of the Goeritz group $\\mathcal G_p$ for the genus two Heegaard splitting of the lens space $L(p,1)$ with $p\\ge 2$ on the homology of the Heegaard surface. We describe the action in terms of matrices in $GL(4, \\mathbb Z)$, and provide homology and homotopy obstructions for when two curves in the Heegaard surface are Goeritz equivalent.",
        "keywords": [
          "math.GT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16458v1",
        "authors": [
          "Brandy Doleshal",
          "Matt Rathbun"
        ],
        "arxiv_categories": [
          "math.GT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.127041"
    },
    {
      "id": "arxiv-2602.16457v1",
      "title": "Topological variations in General Relativity: a rigorous perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16457v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Motivated by recent developments in the theory of gravitation, we revisit the idea of topological variations, originally introduced by Wheeler and Hawking, from a rigorous perspective. Starting from a localized version of the Einstein-Hilbert variational principle, we encode the key aspects of the variational procedure in the form of a topology on a suitable space of variational configurations with low Sobolev regularity. This structure is the final topology with respect to the admissible variational maps and naturally lends itself to generalizations. We rigorously introduce two distinct types of topological variations, corresponding to the infinitesimal addition of disconnected components and to infinitesimal surgeries, both motivated by related physical concepts. Using tools from the theory of Sobolev spaces and precise asymptotics, we establish dimensional obstructions for the continuity and differentiability of the Einstein-Hilbert action with respect to these variations, and show that in the extended variational framework the action does not admit critical points in dimension $n=4$, while higher dimensions are free of this problem. Finally, we demonstrate the non-trivial effect of higher order curvature terms on the critical dimension.",
        "keywords": [
          "math.DG",
          "gr-qc",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16457v1",
        "authors": [
          "Miltiadis Paschalis"
        ],
        "arxiv_categories": [
          "math.DG",
          "gr-qc",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "General Relativity",
        "Framework",
        "BERT",
        "Act",
        "MIT",
        "DOE"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.127242"
    },
    {
      "id": "arxiv-2602.16452v1",
      "title": "On coefficients, potentially abelian quotients, and residual irreducibility of compatible systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16452v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Let $\\{ρ_λ:G_K\\rightarrow GL_n(\\overline E_λ)\\}$ be a semisimple E-rational compatible system of a number field K. In a first step, building upon the theory of pseudocharacters [Ro96],[Ch14], we attach to each $ρ_λ$ an algebraic monodromy group $G_λ$ defined over $E_λ$ and also prove that the compatible system can be descended to a strongly E'-rational compatible system $\\{ρ_{λ'}: G_K\\rightarrow GL_n(E'_{λ'})\\}$ for some finite extension E'/E. Secondly, we demonstrate that the maximal potentially abelian quotient of $G_λ$ is independent of $λ$ in a strong sense. Finally, as an application, we generalize a result of Patrikis--Snowden--Wiles on residual irreducibility of compatible systems.",
        "keywords": [
          "math.NT",
          "math.AG",
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16452v1",
        "authors": [
          "Gebhard Böckle",
          "Chun-Yin Hui"
        ],
        "arxiv_categories": [
          "math.NT",
          "math.AG",
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.127519"
    },
    {
      "id": "arxiv-2602.16434v1",
      "title": "Logarithmic Hurwitz Spaces in Mixed and Positive Characteristic with Wild Ramification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16434v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce new logarithmic Hurwitz spaces $\\mathcal{LH}^{\\mathbb{Z}_{(p)}}_A$ and $\\mathcal{LH}^{\\mathbb{F}_{p}}_{A,Ξ}$ over $\\mathbb{Z}_{(p)}$ and $\\mathbb{F}_p$ respectively that in the mixed characteristic case can be considered as a compactification of the admissible cover stack parametrizing ramified covers of curves in characteristic $0$ of degree $p$ and in the equicharacteristic case compactify the space of separable maps between smooth curves of degree $p$. These Hurwitz spaces will carry a logarithmic structure and to emphasize that they are informative, we prove that in some first cases our Hurwitz spaces are log smooth. To achieve this, we introduce various Moduli spaces that parametrize Artin-Schreier covers and the locus of zeroes and poles of certain differential forms, show their smoothness and compute their dimension.",
        "keywords": [
          "math.AG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16434v1",
        "authors": [
          "Matthias Hippold"
        ],
        "arxiv_categories": [
          "math.AG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Logarithmic Hurwitz Spaces",
        "Positive Characteristic",
        "Wild Ramification We",
        "EPA",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.127828"
    },
    {
      "id": "arxiv-2602.16433v1",
      "title": "Hensel minimality, $p$-adic exponentiation and Tate uniformization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16433v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We use Hensel minimality, a non-Archimedean analog of o-minimality, to study several questions around transcendental number theory, unlikely intersections, and differential fields in a non-Archimedean setting. In particular, we focus on $p$-adic exponentiation and Tate uniformization on $\\mathbb{C}_p$, which we show live in a Hensel minimal structure on $\\mathbb{C}_p$. We start by constructing a large collection of derivations on Hensel minimal fields that respect definable functions, which we then apply to the $p$-adic Schanuel conjecture. We also study properties of local definability in analogy to work of Wilkie, and show that $p$-adic Schanuel implies a uniform version of itself. For Tate uniformization we show a strong closure property when blurring, and deduce that $\\mathbb{C}_p$ with the blurred Tate uniformization is quasiminimal. Finally, we prove a result on $p$-adic density of likely intersections for powers of elliptic curves.",
        "keywords": [
          "math.LO",
          "math.NT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16433v1",
        "authors": [
          "Sebastian Eterović",
          "Floris Vermeulen"
        ],
        "arxiv_categories": [
          "math.LO",
          "math.NT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "For Tate",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.127969"
    },
    {
      "id": "arxiv-2602.16431v1",
      "title": "Cohomological support varieties of certain monomial ideals",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16431v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Building on work of Briggs, Grifo and Pollitz arXiv:2506.10827, we give an example of two cohomological support varieties of monomial ideals which are not unions of linear subspaces. We provide a procedure for the computation of the cohomological support varieties of certain other monomial ideals - including those with homogeneous generators - with improved computational efficiency, leading to a computer-assisted verification of the existence of a third support variety of a monomial ideal which is not a union of linear subspaces and a computer-assisted proof of a classification of cohomological support varieties of homogeneous monomial ideals over $\\mathbb{Q}$ with 6 generators.",
        "keywords": [
          "math.AC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16431v1",
        "authors": [
          "Michael Gintz"
        ],
        "arxiv_categories": [
          "math.AC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.128075"
    },
    {
      "id": "arxiv-2602.16419v1",
      "title": "Relative uniform convergence and Archimedean property in pre-ordered vector spaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16419v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "It is proved that, for a pre-ordered vector space $X$, the quotient space $(X/A,[W])$ is the Archimedeanization of $X$, where $W$ is the closure of the positive wedge $X_+$ in the ru-topology, $A=W\\cap(-W)$, and $[W]$ is the quotient set of $W$ in $X/A$.",
        "keywords": [
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16419v1",
        "authors": [
          "Eduard Emelyanov"
        ],
        "arxiv_categories": [
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.128134"
    },
    {
      "id": "arxiv-2602.16404v1",
      "title": "A Class of algebras admitting infinitely many norm topologies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16404v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Let $\\mathcal{A}$ be an algebra, and let $\\mathcal{A}^2 =$ span$\\{ab : a, b \\in \\mathcal{A}\\}$ be a subalgebra of $\\mathcal{A}$. In this paper, we prove that if $\\mathcal{A}^2$ has infinite codimension in $\\mathcal{A}$ iff $\\mathcal{A}$ has discontinuous square annihilation property (DSAP). In fact, in this case, the algebra $\\mathcal{A}$ admits infinitely many non-equivalent algebra norms.",
        "keywords": [
          "math.FA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16404v1",
        "authors": [
          "J. G. Patel"
        ],
        "arxiv_categories": [
          "math.FA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "DSAP",
        "Act",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:32.128217"
    },
    {
      "id": "arxiv-2602.16663v1",
      "title": "Axisymmetric cavities in hypersonic flow",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16663v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A detailed experimental campaign is conducted to investigate the shear layer characteristics of an axisymmetric open cavity exposed to a Mach $6$ freestream. Experiments are performed in a Ludwieg tunnel for varying Reynolds numbers ($23000\\leq Re_D \\leq 74000$) based on cavity depth ($D$). The effects of geometry are examined through length-to-depth ratios ($[L/D]=[2,4,6]$) and non-dimensional rear-face height differences ($[Δh/D]=[-0.5,-0.25,0,0.25,0.5]$). Shear layer evolution is interpreted using qualitative schlieren and Planar Laser Rayleigh Scattering (PLRS) along with quantitative unsteady pressure measurements. For all $[L/D]$, the shear layer remains laminar at low $Re_D$ and develops Kelvin-Helmholtz (K-H) vortices as $Re_D$ increases. For the longest cavity ($[L/D]=6$), transition to turbulence occurs at the highest $Re_D$ due to a longer K-H growth length. Spectral analysis of pressure signals and PLRS intensity shows a shift in dominant frequency from the first Rossiter mode to higher modes for $[L/D]=6$. Except for $[L/D]=6, [Δh/D]=0$, dominant frequencies agree with Rossiter predictions and remain largely Reynolds-number independent. Variation of $[Δh/D]$ leads to mode switching identified using POD of PLRS snapshots. Negative $[Δh/D]$ favors K-H modes (5th-6th Rossiter), whereas positive values promote a strong flapping mode (1st Rossiter) due to pressure build-up inside the cavity. At $[Δh/D]=0$, both modes may coexist depending on $Re_D$. Azimuthal measurements indicate dominant axisymmetric behavior in flapping cases and weaker correlation for K-H dominated shear layers.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16663v1",
        "authors": [
          "S. K. Karthick",
          "Soumya R. Nanda",
          "J. Cohen"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Planar Laser Rayleigh Scattering",
        "PLRS",
        "Act",
        "POD",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.185606"
    },
    {
      "id": "arxiv-2602.16621v1",
      "title": "WindDensity-MBIR: Model-Based Iterative Reconstruction for Wind Tunnel 3D Density Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16621v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Experimentalists often use wind tunnels to study aerodynamic turbulence, but most wind tunnel imaging techniques are limited in their ability to take non-invasive 3D density measurements of turbulence. Wavefront tomography is a technique that uses multiple wavefront measurements from various viewing angles to non-invasively measure the 3D density field of a turbulent medium. Existing methods make strong assumptions, such as a spline basis representation, to address the ill-conditioned nature of this problem. We formulate this problem as a Bayesian, sparse-view tomographic reconstruction problem and develop a model-based iterative reconstruction algorithm for measuring the volumetric 3D density field inside a wind tunnel. We call this method WindDensity-MBIR and apply it using simulated data to difficult reconstruction scenarios with sparse data, small projection field of view, and limited angular extent. WindDensity-MBIR can recover high-order features in these scenarios within 10% to 25% error even when the tip, tilt, and piston are removed from the wavefront measurements.",
        "keywords": [
          "eess.SP",
          "physics.flu-dyn",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16621v1",
        "authors": [
          "Karl J. Weisenburger",
          "Gregery T. Buzzard",
          "Charles A. Bouman",
          "Matthew R. Kemnetz"
        ],
        "arxiv_categories": [
          "eess.SP",
          "physics.flu-dyn",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Density Estimation Experimentalists",
        "Based Iterative Reconstruction",
        "Wind Tunnel",
        "MBIR",
        "Wind",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.186044"
    },
    {
      "id": "arxiv-2602.16576v1",
      "title": "Multifluid Hydrodynamic Simulation of Metallic-Plate Collision Using the VOF Method",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16576v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The present study is concerned with a one-dimensional problem in explosive welding that pertains to the collision of lead and steel plates. The metal plates and the surrounding air are represented as separate immiscible phases governed by independent equations of state. A multifluid Godunov-type (finite-volume) computational algorithm, based on the mechanical-equilibrium Euler equations and incorporating pressure relaxation, is used to numerically describe the evolution of the waves resulting from the collision. The position of the interface (contact discontinuity) between immiscible phases is tracked by means of the volume-of-fluid (VOF) method. The numerical model allows one to account for the existence of tensile stresses in metal and registers them as regions of negative pressure. The computed arrival time of the unloading wave at the interface between the plates agrees with the experimental data and with simulation results obtained via different methods.",
        "keywords": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16576v1",
        "authors": [
          "Fedor Belolutskiy",
          "Elena Oparina",
          "Svetlana Fortova"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Multifluid Hydrodynamic Simulation",
        "Plate Collision Using",
        "Meta",
        "EPA",
        "Act",
        "VOF",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.186468"
    },
    {
      "id": "arxiv-2602.16567v1",
      "title": "Scattering and sputtering on the lunar surface; Insights from negative ions observed at the surface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16567v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Context. Airless planetary bodies are directly exposed to solar wind ions, which can scatter or become implanted upon impact with the regolith-covered surface, while also sputtering surface atoms. Aims. We construct a semi-analytical model for the scattering of ions of hundreds of eV and the sputtering of surface atoms, both resulting in the emission of negative ions from the lunar surface. Our model contains a novel description of the scattering process that is physics-based and constrained by observations. Methods. We use data from the Negative Ions at the Lunar Surface (NILS) instrument on the Chang'e-6 lander to update prior knowledge of ion scattering and sputtering from lunar regolith through Bayesian inference. Results. Our model shows good agreement with the NILS data. A precipitating solar wind proton has roughly a 22% chance of scattering from the lunar surface in any charge state, and about an 8% chance of sputtering a surface hydrogen atom. The resulting ratio of scattered to sputtered hydrogen flux is eta_sc / eta_sp = 1.5 for a proton speed of 300 km/s. We find a high probability (7-20%) that a hydrogen atom leaves the surface negatively charged. The angular emission distributions at near-grazing angles for both scattered and sputtered fluxes are controlled by surface roughness. Our model also indicates significant inelastic energy losses for hydrogen interacting with the regolith, suggesting a longer effective path length than previously assumed. Finally, we estimate a surface binding energy of 5.5 eV, consistent with the observations. Conclusions. Our model describes the scattering and sputtering of particles of any charge state from any homogeneous, multi-species surface. Using NILS data, we successfully applied the model to update our understanding of solar wind interacting with lunar regolith, and the emission of negative hydrogen ions.",
        "keywords": [
          "physics.space-ph",
          "physics.atom-ph",
          "physics.ins-det",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16567v1",
        "authors": [
          "Romain Canu-Blot",
          "Martin Wieser",
          "Umberto Rollero",
          "Thomas Maynadié",
          "Stas Barabash"
        ],
        "arxiv_categories": [
          "physics.space-ph",
          "physics.atom-ph",
          "physics.ins-det",
          "stat.AP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Negative Ions",
        "Lunar Surface",
        "Agreement",
        "Hydrogen",
        "Solar",
        "Wind",
        "NILS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.187290"
    },
    {
      "id": "arxiv-2602.16515v1",
      "title": "Generative deep learning improves reconstruction of global historical climate records",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16515v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Accurate assessment of anthropogenic climate change relies on historical instrumental data, yet observations from the early 20th century are sparse, fragmented, and uncertain. Conventional reconstructions rely on disparate statistical interpolation, which excessively smooths local features and creates unphysical artifacts, leading to systematic underestimation of intrinsic variability and extremes. Here, we present a unified, probabilistic generative deep learning framework that overcomes these limitations and reveals previously unresolved historical climate variability back to 1850. Leveraging a learned generative prior of Earth system dynamics, our model performs probabilistic inference to recover spatiotemporally consistent historical temperature and precipitation fields from sparse observations. Our approach preserves the higher-order statistics of climate dynamics, transforming reconstruction into a robust uncertainty-aware assessment. We demonstrate that our reconstruction overcomes pronounced biases in widely used historical reference products, including those underlying IPCC assessments, especially regarding extreme weather events. Notably, we uncover higher early 20th-century global warming levels compared to existing reconstructions, primarily driven by more pronounced polar warming, with mean Arctic warming trends exceeding established benchmarks by 0.15--0.29°C per decade for 1900--1980. Conversely, for the modern era, our reconstruction indicates that the broad Arctic warming trend is likely overestimated in recent assessments, yet explicitly resolves previously unrecognized intense, localized hotspots in the Barents Sea and Northeastern Greenland. Furthermore, based on our seamless global reconstruction that recovers precipitation variability across the oceans and under-monitored regions, we uncover an intensification of the global hydrological cycle.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16515v1",
        "authors": [
          "Zhen Qian",
          "Teng Liu",
          "Sebastian Bathiany",
          "Shangshang Yang",
          "Philipp Hess"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Northeastern Greenland",
        "Deep Learning",
        "Barents Sea",
        "Framework",
        "IPCC",
        "IoT",
        "NSF",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.187980"
    },
    {
      "id": "arxiv-2602.16486v1",
      "title": "A fluctuating lattice Boltzmann formulation based on orthogonal central moments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16486v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Thermal fluctuations play a central role in fluid dynamics at mesoscopic scales and must be incorporated into numerical schemes in a manner consistent with statistical mechanics. In this work, we develop a fluctuating lattice Boltzmann formulation based on an orthogonal central-moments-based representation. Stochastic forcing is introduced directly in the space of central moments (CMs) and consistently paired with mode-dependent relaxation, yielding a discrete kinetic model that satisfies the fluctuation-dissipation theorem exactly at the lattice level. Owing to the orthogonality of the basis, the equilibrium covariance matrix of the central moments is diagonal, and each non-conserved mode can be interpreted as an independent discrete Ornstein-Uhlenbeck process with variance fixed by equilibrium thermodynamics. The resulting formulation guarantees exact equipartition of kinetic energy at equilibrium, preserves Galilean invariance, and retains the enhanced numerical stability characteristic of CMs-based collision operators. Explicit fluctuating schemes are constructed for the D2Q9 and D3Q27 lattices. The extension to reduced-velocity discretisation is discussed too. A comprehensive set of numerical tests verifies correct thermalisation, isotropy of equilibrium statistics, and the expected scaling of velocity fluctuations with thermal energy, density, and relaxation time. In contrast to fluctuating BGK formulations, the present method remains stable and well posed in the over-relaxation regime, including in the immediate vicinity of the stability limit. These results demonstrate that CMs-based lattice Boltzmann methods provide a natural and robust framework for fluctuating hydrodynamics, in which dissipation, noise, and kinetic mode structure are consistently aligned at the discrete level.",
        "keywords": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16486v1",
        "authors": [
          "Alessandro De Rosis",
          "Yang Zhou"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "Act",
        "BGK",
        "MIT",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.188254"
    },
    {
      "id": "arxiv-2602.16443v1",
      "title": "Modal Analysis of Buffet Effects Induced by Ultrahigh Bypass Ratio Nacelle Installation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16443v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Unsteady shock-boundary-layer interaction on the lower surface of a transport-aircraft wing can be caused or amplified by ultrahigh-bypass-ratio underwing nacelle installation. This work analyzes the resulting buffet dynamics on the Airbus XRF-1 configuration at a Mach number of $0.84$, a Reynolds number of $3.3\\times 10^6$, and $-4^\\circ$ angle of attack using scale-resolving delayed detached eddy simulations and unsteady pressure-sensitive paint measurements. Coherent structures are extracted employing a data-efficient multi-taper spectral POD. Dominant modes occur in the Strouhal number range $St \\in [0.1,0.3]$. Surface modes reveal wave-like shock motions that originate near the pylon-wing intersection and propagate inboard towards the fuselage. These shock oscillations are linked to unsteady flow separation downstream of the shock. Additional dominant modes show spanwise oscillations of the separated flow region and shock oscillations phase-linked to shear layer instabilities. The modal analysis of volume data reveals pressure waves connected to these modes traveling upstream above and below the wing.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16443v1",
        "authors": [
          "Sebastian Spinner",
          "Andre Weiner"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Ultrahigh Bypass Ratio Nacelle",
        "Buffet Effects Induced",
        "Installation Unsteady",
        "Modal Analysis",
        "XRF-1",
        "EPA",
        "Act",
        "XRF",
        "POD",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.188442"
    },
    {
      "id": "arxiv-2602.16420v1",
      "title": "Combined dynamic-kinematic validation of droplet-wall impact modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16420v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Many numerical studies validate droplet wall impact using only maximum spreading diameter, yet this metric alone cannot ensure correct droplet dynamics. We present a combined dynamic contact angle (DCA) model that merges the geometric accuracy of the generalized Hoffman-Voinov-Tanner law with the kinematic consistency of a Hoffman function-based approach, improving predictions of droplet spreading and receding. We simulate water-glycerol droplet impact on sapphire glass at Weber numbers 20 -- 250 and assess both contact angle formulations. Simulated radial velocity fields are processed in Python using SciPy and compared with Particle Image Velocimetry measurements in the longitudinal section of the spreading droplet. The Hoffman function-based model captures the main droplet kinematic trends and provides more consistent receding dynamics. The generalized Hoffman-Voinov-Tanner law matches the maximum spreading diameter within 7%. However, during receding, it shows a median absolute error in radial velocity up to three times higher than that of the Hoffman function-based solution. Average radial velocity and spreading velocity can differ from experimental trends even when maximum spreading is reproduced. These findings support validation combining geometric and kinematic metrics and motivate the combined model for predicting spreading and receding. Using the maximum spreading factor $β_{max}$ as the ratio of the maximum spreading diameter over the initial droplet diameter and the characteristic capillary number $Ca_{char}$ defined from the mean internal horizontal velocity at 300 micrometer above the substrate, we introduce a $(β_{max},\\,Ca_{char})$ diagram to relate spreading characteristics to internal flow dynamics. We hypothesize that, given sufficient data, the contact-line geometry may be used to estimate internal kinematics.",
        "keywords": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16420v1",
        "authors": [
          "Dmitry Zharikov",
          "Maxim Piskunov",
          "Dmitry Kolomenskiy"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Particle Image Velocimetry",
        "DCA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.189097"
    },
    {
      "id": "arxiv-2602.16408v1",
      "title": "Three dimensional contractile droplet under confinement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16408v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We numerically study the dynamics of a three-dimensional contractile fluid droplet in the bulk and under confinement. We show that varying activity leads to a variety of shapes and motile regimes whose motion is driven by an interplay between spontaneous flows and elasticity. In the bulk the droplet self-propels unidirectionally, acquiring either an almost spherical shape at intermediate activity or a peanut-like geometry for larger values. Under confinement, the droplet exhibits a previously unreported oscillating dynamics characterized by periodic hits against opposite walls of a microchannel while moving forward. These results could be of interest for the study of artificial microswimmers and their biological analogs, such as living cells.",
        "keywords": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16408v1",
        "authors": [
          "Adriano Tiribocchi",
          "Marco Lauricella",
          "Andrea Montessori",
          "Sauro Succi"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "WHO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.189231"
    },
    {
      "id": "arxiv-2602.16403v1",
      "title": "Quantifying the Role of 3D Fault Geometry Complexities on Slow and Fast Earthquakes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16403v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Traditional models of slow slip events (SSEs) often oversimplify fault geometry, yet imaging studies show that real subduction faults are segmented and complex. We investigate how fault interactions influence slip behavior using 3D quasi-dynamic earthquake sequence simulations of two parallel faults with uniform rate-weakening friction, accelerated with hierarchical matrices. Our results identify four slip regimes-periodic earthquakes, coexisting SSEs and earthquakes, only SSEs, and complex sequences-while a single planar fault under the same conditions produces only earthquakes. We quantify fault interaction using the maximum Coulomb stress induced on a target fault by unit, spatially uniform stress drop on a neighboring fault. Because the source stress drop is normalized, the metric depends only on geometry and is independent of friction and nucleation length, and it can be extended to arbitrary fault configurations. The occurrence of SSEs is confined to an intermediate range of interaction strength. We also reproduce the observed moment-duration scaling and show that it depends on event detection thresholds. These results demonstrate that complex fault geometry can naturally generate both slow and fast earthquakes through evolving traction heterogeneities.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16403v1",
        "authors": [
          "J. Cheng",
          "H. S. Bhat",
          "M. Almakari",
          "B. Lecampion",
          "P. Dubernet"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Fast Earthquakes Traditional",
        "Fault Geometry Complexities",
        "Act",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.189444"
    },
    {
      "id": "arxiv-2602.16296v1",
      "title": "Singular jets in free-falling droplets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16296v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We report on singular jets in a free-falling liquid tin droplet following nanosecond laser-pulse impact. Following impact, the droplet (with diameter $D_0=50$ or 70\\,$μ$m) undergoes rapid radial expansion and subsequent retraction, resulting in the formation of an axisymmetric jet. Using numerical simulations in tandem with our experiments, we reveal that a delicate interplay between radial flow and the curvature of the retracting droplet governs jet formation. The resulting dynamics is characterized using the impact Weber number, $\\We$ (in the experiments $2 \\lesssim \\We \\lesssim 16$), and a pressure width, W (typically $1 \\lesssim \\W \\lesssim 2$), which describes the angular distribution over the droplet surface of the instantaneous pressure impulse exerted by the transient laser-produced plasma. %, within the range $0-20$. For values $\\We<10$, the droplet presents a pronounced forward curvature during the retraction, leading to the formation of a cavity. The collapse of such a cavity leads to a singular jet that greatly enhances the jetting velocity up to ten times the impact propulsion velocity, an effect that narrowly peaks around $\\We\\sim6-8$, reminiscent of singular jets in droplet-solid impact. We identify a further sensitivity of the jet velocity enhancement on the pressure width W and capture the dynamics in a phase diagram connecting the various deformation morphologies with jet velocity.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16296v1",
        "authors": [
          "M. Kharbedia",
          "H. Franca",
          "H. K. Schubert",
          "D. J. Engels",
          "M. Jalaal"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.189951"
    },
    {
      "id": "arxiv-2602.16287v1",
      "title": "Ponomarenko dynamo sustained by a free swirling jet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16287v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present numerical results on dynamo action in a flow driven by an azimuthal body force localized near the end of an elongated cylindrical container. The analysis focuses on the central region of the cylinder, where axial variations in the flow are relatively weak, allowing the magnetic field to be represented as a helically traveling wave. Four magnetic impeller configurations and multiple forcing intensities are examined. In all cases, the velocity profiles in the central region display a similar \\propto r^{-2} dependence across a wide range of Reynolds numbers and forcing region widths. The magnetic field is found to start growing under conditions similar to those of the Riga dynamo. However, the growing modes exhibit a substantial nonzero group velocity, indicating that the associated instability is convective: the flow can amplify an externally applied magnetic field but cannot sustain it autonomously. We outline several approaches for overcoming this limitation in order to realize a working laboratory dynamo based on an internally unconstrained swirling jet-type flow.",
        "keywords": [
          "physics.geo-ph",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16287v1",
        "authors": [
          "I. Grants",
          "J. Priede"
        ],
        "arxiv_categories": [
          "physics.geo-ph",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Laboratory",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.190128"
    },
    {
      "id": "arxiv-2602.16221v1",
      "title": "Reinterpreting the sunward electron deficit: Implications for solar wind acceleration and core population formation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16221v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper re-evaluates the relationship between the observed sunward electron cutoff energy and the depth of the Sun's global electrostatic potential. It investigates whether taking into account the effects of local traps formed by magnetic fluctuations provides an alternative explanation for the observed electron deficit. The fluctuations of the highly variable interplanetary magnetic field form a series of shallow magnetic mirror traps that move at approximately the speed of the solar wind. The study investigates the dynamics of electrons as they move outward against an attractive solar electrostatic potential and interact with these traps. By following the motion of the electrons using first-principles calculations, we assess the effect of the traps on the velocity distribution of the particles. Electrons that escape the local trap continue to lose energy as they move outward until they are eventually captured by subsequent traps, preventing them from returning to the observer as sunward-moving particles. We derive a mathematical expression for the cutoff velocity, defined as the limit beyond which particles can no longer overtake the outer endpoint of a local trap. It turns out that the observed cutoff energy characterizes only the local potential drop within a trap, rather than the total depth of the Sun's potential well. The true potential well can be significantly deeper, scaled by the ratio of the radial distance from the Sun to the trap size. Furthermore, electrons captured by these moving traps contribute to the formation of the solar wind core population. The Sun's electrostatic potential is a more significant factor in solar wind acceleration than previously interpreted from cutoff data. The interaction between electrostatic deceleration and moving magnetic traps provides a new framework for understanding the origin and behavior of the solar wind core electrons.",
        "keywords": [
          "astro-ph.SR",
          "physics.plasm-ph",
          "physics.space-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16221v1",
        "authors": [
          "Zoltan Nemeth"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "physics.plasm-ph",
          "physics.space-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Solar",
        "Wind",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.190419"
    },
    {
      "id": "arxiv-2602.16090v1",
      "title": "Examining Fast Radiative Feedbacks Using Machine-Learning Weather Emulators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16090v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The response of the climate system to increased greenhouse gases and other radiative perturbations is governed by a combination of fast and slow feedbacks. Slow feedbacks are typically activated in response to changes in ocean temperatures on decadal timescales and manifest as changes in climatic state with no recent historical analogue. However, fast feedbacks are activated in response to rapid atmospheric physical processes on weekly timescales, and they are already operative in the present-day climate. This distinction implies that the physics of fast radiative feedbacks is present in the historical meteorological reanalyses used to train many recent successful machine-learning-based (ML) emulators of weather and climate. In addition, these feedbacks are functional under the historical boundary conditions pertaining to the top-of-atmosphere radiative balance and sea-surface temperatures. Together, these factors imply that we can use historically trained ML weather emulators to study the response of radiative-convective equilibrium (RCE), and hence the global hydrological cycle, to perturbations in carbon dioxide and other well-mixed greenhouse gases. Without retraining on prospective Earth system conditions, we use ML weather emulators to quantify the fast precipitation response to reduced and elevated carbon dioxed concentrations with no recent historical precedent. We show that the responses from historically trained emulators agree with those produced by full-physics Earth System Models (ESMs). In conclusion, we discuss the prospects for and advantages from using ESMs and ML emulators to study fast processes in global climate.",
        "keywords": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16090v1",
        "authors": [
          "Ankur Mahesh",
          "William D. Collins",
          "Travis A. O'Brien",
          "Paul B. Goddard",
          "Sinclaire Zebaze"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Examining Fast Radiative Feedbacks",
        "Earth System Models",
        "Using Machine",
        "RCE",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.190689"
    },
    {
      "id": "arxiv-2602.16081v1",
      "title": "Non-local physics-informed neural networks for forward and inverse solutions of granular flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16081v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Dense granular flows exhibit nonlocal effects due to stress transmission in microplastic events, especially in quasi-static or slowly sheared regions. Hence, traditional local rheological models fail to capture spatial cooperativity effects that are prominent in many granular systems. The nonlocal granular fluidity (NGF) model addresses this limitation by introducing a diffusive-like partial differential equation for a fluidity field, governed by a key material-dependent parameter: the nonlocal amplitude A. However, determining A from experiments or simulations is known to be difficult and typically requires extensive calibration across multiple geometries. In this work, we present a data-driven platform based on Physics-Informed Neural Networks (PINNs) embedded with the NGF model, capable of solving granular flows in a forward or inverse manner. We show that once trained on transient flow fields, these non-local PINNs can readily infer the material parameters, as well as the pressure and stress fields. These data-driven frameworks allow for accurate recovery of small variations in the nonlocal amplitude, A, which lead to sharp bifurcation-like transitions in the flow field. This approach demonstrates the feasibility of data-driven parameter inference in complex nonlocal models and opens up new possibilities for characterizing granular materials from sparse experimental observations.",
        "keywords": [
          "cond-mat.soft",
          "cond-mat.dis-nn",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16081v1",
        "authors": [
          "Saghar Zolfaghari",
          "Safa Jamali"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "cond-mat.dis-nn",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Informed Neural Networks",
        "Neural Network",
        "Framework",
        "NGF",
        "Act",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.190907"
    },
    {
      "id": "arxiv-2602.16068v1",
      "title": "Stochastic Lorenz dynamics and wind reversals in Rayleigh-Bénard Convection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16068v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Lorenz equations [1] are a severe Galerkin-truncation of the Oberbeck-Boussinesq (OB) equations describing Rayleigh-Bénard convection (RBC). Here we examine the mathematical connections between the chaotic lobe-switching behavior of a stochastic form of the Lorenz equations, that model the interaction between the thermal boundary layers and the core circulation, and the mean wind reversals in the experiments of Sreenivasan et al. [2]. Long-time numerical simulations of these stochastic equations, not easily accessible with the OB equations, yield a probability distribution for lobe inter-switch timings that exhibits non-Gaussian, multifractal behavior. In the Gaussian frequency range the simulations mirror the laboratory measurements and the classical Hurst exponent and quadratic variation show Brownian second-moment statistics. Further scrutiny reveals a non-linear cumulant generating function, or moment-exponent function, and thus multifractality. A simple generalized two-scale Cantor-cascade analysis reproduces these properties, showing that multiplicative intermittency, characteristic of turbulence, strongly influences the statistics. This demonstrates that this stochastic Lorenz system is a faithful, low-dimensional surrogate for mean-wind reversals in RBC.",
        "keywords": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16068v1",
        "authors": [
          "Yanni Bills",
          "J. S. Wettlaufer"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Stochastic Lorenz",
        "Laboratory",
        "Wind",
        "RBC",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.191315"
    },
    {
      "id": "arxiv-2602.15993v1",
      "title": "An Interpretable Physics Informed Multi-Stream Deep Learning Architecture for the Discrimination between Earthquake, Quarry Blast and Noise",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15993v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The reliable discrimination of tectonic earthquakes from anthropogenic quarry blasts and transient noise remains a critical challenge in single station seismic monitoring. In this study, we introduce a novel Physics Informed Convolutional Recurrent Neural Network (PI CRNN) that embeds seismological domain knowledge directly into the feature extraction and learning process. We adapt a multistream architecture with three parallel encoders: (i) Time Domain: SincNet Encoder, (ii) MultiResolution Spectrogram branch, and, (iii) Physics Branch, followed by a fusion and a bidirectionalLSTM module. Evaluated on the Curated Pacific Northwest AI ready Seismic Dataset, the PI CRNN achieves an overall classification accuracy of 97.56 percent on an independent test set. It outperforms a standard CRNN baseline, a classical P to S amplitude ratio method, and a Physics Informed Neural Network (PINN) that enforces physical constraints via the loss function. Furthermore, the model demonstrates perfect precision in noise rejection (100 percent Recall). Interpretability analysis using saliency maps confirms that the architecture successfully learns distinct physical signatures, identifying bimodal P- and S-wave arrivals for earthquakes versus singular impulsive onsets for blasts. This work establishes a scalable, transparent framework for AI-driven seismology, proving that architectural inductive bias provides an alternative reliable approach compared to purely data-driven approaches.",
        "keywords": [
          "physics.geo-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15993v1",
        "authors": [
          "Nishtha Srivastava",
          "Johannes Faber",
          "Dhruv Aditya Srivastava"
        ],
        "arxiv_categories": [
          "physics.geo-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Physics Informed Convolutional Recurrent",
        "An Interpretable Physics Informed",
        "Stream Deep Learning Architecture",
        "Physics Informed Neural Network",
        "Curated Pacific Northwest",
        "Seismic Dataset",
        "Physics Branch",
        "Neural Network",
        "Deep Learning",
        "Quarry Blast",
        "Time Domain",
        "Framework",
        "Standard",
        "Fusion",
        "CRNN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.191558"
    },
    {
      "id": "arxiv-2602.15830v1",
      "title": "Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15830v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members).",
        "keywords": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15830v1",
        "authors": [
          "Christopher David Roberts"
        ],
        "arxiv_categories": [
          "physics.ao-ph",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Transformer",
        "Framework",
        "ECMWF",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.191839"
    },
    {
      "id": "arxiv-2602.15768v1",
      "title": "Southern Ocean latent heat flux variability driven by oceanic meso- and submesoscale motions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15768v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Latent heat flux is a primary pathway for ocean-atmosphere exchange of heat and moisture, yet the influence of sea surface temperature variability at fine scales ($\\leq$ 100 km) on latent heat flux variability, particularly over the Southern Ocean, remains poorly understood. Here we quantify the scale-dependent drivers of latent heat flux (LHF) variability using a year-long, global, fully coupled ocean-atmosphere simulation with kilometer-scale resolution. Annual-mean LHF in eddy-rich regions reaches $\\approx$ 215 W m$^{-2}$, approximately three times larger than in eddy-poor regions. Spectral analyses show that ocean mesoscale [$\\mathcal{O}$(100 km)] and submesoscale [$\\mathcal{O}$(1-10 km)] variability accounts for up to $\\approx$ 80% of the total LHF variance in eddy-rich sectors, but as little as 10% in eddy-poor regions, and increases proportionally with eddy kinetic energy and sea surface temperature (SST) variance. We also find that strong submesoscale SST fronts ($\\approx$ 5 $^\\circ$C over 10 km) force a localized secondary circulation that extends well above the marine boundary layer into the mid-troposphere. Comparison with ERA5 shows that fine ocean scales, responsible for about 17% of the ocean-driven LHF variance in the simulation, are largely unresolved in the reanalysis, leading to a muted atmospheric response lacking any secondary circulation. Despite a strong heterogeneity in LHF variability, the atmospheric dynamics are mostly uniform across the domain, suggesting a non local atmospheric response to ocean forcing. These results highlight the potential for ocean meso- and submesoscales, commonly under-resolved in climate models and reanalysis, to influence Southern Ocean air-sea coupling and atmosphere both locally and remotely.",
        "keywords": [
          "physics.ao-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15768v1",
        "authors": [
          "Lucie Reymondet",
          "Lia Siegelman",
          "Luc Lenain"
        ],
        "arxiv_categories": [
          "physics.ao-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Southern Ocean",
        "SST",
        "LHF",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.192112"
    },
    {
      "id": "arxiv-2602.15744v1",
      "title": "Effect of flexibility on the pitch-heave flutter instability of a flexible foil elastically supported on its leading edge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15744v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "An analytical tool is presented to compute the parametric regions of flutter instabilities of a two-dimensional flexible foil elastically mounted. It is based on a new analytical formulation of the unsteady fluid-estructure interaction valid for small-amplitude oscillations and deformations of the foil immersed in an inviscid fluid. The formulation extends a previous analysis by including the effects of gravity and a second flexural mode, increasing its validity range to much smaller rigidities. The analytical results are validated with available numerical results, capturing the first two natural flexural modes down to values of the stiffness parameter $S$ of order $10^{-1}$. When only passive heave, or only passive pitch, is allowed, the rigid foil is stable, existing an upper stiffness bound for the flexural instabilities, wich become coupled with the spring instability mode for small spring constant increasing the growth rate. These coupled spring (linear or torsional) and flexural instability modes occur below a threshold value of $S$ and above a threshold value of $R$, both depending on the corresponding spring constant. Coupled pitch-heave flutter instabilities of a rigid foil occur in a region below a curve of the parametric plane of the two springs constants that depends on $R$, which shrinks to zero as $R$ decreases. For a flexible foil, the flexural unstable modes become coupled with the springs unstable mode as $S$ decreases from infinity, enlarging the mass ratio range for flutter instability and increasing its growth rate, the more so the smaller the springs constants. The parametric regions for flutter instabilities are easily characterized with the present analytical tool, providing the corresponding frequency and critical flutter velocity. The present results can be useful as a guide in the design of future turbines based on flexible oscillating foils.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15744v1",
        "authors": [
          "Ramon Fernandez-Feria"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.192396"
    },
    {
      "id": "arxiv-2602.15743v1",
      "title": "Physics-informed data-driven inference of an interpretable equivariant LES model of incompressible fluid turbulence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15743v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes.",
        "keywords": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15743v1",
        "authors": [
          "Matteo Ugliotti",
          "Brandon Choi",
          "Mateo Reynoso",
          "Daniel R. Gurevich",
          "Roman O. Grigoriev"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "RANS",
        "LES",
        "MIT",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.192579"
    },
    {
      "id": "arxiv-2602.15670v1",
      "title": "Quantitative enstrophy bounds for measure vorticities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15670v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider the two-dimensional incompressible Navier-Stokes equations with measure initial vorticity. By means of improved Nash inequalities, we establish quantitative estimates for the enstrophy depending on the absolute vorticity decay on balls. The bounds are optimal in several aspects and yield to a conjecturally sharp rate of the dissipation in the Delort's class.",
        "keywords": [
          "math.AP",
          "math-ph",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15670v1",
        "authors": [
          "Luigi De Rosa",
          "Margherita Marcotullio"
        ],
        "arxiv_categories": [
          "math.AP",
          "math-ph",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.192663"
    },
    {
      "id": "arxiv-2602.15639v1",
      "title": "Equilibrium statistical mechanics of waves in inhomogeneous moving media",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15639v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We adapt the microcanonical framework of equilibrium statistical mechanics to predict the statistics of short waves in inhomogeneous moving media. For steady inhomogeneities and background flow, we compute the wave spectrum at any location in the domain based on an ergodic prescription for the action density in phase space, constrained by conservation of absolute frequency. We illustrate the method for shallow-water waves subject to a background flow or to topographic inhomogeneities, and for deep-water surface capillary waves over a background flow, validating the predicted maps of rms surface elevation and interfacial slope against numerical simulations.",
        "keywords": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15639v1",
        "authors": [
          "Alexandre Tlili",
          "Basile Gallet"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "nlin.CD"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.192908"
    },
    {
      "id": "arxiv-2602.15626v1",
      "title": "Deformation and orientation of a capsule with viscosity contrast in linear flows: a theoretical study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15626v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We develop a perturbation theory to study the shape and the orientation of an initially spherical capsule of radius R with a viscosity contrast, a surface tension σ and a bending rigidity $κ$ in linear flows. The elastic mechanical response of membrane to deformations is described by three elastic constitutive law which are either Hookean, Neohookean or Skalak type leading to the introduction of a surface shear elastic modulus $G_s$ and the Poisson ratio (or analog quantities). At the leading order, the deformation, i.e. the so-called Taylor parameter is proportional to the elastic capillary number Ca which evaluates the ratio between the external viscous stress and the elastic membrane response. In this linear regime, the results do not depend on the elastic constitutive law as expected. Without surface tension and bending rigidity, we recover the results of Barthes-Biesel & Rallison (1981) and notably the fact that the Taylor parameter does not depend on the viscosity contrast $λ$ contrary to the case of a viscous droplet. In our more general model, the deformation does no longer depend on $λ$ at the upper order. Now, the Taylor parameter also depends on two other dimensionless numbers: the surface elastocapillary ratio $σ/G_s$ and the dimensionless bending rigidity $B= κ/G_sR^2$. At the further order, the angle of inclination of the capsule with the direction of the shear flow, the analog of the Chaffey and Brenner equation for droplets is determined in each case. The results are in excellent agreement with the numerical ones performed with a code based on the boundary integral method providing an useful method to valid numerical developments.",
        "keywords": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15626v1",
        "authors": [
          "Paul Regazzi",
          "Marc Leonetti"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.flu-dyn"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "Act",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:37.194122"
    },
    {
      "id": "arxiv-2602.15599v1",
      "title": "Influence of the Inhalation Route on Tracheal Flow Structures in Patient-Specific Airways using 3D PTV",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15599v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The tracheal flow field shapes particle transport into the lower airways and thus influences both the spread of inhaled pathogens and the effectiveness of aerosol-based therapies. Identifying how different inhalation routes modify the flow field is therefore crucial for understanding lower-airway disease transmission and for guiding targeted drug delivery. To gain a detailed understanding of the influence of the inhalation route on the flow structures in the human trachea, the flow field in the trachea is investigated in vitro in a non-compliant, refractive-index matched silicone model of the human respiratory tract. The investigations comprise steady inhalation, and oscillatory flow to simulate calm breathing. A realistic breathing pattern is approximated by a sinusoidal waveform for two Reynolds numbers of $Re_{Tr} = [400, 1200]$, based on the bulk velocity at maximum volume flux and the hydraulic diameter of the trachea and two Womersley numbers of $Wo = [3, 4.5]$, representing the oscillation time scales. To capture the inherently three-dimensional and asymmetric nature of the flow field, 3D particle-tracking velocimetry measurements are performed using the Shake-The-Box algorithm. Using a refractive-index matched fluid consisting of water and glycerin, the complex flow structures inside the trachea are fully resolved. The PTV measurements confirm that the nasal and/or oral cavity must be considered when analyzing the flow field in the lower respiratory tract. In particular, we find that the presence of both cavities significantly alters the flow field compared to idealised, fully developed inflow conditions. However, velocity profiles in the sagittal and coronal plane in the trachea as well as contour plots of the of the normalized velocity magnitude evidence nearly identical flow structures for oral and nasal inhalation, indicating minimal influence of the inhalation route.",
        "keywords": [
          "physics.flu-dyn"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15599v1",
        "authors": [
          "Benedikt H. Johanning-Meiners",
          "Luca Mayolle",
          "Dominik Krug",
          "Michael Klaas"
        ],
        "arxiv_categories": [
          "physics.flu-dyn"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Tracheal Flow Structures",
        "Inhalation Route",
        "Specific Airways",
        "NASA",
        "Act",
        "PTV",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.194644"
    },
    {
      "id": "arxiv-2602.15592v1",
      "title": "Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15592v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics.",
        "keywords": [
          "physics.flu-dyn",
          "cs.LG",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15592v1",
        "authors": [
          "Xiao Xue",
          "Tianyue Yang",
          "Mingyang Gao",
          "Leyu Pan",
          "Maida Wang"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cs.LG",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Machine Learning",
        "Framework",
        "Fusion",
        "EPA",
        "IoT",
        "HPC",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.194915"
    },
    {
      "id": "arxiv-2602.15536v1",
      "title": "Novel distance-based masking and adaptive alpha-shape methods for CNN-ready reconstruction of arbitrary 2D CFD flow domains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15536v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Interpolating scattered CFD datasets onto a uniform Cartesian grid can distort the true geometry, producing a convex-hull type envelope and activating nonphysical regions. This work presents a reconstruction framework that recovers physically consistent masks before exporting CNN-ready fields. It introduces two novel strategies, distance-based masking and an adaptive alpha-shape formulation that normalizes alpha using local data resolution, and evaluates them against classical alpha-shape boundary recovery. A quantitative, topology-aware metric suite is introduced to assess retention, suppression of unsupported regions, overlap consistency, and connectivity. The novel distance-based method is robust across the geometries considered under the same threshold rule, with tau set to the minimum CFD grid spacing, and achieves 500-800 times speedups over classical alpha-shapes. The adaptive alpha-shape remains stable when its control parameter is set to 1 and is 1.7-2.6 times faster than the classical variant, which requires geometry-specific alpha tuning. A lightweight boundary inflation post-process using a minimal dilation further improves retention by up to 2.96% with negligible unsupported activation (less than 0.08%). Overall, the distance-based method is recommended as the default due to its accuracy, stability, minimal tuning, and low cost, while the adaptive alpha-shape is a strong alternative when grid-spacing information for threshold selection is unavailable. A companion web application operationalizes the workflow end to end, enabling 2D ASCII dataset upload, parameter tuning, mask and boundary generation, and export of CNN-ready outputs.",
        "keywords": [
          "physics.flu-dyn",
          "math.MG",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15536v1",
        "authors": [
          "Mehran Sharifi",
          "Gorka S. Larraona",
          "Alejandro Rivas"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "math.MG",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "ASCII",
        "CNN",
        "Act",
        "CFD",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.195185"
    },
    {
      "id": "arxiv-2602.15472v1",
      "title": "Fluids You Can Trust: Property-Preserving Operator Learning for Incompressible Flows",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15472v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a novel property-preserving kernel-based operator learning method for incompressible flows governed by the incompressible Navier-Stokes equations. Traditional numerical solvers incur significant computational costs to respect incompressibility. Operator learning offers efficient surrogate models, but current neural operators fail to exactly enforce physical properties such as incompressibility, periodicity, and turbulence. Our method maps input functions to expansion coefficients of output functions in a property-preserving kernel basis, ensuring that predicted velocity fields analytically and simultaneously preserve the aforementioned physical properties. We evaluate the method on challenging 2D and 3D, laminar and turbulent, incompressible flow problems. Our method achieves up to six orders of magnitude lower relative $\\ell_2$ errors upon generalization and trains up to five orders of magnitude faster compared to neural operators. Moreover, while our method enforces incompressibility analytically, neural operators exhibit very large deviations. Our results show that our method provides an accurate and efficient surrogate for incompressible flows.",
        "keywords": [
          "physics.flu-dyn",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15472v1",
        "authors": [
          "Ramansh Sharma",
          "Matthew Lowery",
          "Houman Owhadi",
          "Varun Shankar"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cs.LG"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Preserving Operator Learning",
        "Incompressible Flows We",
        "Fluids You Can Trust",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.195386"
    },
    {
      "id": "arxiv-2602.15416v1",
      "title": "A Robust Truncated-Domain Approach for Cone--Jet Simulations in Electrospinning and Electrospraying",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15416v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Direct numerical simulations of electrospinning and electrospraying are computationally demanding due to large-scale separation between the needle and the tip-to-collector distance. The cone-jet mode that occurs in the vicinity of the needle arises from a delicate balance between surface tension, viscous stresses, inertia, and electric stresses. This mode has a central role in determining the subsequent instabilities of the jet and the eventual outcomes on the collector. Truncated-domain simulations offer a viable alternative but depend critically on the accuracy of far-field electrostatic boundary conditions. Existing truncated-domain approaches based on analytical expressions for the electric potential systematically underestimate the electric field near the needle tip and require empirical tuning informed by prior experiments or full-domain simulations, thereby limiting their predictive capability. Here, we present a general truncated-domain framework for electrohydrodynamic (EHD) simulations of the cone-jet mode that avoids these limitations. Our approach exploits inexpensive full-domain electrostatic simulations to obtain the exact electric field and potential distributions near the needle, which are then imposed as boundary conditions in an EHD simulation carried out on a truncated domain. Comparisons with full-domain EHD simulations and experimental data demonstrate that the proposed approach accurately reproduces cone-jet shapes as well as key physical quantities, including electric currents, charge distributions, velocity fields, and Maxwell stresses, while converging at substantially smaller domain sizes. The formulation eliminates tunable parameters, does not require prior knowledge of the cone-jet configuration, and significantly reduces computational cost, providing a reliable and predictive framework for studying electrohydrodynamic cone-jet flows.",
        "keywords": [
          "physics.flu-dyn",
          "cond-mat.soft",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15416v1",
        "authors": [
          "Ghanashyam K. C.",
          "Satyavrata Samavedi",
          "Harish N Dixit"
        ],
        "arxiv_categories": [
          "physics.flu-dyn",
          "cond-mat.soft",
          "physics.comp-ph"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Electrospraying Direct",
        "Robust Truncated",
        "Domain Approach",
        "Jet Simulations",
        "Framework",
        "EPA",
        "Act",
        "MIT",
        "DOE",
        "EHD",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:37.196124"
    },
    {
      "id": "arxiv-2602.16672v1",
      "title": "FLUKA-Based Optimization of Muon Production Target Design for a Muon Collider Demonstrator",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16672v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This study investigates how target geometry and material influence pion and muon production from an 8 GeV proton beam, in support of target-system design for a muon collider demonstrator. A 2 m long, 0.7 m radius solenoid with a 5 T peak magnetic field is used to capture secondary particles, with the target positioned at its center. We examine how variations in target radius, length, and material affect secondary-beam yield and emittance at the solenoid exit. In parallel, we evaluate temperature rise within the target to assess material limitations and guide future work on thermal and structural survivability. The results provide initial intuition for optimizing both particle yield and target durability in muon collider front-end systems.",
        "keywords": [
          "physics.acc-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16672v1",
        "authors": [
          "Ruaa Al-Harthy"
        ],
        "arxiv_categories": [
          "physics.acc-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Muon Production Target Design",
        "Based Optimization",
        "FLUKA",
        "MIT"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.261646"
    },
    {
      "id": "arxiv-2602.16668v1",
      "title": "Operator based propagation of Whittaker and Helmholtz Gauss beams",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16668v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We introduce a compact operator-based technique that solves the paraxial wave equation for a broad class of structured light fields. Using the spatial evolution operator to propagate two families of physically apodized inputs, Gaussian apodized Whittaker integrals and Gaussian apodized Helmholtz fields, we derive closed form expressions that retain the Gaussian width and therefore describe finite energy beams. The method unifies and extends the Helmholtz Gauss families and readily generalizes to nonseparable nondiffracting architectures. Experiments on superposed Bessel Gauss beams confirm the predicted transverse rotations, demonstrating that this operator approach is a fast, transparent, and practical alternative to standard diffraction ntegral treatments",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16668v1",
        "authors": [
          "M. A. Jacome Silva",
          "I. Julian Macias",
          "F. Soto Eguibar",
          "U. Ruiz Corona",
          "I. Ramos Prieto"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Helmholtz Gauss",
        "Bessel Gauss",
        "Standard",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.261966"
    },
    {
      "id": "arxiv-2602.16665v1",
      "title": "Optimizing p-spin models through hypergraph neural networks and deep reinforcement learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16665v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "p-spin glasses, characterized by frustrated many-body interactions beyond the conventional pairwise case (p>2), are prototypical disordered systems whose ground-state search is NP-hard and computationally prohibitive for large instances. Solving this problem is not only fundamental for understanding high-order disorder, structural glasses, and topological phases, but also central to a wide spectrum of hard combinatorial optimization tasks. Despite decades of progress, there still lacks an efficient and scalable solver for generic large-scale p-spin models. Here we introduce PLANCK, a physics-inspired deep reinforcement learning framework built on hypergraph neural networks. PLANCK directly optimizes arbitrary high-order interactions, and systematically exploits gauge symmetry throughout both training and inference. Trained exclusively on small synthetic instances, PLANCK exhibits strong zero-shot generalization to systems orders of magnitude larger, and consistently outperforms state-of-the-art thermal annealing methods across all tested structural topologies and coupling distributions. Moreover, without any modification, PLANCK achieves near-optimal solutions for a broad class of NP-hard combinatorial problems, including random k-XORSAT, hypergraph max-cut, and conventional max-cut. The presented framework provides a physics-inspired algorithmic paradigm that bridges statistical mechanics and reinforcement learning. The symmetry-aware design not only advances the tractable frontiers of high-order disordered systems, but also opens a promising avenue for machine-learning-based solvers to tackle previously intractable combinatorial optimization challenges.",
        "keywords": [
          "cond-mat.dis-nn",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16665v1",
        "authors": [
          "Li Zeng",
          "Mutian Shen",
          "Tianle Pu",
          "Zohar Nussinov",
          "Qing Feng"
        ],
        "arxiv_categories": [
          "cond-mat.dis-nn",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "Framework",
        "XORSAT",
        "PLANCK",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.262492"
    },
    {
      "id": "arxiv-2602.16652v1",
      "title": "Nonlinear Frequency Shifts due to Phase Coherent Interactions in Incompressible Hall MHD Turbulence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16652v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Turbulence in the magnetized plasma is well understood to be the consequence of wave interactions. When the Hall effect is added to the minimum magnetohydrodynamics (MHD), the MHD waves become dispersive and different nonlinear interactions are expected. The emergent turbulent state will thus be expected to be different. For incompressible Hall MHD we develop a reduced model for wave-wave interactions concentrating on those processes that will lead to phase coherent modifications to the linear dispersion of a given wave. We show that these special interactions provide an amplitude-dependent contribution to the linear dispersion relation, which yields nonlinear frequency shifts. The resonance-driven frequency shifts are dominant and add damping or growth to the linear dispersion. The damping/growth rates represent the nonlinear time scales for energy redistribution and can be used in conjunction with a conjecture like the \"critical balance\" to estimate the energy spectral content.",
        "keywords": [
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16652v1",
        "authors": [
          "Erik C. Hansen",
          "Prerana Sharma",
          "Swadesh M. Mahajan"
        ],
        "arxiv_categories": [
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Phase Coherent Interactions",
        "Nonlinear Frequency Shifts",
        "Turbulence Turbulence",
        "Incompressible Hall",
        "Act",
        "MHD",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.262847"
    },
    {
      "id": "arxiv-2602.16645v1",
      "title": "Ultracold atoms in a dipole trap in microgravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16645v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Most cold atoms experiments in microgravity platforms or in Space are achieved using atom chips, leading to limitations in terms of optical access and inhomogeneous magnetic fields. Optical dipole traps do not have these drawbacks but have difficulties producing atomic samples with a large number of atoms at ultra low temperature in the absence of gravity. Here, we report on an efficient evaporative cooling in two-crossed laser beams during parabolic flights. Time-averaged potentials combine the advantages of large capture volume and trap compression, increasing the initial phase space density and collision rate to favor the evaporative process. With this technique we demonstrate the production of an ultra cold gas of $2.5\\times 10^4$ rubidium atoms at a temperature below 100 nK in less than 4 seconds. Our experiment paves the way for the development of quantum sensors applied to fundamental physics and geodesy as well as the study of ultracold atomic physics in Space.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16645v1",
        "authors": [
          "Julien Le Mener",
          "Clement Metayer",
          "Vincent Jarlaud",
          "Celia Pelluet",
          "Baptiste Battelier"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.263182"
    },
    {
      "id": "arxiv-2602.16632v1",
      "title": "Understanding the influence of yttrium on the dominant twinning mode and local mechanical field evolution in extruded Mg-Y alloys",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16632v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Twinning is a primary deformation mechanism in Mg alloys. This study focuses on tension twins during uniaxial compression of Mg-Y alloys, with three key aspects: the orientation specificity of twin grains, the relative evolution of CRSS with increasing Y content, and the local stress and strain evolution at twin sites. Experimental characterization and crystal plasticity modeling were performed. In Mg-7wt.%Y, TT2-{112-1} tension twins were observed in addition to the common TT1-{101-2} twins. Increasing Y suppressed TT1 formation while promoting TT2 activity. A previously unreported group of crystallographic orientations with a higher global Schmid factor for <c+a> slip was identified, which exhibited TT1 twinning with increasing compression strain. To elucidate Y effects on twin activity and local mechanical fields, both TT1 and TT2 tension twin modes were incorporated into PRISMS-Plasticity, an open-source, finite element-based crystal plasticity solver. Four binary Mg-Y alloys were modeled under compression, and statistical analysis was conducted to correlate initial orientations, stress-strain distributions, and twin activities as functions of Y concentration. The plasticity analysis revealed that increasing Y decreases the CRSS ratio of prismatic and pyramidal slip relative to TT1 twinning, while the slip-to-twin CRSS ratio for TT2 increases, thereby serving as a potential indicator of differential twin activity with Y addition in Mg alloys. Additionally, despite their small volume fraction, TT2 twin sites were predicted higher local strain accumulation locally, relative to the representative volume element and TT1 twins, suggesting their potential influence on localized phenomena such as recrystallization or twin nucleation. These findings provide insight into local mechanical behavior in Mg alloys and support alloy design for advanced engineering applications.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16632v1",
        "authors": [
          "Chaitali Patil",
          "Qianying Shi",
          "Abhishek Kumar",
          "Veera Sundararaghavan",
          "John Allison"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "PRISMS",
        "In Mg",
        "CRSS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.263780"
    },
    {
      "id": "arxiv-2602.16624v1",
      "title": "Measurement of the Saturation Length of the Self-Modulation Instability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16624v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The self-modulation (SM) instability transforms a long charged particle bunch traveling in plasma into a train of microbunches that resonantly drives large-amplitude wakefields. We present the first determination of the saturation length of SM using experimental and numerical results. The saturation length is the distance over which wakefields reach their maximum amplitude along the plasma. By varying the plasma length and measuring the radius of the transverse distribution of the bunch, we find that the saturation length of SM decreases with plasma density and initial field amplitude, e.g., when seeding. The saturation length is a fundamental parameter of the instability, and these results are key for understanding SM and designing plasma wakefield accelerators driven by long bunches, such as AWAKE, or by long laser pulses for radiation production.",
        "keywords": [
          "physics.plasm-ph",
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16624v1",
        "authors": [
          "A. Clairembaud",
          "M. Turner",
          "M. Bergamaschi",
          "L. Ranc",
          "F. Pannell"
        ],
        "arxiv_categories": [
          "physics.plasm-ph",
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Saturation Length",
        "AWAKE",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.264104"
    },
    {
      "id": "arxiv-2602.16577v1",
      "title": "Piezoelectric MEMS Phase Modulator for Silicon Nitride Platform in the Visible Spectrum",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16577v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Active photonic integrated circuits (PICs) in the visible spectrum are essential for on-chip applications, requiring low-loss waveguides with broad transparency and efficient, low-power phase modulation. Here, we demonstrate a compact, ultra-low-power phase modulator based on a silicon nitride (Si$_3$N$_4$) waveguide integrated with thin-film lead zirconate titanate (PZT) that actuates a bridge-type MEMS. The suspended actuator exploits PZT's strong piezoelectric effect to induce mechanically driven phase shifts, enabling efficient modulation in a Mach--Zehnder interferometer. For 3~mm and 5~mm modulators, phase shifts of $1.45π$ and $2.5π$ are achieved at 10~V, corresponding to a scalability metric ($V_π\\cdot L$) of 2.25~V$\\cdot$cm at 635~nm. This represents an order-of-magnitude improvement in scalability over stress-optic PZT modulators. The devices also exhibit ultralow power consumption ($\\sim 12\\,\\mathrm{nW}$), $\\sim 5\\,\\mathrm{ms}$ rise time, and optical loss $< 0.75\\,\\mathrm{dB/cm}$. Furthermore, we demonstrate on-chip beam shaping.",
        "keywords": [
          "physics.optics",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16577v1",
        "authors": [
          "Firehun T. Dullo",
          "Paul C. Thrane",
          "Nikhil Jayakumar",
          "Zeljko Skokic",
          "Christopher A. Dirdal"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Silicon Nitride Platform",
        "Visible Spectrum Active",
        "Phase Modulator",
        "MEMS",
        "PZT",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.265073"
    },
    {
      "id": "arxiv-2602.16563v1",
      "title": "Continuous and discontinuous realizations of first-order phase transitions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16563v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "First-order phase transitions are commonly associated with a discontinuous behavior of some of the thermodynamic variables and the presence of a latent heat. In the present study it is shown that this is not necessarily the case. Using standard thermodynamics, the general characteristics of phase transitions are investigated, considering an arbitrary number of conserved particle species and coexisting phases, and an arbitrary set of state variables. It is found that there exist two different possible types of realizations of a phase transition. In the first type, one has the immediate replacement of a single phase with another one. As a consequence, some of the global extensive variables indeed behave discontinuously. In the second type, one has instead the gradual (dis-) appearance of a single phase over a range of the state variables. This leads to a continuous behavior of the (global) basic thermodynamic variables. Furthermore, in this case it is not possible to define a latent heat in a trivial manner. It is derived that the latter (former) case happens if the number of extensive state variables used is larger or equal (lower) than the number of coexisting phases. The choice of the state variables thus place a crucial role for the qualitative properties of the phase transition.",
        "keywords": [
          "physics.class-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16563v1",
        "authors": [
          "Matthias Hempel"
        ],
        "arxiv_categories": [
          "physics.class-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.265556"
    },
    {
      "id": "arxiv-2602.16542v1",
      "title": "Laboratory observation of collective beam-plasma instabilities in a relativistic pair jet",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16542v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We report on a measurement of collective behavior in a relativistic electron-positron pair plasma produced in the laboratory. Using the Fireball platform at CERN's HiRadMat facility, 440 GeV protons were used to generate an ultra-relativistic, charge-neutral electron-positron pair beam that propagated through an ambient RF discharge plasma. Magnetic-field amplification due to a beam-plasma instability was diagnosed using a high-sensitivity Faraday-rotation probe, supported by detailed characterization of the diagnostic impulse response. The measured path-integrated magnetic field agrees quantitatively with predictions from particle-in-cell simulations. The results provide a critical benchmark for models of relativistic beam-plasma interactions in astrophysical contexts such as blazar jets and pulsar-wind nebulae.",
        "keywords": [
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16542v1",
        "authors": [
          "J W D Halliday",
          "C D Arrowsmith",
          "A M Goillot",
          "P J Bilbao",
          "P Simon"
        ],
        "arxiv_categories": [
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Laboratory",
        "Wind",
        "CERN",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.265887"
    },
    {
      "id": "arxiv-2602.16535v1",
      "title": "Metasurface-encoded optical neural network wavefront sensing for high-speed adaptive optics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16535v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Free-space optical communications with moving targets, such as satellite terminals, demand ultrafast wavefront sensing and correction. This is typically addressed using a Shack-Hartmann sensor, which pairs a high-speed camera with a lenslet array, but such systems add significant cost, weight, and power demands. In this work, we present a hybrid opto-electric neural network (OENN) wavefront sensor that enables ultra-high-speed operation in a compact, low-cost system. Subwavelength diffractive metasurfaces efficiently encode the incoming wavefront into tailored irradiance patterns, which are then decoded by a lightweight multilayer perceptron (MLP). In simulation and experiment, the hybrid approach achieves average Strehl ratio (SR) improvements exceeding 60% and 45%, respectively, for unseen wavefronts compared to purely electronic sensors with few-pixel inputs. Although larger MLPs allow purely electronic sensors to match the hybrid's SR under static conditions, transient atmosphere modeling shows that their added latency leads to rapid SR degradation with increasing Greenwood frequency, while the hybrid system maintains performance. These results highlight the potential of hybrid OENN architectures to unlock scalable, high-bandwidth free-space communication systems and, more broadly, to advance optical technologies where real-time sensing is constrained by electronic latency.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16535v1",
        "authors": [
          "Arturo Martin Jimenez",
          "Dylan Brancato",
          "Marc Baltes",
          "Jackson Cornelius",
          "Neset Akozbek"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "Satellite",
        "Meta",
        "OENN",
        "Act",
        "MLP",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.266273"
    },
    {
      "id": "arxiv-2602.16529v1",
      "title": "Thermal Decoherence and Population Transfer of MeV Channeling Electrons in Diamond",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16529v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Channeling radiation in oriented crystals arises from transitions between quantized transverse bound states in the MeV regime and is strongly affected by thermal diffuse scattering through population transfer and decoherence. A frozen-phonon multislice propagation framework is developed to track a reduced transverse Hilbert space spanned by selected bound-state manifolds using configuration-resolved projection amplitudes. Beyond reproducing transition energies, the method yields reduced manifold density matrices, thermal population kinetics, and depth-resolved coherence metrics. Applied to axial electron channeling in $\\langle100\\rangle$ diamond at 16.9 MeV, the results show approximately exponential population loss with strongly state-dependent feeding among low-lying manifolds. For an initial coherent superposition in the degenerate 2p manifold, the intra-manifold purity relaxes toward the maximally mixed limit, consistent with thermally induced random basis rotations. Under 1s initial excitation, population transferred into the 2p and 3d manifolds remains close to maximally mixed, while weak cross-manifold coherences persist. The framework enables quantitative analysis of thermal population dynamics, decoherence, and their links to spontaneous and coherently driven emission observables across a broad range of crystal structures.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16529v1",
        "authors": [
          "Tadas Paulauskas"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Channeling Electrons",
        "Population Transfer",
        "Diamond Channeling",
        "Framework",
        "BERT",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.266637"
    },
    {
      "id": "arxiv-2602.16461v1",
      "title": "An Integrated Ultralow Noise Spiral Interferometric Laser",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16461v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Photonic integration offers the potential to bring complex high-performance optical systems to the form factor of a compact semiconductor chip. However, the range of system functions accessible critically depends on the extent to which free-space and fiber components can be made integrable. The ultralow-expansion cavity-stabilized laser$-$often used in precision metrology, high-resolution sensors, and advanced systems in atomic physics$-$is one component that currently has no direct parallel on chip. Lasers stabilized to photonically-integrated resonators exist, but exhibit considerably higher frequency noise and are accompanied by large levels of frequency drift. We demonstrate here a new architecture for an ultranarrow linewidth integrated laser based on stabilization to a sinusoidal fringe of an interferometer having a long 25-m unbalanced delay line. Our interferometric laser not only advances the state-of-the-art for on-chip lasers, but we in addition introduce an amplitude locking scheme that greatly suppresses the laser's long-term frequency wander. We achieve a record on-chip fractional frequency noise of $5.6 \\times 10^{-14}$, corresponding to a linewidth of 12 Hz centered at 1348 nm. To showcase the utility of this laser, we divide the optical carrier to microwave frequencies, demonstrating the ability to outperform state-of-the-art quartz crystal oscillators by 15 dB or more.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16461v1",
        "authors": [
          "William Loh",
          "David Reens",
          "Dave Kharas",
          "Alkesh Sumant",
          "Connor Belanger"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spiral Interferometric Laser Photonic",
        "An Integrated Ultralow Noise",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.267118"
    },
    {
      "id": "arxiv-2602.16350v1",
      "title": "Quantum-enhanced sensing via spectral noise reduction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16350v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We report a direct demonstration of quantum-enhanced sensing in the Fourier domain by comparing single- and two-photon interference in a fiber-based interferometer under strictly identical noise conditions. The simultaneous acquisition of both signals provides a common-mode reference that enables a fair and unambiguous benchmark of quantum advantage. Spectral analysis of the interferometric outputs reveals that quantum correlations do not increase the amplitude of the modulation peak, but instead lower the associated noise floor, resulting in the expected 3 dB improvement in signal-to-noise ratio. This enhancement persists in the sub-shot-noise regime, where the classical signal becomes buried in the spectral background while the two-photon contribution remains resolvable. These observations establish Fourier-domain quantum super-sensitivity as an operational and broadly applicable resource for precision interferometric sensing.",
        "keywords": [
          "quant-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16350v1",
        "authors": [
          "Romain Dalidet",
          "Sébastien Tanzilli",
          "Audrey Dot",
          "Inès Ghorbel",
          "Loïc Morvan"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.267468"
    },
    {
      "id": "arxiv-2602.16344v1",
      "title": "Modelling and Analysis of Mechanical and Thermal Response of an Ultrastable, Dual-Axis, Cubic Cavity for Terrestrial and Space Applications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16344v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Transportable all-optical atomic clocks represent the next-generation devices for precision time keeping, ushering a new era in encompassing a wide range of PNT (Positioning, Navigation and Timing) applications in the civil and strategic sectors. Their performance relies on ultra-stable, narrow-linewidth lasers, frequency stabilized to a compact portable optical cavity. Among various designs, the cubic spacer-based ultra-stable cavity is particularly well-suited for transportable applications due to its low sensitivity to vibrations, owing to its symmetric geometry and robust mounting structure. While longer cavities offer a lower fundamental thermal noise floor, one needs to strike a balance between transportability and size. In this aspect, the 7.5 cm dual-axis cubic cavity offers a lower fundamental thermal noise floor in comparison to smaller counterparts, while still retaining a reasonable SWaP (Size, Weight and Power) for terrestrial and aerial PNT applications. Its dual-axis design also enables multi-wavelength laser stabilization, making it a promising candidate for future transportable clock applications. This work presents a detailed study of the 7.5 cm dual-axis cubic cavity using FEM (Finite Element Method) to evaluate its mechanical and thermal stability. We analyze the impact of various geometric factors, mounting forces, and machining imperfections, while also modelling thermal effects such as conduction, radiation, and mirror heating within a vacuum chamber and thermally shielded environment. Our findings provide design insights for developing robust dual-axis optical reference cavities, advancing the deployment of portable atomic clocks for next-generation applications in PNT, geodesy, VLBI (Very Long Baseline Interferometry) and deep space missions.",
        "keywords": [
          "physics.optics",
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16344v1",
        "authors": [
          "Himanshu Miriyala",
          "Rishabh Pal",
          "Arijit Sharma"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Very Long Baseline Interferometry",
        "Space Applications Transportable",
        "Finite Element Method",
        "Cubic Cavity",
        "VLBI",
        "FEM",
        "PNT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.267958"
    },
    {
      "id": "arxiv-2602.16297v1",
      "title": "Characterization of an MPPC-Based Scintillator Telescope and Measurement of Cosmic Muon Angular Distribution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16297v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This report presents the design, characterization, and application of a high-sensitivity optical detection system based on plastic scintillators coupled to Multi-Pixel Photon Counters (MPPCs). The primary objective was to evaluate the performance of MPPCs (Silicon Photomultipliers) as robust, low-voltage alternatives to traditional photomultiplier tubes for detecting faint scintillation light. The optoelectronic properties of the sensors were analyzed, including single-photoelectron gain calibration and dark count rate measurements, to optimize the signal-to-noise ratio. By embedding wavelength-shifting fibers to enhance light collection efficiency, the system was configured into a three-fold coincidence telescope. The angular distribution of the cosmic ray muon flux was measured to validate the detector's stability and geometric acceptance. Fitting the experimental data to a $\\bm{\\cos^n(θ)}$ distribution yielded an angular exponent of $\\bm{n = 1.44 \\pm 0.06}$, consistent with literature values. These results demonstrate the efficacy of the MPPC-scintillator coupling for precise photon counting and timing applications in high-energy physics instrumentation.",
        "keywords": [
          "physics.ins-det",
          "astro-ph.IM",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16297v1",
        "authors": [
          "Sahla Manithottathil",
          "Anuj Gupta",
          "Mudit Kumar",
          "Navaneeth Poonthottathil"
        ],
        "arxiv_categories": [
          "physics.ins-det",
          "astro-ph.IM",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cosmic Muon Angular Distribution",
        "Based Scintillator Telescope",
        "Silicon Photomultipliers",
        "Pixel Photon Counters",
        "MPPC",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.268741"
    },
    {
      "id": "arxiv-2602.16276v1",
      "title": "Birefringence-Driven Anisotropic $α$-MoO3 Optical Cavities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16276v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Many anisotropic layered materials, despite their strong in-plane birefringence, exhibit substantial visible absorption, which severely restricts cavity lengths and hinders the observation of purely birefringence-governed optical phenomena. Here, we realize a birefringence-driven anisotropic optical cavity using $α$-MoO3 flakes, capitalizing on their ultralow optical loss and pronounced in-plane birefringence. Using angle-resolved polarized Raman (ARPR) spectroscopy, we observe a mode-sensitive enhancement of anisotropy, dependent on both flake thickness and Raman shift. A unified model that incorporates the intrinsic Raman tensor, birefringence, and chromatic dispersion accurately reproduces the experimental data, elucidating how cavity resonances at both excitation and scattered wavelengths interact. Within this framework, the intrinsic phonon anisotropy is quantified, providing invaluable insights for accurately predicting ARPR responses and identifying crystallographic orientation. This work provides fundamental insights into birefringence-governed cavities and opens avenues for high-performance birefringent optics and cavity-enhanced anisotropic phenomena.",
        "keywords": [
          "physics.optics",
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16276v1",
        "authors": [
          "Jia-Liang Xie",
          "Ting-Ting Wang",
          "Chen-Kai Liu",
          "Rui Mei",
          "Li-Fa Zhang"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Optical Cavities Many",
        "Driven Anisotropic",
        "Framework",
        "ARPR",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.269502"
    },
    {
      "id": "arxiv-2602.16247v1",
      "title": "Breaking the Moss rule",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16247v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Photonic devices depend critically on the dielectric materials from which they are made, with higher refractive indices and lower absorption losses enabling new functionalities and higher performance. However, these two material properties are intrinsically linked through the empirical Moss rule, which states that the refractive index of a dielectric decreases as its band gap energy increases. Materials that surpass this rule, termed super-Mossian dielectrics, combine large refractive indices with wide optical transparency and are therefore ideal candidates for advanced photonic applications. This Review surveys the expanding landscape of high-index dielectric and semiconductor materials, with a particular focus on those that surpass the Moss rule. We discuss how electronic band structures with a large joint density of states near the band edge give rise to super-Mossian behavior and how first-principles computational screening can accelerate their discovery. Finally, we establish how the refractive index sets the performance limits of nanoresonators, waveguides, and metasurfaces, highlighting super-Mossian dielectrics as a promising route toward the next performance leap in photonic technologies.",
        "keywords": [
          "physics.optics",
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16247v1",
        "authors": [
          "Søren Raza",
          "Kristian Sommer Thygesen",
          "Gururaj Naik"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.269834"
    },
    {
      "id": "arxiv-2602.16213v1",
      "title": "Graph neural network for colliding particles with an application to sea ice floe modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16213v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper introduces a novel approach to sea ice modeling using Graph Neural Networks (GNNs), utilizing the natural graph structure of sea ice, where nodes represent individual ice pieces, and edges model the physical interactions, including collisions. This concept is developed within a one-dimensional framework as a foundational step. Traditional numerical methods, while effective, are computationally intensive and less scalable. By utilizing GNNs, the proposed model, termed the Collision-captured Network (CN), integrates data assimilation (DA) techniques to effectively learn and predict sea ice dynamics under various conditions. The approach was validated using synthetic data, both with and without observed data points, and it was found that the model accelerates the simulation of trajectories without compromising accuracy. This advancement offers a more efficient tool for forecasting in marginal ice zones (MIZ) and highlights the potential of combining machine learning with data assimilation for more effective and efficient modeling.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16213v1",
        "authors": [
          "Ruibiao Zhu"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "cs.CV",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Graph Neural Networks",
        "Machine Learning",
        "Neural Network",
        "Framework",
        "MIZ",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.270216"
    },
    {
      "id": "arxiv-2602.16180v1",
      "title": "Inverse Engineering of Optical Constants in Photochromic Micron-Scale Hybrid Films",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16180v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Photochromic materials enable dynamic optical modulation through reversible transitions between distinct absorption states, with broad potential for smart windows, adaptive optics, and reconfigurable photonic devices. Micron-scale photochromic hybrid films present a particularly attractive platform for these applications, combining straightforward preparation with substantial optical modulation and scalability for high-volume fabrication. However, rational design of such films remains fundamentally constrained by the absence of well-defined optical constants. Unlike homogeneous thin films, micron-scale hybrid photochromic materials comprise active particles dispersed non-uniformly within polymer matrices. Conventional first-principles electromagnetic simulations face substantial computational costs and discrepancies between simulated and experimental particle distributions. Here, we introduce a data-driven framework that extracts effective optical constants directly from minimal experimental transmittance measurements. Our dual-state effective model approximates the complex inhomogeneous photochromic layer as a compressed homogeneous medium characterized by pseudo-refractive indices and pseudo-extinction coefficients for both pristine and UV-irradiated states. Through systematic optimization against experimental data from tungsten oxide-polyvinylpyrrolidone hybrid films, we determine wavelength-dependent pseudo-optical constants and compression ratios that enable accurate prediction of optical modulation within the tested thickness range. Our methodology establishes a framework for engineering hybrid photochromic systems and demonstrates how data-driven modeling can overcome limitations in characterizing complex nanostructured materials.",
        "keywords": [
          "physics.comp-ph",
          "physics.app-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16180v1",
        "authors": [
          "Bahrem Serhat Danis",
          "Amin Tabatabaei Mohseni",
          "Smagul Karazhanov",
          "Esra Zayim"
        ],
        "arxiv_categories": [
          "physics.comp-ph",
          "physics.app-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scale Hybrid Films Photochromic",
        "Inverse Engineering",
        "Photochromic Micron",
        "Optical Constants",
        "Framework",
        "Wind",
        "EPA",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.270664"
    },
    {
      "id": "arxiv-2602.16114v1",
      "title": "Flat-top solitons and anomalous interactions in media with even-order dispersions and competing nonlinearities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16114v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Flat-top (FT) solitons are optical pulses that arise from the balance of dispersion and self-phase modulation in media with the competing cubic-quintic nonlinearity. Previously, FT solitons were studied only in the case of the second-order dispersion ($m=2$). Following the recent observation of pure-quartic solitons (corresponding to $m=4$), we here construct families of FT solitons in the setting with pure-high-even-order dispersion (PHEOD), including $m=4,6,8$, and $10$, and address interactions between them. The PHEOD solitons are completely stable, and, unlike the conventional solitons, they feature oscillatory tails. Interactions between the PHEOD solitons are anomalous, featuring repulsion and attraction between in- and out-of-phase solitons, respectively. These results expand the variety of optical solitons maintained by diverse dispersive nonlinear media.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16114v1",
        "authors": [
          "Xueqing He",
          "Shijie Hao",
          "Lijing Xing",
          "Dumitru Mihalache",
          "Boris A. Malomed"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "PHEOD",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.270943"
    },
    {
      "id": "arxiv-2602.16079v1",
      "title": "Chem-SIM: Super-resolution Chemical Imaging via Photothermal Modulation of Structured-Illumination Fluorescence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16079v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Structured illumination microscopy (SIM) has attained high spatiotemporal delineation of subcellular architecture, yet offers limited insight into chemical composition. Here, we present Chem-SIM, a structured-illumination fluorescence detected mid-infrared photothermal microscopy, for super-resolution chemical imaging of microorganisms and mammalian cells. A computational pipeline combining Poisson maximum-likelihood demodulation and spectral normalization across wavenumber is implemented to robustly recover the weak IR-induced fluorescence intensity change under low photon budgets and convert the fluorescence intensity modulation to chemical fingerprints. A photothermal gating scheme further rejects water backgrounds in aqueous samples, while the IR pump maintains cellular activity at near-physiological temperature. Chem-SIM preserves full vibrational fingerprints, achieves SIM-grade lateral resolution, and operates in a high-throughput, camera-based format with minimal modifications and low photothermal load. At the single-bacterium level, Chem-SIM distinguishes stationary phase from log phase cells through chemical content mapping. In ovarian cancer cells, Chem-SIM delivers readouts of lipid chemistry under deuterium fatty acid treatment and resolves lipid droplets dynamics in live cells. Together, Chem-SIM provides an accessible route to super-resolved mapping of organelle chemistry, metabolism, and dynamics.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16079v1",
        "authors": [
          "Dashan Dong",
          "Danchen Jia",
          "Xinyan Teng",
          "Jianpeng Ao",
          "George Abu-Aqil"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Illumination Fluorescence Structured",
        "Photothermal Modulation",
        "Chemical Imaging",
        "Meta",
        "IoT",
        "SIM",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.271344"
    },
    {
      "id": "arxiv-2602.16074v1",
      "title": "Melting Coulomb clusters through nonreciprocity-enhanced parametric pumping",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16074v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Complex systems out of equilibrium often experience intermittent oscillations between quiescent and highly dynamic states. The type of intermittency depends on how energy is pumped into the system, and how it is dissipated. While intermittency is usually driven by stochastic noise or external forcing, energy can also be sourced from field-mediated interactions between particles, which are often nonreciprocal and effectively violate Newton's 3rd law. Here we demonstrate how nonreciprocal interactions produce intermittency in clusters of charged micron-sized particles confined in a plasma sheath. Through three-dimensional particle tracking, we observe that vertical oscillations, induced by fluctuations of the plasma environment, can be parametrically coupled to the horizontal modes. Experiments and simulations show that nonreciprocal interactions strongly amplify this parametric coupling, creating a positive feedback loop that drives explosive growth of both the horizontal and vertical modes. This mechanism triggers abrupt melting transitions from an ordered cluster to an ergodic gas-like state, and leads to intermittent switching between states over long time scales. Overall, our work identifies nonreciprocal interactions as a key mechanism through which strongly coupled finite systems transform interaction-mediated activity into dynamical nonequilibrium states.",
        "keywords": [
          "cond-mat.soft",
          "physics.plasm-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16074v1",
        "authors": [
          "Zhicheng Shu",
          "Wei-Chih Li",
          "Wentao Yu",
          "Justin C. Burton"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.plasm-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Melting Coulomb",
        "NSF",
        "Act",
        "MIT",
        "WTO"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.271721"
    },
    {
      "id": "arxiv-2602.16058v1",
      "title": "Finding Molecules with Specific Properties: Simulated Annealing vs. Evolution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16058v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We compare the ability of a simulated annealing program and an evolutionary algorithm to find molecules with large molecular average hyperpolarizabilities. This property is an important component of nonlinear optical materials. Both optimization programs represent molecules as SMILES strings, a method that is widely used by chemists to describe molecular structure using short ASCII strings. Our results suggest that both approaches are comparable and can be used to solve a variety of more realistic problems of interest to chemists and material scientists.",
        "keywords": [
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16058v1",
        "authors": [
          "Dominic Mashak",
          "S. A. Alexander"
        ],
        "arxiv_categories": [
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Specific Properties",
        "Simulated Annealing",
        "Finding Molecules",
        "Evolution We",
        "SMILES",
        "ASCII"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.271925"
    },
    {
      "id": "arxiv-2602.16044v1",
      "title": "Multi-Objective Evolutionary Design of Molecules with Enhanced Nonlinear Optical Properties",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16044v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nonlinear optical (NLO) materials are essential for many photonic, telecommunication, and laser technologies, yet discovering better NLO molecules is computationally challenging due to the vast chemical space and competing objectives. We compare evolutionary algorithms for molecular design, targeting four objectives: maximizing the ratio of first-to-second hyperpolarizability $(β/γ)$, optimizing HOMO-LUMO gap and linear polarizability to target ranges, and minimizing energy per atom. We encode molecules as SMILES strings and evaluate their properties using quantum-chemical calculations. We compare NSGA-II, MAP-Elites, MOME, a single-objective $(μ+λ)$ evolutionary algorithm, and simulated annealing. Quality diversity methods maintain archives across a measure space defined by atom and bond count, enabling the discovery of structurally diverse molecules. Our results demonstrate that NSGA-II consistently earns high scores in every objective, leading to high-quality molecules, but MOME does a better job exploring a wide range of possibilities, resulting in higher global hypervolume and MOQD scores. However, each method has strengths and weaknesses, and produced many promising molecules.",
        "keywords": [
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16044v1",
        "authors": [
          "Dominic Mashak",
          "Jacob Schrum",
          "S. A. Alexander"
        ],
        "arxiv_categories": [
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enhanced Nonlinear Optical Properties",
        "Objective Evolutionary Design",
        "SMILES",
        "LUMO",
        "MOME",
        "HOMO",
        "NSGA",
        "MOQD",
        "MAP",
        "NLO",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.272716"
    },
    {
      "id": "arxiv-2602.16003v1",
      "title": "Dynamic Synaptic Modulation of LMG Qubits populations in a Bio-Inspired Quantum Brain",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16003v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present a biologically inspired quantum neural network that encodes neuronal populations as fully connected qubits governed by the Lipkin-Meshkov-Glick (LMG) quantum Hamiltonian and stabilized by a synaptic-efficacy feedback implementing activity-dependent homeostatic control. The framework links collective quantum many-body modes and attractor structure to population homeostasis and rhythmogenesis, outlining scalable computational primitives -- stable set points, controllable oscillations, and size-dependent robustness -- that position LMG-based architectures as promising blueprints for bio-inspired quantum brains on future quantum hardware.",
        "keywords": [
          "quant-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16003v1",
        "authors": [
          "J. J. Torres",
          "E. Romera"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dynamic Synaptic Modulation",
        "Inspired Quantum Brain We",
        "Neural Network",
        "Framework",
        "Act",
        "MIT",
        "LMG",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.272934"
    },
    {
      "id": "arxiv-2602.16002v1",
      "title": "The Beauty of Mathematics in Helfrich's Biomembrane Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16002v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "It is with great regret that Prof. Wolfgang Helfrich passed away on 28 September 2025 in Berlin. As the founder of the membrane liquid crystal model, Prof. Helfrich made outstanding contributions to membrane physics and liquid crystal display technology. This review article is written in his memory. Biomembranes, primarily composed of lipid bilayers, are not merely passive barriers but dynamic and complex materials whose shapes are governed by the principles of soft matter physics. This review explores the shape problem in biomembranes through the lens of material science and liquid crystal theory. Beginning with classical analogies to crystals and soap bubbles, it details the application of the Helfrich elastic model to explain the biconcave shape of red blood cells. The discussion extends to multi-layer systems, drawing parallels between the focal conic structures of smectic liquid crystals, the geometries of fullerenes and carbon nanotubes, and the reversible transitions in peptide assemblies. Furthermore, it examines icosahedral self-assemblies and shape formation in two-dimensional lipid monolayers at air/water interfaces. At the end of the paper, we find that the shapes such as cylinders, spheres, tori, bicocave discoids and Delaunay surfaces form a group. This result is merely an intrinsic geometric feature of these shapes and is independent of the biomembrane equation. When the pressure on the membrane, surface tension, and bending modules meet certain conditions, the biomembrane will take on these shapes. The review concludes by highlighting the unifying power of continuum elastic theories in describing a vast array of membrane morphologies across biological and synthetic systems.",
        "keywords": [
          "physics.comp-ph",
          "physics.bio-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16002v1",
        "authors": [
          "Tao Xu",
          "Zhong-Can Ou-Yang"
        ],
        "arxiv_categories": [
          "physics.comp-ph",
          "physics.bio-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wolfgang Helfrich",
        "WHO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.273344"
    },
    {
      "id": "arxiv-2602.15999v1",
      "title": "Tensor Polarizability of the Nucleus and Angular Mixing in Muonic Deuterium",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15999v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We investigate the effects of the tensor polarizability of a nucleus on thebound-state energy levels, and obtain a general formula for the contribution of the tensor polarizability to the energy levels in two-body bound systems. In particular, it is demonstrated that the tensor polarizability leads to mixing between states with different orbital angular momenta. The effect of tensor polarizability is evaluated for the hyperfine-structure components of P states and for the mixing of S and D states in muonic deuterium.",
        "keywords": [
          "physics.atom-ph",
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15999v1",
        "authors": [
          "G. S. Adkins",
          "U. D. Jentschura"
        ],
        "arxiv_categories": [
          "physics.atom-ph",
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tensor Polarizability",
        "Muonic Deuterium We",
        "Angular Mixing",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.273508"
    },
    {
      "id": "arxiv-2602.15992v1",
      "title": "Properties of a compact neutron supermirror transmission polarizer with an electromagnetic system",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15992v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The paper will present SVAROG, a compact neutron supermirror transmission multichannel polarizer with an electromagnetic system. The basic properties of this polarizer will be considered. Variants for using this polarizer in experimenrtla facilities of the PIK research reactor (Petersburg Nuclear Physics Institute of National Research Centre «Kurchatov Institute» (NRC «Kurchatov Institute» - PNPI)) will be discussed and a comparison of the considered polarizer with known neutron transmission polarizers will be carried out.",
        "keywords": [
          "physics.ins-det",
          "nucl-ex",
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15992v1",
        "authors": [
          "V. G. Syromyatnikov",
          "S. Yu. Semenikhin",
          "M. V. Lasitsa"
        ],
        "arxiv_categories": [
          "physics.ins-det",
          "nucl-ex",
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Petersburg Nuclear Physics Institute",
        "National Research Centre",
        "Kurchatov Institute",
        "Institute",
        "Nuclear",
        "SVAROG",
        "PNPI",
        "NRC",
        "Act",
        "PIK",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.273828"
    },
    {
      "id": "arxiv-2602.15990v1",
      "title": "Memristive tabular variational autoencoder for compression of analog data in high energy physics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15990v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present an implementation of edge AI to compress data on an in-memory analog content-addressable memory (ACAM) device. A variational autoencoder is trained on a simulated sample of energy measurements from incident high-energy electrons on a generic three-layer scintillator-based calorimeter. The encoding part is distilled into tabular format by regressing the latent space variables using decision trees, which is then programmed on a memristor-based ACAM. In real-time, the ACAM compresses 48 continuously valued incoming energies measured by the calorimeter sensors into the latent space, achieving a compression factor of 12x, which is transmitted off-detector for decompression. The performance result of the ACAM, obtained using the Structural Simulation Toolkit, the SST open source framework, gives a latency value of 24 ns and a throughput of 330M compressions per second, i.e., 3 ns between successive inputs, and an average energy consumption of 4.1 nJ per compression.",
        "keywords": [
          "physics.ins-det",
          "hep-ex",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15990v1",
        "authors": [
          "Rajat Gupta",
          "Yuvaraj Elangovan",
          "Tae Min Hong",
          "James Ignowski",
          "John Moon"
        ],
        "arxiv_categories": [
          "physics.ins-det",
          "hep-ex",
          "physics.data-an"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structural Simulation Toolkit",
        "Framework",
        "ACAM",
        "Act",
        "SST",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.274100"
    },
    {
      "id": "arxiv-2602.15946v1",
      "title": "On-chip probabilistic inference for charged-particle tracking at the sensor edge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15946v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Modern scientific instruments operate under increasingly extreme constraints on bandwidth, latency, and power. Inference at the sensor edge determines experimental data collection efficiency by deciding which information to save for further analysis. Particle tracking detectors at the Large Hadron Collider exemplify this challenge: pixelated silicon sensors generate rich spatiotemporal ionization patterns, yet most of this information is discarded due to data-rate limitations. Concurrently, advancements in co-design tools provide rapid turn-around for incorporating machine learning into application-specific integrated circuits, motivating designs for particle detectors with new integrated technologies. We demonstrate that neural networks embedded in the front-end electronics can infer charged-particle kinematic parameters from a single silicon layer. We regress hit positions and incident angles with calibrated uncertainties, while satisfying stringent constraints on numerical precision, latency, and silicon area. Our results establish a path toward probabilistic inference directly at the edge, opening new opportunities for intelligent sensing in high-rate scientific instruments.",
        "keywords": [
          "physics.ins-det",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15946v1",
        "authors": [
          "Arghya Ranjan Das",
          "David Jiang",
          "Rachel Kovach-Fuentes",
          "Shiqi Kuang",
          "Ana Sofía Calle Muñoz"
        ],
        "arxiv_categories": [
          "physics.ins-det",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Hadron Collider",
        "Machine Learning",
        "Neural Network",
        "Intel",
        "IoT",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.274451"
    },
    {
      "id": "arxiv-2602.15939v1",
      "title": "Particle-in-Cell Methods for Simulations of Sheared, Expanding, or Escaping Astrophysical Plasma",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15939v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Particle-in-Cell (PIC) methods have achieved widespread recognition as simple and flexible approaches to model collisionless plasma physics in fully kinetic simulations of astrophysical environments. However, in many situations the standard PIC algorithm must be extended to include macroscopic effects in microscale simulations. For plasmas subjected to shearing or expansion, shearing-box and expanding-box methods can be incorporated into PIC to account for these global effects. For plasmas subjected to local acceleration in confined regions of space, a leaky-box method can allow closed-box PIC simulations to account for particle escape from the accelerator region. In this work, we review and improve methods to include shearing, expansion, and escape in PIC simulations. We provide the numerical details of how Maxwell's equations and the particle equations of motion are solved in each case, and introduce generalized Boris-like particle pushers to solve the momentum equation in the presence of extra forces. This work is intended to serve as a comprehensive reference for the implementation of shearing-box, expanding-box, and leaky-box algorithms in PIC.",
        "keywords": [
          "physics.plasm-ph",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15939v1",
        "authors": [
          "Fabio Bacchini",
          "Evgeny A. Gorbunov",
          "Maximilien Péters de Bonhome",
          "Paul Els",
          "Konstantinos-Xanthos Argyropoulos"
        ],
        "arxiv_categories": [
          "physics.plasm-ph",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Escaping Astrophysical Plasma Particle",
        "Cell Methods",
        "Standard",
        "PIC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.274758"
    },
    {
      "id": "arxiv-2602.15933v1",
      "title": "KPZ-like transport in long-range interacting spin chains proximate to integrability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15933v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Isotropic integrable spin chains such as the Heisenberg model feature superdiffusive spin transport belonging to an as-yet-unidentified dynamical universality class closely related to that of Kardar, Parisi, and Zhang (KPZ). To determine whether these results extend to more generic one-dimensional models, particularly those realizable in quantum simulators, we investigate spin and energy transport in non-integrable, long-range Heisenberg models using state-of-the-art tensor network methods. Despite the lack of integrability and the asymptotic expectation of diffusion, for power-law models (with exponent $2 < α< \\infty$) we observe long-lived $z=3/2$ superdiffusive spin transport and two-point correlators consistent with KPZ scaling functions, up to times $t \\sim 10^3/J$. We conjecture that this KPZ-like transport is due to the proximity of such power-law-interacting models to the integrable family of Inozemtsev models, which we show to also exhibit KPZ-like spin transport across all interaction ranges. Finally, we consider anisotropic spin models naturally realized in Rydberg atom arrays and ultracold polar molecules, demonstrating that a wide range of long-lived, non-diffusive transport can be observed in experimental settings.",
        "keywords": [
          "quant-ph",
          "cond-mat.dis-nn",
          "cond-mat.str-el",
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15933v1",
        "authors": [
          "Sajant Anand",
          "Jack Kemp",
          "Julia Wei",
          "Christopher David White",
          "Michael P. Zaletel"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.dis-nn",
          "cond-mat.str-el",
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "KPZ",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.275470"
    },
    {
      "id": "arxiv-2602.15806v1",
      "title": "Tunable microwave frequency synthesis with optically-derived spectral purity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15806v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Microwave synthesizers are central to test and measurement systems across applications including wireless communications, radar, spectroscopy, and time and frequency metrology. State-of-the-art microwave sources, however, are fundamentally constrained by trade-offs between frequency tunability and spectral purity. Electro-optic frequency division (eOFD) is an emerging technique for dividing down the purity of optical sources to the microwave domain. Previously reported eOFD-based synthesizers generally have limited tunability due to feedback stabilization requirements. Here we demonstrate a feed-forward eOFD architecture in which the frequency tunability of a microwave source is preserved while optical spectral purity is divided through feed-forward cancellation, without any downstream electronic frequency synthesis. By canceling the phase noise of the microwave source without feedback, this eOFD approach removes loop bandwidth and source noise constraints observed in prior eOFD architectures. We achieve octave-spanning tunability, including the entire X-band, with phase noise below -140 dBc/Hz at kilohertz offsets and a high-frequency noise floor between -155 dBc/Hz and -145 dBc/Hz for carrier frequencies from 8 to 16 GHz. This performance corresponds to single-femtosecond integrated timing jitter, enabling, to our knowledge, the first demonstration of coherent, optically referenced microwave synthesis under wide tuning with this level of spectral purity.",
        "keywords": [
          "physics.optics",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15806v1",
        "authors": [
          "James Greenberg",
          "Scott C. Egbert",
          "William F. McGrew",
          "Brendan M. Heffernan",
          "Antoine Rolland"
        ],
        "arxiv_categories": [
          "physics.optics",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.275821"
    },
    {
      "id": "arxiv-2602.15780v1",
      "title": "Deep Learning for Point Spread Function Modeling in Cosmology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15780v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present the development of a data-driven, AI-based model of the Point Spread Function (PSF) that achieves higher accuracy than the current state-of-the-art approach, \"PSF in the Full Field-of-View'' (PIFF). PIFF is widely used in leading weak-lensing surveys, including the Dark Energy Survey (DES), the Hyper Suprime-Cam (HSC) Survey, and the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST). The PSF characterizes how a point source, such as a star, is imaged after its light traverses the atmosphere and telescope optics, effectively representing the \"blurred fingerprint'' of the entire imaging system. Accurate PSF modeling is essential for weak gravitational lensing analyses, as biases in its estimation propagate directly into cosmic shear measurements -- one of the primary cosmological probes of the expansion history of the Universe and the growth of large-scale structure for dark energy studies. To address the limitations of PIFF, which constructs PSF models independently for each CCD and therefore loses spatial coherence across the focal plane, we introduce a deep-learning-based framework for PSF reconstruction. In this approach, an autoencoder is trained on stellar images obtained with the Hyper Suprime-Cam (HSC) of the Subaru Telescope and combined with a Gaussian process to interpolate the PSF across the telescope's full field of view. This hybrid model captures systematic variations across the focal plane and achieves a reconstruction error of $3.4 \\times 10^{-6}$ compared to PIFF's $3.7 \\times 10^{-6}$, laying the foundation for integration into the LSST Science Pipelines.",
        "keywords": [
          "astro-ph.IM",
          "astro-ph.CO",
          "physics.data-an"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15780v1",
        "authors": [
          "Dayana Andrea Henao Arbeláez",
          "Pierre-François Léget",
          "Andrés Alejandro Plazas Malagón"
        ],
        "arxiv_categories": [
          "astro-ph.IM",
          "astro-ph.CO",
          "physics.data-an"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rubin Observatory Legacy Survey",
        "Point Spread Function Modeling",
        "Point Spread Function",
        "Dark Energy Survey",
        "Science Pipelines",
        "Subaru Telescope",
        "Hyper Suprime",
        "Deep Learning",
        "Cosmology We",
        "Full Field",
        "Framework",
        "LSST",
        "PIFF",
        "DES",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.276520"
    },
    {
      "id": "arxiv-2602.15777v1",
      "title": "New Challenges in Plasma Accelerators: Final Focusing for Wakefield Colliders",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15777v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The focusing of particle beams for collider experiments is crucial for maximizing the luminosity and thus the discovery potential of these machines. In recent years, plasma wakefield acceleration has emerged as a leading candidate for achieving higher energy collisions with smaller facility footprints due to the large accelerating gradients in the plasma. This higher beam energy poses significant challenges for the final focusing system of the collider. Here, we discuss the various challenges of final focusing for TeV-scale plasma accelerators and propose possible solutions. Finally, we present the first design of a final focusing system for a 10 TeV linear wakefield collider, evaluate its performance, and discuss its shortcomings as well as improvements for future designs.",
        "keywords": [
          "physics.acc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15777v1",
        "authors": [
          "Keegan Downham",
          "Spencer Gessner",
          "Lewis Kennedy",
          "Rogelio Tomás",
          "Andrei Seryi"
        ],
        "arxiv_categories": [
          "physics.acc-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Plasma Accelerators",
        "Final Focusing",
        "New Challenges"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.276744"
    },
    {
      "id": "arxiv-2602.15762v1",
      "title": "PRISM: Photonics-Informed Inverse Lithography for Manufacturable Inverse-Designed Photonic Integrated Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15762v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent advances in photonic inverse design have demonstrated the ability to automatically synthesize compact, high-performance photonic components that surpass conventional, hand-designed structures, offering a promising path toward scalable and functionality-rich photonic hardware. However, the practical deployment of inverse-designed PICs is bottlenecked by manufacturability: their irregular, subwavelength geometries are highly sensitive to fabrication variations, leading to large performance degradation, low yield, and a persistent gap between simulated optimality and fabricated performance. Unlike electronics, photonics lacks a systematic, flexible mask optimization flow. Fabrication deviations in photonic components cause large optical response drift and compounding error in cascaded circuits, while calibrating fabrication models remains costly and expertise-heavy, often requiring repeated fabrication cycles that are inaccessible to most designers. To bridge this gap, we introduce PRISM, a photonics-informed inverse lithography workflow that makes photonic mask optimization data-efficient, reliable, and optics-informed. PRISM (i) synthesizes compact, informative calibration patterns to minimize required fabrication data, (ii) trains a physics-grounded differentiable fabrication model, enabling gradient-based optimization, and (iii) performs photonics-informed inverse mask optimization that prioritizes performance-critical features beyond geometry matching. Across multiple inverse-designed components with both electron-beam lithography and deep ultra-violet photolithography processes, PRISM significantly boosts post-fabrication performance and yield while reducing calibration area and turnaround time, enabling and democratizing manufacturable and high-yield inverse-designed photonic hardware at scale.",
        "keywords": [
          "physics.optics",
          "cs.ET"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15762v1",
        "authors": [
          "Hongjian Zhou",
          "Haoyu Yang",
          "Nicholas Gangi",
          "Tianle Xu",
          "Rena Huang"
        ],
        "arxiv_categories": [
          "physics.optics",
          "cs.ET"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Designed Photonic Integrated Circuits",
        "Informed Inverse Lithography",
        "Manufacturable Inverse",
        "PRISM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.277169"
    },
    {
      "id": "arxiv-2602.15760v1",
      "title": "Polarization-resolved measurement of forward volume spin waves by micro-focused Brillouin light scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15760v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We show how the micro-focused BLS signal of forward volume spin waves is formed and why it remains observable despite symmetry-based \"suppression\" expectations. A reciprocity-theorem based model with vectorial diffraction-limited focusing identifies the nonnegligible longitudinal focal-field component as the key element responsible for BLS sensitivity in the forward volume geometry. We further demonstrate that full polarization analysis, implemented through polarizer-analyzer maps of coherently excited spin waves, provides information beyond the conventional crossed polarizer-analyzer readout. In a BiYIG thin film, the measured maps exhibit Stokes/anti-Stokes polarization asymmetries and nontrivial patterns that stem from quadratic magneto-optical coupling terms. Fitting the data with a model including Voigt and Cotton-Mouton contributions yields an effective Cotton-Mouton constant and shows that the quadratic response is comparable to the linear Voigt contribution.",
        "keywords": [
          "cond-mat.mes-hall",
          "physics.app-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15760v1",
        "authors": [
          "Krzysztof Szulc",
          "Mengying Guo",
          "Ondřej Wojewoda",
          "Hongyu Wang",
          "Dominik Pavelka"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "physics.app-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "BLS",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.277438"
    },
    {
      "id": "arxiv-2602.15759v1",
      "title": "Three-Dimensional Optical-Electrical Simulation of Cs2AgBiBr6 Double Perovskite Solar Cells",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15759v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Despite significant advances in lead-free perovskite photovoltaics, achieving a balance among environmental safety and high optoelectronic performance remains challenging. The inorganic double perovskite Cs2AgBiBr6 has emerged as a promising candidate owing to its robust three-dimensional crystal structure and suitable visible-range bandgap. However, best power conversion efficiencies (PCEs) for Cs2AgBiBr6 solar cells reported so far - 6.37% experimentally and 27.78% in numerical studies - remain below the theoretical performance potential, largely due to suboptimal charge transport layers, and interface-related recombination losses. Here, we address this gap using a 3D finite-element method (FEM) implemented in COMSOL Multiphysics, which couples optical simulations with semiconductor drift-diffusion transport. To our knowledge, this work represents the first comprehensive 3D FEM-based study of a double halide perovskite solar cell. Screening of 25 electron transport layer (ETL)-hole transport layer (HTL) combinations identifies CeO2 and P3HT as the optimal ETL and HTL respectively. Device performance is further analyzed through systematic variation of layer thicknesses, doping concentrations and defect densities within the FTO/CeO2/Cs2AgBiBr6/P3HT/Au architecture. Under optimized parameters, the simulated device achieves a PCE of 31.76%, representing the theoretical upper bound predicted by the model. Overall, this work demonstrates 3D physics-based device engineering as a decisive pathway for overcoming efficiency bottlenecks in lead-free double perovskite photovoltaics.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.app-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15759v1",
        "authors": [
          "Md Shanian Moed",
          "Adnan Amin Siddiquee",
          "Md Tashfiq Bin Kashem"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.app-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Double Perovskite Solar Cells",
        "Electrical Simulation",
        "Dimensional Optical",
        "COMSOL",
        "Fusion",
        "Solar",
        "ETL",
        "FEM",
        "FTO",
        "PCE",
        "HTL",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.277821"
    },
    {
      "id": "arxiv-2602.15741v1",
      "title": "Singular value decomposition to describe bound states in the continuum in periodic metasurfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15741v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding how bound states in the continuum (BICs) emerge in periodic metasurfaces is essential for the controlled design of high-Q resonances and their systematic manipulation. Here, we investigate the singular value decomposition (SVD) of the effective transition matrix and the scattering matrix of periodic metasurfaces within a parameter range where the metasurface sustains a BIC. Our analysis yields general and practically applicable conditions on the singular values and singular vectors that enable BIC formation. At the BIC eigenfrequency, the inverse of the largest singular value of both matrices vanishes, and the corresponding left (right) singular vector is orthogonal to outgoing (incoming) plane waves that propagate in the directions of open diffraction orders. Our SVD-based approach predicts the spectral position of the BIC and provides detailed information about its properties, including the expansion coefficients in the multipole and plane-wave bases, as well as its behavior under perturbations that transform the BIC into a quasi-BIC. The approach is numerically validated by considering both symmetry-protected and accidental BICs in arrays of scatterers supporting electromagnetic or acoustic multipole resonances. The presented SVD framework offers a broadly applicable foundation for engineering BICs and quasi-BICs in complex metasurfaces, potentially enabling new routes for wave-based devices with tailored radiative properties.",
        "keywords": [
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15741v1",
        "authors": [
          "Nikita Ustimenko",
          "Ivan Fernandez-Corbaton",
          "Carsten Rockstuhl"
        ],
        "arxiv_categories": [
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Meta",
        "NSF",
        "Act",
        "SVD",
        "BIC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.278212"
    },
    {
      "id": "arxiv-2602.15723v1",
      "title": "Microscopic Rydberg electron orbit manipulation with optical tweezers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15723v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Laser cooling and trapping of atomic matter waves in optical potentials has enabled rapid progress in quantum science, particularly when combined with Rydberg excitation of the atoms to induce long-range interactions. Here, we propose the local manipulation and spatio-temporal sculpting of the electronic matter wave of a Rydberg atom by a laser field focused so that its beam width is smaller than the Rydberg electron orbit. We compute the electronic eigenstates in the presence of a sharply focused Gaussian laser beam, and find strong Rydberg state mixing leading to large kilo-Debye dipole moments. These can be modulated with high bandwidth controlled by the local tweezer intensity. Oscillations in the position-dependent level shifts, analogous to the potential wells allowing ultralong-range Rydberg molecules to form, provide opportunities to trap the Rydberg atom in an eccentric way via ponderomotive forces acting on sub-orbital length scales.",
        "keywords": [
          "physics.atom-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15723v1",
        "authors": [
          "Homar Rivera-Rodríguez",
          "Matthew T. Eiles",
          "Tilman Pfau",
          "Florian Meinert"
        ],
        "arxiv_categories": [
          "physics.atom-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Microscopic Rydberg",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:42.278469"
    },
    {
      "id": "arxiv-2602.16679v1",
      "title": "Ab Initio Auxiliary-Field Quantum Monte Carlo in the Thermodynamic Limit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16679v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Ab initio auxiliary-field quantum Monte Carlo (AFQMC) is a systematically improvable many-body method, but its application to extended solids has been severely limited by unfavorable computational scaling and memory requirements that obstruct direct access to the thermodynamic and complete-basis-set limits. By combining tensor hypercontraction via interpolative separable density fitting with $\\mathbf{k}$-point symmetry, we reduce the computational and memory scaling of ab initio AFQMC for solids to $O(N^3)$ and $O(N^2)$ with arbitrary basis, respectively, comparable to diffusion Monte Carlo. This enables direct and simultaneous thermodynamic-limit and complete-basis-set AFQMC calculations across insulating, metallic, and strongly correlated solids, without embedding, local approximations, empirical finite-size corrections, or composite schemes. Our results establish AFQMC as a general-purpose, systematically improvable alternative to diffusion Monte Carlo and coupled-cluster methods for predictive ab initio simulations of solids, enabling accurate energies and magnetic observables within a unified framework.",
        "keywords": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16679v1",
        "authors": [
          "Jinghong Zhang",
          "Meng-Fu Chen",
          "Adam Rettig",
          "Tong Jiang",
          "Paul J. Robinson"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Field Quantum Monte Carlo",
        "Ab Initio Auxiliary",
        "Monte Carlo",
        "Framework",
        "Fusion",
        "AFQMC",
        "Meta",
        "EPA",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.328228"
    },
    {
      "id": "arxiv-2602.16617v1",
      "title": "Fluctuation-induced acceleration of inter-ligand exciton transfer in bis(dipyrrinato)Zn(II) complex",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16617v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Exciton transfer dynamics between chromophores depends on excitonic coupling, which is governed by relative orientation between the chromophores. While the excitonic coupling is treated as a static parameter in many cases, structural dynamics can introduce time-dependence on the excitonic coupling. However, influence of the dynamics of excitonic coupling on the exciton transfer has been scarcely understood. In the present study, exciton transfer under dynamical fluctuation in excitonic coupling was investigated via combined use of non-adiabatic molecular dynamics simulations, exciton density analysis, and a simple two-state model, for inter-ligand exciton transfer in bis(dipyrrinato)Zn(II) as the example case. The reaction coordinate for the exciton transfer was obtained a posteriori via regression analysis where the target and explanatory variables are diabatic energy gaps and atomic displacements, respectively. The results suggest that dynamical angular fluctuation between the two dipyrrinato ligands incidentally increase the excitonic coupling, accelerating the exciton transfer between the ligands.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16617v1",
        "authors": [
          "Hiroki Uratani",
          "Hirofumi Sato"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "NSF",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.328693"
    },
    {
      "id": "arxiv-2602.16528v1",
      "title": "Fragment-Based Configuration Interaction: Towards a Unifying Description of Biexcitonic Processes in Molecular Aggregates",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16528v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Biexcitonic states govern singlet fission, triplet-triplet and exciton-exciton annihilation, yet a unified understanding of how these processes compete within a shared electronic manifold remains elusive. We outline a conceptual framework based on fragment-based configuration-interaction that systematically constructs diabatic Hamiltonians spanning the full one-particle (LE, CT) and two-particle (LELE, CTCT, TT, CTX with X = LE, CT, or T) manifolds from monomer-local building blocks, preserving physical interpretability throughout. SymbolicCI provides analytic Hamiltonian matrix elements for efficient large-scale calculations; NOCI-F delivers benchmark-quality couplings. The resulting diabatic Hamiltonians can be coupled to quantum dynamics simulations. Applications to ethylene aggregates and the anthracene crystal reveal CTX configurations as electronic gateways bridging excitonic manifolds, with CT-mediated relaxation pathways competing with conventional annihilation. In H-type aggregates, LECT admixture stabilizes a \"bi-excimer\" analogous to one-particle excimers. By providing first-principles access to biexciton formation, separation, and transport, we hope to stimulate further exchange between electronic structure and quantum dynamics communities toward a predictive understanding of multiexcitonic photophysics.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16528v1",
        "authors": [
          "Johannes E. Adelsperger",
          "Coen de Graaf",
          "Merle I. S. Röhr"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Molecular Aggregates Biexcitonic",
        "Based Configuration Interaction",
        "Biexcitonic Processes",
        "Unifying Description",
        "Framework",
        "NOCI",
        "CTCT",
        "LELE",
        "LECT",
        "EPA",
        "Act",
        "CTX",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.329252"
    },
    {
      "id": "arxiv-2602.16495v1",
      "title": "General formalism, classification, and demystification of the current warp-drive spacetimes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16495v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We critically examine proposals for the so-called warp-drive spacetimes and classify these models based on their various restrictions within the framework of General Relativity. We then provide a summary of general formalism for each class, and in the process, we highlight some misconceptions, misunderstandings, and errors in the literature that have been used to support claims about the physicality and feasibility of these models. On the way, we prove several new no-go theorems. Our analysis shows that when the principles of General Relativity are applied correctly, most claims regarding physical warp drives must be reassessed, and it becomes highly challenging to justify or support the viability of such models, not merely due to the violation of energy conditions.",
        "keywords": [
          "gr-qc",
          "physics.hist-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16495v1",
        "authors": [
          "Hamed Barzegar",
          "Thomas Buchert",
          "Quentin Vigneron"
        ],
        "arxiv_categories": [
          "gr-qc",
          "physics.hist-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "General Relativity",
        "Framework",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.329540"
    },
    {
      "id": "arxiv-2602.16437v1",
      "title": "Mapping tuberculosis fatalities by region and age group in South Korea: A dataset for targeted health policy optimization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16437v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In South Korea, age-disaggregated tuberculosis (TB) data at the district level are not publicly available due to privacy constraints, limiting fine-scale analyses of healthcare accessibility. To address this limitation, we present a high-resolution, district-level dataset on tuberculosis (TB) fatalities and hospital accessibility in South Korea, covering the years 2014 to 2022 across 228 districts. The dataset is constructed using a reconstruction method that infers age-disaggregated TB cases and fatalities at the district level by integrating province-level age-specific statistics with district-level spatial and demographic data, enabling analyses that account for both spatial heterogeneity and age structure. Building on an existing hospital allocation framework, we extend the objective function to an age-weighted formulation and apply it to the reconstructed dataset to minimize TB fatalities under different age-weighting schemes. We demonstrate that incorporating age structure can give rise to distinct optimized hospital allocation patterns, even when the total number of minimized fatalities is similar, revealing trade-offs between efficiency and demographic targeting. In addition, the dataset supports temporal analyses of TB burden, hospital availability, and demographic variation over time, and provides a testbed for spatial epidemiology and optimization studies that require high-resolution demographic and healthcare data.",
        "keywords": [
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16437v1",
        "authors": [
          "Yongsung Kwon",
          "Deok-Sun Lee",
          "Mi Jin Lee",
          "Seung-Woo Son"
        ],
        "arxiv_categories": [
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "In South Korea",
        "South Korea",
        "Framework",
        "Policy",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.330006"
    },
    {
      "id": "arxiv-2602.16417v1",
      "title": "Network geometry of the Drosophila brain",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16417v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The recent reconstruction of the Drosophila brain provides a neural network of unprecedented size and level of details. In this work, we study the geometrical properties of this system by applying network embedding techniques to the graph of synaptic connections. Since previous analysis have revealed an inhomogeneous degree distribution, we first employ a hyperbolic embedding approach that maps the neural network onto a point cloud in the two-dimensional hyperbolic space. In general, hyperbolic embedding methods exploit the exponentially growing volume of hyperbolic space with increasing distance from the origin, allowing for an approximately uniform spatial distribution of nodes even in scale-free, small-world networks. By evaluating multiple embedding quality metrics, we find that the network structure is well captured by the resulting two-dimensional hyperbolic embedding, and in fact is more congruent with this representation than with the original neuron coordinates in three-dimensional Euclidean space. In order to examine the network geometry in a broader context, we also apply the well-known Euclidean network embedding approach Node2vec, where the dimension of the embedding space, $d$ can be set arbitrarily. In 3 dimensions, the Euclidean embedding of the network yields lower quality scores compared to the original neuron coordinates. However, as a function of the embedding dimension the scores show an improving tendency, surpassing the level of the 2d hyperbolic embedding roughly at $d=16$, and reaching a maximum around $d=64$. Since network embeddings can serve as valuable inputs for a variety of downstream machine learning tasks, our results offer new perspectives on the structure and representation of this recently revealed and biologically significant neural network.",
        "keywords": [
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16417v1",
        "authors": [
          "Bendegúz Sulyok",
          "Sámuel G. Balogh",
          "Gergely Palla"
        ],
        "arxiv_categories": [
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.330537"
    },
    {
      "id": "arxiv-2602.16390v1",
      "title": "Hidden universality in dislocation-loops mediated three-dimensional crystal melting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16390v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Understanding why and how crystalline solids melt remains a central problem in condensed-matter physics. Dislocation loops are fundamental topological excitations that control the thermodynamic stability of crystals, yet their role in setting universal aspects of melting has remained unclear. Here we show, within dislocation-mediated melting theory, that the free-energy condition for loop proliferation leads to a universal ratio between the energy of a minimal dislocation loop and the thermal energy at melting. For minimal dislocation loops that begin to proliferate at the onset of melting, this ratio takes the purely geometric value $\\mathcal{E}_* = E_{\\rm loop}/(k_B T_m) \\approx 25.1$, independent of elastic moduli and chemistry-dependent details. This result provides a microscopic explanation for recent empirical findings by Lunkenheimer \\emph{et al.}, who identified a closely related universal energy scale $\\approx 24.6$ from viscosity data. The same framework also rationalizes the empirical $2/3$ rule relating the glass-transition and melting temperatures.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cond-mat.dis-nn",
          "cond-mat.soft",
          "cond-mat.stat-mech",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16390v1",
        "authors": [
          "Alessio Zaccone",
          "Konrad Samwer"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cond-mat.dis-nn",
          "cond-mat.soft",
          "cond-mat.stat-mech",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "WHO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.330902"
    },
    {
      "id": "arxiv-2602.16325v1",
      "title": "A Unified Formulation for $\\langle \\hat{S}^2 \\rangle $ in Two-Component TDDFT",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16325v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Two-component linear-response time-dependent density functional theory (TDDFT) provides a unified framework that encompasses noncollinear excitations in noncollinear reference states, as well as both spin-conserving and spin-flip excitations in collinear reference states. In this work, we present a general formalism for evaluating the expectation value $\\langle \\hat{S}^2 \\rangle$ of electronically excited states obtained within two-component TDDFT. We then derive and analyze specialized forms of the resulting equations for collinear reference determinants, for which the two-component formalism decomposes into conventional spin-conserving and spin-flip TDDFT. The resulting working equations are systematically compared with previously proposed theoretical approaches. On the basis of our analysis, $\\langle \\hat{S}^2 \\rangle$ in the excited states is shown to arise from two distinct sources: (i) $\\langle \\hat{S}^2 \\rangle_0$ in the reference state and (ii) additional $Δ\\langle \\hat{S}^2 \\rangle$ introduced by the excitation process itself. Finally, we evaluate the expectation value $\\langle \\hat{S}^2 \\rangle$ by performing two-component TDDFT calculations based on two-component DFT, unrestricted Kohn-Sham (UKS), and restricted open-shell Kohn-Sham (ROKS) reference states, respectively.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16325v1",
        "authors": [
          "Xiaoyu Zhang"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unified Formulation",
        "Framework",
        "TDDFT",
        "ROKS",
        "UKS",
        "DFT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.331865"
    },
    {
      "id": "arxiv-2602.16282v1",
      "title": "Neutral species facilitate coexistence among cyclically competing species under birth and death processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16282v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Natural birth and death are fundamental mechanisms of population dynamics in ecosystems and have played pivotal roles in shaping population dynamics. Nevertheless, in studies of cyclic competition systems governed by the rock-paper-scissors (RPS) game, these mechanisms have often been ignored in analyses of biodiversity. On the other hand, given the prevalence and profound impact on biodiversity, understanding how higher-order interactions (HOIs) can affect biodiversity is one of the most challenging issues, and thus HOIs have been continuously studied for their effects on biodiversity in systems of cyclic competing populations, with a focus on neutral species. However, in real ecosystems, species can evolve and die naturally or be preyed upon by predators, whereas previous studies have considered only classic reaction rules among three species with a neutral, nonparticipant species. To identify how neutral species can affect the biodiversity of the RPS system when species' natural birth and death are assumed, we consider a model of neutral species in higher-order interactions within the spatial RPS system, assuming birth-and-death processes. Extensive simulations show that when neutral species interfere positively, they dominate the available space, thereby reducing the proportion of other species. Conversely, when the interference is harmful, the density of competing species increases. In addition, unlike traditional RPS dynamics, biodiversity can be effectively maintained even in high-mobility regimes. Our study reaffirms the critical role of neutral species in preserving biodiversity.",
        "keywords": [
          "q-bio.PE",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16282v1",
        "authors": [
          "Yikang Lu",
          "Wenhao She",
          "Xiaofang Duan",
          "Junpyo Park"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "RPS",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.332368"
    },
    {
      "id": "arxiv-2602.16171v1",
      "title": "Self-Organized Bioelectricity via Collective Pump Alignment: Physical Origin of Chemiosmosis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16171v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Chemiosmosis maintains life in nonequilibrium through ion transport across membranes, yet the origin of this order remains unclear. We develop a minimal model in which ion pump orientation and the intracellular electrochemical potential mutually reinforce each other. This model shows that fluctuations can induce collective pump alignment and the formation of a membrane potential. The alignment undergoes a phase transition from disordered to ordered, analogous to the Ising model. Our results provide a self-organizing mechanism for the emergence of bioelectricity, with implications for the origin of life.",
        "keywords": [
          "physics.bio-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16171v1",
        "authors": [
          "Ryosuke Nishide",
          "Kunihiko Kaneko"
        ],
        "arxiv_categories": [
          "physics.bio-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Collective Pump Alignment",
        "Chemiosmosis Chemiosmosis",
        "Organized Bioelectricity",
        "Physical Origin",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.332610"
    },
    {
      "id": "arxiv-2602.16084v1",
      "title": "Evaporation-Induced Pattern Formation and Wetting in Active Microtubule-Kinesin Droplets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16084v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Active networks composed of biopolymers and motor proteins provide versatile biomimetic systems that have advanced active matter physics and deepened our understanding of cytoskeletal dynamics and self-organization under diverse stimuli. In these systems, activity arises in aqueous solutions where motor proteins cross-link biopolymers and generate active stress driving the emergent network behavior. Here, we establish the active network in the form of a sessile, multi-component droplet on a substrate and investigate how evaporation influences its dynamics. We focus on how mass loss and compositional changes in the droplet reshape the behavior of the active suspension. We show that capillary and Marangoni flows drive the self-organization of microtubules into a distinctive radial arrangement within the droplet. The cross-linking ability of motor proteins gives rise to a striking non-monotonic wetting behavior, where the extensile stresses generated by the motor proteins strongly affect the characteristic timescale of the contact-line retracting and subsequent expansion. Using a combined experimental and theoretical approach, we demonstrate the crucial role of crosslinking in evaporating microtubule networks, and explain how active stresses together with evaporation-induced flows govern the dynamics of reconstituted microtubule systems and their wetting behavior. Evaporating droplets have recently attracted significant attention in the scientific community, and the findings of the setup presented in this study can have broad implications, ranging from self-organization and mechanical pattern formation in biological systems to questions about the origin of life.",
        "keywords": [
          "cond-mat.soft",
          "physics.bio-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16084v1",
        "authors": [
          "Vahid Nasirimarekani",
          "Mehrana R. Nejad",
          "Olinka Ramírez-Soto",
          "Susan Ali",
          "Stefan Karpitschka"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "physics.bio-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Induced Pattern Formation",
        "Kinesin Droplets Active",
        "Active Microtubule",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.333115"
    },
    {
      "id": "arxiv-2602.16000v1",
      "title": "Imaging-Derived Coronary Fractional Flow Reserve: Advances in Physics-Based, Machine-Learning, and Physics-Informed Methods",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16000v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Purpose of Review Imaging derived fractional flow reserve (FFR) is rapidly evolving beyond conventional computational fluid dynamics (CFD) based pipelines toward machine learning (ML), deep learning (DL), and physics informed approaches that enable fast, wire free, and scalable functional assessment of coronary stenosis. This review synthesizes recent advances in CT and angiography based FFR, with particular emphasis on emerging physics informed neural networks and neural operators (PINNs and PINOs) and key considerations for their clinical translation. Recent Findings ML/DL approaches have markedly improved automation and computational speed, enabling prediction of pressure and FFR from anatomical descriptors or angiographic contrast dynamics. However, their real-world performance and generalizability can remain variable and sensitive to domain shift, due to multi-center heterogeneity, interpretability challenges, and differences in acquisition protocols and image quality. Physics informed learning introduces conservation structure and boundary condition consistency into model training, improving generalizability and reducing dependence on dense supervision while maintaining rapid inference. Recent evaluation trends increasingly highlight deployment oriented metrics, including calibration, uncertainty quantification, and quality control gatekeeping, as essential for safe clinical use. Summary The field is converging toward imaging derived FFR methods that are faster, more automated, and more reliable. While ML/DL offers substantial efficiency gains, physics informed frameworks such as PINNs and PINOs may provide a more robust balance between speed and physical consistency. Prospective multi center validation and standardized evaluation will be critical to support broad and safe clinical adoption.",
        "keywords": [
          "physics.med-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16000v1",
        "authors": [
          "Tanxin Zhu",
          "Emran Hossen",
          "Chen Zhao",
          "Michele Esposito",
          "Jiguang Sun"
        ],
        "arxiv_categories": [
          "physics.med-ph",
          "cs.LG"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Derived Coronary Fractional Flow",
        "Informed Methods Purpose",
        "Machine Learning",
        "Recent Findings",
        "Review Imaging",
        "Neural Network",
        "Deep Learning",
        "Framework",
        "Standard",
        "Protocol",
        "Act",
        "FFR",
        "CFD",
        "EU",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.333668"
    },
    {
      "id": "arxiv-2602.15793v1",
      "title": "Extending numerical simulations in SIMPSON: Electron paramagnetic resonance, dynamic nuclear polarisation, propagator splitting, pulse transients, and quadrupolar cross terms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15793v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Aimed at the simulation, design, and interpretation of advanced pulse experiments crossing the boundaries between nuclear magnetic resonance (NMR) and electron paramagnetic resonance (EPR), including the rapidly emerging, hybrid discipline of pulsed dynamic nuclear polarisation (DNP), we present a host of novel features in the widely used SIMPSON software package addressing these aspects. Along with this come new features for advanced pulse sequence evaluation in terms of propagator splitting, high-order spin operator cross terms, and pulse phase transients. These fundamental new tools are introduced in a C++-based next generation of the SIMPSON software, which improves calculations speed in some aspects, is better prepared for further developments, and facilitates easier community contributions to the open-source software package.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15793v1",
        "authors": [
          "David L. Goodwin",
          "Jose P. Carvalho",
          "Anders B. Nielsen",
          "Nino Wili",
          "Thomas Vosegaard"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nuclear",
        "EPA",
        "DNP",
        "NMR",
        "EPR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.333952"
    },
    {
      "id": "arxiv-2602.15747v1",
      "title": "How to Train a Shallow Ensemble",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15747v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Shallow ensembles provide a convenient strategy for uncertainty quantification in machine learning interatomic potentials, that is computationally efficient because the different ensemble members share a large part of the model weights. In this work, we systematically investigate training strategies for shallow ensembles to balance calibration performance with computational cost. We first demonstrate that explicit optimization of a negative log-likelihood (NLL) loss improves calibration with respect to approaches based on ensembles of randomly initialized models, or on a last-layer Laplace approximation. However, models trained solely on energy objectives yield miscalibrated force estimates. We show that explicitly modeling force uncertainties via an NLL objective is essential for reliable calibration, though it typically incurs a significant computational overhead. To address this, we validate an efficient protocol: full-model fine-tuning of a shallow ensemble originally trained with a probabilistic energy loss, or one sampled from the Laplace posterior. This approach results in negligible reduction in calibration quality compared to training from scratch, while reducing training time by up to 96%. We evaluate this protocol across a diverse range of materials, including amorphous carbon, ionic liquids (BMIM), liquid water (H$_2$O), barium titanate (BaTiO$_3$), and a model tetrapeptide (Ac-Ala3-NHMe), establishing practical guidelines for reliable uncertainty quantification in atomistic machine learning.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15747v1",
        "authors": [
          "Moritz Schäfer",
          "Matthias Kellner",
          "Johannes Kästner",
          "Michele Ceriotti"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Shallow Ensemble Shallow",
        "Machine Learning",
        "Guideline",
        "Protocol",
        "BMIM",
        "Act",
        "NLL",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.334348"
    },
    {
      "id": "arxiv-2602.15700v1",
      "title": "Analytical Nuclear Gradients of State-Averaged Configuration Interaction Singles Variants: Application to Conical Intersections",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15700v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We derive analytical nuclear gradients for state-averaged configuration interaction singles (SACIS) and its spin-projected extension (SAECIS), enabling efficient geometry optimization and minimum-energy conical intersection (MECX) searches within a low-cost CIS-based framework. The formulation employs a Lagrangian approach and explicitly removes null-space contributions in the coupled perturbed equations to ensure numerically stable gradients. For twisted-pyramidalized ethylene, both SACIS and SAECIS qualitatively reproduce the correct conical intersection topology, in sharp contrast to conventional CIS and ECIS. Benchmark calculations on twelve MECXs demonstrate that both methods reproduce geometries with mean RMSDs below 0.1~Å relative to high-level reference methods. SACIS captures the essential degeneracy through variational orbital relaxation, which alleviates ground-state Hartree--Fock (HF) orbital bias and effectively incorporates static correlation through localization effects; notably, spin projection is found to be non-essential for the qualitative description of these intersections. Overall, SACIS and SAECIS provide qualitatively reliable CX descriptions at mean-field computational cost in a black-box manner. Given their comparable accuracy and the additional overhead associated with spin projection, SACIS offers a more favorable cost-performance balance for general applications, whereas SAECIS may become advantageous when higher excited states with significant double-excitation character are involved.",
        "keywords": [
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15700v1",
        "authors": [
          "Takashi Tsuchimochi"
        ],
        "arxiv_categories": [
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Averaged Configuration Interaction Singles",
        "Analytical Nuclear Gradients",
        "Conical Intersections We",
        "Framework",
        "Nuclear",
        "SAECIS",
        "SACIS",
        "MECX",
        "ECIS",
        "Act",
        "CIS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.335246"
    },
    {
      "id": "arxiv-2602.15672v1",
      "title": "Dosimetric Study of Lung Modulation and Motion Effects in Carbon ion Therapy for Lung Cancer",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15672v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Carbon-ion radiotherapy provides high dose conformity for lung cancer, but its benefit is limited by two sources of uncertainties: interplay between scanned beam delivery and tumor motion, and dose modulation from heterogeneous lung tissue. This study quantifies the separate and combined dosimetric impact of these effects using the GSI TRiP4D treatment planning system. Eighteen lung cancer 4DCT datasets from TCIA were analyzed. A modulation power ($P_{\\mathrm{mod}}$) was assigned to lung voxels. Three values were sampled from a Gaussian distribution ($200μ\\mathrm{m} \\pm 67μ\\mathrm{m}$), and an extreme value of $750μ\\mathrm{m}$ was tested. Interplay doses were computed by combining scanned-beam delivery with patient-specific respiratory motion. Four scenarios were studied: static, static with modulation, interplay, and interplay with modulation. Metrics included $D95\\%$, $V95\\%$, homogeneity index (HI), lung $V16\\mathrm{Gy}$, and heart $V20\\mathrm{Gy}$. Interplay reduced target coverage by $5.2 \\pm 1.5$ pp ($D95\\%$), $12.1 \\pm 5.9$ pp ($V95\\%$), and $8.3 \\pm 2.4$ pp (HI). Extreme $P_{\\mathrm{mod}}$ alone caused small degradations. When combined with interplay, it partially compensated the loss. This effect decreased with 4D optimization. Fractionation mitigated interplay, leaving lung modulation as the main residual effect.",
        "keywords": [
          "physics.med-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15672v1",
        "authors": [
          "Maria Chiara Martire",
          "Lennart Volz",
          "Marco Durante",
          "Christian Graeff"
        ],
        "arxiv_categories": [
          "physics.med-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Lung Cancer Carbon",
        "Dosimetric Study",
        "Lung Modulation",
        "Motion Effects",
        "TCIA",
        "EPA",
        "IoT",
        "GSI",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.336099"
    },
    {
      "id": "arxiv-2602.15646v1",
      "title": "Planar Structures of Medium-Sized Gold Clusters Become Ground States upon Ionization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15646v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This study investigates the structural stability of ionized gold clusters of sizes ranging from 22 to 100 atoms, contrasting compact, cage and planar structures. While it is well known that neutral clusters in the upper part of this size range predominantly favor compact structures, our results reveal that positively ionized gold clusters exhibit structural transitions in which planar structures become energetically preferred once the charge is sufficiently large. In addition, we study the finite-temperature stability of the structures and find that thermodynamic effects further stabilize planar configurations relative to their compact counterparts. To explore the potential energy surface, we use the Minima Hopping algorithm combined with a machine-learned potential. Since the machine-learned potential does not apply to ionized clusters, we introduce a charge-correction term to incorporate Coulomb interactions and charge screening.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15646v1",
        "authors": [
          "Mohammad Ismaeil Safa",
          "Ehsan Rahmatizad Khajehpasha",
          "Stefan Goedecker"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Sized Gold Clusters Become",
        "Planar Structures",
        "Minima Hopping",
        "Ground States",
        "Act",
        "DOE",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.336386"
    },
    {
      "id": "arxiv-2602.15627v1",
      "title": "Fastest first-passage time for multiple searchers with finite speed",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15627v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study analytically and numerically the mean fastest first-passage time (fFPT) to an immobile target for an ensemble of $N$ independent finite-speed random searchers driven by dichotomous noise and described by the telegrapher's equation. In stark contrast to the well-studied case of Brownian particles -- for which the mean fFPT vanishes logarithmically with $N$ -- we uncover that the mean fFPT is bounded from below by the minimal ballistic travel time, with an exponentially fast convergence to this bound as $N \\to \\infty$. This behavior reveals a dramatic efficiency advantage of physically realistic, finite-speed searchers over Brownian ones and illustrates how diffusive macroscopic models may be conceptually misleading in predicting the short-time behavior of a physical system. We extend our analysis to anomalous diffusion generated by Riemann-Liouville-type dichotomous noises and find that target detection is more efficient in the superdiffusive regime, followed by normal and then subdiffusive regimes, in agreement with physical intuition and contrary to earlier predictions.",
        "keywords": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15627v1",
        "authors": [
          "Denis S. Grebenkov",
          "Ralf Metzler",
          "Gleb Oshanin"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "physics.bio-ph",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "Fusion",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.336697"
    },
    {
      "id": "arxiv-2602.15534v1",
      "title": "Reactive Coarse Grained Force Field for Metal-Organic Frameworks applied to Modeling ZIF-8 Self-Assembly",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15534v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Decoding the self-assembly mechanism of metal-organic frameworks is a crucial step in reducing trial-and-error tests in their synthesis protocols. Atomistic simulations have proven essential in revealing molecular-level features of MOF nucleation, but they still exhibit limitations in the simulation setups due to size constraints (inability of reaching realistic concentrations or exploring non-stoichiometric metal:ligand ratios). In this contribution, we develop a methodology to derive reactive coarse grained force fields based on multiscale coarse graining methods. We apply our novel methodology to the case of the archetypal zeolitic-imidazolate framework ZIF-8. Our coarse grained force field, which we call nb-CG-ZIF-FF, does not contain any explicit connectivity information, but learns the tetrahedral Zn-connectivity from many body correlations within an atomistic benchmark. nb-CG-ZIF-FF quantitatively reproduces the features of bulk, crystalline ZIF-8 as well as the structural evolution of pre-nucleation species in terms of Zn n-fold coordination populations from the atomistic benchmark. While the range of rings that are formed along the synthesis process are well captured by nb-CG-ZIF-FF, the model cannot exactly reproduce ring populations. Our reactive CG force field fitting approach can be applied to any MOF, opening new research avenues in modeling MOF formation, decomposition, defect dynamics and phase transition processes.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15534v1",
        "authors": [
          "Sangita Mondal",
          "Cecilia M. S. Alvares",
          "Rocio Semino"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reactive Coarse Grained Force",
        "Organic Frameworks",
        "Assembly Decoding",
        "Framework",
        "Protocol",
        "ZIF-8",
        "Meta",
        "Act",
        "MIT",
        "MOF",
        "DOE",
        "ZIF",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.337097"
    },
    {
      "id": "arxiv-2602.15476v1",
      "title": "How to Detect Information Voids Using Longitudinal Data from Social Media and Web Searches",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15476v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The model of the attention economy, where content producers compete for the attention of users, relies on two key forces: information supply and demand. This study leverages the feedback loop between these forces to develop a method for detecting and quantifying information voids, i.e., periods in which little or no reliable information is available on a given topic. Using a case study on COVID-19 vaccines rollout in six European countries, and drawing on data from multiple platforms including Facebook, Google, Twitter, Wikipedia, and online news outlets, we examine how information voids emerge, persist and correlate with a decline in the proportion of high-quality information circulating online. By conceptualising information voids as a specific regime of information spreading, we also quantify their counterpart, information overabundance, which constitute a central component of the current definition of infodemic. We show that information voids are associated with a higher prevalence of misinformation, thus representing problematic hotspots in which individuals are more likely to be misled by low-quality online content. Overall, our findings provide empirical support for the inclusion of information voids in mechanistic explanations of misinformation emergence.",
        "keywords": [
          "cs.CY",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15476v1",
        "authors": [
          "Irene Scalco",
          "Francesco Gesualdo",
          "Roy Cerqueti",
          "Matteo Cinelli"
        ],
        "arxiv_categories": [
          "cs.CY",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Detect Information Voids Using",
        "Longitudinal Data",
        "Social Media",
        "COVID-19",
        "Vaccine",
        "Google",
        "COVID",
        "NIST",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.337458"
    },
    {
      "id": "arxiv-2602.15470v1",
      "title": "The Skeletal Trap: Mapping Spatial Inequality and Ghost Stops in Ankara's Transit Network",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15470v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Ankara's public transport crisis is commonly framed as a shortage of buses or operational inefficiency. This study argues that the problem is fundamentally morphological and structural. The city's leapfrog urban expansion has produced fragmented peripheral clusters disconnected from a rigid, center-oriented bus network. As a result, demand remains intensely concentrated along the Kizilay-Ulus axis and western corridors, while peripheral districts experience either chronic under-service or enforced transfer dependency. The deficiency is therefore not merely quantitative but rooted in the misalignment between urban macroform and network architecture. The empirical analysis draws on a 173-day operational dataset derived from route-level passenger and trip reports published by EGO under the former \"Transparent Ankara\" initiative. To overcome the absence of stop-level geospatial data, a Connectivity-Based Weighted Distribution Model reallocates passenger volumes to 1 km x 1 km grid cells using network centrality. The findings reveal persistent center-periphery asymmetries, structural bottlenecks, and spatially embedded accessibility inequalities.",
        "keywords": [
          "physics.soc-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15470v1",
        "authors": [
          "Elifnaz Kancan"
        ],
        "arxiv_categories": [
          "physics.soc-ph",
          "cs.LG"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Based Weighted Distribution Model",
        "Mapping Spatial Inequality",
        "Transit Network Ankara",
        "Transparent Ankara",
        "Ghost Stops",
        "EGO",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.337784"
    },
    {
      "id": "arxiv-2602.15468v1",
      "title": "Students' understanding of the 2D Heat Equation: An APOS approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15468v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we use the APOS theoretical framework to validate a hypothetical learning trajectory of the 2D heat equation, a preliminary genetic decomposition that stresses the conceptual understanding of its mathematical formulation. We design questions to probe specific mental constructions of the preliminary genetic decomposition. We interview 8 students in the second year of the B.Sc. enrolled in either engineering, physics or twin (mathematics and physics) majors. Our findings indicate that students engage with many predicted mental constructions. In particular, coordination and encapsulation of two process conceptions of the Laplacian of the temperature improve understanding although it is challenging. Other parts of the genetic decomposition require refinements. These include mental constructions related to the temperature distribution function, heat flow, and the temperature gradient.",
        "keywords": [
          "physics.ed-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15468v1",
        "authors": [
          "Maria Al Dehaybes",
          "Johan Deprez",
          "Paul van Kampen",
          "Mieke De Cock"
        ],
        "arxiv_categories": [
          "physics.ed-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Heat Equation",
        "Framework",
        "APOS",
        "UN"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.338053"
    },
    {
      "id": "arxiv-2602.15447v1",
      "title": "Household size can explain 40% of the variance in cumulative COVID-19 incidence across Europe",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15447v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Household size impacts the spread of respiratory infectious diseases: Larger households tend to boost transmission by acquiring external infections more frequently and subsequently transmitting them back into the community. Furthermore, mandatory interventions primarily modulate contagion between households rather than within them. We developed an approach to quantify the role of household size in epidemics by separating within-household from out-household transmission, and found that household size explains 41% of the variability in cumulative COVID-19 incidence across 34 European countries (95% confidence interval: [15%, 46%]). The contribution of households to the overall dynamics can be quantified by a boost factor that increases with the effective household size, implying that countries with larger households require more stringent interventions to achieve the same levels of containment. This suggests that households constitute a structural (dis-)advantage that must be considered when designing and evaluating mitigation strategies.",
        "keywords": [
          "q-bio.PE",
          "math.DS",
          "physics.soc-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15447v1",
        "authors": [
          "Seba Contreras",
          "Philipp Dönges",
          "Maciej Filinski",
          "Joel Wagner",
          "Viktor Bezborodov"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "math.DS",
          "physics.soc-ph"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Europe Household",
        "COVID-19",
        "COVID",
        "EPA",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:47.338367"
    },
    {
      "id": "arxiv-2602.15442v1",
      "title": "Virtual ultrasound machine operating in a GHz to MHz frequency range for particle-based biomedical simulations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15442v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Ultrasound-matter interactions underpin numerous biomedical and soft-matter applications, yet simulating these phenomena is challenging due to the large separation of viscous and sonic time scales. Continuum methods capture large-scale wave propagation but cannot resolve microscale interactions, while particle-based approaches offer molecular resolution but struggle with efficiency and stability at larger scales. We introduce a particle-based virtual ultrasound machine that uses a novel smoothed dissipative particle dynamics variant with an implicit pressure solver and a negative-pressure stabilization scheme, required to mimic acoustic propagation across MHz-GHz frequencies. We demonstrate its capabilities by modeling the acoustophoresis of encapsulated microbubbles, a key mechanism in ultrasound-mediated drug delivery. Beyond this application, the approach establishes a generalizable platform for simulating wave-matter interactions in soft and biological materials, opening new directions for computational studies of acoustics-driven phenomena in science and engineering.",
        "keywords": [
          "cond-mat.soft",
          "cond-mat.mes-hall",
          "physics.bio-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15442v1",
        "authors": [
          "Urban Čoko",
          "Tilen Potisk",
          "Matej Praprotnik"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "cond-mat.mes-hall",
          "physics.bio-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.338678"
    },
    {
      "id": "arxiv-2602.15437v1",
      "title": "Isotope effect in the work function of lithium",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15437v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The work functions of 7Li and 6Li metals have been measured as a function of temperature, by using photoionization of pure isolated metal nanoparticles in a beam. These data reveal a marked isotope effect in the temperature variation of these work functions. Furthermore, for both isotopes the curvature of this temperature variation is found to be significantly larger than may be ascribed purely to a change in the electron gas density. These findings enhance the characterization of lithium as a quantum material in which the interplay between electronic and ionic degrees of freedom is nontrivial, and call for a microscopic understanding beyond simple models. Additionally, the slope of the work function curves was observed to vanish in the low temperature limit, as had been predicted on the basis of the Third Law of thermodynamics.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15437v1",
        "authors": [
          "Atef A. Sheekhoon",
          "Abdelrahman O. Haridy",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Third Law",
        "Meta",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.338977"
    },
    {
      "id": "arxiv-2602.15434v1",
      "title": "Temperature-dependent photoionization thresholds of alkali-metal nanoparticles reveal thermal expansion and the melting transition",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15434v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A precision measurement of the photoionization of pure sodium and potassium nanoparticles isolated in a beam enabled an accurate determination of their work functions as a function of temperature. In addition to resolving and quantifying the initial gradual decrease of the work function with temperature, which is associated with thermal expansion, the experiment revealed that the work function then undergoes a distinct drop both in magnitude and in slope that signifies the onset of nanoparticle melting. This establishes that a structural phase transition can be detected via a high-resolution measurement of the photoemission threshold. The melting temperature of nanoparticles with diameters of 7-9 nm is reduced by nearly 100 K relative to the bulk value. This suppression aligns with predictions from the Gibbs-Thomson equation which describes finite-size phase transitions.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15434v1",
        "authors": [
          "Abdelrahman O. Haridy",
          "Atef A. Sheekhoon",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.339220"
    },
    {
      "id": "arxiv-2602.15426v1",
      "title": "Photoionization of temperature-controlled nanoparticles in a beam: Accurate and efficient determination of ionization energies and work functions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15426v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A beam of free alkali metal nanoparticles is produced by a condensation source, passed through a thermalizing tube adjustable over a broad temperature range, and ionized by tunable light. High stability of the particle flux and an automated data acquisition routine allow efficient collection of photoionization yield curves. A careful fit of the data to the universal Fowler function makes it possible to obtain nanoparticle ionization energies, and from those, the metal work functions, with $\\sim$0.2% precision. The experimental arrangement, nanoparticle thermalization rates, and ionization threshold analysis are described in detail. The use of ultrapure and temperature-controlled gas-phase nanoparticles facilitates the analysis of electronic properties, such as work functions, and of their interplay with thermal lattice dynamics.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15426v1",
        "authors": [
          "Atef A. Sheekhoon",
          "Abdelrahman O. Haridy",
          "Sebastian Pedalino",
          "Vitaly V. Kresin"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci",
          "physics.atm-clus",
          "physics.chem-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.339459"
    },
    {
      "id": "arxiv-2602.15345v1",
      "title": "Machine learning electronic structure and atomistic properties from the external potential",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15345v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electronic structure calculations remain a major bottleneck in atomistic simulations and, not surprisingly, have attracted significant attention in machine learning (ML). Most existing approaches learn a direct map from molecular geometries, typically represented as graphs or encoded local environments, to molecular properties or use ML as a surrogate for electronic structure theory by targeting quantities such as Fock or density matrices expressed in an atomic orbital (AO) basis. Inspired by the Hohenberg-Kohn theorem, in this work, we propose an operator-centered framework in which the external (nuclear) potential, expressed in an AO basis, serves as the model input. From this operator, we construct hierarchical, body-ordered representations of atomic configurations that closely mirror the principles underlying several popular atom-centered descriptors. At the same time, the matrix-valued nature of the external potential provides a natural connection to equivariant message-passing neural networks. In particular, we show that successive products of the external potential provide a scalable route to equivariant message passing and enable an efficient description of long-range effects. We demonstrate that this approach can be used to model molecular properties, such as energies and dipole moments, from the external potential, or learn effective operator-to-operator maps, including mappings to the Fock matrix and the reduced density matrix from which multiple molecular observables can be simultaneously derived.",
        "keywords": [
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15345v1",
        "authors": [
          "Jigyasa Nigam",
          "Tess Smidt",
          "Geneviève Dusson"
        ],
        "arxiv_categories": [
          "physics.chem-ph",
          "physics.comp-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "Framework",
        "Nuclear",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.339820"
    },
    {
      "id": "arxiv-2602.15309v1",
      "title": "OSCAR: An Ovipositor-Inspired Self-Propelling Capsule Robot for Colonoscopy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15309v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Self-propelling robotic capsules eliminate shaft looping of conventional colonoscopy, reducing patient discomfort. However, reliably moving within the slippery, viscoelastic environment of the colon remains a significant challenge. We present OSCAR, an ovipositor-inspired self-propelling capsule robot that translates the transport strategy of parasitic wasps into a propulsion mechanism for colonoscopy. OSCAR mechanically encodes the ovipositor-inspired motion pattern through a spring-loaded cam system that drives twelve circumferential sliders in a coordinated, phase-shifted sequence. By tuning the motion profile to maximize the retract phase relative to the advance phase, the capsule creates a controlled friction anisotropy at the interface that generates net forward thrust. We developed an analytical model incorporating a Kelvin-Voigt formulation to capture the viscoelastic stick--slip interactions between the sliders and the tissue, linking the asymmetry between advance and retract phase durations to mean thrust, and slider-reversal synchronization to thrust stability. Comprehensive force characterization experiments in ex-vivo porcine colon revealed a mean steady-state traction force of 0.85 N, closely matching the model. Furthermore, experiments confirmed that thrust generation is speed-independent and scales linearly with the phase asymmetry, in agreement with theoretical predictions, underscoring the capsule's predictable performance and scalability. In locomotion validation experiments, OSCAR demonstrated robust performance, achieving an average speed of 3.08 mm/s, a velocity sufficient to match the cecal intubation times of conventional colonoscopy. By coupling phase-encoded friction anisotropy with a predictive model, OSCAR delivers controllable thrust generation at low normal loads, enabling safer and more robust self-propelling locomotion for robotic capsule colonoscopy.",
        "keywords": [
          "cs.RO",
          "physics.med-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15309v1",
        "authors": [
          "Mostafa A. Atalla",
          "Anand S. Sekar",
          "Remi van Starkenburg",
          "David J. Jager",
          "Aimée Sakes"
        ],
        "arxiv_categories": [
          "cs.RO",
          "physics.med-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Propelling Capsule Robot",
        "Colonoscopy Self",
        "An Ovipositor",
        "Inspired Self",
        "Agreement",
        "Robot",
        "OSCAR",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:47.340257"
    },
    {
      "id": "arxiv-2602.16706v1",
      "title": "How Bursty is Star Formation at z>5?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16706v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Motivated by observational evidence from JWST and theoretical results from cosmological simulations, we use a simple parametric, phenomenological model to test to what extent bursty star formation with standard Initial Mass Function, no continuous star formation, no mergers, \\mr{and no dust} can account for the observed properties in the $M_{UV}$ vs $M_*$ plane of galaxies at redshifts $z>5$. We find that the simplest model that fits the data has a quiescence period between bursts $Δt \\sim 100$~Myrs and the stellar mass in each galaxy grows linearly as a function of time from $z=12$ to $z=5$ (i.e., repeated bursts in each galaxy produce approximately equal mass in stars). The distribution of burst masses across different galaxies follows a power-law $dN/dM_* \\propto M_*^α$ with slope $α\\sim -2$. At $z>9-10$ the observed galaxy population typically had only one or two bursts of stars formation, hence the observed stellar masses at these redshifts (reaching $M_* \\sim 10^{10}$~M$_\\odot$), roughly represent the distribution of masses formed in one burst.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16706v1",
        "authors": [
          "Massimo Stiavelli",
          "Massimo Ricotti"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Initial Mass Function",
        "Star Formation",
        "How Bursty",
        "Standard",
        "JWST",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.440389"
    },
    {
      "id": "arxiv-2602.16676v1",
      "title": "Orbital Motions of Binaries in Orion South",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16676v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present high-angular resolution ($\\simeq 0\\rlap.{''}06$) VLA and ALMA observations of Orion South separated by 15.52 years. The purpose of this study was to search for orbital motions in three close ($\\simeq 0\\rlap.{''}1$) binary systems in the region. We do not detect changes in the position angle of the binaries but in two of the cases we detect significant changes in their separation in the plane of the sky. We use these changes to estimate that the total mass of the binaries is in the $\\simeq$1-2 $M_\\odot$ range. We also estimate the disk masses from the mm emission. The dust-to-stellar mass ratio is in the range of 0.04 to 0.18, values consistent with those expected for very early stellar evolution (Class 0) protostars.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16676v1",
        "authors": [
          "Luis A. Zapata",
          "Luis F. Rodríguez"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Orbital Motions",
        "Orion South We",
        "Orion South",
        "ALMA",
        "EPA",
        "VLA"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.440798"
    },
    {
      "id": "arxiv-2602.16659v1",
      "title": "Updated Constraints on Infrared Cutoff Models and Implications for Large-Scale CMB Anomalies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16659v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The nearly scale-invariant primordial power spectrum provides the standard initial conditions for cosmological perturbations. However, the largest scales remain only weakly constrained by CMB observations, leaving room for deviations such as an infrared (IR) cut-off. This possibility is further motivated by the persistence of large-scale CMB anomalies, most notably the low quadrupole power. In this work, we revisit several broad classes of phenomenologically motivated IR cut-off scenarios using parametrised functional forms of the primordial power spectrum. We confront these models with the latest CMB, BAO, and supernova data and derive updated constraints on the cut-off scale and associated features. Our results remain consistent with earlier studies, showing that although such models suppress power at low multipoles, the improvement in fit is marginal and does not overcome the associated parameter penalties. We therefore find no statistically significant evidence favouring IR cut-off models over the standard power-law spectrum with current data. We further explore the interplay between IR cut-off features and a possible increase in the reionisation optical depth, motivated by the recent CMB-BAO tension highlighted by DESI DR2 within the $Λ$CDM framework. We show that the additional freedom introduced by large-scale suppression is generally insufficient to support a substantial increase in optical depth, owing to the weak statistical preference for suppressed large-scale temperature power. Finally, we examine the implications of IR cut-off models for large-scale CMB anomalies by analysing the corresponding anomaly statistics within a Bayesian framework.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16659v1",
        "authors": [
          "Ujjwal Upadhyay",
          "Yashi Tiwari",
          "Tarun Souradeep"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Infrared Cutoff Models",
        "Updated Constraints",
        "Framework",
        "Standard",
        "DESI",
        "BAO",
        "CDM",
        "CMB",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.441671"
    },
    {
      "id": "arxiv-2602.16651v1",
      "title": "Interpreting the HI 21-cm cosmology maps through Largest Cluster Statistics III: Impact of the lightcone effect",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16651v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The redshifted 21-cm signal emitted by neutral Hydrogen (HI) is a promising probe to understand the evolution of the topology of ionized regions during the Epoch of Reionization (EoR). The topology of ionized regions allows us to infer the nature and properties of ionizing sources, i.e., early galaxies and AGNs. Traditional Fourier statistics, such as the power spectrum, help us quantify the strength of fluctuations in this field at different length scales but do not preserve its phase information. Analyzing the 21-cm brightness temperature field in the image domain retains its non-Gaussian characteristics and morphological information. One such approach is to track the coalescence of multiple ionized regions to form one contiguous ionized region spanning the universe. This is referred to as percolation, and its onset is quantified by a sharp rise in the value of the Largest Cluster Statistic (LCS) approaching unity. In this work, we carry out a percolation analysis of 21-cm brightness temperature fields by studying the redshift evolution of the LCS along a lightcone to distinguish between several simulated reionization scenarios. We have extended previous results on reionization model comparison from the analysis of coeval 21-cm maps to understand how the lightcone effect biases the observed percolation behavior and affects the distinguishability of the source models. We estimate the LCS of subvolumes of different sizes in the 21-cm lightcone maps and study their redshift evolution for different reionization scenarios using a moving volume approach. We find that the percolation transition inferred from a lightcone approaches that from the coeval box as we increase the bandwidth of the moving volume in all but one reionization scenario.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16651v1",
        "authors": [
          "Hemanth Potluri",
          "Manas Mohit Dosibhatla",
          "Leon Noble",
          "Chandra Shekhar Murmu",
          "Suman Majumdar"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Largest Cluster Statistics",
        "Largest Cluster Statistic",
        "Traditional Fourier",
        "Hydrogen",
        "Act",
        "LCS",
        "MIT",
        "III",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.442420"
    },
    {
      "id": "arxiv-2602.16646v1",
      "title": "Two warm sub-Saturn mass planets identified from the TESS Full Frame Images",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16646v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Context. Characterization of warm giants is crucial to constrain giant planet formation and evolution. Measuring the mass and radius of these planets, combined with their moderated irradiation, allows us to estimate their planetary bulk composition, which is a key quantity to comprehend giant planet formation and structure. Aims. We present the discovery of two transiting warm giant planets orbiting solar-type stars from the Transiting Exoplanet Survey Satellite (TESS), which were characterized by further spectroscopic and photometric ground-based observations. Methods. We performed a joint analysis of photometric data with radial velocities to confirm and characterize TOI-883 b and TOI-899 b, two sub-Saturns orbiting solar-like stars. Results. TOI-883 b and TOI-899 b have masses of $0.123 \\pm 0.012$ $M_J$ and $0.213 \\pm 0.024$ $M_J$, radius of $0.604 \\pm 0.028$ $R_J$ and $0.991 \\pm 0.044$ $R_J$, periods of $10.06$ d and $12.85$ d and equilibrium temperature of $1086 \\pm 19$ K and $1040 \\pm 19$ K, respectively. Conclusions. While having similar masses, orbital periods and stellar host properties, these planets seem to have different internal compositions, which could point to distinct formation histories. Both planets are suitable targets for atmospheric studies to further constrain formation scenarios of planets in the Neptune-Saturn mass range",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16646v1",
        "authors": [
          "Felipe I. Rojas",
          "Rafael Brahm",
          "Andrés Jordán",
          "Néstor Espinoza",
          "Thomas Henning"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Transiting Exoplanet Survey Satellite",
        "Full Frame Images Context",
        "Satellite",
        "TOI-899",
        "TOI-883",
        "Solar",
        "TESS",
        "TOI",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.443107"
    },
    {
      "id": "arxiv-2602.16620v1",
      "title": "HOLISMOKES XX. Lens models of binary lens galaxies with five images of Supernova Winny",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16620v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Strongly lensed supernovae (SNe) provide a powerful way to study cosmology, SNe and galaxies. Modelling the lens system is key to extracting astrophysical and cosmological information. We present adaptive-optics-assisted high-resolution images of SN Winny (SN 2025wny) in the J and K filters obtained with the Large Binocular Telescope (LBT). The LBT imaging confirms the presence of a fifth point source, whose colour is consistent with that of the other SN images at similar phases, while lens modelling robustly supports its interpretation as an additional image of SN~Winny. We measure the positions of the five SN images with uncertainties varying between 1 and 14 milliarcseconds. We build the first mass models using lenstronomy and GLEE, and explore three classes of mass models for the two lens galaxies G1 and G2. The optimal model class of the three is a singular isothermal ellipsoid for G1, a singular isothermal sphere for G2, and an external shear. We infer the enclosed masses within the Einstein radius as 4.61^{+0.06}_{-0.04} \\times 10^{11}\\,M_\\odot for G1 and 1.01\\pm0.02 \\times 10^{11}\\,M_\\odot for G2. The lensing configuration by the two lens galaxies can produce two additional magnified SN images beyond the five observed ones; the exclusion of such model configurations further constrains the lens model parameters. Our model fits to the observed image positions with an RMS of ~0.0012\" - 0.0025\", within the observed positional uncertainties. The predicted magnifications of the multiple images vary between ~1.6 (for the faintest fifth image E) to ~10 (for the brightest image A). The predicted relative lensing magnifications of the multiple images do not match that of the observed within 2σuncertainties. The differences in the relative magnifications could be due to millilensing/microlensing. Our mass models form the basis for future analyses of this unique system. (abridged)",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16620v1",
        "authors": [
          "L. R. Ecker",
          "A. G. Schweinfurth",
          "R. Saglia",
          "L. Deng",
          "S. H. Suyu"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Large Binocular Telescope",
        "Supernova Winny Strongly",
        "GLEE",
        "RMS",
        "Act",
        "LBT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.443833"
    },
    {
      "id": "arxiv-2602.16614v1",
      "title": "Meteor statistics I: The distribution of instrumental magnitudes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16614v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The distribution of meteor magnitudes is known to follow an exponential distribution, where the base of this distribution is called the population index. The distribution of observed magnitudes preserves this behavior, but is truncated by the detection threshold. If both the population index and detection threshold can be determined, observed meteor rates can be converted to fluxes and extrapolated to any desired brightness or size. We argue that the distribution of observed or instrumental meteor magnitudes is best modeled as an exponentially modified Gaussian (exGaussian) distribution. This is for three reasons: first, an exGaussian distribution is the natural result of random variations in detection threshold and/or post-detection measurement errors in magnitude. Second, an exGaussian distribution provides a better fit to the magnitude distribution than all other competing distributions in the literature; we demonstrate this using both a set of faint optical meteor magnitudes and a set of radar meteor echo amplitudes. Finally, the population index, mean detection threshold, and random variation/error terms are easily extracted from the best-fit parameters of an exGaussian distribution.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16614v1",
        "authors": [
          "Althea V. Moorhead",
          "Peter G. Brown",
          "Margaret D. Campbell-Brown",
          "Michael J. Mazur",
          "Denis Vida"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.444018"
    },
    {
      "id": "arxiv-2602.16575v1",
      "title": "Chiral gravitational waves from multi-phase magnetogenesis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16575v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cosmological vector fields are central to many early-Universe phenomena, including inflationary dynamics, primordial magnetogenesis, and dark-matter scenarios. However, constructing models able to generate cosmological magnetic fields while avoiding strong coupling, backreaction, and cosmic microwave background constraints remains challenging. We study a novel mechanism in which brief non--slow-roll phases during inflation amplify primordial magnetic fields at small scales, while maintaining theoretical consistency and observational viability. We incorporate parity-violating interactions in the vector sector and demonstrate, for the first time in a non--slow-roll framework, that chirality can significantly boost magnetic-field amplitudes and imprint distinctive polarization-dependent spectral features. We complement detailed numerical computations with an analytical treatment yielding compact expressions for chiral vector mode functions that reproduce the main spectral properties. We then develop a systematic formalism to evaluate the stochastic gravitational-wave background naturally induced at second order by these amplified fields, identifying both an intensity component and a circularly polarized contribution with characteristic frequency profiles. We discuss detection prospects with future multiband gravitational-wave observatories, showing that chiral signatures could provide a distinctive observational probe. Our results introduce new avenues for enhancing primordial magnetic fields and their associated gravitational-wave signals, opening promising possibilities for their future detection and interpretation, both with cosmological and gravitational wave probes.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16575v1",
        "authors": [
          "H. V. Ragavendra",
          "Gianmassimo Tasinato",
          "L. Sriramkumar"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.444250"
    },
    {
      "id": "arxiv-2602.16559v1",
      "title": "GOTO identification and broadband modelling of the counterpart to the SVOM GRB 250818B",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16559v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Rapid localisation and follow-up of gamma-ray bursts (GRBs) increasingly rely on low-latency triggers from new missions coupled to wide-field robotic optical facilities. We present the discovery and multi-wavelength follow-up of GRB 250818B, detected by the Space Variable Objects Monitor (SVOM) and localised optically by the Gravitational-wave Optical Transient Observer (GOTO). We compile and homogenise X-ray, optical/NIR, and radio data to build broadband light curves and spectral energy distributions. The afterglow is unusually luminous for a nominal short GRB, lying on the bright end of the short-GRB population in X-rays and optical and among the most luminous high-redshift short-GRB afterglows in the radio. MeerKAT detects the source at 3.1 GHz, while ALMA provides deep higher-frequency limits. Keck/LRIS spectroscopy shows continuum and metal absorption (Fe II, Mg II, Mg I), giving $z=1.216$. Synchrotron forward-shock modelling favours a constant-density medium and strongly prefers refreshed (energy-injection) emission, well described by a two-component jet with $E_{K,iso} \\sim 4\\times10^{52}$ erg, $n_0 \\sim 3.6$ cm$^{-3}$, $θ_j \\simeq 0.10$ rad ($\\sim 5.7$ deg), and $p \\simeq 1.64$. The host association is ambiguous: the nearest LS DR10 galaxy candidate ($r_{AB} \\sim 24.7$) is offset by $\\sim 4$ arcsec ($\\sim 34$ kpc) with chance-alignment probability $P_{cc} \\sim 0.2$, and current imaging does not exclude a fainter, near-coincident host. SED fitting of the candidate host suggests a low-mass galaxy. GRB 250818B highlights the power of rapid wide-field counterpart identification in the SVOM era, while host-association uncertainty can still limit offset-based interpretation.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16559v1",
        "authors": [
          "Sergey Belkin",
          "Gavin P. Lamb",
          "Kristian Ackley",
          "Matthew E. Wortley",
          "Stuart McGee"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Space Variable Objects Monitor",
        "Optical Transient Observer",
        "Robot",
        "ALMA",
        "Meta",
        "SVOM",
        "GOTO",
        "LRIS",
        "GRB",
        "MIT",
        "SED",
        "DOE",
        "NIR",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.444910"
    },
    {
      "id": "arxiv-2602.16550v1",
      "title": "Searching for White Dwarf Candidates Formed Through Binary evolution in Star Clusters",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16550v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "White dwarfs (WDs), the evolutionary endpoints of most stars, can form through both single-star and binary channels. While single-star evolutionary models enable reliable WD age estimates, binary evolution introduces interactions that can accelerate WD formation and result in a variety of exotic WDs, which may exhibit strong magnetic fields, rapid rotation, or even serve as potential gravitational wave sources. Such systems offer valuable insights into magnetic field generation, angular momentum evolution, and compact object physics. Star clusters, with their approximately coeval populations, allow precise age determination of member WDs. If a WD's total age derived from single-star evolution exceeds that of its host cluster, it likely indicates a binary origin. In this study, we use \\textit{Gaia} 5D astrometry to identify 439 WD candidates in 117 open clusters, with 244 likely formed via binary evolution. We discuss the possibility of dynamical ejection for WDs meeting only 2D (proper motion space) membership criteria. Spectroscopic observations further reveal a subset with strong magnetic fields and rapid rotation, supporting their binary evolutionary origin.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16550v1",
        "authors": [
          "Huahui Yan",
          "Li Wang",
          "David R. Miller",
          "Chenyu He",
          "Jiamao Lin"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "White Dwarf Candidates Formed",
        "Star Clusters White",
        "Through Binary",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.445112"
    },
    {
      "id": "arxiv-2602.16526v1",
      "title": "New self-consistent theoretical descriptions for mass-loss rates of O-type stars",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16526v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Massive O-type stars lose a significant fraction of their mass through radiation-driven winds, a process that critically shapes their evolution and feedback into the interstellar medium. Accurate predictions of mass-loss rates are essential for models of stellar structure and population synthesis. We computed wind parameters for O-type stars using a self-consistent approach that couples the hydrodynamics of the wind with detailed calculations of the line acceleration. This approach follows the theory of radiation-driven stellar winds and allows us to derive mass-loss rate distributions for different atomic configurations of the stellar flux. We used the TLUSTY code for stellar atmosphere models to compute non-local thermodynamic equilibrium models; these models served as input radiation fields for the calculation of the line-force parameters, for which we used the LOCUS code. These line-force parameters were then iteratively coupled with the HYDWIND code to solve the wind hydrodynamics. The procedure was applied across a grid of stellar parameters for three chemical configurations. We obtain self-consistent wind parameters for a broad set of O-type stellar models. The results show a systematic decrease in mass-loss rates with the inclusion of more elements in the radiation field, which is attributed to a strong effect on the UV region of the spectral energy distribution. As more elements are included, resulting in a larger number of spectral lines, the contribution from the UV diminishes, leading to lower mass-loss rates. We fitted three theoretical prescriptions for $\\dot{M}$ using a Bayesian approach; this yielded Pearson correlation values greater than 0.92 for all three model grids. It also allowed for the estimation of the wind momentum-luminosity relationships for each of the grids, yielding results similar to those based on observations of O-type stars.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16526v1",
        "authors": [
          "F. Figueroa-Tapia",
          "J. A. Panei",
          "M. Curé",
          "I. Araya",
          "S. Ekström"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "TLUSTY",
        "LOCUS",
        "Wind",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.445387"
    },
    {
      "id": "arxiv-2602.16519v1",
      "title": "The role of radiative torques in the molecular cloud core L43",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16519v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Polarized emission from interstellar dust grains is commonly used to infer information about the underlying magnetic field from the diffuse interstellar medium to molecular cloud cores. Therefore, the ability to accurately determine properties of the magnetic field requires a thorough understanding of the dust alignment mechanism. We investigate the influence of anisotropic radiation fields on the alignment of dust particles by magnetic fields, known as radiative torque (RAT) alignment. Specifically, we take advantage of the unique spatial configuration of the molecular cloud core L43, which contains an embedded yet optically visible star acting as a local source of anisotropic illumination. Based on polarization maps obtained at wavelengths of $154 μ\\mathrm{m}$ (SOFIA/HAWC+), as well as $450 μ\\mathrm{m}$ and $850 μ\\mathrm{m}$ (JCMT/SCUBA-2), which show variations in the degree and angle of polarized emission across all wavelengths, we applied the differential measure analysis method to infer magnetic field strengths and analyze the global polarization spectrum of this source. We derived plane-of-sky magnetic field strengths ranging from approximately 13 to 60 $μ\\mathrm{G}$, varying with wavelength, and find a negative slope of the polarization spectrum. Compared to 3D radiative transfer simulations, this finding can be attributed, at least partially, to variations in dust properties and temperatures along the line of sight. However, the additional influence of variations in the magnetic field orientation along the line of sight cannot be ruled out. Our results favor radiative torques as the primary alignment mechanism, as they indicate that the degree of polarization is dependent on temperature and hence the strength of the local radiation field.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16519v1",
        "authors": [
          "Marco Leon Scheiter",
          "Sebastian Wolf"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "SCUBA-2",
        "SCUBA",
        "SOFIA",
        "HAWC",
        "JCMT",
        "RAT",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.445971"
    },
    {
      "id": "arxiv-2602.16496v1",
      "title": "Resolving the Multiple Component Outflows in PG 1211+143: II. The Soft X-ray View of the Ultra Fast Outflow",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16496v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The nearby quasar, PG 1211+143, has one of the prototype examples of an ultra fast outflow (UFO), as seen in several past XMM-Newton and Chandra observations. In December 2024, PG 1211+143 was observed simultaneously with XRISM Resolve and XMM-Newton, allowing both the Fe K and soft X-ray outflows to be examined at high resolution simultaneously. The Resolve spectrum revealed a forest of Fe K band absorption lines from the UFO (Mizumoto et al. 2026), comprising of up to six discrete velocity components ranging from $v/c=-0.074$ to $v/c=-0.40$. Here we present the simultaneous XMM-Newton RGS (Reflection Grating Spectrometer) spectrum, where three lower ionization counterparts of the Fe K velocity zones are observed; at $v/c=-0.074, -0.12$ and $-0.33$. The soft X-ray absorbers tend to be somewhat less ionized than their Fe K counterparts, with their opacity mainly arising from Fe L shell lines and highly ionized Oxygen. From comparing the Resolve and RGS absorbers, we show that the outflow can be parameterized with a density profile varying with radius as $r^{-5/3}$, while the lower ionization zones likely originate from denser clumps of gas. Pure electron scattering appears insufficient to provide enough thrust to power the wind, unless sufficient low ionization gas capable of radiative line driving exists outside of the line of sight. Overall, PG 1211+143 provides further evidence for the clumpy nature of accretion disk winds, as was recently revealed in the quasar PDS 456 with XRISM.",
        "keywords": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16496v1",
        "authors": [
          "James Reeves",
          "Valentina Braito",
          "Misaki Mizumoto",
          "Steven Kraemer",
          "Ehud Behar"
        ],
        "arxiv_categories": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reflection Grating Spectrometer",
        "Multiple Component Outflows",
        "In December",
        "XRISM",
        "Wind",
        "UFO",
        "XMM",
        "RGS",
        "PDS",
        "WTO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.446230"
    },
    {
      "id": "arxiv-2602.16453v1",
      "title": "Benchmarking Photolysis Rates with Socrates (24.11): Species for Earth and Exoplanets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16453v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Using the Socrates photolysis scheme, we present newly calculated photolysis rates under modern Earth atmospheric conditions for species directly relevant to Earth and species relevant to different atmospheric compositions. We compare to a previous photolysis comparison exercise, namely PhotoComp 2011. Overall, we find good agreement between our results and previous work, with discrepancies usually caused by the implementation of temperature or pressure dependent quantum yields and updated cross-section data. We provide a new set of benchmark photolysis rates for additional species both for Solar irradiance and when irradiated by an M dwarf host star. In general, the higher actinic flux at far-UV and shorter wavelengths of the M dwarf compared to the Sun drives increased photolysis rates for reactions with high threshold energies. This work provides an updated set of benchmark results for further studies of photolysis in the Earth's atmosphere and that of other planets.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16453v1",
        "authors": [
          "Sophia M. Adams",
          "James Manners",
          "Nathan Mayne",
          "Mei Ting Mak",
          "Éric Hébrard"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Benchmarking Photolysis Rates",
        "Exoplanets Using",
        "Agreement",
        "Solar",
        "EPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.446405"
    },
    {
      "id": "arxiv-2602.16448v1",
      "title": "Euclid preparation. Impact of galaxy intrinsic alignment modelling choices on Euclid 3x2pt cosmology",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16448v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Euclid galaxy survey will provide unprecedented constraints on cosmology, but achieving unbiased results will require an optimal characterisation and mitigation of systematic effects. Among these, the intrinsic alignments (IA) of galaxies are one of the dominant contaminants of the weak lensing (WL) and galaxy-galaxy lensing (GGL) probes. In this work, we assess IA modelling choices for Euclid DR1 3x2pt analyses by comparing the performance of the two most commonly used IA models, nonlinear alignment (NLA) and tidal alignment tidal torquing (TATT), along with several variations. Our analyses combine three perspectives: i) the constraining power on the IA and cosmological parameters for each IA model, ii) the bias that results when the IA analysis model differs from the model used to generate the synthetic data vector, and iii) the degeneracies between IA and photometric redshift (photo-z) nuisance parameters. Among the IA models analysed, the redshift-dependent TATT model (zTATT) provides the most flexible description of IA, with a similar constraining power compared to simpler IA models, making it a well-motivated choice for Euclid DR1 3x2pt analyses.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16448v1",
        "authors": [
          " Euclid Collaboration",
          "D. Navarro-Gironés",
          "I. Tutusaus",
          "M. Crocce",
          "S. Gouyou Beauchamps"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "TATT",
        "EPA",
        "Act",
        "MIT",
        "GGL",
        "NLA",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.446931"
    },
    {
      "id": "arxiv-2602.16415v1",
      "title": "The Astronomical Telescope of the University of Stuttgart (ATUS): Development, Optimization, and Lessons Learned",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16415v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "ATUS, the Astronomical Telescope of the University of Stuttgart, is a fully remote-controlled 0.6 m f/8.17 Ritchey-Chrétien telescope optimized for high-cadence, high-fidelity photometry of transient sources. Observations are time-referenced with very high accuracy and precision, making it an ideal platform for time-domain astronomy and space situational awareness. Initially conceived to support instrument developments and operations of SOFIA, the Stratospheric Observatory for Infrared Astronomy, it evolved into a scientific instrument for various use cases in instrument development, astronomical research, and teaching. This paper presents an overview of its development and optimization to achieve diffraction-limited images and highly accurate pointing and tracking, even at high speeds. The findings and lessons learned are universally applicable to other telescopes that are currently at the planning stage, or where similar issues might be encountered.",
        "keywords": [
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16415v1",
        "authors": [
          "Karsten Schindler",
          "Jürgen Wolf",
          "Alfred Krabbe"
        ],
        "arxiv_categories": [
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stratospheric Observatory",
        "Astronomical Telescope",
        "Infrared Astronomy",
        "Lessons Learned",
        "University",
        "SOFIA",
        "ATUS",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.447243"
    },
    {
      "id": "arxiv-2602.16396v1",
      "title": "Deepest ever photographed Geminid with small but not negligible terminal mass",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16396v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We report an instrumental observation of the very exceptional Geminid fireball which was observed in scope of the Czech part of the European Fireball Network (EN) on 13 December 2012 at 4h12m59.4s UT. The uniqueness of this Geminid fireball consists of the record depth of its penetration in the atmosphere (to the height of 32.5 km) and in the fact that most likely a very small fraction of its initial mass survived severe deceleration in the atmosphere and landed on the ground. Such deeply penetrating Geminid with so precise and reliable data has not yet been observed. From a comparison with a large number of Geminids observed by the European Fireball Network and all brightest Geminids from the Prairie Fireball Network in USA and the Canadian MORP Network, we have shown that for Geminids with an entry mass greater than approximately 10 grams, the terminal altitude limit does not decrease further as it does for smaller Geminids, but remains constant at around 38 km. In this comparison, we have shown that there is only one exception, and that is the Geminid presented here. This one penetrated nearly 6 km deeper with very low terminal speed for Geminids. During the atmospheric flight this Geminid meteoroid slowed down from its original speed of 35.75 km/s to 6.8 km/s. This small meteoroid with initial mass of only 0.25 kg is probably the fastest candidate for a meteorite dropping event ever observed. This solid meteoroid belonging to the meteor shower survived a significant dynamic pressure of almost 2 MPa and thus ranks among the interplanetary bodies of asteroidal origin that caused the observed meteorite fall. Although a similar Geminid event has been previously presented in the literature, we demonstrate here that this claim was flawed.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16396v1",
        "authors": [
          "Pavel Spurný",
          "Jiří Borovička"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "European Fireball Network",
        "Prairie Fireball Network",
        "MORP",
        "USA",
        "Act",
        "MIT",
        "DOE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.447501"
    },
    {
      "id": "arxiv-2602.16395v1",
      "title": "Accretion Disk Magnetic Braking",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16395v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A protostellar disk is threaded by a static magnetic field that is perpendicular to the disk-surface. The magnetic field acts to brake the protostellar disk and cause the disk material to move towards the protostar. General analytic equations are derived for the accretion speed, and mass accretion rate. Simplified analytic equations are also obtained for the disk energy dissipation, accretion timescale and the disk radial position plus disk surface density, as a function of time. In addition to providing physical insight, such equations might be useful as a check on computational models for protostar and protostellar disk formation.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16395v1",
        "authors": [
          "Kurt Liffman"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.EP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Accretion Disk Magnetic Braking",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.447611"
    },
    {
      "id": "arxiv-2602.16394v1",
      "title": "Localized $^{18}$O production in white dwarf mergers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16394v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The merger of a He white dwarf (WD) and a CO WD is the favored formation channel for R Coronae Borealis (RCB) stars. These stars exhibit ${^{16}}\\mathrm{O}/{^{18}}\\mathrm{O}$ ratios that are orders of magnitude lower than the solar value. However, it is not fully understood whether such low ${^{16}}\\mathrm{O}/{^{18}}\\mathrm{O}$ ratios can be achieved in WD merger remnants for the predicted lifetime of RCB stars of around $10^4\\,\\mathrm{years}$. In this work, we perform detailed nucleosynthesis calculations of a 3D magnetohydrodynamical simulation of a merger of a $0.3\\,M_\\odot$ He WD and a $0.6\\,M_\\odot$ CO WD for $4000\\,\\mathrm{s}$ at which point a steady state in temperature and density is reached. From this point, we follow several radial zones to study the long-term production of ${^{18}}\\mathrm{O}$ and its variability throughout the burning region. We find that the asymmetric merger process leaves an imprint on the distribution of the abundances at the end of our hydrodynamic simulation. During the long-term evolution up to $100\\,\\mathrm{years}$, we observe ${^{16}}\\mathrm{O}/{^{18}}\\mathrm{O}$ ratios of order of unity, although the timescale on which ${^{18}}\\mathrm{O}$ is destroyed again is highly location dependent. Importantly, our calculations suggest that in the outer layers of the burning shell, the dominant production channel is $^{14}\\mathrm{C}(α,γ)^{18}\\mathrm{O}$ instead of the commonly considered $^{14}\\mathrm{N}(α,γ)^{18}\\mathrm{F}(β^+)^{18}\\mathrm{O}$ reaction, whereby the former can be sustained for longer periods of time. Furthermore, these outer regions do not reach the conditions necessary for fast $α$-captures in ${^{18}}\\mathrm{O}$ to ${^{22}}\\mathrm{Ne}$, thus being favorable to maintaining a low ${^{16}}\\mathrm{O}/{^{18}}\\mathrm{O}$ ratio.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16394v1",
        "authors": [
          "Alexander Holas",
          "Veronica Agaeva",
          "Friedrich K. Roepke",
          "Samuel W. Jones",
          "Javier Moran-Fraile"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Coronae Borealis",
        "Solar",
        "RCB",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.448208"
    },
    {
      "id": "arxiv-2602.16364v1",
      "title": "High significance detection at 4.8 GHz of the radio halo in the Coma galaxy cluster with the Sardinia Radio Telescope",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16364v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present the results of observations of the radio halo in the Coma galaxy cluster at 4.8 GHz performed with the Sardinia Radio Telescope. The radio halo in this cluster is detected for the first time at this frequency with a statistical significance higher than $3σ$. After the removal of the Radio Frequency Interference and of the discrete sources contribution, and after the correction for the Sunyaev-Zel'dovich effect, we estimate a flux density of $61\\pm11$ mJy, higher than the value previously reported in literature at this frequency. By using the value we obtained, it is possible to estimate an integrated spectral index between 4.8 and 6.6 GHz of $α\\sim1.17$, where $F(ν)\\propto ν^{-α}$, indicating a possible higher-frequency slowdown of the spectral steepening observed between 1.4 and 4.8 GHz. Such a spectral behavior is compatible with turbulent re-acceleration if the seed electrons have a spectrum extending up to high energies, as in the case of continuous injection by hadronic interactions or dark matter annihilation. We also report the detection at 4.8 GHz of a polarized spot inside the halo, without an evident counterpart, already detected at 6.6 GHz.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16364v1",
        "authors": [
          "P. Marchegiani",
          "M. Murgia",
          "F. Loi",
          "V. Vacca",
          "F. Govoni"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Radio Frequency Interference",
        "Sardinia Radio Telescope We",
        "Sardinia Radio Telescope",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.448647"
    },
    {
      "id": "arxiv-2602.16359v1",
      "title": "Numerical analysis of Lyapunov Times for Trans-Neptunian Objects and Main-Belt Asteroids: stability, accuracy, and methodological comparisons",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16359v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We computed Lyapunov times ($T_L$) for a sample of trans-Neptunian objects (TNOs) and outer main-belt asteroids (MBAs) using three numerical approaches: the variational method and two implementations of the renormalization technique. For each object, $T_L$ was derived both from the nominal orbit and from ensembles of 1001 orbital clones, enabling direct comparison between single-orbit and ensemble-based estimates. Across the sample, the methods generally produced consistent results, though larger discrepancies were observed for some MBAs. TNOs, in contrast, displayed greater consistency across methods, likely due to fewer overlapping resonances. Importantly, clone ensembles provided more robust and reliable stability indicators than nominal-orbit computations. Median values from clone populations reduced method-dependent biases and revealed dynamical behaviors that would remain hidden in single-orbit analyses, especially for objects with poorly constrained orbits or evolving in resonant regions. While our study focused on a limited but diverse set of objects, the methodology can be directly extended to larger populations, offering a systematic framework for exploring the long-term stability and dynamical evolution of main-belt asteroids, trans-Neptunian objects or other classes of objects in the Solar System.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16359v1",
        "authors": [
          "Paweł Wajer",
          "Małgorzata Królikowska",
          "Jakub Suchecki"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Neptunian Objects",
        "Lyapunov Times",
        "Belt Asteroids",
        "Solar System",
        "Framework",
        "Solar",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.448854"
    },
    {
      "id": "arxiv-2602.16295v1",
      "title": "SPT-CL J0417-4748: A Deep Chandra Study of a Relaxed Galaxy Cluster Without Central Star Formation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16295v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present an in-depth Chandra X-ray analysis of the galaxy cluster SPT-CL J0417$-$4748 (hereafter SPT J0417), at z = 0.58, with a focus on its thermodynamic properties and the apparent absence of central star formation. Utilizing a total Chandra exposure of 103 ks, we find that the large-scale X-ray morphology is consistent with a dynamically relaxed, cool-core system. The intracluster medium (ICM) shows a central density of 0.08+/-0.01 cm^{-3}, a central pseudo-entropy of 26^{+6}_{-5} keVcm^{2} and a central cooling time of 515^{+96}_{-75} Myr, values typical of massive cool-core clusters. Despite these conditions, no evidence of recent or ongoing star formation is detected in the brightest cluster galaxy (BCG). Spectral energy distribution (SED) fitting of DES photometry indicates that the bulk of the stellar population formed at z~1.25, with no significant star formation over the past ~3 Gyr, while optical spectra from Magellan show no [O II] emission. Complementary ASKAP radio and Spitzer infrared data indicate a lack of strong current AGN activity in the BCG. SPT J0417 exemplifies massive, relaxed, cool-core clusters in which cooling and star formation appear almost completely quenched, providing valuable insights into how AGN feedback regulates the long-term thermal balance of the intracluster medium.",
        "keywords": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16295v1",
        "authors": [
          "Taweewat Somboonpanyakul",
          "Adam B. Mantz",
          "Steven W. Allen",
          "Anthony M. Flores",
          "R. Glenn Morris"
        ],
        "arxiv_categories": [
          "astro-ph.CO",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Relaxed Galaxy Cluster Without",
        "Central Star Formation We",
        "Deep Chandra Study",
        "J0417-4748",
        "ASKAP",
        "AGN",
        "BCG",
        "Act",
        "SED",
        "SPT",
        "ICM",
        "DES",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.449124"
    },
    {
      "id": "arxiv-2602.16292v1",
      "title": "Gravitational Waves from Primordial Black Holes formed by Null Energy Condition Violation during Inflation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16292v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A transient violation of the null energy condition (NEC) during inflation provides a novel mechanism for producing primordial black holes (PBHs) and stochastic gravitational wave (GW) backgrounds. In this work, we extend previous studies by computing the GW contributions from both the ringdown phase of PBH formation and subsequent binary mergers. Our results show that this scenario produces a rich, multi-component GW spectrum consisting of primordial GWs, scalar-induced GWs, and GW emissions from PBH ringdown and binary mergers. We demonstrate that these correlated signatures across different frequency bands provide a novel and powerful avenue to probe or constrain NEC violation during inflation through future multi-band GW observations.",
        "keywords": [
          "gr-qc",
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16292v1",
        "authors": [
          "Dong-Hui Yu",
          "Jia-Zuo Zhang",
          "Yong Cai"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.CO",
          "hep-ph",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Null Energy Condition Violation",
        "Primordial Black Holes",
        "Gravitational Waves",
        "PBH",
        "NEC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.449259"
    },
    {
      "id": "arxiv-2602.16264v1",
      "title": "Prediction of Major Solar Flares Using Interpretable Class-dependent Reward Framework with Active Region Magnetograms and Domain Knowledge",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16264v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we develop, for the first time, a supervised classification framework with class-dependent rewards (CDR) to predict $\\geq$MM flares within 24 hr. We construct multiple datasets, covering knowledge-informed features and line-of sight (LOS) magnetograms. We also apply three deep learning models (CNN, CNN-BiLSTM, and Transformer) and three CDR counterparts (CDR-CNN, CDR-CNN-BiLSTM, and CDR-Transformer). First, we analyze the importance of LOS magnetic field parameters with the Transformer, then compare its performance using LOS-only, vector-only, and combined magnetic field parameters. Second, we compare flare prediction performance based on CDR models versus deep learning counterparts. Third, we perform sensitivity analysis on reward engineering for CDR models. Fourth, we use the SHAP method for model interpretability. Finally, we conduct performance comparison between our models and NASA/CCMC. The main findings are: (1)Among LOS feature combinations, R_VALUE and AREA_ACR consistently yield the best results. (2)Transformer achieves better performance with combined LOS and vector magnetic field data than with either alone. (3)Models using knowledge-informed features outperform those using magnetograms. (4)While CNN and CNN-BiLSTM outperform their CDR counterparts on magnetograms, CDR-Transformer is slightly superior to its deep learning counterpart when using knowledge-informed features. Among all models, CDR-Transformer achieves the best performance. (5)The predictive performance of the CDR models is not overly sensitive to the reward choices.(6)Through SHAP analysis, the CDR model tends to regard TOTUSJH as more important, while the Transformer tends to prioritize R_VALUE more.(7)Under identical prediction time and active region (AR) number, the CDR-Transformer shows superior predictive capabilities compared to NASA/CCMC.",
        "keywords": [
          "cs.LG",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16264v1",
        "authors": [
          "Zixian Wu",
          "Xuebao Li",
          "Yanfang Zheng",
          "Rui Wang",
          "Shunhuang Zhang"
        ],
        "arxiv_categories": [
          "cs.LG",
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Active Region Magnetograms",
        "Major Solar Flares Using",
        "Interpretable Class",
        "Domain Knowledge In",
        "Reward Framework",
        "Deep Learning",
        "Transformer",
        "Framework",
        "Solar",
        "CCMC",
        "SHAP",
        "NASA",
        "NSF",
        "LOS",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.449548"
    },
    {
      "id": "arxiv-2602.16262v1",
      "title": "PDRs4All XXI. JWST-NIRCam Photometric properties of protoplanetary disks in the Orion Nebula Cluster",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16262v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Orion Nebula Cluster (ONC) provides the closest example of star and planet formation in highly irradiated environments. It is a key region to study how UV radiation from massive stars drive mass-loss in protoplanetary disks through photoevaporation. Far-UV photons (6<E<13.6 eV) heat up the gas of the disk, forming a photodissociation region (PDRs). We use the NIRCam images from the PDRs4All program combined with those of the GTO program 1256 to extract key information on ONC disks. Specifically, the radii of the disks observed in silhouette against the bright background , the presence and positions of the dissociation fronts (DFs), the presence and positions of ionization fronts (IFs), intensities of Pa $α$ lines, and their near IR SEDs. From those, we construct a typology for ONC disks: Type I show an IF and DF nearly merged at the disk surface; Type II have their DFs at the disk surface and IFs at a distance of several 10s of astronomical units from the disk; and Type III also have their DF at the disk surface, but show no IF. For all disks, we find that PAH emission traces the PDR. We establish that the SEDs of candidate JuMBOs observed as part of the PDRs4All program are similar to the SEDs of Type III ONC disks except for JuMBO24, which is of Type I or II. A detailed look at this SED shows it is compatible with a young low mass binary star with an unresolved ionized disk : a microproplyd binary. We observe that the disk radius of ONC disks increases with increasing projected distance to the ionizing source interpreted as evidence of the truncation of the disks by the photoevaporation. The disk radii measured at IR wavelengths appear larger than at millimeter wavelengths, interpreted as evidence of the dust radial segregation within the disks. The thermal pressure within the PDRs of ONC disk increases with the FUV radiation field, but with a flatter slope.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16262v1",
        "authors": [
          "P. Amiot",
          "O. Berné",
          "I. Schroetter",
          "M. Robberto",
          "T. J. Haworth"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Orion Nebula Cluster",
        "JWST",
        "FUV",
        "PAH",
        "PDR",
        "XXI",
        "Act",
        "GTO",
        "SED",
        "III",
        "ONC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.450206"
    },
    {
      "id": "arxiv-2602.16252v1",
      "title": "A XRISM View of the Iron Line Complex in NGC 1068: Rethinking the Prototypical Compton-Thick AGN",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16252v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We analyze an XRISM/Resolve observation of NGC1068, focusing on the Fe K$α$ and Fe K$β$ fluorescent lines and on the Fe XXV and Fe XXVI emission complexes. Line centroid energies, intrinsic widths, flux ratios, and constraints on the Compton shoulder are derived through local spectral fitting, and compared with atomic calculations and theoretical predictions. The centroid energies of the Fe K$α$ and Fe K$β$ lines tightly constrain the emitting material to be neutral or near-neutral. The observed Fe K$β$/K$α$ ratio, together with the stringent upper limit on the Compton shoulder ($\\lesssim$8--11% of the core flux), disfavour reflection dominated by a homogeneous, classical Compton-thick medium, indicating that most of the neutral Fe K$α$ emission arises in optically thin or moderately Compton-thick gas. The Fe XXV and Fe XXVI emission lines exhibit remarkably large velocity widths, of several thousand km~s$^{-1}$. These broad profiles closely resemble the integrated optical and infrared [O III] and [O IV] lines associated with the large-scale biconical outflow, and are naturally interpreted as the X-ray signature of a more highly ionized, faster, and more spatially confined phase of the same outflow. The iron-K emission of NGC1068 reveals a stratified circumnuclear environment in which neutral and highly ionized components arise in physically distinct regions. The neutral Fe K fluorescence originates predominantly in optically thin or mildly Compton-thick material, despite the persistently Compton-thick line-of-sight obscuration, indicating a geometrically complex cold reprocessor. The highly ionized iron emission lines trace a fast component consistent with a warm bipolar outflow on parsec scales, whose large velocities and inferred energetics suggest that it may represent an efficient channel for feedback in a heavily obscured Seyfert galaxy.",
        "keywords": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16252v1",
        "authors": [
          "S. Bianchi",
          "B. Vander Meulen",
          "E. Bertola",
          "V. Braito",
          "A. Comastri"
        ],
        "arxiv_categories": [
          "astro-ph.HE",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Prototypical Compton",
        "Iron Line Complex",
        "Nuclear",
        "XRISM",
        "XXVI",
        "XXV",
        "NGC",
        "MIT",
        "WHO",
        "AGN",
        "III",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.450873"
    },
    {
      "id": "arxiv-2602.16239v1",
      "title": "Propagation Characteristics of the April 21, 2023 CME",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16239v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Accurate estimation of propagation characteristics of coronal mass ejections (CMEs) is crucial for predicting their geoeffectiveness. Stereoscopic techniques to study the kinematics of CMEs generally have been carried out using remote sensing observations from three viewpoints, i.e. STEREO-A, STEREO-B, and SOHO. Since the loss of STEREO-B in 2014, stereoscopic reconstruction of CMEs has been restricted to the observations from only two viewpoints, i.e., STEREO-A and SOHO. When the angle of separation between STEREO-A and SOHO is small, it leads to larger uncertainties in the CME kinematics derived using stereoscopic techniques. In this paper, we demonstrate how this limitation can be addressed and how uncertainties in the estimation of CME kinematics and propagation direction can be reduced. For this purpose, we selected the CME of April 21, 2023, which was observed by two spacecraft, i.e. STEREO-A and SOHO, separated by a small 10 degree angle. Using the Graduated Cylindrical Shell (GCS) model on the remote-sensing observations near the Sun and the Advanced Drag-Based Model (ADBM) in the heliosphere, we estimated the arrival time of the CME at different locations in the heliosphere and compared it with the actual arrival time obtained from the in-situ measurements taken by three spacecraft, BepiColombo, STEREO-A and Wind. Our analysis reveals a directional uncertainty of approx 20 degree from observations from two viewpoints. These uncertainties significantly affect the arrival-time prediction of the CME. We consider the actual chronology of CME arrival times at STEREO-A and Wind as critical parameters to constrain the direction of propagation, which serves as a key input in the ADBM. The chronology of arrival of the CME ejecta at STEREO-A, which is 4.5 hrs earlier than at Wind, proved essential for resolving directional ambiguities in the GCS reconstruction model",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16239v1",
        "authors": [
          "Sandeep Kumar",
          "Nandita Srivastava",
          "Parthib Banerjee",
          "Nat Gopalswamy"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Propagation Characteristics",
        "Graduated Cylindrical Shell",
        "Advanced Drag",
        "Based Model",
        "STEREO",
        "Wind",
        "SOHO",
        "ADBM",
        "EPA",
        "CME",
        "GCS",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.451142"
    },
    {
      "id": "arxiv-2602.16237v1",
      "title": "Rotating Black Holes with Primary Scalar Hair: Shadow Signatures in Beyond Horndeski Gravity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16237v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Event Horizon Telescope (EHT) image of M87* provides a direct test of strong-field gravity, measuring an angular shadow diameter $θ_d = 42 \\pm 3~μ\\mathrm{as}$ and a circularity deviation $ΔC \\leq 0.1$. Such observations allow quantitative tests of the Kerr paradigm and of possible deviations from the no-hair theorem. In scalar-tensor extensions of gravity, black holes may possess primary scalar hair, introducing an additional independent parameter beyond mass and spin. In this work, we construct rotating black hole solutions with primary scalar hair in beyond Horndeski gravity and analyze their photon regions and shadow formation. We show that the scalar hair parameter $Q$ induces characteristic modifications of the shadow, and in particular negative $Q$ enlarges the shadow and reduces its oblateness, while positive $Q$ shrinks and enhances its distortion. Modeling M87* within this framework and imposing the EHT bounds on $θ_d$ and $ΔC$, we determine the viable $(a,Q)$ parameter space. We find that current observations do not exclude rotating black holes with primary scalar hair, although the allowed region is significantly restricted for $Q>0$. Finally, the scalar-hair-induced deviations are of order $\\mathcal{O}(μ\\mathrm{as})$, placing them near the sensitivity threshold of present instruments and within reach of next-generation horizon-scale imaging.",
        "keywords": [
          "gr-qc",
          "astro-ph.CO",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16237v1",
        "authors": [
          "Kourosh Nozari",
          "Milad Hajebrahimi",
          "Sara Saghafi",
          "G. Mustafa",
          "Emmanuel N. Saridakis"
        ],
        "arxiv_categories": [
          "gr-qc",
          "astro-ph.CO",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Event Horizon Telescope",
        "Rotating Black Holes",
        "Primary Scalar Hair",
        "Shadow Signatures",
        "Framework",
        "EHT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.451612"
    },
    {
      "id": "arxiv-2602.16227v1",
      "title": "The Enigmatic Type Icn Supernova 2024abvb Located ~22 kpc from Its Host Galaxy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16227v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We report multiwavelength observations of the highly offset (~22.4 kpc) SN 2024abvb, the sixth Type Icn supernova to date. With a peak magnitude of Mr = -19.55 +/- 0.11 mag, it is among the most luminous in the existing sample and shows similar colours and decline rates to other SNe Icn. The early optical spectra show a blue continuum with narrow C II features (vFWHM ~ 2000 km s^-1), consistent with a typical wind velocity of a Wolf-Rayet star. The absence of C III lambda 5696 emission at the time of explosion is consistent with a Type Ibn supernova; however, the lack of narrow He lines in both the optical and near-infrared spectra supports a SNe Icn classification. Unlike the majority of SNe Icn, we do not detect broad features in the late-time (7-21 days relative to o-band peak) spectral phase of SN 2024abvb. Semi-analytical modelling of the light curves shows that it can be reproduced by ~2.6 Msun of SN ejecta interacting with ~0.3 Msun of circumstellar material (CSM), both larger than other SNe Icn but consistent with rapidly evolving SNe Ibn. The metallicity at the SN location is significantly lower than the global metallicity of its host galaxy, suggesting that line-driven mass loss required to strip the progenitor of its H and He envelopes was likely inefficient. We estimate the star-formation-rate history at the location of SN 2024abvb and find that it lies at the bottom ~5th percentile among SESNe hosts, inconsistent with a Wolf-Rayet progenitor. Based on its spectral features, local and host environment properties, and host-galaxy offset, we favour an 8-10 Msun star stripped by a compact companion as the progenitor, with a sufficient runaway velocity to reach the observed offset.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16227v1",
        "authors": [
          "J. Shi",
          "K. Auchettl",
          "W. B. Hoogendam",
          "D. Farias",
          "N. Sarin"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Its Host Galaxy We",
        "Type Ibn",
        "Type Icn",
        "Meta",
        "Wind",
        "CSM",
        "Act",
        "III",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.451891"
    },
    {
      "id": "arxiv-2602.16214v1",
      "title": "Cosmic Ray Spectra and Metal Budget Regulated by the Galactic Wind",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16214v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the advection effect of the Galactic wind on the local cosmic ray spectra. The spectral hardening from a few hundred GV and softening from a few TV are reproduced by a velocity profile with a maximum velocity of $\\sim 700~\\mbox{km}~ \\mbox{s}^{-1}$ without introducing a break in the power-law dependence of the diffusion coefficient. Additionally, we find that a hard CR spectrum below $\\sim$ TV with an index of $\\sim 2$ at an altitude $\\sim 3$-$5$ kpc from the Galactic disk. This hard spectrum is favorable for the gamma-ray spectrum of the Fermi bubbles. With the obtained CR fluxes, we discuss the matter circulation in our Galaxy with the wind. While the wind has an essential role in maintaining the metal abundance in the disk, the production rate of Beryllium, which originates from CR spallation, is so low that the ratio Be/O in the halo should be larger than that in the disk gas.",
        "keywords": [
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16214v1",
        "authors": [
          "Yusaku Fukumoto",
          "Katsuaki Asano",
          "Jiro Shimoda"
        ],
        "arxiv_categories": [
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Metal Budget Regulated",
        "Cosmic Ray Spectra",
        "Galactic Wind We",
        "Fusion",
        "Meta",
        "Wind",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.452078"
    },
    {
      "id": "arxiv-2602.16139v1",
      "title": "Investigating Ionospheric TEC Variations in Solar and Geomagnetic Influences Across Solar Activity Phases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16139v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This study examines the variability of ionospheric total electron content (VTEC) in response to solar and geomagnetic drivers across solar cycles 23 to 25. While the dominant effect of solar radiation on VTEC is well-known, a comprehensive understanding of how these relationships and their time-lags vary across distinct solar cycle phases and across cycles of differing intensity has been lacking. Using global VTEC data from the Chinese Academy of Sciences Global Ionospheric Maps (CASG) and solar-geophysical indices from NASA's OMNI dataset spanning from 1998 to 2025, this study bridges that gap by quantifying correlation strengths and time-lag relationships between VTEC and parameters such as $F_{10.7}$ solar flux, R sunspot number, Kp, Ap, and Dst indices, and solar wind properties. Results show that solar proxies, particularly $F_{10.7}$ and R sunspot number, exhibit the strongest, most consistent correlations with VTEC, especially during the ascending and descending phases of the solar cycle, with a characteristic $\\sim2$-day lag attributed to thermospheric oxygen dynamics and ionospheric recombination processes. In contrast, geomagnetic indices exhibit weaker and phase-dependent correlations, while direct correlations between solar wind parameters and global VTEC are weak, as their influence is primarily mediated by geomagnetic activity and exhibits strong regional and temporal heterogeneity. Phase-resolved analyses further reveal that geomagnetic activity plays a more prominent role during transitional phases, while maximum and minimum periods are dominated by EUV variability and non-solar drivers, respectively. These findings highlight the necessity of incorporating solar phase and time-lag dependencies in ionospheric modelling and forecasting efforts.",
        "keywords": [
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16139v1",
        "authors": [
          "Ziyadat Hassan",
          "Zamri Zainal Abidin",
          "Affan Adly Nazri",
          "Nursyazela Badrina Baharin"
        ],
        "arxiv_categories": [
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Geomagnetic Influences Across Solar",
        "Sciences Global Ionospheric Maps",
        "Investigating Ionospheric",
        "Chinese Academy",
        "Solar",
        "NASA",
        "Wind",
        "VTEC",
        "OMNI",
        "CASG",
        "EUV",
        "Act",
        "TEC",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.452336"
    },
    {
      "id": "arxiv-2602.16134v1",
      "title": "First Detection of the Baryon Acoustic Oscillation (BAO) Feature in the 3-Point Correlation Function of DESI DR1 Luminous Red Galaxies",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16134v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present the first detection of the 3-Point Correlation Function (3PCF) Baryon Acoustic Oscillation (BAO) signal from the DESI Data Release 1 (DR1) sample of Luminous Red Galaxies (LRGs), which contains over 2.1 million galaxies. Our analysis is based on a tree-level redshift-space bispectrum template, which is then transformed to position space using the Fast Fourier Transform on Logarithmic scales (FFTLog) algorithm. We detect the BAO feature with a significance of approximately $8.1σ$ using the EZmock covariance matrix and $8.5σ$ using the analytical covariance matrix, for the full LRG redshift range ($0.4<z<1.1$), denoted as the $z_{\\rm full}$ sample. We use the Abacus altMTL mocks, the most precise DESI DR1 mock catalogs currently available, to validate our model. We find that our model fits the mocks well, with a small offset of $0.6\\%$ in the recovered BAO scale, which we treat as a systematic error due to modeling. We measure the angle-averaged distance, $D_{\\rm V}(z = 0.68)/r_{\\rm d} = 15.88 \\pm 0.27$ ($1.72\\%$ precision) when using the covariance matrix estimated from EZmocks and $D_{\\rm V}(z = 0.68)/r_{\\rm d} = 15.72 \\pm 0.18$ ($1.12\\%$ precision) when using the analytical Gaussian covariance matrix. Our results show excellent agreement with the DESI DR1 2PCF BAO measurements as well. We also explore several other ways to estimate the error and find between $1.7$--$2.2\\%$ precision on the BAO scale from the EZmock covariance matrix and between $1.1$--$1.5\\%$ precision from the analytical covariance matrix. This work represents the first detection of the BAO feature in the DESI 3PCF, establishing its ability to probe the expansion history of the Universe with future DESI 3PCF measurements.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16134v1",
        "authors": [
          "Farshad Kamalinejad",
          "Zachary Slepian",
          "Alex Krolewski",
          "Alessandro Greco",
          "William Ortolá Leonard"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Baryon Acoustic Oscillation",
        "Point Correlation Function",
        "Luminous Red Galaxies We",
        "Fast Fourier Transform",
        "Luminous Red Galaxies",
        "First Detection",
        "Data Release",
        "Agreement",
        "DESI",
        "BAO",
        "LRG",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.452982"
    },
    {
      "id": "arxiv-2602.16128v1",
      "title": "Graph--Based Event Fingerprints for Classifying Geomagnetic Storm--Driven Forbush Decreases",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16128v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Forbush decreases (FDs) are transient depressions in the galactic cosmic-ray flux observed by global neutron-monitor networks and are commonly associated with interplanetary disturbances driven by coronal mass ejections and related shocks. Despite extensive observational work, quantitatively comparing FD morphology across events and linking it to storm severity remains challenging due to heterogeneous station responses, coverage gaps, and the multivariate nature of the network. This work introduces a graph-based event representation in which each FD is mapped to an event network constructed from pairwise dissimilarities between station response time series. A controlled sparse backbone is obtained via the minimum spanning tree, enabling comparable event graphs across cases. From each graph, a compact set of geometric/topological fingerprints is computed, including global integration measures, spectral summaries, mesoscopic structure, centrality aggregates, and complexity descriptors. Predictive skill is assessed using strict leave-one-event-out validation over a pre-defined grid of distance metrics and distance-domain transformations, with selection criteria fixed \\emph{a priori}. The proposed fingerprints exhibit measurable signal for three tasks: (i) multi-class classification of geomagnetic storm intensity (G3/G4/G5) with moderate but consistent performance and errors dominated by adjacent categories; (ii) stronger binary severity screening ($\\ge$G4 vs.\\ G3) with high sensitivity to severe events; and (iii) drop regression with partial least squares achieving positive explained variance relative to a fold-wise mean baseline.",
        "keywords": [
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16128v1",
        "authors": [
          "Juan D. Perez-Navarro",
          "D. Sierra-Porta"
        ],
        "arxiv_categories": [
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Forbush Decreases Forbush",
        "Classifying Geomagnetic Storm",
        "Based Event Fingerprints",
        "NSF",
        "Act",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.453215"
    },
    {
      "id": "arxiv-2602.16117v1",
      "title": "Solving BDNK diffusion using physics-informed neural networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16117v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we reformulate the relativistic BDNK (Bemfica-Disconzi-Noronha-Kovtun) diffusion equation in flux-conservative form, and solve the resulting equations in $(1+1)$D using both a second-order Kurganov-Tadmor finite volume scheme and physics-informed neural networks (PINNs). In particular, we introduce the SA-PINN-ACTO framework, which combines the self-adaptive PINN technique with an exact enforcement of initial and periodic boundary conditions through an algebraic transform of the network's raw output, allowing the network to focus solely on minimizing the PDE residual. We test both approaches on smooth and discontinuous initial data, for both trivial and dynamically evolving velocity and temperature BDNK backgrounds, and for two characteristic speeds. The SA-PINN-ACTO method matches the converged Kurganov-Tadmor solutions for smooth profiles, while for discontinuous profiles the errors increase, reflecting an expected limitation of PINNs near sharp gradients.",
        "keywords": [
          "nucl-th",
          "astro-ph.HE",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16117v1",
        "authors": [
          "Vicente Chomalí-Castro",
          "Nick Clarisse",
          "Nicki Mullins",
          "Jorge Noronha"
        ],
        "arxiv_categories": [
          "nucl-th",
          "astro-ph.HE",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neural Network",
        "Framework",
        "Fusion",
        "ACTO",
        "BDNK",
        "PINN",
        "NSF",
        "Act",
        "PDE",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.453365"
    },
    {
      "id": "arxiv-2602.16107v1",
      "title": "Effects of Symmetron on growth and RSD multipoles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16107v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we investigate the effects of the growth rate scale dependence in the Symmetron modified gravity (MG) model on cosmic structure formation and we analyze the redshift-space distortion (RSD) multipoles, comparing with the Hu-Sawicki $f(R)$ model (specifically the F6) and the standard $Λ$CDM model. The analysis employs a scale-dependent growth equation and utilizes the fk-PT perturbation theory approach, implemented in the FOLPS-nu code, to compute the full 1-loop power spectrum multipoles, in particular, the monopole and quadrupole ($\\ell=0,2$, respectively). The results show that at redshift $z=0$, the monopole of both MG models is suppressed compared to $Λ$CDM, with the Symmetron being closer to the standard model, while the quadrupole presents the opposite behavior. To validate the pipeline, we use General Relativity (GR) mock catalogs (EZMocks), since suitable Symmetron simulations are not available. The main result is that the Markov Chain Monte Carlo (MCMC) analysis successfully recovers the expected GR limit (i.e., $β_0 \\approx 0$) from the Symmetron model when applied to this mock data, confirming the viability of our methodology for cosmological inference. Then, we conclude that the pipeline is prepared to test MG models against current and near-future galaxy surveys.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16107v1",
        "authors": [
          "Gerardo Morales-Navarrete",
          "Jorge L. Cervantes-Cota"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Markov Chain Monte Carlo",
        "General Relativity",
        "Standard",
        "FOLPS",
        "MCMC",
        "EPA",
        "CDM",
        "RSD",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.453793"
    },
    {
      "id": "arxiv-2602.16095v1",
      "title": "Three Saturn-mass Microlensing Planets Identified through Signals from Peripheral-caustic Perturbations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16095v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We present the discovery and analysis of three microlensing planets identified through brief positive anomalies on the wings of their light curves. The events, KMT-2021-BLG-0852, KMT-2024-BLG-2005, and KMT-2025-BLG-0481, were detected in high-cadence survey data from the KMTNet, OGLE, MOA, and PRIME collaborations. The anomaly morphologies are consistent with major-image perturbations induced by planetary-mass companions located near the peripheral caustic. A systematic exploration of model degeneracies, including binary-source scenarios, higher mass-ratio binary lenses, and the inner--outer caustic degeneracy, firmly establishes the planetary origin of each signal. Measurements of the angular Einstein radius and event timescale, combined with Bayesian priors from a Galactic model, yield the physical parameters of each system. The hosts are low-mass stars (0.12--0.75~$M_\\odot$), while the companions are Saturn-mass planets (0.16--0.59 $M_{\\rm J}$) projected at separations of 1.1--7.8 au, placing them beyond the snowline of their hosts. These results demonstrate the capability of microlensing to detect and characterize cold giant planets around low-mass stars at kpc distances, populating the critical transition region between ice giants and gas giants.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16095v1",
        "authors": [
          "Cheongho Han",
          "Chung-Uk Lee",
          "Andrzej Udalski",
          "Ian A. Bond",
          "Michael D. Albrow"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.GA"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Microlensing Planets Identified",
        "Perturbations We",
        "Three Saturn",
        "KMT-2025",
        "KMT-2024",
        "KMT-2021",
        "BLG-0852",
        "BLG-0481",
        "BLG-2005",
        "PRIME",
        "OGLE",
        "EPA",
        "BLG",
        "KMT",
        "Act"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.454057"
    },
    {
      "id": "arxiv-2602.16082v1",
      "title": "Evolution of Low-Mass Population III Stars: Convection, Mass Loss, Nucleosynthesis, and Neutrinos",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16082v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The first stars likely formed from pristine clouds, marking a transformative epoch after the dark ages by initiating reionisation and synthesising the first heavy elements. Among these, low-mass Population III stars are of particular interest, as their long lifespans raise the possibility that some may survive to the present day in the Milky Way's stellar halo or satellite dwarfs. As the first paper in a series, we present hydrodynamic evolutionary models for 0.7 - 1 MSun stars evolved up to the white dwarf phase, utilising the MESA software instrument. We systematically vary mass-loss efficiencies, convective transport, and overshooting prescriptions, thereby mapping how uncertain physics influences nucleosynthetic yields; surface enrichment, including nitrogen-rich post-main sequence stars arising from convective shell mergers; remnant properties, such as low-mass helium or carbon-oxygen white dwarfs (M_WD ~ 0.45-0.55 MSun) and transient UV-bright phases; and potential observational signatures, including neutrino emission during shell mergers and helium flashes. These models establish a predictive framework for identifying surviving Pop III stars and their descendants, providing both evolutionary and observational constraints that were previously unexplored.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16082v1",
        "authors": [
          "Thiago Ferreira",
          "Earl P. Bellinger",
          "Ebraheem Farag",
          "Christopher J. Lindsay"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mass Population",
        "Milky Way",
        "Framework",
        "Mass Loss",
        "Satellite",
        "MESA",
        "NSF",
        "III",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.454246"
    },
    {
      "id": "arxiv-2602.16077v1",
      "title": "The Carousel Lens II: Cosmological Constraints with GIGA-Lens",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16077v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The nature of dark matter and dark energy are among the central questions in cosmology. Strong gravitational lenses with multiple source planes provide a geometric probe of cosmology: the ratio of deflection angles at different redshifts depends only on angular-diameter distances, constraining the matter density $Ω_m$ and the dark energy equation of state $w$. However, constraints from this technique have historically lagged behind those from the CMB, SNe Ia, and BAO. In this work, we present new cosmological constraints from the Carousel Lens, a cluster-scale lens with more than 40 extended images from 11 spectroscopically confirmed sources. Its relaxed core and rich set of extended images behind the main halo make it particularly suitable for cosmological inference. Using the GIGA-Lens pipeline, we construct a pixel-level lens model including six HST-detected sources and four mass components. From this model, we obtain $w$CDM constraints of $Ω_m = 0.34^{+0.16}_{-0.13}$ and $w = -1.31^{+0.35}_{-0.32}$ from the Carousel Lens alone, accounting for both statistical and systematic uncertainties. We further project that including four additional known higher-redshift sources, assuming similar fractional uncertainties, could improve the constraining power by ~80%, bringing the precision close to that of the CMB and SNe Ia. For an evolving dark energy model ($w_0w_a$CDM), the Carousel Lens alone yields constraints comparable to the CMB, providing an independent and complementary probe alongside SN Ia and BAO. While currently systematic uncertainties dominate, which we quantify through simulations, our results demonstrate that relaxed multi-source-plane cluster lenses can deliver competitive cosmological constraints. Further improvements are expected from reductions in systematics and from incorporating higher-redshift sources (known and new) with high-resolution imaging.",
        "keywords": [
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16077v1",
        "authors": [
          "Felipe Urcelay",
          "Xiaosheng Huang",
          "William Sheu",
          "Jackson H. O'Donnell",
          "Tesla Jeltema"
        ],
        "arxiv_categories": [
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cosmological Constraints",
        "Carousel Lens",
        "GIGA",
        "BAO",
        "HST",
        "CDM",
        "Act",
        "CMB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.454892"
    },
    {
      "id": "arxiv-2602.16056v1",
      "title": "Direct contact binary planetesimal formation from gravitational collapse",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16056v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Bilobate contact binaries comprise a significant fraction of the relict Kuiper Belt, which includes the exemplary contact binary (486958) Arrokoth. The surfaces of its lobes contain similar amounts of highly volatile chemical species and few craters, indicating formation in a homogeneous and gentle environment. Arrokoth's bilobate shape was initially hypothesized to have formed via the direct gravitational collapse of a pebble cloud in the solar system's protoplanetary disk. However, alternative hypotheses have proposed that Arrokoth may be the result of binary planetesimal formation and the subsequent dynamical evolution of the binary components into contact through external perturbations over long timescales. Here, we show that contact binary planetesimals like Arrokoth can form directly from the gravitational collapse of pebble clouds. We used a soft-sphere discrete element method (SSDEM) to discover that planetesimals form a wide variety of shapes, including bilobate contact binaries. This method creates planetesimals as particle-aggregates with particles resting upon each other's surfaces via mutual surface penetration. The formation of contact binaries in our simulations strengthens the hypothesis that Arrokoth, and perhaps many other contact binaries in the Kuiper Belt, formed directly as bilobate objects from gravitational collapse, and so their shapes and surfaces record the era of planet formation.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16056v1",
        "authors": [
          "Jackson T. Barnes",
          "Stephen R. Schwartz",
          "Seth A. Jacobson"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Kuiper Belt",
        "SSDEM",
        "Solar",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.455109"
    },
    {
      "id": "arxiv-2602.16043v1",
      "title": "Diffusive Instabilities in Dusty Disks: Linear Growth and Nonlinear Breakdown",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16043v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We revisit the diffusive instability in dusty disks that arises when the dust mass diffusivity and/or viscosity decreases sufficiently steeply with increasing dust density. Our updated model includes an incompressible, viscous gas that responds azimuthally and couples to the dust through drag. We show that the basic criterion for diffusion-slope-driven instability remains approximately $β_\\mathrm{diff}\\lesssim -2$ for small dust stopping times, with gas feedback providing only modest quantitative changes for parameters motivated by streaming-instability turbulence. We perform nonlinear numerical calculations and confirm linear growth and mode selection toward the fastest-growing wavenumber. However, for power-law closures $D\\proptoΣ^{β_\\mathrm{diff}}$ with $β_\\mathrm{diff}<0$, the nonlinear evolution does not saturate. Instead, steepening gradients amplify the nonlinear dust-pressure term and drive finite-time collapse into increasingly sharp spikes. Motivated by the absence of multidimensional saturation channels in our 1D framework, we test a simple piecewise closure in which the negative diffusion slope operates only over a finite density interval. This modification eliminates blowup and produces peak densities controlled by the imposed saturation scale. Our results support diffusive instabilities as a linear organizing mechanism in dusty turbulence, while highlighting that realistic nonlinear saturation requires additional physics beyond the present closure.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16043v1",
        "authors": [
          "Konstantin Gerbig",
          "Min-Kai Lin"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Diffusive Instabilities",
        "Nonlinear Breakdown We",
        "Linear Growth",
        "Dusty Disks",
        "Framework",
        "Fusion",
        "DOE",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.455615"
    },
    {
      "id": "arxiv-2602.16030v1",
      "title": "Molecular diagnostics for the mid-infrared emission of planet-forming disks. Carbon and oxygen elemental abundances",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16030v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Mid-infrared observations of planet-forming disks reveal a wide diversity in molecular spectra. Carbon and oxygen abundances play a central role in setting the chemical environment of the inner disk and the spectral appearance. We aim to systematically explore how variations in elemental carbon and oxygen abundances affect the mid-infrared spectra of planet-forming disks, and to identify robust mid-infrared molecular diagnostics of C/H, O/H, and the C/O ratio. Using the thermochemical disk code ProDiMo and the line radiative transfer code FLiTs, we construct a grid of 25 models with varying carbon and oxygen abundances, covering a broad range of C/O ratios. We analyze the resulting mid-infrared molecular emission, including species such as $\\rm H_2O$, $\\rm CO$, $\\rm CO_2$, $\\rm C_2H_2$, $\\rm OH$. We find that the mid-infrared molecular spectra are highly sensitive not only to the C/O ratio, but also to the absolute abundances of carbon and oxygen. Despite the same disk structure and C/O ratios, molecular fluxes (e.g., $\\rm C_2H_2$, $\\rm CO_2$) vary by more than an order of magnitude. This variation stems from the differences in excitation conditions and emitting regions caused by the elemental abundances of oxygen and carbon. We identify diagnostic molecular flux ratios - such as $\\rm CO_2$/$\\rm H_2O$ and $\\rm H_2O$/$\\rm C_2H_2$ - that can serve as tracers of C/H and O/H respectively. By combining these diagnostics, we demonstrate a method to infer the underlying C/O ratio. Our model grid provides a framework for interpreting mid-infrared molecular emission from disks, allowing estimates of elemental abundances if the disk properties and structure are known. Comparisons with recent JWST observations suggest that a variety in C and O abundances is seen in a sample of T Tauri disks, possibly shaped by disk transport processes and the presence of gaps.",
        "keywords": [
          "astro-ph.EP",
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16030v1",
        "authors": [
          "Aditya M. Arabhavi",
          "Inga Kamp",
          "Ewine F. van Dishoeck",
          "Peter Woitke",
          "Christian Rab"
        ],
        "arxiv_categories": [
          "astro-ph.EP",
          "astro-ph.GA",
          "astro-ph.SR"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Framework",
        "JWST",
        "NSF",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.455899"
    },
    {
      "id": "arxiv-2602.16009v1",
      "title": "CHARA Array Delay Lines: Upgrades, Performance and Future Directions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16009v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Long baseline optical and infrared interferometric arrays achieve high angular resolution and enable detailed astrophysical measurements. Interferometers have enabled observations of stars at various stages of evolution, as well as studies of binary stars, circumstellar disks, and active galactic nuclei. The CHARA Array is a long-baseline interferometric array at the Mount Wilson Observatory, USA. At the core of CHARA operations are the delay lines, which equalize the optical path length for all telescopes as the Earth rotates and compensate for optical path variations induced by atmospheric turbulence. We report recent upgrades and performance of the CHARA Array optical delay lines for high-precision interferometric observations. The legacy system had been operational for over two decades, and it was increasingly difficult to acquire replacement parts. Beginning in mid-2021, the control system underwent a major upgrade, replacing the aging VME-based architecture with a modern hybrid FPGA and Linux-based system; this modernization continued through the end of 2024. We describe hardware/software changes, the servo architecture, and lab/on-sky performance. The upgraded system achieves residual delay line cart tracking errors of $\\sim12$~nm, the same level as the legacy system, and a control bandwidth of 100-130~Hz, allowing fringe tracking across the R, H, and K bands. Initial commissioning revealed key issues such as metrology time-tick jitter and vibration-induced visibility loss, which were diagnosed and resolved. We note ongoing and future efforts to extend baselines up to 1~km and support advanced observing modes such as dual-field interferometry and nulling. This paper is a reference for current and future use of the CHARA Array and for next-generation instrument design.",
        "keywords": [
          "astro-ph.IM",
          "astro-ph.SR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16009v1",
        "authors": [
          "Narsireddy Anugu",
          "Nils H. Turner",
          "Theo A. ten Brummelaar",
          "Gail H. Schaefer",
          "Philippe Bério"
        ],
        "arxiv_categories": [
          "astro-ph.IM",
          "astro-ph.SR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mount Wilson Observatory",
        "Future Directions Long",
        "Array Delay Lines",
        "CHARA",
        "FPGA",
        "USA",
        "Act",
        "VME",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.456174"
    },
    {
      "id": "arxiv-2602.15979v1",
      "title": "Multiwavelength Campaign Observations of a Young Solar-type Star, EK Draconis. III. Comparison between Starspot Mapping, Zeeman Doppler Imaging, and Multiwavelength Variability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15979v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Recent simultaneous multiwavelength observations of a nearby young solar-type star EK Dra in the optical, H$α$ spectrum, and X-ray, have provided evidence for stellar prominence eruptions associated with superflares. The large prominence eruption is suggested to have been caused by a large mid-latitude spot on the polarity inversion lines near the stellar limb from the concurrent Zeeman Doppler Imaging (ZDI) and optical photometry by the TESS. In this study, we perform starspot mapping for the TESS data of EK Dra to investigate the relation of starspots and magnetic fields from the photometry and ZDI. We also explore the multiwavelength rotational variability ascribed to starspots and active regions for the TESS, B-band, H$α$, and X-ray light curves. As a result, we find that (i) spot locations deduced from the TESS light curve are mostly consistent with the intensity map from the ZDI except for a polar spot, and (ii) the H$α$ light curve exhibits clear periodicity with respect to the TESS light curve because the H$α$ line is radiated around spots in the chromosphere. The X-ray light curve does not show such association probably because of multiple spots on high activity level and extended spatial structure of coronal active regions. The results provide clues to explore their association with stellar flares at different heights of active regions in chromospheric and coronal lines. Our study also enables us to quantify the stellar XUV radiation from the magnetic fields of active stars toward understanding atmospheric evolution of exoplanets.",
        "keywords": [
          "astro-ph.SR",
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15979v1",
        "authors": [
          "Kai Ikuta",
          "Kosuke Namekata",
          "Pascal Petit",
          "Vladimir S. Airapetian",
          "Hiroyuki Maehara"
        ],
        "arxiv_categories": [
          "astro-ph.SR",
          "astro-ph.EP",
          "astro-ph.IM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multiwavelength Campaign Observations",
        "Multiwavelength Variability Recent",
        "Zeeman Doppler Imaging",
        "Starspot Mapping",
        "Young Solar",
        "Solar",
        "TESS",
        "DOE",
        "XUV",
        "Act",
        "ZDI",
        "III",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.456759"
    },
    {
      "id": "arxiv-2602.15978v1",
      "title": "Planet-Disk Interactions and the Convective Overstability. I. Low Mass Planets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15978v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Rapid inward migration driven by Type I torques threatens the survival of low-mass planets in their nascent protoplanetary disks (PPDs). Positive co-rotation torques offer a potential solution, but require viscous diffusion to remain unsaturated. However, it is unclear if (magneto)-hydrodynamic turbulence provides the necessary diffusion, and disk profiles supporting such torques are often also susceptible to the Convective Overstability (COS) for suitable gas cooling timescales. To this end, we investigate torques on low-mass planets through radially global 2D (razor-thin) and vertically unstratified 3D hydrodynamic simulations of PPDs with thermal diffusion and optically thin cooling. Our 3D models with thermal diffusion, which allows COS development, show systematically different torque behavior compared to 2D models, wherein COS is absent. In 3D, the COS saturates into large-scale, long-lived vortices that migrate radially and interact gravitationally with the embedded planet. When these vortices encounter the planet, they typically provide positive torque \"kicks\" counteracting inward migration, as the less-massive vortices are scattered onto horseshoe orbits by the more-massive planet. We validate our simulation methods against the theoretical framework of Paardekooper et al. (2011) and demonstrate that COS-induced torque modifications can extend migration timescales by factors of approximately 10. For plausible disk models, our results suggest that COS activity can lengthen migration timescales sufficiently to overlap with, or even exceed Super-Earth formation windows (0.1-5 Myr). In contrast, simulations with optically thin cooling do not show significant torque modifications, as COS saturates in near-axisymmetric structures without producing large-scale vortices for the disk models considered here.",
        "keywords": [
          "astro-ph.EP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15978v1",
        "authors": [
          "M. Lehmann",
          "M. K. Lin"
        ],
        "arxiv_categories": [
          "astro-ph.EP"
        ],
        "steeps_mapping": "E_Environmental"
      },
      "entities": [
        "Convective Overstability",
        "Low Mass Planets Rapid",
        "Disk Interactions",
        "Framework",
        "Fusion",
        "Wind",
        "COS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:47:52.457023"
    },
    {
      "id": "arxiv-2602.15976v1",
      "title": "Early Results from the Coma Legacy IFU Survey (CLIFS): Ram Pressure Induced Shocks and Ionization in Jellyfish Tails",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15976v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Jellyfish galaxies, which exhibit tails of gas opposite to their direction of motion, are a galaxy population showcasing the most extreme effects of ram pressure stripping (RPS). We present the emission line properties of a preliminary sample of five jellyfish galaxies in the Coma cluster, observed with the WEAVE Large-IFU as part of the Coma Legacy IFU Survey (CLIFS). When complete, CLIFS will form a sample of 29 jellyfish galaxies in Coma, selected based on the presence of one-sided tails in the radio continuum, enabling a comprehensive picture of the effects of ram pressure on galaxies in the Coma cluster. We extract emission line properties and confirm consistency between disk fluxes measured from WEAVE and MaNGA for galaxies with overlapping disk coverage between surveys. Comparing resolved radio and H$α$-based star formation rates, we find that, in contrast to the disk, the dominant source of tail emission is not star formation. We find evidence for diffuse ionized gas excited by RPS-driven shocks in the tails, as indicated by: (1) LINER-like tail emission with the [OI]/H$α$ BPT diagnostic; (2) enhanced [OII]/H$α$ ratios in the tails relative to the disks; and (3) similarly elevated emission line velocities and velocity dispersions in the tails with respect to the disks. These results demonstrate that ram-pressure-driven shocks dominate the ionized emission in jellyfish galaxy tails.",
        "keywords": [
          "astro-ph.GA"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15976v1",
        "authors": [
          "Lauren M. Foster",
          "Ian D. Roberts",
          "Laura C. Parker",
          "Timothy A. Davis",
          "Alessandro Ignesti"
        ],
        "arxiv_categories": [
          "astro-ph.GA"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Ram Pressure Induced Shocks",
        "Jellyfish Tails Jellyfish",
        "Early Results",
        "Coma Legacy",
        "WEAVE",
        "LINER",
        "CLIFS",
        "RPS",
        "Act",
        "OII",
        "BPT",
        "IFU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.457514"
    },
    {
      "id": "arxiv-2602.15974v1",
      "title": "Stellar microlensing as a probe of Primordial Black Holes: status and prospects",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15974v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Stellar microlensing is a powerful tool for probing dark matter in the form of planetary and stellar mass compact objects (COs), in particular primordial black holes (PBHs). Under standard assumptions, current observations exclude COs in the mass range $10^{-11} \\lesssim M/M_{\\odot} \\lesssim 10^{4}$ making up all of the dark matter. We provide an overview, aimed at theorists working on PBHs, of the history, theory, observational status, and future prospects of the field.",
        "keywords": [
          "astro-ph.GA",
          "astro-ph.CO"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15974v1",
        "authors": [
          "Anne M. Green"
        ],
        "arxiv_categories": [
          "astro-ph.GA",
          "astro-ph.CO"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Primordial Black Holes",
        "Standard",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:52.457607"
    },
    {
      "id": "arxiv-2602.16701v1",
      "title": "Understanding the kinetics of static recrystallization in Mg-Zn-Ca alloys using an integrated PRISMS simulation framework",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16701v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recrystallization is a phenomenon in which a plastically deformed polycrystalline microstructure with a high dislocation density transforms into another that has low dislocation density. This evolution is driven by the stored energy in dislocations, rather than grain growth driven by grain boundary energy alone. One difficulty in quantitative modeling of recrystallization is the uncertainty in material parameters, which can be addressed by integration of experimental data into simulations. In this work, we compare simulated static recrystallization dynamics of a Mg-3Zn-0.1Ca wt.% alloy to experiments involving thermomechanical processing followed by measurements of the recrystallization fraction over time. The simulations are performed by combining PRISMS software for crystal plasticity and phase-field models (PRISMS-Plasticity and PRISMS-PF, respectively) in an integrated computational materials engineering framework. At 20% strain and annealing at 350 °C, the model accurately describes recrystallization dynamics up to a mobility-dependent time scale factor. While the average grain boundary mobility and the fraction of plastic work converted into stored energy are not precisely known, by fitting simulations to experimental data, we show that the average grain boundary mobility can be determined if the fraction of plastic work converted to stored energy is known, or vice versa. For low annealing temperatures, we observe a discrepancy between the model and experiments in the late stages of recrystallization, where a slowdown in recrystallization kinetics occurs in the experiments. We discuss possible sources of this slowdown and propose additional physical mechanisms that need to be accounted for in the model to improve its predictions.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16701v1",
        "authors": [
          "David Montiel",
          "Philip Staublin",
          "Supriyo Chakraborty",
          "Tracy Berman",
          "Chaitali Patil"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "PRISMS",
        "EPA",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.623222"
    },
    {
      "id": "arxiv-2602.16677v1",
      "title": "$p$-wave magnet driven field-free Josephson diode effect",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16677v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Recently, the superconducting diode effect (SDE), characterized by unequal critical currents in opposite directions, has been observed experimentally and predicted theoretically in models of bulk superconductors and Josephson junctions (JJs). In this work, we construct a Josephson junction using a recently discovered unconventional coplanar magnet, the $p$-wave magnet (PM), with proximity-induced superconductivity, and demonstrate the emergence of a Josephson diode effect (JDE). The barrier region is formed by another unconventional collinear magnet, namely an altermagnet (AM). We illustrate that apart from time-reversal and inversion symmetries, the mirror operation $M_{yz}$ emerges as the key symmetry constraint. Also, unlike earlier models that realize the JDE using unconventional magnets, this setup does not require Rashba spin-orbit coupling (SOC) or different superconductors across the junction. Moreover, we demonstrate that the realization of the JDE in this framework requires only minimal conditions while maintaining high performance. The effect remains robust across a broad parameter regime, and thus making the system particularly promising for applications in quantum circuits and computing technologies.",
        "keywords": [
          "cond-mat.supr-con",
          "cond-mat.mes-hall",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16677v1",
        "authors": [
          "Lovy Sharma",
          "Bimal Ghimire",
          "Manisha Thakurathi"
        ],
        "arxiv_categories": [
          "cond-mat.supr-con",
          "cond-mat.mes-hall",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "SOC",
        "Act",
        "SDE",
        "MIT",
        "JDE",
        "DOE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.623547"
    },
    {
      "id": "arxiv-2602.16670v1",
      "title": "Exceptional horns in $n$-root graphene and Lieb photonic ring lattices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16670v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a systematic construction of non-Hermitian tight-binding lattices whose Bloch spectra are $n$th roots of those of Hermitian parent two-dimensional (2D) lattices, namely graphene and the Lieb lattice. The $n$-roots of these models are constructed from connecting loop modules of unidirectional couplings whose geometrical arrangements match that of the corresponding parent system. Their energy spectrum is shown to consist of $n$ rotated and equivalent branches in the complex energy plane, each matching the real spectrum of the parent model when raised to the $n$th power, together with extra zero-energy flat bands (FBs) accounted for by the generalized index theorem. We show how the low-energy Dirac cones of the parent models translate, for an appropriate choice of phase configuration for the couplings of the $n$-root lattices, as what we call an \"exceptional horn\" appearing at each branch, with the central Dirac point (DP) converted into zero-energy exceptional points (EPs) of order $n$ or higher at high-symmetry momenta. These exceptional horns reflect the behavior of low-lying excitations that scale with momentum as $E\\sim\\vert \\mathbf{q}\\vert^{\\frac{1}{n}}$, with $n\\geq 3$, as opposed to the linear massless modes that characterize a Dirac cone. Moreover, we derive analytic expressions for the associated Landau levels (LLs), whose energies scale with magnetic flux as $E\\simφ^{\\frac{1}{2n}}$. For the case of the $n$-root Lieb lattice, the zeroth LL is shown to be exceptional. These results are analytically derived for both $n$-root models and numerically demonstrated for certain values of $n$. Finally, we propose a realistic photonic implementation based on coupled ring resonators with a split configuration of optical gain and loss.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.other"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16670v1",
        "authors": [
          "A. M. Marques",
          "D. Viedma",
          "V. Ahufinger",
          "R. G. Dias"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.other"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.624421"
    },
    {
      "id": "arxiv-2602.16661v1",
      "title": "A Tale of Two Plateaus: Competing Orders in Spin-1 and Spin-$\\tfrac{3}{2}$ Pyrochlore Magnets",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16661v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We use large-scale density-matrix renormalization group simulations with bond dimensions up to $20\\ 000$ to determine the magnetization curves of spin-1 and spin-$\\tfrac{3}{2}$ pyrochlore Heisenberg antiferromagnets. Both models exhibit a robust half-magnetization plateau, and we find that the same 16-site state (quadrupled unit cell) is selected in both cases on the largest 64-site cubic cluster we consider for the plateau state. This contrasts sharply with the effective quantum dimer model prediction which favors the ``R'' state, and demonstrates the breakdown of the perturbative mechanism at the Heisenberg point. These results provide a nonperturbative characterization of field-induced phases in pyrochlore magnets and predictive guidance for spin-1 and spin-$\\tfrac{3}{2}$ materials.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16661v1",
        "authors": [
          "Imre Hagymási"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Pyrochlore Magnets We",
        "Competing Orders",
        "Two Plateaus",
        "Spin-1",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.624678"
    },
    {
      "id": "arxiv-2602.16658v1",
      "title": "Exponential concentration of fluctuations in mean-field boson dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16658v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the mean-field dynamics of a system of $N$ interacting bosons starting from an initially condensated state. For a broad class of mean-field Hamiltonians, including models with arbitrary bounded interactions and models with unbounded interaction potentials, we prove that the probability of having $n$ particles outside the condensate decays exponentially in $n$ for any finite evolution time. Our results strengthen previously known bounds that provide only polynomial control on the probability of having $n$ excitations.",
        "keywords": [
          "math-ph",
          "cond-mat.stat-mech",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16658v1",
        "authors": [
          "Matias Gabriel Ginzburg",
          "Simone Rademacher",
          "Giacomo De Palma"
        ],
        "arxiv_categories": [
          "math-ph",
          "cond-mat.stat-mech",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.624826"
    },
    {
      "id": "arxiv-2602.16649v1",
      "title": "Design Principles for Fluid Molecular Ferroelectrics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16649v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Fluid molecular ferroelectrics are a new class of organic materials where ferroelectricity is found in conjunction with 3D fluidity whilst still retaining spontaneous polarization values comparable to their traditional solid state counterparts. One of the major challenges for soft condensed matter physics is predicting whether a fluid molecular material will form ferroelectric phase with nematic or smectic order. Through the synthesis of forty five systematically varied molecules, and by analogy to solid molecular ferroelectrics, is it shown that subtle hydrogen fluorine substitution allows for tuneable syn-parallel pairing motifs resulting in either specific pairings leading too geometrically constrained lamellar order or diversified pairings stabilising nematic ordering. Large-scale, fully atomistic molecular dynamics simulations reveal that smectic ferroelectricity emerges from discrete lateral pairing modes, whereas nematic phases arise from a multiplicity of equivalent polar configurations. Together, these findings establish experimentally validated design principles for fluid molecular ferroelectrics and provide a predictive framework for engineering functional polar fluids.",
        "keywords": [
          "cond-mat.soft",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16649v1",
        "authors": [
          "Calum J Gibb",
          "Jordan Hobbs",
          "William C Ogle",
          "Richard J Mandle"
        ],
        "arxiv_categories": [
          "cond-mat.soft",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fluid Molecular Ferroelectrics Fluid",
        "Design Principles",
        "Framework",
        "Hydrogen",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.625088"
    },
    {
      "id": "arxiv-2602.16648v1",
      "title": "Current Induced Switching of Superconducting Order and Enhancement of Superconducting Diode Efficiency",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16648v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We propose that the superconducting diode (SD) efficiency can be significantly enhanced near the transition between two superconducting states by choosing parameters where, before the system goes normal with increasing supercurrent, it switches into a different superconducting order for one direction of the current but not for the other. This mechanism for producing high SD efficiency relies on the expectation that the critical current depends sensitively on the superconducting order. We demonstrate this explicitly by performing detailed calculations for a bilayer superconductor with an in-plane magnetic field, which admits the standard Bardeen-Cooper-Schrieffer (BCS) and the orbital Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) orders as a function of the strength of the magnetic field. We predict a sharp peak in the SD efficiency in the FFLO state close to the transition, which arises from a complex interplay between the two superconducting orders. An implication of our study is that the measurement of the SD efficiency can provide fundamental insight into the nature of the BCS-FFLO transition both as a function of the magnetic field and the supercurrent.",
        "keywords": [
          "cond-mat.supr-con"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16648v1",
        "authors": [
          "Uddalok Nag",
          "Jonathan Schirmer",
          "Chao-Xing Liu",
          "J. K. Jain"
        ],
        "arxiv_categories": [
          "cond-mat.supr-con"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superconducting Diode Efficiency We",
        "Current Induced Switching",
        "Superconducting Order",
        "Standard",
        "FFLO",
        "MIT",
        "BCS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.625362"
    },
    {
      "id": "arxiv-2602.16647v1",
      "title": "Growth and crystallographic structure of TiTe$_2$ on Au(111): From sub-monolayer structures to single- and multi-layer films",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16647v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We investigated the initial growth of TiTe$_2$ on Au(111) from sub-monolayer to multi-layer coverage by scanning tunneling microscopy (STM), low-energy electron diffraction intensity analysis (LEED-IV), and density functional theory (DFT). In the submonolayer regime we find a stable and well-ordered $(5\\times\\sqrt{3})_{\\mathrm{rect}}$ superstructure consisting of separated TiTe$_2$ molecules, whereby the Ti atoms substitute Au atoms of the first substrate layer as proven by LEED-IV. By adding further Ti and Te in a 1:2 ratio and proper annealing dealloying sets in and a homogeneous 1T-TiTe$_2$ monolayer film on an unreconstructed substrate is formed. The resulting moiré structure is close to a $(4 \\times 4)$ superstructure w.r.t. Au(111) and has a slightly expanded in-plane lattice parameter compared to the 1T-TiTe$_2$ bulk value. With further stoichiometric deposition, thicker 1T-TiTe$_2$ films grow. Surprisingly, a five layer thick film exhibits an even larger lattice-parameter (1.5 % larger than the bulk value). All LEED-IV analyses are based on best-fit R-factors of $R \\le 0.13$.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16647v1",
        "authors": [
          "Andreas Raabgrund",
          "Tilman Kißlinger",
          "Alexander Wegerich",
          "Lutz Hammer",
          "M. Alexander Schneider"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "LEED",
        "EPA",
        "STM",
        "DFT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.625871"
    },
    {
      "id": "arxiv-2602.16636v1",
      "title": "Universal Framework for Decomposing Ionic Transport into Interpretable Mechanisms",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16636v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Understanding mechanisms of ion transport in bulk materials is central to designing next-generation ion conductors for energy storage devices, yet studies employing all-atom molecular dynamics (MD) have largely been limited to reporting overall transport coefficients without a quantitative, spatiotemporally resolved breakdown of \\emph{how} charge is carried. We present a computational framework that analyzes MD trajectories to quantitatively interpret macroscopic transport by decomposing it into additive contributions from physically motivated events. They are defined either through heuristically identified microscopic transitions, capturing events such as single-ion hops, multi-ion hops, and vehicular motion, or through transitions between chemically interpretable coordination macrostates. The construction guarantees that attributed contributions sum exactly to the Onsager transport coefficients estimated via the Green-Kubo/Einstein formalism, while scanning the sampling window exposes characteristic temporal scales at which distinct transport mechanisms emerge and dominate. Applied across three prototypical electrolytes-inorganic crystals, liquids, and polymers-the framework quantitatively resolves long-standing debates (e.g., the role of concerted motion and exchange), identifies dominant mechanisms and rate-limiting steps, quantifies their frequencies and effectiveness, and extracts activation energies for distinct transport modes, thereby distilling design rules for fast conduction. This general and reproducible analysis tool turns MD trajectories into quantitative mechanism maps, enabling the ion-conductor community to adjudicate mechanistic hypotheses and accelerate discovery.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16636v1",
        "authors": [
          "KyuJung Jun",
          "Pablo A. Leon",
          "Jurğis Ruža",
          "Juno Nam",
          "Rafael Gómez-Bombarelli"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interpretable Mechanisms Understanding",
        "Decomposing Ionic Transport",
        "Universal Framework",
        "Framework",
        "Wind",
        "NIST",
        "IoT",
        "Act",
        "MIT",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.626278"
    },
    {
      "id": "arxiv-2602.16628v1",
      "title": "Stoichiometry Dependent Properties of Cerium Hydride: An Active Learning Developed Interatomic Potential Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16628v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Cerium hydride has a variety of interesting properties, including a known lattice contraction and densification with increasing hydrogen content. However, precise stoichiometric control is not experimentally straightforward and {\\it ab initio} approaches are not computationally feasible for many properties such as melting and low temperature diffusion. Therefore, we develop a machine-learned interatomic potential for cerium hydride that is valid for H to Ce ratios from 2.0 to 3.0. A query-by-committee active learning approach is used to develop the training set. Leveraging classical molecular dynamics simulations, we assess a range of properties and provide fundamental mechanisms for the trends with stoichiometry. A majority of the properties follow the trend of lattice contraction, being governed by the stronger lattice binding induced by adding octahedral atoms.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16628v1",
        "authors": [
          "Brenden W. Hamilton",
          "Travis E. Jones",
          "Timothy C. Germann",
          "Benjamin T. Nebgen"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stoichiometry Dependent Properties",
        "Interatomic Potential Study Cerium",
        "An Active Learning Developed",
        "Cerium Hydride",
        "Hydrogen",
        "Fusion",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.626555"
    },
    {
      "id": "arxiv-2602.16622v1",
      "title": "Phase-Field Models for Particle-Stabilised Emulsions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16622v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Particle-stabilised emulsions are a cornerstone of soft matter science due to their broad application and fundamental relevance. Computer simulations provide key insights into the formation and behaviour of these emulsions, yet current methods are limited by the spatiotemporal scales accessible for study. The principal issue is that particles are resolved individually. In this work, an alternative strategy is introduced based on phase-field theory, for which we establish the framework. By evolving continuous fields, large-scale dynamics can be simulated in a computationally efficient manner. Our approach is then applied to model the complex formation of a bicontinuous interfacially jammed emulsion gel (bijel) via solvent-transfer induced phase separation (STrIPS). By resolving the coupled dynamics of liquid phase separation and nanoparticle adsorption, the model allows for the characterisation of the influence of nanoparticles on the morphology. Higher concentrations of nanoparticles are found to reduce the average domain size of STrIPS bijels, in line with previous experimental evidence. The presented phase-field model thus represents a promising approach for the morphological investigation of complex particle-stabilised emulsions.",
        "keywords": [
          "cond-mat.soft"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16622v1",
        "authors": [
          "Elisabeth C. Eij",
          "Joost de Graaf",
          "Martin F. Haase",
          "Jesse M. Steenhoff"
        ],
        "arxiv_categories": [
          "cond-mat.soft"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stabilised Emulsions Particle",
        "Field Models",
        "Framework",
        "EPA",
        "IoT",
        "NSF",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.626822"
    },
    {
      "id": "arxiv-2602.16618v1",
      "title": "Addressing Ill-conditioning in Density Functional Theory for Reliable Machine Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16618v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In principle, machine learning (ML) can be used to obtain any electronic property of a many-body system from its electron density within density functional theory. However, some physical quantities are highly sensitive to small variations in the density. This 'ill-conditioning' limits the accuracy with which these quantities can be learned as density functionals from a fixed amount of data. We identify sources of ill-conditioning present in density functionals that belong to two ubiquitous classes: 1) Physical quantities that are globally gauge-dependent, meaning they change value if a constant shift is applied to the external potential -- for example, the total energy; 2) Functionals of the N-electron density that have an implicit dependence on the (N+1)-electron density, such as the fundamental gap. We demonstrate that widely used ML models exhibit orders-of-magnitude greater error when applied to these ill-conditioned density functionals compared to other functionals that fall into neither class, even when the global gauge is fixed to prevent constant shifts. Owing to an absence of ill-conditioning in potential functionals, we find that providing the external potential as input to the ML model leads to significantly improved predictions of quantities in these two classes.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16618v1",
        "authors": [
          "L. Arnstein",
          "J. Wetherell",
          "R. Lawrence",
          "P. J. Hasnip",
          "M. J. P. Hodgson"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Reliable Machine Learning In",
        "Machine Learning",
        "Addressing Ill",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.627110"
    },
    {
      "id": "arxiv-2602.16597v1",
      "title": "Entanglement negativity in decohered topological states",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16597v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We investigate universal entanglement signatures of mixed-state phases obtained by decohering pure-state topological order (TO), focusing on topological corrections to logarithmic entanglement negativity and mutual information: topological entanglement negativity (TEN) and topological mutual information (TMI). For Abelian TOs under decoherence, we develop a replica field-theory framework based on a doubled-state construction that relates TEN and TMI to the quantum dimensions of domain-wall defects between decoherence-induced topological boundary conditions, yielding general expressions in the strong-decoherence regime. We further compute TEN and TMI exactly for decohered $G$-graded string-net states, including cases with non-Abelian anyons. We interpret the results within the strong one-form-symmetry framework for mixed-state TOs: TMI probes the total quantum dimension of the emergent premodular anyon theory, whereas TEN detects only its modular part.",
        "keywords": [
          "cond-mat.str-el",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16597v1",
        "authors": [
          "Kang-Le Cai",
          "Meng Cheng"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "For Abelian",
        "Framework",
        "TEN",
        "TMI",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.627329"
    },
    {
      "id": "arxiv-2602.16557v1",
      "title": "Anisotropic magnetism at the surface of a non-magnetic bulk insulator",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16557v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The potential for topological Kondo insulating behavior in d-electron systems has attracted interest in studying the surface states of the correlated insulators FeSb2 and FeSi. While detailed studies and theoretical description of a spin-orbit coupled ferromagnetic surface state have been applied to FeSi, the magnetic properties of the surface states of FeSb2 have not been addressed. Here, we report on the surface magnetic properties of FeSb2, utilizing the surface area dependence of magnetic susceptibility to separate the surface Curie-Weiss temperature dependence from the bulk spin-gap susceptibility. We use these results to further extract the surface magnetic anisotropy of a thin, rough-surfaced single-crystal FeSb2 to compare with the observed magnetotransport anisotropy, and find good agreement between the anisotropy in the surface magnetization and surface magnetotransport. We conclude with evidence of an anomalous Hall contribution to the low-temperature surface transport.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16557v1",
        "authors": [
          "Jarryd A. Horn",
          "Keenan E. Avers",
          "Nicholas Crombie",
          "Shanta R. Saha",
          "Johnpierre Paglione"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Agreement",
        "EPA",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.627559"
    },
    {
      "id": "arxiv-2602.16552v1",
      "title": "The rise and fall of an oxide: insights into the phase diagram of bismuth oxide on Au(111)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16552v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Bismuth oxide (Bi$_2$O$_3$) is a polymorphic material of considerable technological interest, with applications spanning from heterogeneous catalysis to next-generation nanoelectronics. Despite its relevance, systematic investigations of Bi$_2$O$_3$ thin films remain scarce. Here, we report a comprehensive, multi-technique study of bismuth oxide grown on Au(111). By combining synchrotron-based x-ray photoelectron spectroscopy and diffraction with low-energy electron diffraction and scanning tunneling microscopy, we elucidate the structural evolution of the surface during controlled oxidation and subsequent annealing. We find that Bi deposition induces well-defined surface reconstructions, whereas oxidation triggers the formation of a complex sequence of Bi$_2$O$_3$ domains. High-resolution spectroscopic and diffraction data enable us to propose a structural model consistent with the $(201)$ surface of $β$-Bi$_2$O$_3$. In addition, work function measurements reveal substantial electronic modifications at the interface. These results provide benchmark structural and electronic insights into the Bi oxide/Au(111) system and establish a framework for integrating Bi$_2$O$_3$ in devices in combination to two-dimensional semiconductors exploiting its low contact resistance.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16552v1",
        "authors": [
          "Alberto Turoldo",
          "Marco Bianchi",
          "Alessandro Baraldi",
          "Silvano Lizzit"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.628213"
    },
    {
      "id": "arxiv-2602.16533v1",
      "title": "Exciton-Selective Phonon Coupling in a Lead Halide Perovskite",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16533v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Exciton-phonon interactions govern the optical response of semiconductors, yet disentangling multiple coupling channels in lead halide perovskites remains challenging. We investigate CsPbBr3 microcrystals using photoluminescence, Raman and reflectance spectroscopy at low temperature, revealing the simultaneous presence of high-energy and Rashba excitons, each accompanied by distinct phonon replica series. High-energy exciton replicas are uniquely spaced by approximately 9 meV, whereas Rashba exciton replicas exhibit a characteristic approximately 6 meV spacing, indicating the specificity of the exciton-phonon coupling. Unsupervised machine learning applied to a large low-temperature photoluminescence dataset reveals these replica features are prevalent. With increasing temperature, replica features broaden and merge, evolving into a dominant longitudinal optical phonon coupling regime at room temperature. This work establishes direct spectroscopic evidence for concurrent, exciton-specific phonon coupling within a single material, offering new pathways to engineer light-matter interactions for optoelectronic and phonon-photon-based quantum device applications.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16533v1",
        "authors": [
          "Pradeepa H. L.",
          "Sagnik Chatterjee",
          "Sayantan Patra",
          "Swapneswar Bisoi",
          "Saqlain Mushtaq"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lead Halide Perovskite Exciton",
        "Selective Phonon Coupling",
        "Machine Learning",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.628512"
    },
    {
      "id": "arxiv-2602.16501v1",
      "title": "Quantum-classical correspondence for spins at finite temperatures with application to Monte Carlo simulations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16501v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider quantum-to-classical mapping for an arbitrary system of interacting spins at finite temperatures. We prove that, in the large-$S$ limit, the asymptotic form of the partition function coincides with that of a classical model for spins of length $S_C=\\sqrt{S(S+1)}$. Quantum corrections to the leading term form a series in powers of $1/[S(S+1)]$. This representation provides a rigorous basis for classical modeling of realistic magnetic Hamiltonians. As an application, the classical Monte Carlo simulations are performed to compute transition temperatures for several topical materials with known interaction parameters, including MnF$_2$, MnTe, Rb$_2$MnF$_4$, MnPSe$_3$, FePS$_3$, FePSe$_3$, CoPS$_3$, CrSBr, and CrI$_3$. The resulting transition temperatures show good agreement with experimental data.",
        "keywords": [
          "cond-mat.stat-mech",
          "cond-mat.mtrl-sci",
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16501v1",
        "authors": [
          "A. El Mendili",
          "M. E. Zhitomirsky"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "cond-mat.mtrl-sci",
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "Agreement",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.628775"
    },
    {
      "id": "arxiv-2602.16487v1",
      "title": "Emergent Topological Complexity in the Barabasi-Albert Model with Higher-Order Interactions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16487v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We examine the homological structure of the Barabasi-Albert model, focusing on the time evolution of $Δ$-dimensional simplices and topological holes as functions of time $t$ and the attachment parameter $m$ (the number of edges added by each incoming node). Numerical simulations reveal a non-trivial topological transition (TT) in the $(Δ, m)$ plane, marking a change from a topologically trivial regime to non-trivial topology. This transition signals the emergence of topological complexity in the model, where higher-order structures develop self-similarly across scales. Beyond this transition, the network exhibits self-similar topological growth, evidenced by a power-law decay in the increments of $Δ$-simplices with $m$-dependent exponents. An analogous transition occurs in the Betti numbers, which display self-similar behavior near the TT and an arctangent dependence farther from it. Based on simulation data, we propose explicit scaling relations describing the behavior of both $Δ$-simplices and Betti numbers near the TT. Overall, the analysis reveals a rich, gapful topological transition structure, where topological quantities exhibit discrete jumps at the transition point.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16487v1",
        "authors": [
          "Vadood Adami",
          "Hosein Masoomy",
          "Mirko Luković",
          "Morteza Nattagh Najafi"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Emergent Topological Complexity",
        "Order Interactions We",
        "Albert Model",
        "BERT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.629346"
    },
    {
      "id": "arxiv-2602.16474v1",
      "title": "When Is Structural Lubricity Load Independent? The Role of Contact Geometry and Elastic Compliance",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16474v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Using molecular dynamics simulations of an incommensurate Au(111)/graphite interface, we investigate the conditions under which structural lubricity produces load-independent friction. We show that strict load independence occurs only in laterally infinite, area-filling contacts, where dissipation is governed by phonon-mediated viscous coupling and the shear stress scales linearly with sliding velocity. Finite contacts with explicit boundary terminations exhibit substantially higher friction yet remain load independent up to a critical load. Load dependence arises only when elastic out-of-plane deformation near the contact line exceeds a critical amplitude, activating additional dissipation channels. These results demonstrate that contact geometry and local elastic compliance, rather than normal load itself, determine the onset and breakdown of load-independent structural lubricity.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16474v1",
        "authors": [
          "Hongyu Gao"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "When Is Structural Lubricity",
        "Elastic Compliance Using",
        "Load Independent",
        "Contact Geometry",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.629540"
    },
    {
      "id": "arxiv-2602.16471v1",
      "title": "Monte Carlo study of the classical antiferromagnetic $J_1$-$J_2$-$J_3$ Heisenberg model on a simple cubic lattice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16471v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "An extensive Monte Carlo study of the classical Heisenberg model on a simple cubic lattice with antiferromagnetic exchange interactions $J_n$ between the first, second, and third neighbors is performed in a broad region of $J_2 / J_1$, $J_3 / J_1$ ratios, and temperature. The character of the phase transitions is analyzed via the Binder cumulant method. The Neel temperature $T_{\\mathrm{N}}$ and the frustration parameter (the ratio $f= |θ|/T_{\\mathrm{N}}$, $θ$ being the Curie-Weiss temperature) are calculated. A comparison with the Tyablikov approximation is carried out. The strength of the frustration effects is explored. Possible applications to antiferromagnetic perovskites, such as CaMnO$_3$ and HgMnO$_3$, are discussed.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16471v1",
        "authors": [
          "A. N. Ignatenko",
          "S. V. Streltsov",
          "V. Yu. Irkhin"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Monte Carlo",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.629925"
    },
    {
      "id": "arxiv-2602.16451v1",
      "title": "Confinement Epitaxy of Large-Area Two-Dimensional Sn at the Graphene/SiC Interface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16451v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Confinement epitaxy beneath graphene stabilizes exotic material phases by restricting vertical growth and altering lateral diffusion, conditions unattainable on bare substrates. However, achieving long-range interfacial order while maintaining high-quality graphene remains a significant challenge. Here, we demonstrate the synthesis of large-area quasi-free-standing monolayer graphene (QFMLG) via the intercalation of a two-dimensional (2D) Sn. While the triangular Sn(1x1) interface exhibits a robust metallic band structure, the decoupled QFMLG maintains charge neutrality, confirmed by photoemission spectroscopy. Using high-resolution Raman spectroscopy and microscopy, we distinguish between direct intercalation and diffusion-driven expansion, identifying the latter as the critical pathway to superior QFMLG crystalline quality. Temperature-dependent analysis reveals dynamical structural coupling between the decoupled QFMLG and the Sn interface, providing a novel degree of freedom for strain engineering. Beyond uncovering the diffusion-driven mechanism, this work establishes metal intercalation as an effective strategy for tailoring durable graphene-metal heterostructures with tunable properties for next-generation quantum materials platforms.",
        "keywords": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16451v1",
        "authors": [
          "Zamin Mamiyev",
          "Niclas Tilgner",
          "Narmina O. Balayeva",
          "Dietrich R. T. Zahn",
          "Thomas Seyller"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Interface Confinement",
        "Confinement Epitaxy",
        "Dimensional Sn",
        "Area Two",
        "Fusion",
        "QFMLG",
        "Meta",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.630182"
    },
    {
      "id": "arxiv-2602.16447v1",
      "title": "Evolutionary Advantage of Diversity-Generating Retroelements in Switching Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16447v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Diversity-Generating Retroelements (DGRs) create rapid, targeted variation within specific genomic regions in phages and bacteria. They operate through stochastic retro-transcription of a template region (TR) into a variable region (VR), which typically encodes ligand-binding proteins. Despite their prevalence, the evolutionary conditions that maintain such hypermutating systems remain unclear. Here we introduce a two-timescale framework separating fast VR diversification from slow TR evolution, allowing the dynamics of DGR-controlled loci to be analytically understood from the TR design point of view. We quantity the fitness gain provided by the diversification mechanism of DGR in the presence of environmental switching with respect to standard mutagenesis. Our framework accounts for observed patterns of DGR activity in human-gut \\textit{Bacteroides} and clarifies when constitutive DGR activation is evolutionarily favored.",
        "keywords": [
          "q-bio.PE",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16447v1",
        "authors": [
          "Léo Régnier",
          "Paul Rochette",
          "Raphaël Laurenceau",
          "David Bikard",
          "Simona Cocco"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Switching Environments Diversity",
        "Generating Retroelements",
        "Evolutionary Advantage",
        "Framework",
        "Standard",
        "EPA",
        "Act",
        "DGR",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:47:57.630392"
    },
    {
      "id": "arxiv-2602.16411v1",
      "title": "Transition between one- and two-dimensional topology in a Chern insulator of finite width",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16411v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Topology in quantum systems is typically considered in infinite crystals in one, two, or higher integer dimensions. Here, we show that one can continuously transform a system between a topological phase associated with one dimension and a topological phase associated with two dimensions without closing the energy gap. In this process, the dimension of the system itself changes. Concretely, we investigate a modified version of the Qi-Wu-Zhang model and develop a procedure to smoothly shrink the width of the system in one direction. By tracking gaps which remain open throughout the modulation, we establish a smooth transition from a two-dimensional to a one-dimensional topological insulator. In between the system exhibits both one- and two-dimensional topology, and the way the system accomplishes the transition is by making the one-dimensional topology more robust as the width decreases, while the two-dimensional topology becomes less robust. Finally, we show how the gaps arise from hybridization of edge states due to the finite width.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16411v1",
        "authors": [
          "Frode Balling-Ansø",
          "Adipta Pal",
          "Ashley M. Cook",
          "Anne E. B. Nielsen"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSF",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.630616"
    },
    {
      "id": "arxiv-2602.16405v1",
      "title": "Computation of thermal conductivity based on Path Integral Monte Carlo methods",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16405v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The calculation of thermal conductivity in insulating solids at temperatures below the Debye temperature is problematic, due to the breakdown of classical and semi-classical approaches. In this work, we present a fully quantum methodology to compute thermal conductivity based on Path Integral Monte Carlo (PIMC) simulations combined with the Green-Kubo linear response theory. The method is applied to crystalline argon modeled by a Lennard-Jones potential, a paradigmatic system where quantum effects strongly affect both thermodynamic and transport properties. From PIMC simulations, we obtain the temperature-dependent phonon frequencies, lifetimes, and specific heat. From the imaginary time correlations of the energy current, we extract the thermal transport coefficients based on a physically motivated prior. We show that the experimentally observed increase of the thermal conductivity at low temperatures cannot be explained within a standard Peierls-Boltzmann framework or quasi-harmonic approximation using phonon lifetimes alone. Instead, a distinct transport lifetime emerges from the analysis of heat-current correlations. Our results demonstrate that quantum Monte Carlo methods provide a robust, non-perturbative framework to investigate heat transport in insulating solids, beyond the limits of classical molecular dynamics and quasi-harmonic approximations.",
        "keywords": [
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16405v1",
        "authors": [
          "Vladislav Efremkin",
          "Stefano Mossa",
          "Jean-Louis Barrat",
          "Markus Holzmann"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Path Integral Monte Carlo",
        "Monte Carlo",
        "Framework",
        "Standard",
        "PIMC",
        "Act",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.630921"
    },
    {
      "id": "arxiv-2602.16377v1",
      "title": "Photophysical properties of Eu3+ complexes approaching electronic contact to a metal surface",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16377v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The application of rare-earth complexes in electrically driven light sources poses a series of challenges that require specific optimization of the molecular photophysical properties. Here, we present a report on films of three different Eu3+ complexes characterized in terms of emission spectra and fluorescence decay. We compare molecular complexes in powder form and sublimed films, in films on glass and on a metal surface, and in films of thicknesses down to less than 3 nm (< 3 ML), approaching electrical coupling. Our photoluminescence experiments supported by scanning tunneling microscopy of sub-monolayers indicate that Eu3+(trensal) complexes are less affected by sublimation and more stable on the metal surface than typical beta diketonate complexes, making them promising candidates for electroluminescence devices.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16377v1",
        "authors": [
          "Adrian Ebert",
          "Simon Fromme",
          "Lisa Burgert",
          "Umar Rashid",
          "Lukas Gerhard"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.631156"
    },
    {
      "id": "arxiv-2602.16372v1",
      "title": "AI-Driven Structure Refinement of X-ray Diffraction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16372v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Artificial intelligence can rapidly propose candidate phases and structures from X-ray diffraction (XRD), but these hypotheses often fail in downstream refinement because peak intensities cannot be stably assigned under severe overlap and diffraction consistency is enforced only weakly. Here we introduce WPEM, a physics-constrained whole-pattern decomposition and refinement workflow that turns Bragg's law into an explicit constraint within a batch expectation--maximization framework. WPEM models the full profile as a probabilistic mixture density and iteratively infers component-resolved intensities while keeping peak centres Bragg-consistent, producing a continuous, physically admissible intensity representation that remains stable in heavily overlapped regions and in the presence of mixed radiation or multiple phases. We benchmark WPEM on standard reference patterns (\\ce{PbSO4} and \\ce{Tb2BaCoO5}), where it yields lower $R_{\\mathrm{p}}$/$R_{\\mathrm{wp}}$ than widely used packages (FullProf and TOPAS) under matched refinement conditions. We further demonstrate generality across realistic experimental scenarios, including phase-resolved decomposition of a multiphase Ti--15Nb thin film, quantitative recovery of \\ce{NaCl}--\\ce{Li2CO3} mixture compositions, separation of crystalline peaks from amorphous halos in semicrystalline polymers, high-throughput operando lattice tracking in layered cathodes, automated refinement of a compositionally disordered Ru--Mn oxide solid solution (CCDC 2530452), and quantitative phase-resolved deciphering of an ancient Egyptian make-up sample from synchrotron powder XRD. By providing Bragg-consistent, uncertainty-aware intensity partitioning as a refinement-ready interface, WPEM closes the gap between AI-generated hypotheses and diffraction-admissible structure refinement on challenging XRD data.",
        "keywords": [
          "cond-mat.mtrl-sci",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16372v1",
        "authors": [
          "Bin Cao",
          "Qian Zhang",
          "Zhenjie Feng",
          "Taolue Zhang",
          "Jiaqiang Huang"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Structure Refinement",
        "Artificial Intelligence",
        "Diffraction Artificial",
        "Framework",
        "Standard",
        "TOPAS",
        "Intel",
        "CCDC",
        "WPEM",
        "EPA",
        "XRD",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.631496"
    },
    {
      "id": "arxiv-2602.16370v1",
      "title": "Why the Casimir Force for Magnetic Metals Computed by the Lifshitz Theory Using the Drude Model Disagrees with the Measurement Data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16370v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the Casimir force in configurations with magnetic metal plates and analyze the reasons why the predictions of the Lifshitz theory using the dielectric permittivity of the Drude model are inconsistent with the measurement data. For this purpose, the contributions of the electromagnetic waves with the transverse magnetic and transverse electric polarizations to the Casimir force are computed using the Lifshitz theory expressed in terms of the pure imaginary Matsubara frequencies. Furthermore, the fractions of the evanescent and propagating waves in these contributions are found using an equivalent formulation of the Lifshitz theory along the real frequency axis. All computations are performed for Au-Ni and Ni-Ni plates using the Drude model and the experimentally consistent plasma model over the separation region from 0.5 to 6~mum, where the total force value is determined by conduction electrons. It is shown that the transverse magnetic contribution to the Casimir force does not depend on the used model of the dielectric permittivity, so that the total difference between the predictions of the Lifshitz theory using the Drude model and the measurement data is determined by the transverse electric contribution. In doing so, as opposed to the case of nonmagnetic metals, both fractions of the evanescent and propagating waves in this contribution depend on the model of the dielectric permittivity used in computations, whereas the magnetic properties of the plate metal influence the Casimir force solely through the fraction of propagating waves in the transverse electric contribution. The issue of a more adequate theoretical description of the electromagnetic response of magnetic metals is discussed.",
        "keywords": [
          "quant-ph",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16370v1",
        "authors": [
          "G. L. Klimchitskaya",
          "C. C. Korikov",
          "V. M. Mostepanenko"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Magnetic Metals Computed",
        "Drude Model Disagrees",
        "Measurement Data We",
        "Casimir Force",
        "Meta",
        "EPA",
        "Act",
        "MIT",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.631838"
    },
    {
      "id": "arxiv-2602.16351v1",
      "title": "Liouvillian interpolation of the self-energy of cluster dynamical mean-field theories",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16351v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Two widely-used non-local extensions of dynamical mean field theory (DMFT), cellular DMFT (CDMFT) and the dynamical cluster approximation (DCA), both yield self-energies marred by having some unphysical properties: CDMFT yields real-space self-energies that are not translationally invariant, and DCA yields momentum-space self-energies with discontinuities in their momentum dependence. It is often desirable to remove these flaws by post-processing cluster DMFT results, using strategies called periodization for CDMFT and interpolation for DCA -- for brevity, we refer to both cases as interpolation. However, traditional interpolation approaches struggle to capture intricate structures such as hole pockets in the hole-doped square-lattice Hubbard model, as highlighted in Phys. Rev. B 105, 35117 (2022). Further, these approaches interpolate frequency-dependent functions, which may lead to causality violations. Here, we propose Liouvillian interpolation, a novel, intuitive, and robust scheme for interpolating cluster DMFT results. Our key idea is to interpolate frequency-independent matrix elements of the single-particle irreducible part of the Liouvillian, obtained from a continued-fraction expansion of the cDMFT self-energy. We demonstrate that the ingredients of such an expansion possess a more local Fourier expansion than the functions involved in traditional interpolation schemes, and that Liouvillian interpolation inherently conserves causality. We illustrate our method for the one-dimensional Hubbard model using CDMFT, and for the two-dimensional Hubbard model using four-patch DCA. For the latter, we find that L-interpolation can (depending on doping) yield Fermi and Luttinger arcs which together form a closed surface.",
        "keywords": [
          "cond-mat.str-el"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16351v1",
        "authors": [
          "Mathias Pelz",
          "Jan von Delft",
          "Andreas Gleis"
        ],
        "arxiv_categories": [
          "cond-mat.str-el"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "CDMFT",
        "DMFT",
        "DCA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.632172"
    },
    {
      "id": "arxiv-2602.16331v1",
      "title": "Where Multipartite Entanglement Localizes: The Junction Law for Genuine Multi-Entropy",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16331v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We uncover a \"junction law\" for genuine multipartite entanglement, suggesting that in gapped local systems multipartite entanglement is controlled and effectively localized near junctions where subsystem boundaries meet. Using the Rényi-2 genuine multi-entropy $\\mathrm{GM}^{(\\mathtt{q})}_2$ as a diagnostic of genuine $\\mathtt{q}$-partite entanglement, we establish this behavior in $(2+1)$-dimensional gapped free-fermion lattices with correlation length $ξ$. For partitions with a single junction, $\\mathrm{GM}^{(\\mathtt{q})}_2$ exhibits a universal scaling crossover in $L/ξ$, growing for $L\\llξ$ and saturating to a $ξ$-dependent constant for $L\\ggξ$, up to $\\mathcal{O}(e^{-L/ξ})$ corrections. In sharp contrast, for partitions without a junction, $\\mathrm{GM}^{(\\mathtt{q})}_2$ is exponentially suppressed in $L/ξ$ and drops below numerical resolution once $L\\ggξ$. We observe the same pattern for $\\mathtt{q}=3$ (tripartite) and $\\mathtt{q}=4$ (quadripartite) cases, and further corroborate this localization by translating the junction at fixed system size. We also provide a geometric explanation of the junction law in holography. Altogether, these results show that in this gapped free-fermion setting genuine multipartite entanglement is localized within a correlation-length neighborhood of junctions.",
        "keywords": [
          "hep-th",
          "cond-mat.stat-mech",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16331v1",
        "authors": [
          "Norihiro Iizuka",
          "Akihiro Miyata"
        ],
        "arxiv_categories": [
          "hep-th",
          "cond-mat.stat-mech",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Where Multipartite Entanglement Localizes",
        "Genuine Multi",
        "Entropy We",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.632786"
    },
    {
      "id": "arxiv-2602.16261v1",
      "title": "Stripe antiferromagnetism in van der Waals metal HoTe3 decoupled from charge density wave order",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16261v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The $R\\mathrm{Te}_3$ ($R = \\text{rare earth}$) family of layered van der Waals (vdW) compounds hosts coexisting magnetic and charge density wave (CDW) orders, yet the interplay between these degrees of freedom remains little explored. Combining polarized and unpolarized neutron diffraction on single-crystal $\\mathrm{HoTe}_3$, we identify two distinct antiferromagnetic (AFM) phases, both exhibiting a collinear $\\uparrow\\uparrow\\downarrow\\downarrow$ motif within individual vdW layers. The two phases are distinguished by the vdW stacking of magnetic layers: ferromagnetic (FM) stacking in the higher-temperature AFM-II phase, here termed ``vertical-stripe'', and AFM stacking in the AFM-I ground state, here termed ``tilted-stripe''; the two phases have propagation vectors $\\boldsymbol{q}_{\\mathrm{m2}} = (0.48, 0, 0)$ and $\\boldsymbol{q}_{\\mathrm{m1}} = (0.5, 0.5, 0)$, respectively. In contrast to the CDW-driven exotic magnetism in $\\mathrm{DyTe}_3$, $\\mathrm{TbTe}_3$, and $\\mathrm{GdTe}_3$, we find no evidence for coupling between magnetism and CDW in $\\mathrm{HoTe}_3$. The relative alignment between AFM and CDW propagation vectors, as well as single-ion anisotropy, are likely essential for generating coupled spin/charge orders in layered vdW systems.",
        "keywords": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16261v1",
        "authors": [
          "Weiyi Yun",
          "Ryota Nakano",
          "Ryo Misawa",
          "Rinsuke Yamada",
          "Shun Akatsuka"
        ],
        "arxiv_categories": [
          "cond-mat.str-el",
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "CDW",
        "AFM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.633096"
    },
    {
      "id": "arxiv-2602.16250v1",
      "title": "Unveiling and quantifying the topology-dependent pre-melting of nanoparticles",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16250v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The melting of metallic nanoparticles is governed by surface pre-melting, a phenomenon traditionally modeled as the isotropic growth of a uniform liquid shell. Challenging this classical view, we report facet-dependent surface pre-melting in hexagonal close-packed Co nanoparticles, arising from the structural heterogeneity of the nanoparticle surface. Characterizing melting in molecular dynamics simulations (500 to 6000 atoms), we observe the onset of surface mobility, starting as low as $0.2\\times T_{M,\\infty}$ (the bulk melting point), driven by the early disordering of stepped $\\{01\\bar{1}1\\}$ facets. We found that these facets consistently melt at temperatures nearly 200 Kelvin lower than flat $\\{0001\\}$ facets, regardless of particle size, and relate facets melting temperatures to the nanoparticle size via a 2D extension of the Gibbs-Thomson relation. We determine a critical liquid layer thickness that triggers the melting of the entire nanoparticle, which is found to be size-dependent. Our results confirm the recent experimental observation of the surface pre-melting effect, and extend it to anisotropic particles with different facet orientations.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16250v1",
        "authors": [
          "Marthe Bideault",
          "Arnaud Allera",
          "Ryoji Asahi",
          "Jérôme Creuze",
          "Erich Wimmer"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Meta",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.633335"
    },
    {
      "id": "arxiv-2602.16242v1",
      "title": "Decoherence of Josephson coupling and thermal quenching of the Josephson diode effect in bilayer superconductors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16242v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Motivated by recent studies on superconducting (SC) diode nonreciprocity, we uncover an unexpected hierarchy of SC-phase decoherence in bilayer superconductors hosting both interlayer Josephson coupling and a Josephson diode effect. Contrary to the conventional single-energy-scale paradigm where Josephson coherence and diode nonreciprocity vanish simultaneously at the SC gap-closing temperature, we demonstrate, using a self-consistent microscopic theory incorporating phase fluctuations, that the system undergoes a sequence of distinct thermal crossovers upon heating: the diode effect disappears first at $T_η$, Josephson coherence is subsequently lost at $T_c$, and the SC gap collapses only at a higher temperature $T_s$. Rather than a direct SC-normal transition, the system thus evolves through successive nonreciprocal, reciprocal, and incoherent Josephson regimes before entering the normal state. Counterintuitively, the separation between these regimes is governed not only by interlayer coupling, but also sensitively by in-plane disorder and carrier density. These findings point to a generic hierarchy of SC decoherence in low-dimensional Josephson systems, and suggest broader relevance to layered superconductors, including cuprates and recently discovered nickelates, as well as to SC qubits.",
        "keywords": [
          "cond-mat.supr-con"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16242v1",
        "authors": [
          "F. Yang",
          "C. Y. Dong",
          "Joshua A. Robinson",
          "L. Q. Chen"
        ],
        "arxiv_categories": [
          "cond-mat.supr-con"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.633983"
    },
    {
      "id": "arxiv-2602.16228v1",
      "title": "Coexistence of Rashba and Ising Spin-Singlet Pairings in Two-Dimensional IrTe$_{2}$",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16228v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Symmetry offers a useful approach to unfold the intertwined degrees of freedom. Thus it paves the way to resolve coexisting quantum orders into distinct symmetry sectors. Motivated by the recent observation of superconductivity in nano-flaked IrTe$_2$, we investigate the superconductivity in strain-stabilized two-dimensional (2D) limit of IrTe$_2$ by combining density-functional theory with mean-field solution of spin-fluctuation mediated pairing interaction on a symmetry-constrained ${\\bf k}\\cdot{\\bf p}$ model. The spin-orbit coupled band structure shows $Γ$-centred Fermi sheets with coexistence of band-selective Rashba-like (in-plane) and Ising-like (out-of-plane) superconductivity. Remarkably, the superconducting gaps are odd in spin, orbital, and momentum channels despite the presence of global inversion symmetry. Fermi surface topologies and little-group symmetry enforce distinct irreducible representations to the Rashba and Ising channels, forbidding their mixing. Our findings open up a symmetry-based route to multichannel superconductivity in 2D transition-metal dichalcogenides with unique functionalities.",
        "keywords": [
          "cond-mat.supr-con"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16228v1",
        "authors": [
          "Kunal Dutta",
          "Rajesh O. Sharma",
          "Shreya Das",
          "Indra Dasgupta",
          "Tanmoy Das"
        ],
        "arxiv_categories": [
          "cond-mat.supr-con"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Singlet Pairings",
        "Ising Spin",
        "Meta",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.634516"
    },
    {
      "id": "arxiv-2602.16210v1",
      "title": "Stack of correlated insulating states in bilayer graphene kagome superlattice",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16210v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Graphene-based systems have emerged as a rich platform for exploring emergent quantum phenomena-including superconductivity, magnetism, and correlated insulating behavior-arising from flat electronic bands that enhance many-body interactions. Realizing such flat bands has thus far relied primarily on moiré graphene superlattices or rhombohedral stacking graphene systems, both of which face challenges in reproducibility and tunability. Here, we introduce an artificial Kagome superlattice in bilayer graphene, engineered via nanopatterning of the dielectric substrate to create a precisely defined and electrostatically tunable periodic potential. Magnetotransport measurements reveal the emergence of a stack of correlated insulating states at moderate superlattice potentials, characteristic of strong electron-electron interactions within Kagome-induced flat bands. As temperature increases, these correlated gaps collapse, signaling the thermal suppression of interaction-driven states. Continuum-model calculations confirm the formation of multiple flat minibands and reproduce the observed evolution of band reconstruction. Our results establish dielectric-patterned graphene superlattices as a robust and controllable architecture for realizing flat-band-induced correlated phenomena beyond moiré systems.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16210v1",
        "authors": [
          "Xinyu Cai",
          "Fengfan Ren",
          "Qiao Li",
          "Yanran Shi",
          "Yifan Wang"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.635048"
    },
    {
      "id": "arxiv-2602.16176v1",
      "title": "Reinforcement learning for path integrals in quantum statistical physics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16176v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Machine learning is rapidly finding its way into the field of computational quantum physics. One of the most popular and widely studied approaches in this direction is to use neural networks to model quantum states (NQS) in the Hamiltonian formulation of quantum mechanics. However, an alternative angle of attack to leverage machine learning in physics is through the path integral formulation, which has so far received far more limited attention. In this paper, we explore how reinforcement learning can be used to compute a class of Euclidean path integrals that yield the thermal density matrix of a quantum system, thereby enabling the computation of the free energy or other thermal expectation values. In particular, we propose a two-step approach with the unique feature that after a variational approximation for a quantity is obtained in a first step, it can then be used to efficiently compute the exact result in a second step. We benchmark this method on several simple systems and then apply it to the quantum rotor chain.",
        "keywords": [
          "quant-ph",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16176v1",
        "authors": [
          "Timour Ichmoukhamedov",
          "Dries Sels"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "Act",
        "MIT",
        "NQS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.635263"
    },
    {
      "id": "arxiv-2602.16175v1",
      "title": "Negative Strain-Rate Sensitivity in Metallic Glasses Driven by Rejuvenation-Relaxation Competition: Kinetic Monte Carlo Simulations and a Minimal Effective Model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16175v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "When strain-rate sensitivity (SRS) is negative in metallic glasses, the material becomes weaker as the deformation rate increases, leading to accelerated plastic deformation and, eventually, catastrophic fracture. In this study, we elucidate the mechanism underlying the negative SRS using micromechanics-based kinetic Monte Carlo simulations that couple heterogeneous randomized shear transformation zone (STZ) models for metallic glasses. The model accounted for both the thermomechanical structural rejuvenation and relaxation of the energy barrier for thermal activation of STZs, incorporating a Kohlrausch-Williams-Watts (KWW)-type relaxation function. The present simulations systematically reproduce the dependence of flow stresses on strain rate, temperature, and the form of the relaxation function. The SRS tends to decrease at high strain rates and low temperatures in the simulations, and negative SRS appears when a compressed-exponential relaxation function is employed. Shear localization also appears; however, the conditions under which the observed localization emerges do not fully coincide with those leading to the negative SRS, leaving the dominant factor unclear. To clarify the dominant factor, we introduce a simplified theoretical model that reproduces flow stresses consistent with the simulation results. An analytical expression derived from the theoretical model reveals that negative SRS originates primarily from the temporal evolution of the activation barrier. Specifically, negative SRS arises when the timescale of external loading exceeds that of STZ relaxation.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16175v1",
        "authors": [
          "Tomoaki Niiyama",
          "Akio Ishii",
          "Takahiro Hatano",
          "Tomotsugu Shimokawa",
          "Shigenobu Ogata"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Kinetic Monte Carlo Simulations",
        "Minimal Effective Model When",
        "Metallic Glasses Driven",
        "Relaxation Competition",
        "Rate Sensitivity",
        "Negative Strain",
        "Monte Carlo",
        "Meta",
        "SRS",
        "NSF",
        "Act",
        "STZ",
        "KWW",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.635588"
    },
    {
      "id": "arxiv-2602.16158v1",
      "title": "Dislocation-ledge coupling drives non-conservative migration of semicoherent precipitate interfaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16158v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Precipitate shape and size control the strength and stability of many structural alloys, yet the microscopic mechanism by which semicoherent precipitate interfaces migrate remains unclear. In particular, how dense interfacial dislocation networks move while accommodating transformation strain has resisted direct, time-resolved characterization. Here, we show that non-conservative motion of interfacial dislocations is intrinsically coupled to the nucleation and lateral propagation of nanoscale growth ledges, providing a defect-based kinetic description of lath growth. Phase-field-crystal simulations of a prototypical face-centered cubic/body-centered cubic (FCC/BCC) transformation resolve strongly anisotropic interface kinetics: the end face advances continuously along the lath long axis, whereas facets thicken by discrete ledge sweeps accompanied by mixed glide-climb reactions in a closed dislocation network. Crystallographic analyses predict the dislocation arrangements, rationalize the anisotropy via the geometry of misfit localization, and show how dislocation motion accommodates the transformation strain. In situ transmission electron microscopy of austenite precipitates in duplex stainless steel captures rapid ledge propagation on habit planes, consistent with the predicted migration mode. Our results bridge point-defect transport, dislocation reactions, and interface mobility, enabling quantitative, transferable predictions of precipitate morphology evolution.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16158v1",
        "authors": [
          "Jin-Yu Zhang",
          "Juan Du",
          "Lin Yang",
          "Frédéric Mompiou",
          "Shigenobu Ogata"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "FCC",
        "BCC",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.635876"
    },
    {
      "id": "arxiv-2602.16133v1",
      "title": "Generative Inverse Estimation of 3D Atomic Coordination from Near-Edge Spectra via Equivariant Diffusion Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16133v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Extracting 3D atomic coordinates from spectroscopic data is a longstanding inverse problem. We present an equivariant diffusion model that generates site-specific 3D structures directly from near-edge spectra (ELNES/XANES). Trained on Si-O crystals, the model achieves radial accuracy comparable to Extended X-ray Absorption Fine Structure (EXAFS) (RMSD ~0.06 Å) but with superior coordination number precision (errors < 4.3% vs. EXAFS ~20%). Crucially, it reconstructs full 3D geometries including bond angles, overcoming the limitations of 1D radial distribution analysis. The model demonstrates robust out-of-distribution generalization, accurately predicting local structures in amorphous systems despite being trained exclusively on crystalline lattices. Application to experimental O K-edge spectra from α-quartz validates practical applicability. This generative approach outperforms template matching and establishes automated, quantitative 3D structure determination from spectroscopic data.",
        "keywords": [
          "cond-mat.mtrl-sci"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16133v1",
        "authors": [
          "Ren Okubo",
          "Yu Fujikata",
          "Izumi Takahara",
          "Teruyasu Mizoguchi"
        ],
        "arxiv_categories": [
          "cond-mat.mtrl-sci"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Equivariant Diffusion Models Extracting",
        "Generative Inverse Estimation",
        "Absorption Fine Structure",
        "Atomic Coordination",
        "Edge Spectra",
        "Fusion",
        "ELNES",
        "XANES",
        "EXAFS",
        "RMSD",
        "Act",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.636369"
    },
    {
      "id": "arxiv-2602.16121v1",
      "title": "Enhanced Graphene-Water Thermal Transport via Edge Functionalization without Compromising In-Plane Thermal Conductivity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16121v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Interfacial thermal transport between graphene and water plays a critical role in a wide range of thermal and energy applications. Although chemical functionalization can significantly enhance graphene-water interfacial thermal conductance, it often degrades graphene's intrinsic in-plane phonon transport. In this work, we perform a systematic deep neural network molecular dynamics study comparing edge-functionalized graphene nanoribbons with surface-functionalized graphene in aqueous environments. We demonstrate that functionalizing only 10% of the ribbon edges with hydroxyl groups increases the graphene-water interfacial thermal conductance by more than eightfold, primarily due to strengthened interfacial interactions and improved wettability at the edges. In contrast to basal-plane oxidation, edge functionalization largely preserves in-plane thermal conductivity. Importantly, hydroxyl edge groups exert competing effects on phonon transport: they introduce additional boundary scattering that suppresses heat conduction, while simultaneously passivating dangling bonds at bare edges, thereby reducing phonon localization and edge-induced scattering. This competition leads to a non-monotonic dependence of in-plane thermal conductivity on edge functionalization ratio. These results establish edge functionalization as an effective strategy for enhancing graphene-water interfacial thermal transport without sacrificing intrinsic phonon transport properties.",
        "keywords": [
          "cond-mat.mes-hall"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16121v1",
        "authors": [
          "John Crosby",
          "Haoran Cui",
          "Mehrab Lotfpour",
          "Yan Wang",
          "Lei Cao"
        ],
        "arxiv_categories": [
          "cond-mat.mes-hall"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Edge Functionalization",
        "Enhanced Graphene",
        "Compromising In",
        "Neural Network",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:47:57.636660"
    },
    {
      "id": "arxiv-2602.16694v1",
      "title": "Yang-Mills Flux Tube in AdS II: Effective String Theory",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16694v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We continue the study of flux tubes in confining gauge theories placed in a rigid AdS background, focusing on the three-dimensional case. Our analysis is performed in the large-radius regime, where effective string theory provides a good approximation of the dynamics. Using a combination of techniques, primarily the analytic transcendentality ansatz bootstrap, we compute observables up to two-loop order in the expansion in powers of the string length over the AdS radius, which constitutes the main result of this work. Finally, we employ Padé resummations to explore the possible compatibility of our results with a smooth interpolation of observables between large-radius AdS and small-radius AdS, in which gauge theory is weakly coupled.",
        "keywords": [
          "hep-th",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16694v1",
        "authors": [
          "Barak Gabai",
          "Victor Gorbenko",
          "Bendeguz Offertaler"
        ],
        "arxiv_categories": [
          "hep-th",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mills Flux Tube",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.687338"
    },
    {
      "id": "arxiv-2602.16683v1",
      "title": "Scattering data and correlation function for the $K f_1(1285)$ interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16683v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the interaction of a kaon with the $f_1(1285)$ resonance, assuming that the $f_1(1285)$ is a molecular state generated by the $K \\bar K^*, \\bar K K^*$ interaction, evaluating the scattering amplitude, the scattering length and effective range of the $K f_1$ system. The scattering amplitude develops a resonant structure approximately $10$ MeV below the $K f_1$ threshold, with a width of around $15$ MeV. The corresponding correlation function has the distinctive shape of a system with a bound state close to threshold. We also show that the interaction of the $K f_1$ system is differs significantly from the one obtained assuming that the $f_1(1285)$ is an elementary particle. This provides motivation to continue the search for these observables, already initiated by the measurement of the $p f_1(1285)$ correlation function by the ALICE collaboration.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16683v1",
        "authors": [
          "Wen-Hao Jia",
          "Jing Song",
          "Wei-Hong Liang",
          "Eulogio Oset"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "ALICE",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.687930"
    },
    {
      "id": "arxiv-2602.16674v1",
      "title": "Comparison of Pauli projection and supersymetric transformation methods for three-body nuclear structure and reactions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16674v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Three-body Faddeev-type equations for bound, resonant, and scattering states in the systems of nuclear core and two nucleons are solved using the momentum-space framework. Two approaches for eliminating the Pauli-forbidden deeply-bound states are compared, projecting out those states by a nonlocal term in the potential, and by a supersymmetric transformation of the potential. While the former method is preferred by the experimental data for the deuteron-${}^4${He} scattering, the results for bound and resonant states do not indicate a clear superiority of a single method. Instead, systematic differences between them are found.",
        "keywords": [
          "nucl-th",
          "nucl-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16674v1",
        "authors": [
          "A. Deltuva"
        ],
        "arxiv_categories": [
          "nucl-th",
          "nucl-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Nuclear",
        "NSF",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.688218"
    },
    {
      "id": "arxiv-2602.16657v1",
      "title": "The spatial Wilson loops, string breaking, and AdS/QCD",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16657v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the phenomenon of string breaking in the context of the spatial Wilson loops using the gauge/string duality. In particular, we discuss the impact of light flavors on the pseudopotential. We also introduce the notion of the spatial string breaking distance and estimate it for $SU(3)$ gauge theory in the temperature range $0\\,\\text{-}\\,3\\,T_c$.",
        "keywords": [
          "hep-ph",
          "hep-lat",
          "hep-th",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16657v1",
        "authors": [
          "Oleg Andreev"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-lat",
          "hep-th",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "QCD",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.688441"
    },
    {
      "id": "arxiv-2602.16627v1",
      "title": "Dynamic effects of external axion fields in a system of many particles with spin",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16627v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We develop the theoretical model that describes dynamic non-equilibrium effects of external inertial and axion fields in a system of particles with spin. The possibility of using the spin density and the current density of non-relativistic quantum particle systems for the detection of the hypothetical axion-like dark matter is discussed. The resulting closed system of dynamic equations encompasses the continuity equation, the momentum balance equation, and the spin density evolution equation, accounting for the influence of the spin-rotation coupling and the external axion fields. The new formalism opens up new perspectives for an experimental search of dark matter axions.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16627v1",
        "authors": [
          "Mariya Iv. Trukhanova",
          "Yuri N. Obukhov"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.688728"
    },
    {
      "id": "arxiv-2602.16589v1",
      "title": "Isospin dependence of nuclear EMC effect from global QCD analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16589v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We perform a new global QCD analysis of unpolarized parton distribution functions (PDFs) in the nucleon from proton, deuteron and $A=3$ data, including recent measurements of $^3$He/$D$ and $^3$H/$D$ cross section ratios from the MARATHON experiment at Jefferson Lab. Simultaneously inferring the PDFs and nucleon off-shell corrections allows both to be determined consistently, without theoretical assumptions about the isospin dependence of nuclear effects. The analysis provides strong evidence for the need of nucleon off-shell corrections to describe the $A=3$ data, and suggests the presence of both isoscalar and isovector nuclear effects in $A \\leq 3$ nuclei. We find that the extracted EMC ratios of nuclear to nucleon structure functions for $A=2$ and 3 differ from those naively extrapolated from heavy nuclei down to low $A$.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16589v1",
        "authors": [
          "C. Cocuzza",
          "T. J. Hague",
          "W. Melnitchouk",
          "N. Sato",
          "A. W. Thomas"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Jefferson Lab",
        "Nuclear",
        "Act",
        "EMC",
        "QCD",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.689104"
    },
    {
      "id": "arxiv-2602.16582v1",
      "title": "M2-branes, Higher Form Symmetries and 1-Gerbes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16582v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Higher-Form Symmetries (HFS) of a closed bosonic M2-brane formulated on a compactified target space $\\mathcal{M}_9 \\times T^2$ are investigated. We show that there is an obstruction to the gauging of these global symmetries in the presence of background fields, a mixed 't~Hooft anomaly. Its cancellation is obtained by the inflow term constructed in terms of gauge fields which are flat connections on a $U(1)$-principal bundle and a torsion $\\mathcal{G}_1^{\\nabla_c}$-gerbe on the M2-brane worldvolume. The effect of these gauge structures together with non trivial \\textit{winding} embedding maps ensures the breaking of the continuous HFS $U(1)$ symmetry to a discrete subgroup and a worldvolume flux condition on the M2-brane. A Wilson surface, identified with the holonomy Hol$_\\nabla$ one of the Gerbe structures, the flat $\\mathcal{G}_1^{\\nabla_c}$-gerbe, is naturally introduced as the topological operator characterizing the M2-brane. The resulting topological operators realize discrete symmetries associated with the \\textit{winding} and the flux/\\textit{monopole} sectors, and their operator algebra is well-defined: the \\textit{monopole} operator acts non trivially on a \\textit{vortex-dressed} operator, while the winding operator acts on the pullback of the Wilson surface.",
        "keywords": [
          "hep-th",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16582v1",
        "authors": [
          "Fabián Caro-Pérez",
          "María Pilar García del Moral",
          "Álvaro Restuccia"
        ],
        "arxiv_categories": [
          "hep-th",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Higher Form Symmetries",
        "Form Symmetries",
        "Gerbes Higher",
        "Wind",
        "Act",
        "HFS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.689483"
    },
    {
      "id": "arxiv-2602.16562v1",
      "title": "Testing non-circular black hole spacetime with X-ray reflection",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16562v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "X-ray reflection spectroscopy is a powerful tool for testing the Kerr hypothesis and probing the strong gravity regime around accreting black holes. Most tests of General Relativity (GR) assume that the spacetime around a black hole is circular, meaning the metric possesses a specific symmetry structure common to the Kerr solution. However, deviations from circularity are predicted by various modified gravity theories and non-vacuum General Relativity solutions. In this work, we test a specific non-circular metric constructed based on a locality principle, where the deviation from the Kerr spacetime is driven by the local spacetime curvature. To accurately model the reflection spectrum in this background, we implement a relativistic ray-tracing code in horizon-penetrating (ingoing Kerr) coordinates, which are favored for their ability to avoid introducing curvature singularities at the horizon in non-circular spacetimes. We apply this model to the high-quality \\textit{NuSTAR} spectrum of the Galactic black hole binary EXO 1846--031. Our spectral analysis reveals a source with a high inclination angle ($ι\\approx 76^{\\circ}$) and a near-extremal spin parameter ($a_* \\approx 0.98$). While we identify a global minimum in the parameter space suggesting a non-zero deformation ($\\ell_{\\mathrm{NP}} \\approx 0.12$), the 99\\% confidence interval fully encompasses the Kerr limit ($\\ell_{\\mathrm{NP}}=0$). We conclude that the current X-ray reflection data for EXO 1846--031 are consistent with the Kerr hypothesis. This work demonstrates the feasibility of using X-ray reflection spectroscopy to constrain non-circular metrics and establishes a framework for future tests.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16562v1",
        "authors": [
          "Leda Gao",
          "Swarnim Shashank",
          "Cosimo Bambi"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "General Relativity",
        "Framework",
        "Act",
        "MIT",
        "EXO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.690631"
    },
    {
      "id": "arxiv-2602.16560v1",
      "title": "Recent results on the $Λ\\rightarrow p\\ell \\barν_\\ell$ semileptonic decay",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16560v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a lattice-QCD determination of the $Λ\\to p$ vector and axial-vector form factors, providing theoretical input for studies of the semileptonic decay $Λ\\to p\\ell\\barν_\\ell$. The calculation is carried out on a single gauge ensemble with physical light, strange, and charm quark masses and delivers a precise determination of the complete set of transition form factors, including second-class contributions. Using these form factors, we compute decay rates for both the electronic and muonic channels, as well as their ratio, which offers a sensitive test of lepton-flavor universality and possible non-standard scalar or tensor interactions. This decay mode provides a theoretically well-controlled avenue for extracting the CKM matrix element $|V_{us}|$ from the baryon sector. Our estimate of $|V_{us}|$ is obtained by combining our recent lattice-QCD results with recent measurements of the relevant branching fraction reported by BESIII and LHCb.",
        "keywords": [
          "hep-lat",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16560v1",
        "authors": [
          "Simone Bacchio",
          "Andreas Konstantinou"
        ],
        "arxiv_categories": [
          "hep-lat",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "BESIII",
        "Act",
        "CKM",
        "QCD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.691336"
    },
    {
      "id": "arxiv-2602.16534v1",
      "title": "Quantum Estimation Theory Limits in Neutrino Oscillation Experiments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16534v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Measurements of the Pontecorvo-Maki-Nakagawa-Sakata (PMNS) neutrino mixing parameters have entered a precision era, enabling increasingly stringent tests of neutrino oscillations. Within the framework of quantum estimation theory, we investigate whether flavor measurements, the only observables currently accessible experimentally, are optimal for extracting the oscillation parameters. We compute the Quantum Fisher Information (QFI) and the classical Fisher Information (FI) associated with ideal flavor projections for all oscillation parameters, considering accelerator muon (anti)neutrino and reactor electron antineutrino beams propagating in vacuum. Two main results emerge. First, flavor measurements saturate the QFI at the first oscillation maximum for $θ_{13}$, $θ_{23}$, and $θ_{12}$, demonstrating their information-theoretic optimality for these parameters. In contrast, they are far from optimal for $δ_{CP}$. In particular, only a small fraction of the available information on $δ_{CP}$ is extracted at the first maximum; the sensitivity improves at the second maximum, in line with the strategy of ESS$ν$SB, a planned facility. Second, the QFI associated with $δ_{CP}$ is approximately one order of magnitude smaller than that of the mixing angles, indicating that the neutrino state intrinsically encodes less information about CP violation. Nevertheless, this quantum bound lies well below current experimental uncertainties, implying that the present precision on $δ_{CP}$ is not fundamentally limited. Our results provide a quantitative framework to disentangle fundamental from practical limitations and establish a benchmark for optimizing future neutrino facilities.",
        "keywords": [
          "hep-ph",
          "hep-ex",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16534v1",
        "authors": [
          "Claudia Frugiuele",
          "Marco G. Genoni",
          "Michela Ignoti",
          "Matteo G. A. Paris"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neutrino Oscillation Experiments Measurements",
        "Quantum Fisher Information",
        "Fisher Information",
        "Framework",
        "PMNS",
        "Act",
        "QFI",
        "MIT",
        "ESS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.692505"
    },
    {
      "id": "arxiv-2602.16514v1",
      "title": "Atmospheric Neutrino Charged-Current Interactions at Large Liquid-Scintillator Detectors: I. Physics of Neutrino-Antineutrino Discrimination",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16514v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we present a systematic study of the event characteristics and physics of neutrino-antineutrino discrimination associated with atmospheric neutrino charged-current interactions in large liquid scintillator detectors. This study encompasses the primary neutrino interactions, the sequential second interactions of final-state particles, and the final neutron captures. We carefully investigate the properties of final-state charged leptons and hadrons, providing distinct distributions of inelasticity and captured neutron multiplicity for both neutrino and antineutrino interactions. These distributions are employed to assess the quantitative performance of neutrino-antineutrino discrimination. Our findings lay the groundwork for atmospheric neutrino oscillation studies in large liquid scintillator detectors, particularly in the determination of neutrino mass ordering.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16514v1",
        "authors": [
          "Xinhai He",
          "Gao-song Li",
          "Yu-Feng Li",
          "Wuming Luo",
          "Liang-jian Wen"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Antineutrino Discrimination In",
        "Atmospheric Neutrino Charged",
        "Scintillator Detectors",
        "Current Interactions",
        "Large Liquid",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.692673"
    },
    {
      "id": "arxiv-2602.16477v1",
      "title": "The Crusts of Neutron Stars Revisited: Approximations within a Polytropic Equation of State Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16477v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we revisit several thin-crust approximations presented in the literature and compare them with the exact solutions of the Tolman--Oppenheimer--Volkoff (TOV) equations. In addition, we employ three different equations of state (EoSs), including one with a pasta phase, each based on a distinct theoretical framework: the variational method, relativistic Brueckner--Hartree--Fock theory, and relativistic mean-field theory. We emphasize that these approximations require only the TOV solutions for the core and the EoS properties at the core--crust interface; in our approach, only the energy density is needed. Finally, the relativistic approximation, as well as the Newtonian approximation with corrections, shows good agreement with the exact solutions. This indicates that a simple treatment of the crust is sufficient for structural purposes, independently of the uncertainties in the sub-nuclear equation of state, which are not very large. The unified EoS SINPA (relativistic mean-field theory), including the pasta phase, was used to study the thin-crust approximation, while degeneracy in the $M$--$R$ relation is demonstrated through: (i) anisotropic pressure in the modified TOV equations, (ii) the $f(R, L_m, T)$ gravity model, and (iii) dark matter admixture. As demonstrated, modifications to the description of gravitation introduce degeneracies in the mass--radius relation that are challenging to disentangle or quantify precisely.",
        "keywords": [
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16477v1",
        "authors": [
          "F. Köpp",
          "J. E. Horvath",
          "C. A. Z. Vasconcellos"
        ],
        "arxiv_categories": [
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Neutron Stars Revisited",
        "Polytropic Equation",
        "State Approach In",
        "Agreement",
        "Framework",
        "Nuclear",
        "SINPA",
        "Act",
        "WTO",
        "TOV",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.692915"
    },
    {
      "id": "arxiv-2602.16470v1",
      "title": "High Energy Nuclear Optics of polarized nucleons and nuclei: research at complex Nuclotron M- NICA",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16470v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Refracton of particles (nucleons, nuclei, $γ$-quanta) in matter with polarized protons (nuclei) results in revealing coherent quasi-optical phenomenon of nuclear spin precession of particles (nuclei) in the pseudomagnetic field of matter with polarized spins and the phenomenon of birefringence of particles (nuclei) with spin $S \\ge 1$. These phenomena can be observed and studied at complex NuclotronM-NICA. The similar effects for $γ$-quanta could be observed at LINAC accelerator. Quasi-optical coherent phenomena of spin rotation and dichroism are not caused by strong interactions only, the T-odd P-odd, T-odd P-even, T-even P-odd interactions also contribute. Limits for the value of these contributions at energies available at complex NuclotronM-NICA can be obtained by investigating all these phenomena. When studying polarized particles collisions, it is necessary to consider possible influences of quasi-optical phenomena of spin rotation and spin dichroism caused by nuclear precession and birefringence.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16470v1",
        "authors": [
          "Vladimir Baryshevsky"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "High Energy Nuclear Optics",
        "Nuclear",
        "LINAC",
        "NICA",
        "Act",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.693277"
    },
    {
      "id": "arxiv-2602.16450v1",
      "title": "All-path-length and sub-eikonal corrections to momentum broadening in the opacity expansion approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16450v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a detailed study of momentum broadening for high-energy partons traversing the Quark-Gluon Plasma (QGP), extending the Gyulassy-Levai-Vitev (GLV) formalism to include both all-path-length (APL) and sub-eikonal corrections. Traditional GLV calculations rely on the large separation distance and large formation time approximations, which are valid for large systems, but whose applicability in small systems such as pp and p/dA may fail. We derive analytic expressions for the momentum broadening distributions to first order in the opacity expansion, and perform a numerical investigation to quantify their impact. Our results show that the APL result reduces the low-momentum broadening and the sub-eikonal correction enhances the high-momentum broadening. The combined APL and sub eikonal correction show that the sub-eikonal correction mitigates the effect of the APL correction.",
        "keywords": [
          "hep-ph",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16450v1",
        "authors": [
          "Dario van den Berg",
          "Isobel Kolbe"
        ],
        "arxiv_categories": [
          "hep-ph",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Gluon Plasma",
        "EPA",
        "APL",
        "Act",
        "MIT",
        "WHO",
        "GLV",
        "QGP",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.693462"
    },
    {
      "id": "arxiv-2602.16428v1",
      "title": "The Penrose-Rindler equation and horizon thermodynamics of stationary black holes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16428v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Black holes are the natural arena for exploring the interplay between gravity and thermodynamics. Although the association between black hole mechanics and black hole thermodynamics is well-established, the comprehensive geometric formulation of thermodynamic variables deserves further investigation. In this work, both Newman-Penrose (NP) and Geroch-Held-Penrose (GHP) formalisms are considered within the framework of horizon thermodynamics. We show that the NP formalism reformulates the horizon condition as the Penrose-Rindler equation. In this context, a Smarr-like formula for stationary black holes is recovered from the Penrose-Rindler equation reinterpreted as a horizon equilibrium of pressures, which includes a pressure associated with the horizon rotation. A complete geometric reformulation of this reinterpretation of the Penrose-Rindler equation evaluated at the horizon is developed within the GHP formalism. The GHP approach further inspires the introduction of the horizon-averaged matter pressure and its conjugate volume, thereby enabling a quasi-local realization of the Smarr-like formula for stationary black holes. This geometric formulation clarifies the connection between horizon dynamics and thermodynamics and offers a unified setting for extending black hole thermodynamics beyond spherical symmetry.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16428v1",
        "authors": [
          "Diego Fernández-Silvestre",
          "Alberto Guilabert",
          "Pedro Bargueño",
          "Juan A. Miralles"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "GHP",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.693659"
    },
    {
      "id": "arxiv-2602.16425v1",
      "title": "Dynamical generation of fermion mass in a scalar-fermion theory with $λφ^4$ interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16425v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The effective potential for a scalar theory with $λφ^4$ interaction, coupled to a massless fermion through Yukawa interaction is calculated by summing over infinite number of two particle irreducible (2PI) diagrams of two different types and a 2PI diagram of a third type using Cornwall, Jackiw and Tomboulis (CJT) method. There is an inversion symmetry present in the effective potential under $φ\\rightarrow -φ$. At large coupling it exhibits minima below the zero potential line and on either side of the maximum at $φ=0$. The fermion acquires a mass at any non-trivial, positive minimum breaking the inversion symmetry of the vacuum.",
        "keywords": [
          "hep-th",
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16425v1",
        "authors": [
          "Somnath Majumder",
          "Krishnendu Mukherjee"
        ],
        "arxiv_categories": [
          "hep-th",
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "CJT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.693900"
    },
    {
      "id": "arxiv-2602.16423v1",
      "title": "Quasi-two-body decays $B^+\\to D_s^+ (R\\to) K^+K^-$ in the perturbative QCD approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16423v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A search for the decay $B^+\\to D_s^+ K^+K^-$ has been reported by the LHCb Collaboration using $pp$ collision data corresponding to an integrated luminosity of $4.8\\,\\mathrm{fb}^{-1}$, collected at center-of-mass energies of 7, 8, and 13~TeV, in which no amplitude analysis of the $K^+K^-$ subsystem was performed. In this work, we study the resonant contributions to the decay $B^+\\to D_s^+ K^+K^-$ within the perturbative QCD (PQCD) factorization framework. Contributions from the $S$-wave resonances $f_0(980)$, $f_0(1370)$, and $f_0(1500)$, the $P$-wave resonance $φ(1020)$, and the $D$-wave resonances $f_2(1270)$ and $f_2(1525)$ are taken into account. By introducing the corresponding two-meson distribution amplitudes for the $K^+K^-$ system, we perform a complete perturbative analysis of the quasi-two-body decays $B^+\\to D_s^+(R\\to)K^+K^-$, where $R$ denotes an intermediate resonance, and present the first PQCD predictions for the associated branching fractions. Using the narrow-width approximation, we further extract the branching fractions of the corresponding two-body decays $B^+\\to D_s^+R$. Our results are consistent with the available experimental measurements and previous theoretical studies. Finally, we find that direct CP asymmetries vanish for these quasi-two-body decays within the Standard Model, so that any experimentally observed nonzero CP asymmetry would constitute a clear signal of physics beyond the Standard Model.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16423v1",
        "authors": [
          "Zhi-Tian Zou",
          "Jun-Peng Wang",
          "Zhou Rui",
          "Ying Li"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard Model",
        "Framework",
        "Standard",
        "PQCD",
        "Act",
        "QCD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.694373"
    },
    {
      "id": "arxiv-2602.16380v1",
      "title": "Asymptotic Freedom of V-A Fermi Interaction",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16380v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the V-A Fermi interaction and apply an earlier developed method for summing up the leading asymptotics for scattering amplitudes in non-renormalizable theories. We consider the amplitude of fermion-antifermion scattering and derive the corresponding RG equation that sums the leading logarithmic contributions just like in renormalizable models. Numerical solution of this equation in the asymptotic regime $s\\sim t\\sim u \\sim E^2 \\to \\infty$ leads to amplitude logarithmically decreasing with energy, thus restoring the unitarity violated at the tree level.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16380v1",
        "authors": [
          "A. T. Borlakov",
          "D. I. Kazakov"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fermi Interaction We",
        "Asymptotic Freedom",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.694487"
    },
    {
      "id": "arxiv-2602.16369v1",
      "title": "Rapidity dependence of mean transverse momentum fluctuation and decorrelation in baryon-dense medium",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16369v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "I study the event-by-event fluctuation and rapidity decorrelation of the mean transverse momentum $\\spt$, which has recently been proposed as a sensitive probe of the equation of state at finite baryon density. The investigation reveals that, in a baryon-rich medium, the event-by-event fluctuation of the mean transverse momentum is driven by the combined effects of energy-density and net-baryon-density fluctuations. Consequently, the rapidity dependence of this observable provides a promising handle to probe the three-dimensional structure of both energy and baryon density profiles. Previous studies have shown that $\\spt$ decorrelation along rapidity is largely insensitive to shear and bulk viscosity; however, its dependence on baryon diffusion, another key transport coefficient in baryonic matter, has not been explored. I find that baryon diffusion has a negligible impact, establishing this observable as a robust probe of the equation of state. Furthermore, I present predictions for identified hadrons and observe a pronounced splitting in the rapidity decorrelation of mean transverse momentum between protons and antiprotons, indicating different transverse flow dynamics for baryons and antibaryons.",
        "keywords": [
          "nucl-th",
          "hep-ph",
          "nucl-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16369v1",
        "authors": [
          "Tribhuban Parida"
        ],
        "arxiv_categories": [
          "nucl-th",
          "hep-ph",
          "nucl-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.694666"
    },
    {
      "id": "arxiv-2602.16294v1",
      "title": "Entropy Modifications from Stochastic Metric Fluctuations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16294v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Deviations from the area law of the horizon entropy, in the cosmological setup, are known to lead to modified Friedmann equations governing the evolution of the universe. In this work, we propose that such modifications need not be introduced phenomenologically but can emerge dynamically from stochastic fluctuations of the spacetime metric. We consider a Friedmann-Robertson-Walker (FRW) universe perturbed by a conformal, time-dependent noise factor, whose ensemble average vanishes, leaving the mean background geometry unchanged. By averaging the Einstein equations to second order in the fluctuation amplitude, we derive a modified Friedmann equation that includes an effective correction term. This correction is shown to be equivalent to the general expression obtained from an arbitrary deformation of the entropy-area relation. By specifying the statistical properties, particularly the variance of the conformal noise, we successfully reproduce the Friedmann equation corrections associated with several well-known generalized entropy frameworks, including Rényi, (dual) Kaniadakis, Barrow, logarithmic, and MOND inspired hypergeometric entropies. Our results suggest that deviations from the area law can be interpreted as the macroscopic, coarse-grained imprint of unresolved, microscopic stochastic degrees of freedom in spacetime.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16294v1",
        "authors": [
          "Amir A. Khodahami",
          "Ahmad Sheykhi"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Stochastic Metric Fluctuations Deviations",
        "Entropy Modifications",
        "Framework",
        "BERT",
        "MOND",
        "Act",
        "FRW",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.695214"
    },
    {
      "id": "arxiv-2602.16288v1",
      "title": "Is the Standard Model Effective Field Theory Enough for Higgs Pair Production?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16288v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study Higgs-boson pair production in the Standard Model Effective Field Theory (SMEFT) up to dimension six and in the Higgs Effective Field Theory (HEFT) at leading order in the effective theory expansion, and assess which description is appropriate in concrete UV scenarios. Motivated by \"Loryon\"-inspired models, we compare the Higgs pair production cross sections predicted by the full models to their SMEFT and HEFT counterparts. We identify regimes in which the two EFTs provide comparable descriptions, and clarify the limits required for their couplings to match. We also find that, for parts of parameter space in some of these models, HEFT can reproduce Higgs pair production more accurately than SMEFT, highlighting di-Higgs measurements as a potential probe of non-linear electroweak dynamics.",
        "keywords": [
          "hep-ph",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16288v1",
        "authors": [
          "Íñigo Asiáin",
          "Ramona Gröber",
          "Lorenzo Tiberi"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard Model Effective Field",
        "Higgs Pair Production",
        "Standard",
        "SMEFT",
        "HEFT",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.695558"
    },
    {
      "id": "arxiv-2602.16285v1",
      "title": "Tidal Deformation Bounds and Perturbation Transfer in Bounded Curvature Spacetimes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16285v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We derive two model-independent results for spacetimes with globally bounded tidal fields. These are operational resolution scales of the local-inertial approximation and tidal dynamics; no spacetime discreteness is implied. Given an invariant bound $λ_{\\max}\\leλ_{\\rm bound}$ on the electric Riemann eigenvalues $E_{ij}\\equiv R_{\\hat{0}i\\hat{0}j}$ along freely falling worldlines, we prove (i)~a rigorous upper bound on accumulated geodesic deviation through any bounded curvature interior, controlled by $τ_*\\equivλ_{\\max}^{-1/2}$, and (ii)~the existence of a critical wavenumber $k_*\\simτ_*^{-1}$ separating adiabatic from non-adiabatic perturbation transfer through high-curvature epochs, with Bogoliubov coefficients exponentially suppressed for $k\\,τ_*\\gg 1$. Both results depend only on the tidal bound (and, for mode transfer, on a mild timescale assumption for the curvature-driven effective potential) and are otherwise insensitive to metric details. For preparation, we collect the standard operational consequences of bounded curvature, including the accuracy-dependent local-inertial domain $L_{\\rm LI}(\\varepsilon)\\sim\\sqrt{\\varepsilon}\\, λ_{\\max}^{-1/2}$ and, for conformally flat cores in four dimensions, the benchmark ratio $τ_*/L_*=24^{1/4}$ with $L_*\\equiv K_{\\max}^{-1/4}$. We quantify the robustness of this coefficient under departures from maximal symmetry via the Weyl-to-Kretschmann ratio $ε_C$. The general framework is validated numerically in the extremal Hayward geometry.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16285v1",
        "authors": [
          "Martin Drobczyk"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Bounded Curvature Spacetimes We",
        "Tidal Deformation Bounds",
        "Perturbation Transfer",
        "Framework",
        "Standard",
        "EPA",
        "NSF",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.696636"
    },
    {
      "id": "arxiv-2602.16269v1",
      "title": "Error correcting codes and heterotic Narain CFTs",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16269v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study error correcting codes that construct the Narain lattices of heterotic strings as code lattices. We identify, in both $E_8\\times E_8$ and Spin$(32)/Z_2$ heterotic strings, a pair of a binary code and a set of the corresponding metric, B field, and background gauge field, such that the lattice constructed from the binary code by Construction A coincides with the Narain lattice. We also construct heterotic Narain lattices using codes over $F_3$ and $F_5$ by Construction A${}_C$ and \"Construction A${}_g$\" with $g=SU(5)$, respectively. As a bi-product, we also clarify the relationship between codes that construct Euclidean even self-dual lattices and NSR-fermions, where the $Z_2$ inversion structure of the generator matrices plays a significant role.",
        "keywords": [
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16269v1",
        "authors": [
          "Shun'ya Mizoguchi",
          "Takumi Oikawa"
        ],
        "arxiv_categories": [
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "NSR",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.696913"
    },
    {
      "id": "arxiv-2602.16243v1",
      "title": "Multi-centered Myers-Perry Black Holes in Five Dimensions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16243v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a new family of multi-centered rotating black hole solutions in 5D vacuum Einstein gravity, providing explicit examples of cohomogeneity-three spacetimes. It is well known that, in the presence of two commuting Killing vector fields, the theory reduces to 3D gravity coupled to an $SL(3,\\mathbb{R})$ nonlinear sigma model with five scalar fields. We show that the scalar fields of the extremal Myers-Perry solution can be expressed in terms of two harmonic functions on 3D flat space, and that promoting these functions to include multiple sources yields explicit multi-centered extremal Myers-Perry black holes located at arbitrary positions. Each center forms a smooth $S^3$ Killing horizon, provided that the rotation parameters satisfy $|j_i|<1/2$. We further demonstrate that all curvature singularities are hidden behind the horizons and that no closed timelike curves arise on or outside the horizons. The solutions are asymptotically locally Minkowski in the sense that constant-time hypersurfaces are asymptotically locally Euclidean (ALE). As a concrete example, we consider a binary configuration, examine its rod structure, and demonstrate the absence of conical singularities between the two black holes, indicating that they are supported by an intermediate bubble region separating them.",
        "keywords": [
          "hep-th",
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16243v1",
        "authors": [
          "Shinya Tomizawa",
          "Jun-ichi Sakamoto",
          "Ryotaku Suzuki"
        ],
        "arxiv_categories": [
          "hep-th",
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Five Dimensions We",
        "Perry Black Holes",
        "EPA",
        "ALE",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.697341"
    },
    {
      "id": "arxiv-2602.16230v1",
      "title": "Electromagnetic Production of Kaons on the Nucleon",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16230v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Studies of the electromagnetic production of strange quarks began in the 1950s as something of a curiosity that puzzled experimentalists and theorists alike. As the datasets increased, concomitant advances in theoretical models were realized. A paradigm shift occurred in the 1990s with the development of second-generation facilities at ELSA, MAMI, SPring-8, and JLab, which brought nuclear physics experiments forward by orders of magnitude in counting statistics compared to the first-generation efforts. This was an utter boon to strangeness physics investigations, and to date, more than 50 dedicated experiments in kaon photo- and electroproduction have been completed at facilities around the world, leading to a host of experimental observables that have enabled significant advances in the exploration of strongly interacting systems that decay via $s\\bar{s}$ quark pair creation. This review was designed to provide the first-ever in-depth overview of both the experimental and theoretical progress in the field of the electromagnetic production of strangeness. This work looks back over 70 years of past developments, discusses ongoing work and near-term plans, and details future possibilities being considered for third-generation facilities. Throughout this work, the primary impacts of these explorations are highlighted, along with connections to a wide range of related phenomenological applications. An important goal of this review is to provide a complete, self-contained guide into this field prepared at a level that is relevant for both new and seasoned scientists, whether experimentalists, phenomenologists, or theorists, to better understand what has been accomplished by so many dedicated folks-each building on what has come before-and to appreciate the exciting future potential for continued studies in this area. A more complete abstract is provided in the paper.",
        "keywords": [
          "hep-ph",
          "hep-ex",
          "nucl-ex",
          "nucl-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16230v1",
        "authors": [
          "Terry Mart",
          "Jovan Alfian Djaja",
          "Daniel S. Carman"
        ],
        "arxiv_categories": [
          "hep-ph",
          "hep-ex",
          "nucl-ex",
          "nucl-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Electromagnetic Production",
        "Nucleon Studies",
        "SPring-8",
        "Nuclear",
        "ELSA",
        "MAMI",
        "EPA",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.697979"
    },
    {
      "id": "arxiv-2602.16219v1",
      "title": "On the Possibility of Quantum Gravity Emerging from Geometry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16219v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Is it possible to induce an effective generalized uncertainty principle (GUP) emerging from geometry and reinterpret the gravitational GUP as the effective uncertainty relation induced by microscopic horizon geometry? More broadly, is it possible to develop a notion of quantum gravity emerging from geometry? We will give a positive answer, but with important caveats.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16219v1",
        "authors": [
          "Jaume Gine"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Gravity Emerging",
        "Geometry Is",
        "GUP",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.698059"
    },
    {
      "id": "arxiv-2602.16190v1",
      "title": "Comments on Entire Functions of the Derivative Operator",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16190v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Many attempts to introduce fundamental nonlocality into quantum (or classical) field theory are based on the assumption that exponentials of the d'Alembertian are positive-definite, so that these operators can be employed without engendering the Ostrogradskian instability associated with higher derivative Lagrangians. {\\bf This assumption is false.} Working in the simple context of a 1-dimensional, point particle $q(t)$, I demonstrate that the equation $\\exp[T^2 \\tfrac{d^2}{dt^2}] q(t) = 0$ has an infinite number of rapidly oscillating, exponentially rising and falling solutions. This infinite kernel is in one-to-one correspondence with the ability to specify ``initial value data'' {\\it arbitrarily} over {\\it any} finite interval $t_1 < t < t_2$.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16190v1",
        "authors": [
          "R. P. Woodard"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Derivative Operator Many",
        "Entire Functions",
        "BERT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.698182"
    },
    {
      "id": "arxiv-2602.16116v1",
      "title": "A Brief Review of Wormhole Cosmic Censorship",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16116v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Spacetime singularities, in the sense that curvature invariants are infinite at some point or region, are thought to be impossible to observe, and must be hidden within an event horizon. This conjecture is called Cosmic Censorship (CC), and was formulated by Penrose. Here we review another type of CC where spacetime singularities are causally disconnected from the universe, because the throat of a wormhole ``sucks in'' the geodesics and prevents them from making contact with the singularity. In this work, we present a series of exact solutions to the Einstein--Maxwell--Dilaton equations that feature a ring singularity; that is, the curvature invariants are singular in this ring, but the ring is causally disconnected from the universe so that no geodesics can touch it. This extension of CC is called Wormhole Cosmic Censorship.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16116v1",
        "authors": [
          "Leonel Bixano",
          "I. A. Sarmiento-Alvarado",
          "Tonatiuh Matos"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wormhole Cosmic Censorship Spacetime",
        "Wormhole Cosmic Censorship",
        "Cosmic Censorship",
        "Brief Review",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.698339"
    },
    {
      "id": "arxiv-2602.16088v1",
      "title": "Group character averages via a single Laguerre",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16088v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Average of exponential ${\\rm Tr}_R e^X$, i.e. of a group rather than an algebra character, in Gaussian matrix model is known to be an amusing generalization of Schur polynomial, where time variables are substituted by traces of products of non-commuting matrices ${\\rm Tr} \\left(\\prod_i A_{k_i}\\right)$ and are thus labeled by weak compositions. The entries of matrices $A_k$ are made from extended Laguerre polynomials, what introduces additional difficulties. We describe the generic sum rules, which express arbitrary traces through convolutions of a single Laguerre polynomial $L_{N-1}^1(z_{k_i})$, what is a considerable simplification.",
        "keywords": [
          "hep-th",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16088v1",
        "authors": [
          "Alexei Morozov",
          "Kazumi Okuyama"
        ],
        "arxiv_categories": [
          "hep-th",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Laguerre Average",
        "Act",
        "N-1"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.698447"
    },
    {
      "id": "arxiv-2602.16076v1",
      "title": "The most general four-derivative Unitary String Effective Action with Torsion and Stringy-Running-Vacuum-Model Inflation: Old ideas from a modern perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16076v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The string-inspired running vacuum model (StRVM) of inflation is based on a Chern-Simons (CS) gravity effective action, in which the only four-spacetime-derivative-order term is a gravitational anomalous CS Pontryagin density coupled to an axion. In this work, we revisit curvature-squared string-inspired effective actions, from the point of view of appropriate local field redefinitions, leaving the perturbative string scattering matrices invariant. We require simultaneously unitarity and torsion interpretation of the field strength of the Kalb-Ramond antisymmetric tensor, features characterising the (3+1)-dimensional StRVM Cosmology. Unlike the higher dimensional case, the above feature is possible in the context of (3+1)-dimensional spacetimes, obtained after string compactification. We demonstrate that the unitarity and torsion-interpretation requirements lead to a single-type of extra four-derivative terms in the effective gravitational action, not discussed in the previous literature of StRVM, which however is shown to be subleading by many orders of magnitude, compared to the terms of the StRVM framework. Hence, its presence has no practical implications for the relevant inflationary (and, hence, postinflationary) physics of the StRVM. This demonstrates the phenomenological completeness of the StRVM cosmological scenario, which is thus fully embeddable in the UV complete (quantum-gravity compatible) string theory framework.",
        "keywords": [
          "gr-qc",
          "hep-th"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16076v1",
        "authors": [
          "Nick E. Mavromatos",
          "George Panagopoulos"
        ],
        "arxiv_categories": [
          "gr-qc",
          "hep-th"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Unitary String Effective Action",
        "Model Inflation",
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.698810"
    },
    {
      "id": "arxiv-2602.16029v1",
      "title": "Towards the inclusion of NLO EW corrections in the MiNLO method in Drell-Yan processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16029v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper we present the first application of the MiNLO method to the calculation of QED NLO corrections to the production of a neutral vector boson in Drell-Yan processes. We consider only the case of initial-state radiation, when the Z boson decays into neutrinos. We illustrate the abelianization procedure of the MiNLO formulae and discuss the impact that it has on the differential cross section. We then propose a variant of the MiNLO formulae in order to circumvent some of the problems that arise when dealing with QED emissions. Since this is a case study, we use ad-hoc parton distribution functions and a larger value of the electromagnetic coupling constant, in order to emphasize potential discrepancies with respect to the expected behavior of the MiNLO formulae. We quantify the uncertainties connected with the proposed method, also for a the physical value of the electromagnetic coupling. The study presented here is a necessary first step towards incorporating full electroweak effects into the MiNNLOPS framework.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16029v1",
        "authors": [
          "Filippo Belloni",
          "Mauro Chiesa",
          "Carlo Oleari",
          "Emanuele Re"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "EPA",
        "NLO",
        "QED",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.699148"
    },
    {
      "id": "arxiv-2602.15991v1",
      "title": "Power-Law Inflation in n-Dimensional Fractional Scalar Field Cosmology: Observational Constraints and Dynamical Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15991v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Power-law inflation with $a(t) \\propto t^m$ is conceptually simple and predicts a scalar tilt $n_s = 1 - 2/m$ compatible with CMB data, but in four-dimensional Einstein gravity it typically yields a tensor-to-scalar ratio $r = 16/m$ that is too large to satisfy current bounds. We show that a minimal extension based on fractional scalar-field cosmology resolves this tension. Introducing a fractional order $α\\neq 1$ generates non-local (memory) corrections in the Friedmann and Klein-Gordon dynamics that suppress $r$ while keeping $n_s$ essentially unchanged. We derive an explicit mapping $α(n,m)$ and recover the standard power-law limit as $α\\to 1$. For observationally favored values $α\\approx 0.8$-$0.9$ in four dimensions we obtain $n_s \\approx 0.965$ and $r \\lesssim 0.04$, bringing power-law inflation into agreement with data. The scalar potential follows self-consistently as an exponential, and a dynamical-systems analysis shows the fractional power-law solutions form stable inflationary attractors over the viable parameter range. These results establish fractional power-law inflation as a predictive and testable framework, with clear targets for forthcoming CMB polarization measurements.",
        "keywords": [
          "gr-qc"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15991v1",
        "authors": [
          "Daniel Oliveira",
          "Seyed Rasouli",
          "Joao Marto",
          "Paulo Moniz"
        ],
        "arxiv_categories": [
          "gr-qc"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Fractional Scalar Field",
        "Observational Constraints",
        "Dynamical Analysis Power",
        "Law Inflation",
        "Agreement",
        "Framework",
        "Standard",
        "Act",
        "MIT",
        "CMB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.699600"
    },
    {
      "id": "arxiv-2602.15987v1",
      "title": "Gaussian continuous tensor network states: short-distance properties and imaginary-time evolution",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15987v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study Gaussian continuous tensor network states (GCTNS) - a finitely-parameterized subclass of Gaussian states admitting an interpretation as continuum limits of discrete tensor network states. We show that, at short distance, GCTNS correspond to free Lifshitz vacua, establishing a connection between certain entanglement properties of the two. Two schemes to approximate ground states of (free) bosonic field theories using GCTNS are presented: rational approximants to the exact dispersion relation and Trotterized imaginary-time evolution. We apply them to Klein-Gordon theory and characterize the resulting approximations, identifying the energy scales at which deviations from the target theory appear. These results provide a simple and analytically controlled setting to assess the strengths and limitations of GCTNS as variational ansätze for relativistic quantum fields.",
        "keywords": [
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15987v1",
        "authors": [
          "Marco Rigobello",
          "Erez Zohar"
        ],
        "arxiv_categories": [
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "GCTNS",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.699990"
    },
    {
      "id": "arxiv-2602.15960v1",
      "title": "Novel Constraints on Spin-Dependent Light Dark Matter Scattering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15960v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We explore the sensitivity of the SNO experiment to light dark matter particles $χ$ with spin-dependent interactions with nucleons. We show that the pair-production of MeV scale dark matter is possible in heavy water (CANDU) reactors via ${\\rm D}(n,χ\\barχ)^3{\\rm He}$, and calculate the expected rate within the simplest models of $χ$-nucleon interactions. %Heavy water nuclear reactors serve as an excellent production method for spin-dependent dark matter. Owing to a sizable $Q$-value for this reaction, a large fraction of DM particles produced this way are above the threshold for deuteron disintegration, ${\\rm D}(χ,χ)np$, which adds to the SNO neutral current signal. Evaluating the CANDU-to-SNO scheme for the production and detection of DM, we derive novel constraints for the $χ$-nucleon spin-dependent cross sections, showing that cross sections above $σ_{χp} \\sim 10^{-33}\\,{\\rm cm}^{2}$ are generally excluded if $m_χ\\leq1.5$\\,MeV. An isospin-mirror reaction will occur in the Sun, and for the kinematically allowed region it excludes a portion of parameter space with cross sections on the order $10^{-37}\\,{\\rm cm}^{2}$. We also evaluate the potential sensitivity of small ``near\" detectors placed in close proximity to a CANDU reactor to search for a coherent nuclear recoil, finding subdominant sensitivity.",
        "keywords": [
          "hep-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15960v1",
        "authors": [
          "Alexander Clarke",
          "Maxim Pospelov"
        ],
        "arxiv_categories": [
          "hep-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dependent Light Dark Matter",
        "Novel Constraints",
        "Scattering We",
        "Nuclear",
        "CANDU",
        "Act",
        "SNO",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.700548"
    },
    {
      "id": "arxiv-2602.15947v1",
      "title": "Statistics of Daily Modulation in Dark Matter Direct Detection Experiments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15947v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The time-dependent modulation of the event rate in dark matter direct detection experiments, arising from the motion of the Earth with respect to the Galactic rest frame, is a distinctive signature whose observation is crucial for claiming a discovery of dark matter. While annual modulation has been well studied for decades, daily modulation due to the Earth's rotation has attracted increased attention recently due to the identification of anisotropic solid-state detector materials that yield a direction-dependent scattering rate without sacrificing the overall rate. We perform a statistical analysis of daily modulation in dark matter scattering experiments, with the goal of maximizing the statistical significance of a modulating signal in the presence of an unknown background rate, which may be either flat (non-modulating), or modulating over a 24-hour period with a known or unknown phase. In the background-dominated regime, we find that the discovery significance scales as $f_\\text{RMS} \\sqrt{T}$, where $T$ is the total exposure time and $f_\\text{RMS}$ is the root-mean-square modulation amplitude; in particular, the significance continues to improve with exposure rather than saturating due to systematic uncertainties in the background rate. Using anisotropic trans-stilbene detectors for sub-GeV dark matter as a benchmark example, we provide prescriptions for optimizing the significance for a given total detector mass and location. In an example analysis using three detectors, optimizing the detector orientations can reduce the required exposure by a factor of $\\sim 5$ for a desired discovery or exclusion significance, even after profiling over an unknown modulating background phase.",
        "keywords": [
          "hep-ph",
          "astro-ph.IM",
          "hep-ex"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15947v1",
        "authors": [
          "Carlos Blanco",
          "Joshua W. Foster",
          "Yonatan Kahn",
          "Benjamin Lillard"
        ],
        "arxiv_categories": [
          "hep-ph",
          "astro-ph.IM",
          "hep-ex"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dark Matter Direct Detection",
        "Daily Modulation",
        "RMS",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:02.700926"
    },
    {
      "id": "arxiv-2602.16693v1",
      "title": "Numerical study of non-relativistic quantum systems and small oscillations induced in a helically twisted geometry",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16693v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We investigate bound states of a non-relativistic scalar particle in a three-dimensional helically twisted (torsional) geometry, considering both the free case and the presence of external radial interactions. The dynamics is described by the Schrödinger equation on a curved spatial background and, when included, by minimal coupling to a magnetic vector potential incorporating an Aharonov--Bohm flux. After separation of variables, the problem reduces to a one-dimensional radial eigenvalue equation governed by an effective potential that combines torsion-induced Coulomb-like and centrifugal-like structures with magnetic/flux-dependent terms and optional model interactions. Because closed-form analytic solutions are not reliable over the parameter ranges required for systematic scans, we compute spectra and eigenfunctions numerically by formulating the radial equation as a self-adjoint Sturm--Liouville problem and solving it with a finite-difference discretization on a truncated radial domain, with explicit convergence control. We analyze four representative scenarios: (i) no external potential, (ii) Cornell-type confinement, (iii) Kratzer-type interaction, and (iv) the small-oscillation regime around the minimum of a Morse potential. We present systematic trends of the low-lying levels as functions of the torsion parameter, magnetic field, and azimuthal sector, and we show that geometric couplings alone can produce effective confinement even in the absence of an external interaction.",
        "keywords": [
          "quant-ph",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16693v1",
        "authors": [
          "C. F. S. Pereira",
          "R. L. L. Vitória",
          "A. R. Soares",
          "B. B. Silva",
          "H. Belich"
        ],
        "arxiv_categories": [
          "quant-ph",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.763524"
    },
    {
      "id": "arxiv-2602.16680v1",
      "title": "Intermodal quantum key distribution over an 18 km free-space channel with adaptive optics and room-temperature detectors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16680v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Intermodal quantum key distribution at telecom wavelengths provides a hybrid interface between fiber connections and free-space links, both essential for the realization of scalable and interoperable quantum networks. Although demonstrated over short-range free-space links, long-distance implementations of intermodal quantum key distribution remain challenging, due to turbulence-induced wavefront aberrations which limit efficient single-mode fiber coupling at the optical receiver. Here, we demonstrate a real-time intermodal quantum key distribution field trial over an 18 km free-space link, connecting a remote terminal to an urban optical ground station equipped with a 40 cm-class telescope. An adaptive optics system, implementing direct wavefront sensing and high-order aberration correction, enables efficient single-mode fiber coupling and allows secure key generation of 200 bit/s using a compact state analyzer equipped with room-temperature detectors. We further validate through experimental data a turbulence-based model for predicting fiber coupling efficiency, providing practical design guidelines for future intermodal quantum networks.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16680v1",
        "authors": [
          "Edoardo Rossi",
          "Ilektra Karakosta-Amarantidou",
          "Matteo Padovan",
          "Marco Nardi",
          "Marco Avesani"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Guideline",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.763957"
    },
    {
      "id": "arxiv-2602.16655v1",
      "title": "Amplification of bosonic interactions through squeezing in the presence of decoherence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16655v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider the amplification of bosonic interactions through parametric control that implements squeezing along orthogonal quadratures. We show that bosonic interactions described by certain classes of quadratic and quartic Hamiltonians can be enhanced in this way while simultaneously overcoming noise and decoherence. In general, the amplification method enhances both desired and undesired interactions present in the system. Depending on the case, however, detrimental processes can be less amplified than the desired couplings. We leverage this observation to improve the fidelity for preparing Bell-type entangled states between two bosonic modes in the presence of noise and losses. We also investigate noise models for which the protocol either fails or partially achieves a loss-tolerant state preparation speedup. Our work facilitates faster preparation of complex quantum states and implementation of entangling gates in the presence of decoherence mechanisms.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16655v1",
        "authors": [
          "Ankit Tiwari",
          "Cecilia Cormick",
          "Christian Arenz"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.764324"
    },
    {
      "id": "arxiv-2602.16623v1",
      "title": "Beyond the Classical Ceiling: Multi-Layer Fully-Connected Variational Quantum Circuits",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16623v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Standard Variational Quantum Circuits (VQCs) struggle to scale to high-dimensional data due to the ``curse of dimensionality,'' which manifests as exponential simulation costs ($\\mathcal{O}(2^d)$) and untrainable Barren Plateaus. Existing solutions often bypass this by relying on classical neural networks for feature compression, obscuring the true quantum capability. In this work, we propose the \\textbf{Multi-Layer Fully-Connected VQC (FC-VQC)}, a modular architecture that performs \\textbf{end-to-end quantum learning} without trainable classical encoders. By restricting local Hilbert space dimensions while enabling global feature interaction via structured block mixing, our framework achieves \\textbf{linear scalability $\\mathcal{O}(d)$}. We empirically validate this approach on standard benchmarks and a high-dimensional industrial task: \\textbf{300-asset Option Portfolio Pricing}. In this regime, the FC-VQC breaks the ``Classical Ceiling,'' outperforming state-of-the-art Gradient Boosting baselines (XGBoost/CatBoost) while exhibiting \\textbf{$\\approx 17\\times$ greater parameter efficiency} than Deep Neural Networks. These results provide concrete evidence that pure, modular quantum architectures can effectively learn industrial-scale feature spaces that are intractable for monolithic ansatzes.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16623v1",
        "authors": [
          "Howard Su",
          "Chen-Yu Liu",
          "Samuel Yen-Chi Chen",
          "Kuan-Cheng Chen",
          "Huan-Hsin Tseng"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Connected Variational Quantum Circuits",
        "Standard Variational Quantum Circuits",
        "Option Portfolio Pricing",
        "Deep Neural Networks",
        "Gradient Boosting",
        "Classical Ceiling",
        "Barren Plateaus",
        "Neural Network",
        "Layer Fully",
        "Framework",
        "Standard",
        "BERT",
        "VQC",
        "Act",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.764759"
    },
    {
      "id": "arxiv-2602.16613v1",
      "title": "Bichromatic Quantum Teleportation of Weak Coherent Polarization States on a Metropolitan Fiber",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16613v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "As quantum technologies mature, telecommunication operators have a clear opportunity to unlock and scale new services by providing the connectivity layer that links quantum computers, sensors, clocks, and other quantum devices. Realizing this opportunity requires demonstrating quantum networking protocols, including quantum teleportation, under real-world conditions on existing telecom infrastructure. In this work, we demonstrate quantum teleportation over Deutsche Telekom's metropolitan fiber testbed in Berlin using commercial components deployed at the telecom datacenter. A local Bell-state measurement between 795 nm photons from a weak coherent source and from a bichromatic warm-atom entangled photon source enables conditional state transfer onto an O-band photon, which is transmitted through a 30-km field-deployed fiber loop under real-world environmental conditions. The teleported state is reconstructed after propagation via state tomography, achieving an average teleportation fidelity of 90\\% on the deployed link. System performance is evaluated in both the absence and the presence of co-propagating C-band classical traffic within the same fiber, demonstrating compatibility with wavelength-division multiplexed telecom infrastructure carrying live data channels.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16613v1",
        "authors": [
          "Zofia A. Borowska",
          "Shane Andrewski",
          "Giorgio De Pascalis",
          "Olivia Brasher",
          "Mael Flament"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Weak Coherent Polarization States",
        "Bichromatic Quantum Teleportation",
        "Metropolitan Fiber As",
        "Deutsche Telekom",
        "Protocol",
        "NSF",
        "MIT",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.765203"
    },
    {
      "id": "arxiv-2602.16513v1",
      "title": "Port-based teleportation under pure-dephasing decoherence",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16513v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study deterministic port based teleportation in the presence of noise affecting both the entangled resource state and the measurement process. We focus on a physically motivated model in which each Bell pair constituting the resource interacts with an identical local environment, corresponding to independently distributed entangled links. Two noisy scenarios are analyzed: one with decoherence acting solely on the resource state and ideal measurements, and another with noisy, noise adapted measurements optimised for the given noise model. In the first case, we derive an analytical lower bound and later a closed-form expression for the entanglement fidelity of the teleportation channel and analyze its asymptotic behaviour. In the second, we combine semi analytical and numerical methods. Surprisingly, we find that noise-adapted measurements perform worse than the noiseless ones. To connect the abstract noise description with microscopic physics, we embed the protocol in a spin boson model and investigate the influence of bath memory and temperature on the teleportation fidelity, highlighting qualitative differences between different environments.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16513v1",
        "authors": [
          "Rajendra S. Bhati",
          "Michał Studziński",
          "Jarosław K. Korbicz"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "NIST",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.766057"
    },
    {
      "id": "arxiv-2602.16483v1",
      "title": "Nonequilibrium Casimir-Polder Force: Motion-induced Thermal-like Effect",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16483v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Casimir-Polder force is analyzed when an atom is moving at a constant velocity relative to a collection of translationally invariant macroscopic bodies with generic shapes and compositions. The interaction is described within an approach that accurately treats the atom-field coupling and accounts for the backaction from the environment onto the moving particle. Previously overlooked aspects are uncovered and linked to the nonequilibrium and nonconservative nature of the interaction. Specifically, we examine a behavior that can be understood by characterizing the underlying physical processes in terms of a motional-induced effective temperature. This phenomenon shares similarities with the Fulling-Davies-Unruh effect, opening new perspectives for the understanding of nonequilibrium physics at work in the system.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16483v1",
        "authors": [
          "D. Reiche",
          "B. Beverungen",
          "K. Busch",
          "F. Intravaia"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonequilibrium Casimir",
        "Polder Force",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.766357"
    },
    {
      "id": "arxiv-2602.16464v1",
      "title": "Quantitative study of Silicon Waveguides for the Generation of Quantum Correlated Photon Pairs Bridging Mid-Infrared and Telecom Bands",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16464v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Sources of quantum correlated photons pairs bridging the 3um-4um Mid-infrared (MIR) band and Telecom/Near-Infrared/Visible band are of high importance for quantum technologies. Spontaneous Parametric Down Conversion is generally used for realizing such sources, but requires costly implementation platforms with reduced versatility. Here, we explore the potentialities of Spontaneous Four-Wave Mixing (SFWM) in all-solid Silicon On Insulator (SOI) waveguides thanks to an experimentally validated model and propose designs ensuring the production of correlated photon pairs bridging the 3um-4um Mid-infrared band and Telecom C-band. Choosing a pump with a wavelength in the range 2100nm-2210nm and a pulse duration of 5ps, we quantitatively performed simulations targeting a probability of photon pair generation per pulse of 0.05, and we found realistic conditions of utilization (2cm-length straight waveguides, intra-modal Four Wave Mixing with the fundamental TE00 mode) with a pump peak power in between 9.2mW and 32mW. A first design (wCOM) reaches a signal wavelength as high as 3.905um, which is situated in an atmospheric transparency window, while maintaining an idler in the Telecom C-band, making it of high interest for atmospheric Quantum Key Distribution. Two other designs wCH4 and wNO2 aim precise CH4 and NO2 gas sensing with a signal wavelength of 3265nm and 3461nm respectively. In terms of signal/idler wavelength separation, wCOM attains the value of 2364nm which is well above the current record of ~1125nm obtained in quantum regime with SFWM in all-solid SOI waveguides.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16464v1",
        "authors": [
          "Abhishek Kumar Pandey",
          "Deepak Jain",
          "Catherine Baskiotis"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spontaneous Parametric Down Conversion",
        "Quantum Correlated Photon Pairs",
        "Quantum Key Distribution",
        "Telecom Bands Sources",
        "Silicon On Insulator",
        "Silicon Waveguides",
        "Four Wave Mixing",
        "Spontaneous Four",
        "Bridging Mid",
        "Wave Mixing",
        "Wind",
        "SFWM",
        "EPA",
        "MIR",
        "SOI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.766881"
    },
    {
      "id": "arxiv-2602.16454v1",
      "title": "Edge states and quantum optical high-harmonic generation from topological insulators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16454v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The strong-field process of high-harmonic generation (HHG) has, in recent years, been treated from a quantum optical perspective in the emerging research area of strong-field quantum optics. These investigations show that HHG radiation is, in general, in a nonclassical state of light. However, the quantum optical treatment of HHG from topological nontrivial materials is missing. Here, we aim to address this gap in current knowledge and consider the quantum optical HHG response from the Su-Schrieffer-Heeger model, a finite chain of atoms with both a topologically trivial and nontrivial insulating phase, the latter supporting edge states. We find that HHG from both topological phases is squeezed at the band-gap frequency. Interestingly, while the harmonic spectrum discriminates the two topological phases of the system, the degree of squeezing only discriminates the phases for smaller chain lengths. We attribute this difference to a relative increase in overlap between bulk and edge states in the topological nontrivial phase for smaller systems. Our findings reveal how the strength of dipole couplings governs the nonclassical HHG response and define new research questions on topologically protected generation of quantum light in strong-field physics.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16454v1",
        "authors": [
          "Christian Saugbjerg Lange",
          "Lars Bojer Madsen"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "HHG",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.767291"
    },
    {
      "id": "arxiv-2602.16426v1",
      "title": "Nonlocal prediction of quantum measurement outcomes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16426v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We define nonlocal predictability as how well one observer can predict another's measurement outcomes without classical communication, given full knowledge of the shared quantum state and measurement settings. The local bound on nonlocal predictability is defined as the maximum probability with which one observer can correctly predict the other's measurement outcome prior to measurement. We show that product states always meet this bound, while all pure entangled states and some classically correlated states can exceed it. This demonstrates a nonlocal phenomenon since the predictability of measurement outcomes increases after the measurement. Perfect nonlocal predictability for arbitrary projective measurements occurs only for maximally entangled states among all pure states, underscoring their special role. Comparing pure entangled states with their dephased versions, we find that dephasing on one subsystem can enhance nonlocal predictability for a broad class of states and measurements - a counterintuitive, noise-induced advantage that vanishes for maximally entangled states under any projective measurement.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16426v1",
        "authors": [
          "Chirag Srivastava",
          "Aparajita Bhattacharyya",
          "Ujjwal Sen"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.767653"
    },
    {
      "id": "arxiv-2602.16413v1",
      "title": "Measurement Induced Subradiance",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16413v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Preparing subradiant steady states of collectively emitting quantum two-level emitters (TLEs) is hindered by their dark, weakly interacting nature. Existing approaches rely on patterned driving, local control, or structured environments. We propose a platform-independent protocol based on projective measurements on a single TLE. For permutation-symmetric ensembles, a single measurement yields appreciable occupation of single-excitation subradiant steady states. For generic arrays, repeated measurements on one emitter drive the unmeasured TLEs into a nearly pure state with large overlap with the subradiant Dicke subspace.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16413v1",
        "authors": [
          "Ipsita Bar",
          "Aditi Thakar",
          "B. Prasanna Venkatesh"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Measurement Induced Subradiance Preparing",
        "Protocol",
        "EPA",
        "TLE",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.767881"
    },
    {
      "id": "arxiv-2602.16391v1",
      "title": "Enhancing delocalization and entanglement in asymmetric discrete-time quantum walks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16391v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this paper, we investigate the enhancement of delocalization and coin-position entanglement in asymmetric discrete-time quantum walks (DTQWs). The asymmetry results from asymmetric coin operations, asymmetric initial states, and asymmetric polarization-dependent losses. By varying these asymmetry factors, the inverse participation ratio and entanglement entropy of the walker are numerically calculated for different coin and loss parameters, both for symmetric and asymmetric initial states. We then experimentally implement a 16-step asymmetric DTQW using a time-multiplexing fiber loop structure. By choosing an asymmetric initial state, both coin-position entanglement and delocalization are simultaneously enhanced under specific coin parameters. Moreover, we observe that with finite asymmetric polarization-dependent loss, the photon probability on the left side decreases significantly, while that on the right side increases and becomes more localized. Interestingly, under specific coin parameters, the entanglement and delocalization exhibit improved robustness against polarization-dependent loss. These results demonstrate that the DTQWs constitute an ideal platform for investigating photonic delocalization and hybrid entanglement.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16391v1",
        "authors": [
          "Hao Zhao",
          "Qiyan He",
          "Fengzhi Yang",
          "Cui Kong",
          "Huiyun Cao"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "DTQW",
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.768295"
    },
    {
      "id": "arxiv-2602.16382v1",
      "title": "Solving the Mysteries of Quantum Mechanics: Why Nature Abhors a Continuum",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16382v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Feynman famously asserted that interference is the only real mystery in quantum mechanics (QM). It is concluded that the reason for this mystery, and thereby the related mysteries of complementarity, non-commutativity of observables, the uncertainty principle and violation of Bell's equality, is that the axioms of QM depend vitally on the continuum nature of Hilbert Space, deemed unphysical. We develop a theory of quantum physics - Rational Quantum Mechanics (RaQM) - in which Hilbert Space is gravitationally discretised. The key to solving the mysteries of QM in RaQM is a number-theoretic property of the cosine function, concealed in QM when angles range over the continuum. This number-theoretic property describes mathematically the utter indivisibility of the quantum world and implies that the laws of physics are profoundly holistic. We contrast holism with nonlocality. In theories which embrace the continuum, the violation of Bell's inequality requires the laws of physics to be either nonlocal or not realistic; both incomprehensible concepts. By contrast, holism, as embodied in Mach's Principle or in the fractal geometry of a chaotic attractor, is neither incomprehensible nor unphysical. As part of this, we solve the deepest mystery of all; why nature makes use of complex numbers.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16382v1",
        "authors": [
          "Tim Palmer"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Rational Quantum Mechanics",
        "Why Nature Abhors",
        "Quantum Mechanics",
        "Continuum Feynman",
        "Hilbert Space",
        "BERT",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.768714"
    },
    {
      "id": "arxiv-2602.16368v1",
      "title": "A Formal Theory for Finite-Dimensional Possibilistic Quantum Mechanics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16368v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we present a logical formalism for reasoning about quantum systems in finite dimension. Contrary to the usual approach in quantum logic, our formalism is based classical first-order logic, which allows us to use the tools of model theory in our study. In particular, we show that our formal theory is complete, meaning that it entirely determines the behaviour of quantum systems. Moreover, we provide a characterization of the models of our formal theory, thus providing new insights in the study of hidden variable models of quantum theory.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16368v1",
        "authors": [
          "Olivier Brunet"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Possibilistic Quantum Mechanics",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.769014"
    },
    {
      "id": "arxiv-2602.16314v1",
      "title": "A resolution of the Ito-Stratonovich debate in quantum stochastic processes",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16314v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Quantum stochastic processes are widely used in describing open quantum systems and in the context of quantum foundations. Physically relevant quantum stochastic processes driven by multiplicative colored noise are generically non-Markovian and analytically intractable. Further, their Markovian limits are generically inequivalent when using either the Ito or Stratonovich conventions for the same quantum stochastic processes. We introduce a quantum noise homogenization scheme that temporally coarse-grains non-Markovian, colored-noise driven quantum stochastic processes and connects them to their effective white-noise (Markovian) limits. Our approach uses a novel phase-space augmentation that maps the non-Markovian dynamics into a higher dimensional Markovian system and then applies a controlled perturbative coarse-graining scheme in the characteristic time scales of the noise. This allows an explicit analytical algorithm to derive effective Markovian generators with renormalized coefficients and enables imposing various physical constraints on them. We thus resolve the Ito-Stratonovich ambiguity for multiplicative colored noise driven quantum stochastic processes, wherein we show that their consistent Markovian limit corresponds to the Stratonovich convention with renormalized coefficients as well as Ito correction terms. By assuming their Markovian limit unravels completely positive, trace-preserving maps, we further characterize a physically relevant family of non-Markovian quantum stochastic processes driven by multiplicative colored noise.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16314v1",
        "authors": [
          "Aritro Mukherjee"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.769572"
    },
    {
      "id": "arxiv-2602.16286v1",
      "title": "What Kind of World Supports Darwinian Evolution? Quantum Foundational Options",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16286v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Darwinian evolution requires (i) heritable records, (ii) repeatable copying with variation, and (iii) routine irreversibility. Categorical quantum mechanics (CQM) makes precise why ``copy'' and ``delete'' are not generic quantum operations: they exist only for a realized \\emph{classical data} sector (a preferred basis/observable; a commutative structure). Decoherence explains how a pointer basis can be selected dynamically, but it does not by itself select a unique outcome. This motivates a neutral presentation of the main ontological options (unique-history, decohered multiplicity, agent-relative facticity, and a stochastic foundation with variable diffusion). We also note the relevance of the ``agency constraint'' argued by Adlam-McQueen-Waegell: in a strictly coherent, basis-unselected ``purely quantum'' regime, minimal agency fails due to no-cloning and linearity, which sharpens the role of classical resources for record-based processes. Extended Wigner's Friend scenarios then serve as a stress test, since they treat ``friends'' simultaneously as coherent quantum systems and as agents possessing stable records. Finally, a stochastic-mechanics foundation (with variable diffusion) offers a continuous bridge between quantum and classical regimes, and suggests a principled way to implement measurement update as conditioning plus a time-symmetric minimal-change rule.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16286v1",
        "authors": [
          "Partha Ghose"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Foundational Options Darwinian",
        "World Supports Darwinian Evolution",
        "Extended Wigner",
        "What Kind",
        "Fusion",
        "CQM",
        "Act",
        "DOE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.769943"
    },
    {
      "id": "arxiv-2602.16280v1",
      "title": "Tomographically-nonlocal entanglement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16280v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Entanglement is a central and subtle feature of quantum theory, whose structure and operational behavior can change dramatically when additional physical constraints, such as symmetries or superselection rules, are imposed. Such constraints can give rise to striking and counter-intuitive phenomena, including local broadcasting of entangled states and failures of entanglement monogamy. These effects naturally arise in tomographically nonlocal theories (like real quantum theory, twirled worlds, or fermionic quantum theory), where composite systems possess holistic degrees of freedom that are inaccessible to local measurements. In this work, we study entanglement in such theories within the framework of generalized probabilistic theories. We show that the failure of tomographic locality leads to two qualitatively distinct forms of entanglement, which we term $\\textit{tomographically-local}$ entanglement and $\\textit{tomographically-nonlocal}$ entanglement. We analyze the operational consequences of this distinction, proving that tomographically-nonlocal entanglement is useless for Bell nonlocality, steering, and teleportation, but sufficient for dense coding and perfectly secure data hiding. This framework clarifies the origin of several previously puzzling features of entanglement that arise when tomographic locality fails, as can happen even in quantum theory when one considers fermions or fundamental superselection rules.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16280v1",
        "authors": [
          "Roberto D. Baldijão",
          "Marco Erba",
          "David Schmid",
          "John H. Selby",
          "Ana Belén Sainz"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "WHO",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.770332"
    },
    {
      "id": "arxiv-2602.16266v1",
      "title": "Structured Unitary Tensor Network Representations for Circuit-Efficient Quantum Data Encoding",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16266v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Encoding classical data into quantum states is a central bottleneck in quantum machine learning: many widely used encodings are circuit-inefficient, requiring deep circuits and substantial quantum resources, which limits scalability on quantum hardware. In this work, we propose TNQE, a circuit-efficient quantum data encoding framework built on structured unitary tensor network (TN) representations. TNQE first represents each classical input via a TN decomposition and then compiles the resulting tensor cores into an encoding circuit through two complementary core-to-circuit strategies. To make this compilation trainable while respecting the unitary nature of quantum operations, we introduce a unitary-aware constraint that parameterizes TN cores as learnable block unitaries, enabling them to be directly optimized and directly encoded as quantum operators. The proposed TNQE framework enables explicit control over circuit depth and qubit resources, allowing the construction of shallow, resource-efficient circuits. Across a range of benchmarks, TNQE achieves encoding circuits as shallow as $0.04\\times$ the depth of amplitude encoding, while naturally scaling to high-resolution images ($256 \\times 256$) and demonstrating practical feasibility on real quantum hardware.",
        "keywords": [
          "quant-ph",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16266v1",
        "authors": [
          "Guang Lin",
          "Toshihisa Tanaka",
          "Qibin Zhao"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structured Unitary Tensor Network",
        "Efficient Quantum Data Encoding",
        "Machine Learning",
        "Framework",
        "TNQE",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.770689"
    },
    {
      "id": "arxiv-2602.16215v1",
      "title": "Squeezed superradiant lasing of a quantum many-body emitter",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16215v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In conventional lasers, the emitters are typically incoherent, radiating photons independently; in superradiant lasers, many coherent emitters radiate photons collectively, but they essentially do not interact with each other. Here, we present the concept of quantum many-body lasers, in which the emitters interact coherently and radiate collectively. In this proof-of-concept study, we consider a cavity coupled to many pumped spin-1/2 emitters with all-to-all interaction. We find that the squeezing induced by the coherent many-body interaction can be transferred from the spins to photons through superradiant lasing. This work illustrates the concept of using a pumped quantum many-body system to generate bright quantum light with quantum correlations beyond conventional optical coherence, which can facilitate quantum technologies and the study of nonlinear optics in the quantum realm.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16215v1",
        "authors": [
          "Da-Wu Xiao",
          "Chong Chen",
          "Ren-Bao Liu"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "NSF"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.771010"
    },
    {
      "id": "arxiv-2602.16141v1",
      "title": "Reductions of QAOA Induced by Classical Symmetries: Theoretical Insights and Practical Implications",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16141v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The performance of the Quantum Approximate Optimization Algorithm (QAOA) is closely tied to the structure of the dynamical Lie algebra (DLA) generated by its Hamiltonians, which determines both its expressivity and trainability. In this work, we show that classical symmetries can be systematically exploited as a design principle for QAOA. Focusing on the MaxCut problem with global bit-flip symmetry, we analyze reduced QAOA instances obtained by fixing a single variable and study how this choice affects the associated DLAs. We show that the structure of the DLAs can change dramatically depending on which variable is held fixed. In particular, we construct explicit examples where the dimension collapses from exponential to quadratic, uncovering phenomena that do not appear in the original formulation. Numerical experiments on asymmetric graphs indicate that such reductions often produce DLAs of much smaller dimension, suggesting improved trainability. We also prove that any graph can be embedded into a slightly larger one (requiring only quadratic overhead) such that the standard reduced DLA coincides with the free reduced DLA, in most cases implying exponential dimension and irreducibility on the Hilbert space for reduced QAOA instances. These results establish symmetry-aware reduction as a principled tool for designing expressive and potentially trainable QAOA circuits.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16141v1",
        "authors": [
          "Boris Tsvelikhovskiy",
          "Bao Bach",
          "Jose Falla",
          "Ilya Safro"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantum Approximate Optimization Algorithm",
        "Classical Symmetries",
        "Standard",
        "BERT",
        "QAOA",
        "Act",
        "DLA",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.771448"
    },
    {
      "id": "arxiv-2602.16097v1",
      "title": "Local and Multi-Scale Strategies to Mitigate Exponential Concentration in Quantum Kernels",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16097v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Fidelity-based quantum kernels provide a direct interface between quantum feature maps and classical kernel methods, but they can exhibit exponential concentration: with increasing system size or circuit expressivity, the Gram matrix approaches the identity and suppresses informative similarity structure. We present an empirical study of two mitigation strategies implemented in Qiskit: (i) local (patch-wise) kernels that aggregate subsystem similarities, and (ii) multi-scale kernels that mix local and global similarity across patch granularities. We benchmark baseline, local, and multi-scale kernels under matched preprocessing, splits, and SVM protocols on several tabular datasets, sweeping the feature dimension $d\\in\\{4,6,\\dots,20\\}$. We report concentration diagnostics based on off-diagonal kernel statistics, spectral richness via effective rank, and centered alignment with labels. Across datasets, local and multi-scale constructions consistently mitigate concentration and yield richer kernel spectra relative to the global fidelity baseline, while the impact on classification accuracy depends on the dataset and dimension.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16097v1",
        "authors": [
          "Claudia Zendejas-Morales",
          "Debashis Saikia",
          "Utkarsh Singh"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Mitigate Exponential Concentration",
        "Quantum Kernels Fidelity",
        "Scale Strategies",
        "Protocol",
        "Act",
        "MIT",
        "SVM",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.771773"
    },
    {
      "id": "arxiv-2602.16094v1",
      "title": "Lie-Algebraic Analysis of Generators: Approximation-Error Bounds and Barren-Plateau Heuristics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16094v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Lie algebras provide a useful framework for theoretical analysis in quantum machine learning, particularly in hybrid quantum-classical learning. From the viewpoint of function approximation, expectation values of parameterized quantum circuits can be viewed as trigonometric polynomials whose accessible Fourier modes are determined by the spectra of the generators. In this study, we describe: (1) a minimax lower bound on the $ L^{2} $-approximation error over a Sobolev ball when the circuit's effective frequency set is contained in a radius-$K$ ball, which yields a scaling law of the form $ Ω(K^{\\frac{d}{2} - r}) $ for $ r > \\frac{d}{2} $ (assuming the target function belongs to the Sobolev space $ W_2^{r}(\\mathbb{T}^{d}) $), and we also derive a Jackson-type upper bound on the approximation error of quantum circuits under Sobolev regularity of the target function, expressed in terms of an effective bandwidth determined by generator spectral gaps; (2) a generator-selection rule motivated by enlarging the effective frequency set via non-commuting generators; and (3) a simple heuristic metric based on the trace component of generators, aimed at characterizing training behaviors related to barren plateaus. Simulation experiments on toy problems illustrate the practical implications of the frequency-spectrum perspective and the proposed heuristics.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16094v1",
        "authors": [
          "Hiroshi Ohno"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Plateau Heuristics Lie",
        "Algebraic Analysis",
        "Machine Learning",
        "Error Bounds",
        "Framework",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.772640"
    },
    {
      "id": "arxiv-2602.16067v1",
      "title": "Contractivity of time-dependent driven-dissipative systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16067v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In a number of physically relevant contexts, a quantum system interacting with a decohering environment is simultaneously subjected to time-dependent controls and its dynamics is thus described by a time-dependent Lindblad master equation. Of particular interest in such systems is to understand the circumstances in which, despite the ability to apply time-dependent controls, they lose information about their initial state exponentially with time i.e., their dynamics are exponentially contractive. While there exists an extensive framework to study contractivity for time-independent Lindbladians, their time-dependent counterparts are far less well understood. In this paper, we study the contractivity of Lindbladians, which have a fixed dissipator (describing the interaction with an environment), but with a time-dependent driving Hamiltonian. We establish exponential contractivity in the limit of sufficiently small or sufficiently slow drives together with explicit examples showing that, even when the fixed dissipator is exponentially contractive by itself, a sufficiently large or a sufficiently fast Hamiltonian can result in non-contractive dynamics. Furthermore, we provide a number of sufficient conditions on the fixed dissipator that imply exponential contractivity independently of the Hamiltonian. These sufficient conditions allow us to completely characterize Hamiltonian-independent contractivity for unital dissipators and for two-level systems.",
        "keywords": [
          "quant-ph",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16067v1",
        "authors": [
          "Lasse H. Wolff",
          "Daniel Malz",
          "Rahul Trivedi"
        ],
        "arxiv_categories": [
          "quant-ph",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "MIT",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.773028"
    },
    {
      "id": "arxiv-2602.16045v1",
      "title": "Strong-to-Weak Symmetry Breaking in Open Quantum Systems: From Discrete Particles to Continuum Hydrodynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16045v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We explore the onset of spontaneous strong-to-weak symmetry breaking (SW-SSB) under U(1)-symmetric (i.e., charge-conserving) open-system dynamics. We define this phenomenon for quantum states and classical probability distributions, and explore it in three complementary models, one of which exhibits nontrivial quantum coherence at short times. Our main conclusions are as follows. In one dimension, the strong symmetry is not spontaneously broken at any finite time; however, correlators probing strong-to-weak symmetry breaking develop order on length scales that grow linearly in time, parametrically faster than charge diffusion. We provide numerical evidence for this scaling in multiple distinct probes of SW-SSB, and derive it from a field-theory analysis. Moreover, we relate this scaling to the problem of inferring the charge inside a subregion by measuring its surroundings, and construct explicit decoding protocols that illustrate its origin. In two dimensions, field theory and numerical simulations support a finite-time Berezinskii-Kosterlitz-Thouless-like SW-SSB transition. Within continuum hydrodynamics, by contrast, SW-SSB happens at infinitesimal time in two or more dimensions. The SW-SSB transition time can thus be interpreted as marking the emergence of a continuum hydrodynamic description, or (more precisely) the timescale beyond which non-hydrodynamic information such as discrete particle worldlines can no longer be inferred. We support this picture by analyzing a model in which we exploit SW-SSB to derive a classical stochastic hydrodynamic description from the underlying quantum dynamics.",
        "keywords": [
          "quant-ph",
          "cond-mat.stat-mech"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16045v1",
        "authors": [
          "Jacob Hauser",
          "Kaixiang Su",
          "Hyunsoo Ha",
          "Jerome Lloyd",
          "Thomas G. Kiely"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.stat-mech"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Continuum Hydrodynamics We",
        "From Discrete Particles",
        "Weak Symmetry Breaking",
        "Open Quantum Systems",
        "Protocol",
        "Fusion",
        "SSB",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.773479"
    },
    {
      "id": "arxiv-2602.16032v1",
      "title": "Multi-emitter oscillating bound states in Waveguide QED",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16032v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Waveguide quantum electrodynamics platforms have emerged as promising candidates for exploring and implementing non-Markovian quantum phenomena. In this work, we investigate the formation and dynamics of superpositions of bound states in a cavity array waveguide coupled to two spatially separated quantum emitters. By tuning the system parameters, we show that spontaneous emission can drive the system into non-local equilibrium states in which both photonic and emitter populations exhibit persistent oscillations. These states arise from the coexistence of bound states embedded in the energy continuum and bound states outside it, leading to hybrid oscillatory modes. We analytically derive the conditions required for the emergence of these states, numerically simulate their formation through spontaneous emission, and predict their long-time behaviour. Our results demonstrate that such bound-state superpositions enable the generation of emitter-emitter interaction through free evolution, while supporting oscillatory breathing modes of the photon density between the emitters.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16032v1",
        "authors": [
          "Sergi Terradas-Briansó",
          "Carlos A. González-Gutiérrez",
          "Iván Huarte",
          "David Zueco",
          "Luis Martin-Moreno"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "QED",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.773788"
    },
    {
      "id": "arxiv-2602.16025v1",
      "title": "Device for MHz-rate rastering of arbitrary 2D optical potentials",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16025v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Current architectures for neutral-atom arrays utilize devices such as acousto-optic deflectors (AODs) and spatial light modulators (SLMs) to multiplex a single classical control line into N qubit control lines. Dynamic control is speed-limited by the response time of AODs, and geometrically constrained to respect a product structure, limiting motion to row-by-row or column-by-column moves. We propose an optical rastering device that can produce any 2D pattern, not limited to grids, at 1 MHz refresh rates. We demonstrate a design with a resolution of 40 x 40 that can be further scaled up to 100 x 100 to match existing and future neutral atom devices. The ability to simultaneously transport atomic qubits in arbitrary directions will enhance qubit connectivity, enable more efficient circuits, and may have broader applications ranging from LiDAR to fluorescence microscopy.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16025v1",
        "authors": [
          "Edita Bytyqi",
          "Josiah Sinclair",
          "Joshua Ramette",
          "Vladan Vuletić"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.774050"
    },
    {
      "id": "arxiv-2602.16014v1",
      "title": "Benchmarking the Lights Out Problem on Real Quantum Hardware",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16014v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We implement the Lights Out problem on a 2D grid and on Mobius ladder graphs and evaluate the performance of Grover's search on real quantum hardware. We use two instances using 9 and 16 qubits, and implement them on publicly available quantum hardware by IBM and IQM. Our experiments show improvements in IBM hardware between the Heron r1 and Heron r2 generations, highlighting progress in IBM hardware during the 2023-2024 period. The Lights Out circuits produced output distributions close to uniform on IQM devices. To diagnose device limitations, we additionally ran a small Grover SAT baseline, finding that IQM Garnet performs more reliably than other tested IQM devices. We also observed that QPUs of the same manufacturing revision can differ significantly in performance (a newer device is not guaranteed to be better), and that calibration has a significant impact on the performance of quantum devices, so the choice of device strongly depends on calibration quality.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16014v1",
        "authors": [
          "Maksims Dimitrijevs",
          "Maria Palchiha",
          "Abuzer Yakaryilmaz"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Real Quantum Hardware We",
        "Lights Out Problem",
        "Lights Out",
        "IQM",
        "IBM",
        "Act",
        "SAT",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.774387"
    },
    {
      "id": "arxiv-2602.15948v1",
      "title": "Enhanced Superconducting Nanowire Single Photon Detector Performances using Silicon Capping",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15948v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Niobium Titanium nitride (NbTiN) based superconducting nanowire single photon detectors (SNSPDs) are known for their high performance across a wide spectral range, from the X-ray to the mid-infrared. Nonetheless, fabrication challenges and performance degradation attributable to surface oxidation and lack of uniformity in films thinner than 5 nm remain a significant barrier for achieving high-quality detectors. In this work, we study the influence of a Silicon capping layer on film properties and on the performance of SNSPDs. A Silicon capping layer effectively suppresses oxidation and increases the superconducting transition temperature. This enables superconductivity in films as thin as 3 nm at 3 K, increases critical current in patterned nanowires and significantly extends the saturation plateau from the visible to the near infrared (up to 2050 nm): These detectors maintain sub-50 ps timing jitter, even for nanowires as wide as 250 nm and with detection areas of 20x20μm2. Our results establish that thinner films protected by a capping layer allow for the fabrication of wider wires, decreasing nanofabrication challenges and extending the operating temperature range for efficient single photon detection.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15948v1",
        "authors": [
          "C. Klein",
          "S. Cohen",
          "T. Descamps",
          "A. Iovan",
          "P. Zolotov"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enhanced Superconducting Nanowire Single",
        "Silicon Capping Niobium Titanium",
        "Photon Detector Performances",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.775312"
    },
    {
      "id": "arxiv-2602.15942v1",
      "title": "Limits of Clifford Disentangling in Tensor Network States",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15942v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Tensor network methods leverage the limited entanglement of quantum states to efficiently simulate many-body systems. Alternatively, Clifford circuits provide a framework for handling highly entangled stabilizer states, which have low magic and are thus also classically tractable. Clifford tensor networks combine the benefits of both approaches, exploiting Clifford circuits to reduce the classical complexity of the tensor network description of states, with promising effects on simulation approaches. We study the disentangling power of Clifford transformations acting on tensor networks, with a particular emphasis on entanglement cooling strategies. We identify regimes where exact or heuristic Clifford disentanglers are effective, explain the link between the two approaches, and characterize their breakdown as non-Clifford resources accumulate. Additionally, we prove that, beyond stabilizer settings, no Clifford operation can universally disentangle even a single qubit from an arbitrary non-Clifford rotation. Our results clarify both the capabilities and fundamental limitations of Clifford-based simulation methods.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15942v1",
        "authors": [
          "Sergi Masot-Llima",
          "Piotr Sierant",
          "Paolo Stornati",
          "Artur Garcia-Saez"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tensor Network States Tensor",
        "Clifford Disentangling",
        "Framework",
        "NSF",
        "Act",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.775597"
    },
    {
      "id": "arxiv-2602.15931v1",
      "title": "Entanglement-assisted Hamiltonian dynamics learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15931v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Approximating the dynamics given by a complex many-body Hamiltonian with a simpler effective model lies at the interface of quantum Hamiltonian learning and quantum simulation. In this context, quantum generative adversarial networks (QGANs) have been shown to outperform standard Trotter-based approximations. However, their performance is often hindered by training plateaus and local minima that become increasingly severe with system size. To overcome these limitations, we propose an entanglement-assisted learning strategy that couples a single randomly initialized auxiliary qubit to the learning system at an intermediate stage of the training process. The interplay between randomization and entanglement significantly enhances the learning performance of the protocol.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15931v1",
        "authors": [
          "Ayaka Usui",
          "Guillermo Abad-López",
          "Hari krishnan SV",
          "Anna Sanpera",
          "Some Sankar Bhattacharya"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Protocol",
        "MIT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.775857"
    },
    {
      "id": "arxiv-2602.15826v1",
      "title": "QwaveMPS: An efficient open-source Python package for simulating non-Markovian waveguide-QED using matrix product states",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15826v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "QwaveMPS is an open-source Python library for simulating one-dimensional quantum many-body waveguide systems using matrix product states (MPS). It provides a user-friendly interface for constructing, evolving, and analyzing quantum states and operators, facilitating studies in quantum physics and quantum information with waveguide QED systems. This approach enables efficient, scalable simulations by focusing computational resources on the most relevant parts of the quantum system. Thus, one can study a wide range of complex dynamical interactions, including time-delayed feedback effects in the non-Markovian regime and deeply non-linear systems, at a highly reduced computational cost compared to full Hilbert space approaches, making it both practical and convenient to model a variety of open waveguide-QED systems (in Markovian and non-Markovian regimes), treating quantized atoms and quantized photons on an equal footing.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15826v1",
        "authors": [
          "Sofia Arranz Regidor",
          "Matthew Kozma",
          "Stephen Hughes"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "BERT",
        "Act",
        "MPS",
        "QED"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.776110"
    },
    {
      "id": "arxiv-2602.15801v1",
      "title": "Deformed Heisenberg algebra and its Hilbert space representations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15801v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A deformation of Heisenberg algebra induces among other consequences a loss of Hermiticity of some operators that generate this algebra. Therefore, these operators are not Hermitian, nor is the Hamiltonian operator built from them. In the present paper, we propose a position deformation of Heisenberg algebra with both maximal length and minimal momentum uncertainties. By using a pseudo-similarity transformation to the non-Hermitian operators, we prove their Hermiticity with a suitable positive-definite pseudo-metric operator. We then construct Hilbert space representations associated with these pseudo-Hermitian operators. Finally, we study the eigenvalue problem of a free particle in this deformed space and we show that this deformation curved the quantum levels allowing particles to jump from one state to another with low energy transitions.",
        "keywords": [
          "math-ph",
          "hep-th",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15801v1",
        "authors": [
          "Latévi M. Lawson",
          "Ibrahim Nonkané",
          "Kinvi Kangni"
        ],
        "arxiv_categories": [
          "math-ph",
          "hep-th",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deformed Heisenberg",
        "BERT",
        "NSF",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.776339"
    },
    {
      "id": "arxiv-2602.15800v1",
      "title": "Entanglement in the Dicke subspace",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15800v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we provide a complete mathematical theory for the entanglement of mixtures of Dicke states. These quantum states form an important subclass of bosonic states arising in the study of indistinguishable particles. We introduce a tensor-based parametrization where the diagonal entries of these states are encoded as a symmetric tensor, enabling a direct translation between entanglement properties and well-studied convex cones of tensors. Our results bridge multipartite entanglement theory with semialgebraic geometry and the theory of completely positive and copositive tensors. This dictionary maps separability to completely positive tensors, the PPT property to moment tensors, entanglement witnesses to copositive tensors, and decomposable witnesses to sum of squares tensors. Using this framework, we construct explicit PPT entangled states in three or more qutrits. In this class of states, we establish that PPT entanglement exists for all multipartite systems with three qutrits or more, disproving a recent conjecture in [J. Math. Phys. 66, 022203 (2025)]. We also show that, for mixtures of Dicke states, the PPT condition with respect to the most balanced bipartition implies PPT with respect to any other bipartition. We further connect bosonic extendibility of mixtures of Dicke states to the duals of known hierarchies for non-negative polynomials, such as the ones by Reznick and Polya. We thus provide semidefinite programming relaxations for separability and entanglement testing in the Dicke subspace.",
        "keywords": [
          "quant-ph",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15800v1",
        "authors": [
          "Aabhas Gulati",
          "Ion Nechita",
          "Clément Pellegrini"
        ],
        "arxiv_categories": [
          "quant-ph",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "EPA",
        "PPT",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.776703"
    },
    {
      "id": "arxiv-2602.15790v2",
      "title": "Steady state coherence in a qubit is incompatible with a quantum map",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15790v2",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We consider the recent proposal of steady state coherences in a single qubit in the case of a composite system-bath interaction. Based on a field theoretical approach we reanalyse the issue within a Redfield description. We find that the Redfield approach in accordance with a recent proposal yields steady state coherences but also violates the properties of a quantum map yielding negative populations. The issue is resolved by applying the Lindblad equation which is in accordance with a proper quantum map. The Lindblad equation, however, also implies the absence of steady state coherence. We conclude that steady state coherence in a a qubit is incompatible with a quantum map.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15790v2",
        "authors": [
          "Hans C. Fogedby"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.776897"
    },
    {
      "id": "arxiv-2602.15706v1",
      "title": "Meta-Learning for GPU-Accelerated Quantum Many-Body Problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15706v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We explore the industrial and scientific applicability of the VQE-LSTM framework by integrating meta-learning with GPU accelerated quantum simulation using NVIDIA's CUDA-Q (CUDAQ) platform. This work demonstrates how an LSTM-FC meta-initialization module can extend the practical reach of the Variational Quantum Eigensolver (VQE) in both chemistry and physics domains. In the chemical regime, the framework predicts ground-state energies of molecular Hamiltonians derived from PySCF, achieving near FCI accuracy while maintaining favorable O(N^2) scaling with molecular size. In the physical counterpart, we applied the same model to quantized Simple Harmonic Motion systems (SHM), successfully reproducing its ground and excited states through VQE and Variational Quantum Deflation (VQD) methods. Benchmark results on NVIDIA GPUs reveal significant speedups over CPU-based implementations, validating CUDAQ's capability to handle large-scale variational workloads efficiently. Overall, this study establishes VQE-LSTM as a viable and scalable approach for GPU accelerated quantum simulation, bridging quantum chemistry and condensed-matter physics through a unified, meta-learned initialization strategy.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15706v1",
        "authors": [
          "Yun-Hsuan Chen",
          "Jen-Yu Chang",
          "Tsung-Wei Huang",
          "En-Jui Kuo"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Variational Quantum Eigensolver",
        "Variational Quantum Deflation",
        "Accelerated Quantum Many",
        "Simple Harmonic Motion",
        "Body Problems We",
        "Framework",
        "NVIDIA",
        "CUDAQ",
        "LSTM",
        "Meta",
        "CUDA",
        "FCI",
        "SHM",
        "CPU",
        "GPU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.777199"
    },
    {
      "id": "arxiv-2602.15655v1",
      "title": "Generating quantum entanglement from sunlight",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15655v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Energy consumption is becoming a serious bottleneck for integrating quantum technologies within the existing global information infrastructure. In photonic architectures, considerable energy overheads stem from using lasers, whose high coherence was long considered indispensable for quantum state preparation. Here, we demonstrate that natural, incoherent sunlight can successfully produce quantum-entangled states via spontaneous parametric down-conversion. We detect polarization-entangled photon pairs with a concurrence of $0.905\\pm0.053$ and a Bell state fidelity of $0.939\\pm0.027$. Importantly, the system violates Bell's inequality with $S=2.5408\\pm0.2171$, exceeding the classical threshold of 2, while maintaining generation rates comparable to laser-based setups. These findings pave the way for sustainable quantum applications in resource-limited environments like interplanetary missions.",
        "keywords": [
          "quant-ph",
          "physics.optics"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15655v1",
        "authors": [
          "Cheng Li",
          "Jasvinder Brar",
          "Michael Küblböck",
          "Jeremy Upham",
          "Hanieh Fattahi"
        ],
        "arxiv_categories": [
          "quant-ph",
          "physics.optics"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EPA",
        "MIT",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.777433"
    },
    {
      "id": "arxiv-2602.15653v1",
      "title": "High-rate Scalable Entanglement Swapping Between Remote Entanglement Sources on Deployed New York City Fibers",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15653v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Entanglement swapping between photon pairs generated at physically separated nodes over telecommunication fiber infrastructure is an essential step towards the quantum internet, enabling applications such as quantum repeaters, blind quantum computing, distributed quantum computing, and distributed quantum sensing. However, successful networked entanglement swapping relies on generating indistinguishable pairs of photons and preserving them over deployed fibers. This has limited most previous demonstrations to laboratory settings or relied on sophisticated methods to maintain the necessary indistinguishability. Here, we demonstrate a scalable entanglement swapping experiment using naturally indistinguishable entanglement sources based on warm atomic vapor cells. Without sharing lasers or optical frequency references between nodes, nor the need for pulsing the sources, we achieve a swapping rate of nearly 500 pairs/s while maintaining the CHSH parameter above 2. Additionally, we demonstrate the scalability of our method by maintaining the quality of the entanglement swapping on 17.6-km of deployed fibers in NYC, relying on commercially available SPADs at the spoke nodes, SNSPDs at the hub and standard time-synchronization techniques. Our work paves the way for the practical deployment of large-scale hub-and-spoke quantum networks within cities and data centers.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15653v1",
        "authors": [
          "Alexander N. Craddock",
          "Tyler Cowan",
          "Niccolò Bigagli",
          "Suresh Yekasiri",
          "Dylan Robinson"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Scalable Entanglement Swapping Between",
        "Remote Entanglement Sources",
        "Deployed New York City",
        "Fibers Entanglement",
        "Quantum Computing",
        "Laboratory",
        "Standard",
        "CHSH",
        "EPA",
        "NYC",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.777790"
    },
    {
      "id": "arxiv-2602.15630v1",
      "title": "Controlling correlations of a polaritonic Luttinger liquid by engineered cross-Kerr nonlinearity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15630v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study correlation properties of polaritons at zero temperature in a multiconnected Jaynes--Cummings (MCJC) lattice on a superconducting circuit quantum electrodynamics platform with engineered cross-Kerr nonlinearity that mimics attractive nearest-neighbour interaction. A multi-connected Jaynes--Cummings lattice is a one-dimensional lattice constructed from alternating qubits and resonators with different left and right couplings. The nearest-neighbour interaction or cross-Kerr coupling is implemented dispersively through ladder-type qutrits between each nearest neighboring pair of resonator modes. Projecting onto the lower-polaritonic manifold, we derive an extended two-mode (bipartite) Bose--Hubbard-like model featuring on-site and attractive nearest-neighbor interactions. Employing a continuum bosonization approach, we express the Hamiltonian in terms of symmetric ($+$) and antisymmetric ($-$) collective modes. In the regime where the ($-$) sector acquires a finite gap, one can reduce the system to an effective single-component Luttinger liquid model for the $+$ sector. The cross-Kerr term reduces the compressibility of the ($+$) mode, thereby enhancing the corresponding Luttinger parameter $K_{+}$, resulting in the slower algebraic decay of single-particle correlations, $G(x)\\propto|x|^{-1/(4K_{+})}$.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15630v1",
        "authors": [
          "Nabaneet Sharma",
          "Anushree Dey",
          "Bimalendu Deb"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MCJC",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.778117"
    },
    {
      "id": "arxiv-2602.15619v1",
      "title": "Nonlinear Phase Gates Beyond the Lamb-Dicke Regime",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15619v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nonlinear phase gates are essential to achieve the universality of continuous-variable quantum processing and its applications. We present a deterministic protocol for generating nonlinear phase gates in trapped ion systems using simultaneous two-tone sideband drives beyond the Lamb-Dicke regime. Our approach harnesses higher-order interaction terms typically neglected or suppressed to construct nonlinear phase gates. This methodology enables high-fidelity gate engineering with a near three-fold reduction in control pulses compared to state-of-the-art theoretical proposals.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15619v1",
        "authors": [
          "Akram Kasri",
          "Kimin Park",
          "Radim Filip"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlinear Phase Gates Beyond",
        "Dicke Regime Nonlinear",
        "Protocol",
        "NIST",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.778288"
    },
    {
      "id": "arxiv-2602.15615v1",
      "title": "Magnetically assisted spin-resolved electron diffraction: Coherent control of spin population and spatial filtering",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15615v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electron diffraction from nanogratings provides a platform for free-electron interferometry, yet controlled manipulation of electron spin in such geometries remains largely unexplored. In particular, the role of the self-generated magnetic field arising from electron motion and the feasibility of coherent spin control without disrupting diffraction coherence have not been quantitatively investigated. In this article, a self-consistent Maxwell-Pauli framework is developed to study spin-resolved electron diffraction from nanogratings in the presence of magnetic fields. The model incorporates geometric confinement, image-charge interactions, self-generated magnetostatic fields, and externally applied magnetic fields. Numerical simulations show that the intrinsic magnetic self-field produced by the electron probability current is several orders of magnitude too weak to induce measurable spin mixing, demonstrating that nanogratings act as spin-conserving beam splitters under field-free conditions. When a uniform magnetic field is applied upstream of the nanograting, coherent Larmor precession enables controlled spin rotation without modifying the diffraction geometry or degrading coherence. The magnetic field required for a $π$ spin rotation scales inversely with the interaction length and electron de Broglie wavelength $λ_{dB}$. Furthermore, a downstream nonuniform magnetic field applied after the nanograting imparts a spatially varying Zeeman phase, producing opposite transverse momentum shifts for the two spin components. The spin-dependent transverse dynamics is analyzed using Husimi Q-function phase-space maps, which visualize spin-dependent population redistribution and momentum separation. The proposed approach enables tunable spatial separation of spin-resolved free electron beams and establishes an all-magnetic route for coherent spin rotation, control, and interferometry.",
        "keywords": [
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15615v1",
        "authors": [
          "Sushanta Barman",
          "Kuldeep Godara",
          "Sudeep Bhattacharjee"
        ],
        "arxiv_categories": [
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.779333"
    },
    {
      "id": "arxiv-2602.15582v1",
      "title": "Engineering interactions shape in resonantly driven bosonic gas",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15582v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In systems with fast periodic driving, there are special subsets of (resonant) states, which behavior can be described with effective, time-independent Hamiltonian in a rotating reference frame. Here, we show that experimentally feasible system of ultracold bosonic atoms on a ring with rapidly oscillating scattering length can be used to simulate time-independent two-component atomic mixture with exotic, long-range interactions.",
        "keywords": [
          "cond-mat.quant-gas",
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15582v1",
        "authors": [
          "Damian Włodzyński",
          "Krzysztof Sacha"
        ],
        "arxiv_categories": [
          "cond-mat.quant-gas",
          "cond-mat.dis-nn",
          "quant-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:07.779477"
    },
    {
      "id": "arxiv-2602.16566v1",
      "title": "Ground state energy of the dilute Bose-Hubbard gas on Bravais lattices",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16566v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study interacting bosons on a three-dimensional Bravais lattice with positive hopping amplitudes and on-site repulsive interactions. We prove that, in the dilute limit $ρ\\to 0$, the ground state energy density satisfies $$e_0(ρ) = 4πa ρ^2 \\big(1+O(ρ^{1/6})\\big),$$ where $a$ is the lattice scattering length defined through the corresponding two-body problem. This establishes the analogue of the Dyson and Lieb-Yngvason theorems for the Bose-Hubbard gas. Our result shows that the leading-order energy is universal: although the lattice geometry affects the microscopic dispersion relation, it enters the leading order asymptotics only through the scattering length. In particular, it is independent of other features of the underlying Bravais lattice.",
        "keywords": [
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16566v1",
        "authors": [
          "Norbert Mokrzański",
          "Macrin Napiórkowski",
          "Jacek Wojtkiewicz"
        ],
        "arxiv_categories": [
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.856660"
    },
    {
      "id": "arxiv-2602.16303v1",
      "title": "Finite elements for the space approximation of a differential model for salts crystallization",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16303v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This article investigates a space-time differential model related to the degradation of stone artifacts caused by exposure to air and atmospheric agents, which specifically lead to the accumulation of salt crystals in the material. A numerical method based on finite-element space discretization and implicit-explicit time marching is proposed as an extension of a one-dimensional finite-difference framework introduced in the literature. Within the same one-dimensional setting, a sensitivity analysis is performed, based on the techniques developed therein. They are also used as a comparison tool for the finite-element formulation, here introduced for more realistic simulations in higher space dimensions. Considerations about stability will be provided, together with an experimental convergence analysis highlighting the performance of the proposed approach. Numerical results in two and three space dimensions, obtained by an efficient code implementation, will be presented and discussed.",
        "keywords": [
          "math.NA",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16303v1",
        "authors": [
          "Alessandra Aimi",
          "Gabriella Bretti",
          "Giulia Di Credico",
          "Francesco Freddi",
          "Chiara Guardasoni"
        ],
        "arxiv_categories": [
          "math.NA",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.857415"
    },
    {
      "id": "arxiv-2602.16278v1",
      "title": "Gaussian-like fixed point and variational properties of integral discriminants",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16278v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We consider partition functions Z(g) = exp (-g(x))dx where g is a nonnegative polynomial action (a degree-2n form) vanishing only at the origin. Such integrals, known as integral discriminants, appear in statistical mechanics, quantum field theory, and the theory of exponential families. We show that the associated Boltzmann measure d$μ$ = exp(-g(x))dx satisfies a fixed-point property identity relating in a simple manner its degree-2n moments to the coefficients of g. This generalizes familiar identities for the exponential distribution (degree-1) on the positive orthant and the Gaussian measure (degree-2). We further show that g is characterized by three variational principles, including a maximum-entropy principle under scaled moments constraints, extending the Gaussian extremality principle to arbitrary even-degree homogeneous actions. Exploiting these identities in a truncatedmoment numerical scheme (known as the Moment-SOS hierarchy), strengthens the standard semidefinite relaxations, and results in a much faster convergence, thus allowing more efficient approximations of the partition function Z(g) as well as moments of $μ$.",
        "keywords": [
          "math.FA",
          "math-ph",
          "math.PR"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16278v1",
        "authors": [
          "Jean B Lasserre"
        ],
        "arxiv_categories": [
          "math.FA",
          "math-ph",
          "math.PR"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Standard",
        "Act",
        "SOS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.858295"
    },
    {
      "id": "arxiv-2602.16267v1",
      "title": "On the Lie noncommutative integrability",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16267v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The Lie theory of non-commutative integrability is used to reconstruct some integrable systems of ordinary differential equations in three dimensional Eucledian space. The Darboux-Brioschi-Halphen system is an example of the Lie integrable system associated with the simple Lie algebra sl(2,R). Other examples are related with solvable three dimensional real Lie algebras of Bianchi B class.",
        "keywords": [
          "nlin.SI",
          "math-ph",
          "math.DS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16267v1",
        "authors": [
          "A. V. Tsiganov"
        ],
        "arxiv_categories": [
          "nlin.SI",
          "math-ph",
          "math.DS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.858477"
    },
    {
      "id": "arxiv-2602.16255v1",
      "title": "Piecewise integrability of the discrete Hasimoto map for analytic prediction and design of helical peptides",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16255v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The representation of protein backbone geometry through the discrete nonlinear Schrödinger equation provides a theoretical connection between biological structure and integrable systems. Although the global application of this framework is constrained by chiral degeneracies and non-local interactions we propose that helical peptides can be effectively modeled as piecewise integrable systems in which the discrete Hasimoto map remains applicable within specific geometric boundaries. We delineate these boundaries through an analytic characterization of the mapping between biochemical dihedral angles and Frenet frame parameters for a dataset of 50 helical peptide chains. We demonstrate that the transformation is information-preserving globally but ill-conditioned within the helical basin characterized by a median Jacobian condition number of 31 which suggests that the loss of chiral information arises primarily from local coordinate compression rather than topological singularities. We define a local integrability error $E[n]$ derived from the discrete dispersion relation to show that deviations from integrability are driven predominantly by torsion non-uniformity while curvature remains structurally rigid. This metric identifies integrable islands where the analytic dispersion relation predicts backbone coordinates with sub-angstrom accuracy yielding a median root-mean-square deviation of 0.77\\,Å and enables a segmentation strategy that isolates structural defects. We further indicate that the inverse design of peptide backbones is feasible within a quantitatively defined integrability zone where the design constraint reduces essentially to the control of torsion uniformity. These findings advance the Hasimoto formalism from a qualitative descriptor toward a precise quantitative framework for analyzing and designing local protein geometry within the limits of piecewise integrability.",
        "keywords": [
          "q-bio.BM",
          "math-ph",
          "nlin.PS",
          "nlin.SI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16255v1",
        "authors": [
          "Yiquan Wang"
        ],
        "arxiv_categories": [
          "q-bio.BM",
          "math-ph",
          "nlin.PS",
          "nlin.SI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "NSF",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.859637"
    },
    {
      "id": "arxiv-2602.16049v1",
      "title": "Quantitative Landis-type result for Dirac operators",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16049v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study quantitative unique continuation at infinity for Dirac equations with bounded matrix-valued potentials. For the massless Dirac operator $\\mathcal{D}_n$ in $\\mathbb{R}^n$, we establish a Landis-type estimate showing that the vanishing order of any nontrivial bounded solution of $( \\mathcal{D}_n + \\mathbb{V} ) \\varphi = 0$ satisfies a lower bound of order $\\exp(-κR^{2} (\\log R)^{2})$ as $|x|=R\\to \\infty$; the quadratic growth in the exponent is sharp, in view of previous known results. Our proof follows a Bourgain--Kenig type approach based on a Carleman inequality for Dirac operators which relies on a local Hölder regularity result, which we also prove. In two dimension, we obtain improved quantitative estimates under symmetry assumptions on the potential $\\mathbb{V}$ and for real-valued solutions. Finally, we also derive qualitative Landis-type results for Dirac equations with decaying potentials, including critical decay rates.",
        "keywords": [
          "math.AP",
          "math-ph",
          "math.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16049v1",
        "authors": [
          "Ujjal Das",
          "Luca Fanelli",
          "Luz Roncal"
        ],
        "arxiv_categories": [
          "math.AP",
          "math-ph",
          "math.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Quantitative Landis",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.860456"
    },
    {
      "id": "arxiv-2602.16017v1",
      "title": "Homotopy Lie algebras and coherent infinitesimal 2-braidings",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16017v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Given a homotopy Lie algebra (i.e. an $L_\\infty$-algebra) $\\mathfrak{g}$, we show concretely how the Lada-Markl $\\mathfrak{g}$-modules (i.e. representations) assemble into a symmetric monoidal dg-category. Considering the homotopy 2-category of that dg-category, we construct infinitesimal 2-braidings from 2-shifted Poisson structures then show that such infinitesimal 2-braidings are coherent in Cirio and Faria Martins' sense. We then explicitly determine the differential of the Chevalley-Eilenberg algebra associated with a finite-dimensional homotopy Lie algebra and construct the symmetric monoidal dg-equivalence between the category of representations and the category of semi-free dg-modules over the Chevalley-Eilenberg algebra.",
        "keywords": [
          "math.QA",
          "math-ph",
          "math.CT",
          "math.RT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16017v1",
        "authors": [
          "Cameron Kemp"
        ],
        "arxiv_categories": [
          "math.QA",
          "math-ph",
          "math.CT",
          "math.RT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Faria Martins",
        "Homotopy Lie",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.860728"
    },
    {
      "id": "arxiv-2602.15956v1",
      "title": "Einstein connection of nonsymmetric pseudo-Riemannian manifold",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15956v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A.~Einstein considered a nonsymmetric (0,2)-tensor $G=g+F$, where $g$ is a pseudo-Riemannian metric and $F\\ne0$ is skew-symmetric, and a linear connection $\\nabla$ with torsion $T$ such that $(\\nabla_X\\,G)(Y,Z)=-G(T(X,Y),Z)$. M. Prvanović (1995) obtained the explicit form of the Einstein connection of an almost Hermitian manifold. In this paper, first, we present the result above in coordinate-free form, and then extend it to almost contact metric mani\\-folds satisfying the so-called $f^2$-torsion condition. We then derive the Einstein connection of nonsymmetric pseudo-Riemannian, in particular, weak almost Hermitian manifolds $(M,f,g)$, satisfying the $f^2$-torsion condition, where $F(X,Y)=g(X,fY)$, give explicit formulas for the torsion in terms of $\\nabla^g F$, $dF$ and a new (1,1)-tensor $\\widetilde Q:=-f^2-{\\rm Id}$, and show that in the almost Hermitian case, our main result reduces to the coordinate-free form of Prvanović's solution. Finally, we describe special Einstein connections, i.e., the difference tensor has the property~$K_XY=-K_YX$, and indicate the Gray-Hervella classes. Illustrative examples are given, including the construction of a weighted product.",
        "keywords": [
          "math.DG",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15956v1",
        "authors": [
          "Vladimir Rovenski",
          "Milan Zlatanović"
        ],
        "arxiv_categories": [
          "math.DG",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "MIT",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.861487"
    },
    {
      "id": "arxiv-2602.15943v1",
      "title": "New formula for Asymptotic behavior of the Synchrotron function",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15943v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Synchrotron radiation plays a central role in astrophysical and high-energy processes. Its spectral description involves the synchrotron function, defined by a non-trivial integral of modified Bessel functions and commonly evaluated through numerical methods or dedicated approximations. In this work, we obtain a compact analytical representation of the synchrotron function using the Method of Brackets, which yields systematically controllable asymptotic expansions in both the small- and large-argument regimes. The resulting expressions accurately reproduce numerical integration and make the analytic structure of the function explicit. Our results provide an efficient alternative to repeated numerical evaluations and facilitate applications requiring fast and controlled approximations.",
        "keywords": [
          "math-ph",
          "astro-ph.HE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15943v1",
        "authors": [
          "Ivan Gonzalez",
          "Daniel Salinas-Arizmendi"
        ],
        "arxiv_categories": [
          "math-ph",
          "astro-ph.HE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.861730"
    },
    {
      "id": "arxiv-2602.15810v1",
      "title": "Effective energy-enstrophy diffusion process and condensation bound",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15810v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this article we use Gaussian measure on $\\mathbb{R}^N$ to define the coefficients of an elliptic diffusion on an open cone of $\\mathbb{R}^2$. We prove the existence and uniqueness of a stationary distribution for this diffusion. In a companion article, we show that the diffusion constructed in this work is the inviscid limit of the laws of the ``enstrophy-energy'' process of a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (the strength of which can be made to go to zero in the inviscid limit). In the present work, owing to the special properties of the coefficients constructed with the Gaussian measure, we bound the distance to $1$ of the ratio of the expected energy to the expected enstrophy (this ratio is at most $1$ with our normalization). Together with our companion article, this shows that for suitable Brownian forcings an inviscid condensation inducing an attrition of all but the lowest modes takes place.",
        "keywords": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15810v1",
        "authors": [
          "Alain-Sol Sznitman",
          "Klaus Widmayer"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.862019"
    },
    {
      "id": "arxiv-2602.15805v1",
      "title": "Inviscid limit and an effective energy-enstrophy diffusion process",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15805v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this article we consider a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (of arbitrarily small strength). We show that the stationary diffusion in an open two-dimensional cone constructed in a companion article, stands as the inviscid limit of the laws of the ``enstrophy-energy'' process of the $N$-dimensional diffusion process considered here, this regardless of the strength of the stirring. With the help of the quantitative condensation bounds of the companion article, we infer quantitative inviscid condensation bounds, which for suitable forcings show an attrition of all but the lowest modes in the inviscid limit.",
        "keywords": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15805v1",
        "authors": [
          "Alain-Sol Sznitman",
          "Klaus Widmayer"
        ],
        "arxiv_categories": [
          "math.PR",
          "math-ph",
          "math.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.862237"
    },
    {
      "id": "arxiv-2602.15789v1",
      "title": "Displacement general solutions in strain gradient elasticity: review and analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15789v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this work, we provide an overview of general solutions for displacement fields in static problems of isotropic strain gradient elasticity (SGE). We not only review existing solutions but also derive new representations, showing that all classical elasticity solutions - including those of Boussinesq-Galerkin, Papkovich-Neuber, Naghdi, Lame, Love and Boussinesq - can be simply generalized to SGE framework. In general, it is shown that SGE enables the use of any classical general solution representation combined with a Helmholtz decomposition for the gradient part of the displacement field. Consistency is also established between the presented Papkovich-Neuber representation and the general solutions of SGE proposed previously by Mindlin (1964), Lurie et al. (2006) and Charalambopoulos et al. (2020). Furthermore, we establish the relationships between the stress functions of different general solutions and show their completeness.",
        "keywords": [
          "cond-mat.other",
          "math-ph"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15789v1",
        "authors": [
          "Y. Solyaev",
          "E. Hamouda",
          "S. Sherbakov"
        ],
        "arxiv_categories": [
          "cond-mat.other",
          "math-ph"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "SGE",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:12.862620"
    },
    {
      "id": "arxiv-2602.16631v1",
      "title": "Can Wearable Exoskeletons Reduce Gender and Disability Gaps in the Construction Industry?",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16631v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The share of construction trade jobs held by women and people with disabilities has remained stubbornly low in the face of chronic shortages of skilled labor. This study explores the potential of wearable assistive technologies to reduce these disparities. We use U.S. worker-level data to estimate employment and wage differences by gender and by mobility/strength impairments in construction and non-construction jobs. We also use occupational-level data to examine variations in workforce composition, physical skill requirements, and earnings across detailed construction occupations. Regression estimates indicate that being a woman and having strength and mobility impairments are associated with substantial employment and pay gaps in construction compared to non-construction jobs. Further analysis shows a high negative correlation between the representation of women and the ability levels required in those occupations. Finally, we discuss several wearable exoskeletons under development for people with upper-body and lower-body impairments, focusing on how these innovations could be integrated into construction jobs. These findings suggest that wearable exoskeletons that enhance manual dexterity, balance, and strength may improve the representation of women and people with disabilities in some of the higher-paying occupations in construction.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16631v1",
        "authors": [
          "Yana Rodgers",
          "Xiangmin Liu",
          "Jingang Yi",
          "Liang Zhang"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Can Wearable Exoskeletons Reduce",
        "Construction Industry",
        "Disability Gaps",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.041373"
    },
    {
      "id": "arxiv-2602.16527v1",
      "title": "Model selection confidence sets for time series models with applications to electricity load data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16527v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper studies the Model Selection Confidence Set (MSCS) methodology for univariate time series models involving autoregressive and moving average components, and applies it to study model selection uncertainty in the Italian electricity load data. Rather than relying on a single model selected by an arbitrary criterion, the MSCS identifies a set of models that are statistically indistinguishable from the true data-generating process at a given confidence level. The size and composition of this set reveal crucial information about model selection uncertainty: noisy data scenarios produce larger sets with many candidate models, while more informative cases narrow the set considerably. To study the importance of each model term, we consider numerical statistics measuring the frequency with which each term is included in both the entire MSCS and in Lower Boundary Models (LBM), its most parsimonious specifications. Applied to Italian hourly electricity load data, the MSCS methodology reveals marked intraday variation in model selection uncertainty and isolates a collection of model specifications that deliver competitive short-term forecasts while highlighting key drivers of electricity load like intraday hourly lags, temperature, calendar effects and solar energy generation.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16527v1",
        "authors": [
          "Piersilvio De Bortoli",
          "Davide Ferrari",
          "Francesco Ravazzolo",
          "Luca Rossini"
        ],
        "arxiv_categories": [
          "econ.EM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Model Selection Confidence Set",
        "Lower Boundary Models",
        "Solar",
        "MSCS",
        "LBM",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.041832"
    },
    {
      "id": "arxiv-2602.16401v1",
      "title": "Stackelberg Equilibria in Monopoly Insurance Markets with Probability Weighting",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16401v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study Stackelberg Equilibria (Bowley optima) in a monopolistic centralized sequential-move insurance market, with a profit-maximizing insurer who sets premia using a distortion premium principle, and a single policyholder who seeks to minimize a distortion risk measure. We show that equilibria are characterized as follows: In equilibrium, the optimal indemnity function exhibits a layer-type structure, providing full insurance over any loss layer on which the policyholder is more pessimistic than the insurer's pricing functional about tail losses; and no insurance coverage over loss layers on which the policyholder is less pessimistic than the insurer's pricing functional about tail losses. In equilibrium, the optimal pricing distortion function is determined by the policyholder's degree of risk aversion, whereby prices never exceed the policyholder's marginal willingness to insure tail losses. Moreover, we show that both the insurance coverage and the insurer's expected profit increase with the policyholder's degree of risk aversion. Additionally, and echoing recent work in the literature, we show that equilibrium contracts are Pareto efficient, but they do not induce a welfare gain to the policyholder. Conversely, any Pareto-optimal contract that leaves no welfare gain to the policyholder can be obtained as an equilibrium contract. Finally, we consider a few examples of interest that recover some existing results in the literature as special cases of our analysis.",
        "keywords": [
          "q-fin.RM",
          "econ.TH",
          "q-fin.MF"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16401v1",
        "authors": [
          "Maria Andraos",
          "Mario Ghossoub",
          "Bin Li",
          "Benxuan Shi"
        ],
        "arxiv_categories": [
          "q-fin.RM",
          "econ.TH",
          "q-fin.MF"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Monopoly Insurance Markets",
        "Probability Weighting We",
        "Stackelberg Equilibria",
        "Policy",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.042315"
    },
    {
      "id": "arxiv-2602.16376v1",
      "title": "Two-way Clustering Robust Variance Estimator in Quantile Regression Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16376v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study inference for linear quantile regression with two-way clustered data. Using a separately exchangeable array framework and a projection decomposition of the quantile score, we characterize regime-dependent convergence rates and establish a self-normalized Gaussian approximation. We propose a two-way cluster-robust sandwich variance estimator with a kernel-based density ``bread'' and a projection-matched ``meat'', and prove consistency and validity of inference in Gaussian regimes. We also show an impossibility result for uniform inference in a non-Gaussian interaction regime.",
        "keywords": [
          "econ.EM",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16376v1",
        "authors": [
          "Ulrich Hounyo",
          "Jiahao Lin"
        ],
        "arxiv_categories": [
          "econ.EM",
          "stat.AP"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Clustering Robust Variance Estimator",
        "Quantile Regression Models We",
        "Framework",
        "EPA",
        "Act",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.042553"
    },
    {
      "id": "arxiv-2602.16310v1",
      "title": "Introducing the b-value: combining unbiased and biased estimators from a sensitivity analysis perspective",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16310v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In empirical research, when we have multiple estimators for the same parameter of interest, a central question arises: how do we combine unbiased but less precise estimators with biased but more precise ones to improve the inference? Under this setting, the point estimation problem has attracted considerable attention. In this paper, we focus on a less studied inference question: how can we conduct valid statistical inference in such settings with unknown bias? We propose a strategy to combine unbiased and biased estimators from a sensitivity analysis perspective. We derive a sequence of confidence intervals indexed by the magnitude of the bias, which enable researchers to assess how conclusions vary with the bias levels. Importantly, we introduce the notion of the b-value, a critical value of the unknown maximum relative bias at which combining estimators does not yield a significant result. We apply this strategy to three canonical combined estimators: the precision-weighted estimator, the pretest estimator, and the soft-thresholding estimator. For each estimator, we characterize the sequence of confidence intervals and determine the bias threshold at which the conclusion changes. Based on the theory, we recommend reporting the b-value based on the soft-thresholding estimator and its associated confidence intervals, which are robust to unknown bias and achieve the lowest worst-case risk among the alternatives.",
        "keywords": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16310v1",
        "authors": [
          "Zhexiao Lin",
          "Peter J. Bickel",
          "Peng Ding"
        ],
        "arxiv_categories": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "DOE",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.043013"
    },
    {
      "id": "arxiv-2602.16211v1",
      "title": "Equity in auction design with unit-demand agents and non-quasilinear preferences",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16211v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study a model of auction design where a seller is selling a set of objects to a set of agents who can be assigned no more than one object. Each agent's preference over (object, payment) pair need not be quasilinear. If the domain contains all classical preferences, we show that there is a unique mechanism, the minimum Walrasian equilibrium price (MWEP) mechanism, which is strategy-proof, individually rational, and satisfies equal treatment of equals, no-wastage (every object is allocated to some agent), and no-subsidy (no agent is subsidized). This provides an equity-based characterization of the MEWP mechanism, and complements the efficiency-based characterization of the MWEP mechanism known in the literature.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16211v1",
        "authors": [
          "Tomoya Kazumura",
          "Debasis Mishra",
          "Shigehiro Serizawa"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "MWEP",
        "MEWP",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.043284"
    },
    {
      "id": "arxiv-2602.16078v1",
      "title": "AI as Coordination-Compressing Capital: Task Reallocation, Organizational Redesign, and the Regime Fork",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16078v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Task-based models of AI and labor hold organizational structure fixed, analyzing how technology shifts task assignments within a given firm architecture. Yet emerging evidence shows firms flattening hierarchies in response to AI adoption -- a phenomenon these models cannot generate. We extend the task-based framework by introducing agent capital (K_A): AI systems that reduce coordination costs within organizations, expanding managerial spans of control and enabling endogenous task creation. We derive five propositions characterizing how coordination compression affects output, hierarchy, manager demand, wage dispersion, and the task frontier. The model generates a regime fork: depending on whether agent capital complements all workers broadly (general infrastructure) or high-skill managers disproportionately (elite complementarity), the same technology produces either broad-based productivity gains or superstar concentration, with sharply divergent distributional consequences. Numerical simulations with heterogeneous managers and workers across a 2x2 parameter space (elite complementarity x endogenous task creation) confirm sharp regime divergence: in settings where coordination compression substantially expands employment, economy-wide inequality falls in all regimes, but the rate of reduction is regime-dependent and the manager-worker wage gap widens universally. The distributional impact of AI hinges not on the technology itself but on the elasticity of organizational structure -- and on who controls that elasticity.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16078v1",
        "authors": [
          "Alex Farach"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Organizational Redesign",
        "Compressing Capital",
        "Task Reallocation",
        "Regime Fork Task",
        "Framework",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.043767"
    },
    {
      "id": "arxiv-2602.16061v1",
      "title": "Partial Identification under Missing Data Using Weak Shadow Variables from Pretrained Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16061v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Estimating population quantities such as mean outcomes from user feedback is fundamental to platform evaluation and social science, yet feedback is often missing not at random (MNAR): users with stronger opinions are more likely to respond, so standard estimators are biased and the estimand is not identified without additional assumptions. Existing approaches typically rely on strong parametric assumptions or bespoke auxiliary variables that may be unavailable in practice. In this paper, we develop a partial identification framework in which sharp bounds on the estimand are obtained by solving a pair of linear programs whose constraints encode the observed data structure. This formulation naturally incorporates outcome predictions from pretrained models, including large language models (LLMs), as additional linear constraints that tighten the feasible set. We call these predictions weak shadow variables: they satisfy a conditional independence assumption with respect to missingness but need not meet the completeness conditions required by classical shadow-variable methods. When predictions are sufficiently informative, the bounds collapse to a point, recovering standard identification as a special case. In finite samples, to provide valid coverage of the identified set, we propose a set-expansion estimator that achieves slower-than-$\\sqrt{n}$ convergence rate in the set-identified regime and the standard $\\sqrt{n}$ rate under point identification. In simulations and semi-synthetic experiments on customer-service dialogues, we find that LLM predictions are often ill-conditioned for classical shadow-variable methods yet remain highly effective in our framework. They shrink identification intervals by 75--83\\% while maintaining valid coverage under realistic MNAR mechanisms.",
        "keywords": [
          "stat.ML",
          "cs.LG",
          "econ.EM",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16061v1",
        "authors": [
          "Hongyu Chen",
          "David Simchi-Levi",
          "Ruoxuan Xiong"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG",
          "econ.EM",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Pretrained Models Estimating",
        "Missing Data Using Weak",
        "Partial Identification",
        "Shadow Variables",
        "Framework",
        "Standard",
        "MNAR",
        "LLM",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.044358"
    },
    {
      "id": "arxiv-2602.15980v1",
      "title": "Dutch Disease and the Resource Curse: The Progression of Views from Exchange Rates to Women's Agency and Well-Being",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15980v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This article provides an overview of the history of economic thought on natural resource extraction, which has long been considered an enclave industry with few benefits for areas beyond the local economy. We focus on more recent scholarship examining the social impacts of natural resource extraction, emphasizing gender-related outcomes and determinants. An important lesson from this scholarship is that it is difficult to discuss sustainable development in its contemporary sense without paying due diligence to the gender dimensions of natural resource extraction. A lesson highlighted is that the \"resource curse\" view of natural capital may not be as pervasive as previously thought.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15980v1",
        "authors": [
          "Nidhiya Menon",
          "Yana Rodgers"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Resource Curse",
        "Exchange Rates",
        "Dutch Disease",
        "Act",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.044670"
    },
    {
      "id": "arxiv-2602.15957v1",
      "title": "Evolutionary Systems Thinking -- From Equilibrium Models to Open-Ended Adaptive Dynamics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15957v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Complex change is often described as \"evolutionary\" in economics, policy, and technology, yet most system dynamics models remain constrained to fixed state spaces and equilibrium-seeking behavior. This paper argues that evolutionary dynamics should be treated as a core system-thinking problem rather than as a biological metaphor. We introduce Stability-Driven Assembly (SDA) as a minimal, non-equilibrium framework in which stochastic interactions combined with differential persistence generate endogenous selection without genes, replication, or predefined fitness functions. In SDA, longer-lived patterns accumulate in the population, biasing future interactions and creating feedback between population composition and system dynamics. This feedback yields fitness-proportional sampling as an emergent property, realizing a natural genetic algorithm driven solely by stability. Using SDA, we demonstrate why equilibrium-constrained models, even when simulated numerically, cannot exhibit open-ended evolution: evolutionary systems require population-dependent, non-stationary dynamics in which structure and dynamics co-evolve. We conclude by discussing implications for system dynamics, economics, and policy modeling, and outline how agent-based and AI-enabled approaches may support evolutionary models capable of sustained novelty and structural emergence.",
        "keywords": [
          "q-bio.PE",
          "cs.NE",
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15957v1",
        "authors": [
          "Dan Adler"
        ],
        "arxiv_categories": [
          "q-bio.PE",
          "cs.NE",
          "econ.TH"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Ended Adaptive Dynamics Complex",
        "Evolutionary Systems Thinking",
        "From Equilibrium Models",
        "Driven Assembly",
        "Framework",
        "Policy",
        "Meta",
        "SDA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:48:18.045101"
    },
    {
      "id": "arxiv-2602.15730v1",
      "title": "Causal Effect Estimation with Latent Textual Treatments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15730v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.",
        "keywords": [
          "cs.CL",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15730v1",
        "authors": [
          "Omri Feldman",
          "Amar Venugopal",
          "Jann Spiess",
          "Amir Feder"
        ],
        "arxiv_categories": [
          "cs.CL",
          "econ.EM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Latent Textual Treatments Understanding",
        "Causal Effect Estimation",
        "LLM",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.045488"
    },
    {
      "id": "arxiv-2602.15722v1",
      "title": "Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15722v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme.",
        "keywords": [
          "math.OC",
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15722v1",
        "authors": [
          "Cheng Guo",
          "Lauren Henderson",
          "Ryan Cory-Wright",
          "Boshi Yang"
        ],
        "arxiv_categories": [
          "math.OC",
          "econ.GN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nonlinear Markets With Semidefinite",
        "Relaxations Nonconvexities",
        "Pricing Discrete",
        "Framework",
        "IEEE",
        "SDP",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.045906"
    },
    {
      "id": "arxiv-2602.15699v1",
      "title": "Understanding Classical Decomposability of Inequality Measures: A Graphical Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15699v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper's objective is pedagogical and interpretive. Namely, it gives a simple geometric analysis of classical (by which I mean population-share-weighted or income-share-weighted) inequality decomposability in the simplest nontrivial setting of three individuals. Income distributions in this case can be represented as points on the two-dimensional income-share simplex. In this representation, classical decomposability translates into concrete geometric restrictions of within- and between-group components. The geometric framework makes it possible to localize and compare violations of decomposability across inequality measures. The analysis is applied to the Mean Log Deviation, the Gini coefficient, the coefficient of variation, and the Theil index.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15699v1",
        "authors": [
          "Tatiana Komarova"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Understanding Classical Decomposability",
        "Inequality Measures",
        "Mean Log Deviation",
        "Framework",
        "UN"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.046141"
    },
    {
      "id": "arxiv-2602.15690v1",
      "title": "Income Inequality and Economic Growth: A Meta-Analytic Approach",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15690v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The empirical literature on the relationship between income inequality and economic growth has produced highly heterogeneous and often conflicting results. This paper investigates the sources of this heterogeneity using a meta-analytic approach that systematically combines and analyzes evidence from relevant studies published between 1994 and 2025. We find an economically small but statistically significant negative average effect of income inequality on subsequent economic growth, together with strong evidence of substantial heterogeneity and selective publication based on statistical significance, but no evidence of systematic directional bias. To explain the observed heterogeneity, we estimate a meta-regression. The results indicate that both real-world characteristics and research design choices shape reported effect sizes. In particular, inequality measured net of taxes and transfers is associated with more negative growth effects, and the adverse impact of inequality is weaker - or even reversed - in high-income economies relative to developing countries. Methodological choices also matter: cross-sectional studies tend to report more negative estimates, while fixed-effects, instrumental-variable, and GMM estimators are associated with more positive estimates in panel settings.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15690v1",
        "authors": [
          "Lisa Cpretti",
          "Lorenzo Tonni"
        ],
        "arxiv_categories": [
          "econ.EM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Income Inequality",
        "Economic Growth",
        "Meta",
        "NSF",
        "Act",
        "GMM",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.046493"
    },
    {
      "id": "arxiv-2602.15686v1",
      "title": "Minimizing Volatility: Optimal Adjustment with Evolving Feasibility Constraints",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15686v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Minimizing volatility and adjustment costs is of central importance in many economic environments, yet it is often complicated by evolving feasibility constraints. We study a decision maker who repeatedly selects an action from a stochastically evolving interval of feasible actions in order to minimize either average adjustment costs or variance. We show that for strictly convex adjustment costs (such as quadratic variation), the optimal decision rule is a reference rule in which the decision maker minimizes the distance to a target action. In general, the optimal target depends both on the previous action and the expectation of future constraints; but for the special case where the constraints follow a random walk, the optimal mechanism is to simply target the previous action. If the decision maker minimizes variance, the optimal policy is also a reference rule, but the target is a constant, which is not necessarily equal to the long-term average action. Compared to mid-point heuristics, these optimal rules may substantially reduce quadratic variation and variance, in natural environments by $50\\%$ or more. Applied to stock market auctions, our results provide an explanation for the wide-spread use of reference price rules. We also apply our results to bilateral trade in over-the-counter markets, capacity planning in supply chains, and positioning in political agenda setting.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15686v1",
        "authors": [
          "Simon Jantschgi",
          "Heinrich H. Nax",
          "Bary S. R. Pradelski",
          "Marek Pycia"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Evolving Feasibility Constraints Minimizing",
        "Minimizing Volatility",
        "Optimal Adjustment",
        "Policy",
        "Act",
        "WHO",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.046871"
    },
    {
      "id": "arxiv-2602.15674v1",
      "title": "Complexity and Misspecification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15674v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We propose a tractable unified framework to study the evolution and interaction of model-misspecification concerns and complexity aversion in repeated decision problems. This aims to capture environments where decision makers worry that their models are misspecified while also disliking overly complex models. We find that pathological cycles caused by endogenous concerns for misspecification can be eliminated by penalizing complex models and show that such preferences for simplicity tend to favor safety, which can enhance welfare in the long run. We use our framework to provide new microfoundations for pervasive empirical phenomena such as \"scale heterogeneity\" in discrete-choice analysis, \"probability neglect\" in behavioral economics, and \"home bias\" in international finance.",
        "keywords": [
          "econ.TH"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15674v1",
        "authors": [
          "Drew Fudenberg",
          "Florian Mudekereza"
        ],
        "arxiv_categories": [
          "econ.TH"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Misspecification We",
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.047096"
    },
    {
      "id": "arxiv-2602.15607v1",
      "title": "Agent-based macroeconomics for the UK's Seventh Carbon Budget",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15607v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In June 2026, the UK government will set its carbon budget for the period 2038 to 2042, the seventh such carbon budget (CB7) since the Climate Change Act became law in 2008. For the first time, this carbon budget will be accompanied by a macroeconomic assessment of its impact on growth, employment, inflation and inequality. Researchers from the Institute of New Economic Thinking (INET) Oxford are working in partnership with the Department for Energy Security and Net Zero to deliver this assessment using our data-driven macroeconomic agent-based model (ABM). This extended abstract presents the work in progress towards this pioneering policymaking using our data-driven macroeconomic ABM. We are conducting our work in three work packages. By the time of the workshop, we hope to be able to present preliminary findings from the first two work packages. In WP1, we adapt an existing macro-ABM prototype and build a UK macroeconomic baseline. The main task for this is initialising the model with suitable UK household microdata. We present the options considered and the approach settled upon. In WP2, we conduct preliminary modelling that represents UK decarbonisation as an external shock to financial flows and technical coefficients. In order to present results in time to influence the June 2026 policy decision, this second work package exogenously forces the ABM to follow the CB7 green investment and associated technological change projections provided by the Climate Change Committee. Finally, we will implement more sophisticated social and technological learning packages in WP3, building our own projections of likely decarbonisation pathways that may diverge from UK government plans. For the workshop, we will present the progress of WP1 and WP2.",
        "keywords": [
          "econ.GN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15607v1",
        "authors": [
          "Tom Youngman",
          "Tim Lennox",
          "M. Lopes Alves",
          "Pirta Palola",
          "Brendon Tankwa"
        ],
        "arxiv_categories": [
          "econ.GN"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Seventh Carbon Budget In",
        "Climate Change Committee",
        "New Economic Thinking",
        "Climate Change Act",
        "Energy Security",
        "Institute",
        "Net Zero",
        "Policy",
        "INET",
        "EPA",
        "Act",
        "ABM",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.047585"
    },
    {
      "id": "arxiv-2602.15559v1",
      "title": "Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15559v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails.",
        "keywords": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15559v1",
        "authors": [
          "Gabriel Saco"
        ],
        "arxiv_categories": [
          "stat.ME",
          "econ.EM",
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Logged Propensities Adaptive",
        "Adaptive Experiments",
        "Normalized Inference",
        "Horizon Self",
        "Standard",
        "AIPW",
        "NIST",
        "Act",
        "MIT",
        "ATE",
        "DML",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.048009"
    },
    {
      "id": "arxiv-2602.15312v1",
      "title": "Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15312v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.",
        "keywords": [
          "cs.CL",
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15312v1",
        "authors": [
          "Stephan Ludwig",
          "Peter J. Danaher",
          "Xiaohao Yang",
          "Yu-Ting Lin",
          "Ehsan Abedin"
        ],
        "arxiv_categories": [
          "cs.CL",
          "econ.EM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Evaluation Measurement Accurately",
        "Large Language Model Approach",
        "Extracting Consumer Insight",
        "Amazon",
        "GPT-4",
        "BERT",
        "GPT",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:18.048418"
    },
    {
      "id": "arxiv-2602.15289v1",
      "title": "A Projection Approach to Nonparametric Significance and Conditional Independence Testing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15289v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper develops a novel nonparametric significance test based on a tailored nonparametric-type projected weighting function that exhibits appealing theoretical and numerical properties. We derive the asymptotic properties of the proposed test and show that it can detect local alternatives at the parametric rate. Using the nonparametric orthogonal projection, we construct a computationally convenient multiplier bootstrap to obtain critical values from the case-dependent asymptotic null distribution. Compared with the existing literature, our approach overcomes the need for a stronger compact support assumption on the density of covariates arising from random denominators. We also extend the tailor-made projection procedure to test the conditional independence assumption. The simulation experiments further illustrate the advantages of our proposed method in testing significance and conditional independence in finite samples.",
        "keywords": [
          "econ.EM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15289v1",
        "authors": [
          "Xiaojun Song",
          "Jichao Yuan"
        ],
        "arxiv_categories": [
          "econ.EM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Nonparametric Significance",
        "Projection Approach",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:18.048692"
    },
    {
      "id": "arxiv-2602.16539v1",
      "title": "Caratheodory, Finite Resources and the Geometry of Arbitrage",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16539v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Caratheodory's axiom of adiabatic inaccessibility states that, in any neighborhood of a thermodynamic state, certain states remain unreachable via adiabatic processes. Non-arbitrage mirrors this topological restriction in finance. Preserving this constraint in resource-limited systems identifies the exponential family not as a modeling convenience but as the requisite geometric structure unifying both domains.",
        "keywords": [
          "q-fin.PM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16539v1",
        "authors": [
          "B. K. Meister"
        ],
        "arxiv_categories": [
          "q-fin.PM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Arbitrage Caratheodory",
        "Finite Resources",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:23.127714"
    },
    {
      "id": "arxiv-2602.16232v1",
      "title": "A Wiener Chaos Approach to Martingale Modelling and Implied Volatility Calibration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16232v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Calibration to a surface of option prices requires specifying a suitably flexible martingale model for the discounted asset price under a risk-neutral measure. Assuming Brownian noise and mean-square integrability, we construct an over-parameterized model based on the martingale representation theorem. In particular, we approximate the terminal value of the martingale via a truncated Wiener--chaos expansion and recover the intermediate dynamics by computing the corresponding conditional expectations. Using the Hermite-polynomial formulation of the Wiener chaos, we obtain easily implementable expressions that enable fast calibration to a target implied-volatility surface. We illustrate the flexibility and expressive power of the resulting model through numerical experiments on both simulated and real market data.",
        "keywords": [
          "q-fin.MF",
          "q-fin.CP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16232v1",
        "authors": [
          "Pere Diaz-Lozano",
          "Thomas K. Kloster"
        ],
        "arxiv_categories": [
          "q-fin.MF",
          "q-fin.CP"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Implied Volatility Calibration Calibration",
        "Wiener Chaos Approach",
        "Martingale Modelling",
        "Assuming Brownian",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:23.128186"
    },
    {
      "id": "arxiv-2602.16212v1",
      "title": "Money-Back Tontines for Retirement Decumulation: Neural-Network Optimization under Systematic Longevity Risk",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16212v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Money-back guarantees (MBGs) are features of pooled retirement income products that address bequest concerns by ensuring the initial premium is returned through lifetime payments or, upon early death, as a death benefit to the estate. This paper studies optimal retirement decumulation in an individual tontine account with an MBG overlay under international diversification and systematic longevity risk. The retiree chooses withdrawals and asset allocation dynamically to trade off expected total withdrawals (EW) against the Conditional Value-at-Risk (CVaR) of terminal wealth, subject to realistic investment constraints. The optimization is solved under a plan-to-live convention, while stochastic mortality affects outcomes through its impact on mortality credits at the pool level. We develop a neural-network based computational approach for the resulting high-dimensional, constrained control problem. The MBG is priced ex post under the induced EW--CVaR optimal policy via a simulation-based actuarial rule that combines expected guarantee costs with a prudential tail buffer. Using long-horizon historical return data expressed in real domestic-currency terms, we find that international diversification and longevity pooling jointly deliver the largest improvements in the EW--CVaR trade-off, while stochastic mortality shifts the frontier modestly in the expected direction. The optimal controls use foreign equity primarily as a state-dependent catch-up instrument, and implied MBG loads are driven mainly by tail outcomes (and the chosen prudential buffer) rather than by mean payouts.",
        "keywords": [
          "q-fin.PM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16212v1",
        "authors": [
          "German Nova Orozco",
          "Duy-Minh Dang",
          "Peter A. Forsyth"
        ],
        "arxiv_categories": [
          "q-fin.PM"
        ],
        "steeps_mapping": "E_Economic"
      },
      "entities": [
        "Systematic Longevity Risk Money",
        "Retirement Decumulation",
        "Network Optimization",
        "Conditional Value",
        "Back Tontines",
        "Policy",
        "MBG",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "E",
      "collected_at": "2026-02-19T14:48:23.128715"
    },
    {
      "id": "arxiv-2602.15474v1",
      "title": "Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15474v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space.",
        "keywords": [
          "quant-ph",
          "cond-mat.supr-con",
          "q-fin.ST"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15474v1",
        "authors": [
          "J. J. Prieto-Garcia",
          "A. G. del Pozo-Martín",
          "M. Pino"
        ],
        "arxiv_categories": [
          "quant-ph",
          "cond-mat.supr-con",
          "q-fin.ST"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Superconducting Quantum Circuit We",
        "Quantum Reservoir Computing",
        "Statistical Classification",
        "Standard",
        "BERT",
        "MIT",
        "QRC",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:23.129081"
    },
    {
      "id": "arxiv-2602.15385v2",
      "title": "From Chain-Ladder to Individual Claims Reserving",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15385v2",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The chain-ladder (CL) method is the most widely used claims reserving technique in non-life insurance. This manuscript introduces a novel approach to computing the CL reserves based on a fundamental restructuring of the data utilization for the CL prediction procedure. Instead of rolling forward the cumulative claims with estimated CL factors, we estimate multi-period factors that project the latest observations directly to the ultimate claims. This alternative perspective on CL reserving creates a natural pathway for the application of machine learning techniques to individual claims reserving. As a proof of concept, we present a small-scale real data application employing neural networks for individual claims reserving.",
        "keywords": [
          "stat.AP",
          "q-fin.RM",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15385v2",
        "authors": [
          "Ronald Richman",
          "Mario V. Wüthrich"
        ],
        "arxiv_categories": [
          "stat.AP",
          "q-fin.RM",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Machine Learning",
        "Neural Network",
        "From Chain",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:23.129344"
    },
    {
      "id": "arxiv-2602.16616v1",
      "title": "Design and Analysis Strategies for Pooling in High Throughput Screening: Application to the Search for a New Anti-Microbial",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16616v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A major public health issue is the growing resistance of bacteria to antibiotics. An important part of the needed response is the discovery and development of new antimicrobial strategies. These require the screening of potential new drugs, typically accomplished using high-throughput screening (HTS). Traditionally, HTS is performed by examining one compound per well, but a more efficient strategy pools multiple compounds per well. In this work, we study several recently proposed pooling construction methods, as well as a variety of pooled high-throughput screening analysis methods, in order to provide guidance to practitioners on which methods to use. This is done in the context of an application of the methods to the search for new drugs to combat bacterial infection. We discuss both an extensive pilot study as well as a small screening campaign, and highlight both the successes and challenges of the pooling approach.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16616v1",
        "authors": [
          "Byran Smucker",
          "Benjamin Brennan",
          "Emily Rego",
          "Meng Wu",
          "Zhihong Lin"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "High Throughput Screening",
        "Analysis Strategies",
        "New Anti",
        "IoT",
        "Act",
        "HTS",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.223833"
    },
    {
      "id": "arxiv-2602.16583v1",
      "title": "Physical Activity Trajectories Preceding Incident Major Depressive Disorder Diagnosis Using Consumer Wearable Devices in the All of Us Research Program: Case-Control Study",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16583v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Low physical activity is a known risk factor for major depressive disorder (MDD), but changes in activity before a first clinical diagnosis remain unclear, especially using long-term objective measurements. This study characterized trajectories of wearable-measured physical activity during the year preceding incident MDD diagnosis. We conducted a retrospective nested case-control study using linked electronic health record and Fitbit data from the All of Us Research Program. Adults with at least 6 months of valid wearable data in the year before diagnosis were eligible. Incident MDD cases were matched to controls on age, sex, body mass index, and index time (up to four controls per case). Daily step counts and moderate-to-vigorous physical activity (MVPA) were aggregated into monthly averages. Linear mixed-effects models compared trajectories from 12 months before diagnosis to diagnosis. Within cases, contrasts identified when activity first significantly deviated from levels 12 months prior. The cohort included 4,104 participants (829 cases and 3,275 controls; 81.7% women; median age 48.4 years). Compared with controls, cases showed consistently lower activity and significant downward trajectories in both step counts and MVPA during the year before diagnosis (P < 0.001). Significant declines appeared about 4 months before diagnosis for step counts and 5 months for MVPA. Exploratory analyses suggested subgroup differences, including steeper declines in men, greater intensity reductions at older ages, and persistently low activity among individuals with obesity. Sustained within-person declines in physical activity emerged months before incident MDD diagnosis. Longitudinal wearable monitoring may provide early signals to support risk stratification and earlier intervention.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16583v1",
        "authors": [
          "Yuezhou Zhang",
          "Amos Folarin",
          "Hugh Logan Ellis",
          "Rongrong Zhong",
          "Callum Stewart"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Physical Activity Trajectories Preceding",
        "Incident Major Depressive Disorder",
        "Diagnosis Using Consumer Wearable",
        "Us Research Program",
        "Control Study Low",
        "MVPA",
        "Act",
        "MDD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.224767"
    },
    {
      "id": "arxiv-2602.16497v1",
      "title": "Factor-Adjusted Multiple Testing for High-Dimensional Individual Mediation Effects",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16497v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Identifying individual mediators is a central goal of high-dimensional mediation analysis, yet pervasive dependence among mediators can invalidate standard debiased inference and lead to substantial false discovery rate (FDR) inflation. We propose a Factor-Adjusted Debiased Mediation Testing (FADMT) framework that enables large-scale inference for individual mediation effects with FDR control under complex dependence structures. Our approach posits an approximate factor structure on the unobserved errors of the mediator model, extracts common latent factors, and constructs decorrelated pseudo-mediators for the subsequent inferential procedure. We establish the asymptotic normality of the debiased estimator and develop a multiple testing procedure with theoretical FDR control under mild high-dimensional conditions. By adjusting for latent factor induced dependence, FADMT also improves robustness to spurious associations driven by shared latent variation in observational studies. Extensive simulations demonstrate the superior finite-sample performance across a wide range of correlation structures. Applications to TCGA-BRCA multi-omics data and to China's stock connect study further illustrate the practical utility of the proposed method.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16497v1",
        "authors": [
          "Chen Shi",
          "Zhao Chen",
          "Christina Dan Wang"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Dimensional Individual Mediation Effects",
        "Adjusted Debiased Mediation Testing",
        "Adjusted Multiple Testing",
        "Framework",
        "Standard",
        "FADMT",
        "TCGA",
        "BRCA",
        "FDR",
        "Act",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.225626"
    },
    {
      "id": "arxiv-2602.16463v1",
      "title": "Focused Relative Risk Information Criterion for Variable Selection in Linear Regression",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16463v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper motivates and develops a novel and focused approach to variable selection in linear regression models. For estimating the regression mean $μ=\\E\\,(Y\\midd x_0)$, for the covariate vector of a given individual, there is a list of competing estimators, say $\\hattμ_S$ for each submodel $S$. Exact expressions are found for the relative mean squared error risks, when compared to the widest model available, say $\\mse_S/\\mse_\\wide$. The theory of confidence distributions is used for accurate assessments of these relative risks. This leads to certain Focused Relative Risk Information Criterion scores, and associated FRIC plots and FRIC tables, as well as to Confidence plots to exhibit the confidence the data give in the submodels. The machinery is extended to handle many focus parameters at the same time, with appropriate averaged FRIC scores. The particular case where all available covariate vectors have equal importance yields a new overall criterion for variable selection, balancing complexity and fit in a natural fashion. A connection to the Mallows criterion is demonstrated, leading also to natural modifications of the latter. The FRIC and AFRIC strategies are illustrated for real data.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16463v1",
        "authors": [
          "Nils Lid Hjort"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Focused Relative Risk Information",
        "Variable Selection",
        "AFRIC",
        "FRIC",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.226617"
    },
    {
      "id": "arxiv-2602.16340v1",
      "title": "The Implicit Bias of Adam and Muon on Smooth Homogeneous Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16340v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study the implicit bias of momentum-based optimizers on homogeneous models. We first extend existing results on the implicit bias of steepest descent in homogeneous models to normalized steepest descent with an optional learning rate schedule. We then show that for smooth homogeneous models, momentum steepest descent algorithms like Muon (spectral norm), MomentumGD ($\\ell_2$ norm), and Signum ($\\ell_\\infty$ norm) are approximate steepest descent trajectories under a decaying learning rate schedule, proving that these algorithms too have a bias towards KKT points of the corresponding margin maximization problem. We extend the analysis to Adam (without the stability constant), which maximizes the $\\ell_\\infty$ margin, and to Muon-Signum and Muon-Adam, which maximize a hybrid norm. Our experiments corroborate the theory and show that the identity of the margin maximized depends on the choice of optimizer. Overall, our results extend earlier lines of work on steepest descent in homogeneous models and momentum-based optimizers in linear models.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16340v1",
        "authors": [
          "Eitan Gronich",
          "Gal Vardi"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Smooth Homogeneous Neural Networks",
        "Neural Network",
        "KKT",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.227120"
    },
    {
      "id": "arxiv-2602.16328v1",
      "title": "A general framework for modeling Gaussian process with qualitative and quantitative factors",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16328v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Computer experiments involving both qualitative and quantitative (QQ) factors have attracted increasing attention. Gaussian process (GP) models have proven effective in this context by choosing specialized covariance functions for QQ factors. In this work, we extend the latent variable-based GP approach, which maps qualitative factors into a continuous latent space, by establishing a general framework to apply standard kernel functions to continuous latent variables. This approach provides a novel perspective for interpreting some existing GP models for QQ factors and introduces new covariance structures in some situations. The ordinal structure can be incorporated naturally and seamlessly in this framework. Furthermore, the Bayesian information criterion and leave-one-out cross-validation are employed for model selection and model averaging. The performance of the proposed method is comprehensively studied on several examples.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16328v1",
        "authors": [
          "Linsui Deng",
          "C. F. Jeff Wu"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "Act",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.227440"
    },
    {
      "id": "arxiv-2602.16283v1",
      "title": "Orthogonal parametrisations of Extreme-Value distributions",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16283v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Extreme value distributions are routinely employed to assess risks connected to extreme events in a large number of applications. They typically are two- or three- parameter distributions: the inference can be unstable, which is particularly problematic given the fact that often times these distributions are fitted to small samples. Furthermore, the distribution's parameters are generally not directly interpretable and not the key aim of the estimation. We present several orthogonal reparametrisations of the main extreme-value distributions, key in the modelling of rare events. In particular, we apply the theory developed in Cox and Reid (1987) to the Generalised Extreme-Value, Generalised Pareto, and Gumbel distributions. We illustrate the principal advantage of these reparametrisations in a simulation study.",
        "keywords": [
          "math.ST",
          "stat.OT"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16283v1",
        "authors": [
          "Nathan Huet",
          "Ilaria Prosdocimi"
        ],
        "arxiv_categories": [
          "math.ST",
          "stat.OT"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalised Extreme",
        "Generalised Pareto",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.227795"
    },
    {
      "id": "arxiv-2602.16274v1",
      "title": "Regret and Sample Complexity of Online Q-Learning via Concentration of Stochastic Approximation with Time-Inhomogeneous Markov Chains",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16274v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present the first high-probability regret bound for classical online Q-learning in infinite-horizon discounted Markov decision processes, without relying on optimism or bonus terms. We first analyze Boltzmann Q-learning with decaying temperature and show that its regret depends critically on the suboptimality gap of the MDP: for sufficiently large gaps, the regret is sublinear, while for small gaps it deteriorates and can approach linear growth. To address this limitation, we study a Smoothed $ε_n$-Greedy exploration scheme that combines $ε_n$-greedy and Boltzmann exploration, for which we prove a gap-robust regret bound of near-$\\tilde{O}(N^{9/10})$. To analyze these algorithms, we develop a high-probability concentration bound for contractive Markovian stochastic approximation with iterate- and time-dependent transition dynamics. This bound may be of independent interest as the contraction factor in our bound is governed by the mixing time and is allowed to converge to one asymptotically.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16274v1",
        "authors": [
          "Rahul Singh",
          "Siddharth Chandak",
          "Eric Moulines",
          "Vivek S. Borkar",
          "Nicholas Bambos"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Inhomogeneous Markov Chains We",
        "Stochastic Approximation",
        "Sample Complexity",
        "Act",
        "MDP",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.228610"
    },
    {
      "id": "arxiv-2602.16265v1",
      "title": "On sparsity, extremal structure, and monotonicity properties of Wasserstein and Gromov-Wasserstein optimal transport plans",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16265v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This note gives a self-contained overview of some important properties of the Gromov-Wasserstein (GW) distance, compared with the standard linear optimal transport (OT) framework. More specifically, I explore the following questions: are GW optimal transport plans sparse? Under what conditions are they supported on a permutation? Do they satisfy a form of cyclical monotonicity? In particular, I present the conditionally negative semi-definite property and show that, when it holds, there are GW optimal plans that are sparse and supported on a permutation.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16265v1",
        "authors": [
          "Titouan Vayer"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Standard",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.228848"
    },
    {
      "id": "arxiv-2602.16259v1",
      "title": "HAL-MLE Log-Splines Density Estimation (Part I: Univariate)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16259v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We study nonparametric maximum likelihood estimation of probability densities under a total variation (TV) type penalty, sectional variation norm (also named as Hardy-Krause variation). TV regularization has a long history in regression and density estimation, including results on $L^2$ and KL divergence convergence rates. Here, we revisit this task using the Highly Adaptive Lasso (HAL) framework. We formulate a HAL-based maximum likelihood estimator (HAL-MLE) using the log-spline link function from \\citet{kooperberg1992logspline}, and show that in the univariate setting the bounded sectional variation norm assumption underlying HAL coincides with the classical bounded TV assumption. This equivalence directly connects HAL-MLE to existing TV-penalized approaches such as local adaptive splines \\citep{mammen1997locally}. We establish three new theoretical results: (i) the univariate HAL-MLE is asymptotically linear, (ii) it admits pointwise asymptotic normality, and (iii) it achieves uniform convergence at rate $n^{-(k+1)/(2k+3)}$ up to logarithmic factors for the smoothness order $k \\geq 1$. These results extend existing results from \\citet{van2017uniform}, which previously guaranteed only uniform consistency without rates when $k=0$. We will include the uniform convergence for general dimension $d$ in the follow-up work of this paper. The intention of this paper is to provide a unified framework for the TV-penalized density estimation methods, and to connect the HAL-MLE to the existing TV-penalized methods in the univariate case, despite that the general HAL-MLE is defined for multivariate cases.",
        "keywords": [
          "math.ST",
          "stat.CO",
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16259v1",
        "authors": [
          "Yilong Hou",
          "Zhengpu Zhao",
          "Yi Li",
          "Mark van der Laan"
        ],
        "arxiv_categories": [
          "math.ST",
          "stat.CO",
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Splines Density Estimation",
        "Highly Adaptive Lasso",
        "Framework",
        "MLE",
        "Act",
        "MIT",
        "HAL",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.229353"
    },
    {
      "id": "arxiv-2602.16218v1",
      "title": "Bayesian Quadrature: Gaussian Processes for Integration",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16218v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Bayesian quadrature is a probabilistic, model-based approach to numerical integration, the estimation of intractable integrals, or expectations. Although Bayesian quadrature was popularised already in the 1980s, no systematic and comprehensive treatment has been published. The purpose of this survey is to fill this gap. We review the mathematical foundations of Bayesian quadrature from different points of view; present a systematic taxonomy for classifying different Bayesian quadrature methods along the three axes of modelling, inference, and sampling; collect general theoretical guarantees; and provide a controlled numerical study that explores and illustrates the effect of different choices along the axes of the taxonomy. We also provide a realistic assessment of practical challenges and limitations to application of Bayesian quadrature methods and include an up-to-date and nearly exhaustive bibliography that covers not only machine learning and statistics literature but all areas of mathematics and engineering in which Bayesian quadrature or equivalent methods have seen use.",
        "keywords": [
          "cs.LG",
          "math.NA",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16218v1",
        "authors": [
          "Maren Mahsereci",
          "Toni Karvonen"
        ],
        "arxiv_categories": [
          "cs.LG",
          "math.NA",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Integration Bayesian",
        "Bayesian Quadrature",
        "Gaussian Processes",
        "Although Bayesian",
        "Machine Learning",
        "Act",
        "MIT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.229707"
    },
    {
      "id": "arxiv-2602.16195v1",
      "title": "Phase Transitions in Collective Damage of Civil Structures under Natural Hazards",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16195v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The fate of cities under natural hazards depends not only on hazard intensity but also on the coupling of structural damage, a collective process that remains poorly understood. Here we show that urban structural damage exhibits phase-transition phenomena. As hazard intensity increases, the system can shift abruptly from a largely safe to a largely damaged state, analogous to a first-order phase transition in statistical physics. Higher diversity in the building portfolio smooths this transition, but multiscale damage clustering traps the system in an extended critical-like regime (analogous to a Griffiths phase), suppressing the emergence of a more predictable disordered (Gaussian) phase. These phenomenological patterns are characterized by a random-field Ising model, with the external field, disorder strength, and temperature interpreted as the effective hazard demand, structural diversity, and modeling uncertainty, respectively. Applying this framework to real urban inventories reveals that widely used engineering modeling practices can shift urban damage patterns between synchronized and volatile regimes, systematically biasing exceedance-based risk metrics by up to 50% under moderate earthquakes ($M_w \\approx 5.5$--$6.0$), equivalent to a several-fold gap in repair costs. This phase-aware description turns the collective behavior of civil infrastructure damage into actionable diagnostics for urban risk assessment and planning.",
        "keywords": [
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16195v1",
        "authors": [
          "Sebin Oh",
          "Jinyan Zhao",
          "Raul Rincon",
          "Jamie E. Padgett",
          "Ziqi Wang"
        ],
        "arxiv_categories": [
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Collective Damage",
        "Phase Transitions",
        "Civil Structures",
        "Framework",
        "EPA",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.230164"
    },
    {
      "id": "arxiv-2602.16177v1",
      "title": "Conjugate Learning Theory: Uncovering the Mechanisms of Trainability and Generalization in Deep Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16177v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "In this work, we propose a notion of practical learnability grounded in finite sample settings, and develop a conjugate learning theoretical framework based on convex conjugate duality to characterize this learnability property. Building on this foundation, we demonstrate that training deep neural networks (DNNs) with mini-batch stochastic gradient descent (SGD) achieves global optima of empirical risk by jointly controlling the extreme eigenvalues of a structure matrix and the gradient energy, and we establish a corresponding convergence theorem. We further elucidate the impact of batch size and model architecture (including depth, parameter count, sparsity, skip connections, and other characteristics) on non-convex optimization. Additionally, we derive a model-agnostic lower bound for the achievable empirical risk, theoretically demonstrating that data determines the fundamental limit of trainability. On the generalization front, we derive deterministic and probabilistic bounds on generalization error based on generalized conditional entropy measures. The former explicitly delineates the range of generalization error, while the latter characterizes the distribution of generalization error relative to the deterministic bounds under independent and identically distributed (i.i.d.) sampling conditions. Furthermore, these bounds explicitly quantify the influence of three key factors: (i) information loss induced by irreversibility in the model, (ii) the maximum attainable loss value, and (iii) the generalized conditional entropy of features with respect to labels. Moreover, they offer a unified theoretical lens for understanding the roles of regularization, irreversible transformations, and network depth in shaping the generalization behavior of deep neural networks. Extensive experiments validate all theoretical predictions, confirming the framework's correctness and consistency.",
        "keywords": [
          "stat.ML",
          "cs.AI",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16177v1",
        "authors": [
          "Binchuan Qi"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.AI",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Deep Neural Networks In",
        "Neural Network",
        "Framework",
        "NIST",
        "NSF",
        "Act",
        "SGD",
        "MIT",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.230766"
    },
    {
      "id": "arxiv-2602.16146v1",
      "title": "Uncertainty-Aware Neural Multivariate Geostatistics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16146v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We propose Deep Neural Coregionalization, a scalable framework for uncertainty-aware multivariate geostatistics. DNC models multivariate spatial effects through spatially varying latent factors and loadings, assigning deep Gaussian process (DGP) priors to both the factors and the entries of the loading matrix. This joint construction learns shared latent spatial structure together with response-specific, location-dependent mixing weights, enabling flexible nonlinear and space-dependent associations within and across variables. A key contribution is a variational formulation that makes the DGP to deep neural network (DNN) correspondence explicit: maximizing the DGP evidence lower bound (ELBO) is equivalent to training DNNs with weight decay and Monte Carlo (MC) dropout. This yields fast mini-batch stochastic optimization without Markov Chain Monte Carlo (MCMC), while providing principled uncertainty quantification through MC-dropout forward passes as approximate posterior draws, producing calibrated credible surfaces for prediction and spatial effect estimation. Across simulations, DNC is competitive with existing spatial factor models, particularly under strong nonstationarity and complex cross-dependence, while delivering substantial computational gains. In a multivariate environmental case study, DNC captures spatially varying cross-variable interactions, produces interpretable maps of multivariate outcomes, and scales uncertainty quantification to large datasets with orders-of-magnitude reductions in runtime.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16146v1",
        "authors": [
          "Yeseul Jeon",
          "Aaron Scheffler",
          "Rajarshi Guhaniyogi"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Neural Multivariate Geostatistics",
        "Deep Neural Coregionalization",
        "Markov Chain Monte Carlo",
        "Neural Network",
        "Monte Carlo",
        "Framework",
        "ELBO",
        "MCMC",
        "DNN",
        "DNC",
        "Act",
        "DGP",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.231230"
    },
    {
      "id": "arxiv-2602.16137v1",
      "title": "Experimental Assortments for Choice Estimation and Nest Identification",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16137v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "What assortments (subsets of items) should be offered, to collect data for estimating a choice model over $n$ total items? We propose a structured, non-adaptive experiment design requiring only $O(\\log n)$ distinct assortments, each offered repeatedly, that consistently outperforms randomized and other heuristic designs across an extensive numerical benchmark that estimates multiple different choice models under a variety of (possibly mis-specified) ground truths. We then focus on Nested Logit choice models, which cluster items into \"nests\" of close substitutes. Whereas existing Nested Logit estimation procedures assume the nests to be known and fixed, we present a new algorithm to identify nests based on collected data, which when used in conjunction with our experiment design, guarantees correct identification of nests under any Nested Logit ground truth. Our experiment design was deployed to collect data from over 70 million users at Dream11, an Indian fantasy sports platform that offers different types of betting contests, with rich substitution patterns between them. We identify nests based on the collected data, which lead to better out-of-sample choice prediction than ex-ante clustering from contest features. Our identified nests are ex-post justifiable to Dream11 management.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16137v1",
        "authors": [
          "Xintong Yu",
          "Will Ma",
          "Michael Zhao"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Nest Identification What",
        "Experimental Assortments",
        "Choice Estimation",
        "Nested Logit",
        "EU",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.231594"
    },
    {
      "id": "arxiv-2602.16131v1",
      "title": "Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16131v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Large language models (LLMs) are increasingly used as agents to solve complex tasks such as question answering (QA), scientific debate, and software development. A standard evaluation procedure aggregates multiple responses from LLM agents into a single final answer, often via majority voting, and compares it against reference answers. However, this process can obscure the quality and distributional characteristics of the original responses. In this paper, we propose a novel evaluation framework based on the empirical cumulative distribution function (ECDF) of cosine similarities between generated responses and reference answers. This enables a more nuanced assessment of response quality beyond exact match metrics. To analyze the response distributions across different agent configurations, we further introduce a clustering method for ECDFs using their distances and the $k$-medoids algorithm. Our experiments on a QA dataset demonstrate that ECDFs can distinguish between agent settings with similar final accuracies but different quality distributions. The clustering analysis also reveals interpretable group structures in the responses, offering insights into the impact of temperature, persona, and question topics.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16131v1",
        "authors": [
          "Chihiro Watanabe",
          "Jingyu Sun"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Empirical Cumulative Distribution Function",
        "Agent System Analysis Large",
        "Framework",
        "Standard",
        "ECDF",
        "LLM",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.231934"
    },
    {
      "id": "arxiv-2602.16120v1",
      "title": "Feature-based morphological analysis of shape graph data",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16120v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper introduces and demonstrates a computational pipeline for the statistical analysis of shape graph datasets, namely geometric networks embedded in 2D or 3D spaces. Unlike traditional abstract graphs, our purpose is not only to retrieve and distinguish variations in the connectivity structure of the data but also geometric differences of the network branches. Our proposed approach relies on the extraction of a specifically curated and explicit set of topological, geometric and directional features, designed to satisfy key invariance properties. We leverage the resulting feature representation for tasks such as group comparison, clustering and classification on cohorts of shape graphs. The effectiveness of this representation is evaluated on several real-world datasets including urban road/street networks, neuronal traces and astrocyte imaging. These results are benchmarked against several alternative methods, both feature-based and not.",
        "keywords": [
          "cs.LG",
          "stat.AP",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16120v1",
        "authors": [
          "Murad Hossen",
          "Demetrio Labate",
          "Nicolas Charon"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.AP",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "EU",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.232209"
    },
    {
      "id": "arxiv-2602.16111v1",
      "title": "Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16111v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Online media platforms often need to measure how frequently users are exposed to specific content attributes in order to evaluate trade-offs in A/B experiments. A direct approach is to sample content, label it using a high-quality rubric (e.g., an expert-reviewed LLM prompt), and estimate impression-weighted prevalence. However, repeatedly running such labeling for every experiment arm and segment is too costly and slow to serve as a default measurement at scale. We present a scalable \\emph{surrogate-based prevalence measurement} framework that decouples expensive labeling from per-experiment evaluation. The framework calibrates a surrogate signal to reference labels offline and then uses only impression logs to estimate prevalence for arbitrary experiment arms and segments. We instantiate this framework using \\emph{score bucketing} as the surrogate: we discretize a model score into buckets, estimate bucket-level prevalences from an offline labeled sample, and combine these calibrated bucket level prevalences with the bucket distribution of impressions in each arm to obtain fast, log-based estimates. Across multiple large-scale A/B tests, we validate that the surrogate estimates closely match the reference estimates for both arm-level prevalence and treatment--control deltas. This enables scalable, low-latency prevalence measurement in experimentation without requiring per-experiment labeling jobs.",
        "keywords": [
          "stat.AP",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16111v1",
        "authors": [
          "Zehao Xu",
          "Tony Paek",
          "Kevin O'Sullivan",
          "Attila Dobi"
        ],
        "arxiv_categories": [
          "stat.AP",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Based Prevalence Measurement",
        "Testing Online",
        "Framework",
        "LLM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.232594"
    },
    {
      "id": "arxiv-2602.16099v1",
      "title": "Quantifying and Attributing Submodel Uncertainty in Stochastic Simulation Models and Digital Twins",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16099v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Stochastic simulation is widely used to study complex systems composed of various interconnected subprocesses, such as input processes, routing and control logic, optimization routines, and data-driven decision modules. In practice, these subprocesses may be inherently unknown or too computationally intensive to directly embed in the simulation model. Replacing these elements with estimated or learned approximations introduces a form of epistemic uncertainty that we refer to as submodel uncertainty. This paper investigates how submodel uncertainty affects the estimation of system performance metrics. We develop a framework for quantifying submodel uncertainty in stochastic simulation models and extend the framework to digital-twin settings, where simulation experiments are repeatedly conducted with the model initialized from observed system states. Building on approaches from input uncertainty analysis, we leverage bootstrapping and Bayesian model averaging to construct quantile-based confidence or credible intervals for key performance indicators. We propose a tree-based method that decomposes total output variability and attributes uncertainty to individual submodels in the form of importance scores. The proposed framework is model-agnostic and accommodates both parametric and nonparametric submodels under frequentist and Bayesian modeling paradigms. A synthetic numerical experiment and a more realistic digital-twin simulation of a contact center illustrate the importance of understanding how and how much individual submodels contribute to overall uncertainty.",
        "keywords": [
          "stat.CO",
          "stat.ME",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16099v1",
        "authors": [
          "Mohammadmahdi Ghasemloo",
          "David J. Eckman",
          "Yaxian Li"
        ],
        "arxiv_categories": [
          "stat.CO",
          "stat.ME",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Attributing Submodel Uncertainty",
        "Stochastic Simulation Models",
        "Digital Twins Stochastic",
        "Framework",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.233013"
    },
    {
      "id": "arxiv-2602.16065v1",
      "title": "Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated Recursive Training",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16065v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Generative Artificial Intelligence (AI), such as large language models (LLMs), has become a transformative force across science, industry, and society. As these systems grow in popularity, web data becomes increasingly interwoven with this AI-generated material and it is increasingly difficult to separate them from naturally generated content. As generative models are updated regularly, later models will inevitably be trained on mixtures of human-generated data and AI-generated data from earlier versions, creating a recursive training process with data contamination. Existing theoretical work has examined only highly simplified settings, where both the real data and the generative model are discrete or Gaussian, where it has been shown that such recursive training leads to model collapse. However, real data distributions are far more complex, and modern generative models are far more flexible than Gaussian and linear mechanisms. To fill this gap, we study recursive training in a general framework with minimal assumptions on the real data distribution and allow the underlying generative model to be a general universal approximator. In this framework, we show that contaminated recursive training still converges, with a convergence rate equal to the minimum of the baseline model's convergence rate and the fraction of real data used in each iteration. To the best of our knowledge, this is the first (positive) theoretical result on recursive training without distributional assumptions on the data. We further extend the analysis to settings where sampling bias is present in data collection and support all theoretical results with empirical studies.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "math.ST",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16065v1",
        "authors": [
          "Kevin Wang",
          "Hongqian Niu",
          "Didong Li"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "math.ST",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Contaminated Recursive Training Generative",
        "Can Generative Artificial Intelligence",
        "Survive Data Contamination",
        "Artificial Intelligence",
        "Framework",
        "Intel",
        "EPA",
        "LLM",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.233466"
    },
    {
      "id": "arxiv-2602.16041v1",
      "title": "Predictive Subsampling for Scalable Inference in Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16041v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Network datasets appear across a wide range of scientific fields, including biology, physics, and the social sciences. To enable data-driven discoveries from these networks, statistical inference techniques like estimation and hypothesis testing are crucial. However, the size of modern networks often exceeds the storage and computational capacities of existing methods, making timely, statistically rigorous inference difficult. In this work, we introduce a subsampling-based approach aimed at reducing the computational burden associated with estimation and two-sample hypothesis testing. Our strategy involves selecting a small random subset of nodes from the network, conducting inference on the resulting subgraph, and then using interpolation based on the observed connections between the subsample and the rest of the nodes to estimate the entire graph. We develop the methodology under the generalized random dot product graph framework, which affords broad applicability and permits rigorous analysis. Within this setting, we establish consistency guarantees and corroborate the practical effectiveness of the approach through comprehensive simulation studies.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16041v1",
        "authors": [
          "Arpan Kumar",
          "Minh Tang",
          "Srijan Sengupta"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Predictive Subsampling",
        "Scalable Inference",
        "Networks Network",
        "Framework",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.233973"
    },
    {
      "id": "arxiv-2602.16040v1",
      "title": "Covariate Adjustment for Wilcoxon Two Sample Statistic and Test",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16040v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We apply covariate adjustment to the Wincoxon two sample statistic and Wincoxon-Mann-Whitney test in comparing two treatments. The covariate adjustment through calibration not only improves efficiency in estimation/inference but also widens the application scope of the Wilcoxon two sample statistic and Wincoxon-Mann-Whitney test to situations where covariate-adaptive randomization is used. We motivate how to adjust covariates to reduce variance, establish the asymptotic distribution of adjusted Wincoxon two sample statistic, and provide explicitly the guaranteed efficiency gain. The asymptotic distribution of adjusted Wincoxon two sample statistic is invariant to all commonly used covariate-adaptive randomization schemes so that a unified formula can be used in inference regardless of which covariate-adaptive randomization is applied.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16040v1",
        "authors": [
          "Zhilan Lou",
          "Jun Shao",
          "Ting Ye",
          "Tuo Wang",
          "Yanyao Yi"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Wilcoxon Two Sample Statistic",
        "Covariate Adjustment",
        "Test We",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.234236"
    },
    {
      "id": "arxiv-2602.16031v1",
      "title": "Competing Risk Analysis in Cardiovascular Outcome Trials: A Simulation Comparison of Cox and Fine-Gray Models",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16031v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Cardiovascular outcome trials commonly face competing risks when non-CV death prevents observation of major adverse cardiovascular events (MACE). While Cox proportional hazards models treat competing events as independent censoring, Fine-Gray subdistribution hazard models explicitly handle competing risks, targeting different estimands. This simulation study using bivariate copula models systematically varies competing event rates (0.5%-5% annually), treatment effects on competing events (50% reduction to 50% increase), and correlation structures to compare these approaches. At competing event rates typical of CV outcome trials (~1% annually), Cox and Fine-Gray produce nearly identical hazard ratio estimates regardless of correlation strength or treatment effect direction. Substantial divergence occurs only with high competing rates and directionally discordant treatment effects, though neither estimator provides unbiased estimates of true marginal hazard ratios under these conditions. In typical CV trial settings with low competing event rates, Cox models remain appropriate for primary analysis due to superior interpretability. Pre-specified Cox models should not be abandoned for competing risk methods. Importantly, Fine-Gray models do not constitute proper sensitivity analyses to Cox models per ICH E9(R1), as they target different estimands rather than testing assumptions. As supplementary analysis, cumulative incidence using Aalen-Johansen estimator can provide transparency about competing risk impact. Under high competing-risk scenarios, alternative approaches such as inverse probability of censoring weighting, multiple imputation, or inclusion of all-cause mortality in primary endpoints warrant consideration.",
        "keywords": [
          "stat.ME",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16031v1",
        "authors": [
          "Tuo Wang",
          "Yu Du"
        ],
        "arxiv_categories": [
          "stat.ME",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cardiovascular Outcome Trials",
        "Gray Models Cardiovascular",
        "Competing Risk Analysis",
        "Simulation Comparison",
        "While Cox",
        "MACE",
        "Act",
        "ICH",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.234704"
    },
    {
      "id": "arxiv-2602.15972v1",
      "title": "Fast Online Learning with Gaussian Prior-Driven Hierarchical Unimodal Thompson Sampling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15972v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "We study a type of Multi-Armed Bandit (MAB) problems in which arms with a Gaussian reward feedback are clustered. Such an arm setting finds applications in many real-world problems, for example, mmWave communications and portfolio management with risky assets, as a result of the universality of the Gaussian distribution. Based on the Thompson Sampling algorithm with Gaussian prior (TSG) algorithm for the selection of the optimal arm, we propose our Thompson Sampling with Clustered arms under Gaussian prior (TSCG) specific to the 2-level hierarchical structure. We prove that by utilizing the 2-level structure, we can achieve a lower regret bound than we do with ordinary TSG. In addition, when the reward is Unimodal, we can reach an even lower bound on the regret by our Unimodal Thompson Sampling algorithm with Clustered Arms under Gaussian prior (UTSCG). Each of our proposed algorithms are accompanied by theoretical evaluation of the upper regret bound, and our numerical experiments confirm the advantage of our proposed algorithms.",
        "keywords": [
          "cs.LG",
          "stat.ML"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15972v1",
        "authors": [
          "Tianchi Zhao",
          "He Liu",
          "Hongyin Shi",
          "Jinliang Li"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.ML"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Driven Hierarchical Unimodal Thompson",
        "Unimodal Thompson Sampling",
        "Fast Online Learning",
        "Thompson Sampling",
        "Clustered Arms",
        "Gaussian Prior",
        "Armed Bandit",
        "Sampling We",
        "UTSCG",
        "TSCG",
        "MAB",
        "TSG",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.235024"
    },
    {
      "id": "arxiv-2602.15955v1",
      "title": "Adaptive Semi-Supervised Training of P300 ERP-BCI Speller System with Minimum Calibration Effort",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15955v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "A P300 ERP-based Brain-Computer Interface (BCI) speller is an assistive communication tool. It searches for the P300 event-related potential (ERP) elicited by target stimuli, distinguishing it from the neural responses to non-target stimuli embedded in electroencephalogram (EEG) signals. Conventional methods require a lengthy calibration procedure to construct the binary classifier, which reduced overall efficiency. Thus, we proposed a unified framework with minimum calibration effort such that, given a small amount of labeled calibration data, we employed an adaptive semi-supervised EM-GMM algorithm to update the binary classifier. We evaluated our method based on character-level prediction accuracy, information transfer rate (ITR), and BCI utility. We applied calibration on training data and reported results on testing data. Our results indicate that, out of 15 participants, 9 participants exceed the minimum character-level accuracy of 0.7 using either on our adaptive method or the benchmark, and 7 out of these 9 participants showed that our adaptive method performed better than the benchmark. The proposed semi-supervised learning framework provides a practical and efficient alternative to improve the overall spelling efficiency in the real-time BCI speller system, particularly in contexts with limited labeled data.",
        "keywords": [
          "cs.LG",
          "stat.AP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15955v1",
        "authors": [
          "Shumeng Chen",
          "Jane E. Huggins",
          "Tianwen Ma"
        ],
        "arxiv_categories": [
          "cs.LG",
          "stat.AP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Minimum Calibration Effort",
        "Supervised Training",
        "Computer Interface",
        "Speller System",
        "Adaptive Semi",
        "Framework",
        "ERP",
        "EEG",
        "NSF",
        "Act",
        "ITR",
        "MIT",
        "GMM",
        "BCI",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.235398"
    },
    {
      "id": "arxiv-2602.15809v1",
      "title": "Decision Quality Evaluation Framework at Pinterest",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15809v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed and deployed at Pinterest. The framework is centered on a high-trust Golden Set (GDS) curated by subject matter experts (SMEs), which serves as a ground truth benchmark. We introduce an automated intelligent sampling pipeline that uses propensity scores to efficiently expand dataset coverage. We demonstrate the framework's practical application in several key areas: benchmarking the cost-performance trade-offs of various LLM agents, establishing a rigorous methodology for data-driven prompt optimization, managing complex policy evolution, and ensuring the integrity of policy content prevalence metrics via continuous validation. The framework enables a shift from subjective assessments to a data-driven and quantitative practice for managing content safety systems.",
        "keywords": [
          "stat.AP",
          "cs.AI"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15809v1",
        "authors": [
          "Yuqi Tian",
          "Robert Paine",
          "Attila Dobi",
          "Kevin O'Sullivan",
          "Aravindh Manickavasagam"
        ],
        "arxiv_categories": [
          "stat.AP",
          "cs.AI"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Decision Quality Evaluation Framework",
        "Large Language Models",
        "Pinterest Online",
        "Golden Set",
        "Framework",
        "Policy",
        "Intel",
        "LLM",
        "Act",
        "GDS",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.235750"
    },
    {
      "id": "arxiv-2602.15925v1",
      "title": "Robust Stochastic Gradient Posterior Sampling with Lattice Based Discretisation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15925v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Stochastic-gradient MCMC methods enable scalable Bayesian posterior sampling but often suffer from sensitivity to minibatch size and gradient noise. To address this, we propose Stochastic Gradient Lattice Random Walk (SGLRW), an extension of the Lattice Random Walk discretization. Unlike conventional Stochastic Gradient Langevin Dynamics (SGLD), SGLRW introduces stochastic noise only through the off-diagonal elements of the update covariance; this yields greater robustness to minibatch size while retaining asymptotic correctness. Furthermore, as comparison we analyze a natural analogue of SGLD utilizing gradient clipping. Experimental validation on Bayesian regression and classification demonstrates that SGLRW remains stable in regimes where SGLD fails, including in the presence of heavy-tailed gradient noise, and matches or improves predictive performance.",
        "keywords": [
          "stat.ML",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15925v1",
        "authors": [
          "Zier Mensch",
          "Lars Holdijk",
          "Samuel Duffield",
          "Maxwell Aifer",
          "Patrick J. Coles"
        ],
        "arxiv_categories": [
          "stat.ML",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Lattice Based Discretisation Stochastic",
        "Stochastic Gradient Langevin Dynamics",
        "Robust Stochastic Gradient Posterior",
        "Stochastic Gradient Lattice Random",
        "Lattice Random Walk",
        "SGLRW",
        "MCMC",
        "SGLD",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.236028"
    },
    {
      "id": "arxiv-2602.15731v1",
      "title": "Generalised Exponential Kernels for Nonparametric Density Estimation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15731v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This paper introduces a novel kernel density estimator (KDE) based on the generalised exponential (GE) distribution, designed specifically for positive continuous data. The proposed GE KDE offers a mathematically tractable form that avoids the use of special functions, for instance, distinguishing it from the widely used gamma KDE, which relies on the gamma function. Despite its simpler form, the GE KDE maintains similar flexibility and shape characteristics, aligning with distributions such as the gamma, which are known for their effectiveness in modelling positive data. We derive the asymptotic bias and variance of the proposed kernel density estimator, and formally demonstrate the order of magnitude of the remaining terms in these expressions. We also propose a second GE KDE, for which we are able to show that it achieves the optimal mean integrated squared error, something that is difficult to establish for the former. Through numerical experiments involving simulated and real data sets, we show that GE KDEs can be an important alternative and competitive to existing KDEs.",
        "keywords": [
          "stat.ME"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15731v1",
        "authors": [
          "Laura M. Craig",
          "Wagner Barreto-Souza"
        ],
        "arxiv_categories": [
          "stat.ME"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Generalised Exponential Kernels",
        "Act",
        "KDE",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:28.236341"
    },
    {
      "id": "arxiv-2602.16633v1",
      "title": "Behavioral change models for infectious disease transmission: a systematic review (2020-2025)",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16633v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Background: Human behavior shapes infectious disease dynamics, yet its integration into transmission models remains fragmented. Recent epidemics, particularly COVID-19, highlight the need for models capturing adaptation to perceived risk, social influence, and policy signals. This review synthesizes post-2020 models incorporating behavioral adaptation, examines their theoretical grounding, and evaluates how behavioral constructs modify transmission, vaccination, and compliance. Methods: Following PRISMA guidelines, we searched Scopus and PubMed (2020-2025), screening 1,274 records with citation chaining. We extracted data on disease context, country, modeling framework, behavioral mechanisms (prevalence-dependent, policy/media, imitation/social learning), and psychosocial constructs (personal threat, coping appraisal, barriers, social norms, cues to action). A total of 216 studies met inclusion criteria. Results: COVID-19 accounted for 73% of studies. Most used compartmental ODE models (81%) and focused on theoretical or U.S. settings. Behavioral change was mainly reactive: 47% applied prevalence-dependent feedback, 25% included awareness/media dynamics, and 19% relied on exogenous policy triggers. Game-theoretic or social learning approaches were rare (less or equal than 5%). Behavioral effects primarily modified contact or transmission rates (91%). Psychosocial constructs were unevenly represented: cues to action (n=159) and personal threat (n=145) dominated, whereas coping appraisal (n=82), barriers (n=36), and social norms (n=25) were less common. Conclusions: We propose a taxonomy structured by behavioral drivers, social scale, and memory to clarify dominant paradigms and their empirical basis. Mapping models to psychosocial constructs provides guidance for more theory-informed and data grounded-integration of behavioral processes in epidemiological modeling.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16633v1",
        "authors": [
          "Youngji Jo",
          "Sileshi Sintayehu Sharbayta",
          "Bruno Buonomo"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Framework",
        "Guideline",
        "COVID-19",
        "Policy",
        "PRISMA",
        "COVID",
        "ODE",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:48:33.416599"
    },
    {
      "id": "arxiv-2602.16584v1",
      "title": "The Representational Alignment Hypothesis: Evidence for and Consequences of Invariant Semantic Structure Across Embedding Modalities",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16584v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "There is growing evidence that independently trained AI systems come to represent the world in the same way. In other words, independently trained embeddings from text, vision, audio, and neural signals share an underlying geometry. We call this the Representational Alignment Hypothesis (RAH) and investigate evidence for and consequences of this claim. The evidence is of two kinds: (i) internal structure comparison techniques, such as representational similarity analysis and topological data analysis, reveal matching relational patterns across modalities without explicit mapping; and (ii) methods based on cross-modal embedding alignment, which learn mappings between representation spaces, show that simple linear transformations can bring different embedding spaces into close correspondence, suggesting near-isomorphism. Taken together, the evidence suggests that, even after controlling for trivial commonalities inherent in standard data preprocessing and embedding procedures, a robust structural correspondence persists, hinting at an underlying organizational principle. Some have argued that this result shows that the shared structure is getting at a fundamental, Platonic level of reality. We argue that this conclusion is unjustified. Moreover, we aim to give the idea an alternative philosophical home, rooted in contemporary metasemantics (i.e., theories of what makes a representation and what makes something meaningful) and responses to the symbol grounding problem. We conclude by considering the scope of the RAH and proposing new ways of distinguishing semantic structures that are genuinely invariant from those that inevitably arise due to the fact that all our data is generated under human-specific conditions on Earth.",
        "keywords": [
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16584v1",
        "authors": [
          "Akhil Ramidi",
          "Kevin Scharp"
        ],
        "arxiv_categories": [
          "q-bio.NC"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Representational Alignment Hypothesis",
        "Invariant Semantic Structure Across",
        "Standard",
        "Meta",
        "NSF",
        "Act",
        "RAH",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-19T14:48:33.417241"
    },
    {
      "id": "arxiv-2602.16504v1",
      "title": "GRIMM: Genetic stRatification for Inference in Molecular Modeling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16504v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The vast majority of biological sequences encode unknown functions and bear little resemblance to experimentally characterized proteins, limiting both our understanding of biology and our ability to harness functional potential for the bioeconomy. Predicting enzyme function from sequence remains a central challenge in computational biology, complicated by low sequence diversity and imbalanced label support in publicly available datasets. Models trained on these data can overestimate performance and fail to generalize. To address this, we introduce GRIMM (Genetic stRatification for Inference in Molecular Modeling), a benchmark for enzyme function prediction that employs genetic stratification: sequences are clustered by similarity and clusters are assigned exclusively to training, validation, or test sets. This ensures that sequences from the same cluster do not appear in multiple partitions. GRIMM produces multiple test sets: a closed-set test with the same label distribution as training (Test-1) and an open-set test containing novel labels (Test-2), serving as a realistic out-of-distribution proxy for discovering novel enzyme functions. While demonstrated on enzymes, this approach is generalizable to any sequence-based classification task where inputs can be clustered by similarity. By formalizing a splitting strategy often used implicitly, GRIMM provides a unified and reproducible framework for closed- and open-set evaluation. The method is lightweight, requiring only sequence clustering and label annotations, and can be adapted to different similarity thresholds, data scales, and biological tasks. GRIMM enables more realistic evaluation of functional prediction models on both familiar and unseen classes and establishes a benchmark that more faithfully assesses model performance and generalizability.",
        "keywords": [
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16504v1",
        "authors": [
          "Ashley Babjac",
          "Adrienne Hoarfrost"
        ],
        "arxiv_categories": [
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Molecular Modeling",
        "Framework",
        "Test-1",
        "Test-2",
        "GRIMM",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.417762"
    },
    {
      "id": "arxiv-2602.16357v1",
      "title": "Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16357v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \\textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth.",
        "keywords": [
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16357v1",
        "authors": [
          "Sarkis Ter Martirosyan",
          "Xinyue Huang",
          "David Qin",
          "Anthony Yu",
          "Stanislav Emelianov"
        ],
        "arxiv_categories": [
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Spectroscopic Photoacoustic Images",
        "Informed Neural Networks Accurate",
        "Inversion Autoencoder",
        "Spectral Unmixing",
        "Optical Inversion",
        "Neural Network",
        "SPOI",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.418153"
    },
    {
      "id": "arxiv-2602.16129v1",
      "title": "Oscillation Criteria in Large-Scale Gene Regulatory Networks with Intrinsic Fluctuations",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16129v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Gene Regulatory Networks(GRNs) with feedback are essential components of many cellular processes and may exhibit oscillatory behavior. Analyzing such systems becomes increasingly complex as the number of components increases. Since gene regulation often involves a small number of molecules, fluctuations are inevitable. Therefore, it is important to understand how fluctuations affect the oscillatory dynamics of cellular processes, as this will allow comprehension of the mechanisms that enable cellular functions to remain even in the presence of fluctuations or, failing that, to determine the limit of fluctuations that permits various cellular functions. In this study, we investigated the conditions under which GRNs with feedback and intrinsic fluctuations exhibit oscillatory behavior. Our focus was on developing a procedure that would be both manageable and practical, even for extensive regulatory networks, that is, those comprising numerous nodes. Using the second-moment approach, we described the stochastic dynamics through a set of ordinary differential equations for the mean concentration and its second central moment. The system can attain either a stable equilibrium or oscillatory behavior, depending on its scale and, consequently, the intensity of fluctuations. To illustrate the procedure, we analyzed two relevant systems: a repressilator with three nodes and a system with five nodes, both incorporating intrinsic fluctuations. In both cases, it was observed that for very small systems, which therefore exhibit significant fluctuations, oscillatory behavior is inhibited. The procedure presented here for analyzing the stability of oscillations under fluctuations enables the determination of the critical minimum size of GRNs at which intrinsic fluctuations do not eliminate their cyclical behavior.",
        "keywords": [
          "q-bio.MN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16129v1",
        "authors": [
          "Manuel Eduardo Hernández-García",
          "Jorge Velázquez-Castro"
        ],
        "arxiv_categories": [
          "q-bio.MN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Intrinsic Fluctuations Gene Regulatory",
        "Scale Gene Regulatory Networks",
        "Oscillation Criteria",
        "Regulation",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.418931"
    },
    {
      "id": "arxiv-2602.16072v1",
      "title": "Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16072v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches are typically developed on single-center datasets that are inconsistent in format and metadata, lack standardized benchmarks, and rarely release pathological event annotations, creating barriers to reproducibility, cross-center validation, and clinical relevance. With extensive efforts to reconcile heterogeneous iEEG formats, metadata, and recordings across publicly available sources, we present $\\textbf{Omni-iEEG}$, a large-scale, pre-surgical iEEG resource comprising $\\textbf{302 patients}$ and $\\textbf{178 hours}$ of high-resolution recordings. The dataset includes harmonized clinical metadata such as seizure onset zones, resections, and surgical outcomes, all validated by board-certified epileptologists. In addition, Omni-iEEG provides over 36K expert-validated annotations of pathological events, enabling robust biomarker studies. Omni-iEEG serves as a bridge between machine learning and epilepsy research. It defines clinically meaningful tasks with unified evaluation metrics grounded in clinical priors, enabling systematic evaluation of models in clinically relevant settings. Beyond benchmarking, we demonstrate the potential of end-to-end modeling on long iEEG segments and highlight the transferability of representations pretrained on non-neurophysiological domains. Together, these contributions establish Omni-iEEG as a foundation for reproducible, generalizable, and clinically translatable epilepsy research. The project page with dataset and code links is available at omni-ieeg.github.io/omni-ieeg.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16072v1",
        "authors": [
          "Chenda Duan",
          "Yipeng Zhang",
          "Sotaro Kanai",
          "Yuanyi Ding",
          "Atsuro Daida"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "q-bio.NC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Epilepsy Research Epilepsy",
        "Machine Learning",
        "Standard",
        "Meta",
        "NSF",
        "EEG",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.419831"
    },
    {
      "id": "arxiv-2602.16059v1",
      "title": "Properties of biodiversity indices that model future extinction risk",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16059v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The loss of biodiversity due to the likely widespread extinction of species in the near future is a focus of current concern in conservation biology. One approach to measure the impact of this extinction is based on the predicted loss of phylogenetic diversity. These predictions have become a focus of the Zoological Society of London's 'EDGE2' program for quantifying biodiversity loss and involves considering the HED (heightened evolutionary distinctiveness) and HEDGE (heightened evolutionary distinctiveness and globally endangered) indices. Here, we show how to generalise the HED(GE) indices by expanding their application to more general settings (to phylogenetic networks, to feature diversity on discrete traits, and to arbitrary biodiversity measures). We provide a simple and explicit description of the mean and variance of such measures, and illustrate our results by an application to the phylogeny of all 27 extant Crocodilians. We also derive various equalities for feature diversity, and an inequality if species extinction rates are correlated with feature types.",
        "keywords": [
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16059v1",
        "authors": [
          "Mike Steel",
          "Kristina Wicke",
          "Arne Mooers"
        ],
        "arxiv_categories": [
          "q-bio.PE"
        ],
        "steeps_mapping": "S_Social"
      },
      "entities": [
        "Zoological Society",
        "HEDGE",
        "HED",
        "Act",
        "AI"
      ],
      "preliminary_category": "S",
      "collected_at": "2026-02-19T14:48:33.420190"
    },
    {
      "id": "arxiv-2602.16022v1",
      "title": "The lingering phenomenon and pattern formation in a nonlocal population model with cognitive map",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16022v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The rates at which individuals memorize and forget environmental information strongly influence their movement paths and long-term space use. To understand how these cognitive time scales shape population-level patterns, we propose and analyze a nonlocal population model with a cognitive map. The population density moves by a Fokker--Planck type diffusion driven by a cognitive map that stores a habitat quality information nonlocally. The map is updated through local presence with learning and forgetting rates, and we consider both truncated and normalized perception kernels. We first study the movement-only system without growth. We show that finite perceptual range generates spatial heterogeneity in the cognitive map even in nearly homogeneous habitats, and we prove a lingering phenomenon on unimodal landscapes: for the fixed high learning rate, the peak density near the best location is maximized at an intermediate forgetting rate. We then couple cognitive diffusion to logistic growth. We establish local well-posedness and persistence by proving instability of the extinction equilibrium and the existence of a positive steady state, with uniqueness under an explicit condition on the motility function. Numerical simulations show that lingering persists under logistic growth and reveal a trade-off between the lingering and total population size, since near the strongest-lingering regime the total mass can fall below the total resource, in contrast to classical random diffusive--logistic models.",
        "keywords": [
          "math.AP",
          "q-bio.PE"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16022v1",
        "authors": [
          "Kyung-Han Choi",
          "Thomas Hillen"
        ],
        "arxiv_categories": [
          "math.AP",
          "q-bio.PE"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Fusion",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.420642"
    },
    {
      "id": "arxiv-2602.16004v1",
      "title": "Time-Varying Directed Interactions in Functional Brain Networks: Modeling and Validation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16004v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Understanding the dynamic nature of brain connectivity is critical for elucidating neural processing, behavior, and brain disorders. Traditional approaches such as sliding-window correlation (SWC) characterize time-varying undirected associations but do not resolve directional interactions, limiting inference about time-resolved information flow in brain networks. We introduce sliding-window prediction correlation (SWpC), which embeds a directional linear time-invariant (LTI) model within each sliding window to estimate time-varying directed functional connectivity (FC). SWpC yields two complementary descriptors of directed interactions: a strength measure (prediction correlation) and a duration measure (window-wise duration of information transfer). Using concurrent local field potential (LFP) and fMRI BOLD recordings from rat somatosensory cortices, we demonstrate stable directionality estimates in both LFP band-limited power and BOLD. Using Human Connectome Project (HCP) motor task fMRI, SWpC detects significant task-evoked changes in directed FC strength and duration and shows higher sensitivity than SWC for identifying task-evoked connectivity differences. Finally, in post-concussion vestibular dysfunction (PCVD), SWpC reveals reproducible vestibular-multisensory brain-state shifts and improves healthy-control vs subacute patient (HC-ST) discrimination using state-derived features. Together, these results show that SWpC provides biologically interpretable, time-resolved directed connectivity patterns across multimodal validation and clinical application settings, supporting both basic and translational neuroscience.",
        "keywords": [
          "q-bio.NC",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16004v1",
        "authors": [
          "Nan Xu",
          "Xiaodi Zhang",
          "Wen-Ju Pan",
          "Jeremy L. Smith",
          "Eric H. Schumacher"
        ],
        "arxiv_categories": [
          "q-bio.NC",
          "q-bio.QM"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Using Human Connectome Project",
        "Varying Directed Interactions",
        "Functional Brain Networks",
        "Validation Understanding",
        "BOLD",
        "Wind",
        "PCVD",
        "SWC",
        "LFP",
        "LTI",
        "HCP",
        "NSF",
        "Act",
        "MIT",
        "EU"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-19T14:48:33.421131"
    },
    {
      "id": "arxiv-2602.15787v1",
      "title": "Energy budgets govern synaptic precision and its regulation during plasticity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15787v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Synaptic transmission must balance the need for reliable signalling against the metabolic cost of achieving that reliability. How energetic constraints shape synaptic precision and its regulation during plasticity remains unclear. Here we develop an energy--constrained framework in which synapses minimise postsynaptic response variance subject to a fixed mean and an effective energy budget. Combinations of candidate physiological costs are used to estimate an energy cost for synaptic transmission; this cost is then inferred from quantal statistics. Analysing five published pre- and post-plasticity datasets, we find that observed synaptic mean--variance pairs cluster near a minimal-energy boundary, indicating that precision is limited by energetic availability. Model comparison identifies a dominant calcium pump-like cost paired with a smaller vesicle turnover-like cost, yielding a separable precision--energy relationship, $σ^{-2} \\propto E^5$. We further show that plasticity systematically updates synaptic energy budgets according to the scale-free magnitude of mean change, enabling accurate prediction of post-plasticity variance from energy allocation alone. These results provide direct experimental support for the hypothesis that synaptic precision is governed by energy budgets, establishing energy allocation as a fundamental principle linking metabolic constraints, synaptic reliability, and plasticity.",
        "keywords": [
          "q-bio.NC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15787v1",
        "authors": [
          "James Malkin",
          "Cian O'Donnell",
          "Conor Houghton"
        ],
        "arxiv_categories": [
          "q-bio.NC"
        ],
        "steeps_mapping": "s_spiritual"
      },
      "entities": [
        "Regulation",
        "Framework",
        "Meta",
        "EPA",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "s",
      "collected_at": "2026-02-19T14:48:33.422154"
    },
    {
      "id": "arxiv-2602.15691v1",
      "title": "Relating biomarkers and phenotypes using dynamical trap spaces",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15691v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Connecting the dynamics of biomolecular networks to experimentally measurable cell phenotypes remains a central challenge in systems biology. Here we introduce a model-based definition of phenotype as a partial steady state that is committed to a certain dynamical outcome while otherwise being minimally constrained. We focus on Boolean models and define \\emph{dynamical phenotypes} as complete trap spaces that maximally specify a chosen set of phenotype-determining nodes that correspond to biomarkers while keeping external inputs unconstrained. We show that dynamical phenotypes can be efficiently identified without full attractor enumeration. Using four published models, including a 70-node Boolean model of T cell differentiation, we show that dynamical phenotypes recover known cell types and activation states, and indicate the environmental conditions ensuring their existence. We also propose a method to identify informative phenotype-determining nodes based on the canalization of the Boolean functions. This method reveals biologically relevant cell state information that is complementary to the phenotypes manually defined by model creators and is validated by two attractor-based approaches. Our results demonstrate that dynamical phenotypes provide a scalable framework for linking model structure, external inputs, and phenotypic outcomes, and offer a principled tool for model-guided biomarker selection.",
        "keywords": [
          "q-bio.MN"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15691v1",
        "authors": [
          "Samuel Pastva",
          "Kyu Hyong Park",
          "Jordan C. Rozum",
          "Van-Giang Trinh",
          "Réka Albert"
        ],
        "arxiv_categories": [
          "q-bio.MN"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.422689"
    },
    {
      "id": "arxiv-2602.15677v1",
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15677v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
        "keywords": [
          "cs.LG",
          "q-bio.QM"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15677v1",
        "authors": [
          "Neelay Velingker",
          "Alaia Solko-Breslin",
          "Mayank Keoliya",
          "Seewon Choi",
          "Jiayi Xin"
        ],
        "arxiv_categories": [
          "cs.LG",
          "q-bio.QM"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Forecasting Cardiac Events Electrocardiograms",
        "Language Model",
        "Framework",
        "CAMEL",
        "SOTA",
        "LLM",
        "ELM",
        "ECG",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:33.422894"
    },
    {
      "id": "arxiv-2602.16637v1",
      "title": "Active RIS-Assisted MIMO System for Vital Signs Extraction: ISAC Modeling, Deep Learning, and Prototype Measurements",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16637v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present the RIS-VSign system, an active reconfigurable intelligent surface (RIS)-assisted multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) framework for vital signs extraction under an integrated sensing and communication (ISAC) model. The system consists of two stages: the phase selector of RIS and the extraction of respiration rate. To mitigate synchronization-induced common phase drifts, the difference of Möbius transformation (DMT) is integrated into the deep learning framework, named DMTNet, to jointly configure multiple active RIS elements. Notably, the training data are generated in simulation without collecting real-world measurements, and the resulting phase selector is validated experimentally. For sensing, multi-antenna measurements are fused by the DC-offset calibration and the DeepMining-MMV processing with CA-CFAR detection and Newton's refinements. Prototype experiments indicate that active RIS deployment improves respiration detectability while simultaneously enabling higher-order modulation; without RIS, respiration detection is unreliable and only lower-order modulation is supported.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16637v1",
        "authors": [
          "De-Ming Chian",
          "Chao-Kai Wen",
          "Feng-Ji Chen",
          "Yi-Jie Sun",
          "Fu-Kang Wang"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Prototype Measurements We",
        "Vital Signs Extraction",
        "Deep Learning",
        "Framework",
        "Intel",
        "CFAR",
        "MIMO",
        "ISAC",
        "OFDM",
        "MMV",
        "NSF",
        "Act",
        "RIS",
        "MIT",
        "WTO"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.604384"
    },
    {
      "id": "arxiv-2602.16565v1",
      "title": "Optimal Placement and Sizing of PV-Based DG Units in a Distribution Network Considering Loading Capacity",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16565v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This research paper proposes an efficient methodology for the allocation of multiple photovoltaic (PV)-based distributed generation (DG) units in the radial distribution network (RDN), while considering the loading capacity of the network. The proposed method is structured using a two-stage approach. In the first stage, the additional active power loading capacity of the network and each individual bus is determined using an iterative approach. This analysis quantifies the network's additional active loadability limits and identifies buses with high active power loading capacity, which are considered candidate nodes for the placement of DG units. Subsequently, in the second stage, the optimal locations and sizes of DG units are determined using the Monte Carlo method, with the objectives of minimizing voltage deviation and reducing active power losses in the network. The methodology is validated on the standard IEEE 33-bus RDN to determine the optimal locations and sizes of DG units. The results demonstrate that the optimal allocation of one, two, and three DG units, achieved from proposed method, reduces network active power losses by 50.37%, 58.62%, and 65.16%, respectively, and also significantly enhances the voltage profile across all buses. When the obtained results are compared with the results of several existing studies, it is found that the proposed method allows for larger DG capacities and maintains better voltage profiles throughout the RDN.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16565v1",
        "authors": [
          "Abhinav Sharma",
          "Pratyush Chakraborty",
          "Manoj Datta",
          "Kazi N. Hasan"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distribution Network Considering Loading",
        "Optimal Placement",
        "Monte Carlo",
        "Standard",
        "IEEE",
        "RDN",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.605031"
    },
    {
      "id": "arxiv-2602.16546v1",
      "title": "Failure-Aware Access Point Selection for Resilient Cell-Free Massive MIMO Networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16546v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper presents a Failure-Aware Access Point Selection (FAAS) method aimed at improving hardware resilience in cell-free massive MIMO (CF-mMIMO) networks. FAAS selects APs for each user by jointly considering channel strength and the failure probability of each AP. A tunable parameter \\(α\\in [0,1]\\) scales these failure probabilities to model different levels of network stress. We evaluate resilience using two key metrics: the minimum-user spectral efficiency, which captures worst-case user performance, and the outage probability, defined as the fraction of users left without any active APs. Simulation results show that FAAS maintains significantly better performance under failure conditions compared to failure-agnostic clustering. At high failure levels, FAAS reduces outage by over 85\\% and improves worst-case user rates. These results confirm that FAAS is a practical and efficient solution for building more reliable CF-mMIMO networks.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16546v1",
        "authors": [
          "Mostafa Rahmani Ghourtani",
          "Junbo Zhao",
          "Yi Chu",
          "Hamed Ahmadi",
          "David Grace"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Aware Access Point Selection",
        "Resilient Cell",
        "Free Massive",
        "MIMO",
        "FAAS",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.605792"
    },
    {
      "id": "arxiv-2602.16475v1",
      "title": "Certifying Hamilton-Jacobi Reachability Learned via Reinforcement Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16475v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We present a framework to \\emph{certify} Hamilton--Jacobi (HJ) reachability learned by reinforcement learning (RL). Building on a discounted initial time \\emph{travel-cost} formulation that makes small-step RL value iteration provably equivalent to a forward Hamilton--Jacobi (HJ) equation with damping, we convert certified learning errors into calibrated inner/outer enclosures of strict backward reachable tube. The core device is an additive-offset identity: if $W_λ$ solves the discounted travel-cost Hamilton--Jacobi--Bellman (HJB) equation, then $W_\\varepsilon:=W_λ+ \\varepsilon$ solves the same PDE with a constant offset $λ\\varepsilon$. This means that a uniform value error is \\emph{exactly} equal to a constant HJB offset. We establish this uniform value error via two routes: (A) a Bellman operator-residual bound, and (B) a HJB PDE-slack bound. Our framework preserves HJ-level safety semantics and is compatible with deep RL. We demonstrate the approach on a double-integrator system by formally certifying, via satisfiability modulo theories (SMT), a value function learned through reinforcement learning to induce provably correct inner and outer backward-reachable set enclosures over a compact region of interest.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16475v1",
        "authors": [
          "Prashant Solanki",
          "Isabelle El-Hajj",
          "Jasper J. van Beers",
          "Erik-Jan van Kampen",
          "Coen C. de Visser"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Jacobi Reachability Learned",
        "Reinforcement Learning We",
        "Certifying Hamilton",
        "Framework",
        "LLM",
        "HJB",
        "Act",
        "PDE",
        "SMT",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.606642"
    },
    {
      "id": "arxiv-2602.16441v1",
      "title": "Proof of Concept: Local TX Real-Time Phase Calibration in MIMO Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16441v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Channel measurements in MIMO systems hinge on precise synchronization. While methods for time and frequency synchronization are well established, maintaining real-time phase coherence remains an open requirement for many MIMO systems. Phase coherence in MIMO systems is crucial for beamforming in digital arrays and enables precise parameter estimates such as Angle-of-Arrival/Departure. This work presents and validates a simple local real-time phase calibration method for a digital array. We compare two different approaches, instantaneous and smoothed calibration, to determine the optimal interval between synchronization procedures. To quantitatively assess calibration performance, we use two metrics: the average beamforming power loss and the RMS cycle-to-cycle jitter. Our results indicate that both approaches for phase calibration are effective and yield RMS of jitter in the 2.1 ps to 124 fs range for different SDR models. This level of precision enables coherent transmission on commonly available SDR platforms, allowing investigation on advanced MIMO techniques and transmit beamforming in practical testbeds.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16441v1",
        "authors": [
          "Carl Collmann",
          "Ahmad Nimr",
          "Gerhard Fettweis"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Time Phase Calibration",
        "Systems Channel",
        "MIMO",
        "EPA",
        "Act",
        "MIT",
        "RMS",
        "SDR",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.607176"
    },
    {
      "id": "arxiv-2602.16418v1",
      "title": "Reconstruction of Piecewise-Constant Sparse Signals for Modulo Sampling",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16418v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Modulo sampling is a promising technology to preserve amplitude information that exceeds the observable range of analog-to-digital converters during the digitization of analog signals. Since conventional methods typically reconstruct the original signal by estimating the differences of the residual signal and computing their cumulative sum, each estimation error inevitably propagates through subsequent time samples. In this paper, to eliminate this error-propagation problem, we propose an algorithm that reconstructs the residual signal directly. The proposed method takes advantage of the high-frequency characteristics of the modulo samples and the sparsity of both the residual signal and its difference. Simulation results show that the proposed method reconstructs the original signal more accurately than a conventional method based on the differences of the residual signal.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16418v1",
        "authors": [
          "Haruka Kobayashi",
          "Ryo Hayakawa"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Constant Sparse Signals",
        "Modulo Sampling Modulo",
        "Act"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.607581"
    },
    {
      "id": "arxiv-2602.16383v1",
      "title": "Joint beamforming and mode optimization for multi-functional STAR-RIS-aided integrated sensing and communication networks",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16383v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper investigates the design of integrated sensing and communication (ISAC) systems assisted by simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs), which act as multi-functional programmable metasurfaces capable of supporting concurrent communication and sensing within a unified architecture. We propose a two-stage ISAC protocol, in which the preparation phase performs direction estimation for outdoor users located in the reflection space, while maintaining communication with both outdoor and indoor users in the transmission space. The subsequent communication phase exploits the estimated directions to enhance information transfer. The directions of outdoor users are modeled as Gaussian random variables to capture estimation uncertainty, and the corresponding average communication performance is incorporated into the design. Building on this framework, we formulate a performance-balanced optimization problem that maximizes the communication sum-rate while guaranteeing the required sensing accuracy, jointly determining the beamforming vectors at the base station (BS), the STAR-RIS transmission and reflection coefficients, and the metasurface partition between energy-splitting and transmit-only modes. The physical constraints of STAR-RIS elements and the required sensing performance are explicitly enforced. To address the non-convex nature of the problem, we combine fractional programming, Lagrangian dual reformulation, and successive convex approximation. The binary metasurface partition is ultimately recovered via continuous relaxation followed by projection-based binarization. Numerical results demonstrate that the proposed design achieves an effective trade-off between sensing accuracy and communication throughput, by significantly outperforming conventional STAR-RIS-aided ISAC schemes.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16383v1",
        "authors": [
          "Ziming Liu",
          "Tao Chen",
          "Giacinto Gelli",
          "Vincenzo Galdi",
          "Francesco Verde"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Framework",
        "Protocol",
        "Intel",
        "Meta",
        "STAR",
        "ISAC",
        "EPA",
        "NSF",
        "Act",
        "RIS",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.608174"
    },
    {
      "id": "arxiv-2602.16320v1",
      "title": "RefineFormer3D: Efficient 3D Medical Image Segmentation via Adaptive Multi-Scale Transformer with Cross Attention Fusion",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16320v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Accurate and computationally efficient 3D medical image segmentation remains a critical challenge in clinical workflows. Transformer-based architectures often demonstrate superior global contextual modeling but at the expense of excessive parameter counts and memory demands, restricting their clinical deployment. We propose RefineFormer3D, a lightweight hierarchical transformer architecture that balances segmentation accuracy and computational efficiency for volumetric medical imaging. The architecture integrates three key components: (i) GhostConv3D-based patch embedding for efficient feature extraction with minimal redundancy, (ii) MixFFN3D module with low-rank projections and depthwise convolutions for parameter-efficient feature extraction, and (iii) a cross-attention fusion decoder enabling adaptive multi-scale skip connection integration. RefineFormer3D contains only 2.94M parameters, substantially fewer than contemporary transformer-based methods. Extensive experiments on ACDC and BraTS benchmarks demonstrate that RefineFormer3D achieves 93.44\\% and 85.9\\% average Dice scores respectively, outperforming or matching state-of-the-art methods while requiring significantly fewer parameters. Furthermore, the model achieves fast inference (8.35 ms per volume on GPU) with low memory requirements, supporting deployment in resource-constrained clinical environments. These results establish RefineFormer3D as an effective and scalable solution for practical 3D medical image segmentation.",
        "keywords": [
          "eess.IV",
          "cs.CV",
          "cs.LG"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16320v1",
        "authors": [
          "Kavyansh Tyagi",
          "Vishwas Rathi",
          "Puneet Goyal"
        ],
        "arxiv_categories": [
          "eess.IV",
          "cs.CV",
          "cs.LG"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Cross Attention Fusion Accurate",
        "Medical Image Segmentation",
        "Scale Transformer",
        "Adaptive Multi",
        "Transformer",
        "Fusion",
        "ACDC",
        "GPU",
        "NSF",
        "Act",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.608682"
    },
    {
      "id": "arxiv-2602.16271v1",
      "title": "Impact of Preprocessing on Neural Network-Based RSS/AoA Positioning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16271v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Hybrid received signal strength (RSS)-angle of arrival (AoA)-based positioning offers low-cost distance estimation and high-resolution angular measurements. Still, it comes at a cost of inherent nonlinearities, geometry-dependent noise, and suboptimal weighting in conventional linear estimators that might limit accuracy. In this paper, we propose a neural network-based approach using a multilayer perceptron (MLP) to directly map RSS-AoA measurements to 3D positions, capturing nonlinear relationships that are difficult to model with traditional methods. We evaluate the impact of input representation by comparing networks trained on raw measurements versus preprocessed features derived from a linearization method. Simulation results show that the learning-based approach consistently outperforms existing linear methods under RSS noise across all noise levels, and matches or surpasses state-of-the-art performance under increasing AoA noise. Furthermore, preprocessing measurements using the linearization method provides a clear advantage over raw data, demonstrating the benefit of geometry-aware feature extraction.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16271v1",
        "authors": [
          "Omid Abbassi Aghda",
          "Slavisa Tomic",
          "Oussama Ben Haj Belkacem",
          "Joao Guerreiro",
          "Nuno Souto"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Positioning Hybrid",
        "Neural Network",
        "Act",
        "MLP",
        "MIT",
        "RSS",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.609023"
    },
    {
      "id": "arxiv-2602.16260v1",
      "title": "Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16260v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.",
        "keywords": [
          "eess.SY",
          "math.DS",
          "math.OC"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16260v1",
        "authors": [
          "Miguel A. Trujillo",
          "Rodrigo Aldana-López",
          "David Gomez Gutierrez",
          "Michael Defoort",
          "Javier Ruiz Leon"
        ],
        "arxiv_categories": [
          "eess.SY",
          "math.DS",
          "math.OC"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Upper Bound",
        "Protocol",
        "UBST",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.609382"
    },
    {
      "id": "arxiv-2602.16257v1",
      "title": "SeaSpoofFinder -- Potential GNSS Spoofing Event Detection Using AIS",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16257v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "This paper investigates whether large-scale GNSS spoofing activity can be inferred from maritime Automatic Identification System (AIS) position reports. A data-processing framework, called SeaSpoofFinder, available here: seaspooffinder.github.io/ais_data, was developed to ingest and post-process global AIS streams and to detect candidate anomalies through a two-stage procedure. In Stage 1, implausible position jumps are identified using kinematic and data-quality filters; in Stage 2, events are retained only when multiple vessels exhibit spatially consistent source and target clustering, thereby reducing false positives from single-vessel artifacts. The resulting final potential spoofing events (FPSEs) reveal recurrent patterns in several regions, including the Baltic Sea, the Black Sea, Murmansk, Moscow, and the Haifa area, with affected footprints that can span large maritime areas. The analysis also highlights recurring non-spoofing artifacts (e.g., back-to-port jumps and data gaps) that can still pass heuristic filters in dense traffic regions. These results indicate that AIS-based monitoring can provide useful evidence for identifying and characterizing potential spoofing activity at scale, while emphasizing that AIS-only evidence does not provide definitive attribution.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16257v1",
        "authors": [
          "Jón Winkel",
          "Tom Willems",
          "Cillian O'Driscoll",
          "Ignacio Fernandez-Hernandez"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Automatic Identification System",
        "Spoofing Event Detection Using",
        "Baltic Sea",
        "Framework",
        "Black Sea",
        "In Stage",
        "GNSS",
        "AIS",
        "Act",
        "DOE",
        "EU",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.609757"
    },
    {
      "id": "arxiv-2602.16244v1",
      "title": "Pinching Antennas-Aided Integrated Sensing and Multicast Communication Systems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16244v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "A pinching antennas (PAs)-aided integrated sensing and multicast communication framework is proposed. In this framework, the communication performance is measured by the multicast rate considering max-min fairness. Moreover, the sensing performance is quantified by the Bayesian Cramér-Rao bound (BCRB), where a Gauss-Hermite quadrature-based approach is proposed to compute the Bayesian Fisher information matrix. Based on these metrics, PA placement is optimized under three criteria: communications-centric (C-C), sensing-centric (S-C), and Pareto-optimal designs. These designs are investigated in two scenarios: the single-PA case and the multi-PA case. 1) For the single-PA case, a closed-form solution is derived for the location of the C-C transmit PA, while the S-C design yields optimal transmit and receive PA placements that are symmetric about the target location. Leveraging this geometric insight, the Pareto-optimal design is solved by enforcing this PA placement symmetry, thereby reducing the joint transmit and receive PA placement to the transmit PA optimization. 2) For the general multi-PA case, the PA placements constitute a highly non-convex optimization problem. To solve this, an element-wise alternating optimization-based method is proposed to sequentially optimize all PA placements for the S-C design, and is further incorporated into an augmented Lagrangian (AL) framework and a rate-profile formulation to solve the C-C and Pareto-optimal design problems, respectively. Numerical results show that: i) PASS substantially outperforms fixed-antenna baselines in both multicast rate and sensing accuracy; ii) the multicasting gain becomes more pronounced as the user density increases; and iii) the sensing accuracy improves with the number of deployed PAs.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16244v1",
        "authors": [
          "Shan Shan",
          "Chongjun Ouyang",
          "Xiaohang Yang",
          "Yong Li",
          "Zhiqin Wang"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multicast Communication Systems",
        "Aided Integrated Sensing",
        "Pinching Antennas",
        "Bayesian Fisher",
        "Framework",
        "PASS",
        "BCRB",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.611035"
    },
    {
      "id": "arxiv-2602.16166v1",
      "title": "Discovering Unknown Inverter Governing Equations via Physics-Informed Sparse Machine Learning",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16166v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Discovering the unknown governing equations of grid-connected inverters from external measurements holds significant attraction for analyzing modern inverter-intensive power systems. However, existing methods struggle to balance the identification of unmodeled nonlinearities with the preservation of physical consistency. To address this, this paper proposes a Physics-Informed Sparse Machine Learning (PISML) framework. The architecture integrates a sparse symbolic backbone to capture dominant model skeletons with a neural residual branch that compensates for complex nonlinear control logic. Meanwhile, a Jacobian-regularized physics-informed training mechanism is introduced to enforce multi-scale consistency including large/small-scale behaviors. Furthermore, by performing symbolic regression on the neural residual branch, PISML achieves a tractable mapping from black-box data to explicit control equations. Experimental results on a high-fidelity Hardware-in-the-Loop platform demonstrate the framework's superior performance. It not only achieves high-resolution identification by reducing error by over 340 times compared to baselines but also realizes the compression of heavy neural networks into compact explicit forms. This restores analytical tractability for rigorous stability analysis and reduces computational complexity by orders of magnitude. It also provides a unified pathway to convert structurally inaccessible devices into explicit mathematical models, enabling stability analysis of power systems with unknown inverter governing equations.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16166v1",
        "authors": [
          "Jialin Zheng",
          "Ruhaan Batta",
          "Zhong Liu",
          "Xiaonan Lu"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Discovering Unknown Inverter Governing",
        "Informed Sparse Machine Learning",
        "Machine Learning",
        "Neural Network",
        "Framework",
        "PISML",
        "Act",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.611722"
    },
    {
      "id": "arxiv-2602.16119v1",
      "title": "In-Situ Analysis of Vibration and Acoustic Data in Additive Manufacturing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16119v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Vibration from an erroneous disturbance harms the manufactured components and lowers the output quality of an FDM printer. For moving machinery, vibration analysis and control are crucial. Additive manufacturing is the basis of 3D printing, which utilizes mechanical movement of the extruder to fabricate objects, and faults occur due to unwanted vibrations. Therefore, it is vital to examine the vibration patterns of a 3D printer. In this work, we observe these parameters of an FDM printer, exemplified by the MakerBot Method X. To analyze the system, it is necessary to understand the motion it generates and select appropriate sensors to detect those motions. The sensor measurement values can be used to determine the condition of the printer. We used an accelerometer and an acoustic sensor to measure the vibration and sound produced by the printer. The outputs from these sensors were examined individually. The findings show that vibration occurs at relatively low levels during continuous motion because it mainly appears at component transition edges. Due to abrupt acceleration and deceleration during zigzag motion, vibration reaches its peak.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16119v1",
        "authors": [
          "Muhammad Fasih Waheed",
          "Shonda Bernadin"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Additive Manufacturing Vibration",
        "Situ Analysis",
        "Acoustic Data",
        "Act",
        "FDM",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.612224"
    },
    {
      "id": "arxiv-2602.16108v1",
      "title": "Advancing Industry 4.0: Multimodal Sensor Fusion for AI-Based Fault Detection in 3D Printing",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16108v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "Additive manufacturing, particularly fused deposition modeling, is transforming modern production by enabling rapid prototyping and complex part fabrication. However, its layer-by-layer process remains vulnerable to faults such as nozzle clogging, filament runout, and layer misalignment, which compromise print quality and reliability. Traditional inspection methods are costly, time-intensive, and often limited to post-process analysis, making them unsuitable for real-time intervention. In this current study, the authors developed a novel, low-cost, and portable faultdetection system that leverages multimodal sensor fusion and artificial intelligence for real-time monitoring in FDM-based 3D printing. The system integrates acoustic, vibration, and thermal sensing into a non-intrusive architecture, capturing complementary data streams that reflect both mechanical and process-related anomalies. Acoustic and thermal sensors operate in a fully contactless manner, while the vibration sensor requires minimal attachment such that it will not interfere with printer hardware, thereby preserving portability and ease of deployment. The multimodal signals are processed into spectrograms and time-frequency features, which are classified using convolutional neural networks for intelligent fault detection. The proposed system advances Industry 4.0 objectives by offering an affordable, scalable, and practical monitoring solution that improves faultdetection accuracy, reduces waste, and supports sustainable, adaptive manufacturing.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16108v1",
        "authors": [
          "Muhammad Fasih Waheed",
          "Shonda Bernadin",
          "Ali Hassan"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Multimodal Sensor Fusion",
        "Artificial Intelligence",
        "Based Fault Detection",
        "Advancing Industry",
        "Printing Additive",
        "Neural Network",
        "Fusion",
        "Intel",
        "NSF",
        "Act",
        "MIT",
        "FDM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.612765"
    },
    {
      "id": "arxiv-2602.16102v1",
      "title": "Tunable Ferroelectric Acoustic Resonators in Monolithic Thin-Film Barium Titanate",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16102v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "The increasing development of wireless communication bands has motivated the development of compact, low-loss, and frequency adjustable RF filtering technologies. Acoustic resonators are the ideal solution to these requirements, and tunable implementations offer a path toward reconfigurable front ends. In this work, we investigate epitaxial barium titanate (BTO) grown on silicon as a platform for tunable acoustic resonators operating in the sub-GHz regime. We demonstrate lateral excitation of symmetric lamb (S0) modes in X-cut BTO membranes, in contrast to prior thickness-defined ferroelectric resonators. Devices are designed using finite-element simulations and fabricated with laterally patterned electrodes that enable overtone coupling to multiple resonant modes. Under applied DC bias, ferroelectric domains align, allowing electrical excitation, frequency tuning, and quality-factor enhancement of acoustic modes. Resonances near 300 MHz and 700 MHz exhibit electromechanical coupling up to 8% and bias-dependent frequency tuning, with a distinct transition in behavior near 20 V. These results highlight monolithic BTO on silicon as a promising material system for laterally excited, tunable acoustic resonators for reconfigurable RF applications.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16102v1",
        "authors": [
          "Ian Anderson",
          "Agham Posadas",
          "Alexander A. Demkov",
          "Ruochen Lu"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Tunable Ferroelectric Acoustic Resonators",
        "Monolithic Thin",
        "Act",
        "BTO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.613180"
    },
    {
      "id": "arxiv-2602.16036v1",
      "title": "Stability and convergence of multi-converter systems using projection-free power-limiting droop control",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16036v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "In this paper, we propose a projection-free power-limiting droop control for grid-connected power electronics and an associated constrained flow problem. In contrast to projection-based power-limiting droop control, the novel projection-free power-limiting droop control results in networked dynamics that are semi-globally exponentially stable with respect to the set of optimizers of the constrained flow problem. Under a change to edge coordinates, the overall networked dynamics arising from projection-free power-limiting droop control coincide with the projection-free primal-dual dynamics associated with an augmented Lagrangian of the constrained flow problem. Leveraging this result, we (i) provide a bound on the convergence rate of the projection-free networked dynamics, (ii) propose a tuning method for controller parameters to improve the bound on the convergence rate, and (iii) analyze the relationship of the bound on the convergence rate and connectivity of the network. Finally, the analytical results are illustrated using an Electromagnetic transient (EMT) simulation.",
        "keywords": [
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16036v1",
        "authors": [
          "Amirhossein Iraniparast",
          "Dominic Groß"
        ],
        "arxiv_categories": [
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "MIT",
        "EMT",
        "AI",
        "UN"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.613745"
    },
    {
      "id": "arxiv-2602.15808v1",
      "title": "Measurement-Based Validation of Geometry-Driven RIS Beam Steering in Industrial Environments",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15808v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Reconfigurable intelligent surfaces (RISs) offer programmable control of radio propagation for future wireless systems. For configuration, geometry-driven analytical approaches are appealing for their simplicity and real-time operation, but their performance in challenging environments such as industrial halls with dense multipath and metallic scattering is not well established. To this end, we present a measurement-based evaluation of geometry-driven RIS beam steering in a large industrial hall using a 5 GHz RIS prototype. A novel RIS configuration is proposed in which four patch antennas are mounted in close proximity in front of the RIS to steer the incident field and enable controlled reflection. For this setup, analytically computed, quantized configurations are implemented. Two-dimensional received power maps from two measurement areas reveal consistent, spatially selective focusing. Configurations optimized near the receiver produce clear power maxima, while steering to offset locations triggers a rapid 20-30 dB reduction. With increasing RIS-receiver distance, elevation selectivity broadens due to finite-aperture and geometric constraints, while azimuth steering remains robust. These results confirm the practical viability of geometry-driven RIS beam steering in industrial environments and support its use for spatial field control and localization under non-ideal propagation.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15808v1",
        "authors": [
          "Adam Umra",
          "Simon Tewes",
          "Niklas Beckmann",
          "Niels König",
          "Aydin Sezgin"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Industrial Environments Reconfigurable",
        "Based Validation",
        "Beam Steering",
        "Intel",
        "Meta",
        "Act",
        "RIS",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.614352"
    },
    {
      "id": "arxiv-2602.15794v1",
      "title": "Service Orchestration in the Computing Continuum: Structural Challenges and Vision",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15794v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "The Computing Continuum (CC) integrates different layers of processing infrastructure, from Edge to Cloud, to optimize service quality through ubiquitous and reliable computation. Compared to central architectures, however, heterogeneous and dynamic infrastructure increases the complexity for service orchestration. To guide research, this article first summarizes structural problems of the CC, and then, envisions an ideal solution for autonomous service orchestration across the CC. As one instantiation, we show how Active Inference, a concept from neuroscience, can support self-organizing services in continuously interpreting their environment to optimize service quality. Still, we conclude that no existing solution achieves our vision, but that research on service orchestration faces several structural challenges. Most notably: provide standardized simulation and evaluation environments for comparing the performance of orchestration mechanisms. Together, the challenges outline a research roadmap toward resilient and scalable service orchestration in the CC.",
        "keywords": [
          "cs.DC",
          "cs.ET",
          "eess.SY"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15794v1",
        "authors": [
          "Boris Sedlak",
          "Víctor Casamayor Pujol",
          "Ildefons Magrans de Abril",
          "Praveen Kumar Donta",
          "Adel N. Toosi"
        ],
        "arxiv_categories": [
          "cs.DC",
          "cs.ET",
          "eess.SY"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Structural Challenges",
        "Service Orchestration",
        "Computing Continuum",
        "Active Inference",
        "Standard",
        "Act",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.614696"
    },
    {
      "id": "arxiv-2602.15779v1",
      "title": "Rate-Distortion Optimization for Ensembles of Non-Reference Metrics",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15779v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Non-reference metrics (NRMs) can assess the visual quality of images and videos without a reference, making them well-suited for the evaluation of user-generated content. Nonetheless, rate-distortion optimization (RDO) in video coding is still mainly driven by full-reference metrics, such as the sum of squared errors, which treat the input as an ideal target. A way to incorporate NRMs into RDO is through linearization (LNRM), where the gradient of the NRM with respect to the input guides bit allocation. While this strategy improves the quality predicted by some metrics, we show that it can yield limited gains or degradations when evaluated with other NRMs. We argue that NRMs are highly non-linear predictors with locally unstable gradients that can compromise the quality of the linearization; furthermore, optimizing a single metric may exploit model-specific biases that do not generalize across quality estimators. Motivated by this observation, we extend the LNRM framework to optimize ensembles of NRMs and, to further improve robustness, we introduce a smoothing-based formulation that stabilizes NRM gradients prior to linearization. Our framework is well-suited to hybrid codecs, and we advocate for its use with overfitted codecs, where it avoids iterative evaluations and backpropagation of neural network-based NRMs, reducing encoder complexity relative to direct NRM optimization. We validate the proposed approach on AVC and Cool-chic, using the YouTube UGC dataset. Experiments demonstrate consistent bitrate savings across multiple NRMs with no decoder complexity overhead and, for Cool-chic, a substantial reduction in encoding runtime compared to direct NRM optimization.",
        "keywords": [
          "eess.IV"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15779v1",
        "authors": [
          "Xin Xiong",
          "Samuel Fernández-Menduiña",
          "Eduardo Pavez",
          "Antonio Ortega",
          "Neil Birkbeck"
        ],
        "arxiv_categories": [
          "eess.IV"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Distortion Optimization",
        "Reference Metrics Non",
        "Neural Network",
        "Framework",
        "LNRM",
        "RDO",
        "AVC",
        "MIT",
        "UGC",
        "NRM",
        "EU",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.615152"
    },
    {
      "id": "arxiv-2602.15737v1",
      "title": "NYUSIM: A Roadmap to AI-Enabled Statistical Channel Modeling and Simulation",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15737v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Integrating artificial intelligence (AI) into wireless channel modeling requires large, accurate, and physically consistent datasets derived from real measurements. Such datasets are essential for training and validating models that learn spatio-temporal channel behavior across frequencies and environments. NYUSIM, introduced by NYU WIRELESS in 2016, generates realistic spatio-temporal channel data using extensive outdoor and indoor measurements between 28 and 142 GHz. To improve scalability and support 6G research, we migrated the complete NYUSIM framework from MATLAB to Python, and are incorporating new statistical model generation capabilities from extensive field measurements in the new 6G upper mid-band spectrum at 6.75 GHz (FR1(C)) and 16.95 GHz (FR3) [1]. The NYUSIM Python also incorporates a 3D antenna data format, referred to as Ant3D, which is a standardized, full-sphere format for defining canonical, commercial, or measured antenna patterns for any statistical or site-specific ray tracing modeling tool. Migration from MATLAB to Python was rigorously validated through Kolmogorov-Smirnov (K-S) tests, moment analysis, and end-to-end testing with unified randomness control, confirming statistical consistency and reproduction of spatio-temporal channel statistics, including spatial consistency with the open-source MATLAB NYUSIM v4.0 implementation. The NYUSIM Python version is designed to integrate with modern AI workflows and enable large-scale parallel data generation, establishing a robust, verified, and extensible foundation for future AI-enabled channel modeling.",
        "keywords": [
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15737v1",
        "authors": [
          "Isha Jariwala",
          "Xinquan Wang",
          "Bridget Meier",
          "Guanyue Qian",
          "Dipankar Shakya"
        ],
        "arxiv_categories": [
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Enabled Statistical Channel Modeling",
        "Artificial Intelligence",
        "Simulation Integrating",
        "Framework",
        "Standard",
        "NYUSIM",
        "MATLAB",
        "Intel",
        "NYU",
        "6G",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.615640"
    },
    {
      "id": "arxiv-2602.15711v1",
      "title": "Random Wavelet Features for Graph Kernel Machines",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15711v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Node embeddings map graph vertices into low-dimensional Euclidean spaces while preserving structural information. They are central to tasks such as node classification, link prediction, and signal reconstruction. A key goal is to design node embeddings whose dot products capture meaningful notions of node similarity induced by the graph. Graph kernels offer a principled way to define such similarities, but their direct computation is often prohibitive for large networks. Inspired by random feature methods for kernel approximation in Euclidean spaces, we introduce randomized spectral node embeddings whose dot products estimate a low-rank approximation of any specific graph kernel. We provide theoretical and empirical results showing that our embeddings achieve more accurate kernel approximations than existing methods, particularly for spectrally localized kernels. These results demonstrate the effectiveness of randomized spectral constructions for scalable and principled graph representation learning.",
        "keywords": [
          "cs.LG",
          "cs.AI",
          "eess.SP"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15711v1",
        "authors": [
          "Valentin de Bassompierre",
          "Jean-Charles Delvenne",
          "Laurent Jacques"
        ],
        "arxiv_categories": [
          "cs.LG",
          "cs.AI",
          "eess.SP"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Graph Kernel Machines Node",
        "Random Wavelet Features",
        "WHO",
        "EU"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:39.615988"
    },
    {
      "id": "arxiv-2602.16273v1",
      "title": "Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.16273v1",
        "published_date": "2026-02-18"
      },
      "content": {
        "abstract": "We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.",
        "keywords": [
          "nlin.AO",
          "cs.CL"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.16273v1",
        "authors": [
          "Jelena Vasic",
          "Branislav Andjelic",
          "Ana Mancic",
          "Dusica Filipovic Djurdjevic",
          "Ljiljana Mihic"
        ],
        "arxiv_categories": [
          "nlin.AO",
          "cs.CL"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Speech Embedding Trajectories",
        "Lyapunov Spectral Analysis",
        "Psychosis We",
        "EPA",
        "Act",
        "WHO",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:44.659313"
    },
    {
      "id": "arxiv-2602.15512v1",
      "title": "Anomalous transport in the Fermi-Pasta-Ulam-Tsingou model: a review and open problems",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15512v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "This review provides an up-to-date account of energy transport in Fermi-Pasta-Ulam-Tsingou (FPUT) chains, a key testbed for nonequilibrium statistical physics. We discuss the transition from the historical puzzle of thermalization to the discovery of anomalous heat transport, where the effective thermal conductivity $κ$ diverges with system size $L$ as $κ\\propto L^δ$. The article clarifies the distinction between two universality classes: the FPUT-$αβ$ model, characterized by $δ= 1/3$ and linked to Kardar-Parisi-Zhang (KPZ) physics, and the symmetric FPUT-$β$ model, where numerical and theoretical evidence support $δ= 2/5$. We investigate how finite-size effects - unavoidably induced by the thermostatting protocols - can disguise the asymptotic scaling. Additionally, we analyze the role of conservative noise in preserving hydrodynamic properties and examine how proximity to integrable limits leads to long-lived quasi-particles and, thereby, to diffusive regimes over intermediate spatial scales.",
        "keywords": [
          "cond-mat.stat-mech",
          "nlin.CD"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15512v1",
        "authors": [
          "Stefano Lepri",
          "Roberto Livi",
          "Antonio Politi"
        ],
        "arxiv_categories": [
          "cond-mat.stat-mech",
          "nlin.CD"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Protocol",
        "FPUT",
        "KPZ",
        "Act",
        "MIT",
        "UN",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:44.660220"
    },
    {
      "id": "arxiv-2602.15279v1",
      "title": "On the efficiency of pairwise Hamiltonian control to desynchronize the higher-order Kuramoto model",
      "source": {
        "name": "arXiv",
        "type": "academic",
        "url": "https://arxiv.org/abs/2602.15279v1",
        "published_date": "2026-02-17"
      },
      "content": {
        "abstract": "Synchronization of coupled oscillators is observed in many natural and engineered systems and emerges due to the interactions within the system. It can be both beneficial, e.g., in power grids, and harmful, e.g., in epileptic seizures. In the latter case, efficient control methods to desynchronize the systems are crucial. Recent studies have shown that interactions are not always pairwise, but higher-order, i.e., many-body, and this greatly affects the dynamics. For instance, higher-order interactions increase the linear stability of synchronized states but simultaneously shrink their attraction basin, with potentially opposite effects on control methods. Here, we use a minimally invasive pairwise control based on Hamiltonian control theory, and investigate its efficiency on phase oscillators with higher-order interactions. We show that, if the initial phases are close to the synchronized state, higher-order interactions make desynchronization more difficult to achieve. Otherwise, a non-monotonic effect appears: intermediate strengths of higher-order interactions impede desynchronization while larger ones facilitate it. In all cases, the control can desynchronize the system with a sufficient number of controlled nodes and intensity.",
        "keywords": [
          "nlin.AO",
          "math-ph",
          "math.DS",
          "math.OC",
          "nlin.PS"
        ],
        "language": "en"
      },
      "metadata": {
        "arxiv_id": "2602.15279v1",
        "authors": [
          "Martin Moriamé",
          "Riccardo Muolo",
          "Timoteo Carletti",
          "Maxime Lucas"
        ],
        "arxiv_categories": [
          "nlin.AO",
          "math-ph",
          "math.DS",
          "math.OC",
          "nlin.PS"
        ],
        "steeps_mapping": "T_Technological"
      },
      "entities": [
        "Act",
        "AI"
      ],
      "preliminary_category": "T",
      "collected_at": "2026-02-19T14:48:44.660433"
    }
  ]
}