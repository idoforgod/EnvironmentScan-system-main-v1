# 일일 환경 스캐닝 보고서

**워크플로우**: WF2 - arXiv 학술 심층 스캐닝 (arXiv Academic Deep Scanning)
**보고서 생성일**: 2026년 2월 16일
**보고서 ID**: wf2-arxiv-2026-02-16
**데이터 출처**: arXiv (22개 쿼리 그룹, ~180개 카테고리)
**스캐닝 범위**: 14일 회고, 카테고리당 최대 50건
**참고**: arXiv 주말 게시 동결(weekend posting freeze)로 인해 수집된 논문의 published_date는 2026-02-12이나, arXiv 배치 시스템을 통해 2026-02-14~15에 실제 공개된 논문입니다. arXiv 주말 게시 중단으로 2/12 게시 논문을 예외적으로 포함하였습니다.

> **스캔 시간 범위**: 2026년 02월 13일 21:48 UTC ~ 2026년 02월 15일 21:48 UTC (48시간)
> **기준 시점 (T0)**: 2026년 02월 15일 21:48:54 UTC

---

## 1. 경영진 요약

### 오늘의 핵심 발견 (Top 3 신호)

1. **검증 스케일링이 정책 학습 스케일링보다 효과적: VLA 정렬의 새로운 패러다임** (기술 T)
   - 중요도: 9/10
   - 핵심 내용: 테스트 시점 검증(test-time verification)이 정책 사전학습 스케일링보다 로봇 비전-언어-행동(VLA) 모델의 지시 준수 정렬에서 최대 45% 더 효과적임을 입증한 CoVer 프레임워크 발표. 범용 로봇의 "의도-행동 격차"를 체계적으로 해소하는 새로운 접근법 제시.
   - 전략적 시사점: 로봇 AI의 신뢰성 확보 방식이 "더 많은 학습 데이터"에서 "더 나은 추론 시점 검증"으로 패러다임 전환될 가능성이 높으며, 이는 로봇 배포 비용과 안전성 모두에 근본적 영향을 미침.

2. **UniT: 통합 멀티모달 연쇄적 사고 테스트 시점 스케일링** (기술 T)
   - 중요도: 9/10
   - 핵심 내용: 단일 통합 모델 내에서 멀티모달 이해와 생성을 반복적 추론으로 개선하는 UniT 프레임워크 발표. 짧은 추론 궤적으로 훈련된 모델이 테스트 시점에 더 긴 추론 체인으로 일반화되며, 순차적 CoT 추론이 병렬 샘플링보다 효율적임을 증명.
   - 전략적 시사점: 멀티모달 AI의 "생각하는 시간"을 늘려 성능을 향상시키는 새로운 스케일링 패러다임이 정립되고 있으며, 이는 "학습 스케일링 법칙" 이후의 차세대 AI 발전 축을 형성할 전망.

3. **DeepSight: 대형 모델 안전성 통합 툴킷** (기술 T)
   - 중요도: 9/10
   - 핵심 내용: 대형 언어 모델(LLM)과 멀티모달 대형 언어 모델(MLLM)의 안전성 평가-진단을 통합한 최초의 오픈소스 툴킷 DeepSight 발표. 블랙박스 안전 평가를 화이트박스 내부 메커니즘 진단으로 전환하며, 프론티어 AI 위험 평가를 최초로 지원.
   - 전략적 시사점: AI 안전성 평가가 "외부 행동 관찰"에서 "내부 메커니즘 이해"로 전환되는 분수령이 될 수 있으며, 규제 기관의 AI 감사 역량 강화에 실질적 도구를 제공.

### 주요 변화 요약
- 발견된 신규 신호: 568개
- 우선순위 상위 신호: 15개
- 주요 영향 도메인: 기술(T) 7건, 사회(S) 3건, 경제(E) 2건, 환경(E) 1건, 정치(P) 1건, 정신적(s) 1건

이번 arXiv 심층 스캐닝에서는 **테스트 시점 스케일링(test-time scaling)**이 2026년 초 AI 연구의 지배적 패러다임으로 부상하고 있음이 확인되었다. 상위 15개 신호 중 3건(#1 CoVer, #2 UniT, #11 CATTS)이 직접적으로 테스트 시점 연산 할당 최적화를 다루고 있으며, 이는 "훈련 스케일링 법칙(training scaling laws)"의 후속 패러다임으로서 "추론 스케일링 법칙(inference scaling laws)"이 체계적으로 정립되고 있음을 시사한다. 동시에, AI 안전성 도구의 오픈소스화(#3 DeepSight), AI-인간 상호작용의 이론적 프레임워크 구축(#6 KPM, #9 인간-LLM 아키타입), 탈중앙화 거버넌스의 정량적 분석(#12 Legitimate Overrides) 등 기술적 발전과 사회적-제도적 대응이 동시에 진행되는 양상이 뚜렷하다. 특히 arXiv 주말 게시 중단으로 2/12 게시 논문을 예외적으로 포함하였으나, 해당 논문들의 학술적 중요도가 높아 스캔 품질에는 영향이 없다.

---

## 2. 신규 탐지 신호

arXiv 22개 쿼리 그룹에서 총 568개의 학술 논문 시그널이 수집되었다. STEEPs 6개 도메인 전반에 걸쳐 분류되었으며, 전문가 큐레이션을 통해 미래 변화 감지 관점에서 가장 중요한 15개 시그널을 선별하였다. 다음은 pSST(predicted Signal Scanning Trust) 점수 순으로 정렬한 상위 15개 시그널의 상세 분석이다.

---

### 우선순위 1: 검증 스케일링이 정책 학습 스케일링보다 효과적 - VLA 정렬의 새로운 패러다임 (CoVer)

- **신뢰도**: pSST 90.0/100 (Grade A)

1. **분류**: 기술(T) - 로보틱스, AI 정렬, 비전-언어-행동 모델
2. **출처**: Kwok, J. et al. "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment" (arXiv:2602.12281v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12281v1)
3. **핵심 사실**: 비전-언어-행동(VLA) 모델에서 테스트 시점 검증(test-time verification)이 동일 데이터 기반 정책 사전학습 스케일링보다 분포 내(in-distribution) 22%, 분포 외(OOD) 13%, 실세계 실험에서 45% 더 높은 성능 향상을 달성함을 입증. 대조 검증기(contrastive verifier) CoVer와 계층적 검증 추론 파이프라인을 제안.
4. **정량 지표**: SIMPLER 벤치마크 분포 내 +22%, 분포 외 +13%, 실세계 실험 +45%, PolaRiS 벤치마크 과제 진행 +14%, 성공률 +9%
5. **영향도**: 9/10 - 범용 로봇의 지시 준수 신뢰성을 근본적으로 개선할 수 있는 새로운 스케일링 패러다임으로, 로봇 산업의 상용화 임계점에 직접 영향
6. **상세 설명**: 이 연구는 범용 로봇의 핵심 과제인 "의도-행동 격차(intention-action gap)"를 해소하기 위해 테스트 시점 스케일링 법칙을 체계적으로 분석했다. 핵심 발견은 재표현된 지시(rephrased instructions)와 생성된 행동 후보의 수를 공동으로 스케일링하면 각각을 독립적으로 스케일링하는 것보다 훨씬 효율적으로 올바른 행동을 회복할 수 있다는 것이다. CoVer(Contrastive Verifier)는 이 스케일링 법칙을 활용하여 비전-언어 모델(VLM)으로 다양한 지시 재표현을 사전 계산하고, 각 지시에 대해 반복적으로 행동 후보를 생성한 뒤, 검증기가 최적의 고수준 프롬프트와 저수준 행동 청크를 선택한다. "부팅 시점 연산(boot-time compute)" 개념의 도입으로 배포 효율성도 확보했다.
7. **추론**: 이 결과는 로봇 AI 개발의 전략적 방향에 근본적 전환을 촉발할 수 있다. "더 큰 모델, 더 많은 데이터"라는 기존 스케일링 전략에서 "더 스마트한 추론 시점 검증"으로의 이동은 로봇 배포 비용을 크게 줄이면서도 안전성을 높일 수 있다. 특히 제조업, 물류, 가정용 로봇 등 실세계 배포에서 VLA 모델의 신뢰성 한계가 상용화의 주요 장벽이었다는 점에서, CoVer 패러다임은 로봇 산업의 상용화 타임라인을 앞당길 잠재력이 있다. Google, Tesla, Figure AI 등 주요 로봇 기업이 유사한 검증 기반 접근법을 채택할 가능성이 높다.
8. **이해관계자**: 로봇 AI 기업 (Boston Dynamics, Figure AI, Sanctuary AI), 대형 기술 기업 로봇 부서 (Google DeepMind Robotics, Tesla Optimus), 제조업 자동화 기업 (Fanuc, ABB), 산업안전 규제 기관, 로보틱스 연구 기관 (CMU RI, MIT CSAIL)
9. **모니터링 지표**: 주요 로봇 기업의 테스트 시점 검증 기법 채택 발표, VLA 모델 벤치마크 성능 추이 (SIMPLER, PolaRiS), 로봇 상용화 배포 사례 및 안전 사고 보고, 관련 후속 논문 발표 빈도

---

### 우선순위 2: UniT - 통합 멀티모달 연쇄적 사고 테스트 시점 스케일링

- **신뢰도**: pSST 89.0/100 (Grade A)

1. **분류**: 기술(T) - 멀티모달 AI, 테스트 시점 스케일링, 연쇄적 사고
2. **출처**: Chen, L.L. et al. "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling" (arXiv:2602.12279v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12279v1)
3. **핵심 사실**: 단일 통합 모델에서 멀티모달 연쇄적 사고(chain-of-thought) 테스트 시점 스케일링을 가능하게 하는 UniT 프레임워크 발표. 짧은 추론 궤적으로 훈련된 통합 모델이 테스트 시점에 더 긴 추론 체인으로 일반화되며, 순차적 CoT 추론이 병렬 샘플링보다 확장성과 연산 효율성이 우수함을 입증.
4. **정량 지표**: 순차적 CoT가 병렬 샘플링 대비 더 나은 확장성 및 연산 효율성, 생성/편집 궤적 훈련이 분포 외 시각 추론 능력 향상, 에이전틱 데이터 합성 + 통합 모델 훈련 + 유연한 추론의 3단계 파이프라인
5. **영향도**: 9/10 - 멀티모달 AI의 추론 능력을 근본적으로 향상시키는 새로운 스케일링 축을 제시하며, "생각하는 AI"의 실용화에 핵심적 기여
6. **상세 설명**: UniT는 기존 통합 멀티모달 모델이 단일 패스로 출력을 생성하는 한계를 극복한다. 복잡한 공간 구성, 다수의 상호작용 객체, 진화하는 지시 등을 포함하는 멀티모달 과제에서 지시 분해, 중간 결과 검증, 반복적 수정 등의 인지적 행동을 유도한다. 핵심적으로, 에이전틱 데이터 합성(agentic data synthesis)으로 훈련 데이터를 생성하고, 통합 모델 훈련으로 이를 내재화하며, 유연한 테스트 시점 추론으로 실행하는 3단계 접근법을 제시한다. 검증(verification), 하위 목표 분해(subgoal decomposition), 콘텐츠 기억(content memory) 등의 인지적 행동이 발현된다.
7. **추론**: UniT는 "테스트 시점 스케일링"이 텍스트 전용 LLM을 넘어 멀티모달 통합 모델로 확장될 수 있음을 실증적으로 보여준다. 이는 GPT-4V, Gemini 등 최신 멀티모달 모델의 다음 세대 아키텍처에 직접적 영향을 미칠 전망이다. 특히 "짧은 궤적 훈련 → 긴 추론 일반화"라는 발견은 훈련 비용을 절감하면서도 추론 능력을 확장하는 실용적 경로를 제시하여, 중소 규모 AI 기업도 고성능 멀티모달 모델을 구축할 수 있는 가능성을 열어준다.
8. **이해관계자**: 대형 AI 기업 (OpenAI, Google DeepMind, Anthropic, Meta FAIR), 멀티모달 AI 스타트업 (Runway, Stability AI), 컴퓨터 비전 연구 커뮤니티, AI 하드웨어 기업 (NVIDIA, AMD), 클라우드 서비스 제공자 (AWS, Azure, GCP)
9. **모니터링 지표**: 주요 AI 기업의 멀티모달 테스트 시점 스케일링 기법 채택 현황, 통합 멀티모달 모델 벤치마크 성능 추이, 추론 연산 비용 대비 성능 효율성 지표 변화, 관련 후속 연구 발표 빈도 및 인용 추이

---

### 우선순위 3: DeepSight - 대형 모델 안전성 평가-진단 통합 툴킷

- **신뢰도**: pSST 88.0/100 (Grade A)

1. **분류**: 기술(T) - AI 안전성, 모델 평가, 오픈소스 도구
2. **출처**: Zhang, B. et al. "DeepSight: An All-in-One LM Safety Toolkit" (arXiv:2602.12092v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12092v1)
3. **핵심 사실**: 대형 언어 모델(LLM)과 멀티모달 대형 언어 모델(MLLM)의 안전성 평가와 진단을 통합한 최초의 오픈소스 프로젝트 DeepSight 발표. DeepSafe(평가 툴킷)와 DeepScan(진단 툴킷)으로 구성되며, 프론티어 AI 위험 평가와 안전성 평가-진단 공동 수행을 최초로 지원.
4. **정량 지표**: 평가 + 진단 2단계 통합 파이프라인, 프론티어 AI 위험 평가 최초 오픈소스 지원, 낮은 비용 + 재현 가능 + 고효율 + 높은 확장성의 4가지 설계 원칙 충족
5. **영향도**: 9/10 - AI 안전성 생태계의 민주화를 촉진하며, 블랙박스 평가에서 화이트박스 내부 메커니즘 진단으로의 패러다임 전환을 가속화
6. **상세 설명**: 현재 AI 안전성 워크플로우에서 평가(evaluation), 진단(diagnosis), 정렬(alignment)은 각각 별도의 도구로 처리되며, 이 세 단계 간 연결이 단절되어 있다. 안전 평가는 외부 행동 위험만 식별할 뿐 내부 원인을 파악하지 못하고, 진단은 구체적 위험 시나리오에서 유리되어 설명 수준에 머물며, 정렬은 내부 메커니즘 변화에 대한 전용 설명이 부족하여 일반 능력 저하를 야기할 수 있다. DeepSight는 태스크와 데이터 프로토콜을 통일하여 평가-진단 두 단계를 연결하고, 안전 평가를 블랙박스에서 화이트박스 통찰로 전환한다.
7. **추론**: DeepSight의 오픈소스 공개는 AI 안전성 연구의 "민주화" 전환점이 될 수 있다. 기존에 대형 AI 기업만 수행할 수 있던 심층 안전 진단을 학계, 규제 기관, 중소기업도 활용할 수 있게 되면, EU AI Act, 미국 AI 행정명령 등 규제 프레임워크의 실효성이 크게 향상될 전망이다. 특히 프론티어 AI 위험 평가 기능은 2026년 본격 시행되는 EU AI Act의 고위험 AI 시스템 요구사항 준수에 실질적 도구를 제공한다.
8. **이해관계자**: AI 안전 연구 기관 (MIRI, ARC, Anthropic Safety), 규제 기관 (EU AI Office, NIST AI Safety Institute, 한국 AI 안전위원회), 오픈소스 AI 커뮤니티 (Hugging Face, EleutherAI), AI 감사 기업 (Anthropic, Holistic AI), 학계 AI 연구실
9. **모니터링 지표**: DeepSight GitHub 스타 수 및 포크 수 추이, 규제 기관의 공식 도구 채택 현황, 후속 논문에서의 인용 빈도, 프론티어 AI 위험 평가 결과 공개 사례, AI 안전 감사 산업의 시장 규모 변화

---

### 우선순위 4: VIRENA - 민주적 혁신을 위한 가상 소셜 미디어 실험 플랫폼

- **신뢰도**: pSST 88.0/100 (Grade A)

1. **분류**: 사회(S) - 디지털 민주주의, 소셜 미디어 연구, 인간-AI 상호작용
2. **출처**: Hoes, E. et al. "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation" (arXiv:2602.12207v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12207v1)
3. **핵심 사실**: 현실적 소셜 미디어 환경(Instagram, Facebook, Reddit, WhatsApp, Messenger 복제)에서 인간과 LLM 기반 AI 에이전트가 동시에 상호작용하는 통제 실험을 가능하게 하는 오픈소스 플랫폼 VIRENA 발표. 프로그래밍 기술 없이 콘텐츠 모더레이션 비교, 인간-AI 상호작용, 집단 숙의 관찰 등의 연구 설계를 지원.
4. **정량 지표**: 5개 소셜 미디어 플랫폼 복제 (Instagram, Facebook, Reddit, WhatsApp, Messenger), 노코드(no-code) 시각적 인터페이스, 취리히 대학교에서 파일럿 운용 중, 오픈소스 기술 기반 데이터 보호 규정 준수
5. **영향도**: 8/10 - 소셜 미디어 규제와 민주적 숙의 과정의 실증적 연구를 위한 전례 없는 인프라를 제공하며, 증거 기반 정책 수립을 가능하게 함
6. **상세 설명**: 데이터 접근 제한, 실세계 실험의 윤리적 제약, 기존 연구 도구의 한계 등으로 소셜 미디어 역학 연구가 점점 어려워지는 상황에서 VIRENA는 돌파구를 제시한다. 핵심 혁신은 LLM 기반 AI 에이전트가 설정 가능한 페르소나와 현실적 행동으로 인간 참가자와 함께 참여한다는 점이다. 연구자는 콘텐츠 모더레이션 접근법 조작, 자극 콘텐츠 사전 예약, 조건 간 실험 실행 등을 시각적 인터페이스로 수행할 수 있다. 이는 기존에 비실용적이었던 연구 설계를 가능하게 한다.
7. **추론**: VIRENA는 "소셜 미디어 규제의 실증적 기반"을 구축하는 핵심 인프라가 될 수 있다. 현재 소셜 미디어 규제 논의는 대부분 일화적 증거나 관찰 연구에 기반하지만, VIRENA를 통해 모더레이션 정책의 인과적 효과를 실험적으로 검증할 수 있다. EU의 디지털 서비스법(DSA), 한국의 온라인 플랫폼 규제 논의에서 증거 기반 정책 수립의 핵심 도구로 활용될 전망이다. 또한 선거 시기 허위 정보 확산 메커니즘 연구에도 중요한 기여를 할 것이다.
8. **이해관계자**: 미디어 및 커뮤니케이션 연구자, 선거 관리 기관, 소셜 미디어 기업 정책 팀 (Meta, X, Reddit), 민주주의 연구 기관, 데이터 보호 기관 (GDPR 감독 기관), 시민 사회 단체
9. **모니터링 지표**: VIRENA 플랫폼 채택 대학 및 연구 기관 수, 플랫폼 기반 출판 논문 수, 규제 기관의 VIRENA 활용 정책 실험 사례, 소셜 미디어 기업의 반응 및 유사 도구 개발 동향

---

### 우선순위 5: 에이전틱 AI 사이버 보안 - 통제 가능한 자율성을 위한 메타인지 아키텍처

- **신뢰도**: pSST 87.0/100 (Grade A)

1. **분류**: 기술(T) - 사이버 보안, AI 거버넌스, 다중 에이전트 시스템
2. **출처**: Kojukhov, A. & Bovshover, A. "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy" (arXiv:2602.11897v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11897v1)
3. **핵심 사실**: 사이버 보안 오케스트레이션을 선형 탐지-대응 파이프라인이 아닌 에이전틱 다중 에이전트 인지 시스템으로 재개념화하는 아키텍처 프레임워크 제시. 탐지, 가설 형성, 맥락 해석, 설명, 거버넌스를 담당하는 이질적 AI 에이전트를 명시적 메타인지 판단 함수로 조율.
4. **정량 지표**: 분산 인지 이론 + 다중 에이전트 시스템 + 책임 있는 AI 거버넌스 프레임워크 3개 분야 통합, 메타인지 판단 함수의 1급 시스템 기능화, 증거 불완전/상충/운영 위험 상황에서의 동적 자율성 보정
5. **영향도**: 8/10 - SOC(보안 운영 센터)의 차세대 아키텍처를 정의하며, AI 자율 시스템의 책임 있는 의사 결정 프레임워크에 광범위한 시사점 제공
6. **상세 설명**: 현재 AI 기반 사이버 보안 시스템은 정확도와 대응 지연 같은 태스크 수준 성능 지표에 최적화된 모델 중심 탐지 파이프라인으로 설계되어 있다. 그러나 이 아키텍처는 적대적 불확실성 하에서 설명 가능하고 통제 가능한 의사 결정을 지원하기 어렵다. 이 논문은 현대 보안 운영이 이미 "분산 인지 시스템"으로 기능하고 있지만 명시적 조직 원리가 없다는 핵심 관찰에서 출발하여, 메타인지 판단을 1급 시스템 기능으로 내장함으로써 이 인지 구조를 명시적이고 통제 가능하게 만든다.
7. **추론**: 이 프레임워크는 사이버 보안을 넘어 "AI 자율 시스템의 통제 가능성(governability)" 문제의 일반적 해결 모델로 확장될 수 있다. 의료 진단, 자율 주행, 금융 거래 등 고위험 의사 결정 영역에서 AI 자율성과 인간 통제 간 균형 설정에 적용 가능한 설계 원칙을 제공한다. CISO(최고정보보안책임자)와 SOC 관리자에게 AI 기반 보안 시스템의 다음 세대 아키텍처 로드맵을 제시한다.
8. **이해관계자**: CISO 및 SOC 관리자, 사이버 보안 기업 (CrowdStrike, Palo Alto Networks, SentinelOne), 국가 사이버 보안 기관 (CISA, NCSC, KISA), AI 거버넌스 연구 기관, 방위 산업 사이버 부서
9. **모니터링 지표**: SOC 자동화 솔루션의 에이전틱 아키텍처 채택 현황, 사이버 보안 기업의 메타인지 기반 제품 발표, 국가 사이버 보안 전략에서의 AI 거버넌스 프레임워크 반영 여부, 관련 학술 논문 인용 추이

---

### 우선순위 6: 생성적 소셜 에이전트와 인간 간 설득적 상호작용 - 지식 기반 설득 모델(KPM)

- **신뢰도**: pSST 87.0/100 (Grade A)

1. **분류**: 사회(S) - AI 설득, 인간-AI 상호작용, 윤리적 AI
2. **출처**: Vonschallen, S. et al. "Understanding Persuasive Interactions between Generative Social Agents and Humans: The Knowledge-based Persuasion Model (KPM)" (arXiv:2602.11483v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11483v1)
3. **핵심 사실**: 생성적 소셜 에이전트(GSA)와 인간 사용자 간 설득적 상호작용을 체계적으로 이론화한 최초의 프레임워크인 지식 기반 설득 모델(KPM) 제시. GSA의 자아 지식, 사용자 지식, 맥락 지식이 설득 행동을 유도하고, 이것이 사용자의 태도와 행동을 형성하는 메커니즘을 체계화.
4. **정량 지표**: 3가지 지식 유형(자아/사용자/맥락)의 설득 메커니즘 체계화, 헬스케어 및 교육 등 적용 도메인의 시사점 도출, 사회 규범 및 윤리 기준 준수를 위한 설계 가이드라인 제시
5. **영향도**: 8/10 - AI 에이전트의 설득 능력이 급격히 향상되는 현 시점에서, "동기 부여(motivate) vs. 조작(manipulate)" 경계의 학문적 기준을 최초로 제시
6. **상세 설명**: ChatGPT, Claude 등 대화형 AI가 범용화되면서 AI 에이전트의 설득 능력에 대한 우려가 커지고 있으나, 이를 이론적으로 분석하는 프레임워크가 부재했다. KPM은 GSA가 자기 자신에 대한 지식(자아 지식), 대화 상대에 대한 지식(사용자 지식), 상황에 대한 지식(맥락 지식)을 어떻게 활용하여 설득 행동을 생성하는지를 체계화한다. 핵심적으로, "조작이 아닌 동기 부여"를 위한 책임 있는 GSA 설계 원칙을 제시하며, 사회 규범과 윤리 기준 준수를 통해 사용자 웰빙을 증진하는 방향으로의 에이전트 개발을 독려한다.
7. **추론**: KPM은 AI 규제 논의에서 "설득 vs. 조작"의 경계를 정량적으로 정의하는 데 기여할 수 있다. EU AI Act의 "조작적 AI 기술" 금지 조항의 구체적 해석 기준으로 활용될 가능성이 있으며, 마케팅, 선거 캠페인, 헬스케어 영역에서 AI 설득 에이전트의 윤리적 가이드라인 수립에 실질적 프레임워크를 제공한다. 특히 AI 치료 봇(therapy bot)의 급성장 맥락에서, 치료적 설득과 상업적 조작의 구분 기준이 시급히 필요한 상황이다.
8. **이해관계자**: AI 윤리 기구 (EU AI Office, UNESCO AI 윤리 위원회), 디지털 마케팅 기업, 헬스테크 기업 (AI 치료 봇 개발사), 소비자 보호 기관, 선거 관리 위원회, HCI(인간-컴퓨터 상호작용) 연구 커뮤니티
9. **모니터링 지표**: KPM 인용 빈도 및 적용 연구 사례, EU AI Act "조작적 AI" 조항의 해석 가이드라인 발표, AI 치료 봇 규제 동향 (FDA, EMA), 디지털 마케팅 AI의 설득 기법 투명성 요구 사항 변화

---

### 우선순위 7: 지속 가능 투자 정책을 위한 상대방 형성 기반 다중 에이전트 시뮬레이션 (InvestESG)

- **신뢰도**: pSST 87.0/100 (Grade A)

1. **분류**: 경제(E) - ESG 투자, 기후 리스크, 다중 에이전트 시뮬레이션
2. **출처**: Duque, J.A. et al. "Towards Sustainable Investment Policies Informed by Opponent Shaping" (arXiv:2602.11829v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11829v1)
3. **핵심 사실**: 기후 리스크 하에서 투자자와 기업 간 역학을 포착하는 다중 에이전트 시뮬레이션 InvestESG에 Advantage Alignment 알고리즘을 적용하여, 경제 에이전트의 학습 과정을 전략적으로 형성함으로써 개인 인센티브를 장기 지속 가능성 목표에 정렬시킬 수 있음을 이론적으로 증명.
4. **정량 지표**: InvestESG 시간 간 사회적 딜레마의 형식적 특성 규명, 개인 인센티브와 집단 복지가 분리되는 이론적 임계값 도출, Advantage Alignment이 사회적으로 유익한 균형으로 학습 역학을 편향시키는 메커니즘의 이론적 설명
5. **영향도**: 8/10 - 기후 변화 대응의 핵심 과제인 "개인 이익 vs. 집단 복지" 딜레마에 대한 AI 기반 정책 설계 도구를 제시
6. **상세 설명**: 기후 변화 대응은 글로벌 협조를 요구하지만, 합리적 경제 행위자는 즉각적 이익을 집단 복지보다 우선시하여 사회적 딜레마를 형성한다. 이 연구는 InvestESG 시뮬레이션에서 이러한 딜레마가 형성되는 조건을 형식적으로 규명하고, "상대방 형성(opponent shaping)" 기법인 Advantage Alignment이 에이전트의 학습 역학을 협력적 결과로 편향시켜 사회적으로 유익한 균형을 체계적으로 촉진함을 보여준다. 일반 합(general-sum) 게임에서 효과가 검증된 확장 가능한 알고리즘이라는 점에서 실용성이 높다.
7. **추론**: 이 연구는 ESG 투자 정책 설계에 "AI 기반 정책 시뮬레이션"이라는 새로운 도구를 제공한다. 중앙은행, 금융감독원, 국부펀드 등이 ESG 규제의 효과를 사전에 시뮬레이션하고, 시장 인센티브를 장기 지속 가능성 목표에 정렬시키는 최적 정책을 설계하는 데 활용될 수 있다. 한국의 K-Taxonomy, EU의 Sustainable Finance Disclosure Regulation(SFDR) 등 ESG 규제 프레임워크의 효과성을 사전 검증하는 도구로 발전할 가능성이 있다.
8. **이해관계자**: 중앙은행 및 금융감독 기관 (FSB, BIS, 한국 금감원), 국부펀드 (GPIF, GIC, KIC), ESG 평가 기관 (MSCI, Sustainalytics), 기후 금융 연구 기관 (NGFS), 국제기구 (UNEP FI, World Bank)
9. **모니터링 지표**: InvestESG 시뮬레이션의 정책 기관 채택 사례, Advantage Alignment 기반 정책 설계 도구 개발 동향, ESG 규제 사전 시뮬레이션 요구 도입 여부, 기후 금융 관련 AI 활용 논문 발표 추이

---

### 우선순위 8: 교차 아키텍처 모델 비교를 위한 Crosscoder - LLM 간 차이의 비지도적 발견

- **신뢰도**: pSST 86.0/100 (Grade A)

1. **분류**: 기술(T) - AI 해석 가능성, 모델 안전성, 기계적 해석 가능성
2. **출처**: Jiralerspong, T. & Bricken, T. "Cross-Architecture Model Diffing with Crosscoders: Unsupervised Discovery of Differences Between LLMs" (arXiv:2602.11729v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11729v1)
3. **핵심 사실**: 서로 다른 아키텍처의 LLM 내부 표현을 비교하여 안전성 관련 행동 차이를 비지도적으로 발견하는 Crosscoder 기법의 최초 교차 아키텍처 적용 성공. Qwen3-8B의 중국 공산당 정렬, Llama3.1의 미국 예외주의, GPT-OSS-20B의 저작권 거부 메커니즘 등을 비지도 방식으로 발견.
4. **정량 지표**: Dedicated Feature Crosscoders(DFCs) 아키텍처 수정안 제시, Qwen3-8B/Deepseek-R1-0528의 CCP 정렬 특성, Llama3.1-8B-Instruct의 미국 예외주의 특성, GPT-OSS-20B의 저작권 거부 메커니즘 등 비지도 발견
5. **영향도**: 8/10 - AI 모델의 "숨겨진 편향"을 체계적으로 발견하는 도구로, 지정학적 AI 경쟁 시대의 모델 신뢰성 평가에 핵심적 기여
6. **상세 설명**: 모델 비교(model diffing)는 새로운 모델의 안전성 관련 행동을 기존 모델과 비교하여 발견하는 유망한 접근법이나, 기존에는 동일 아키텍처의 베이스-파인튠 비교에 제한되어 있었다. 새로운 LLM은 대부분 새로운 아키텍처로 출시되므로, 교차 아키텍처 방법이 필수적이다. 이 연구는 Crosscoder를 교차 아키텍처로 확장하고, 특정 모델에 고유한 특성을 더 잘 분리하기 위한 Dedicated Feature Crosscoders(DFCs)를 도입했다. 발견된 특성들 -- 중국 공산당 정렬, 미국 예외주의, 저작권 거부 -- 은 각 모델의 훈련 데이터와 정렬 과정에서 내재된 가치 체계를 반영한다.
7. **추론**: 이 연구는 "AI 모델의 지정학적 편향 감사"라는 새로운 분야의 개척을 예고한다. 각국 정부와 기업이 외국산 AI 모델을 도입할 때 해당 모델에 내재된 가치 편향을 사전에 감사하는 프로세스가 표준화될 가능성이 있다. 한국 기업이 중국산(Qwen, DeepSeek) 또는 미국산(Llama, GPT) 모델을 채택할 때 Crosscoder 기반 편향 감사가 필수 절차로 자리잡을 수 있다. 이는 "AI 주권(AI sovereignty)" 논의에 구체적 기술적 도구를 제공한다.
8. **이해관계자**: 국가 AI 전략 기관 (한국 AI 위원회, 미국 NIST AI Safety Institute), AI 모델 개발사 (Anthropic, Meta, Alibaba), AI 감사 기업, 국방/정보 기관, 기업 CTO/AI 담당 부서
9. **모니터링 지표**: Crosscoder 기반 모델 감사 도구의 상용화 동향, 주요국 AI 모델 수입 규제에서의 편향 감사 요구 도입, LLM 내재 가치 편향 관련 후속 연구 발표, AI 주권 정책 논의에서의 기술적 감사 도구 언급 빈도

---

### 우선순위 9: 인간-AI 의사결정에서 LLM 역할 아키타입 - 누가 무엇을 하는가?

- **신뢰도**: pSST 86.0/100 (Grade A)

1. **분류**: 사회(S) - 인간-AI 의사결정, 조직 설계, 사회기술적 상호작용
2. **출처**: Chappidi, S. et al. "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making" (arXiv:2602.11924v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11924v1)
3. **핵심 사실**: LLM 기반 의사결정에서 인간과 LLM에 부여되는 역할의 반복적 사회기술적 패턴인 17가지 인간-LLM 아키타입을 113편 논문의 범위 문헌 검토와 주제 분석을 통해 체계화. 실제 임상 진단 사례에서 아키타입 선택이 LLM 출력과 의사결정 결과에 미치는 영향을 실증.
4. **정량 지표**: 113편 LLM 지원 의사결정 논문 분석, 17개 인간-LLM 아키타입 도출, 실제 임상 진단 사례 기반 아키타입 효과 평가, 의사결정 통제/사회적 위계/인지 강제 전략/정보 요구사항 등 설계 차원 분석
5. **영향도**: 8/10 - 인간-AI 협업 시스템 설계의 표준 프레임워크를 제시하며, 의료, 법률, 금융 등 고위험 의사결정 영역의 AI 도입 설계에 직접 적용 가능
6. **상세 설명**: LLM이 의료, 법률, 금융 등 고위험 의사결정 영역에서 활용이 확대되면서, 인간과 LLM의 역할 분담 방식이 의사결정 품질에 미치는 영향을 체계적으로 이해할 필요가 커지고 있다. 이 연구는 "인간-LLM 아키타입"이라는 개념을 도입하여 17가지 반복적 상호작용 패턴을 식별했다. 핵심 발견은 아키타입 선택 자체가 LLM 출력과 의사결정 결과에 영향을 미친다는 것이며, 이는 AI 시스템 설계자가 역할 분담 방식을 의식적으로 설계해야 함을 시사한다.
7. **추론**: 이 프레임워크는 AI 보조 의사결정 시스템의 설계 표준으로 발전할 가능성이 높다. 의료 AI(진단 보조), 법률 AI(판결 예측), 금융 AI(투자 자문) 등 각 영역별로 최적의 인간-LLM 아키타입이 상이할 수 있으며, 이를 실증적으로 검증하는 후속 연구가 활발해질 전망이다. 특히 규제 기관이 고위험 AI 시스템의 인간-AI 역할 분담 방식을 인증 요건에 포함시킬 가능성도 있다.
8. **이해관계자**: 의료 AI 기업 및 병원 AI 위원회, 법률 AI 기업 (Harvey, Casetext), 금융 AI 규제 기관, UX/HCI 연구 커뮤니티, AI 시스템 설계자, ISO/IEC AI 표준 기구
9. **모니터링 지표**: 인간-LLM 아키타입 프레임워크 인용 및 적용 사례, 의료/법률/금융 AI의 역할 분담 설계 가이드라인 발표, 규제 기관의 인간-AI 상호작용 설계 인증 요건 도입, 후속 실증 연구 발표 빈도

---

### 우선순위 10: 지속 가능한 정보 신선도 지표 - 실시간 상태 업데이트의 탄소 발자국

- **신뢰도**: pSST 86.0/100 (Grade A)

1. **분류**: 환경(E) - 탄소 발자국, IoT/통신 지속 가능성, 그린 네트워킹
2. **출처**: Chou, S. et al. "Towards a Sustainable Age of Information Metric: Carbon Footprint of Real-Time Status Updates" (arXiv:2602.11946v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11946v1)
3. **핵심 사실**: 정보 신선도(Age of Information, AoI) 최적화와 탄소 발자국(Carbon Footprint, CF) 간의 명확한 트레이드오프를 최초로 규명하고, 탄소 인식 AoI 프레임워크를 제시. AoI 최소화가 CF 최소화를 내재적으로 보장하지 않으며, 지속 가능한 운용에는 CF 예산, 신호 대 잡음비(SNR), 전송 스케줄링의 공동 최적화가 필요함을 증명.
4. **정량 지표**: M/M/1 및 M/M/1* 대기 모델에 대한 AoI 폐쇄형 해석, 고정 탄소 강도(CI) 및 동적 시변 CI 조건 분석, CF 예산 제약 하 AoI 최소화 문제 해법 도출
5. **영향도**: 8/10 - 5G/6G, IoT, 자율 시스템 등 차세대 네트워크의 설계 원칙에 탄소 인식을 내재화하는 기초 이론을 제공
6. **상세 설명**: 데이터 기반 지능형 인프라에서 수집 정보의 적시성은 모니터링과 제어에 필수적이며, 이는 AoI 지표로 정량화된다. 그러나 정보 신선도를 유지하기 위한 빈번한 전송은 상당한 탄소 발자국을 수반한다. 이 연구는 이 격차를 해소하기 위해 탄소 인식 AoI 프레임워크를 도입했다. 핵심 결과로, AoI 최소화와 CF 최소화가 정렬되지 않음을 보여주며, 탄소 강도의 시변성이 달성 가능한 AoI에 추가적 영향을 미침을 증명했다.
7. **추론**: 이 연구는 차세대 통신 네트워크(5G/6G) 설계에서 "탄소 인식"이 기본 설계 원칙으로 내재화되는 전환점을 예고한다. 현재 네트워크 설계는 지연 시간, 처리량, 신뢰성 등 성능 지표에 최적화되지만, 유럽 그린딜, 파리 협정 이행 가속 등의 정책 압력 하에서 탄소 발자국이 추가 설계 제약으로 부상할 전망이다. 한국의 디지털 탄소 중립 전략에도 직접 적용 가능한 이론적 기반을 제공한다.
8. **이해관계자**: 통신 사업자 (SKT, KT, LGU+, AT&T, Vodafone), 네트워크 장비 기업 (Samsung Networks, Ericsson, Nokia), 3GPP/ETSI 표준 기구, 환경 규제 기관, IoT 플랫폼 기업 (AWS IoT, Azure IoT), 스마트 시티 추진 기관
9. **모니터링 지표**: 3GPP/ETSI 표준에서의 탄소 인식 네트워크 설계 논의 진행 상황, 통신 사업자의 네트워크 탄소 발자국 보고 의무화 동향, 탄소 인식 IoT 프로토콜 관련 연구 발표 추이, 유럽 그린딜 디지털 부문 규제 업데이트

---

### 우선순위 11: CATTS - 웹 에이전트를 위한 에이전틱 테스트 시점 스케일링

- **신뢰도**: pSST 85.0/100 (Grade B+)

1. **분류**: 기술(T) - 웹 에이전트, 테스트 시점 스케일링, 적응적 연산 할당
2. **출처**: Lee, N. et al. "Agentic Test-Time Scaling for WebAgents" (arXiv:2602.12276v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12276v1)
3. **핵심 사실**: 다단계 에이전트 과제에서 균일한 연산 증가가 급속히 포화됨을 발견하고, 투표 분포 기반 불확실성(엔트로피, top-1/top-2 마진)을 활용하여 의사결정이 실질적으로 논쟁적일 때만 연산을 동적 할당하는 CATTS(Confidence-Aware Test-Time Scaling) 기법 제시. WebArena-Lite 및 GoBrowse에서 최대 9.1% 성능 향상, 토큰 사용량 최대 2.3배 감소.
4. **정량 지표**: WebArena-Lite/GoBrowse에서 React 대비 최대 +9.1% 성능, 균일 스케일링 대비 최대 2.3배 토큰 절감, 엔트로피 및 top-1/top-2 마진의 성공률 상관관계 실증
5. **영향도**: 8/10 - AI 에이전트의 연산 효율성과 성능을 동시에 향상시키는 실용적 프레임워크로, 에이전트 상용화의 핵심 장벽인 비용 문제 해결에 기여
6. **상세 설명**: 테스트 시점 스케일링이 언어 모델의 표준적 성능 향상 방법으로 자리잡았지만, 다단계 에이전트 과제에서의 동작은 잘 이해되지 않았다. 작은 단계별 오류가 긴 시간 범위에서 복합되며, 균일한 샘플링 증가는 수확 체감을 보인다. CATTS는 에이전트 자체의 투표 분포에서 도출된 불확실성 통계를 활용하여 의사결정이 진정으로 논쟁적인 경우에만 추가 연산을 할당하는 원칙을 제시한다.
7. **추론**: CATTS는 AI 에이전트의 "연산 비용 최적화"라는 상업적으로 핵심적인 문제에 실용적 해법을 제시한다. 웹 브라우징 에이전트(Anthropic Computer Use, OpenAI Operator 등)의 상용화가 가속되는 현 시점에서, 토큰 사용량을 크게 줄이면서도 성능을 유지/향상시키는 기법은 에이전트 서비스의 가격 경쟁력에 직접적 영향을 미친다.
8. **이해관계자**: AI 에이전트 개발사 (Anthropic, OpenAI, Cognition AI), 웹 자동화 기업, 클라우드 컴퓨팅 제공자, RPA(Robotic Process Automation) 기업, 엔터프라이즈 소프트웨어 기업
9. **모니터링 지표**: 주요 AI 에이전트 서비스의 CATTS 유사 기법 채택 발표, 웹 에이전트 벤치마크 성능 대비 비용 효율성 추이, AI 에이전트 서비스 가격 변동, 적응적 연산 할당 관련 후속 연구 발표

---

### 우선순위 12: 탈중앙화 프로토콜의 정당한 개입 - 긴급 거버넌스의 정량적 분석

- **신뢰도**: pSST 85.0/100 (Grade B+)

1. **분류**: 정치(P) - 블록체인 거버넌스, 탈중앙화 규제, 디지털 자산 정책
2. **출처**: Elem, O. & Talmon, N. "Legitimate Overrides in Decentralized Protocols" (arXiv:2602.12260v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12260v1)
3. **핵심 사실**: 탈중앙화 프로토콜의 긴급 개입 메커니즘(체인 동결, 프로토콜 일시 중지, 계정 격리)을 Scope x Authority 분류 체계로 체계화하고, 705건의 실제 익스플로잇 사건 분석을 통해 권한 유형별 봉쇄 시간 차이, 손실의 중꼬리 분포(heavy-tailed distribution, alpha 약 1.33), 커뮤니티 감정의 비용 조절 효과를 실증.
4. **정량 지표**: 705건 익스플로잇 사건 분석, 약 100억 달러 기술적 익스플로잇 손실 추정(2016-2026), 손실 분포 alpha 약 1.33 (heavy-tailed), 권한 유형별 봉쇄 시간 체계적 차이 확인
5. **영향도**: 8/10 - "탈중앙화 vs. 안전" 딜레마를 이념적 논쟁에서 정량적 공학으로 전환하는 최초의 체계적 분석으로, DeFi 규제 설계에 직접 적용 가능
6. **상세 설명**: 탈중앙화 프로토콜은 불변의 규칙 기반 실행을 표방하지만, 실제로는 익스플로잇과 시스템 장애 대응을 위한 긴급 메커니즘을 내장하고 있다. 이 연구는 개입의 정밀도와 트리거 권한의 집중도라는 두 차원으로 긴급 아키텍처의 설계 공간을 매핑하는 Scope x Authority 분류 체계를 개발했다. 705건의 실제 익스플로잇 데이터를 분석한 결과, 봉쇄 시간은 권한 유형에 따라 체계적으로 다르며, 손실은 드문 재앙적 사건에 집중되는 중꼬리 분포를 따르고, 커뮤니티 감정이 개입 역량 유지 비용을 측정 가능하게 조절함을 발견했다.
7. **추론**: 이 연구는 DeFi 거버넌스 논의를 "완전 탈중앙화 vs. 중앙 집중" 이분법에서 "최적 거버넌스 설계"로 전환시킬 수 있다. 미국 SEC, EU MiCA, 한국 가상자산법 등 각국 규제 프레임워크가 탈중앙화 프로토콜의 긴급 개입 메커니즘 의무화를 검토할 때 실증적 기반을 제공한다. 특히 alpha 약 1.33의 중꼬리 분포 발견은 보험 산업의 DeFi 리스크 모델링에도 직접 적용 가능하다.
8. **이해관계자**: 블록체인 거버넌스 연구자, DeFi 프로토콜 개발팀 (Aave, Uniswap, MakerDAO), 금융 규제 기관 (SEC, MiCA 감독 기관, 한국 금감원), 블록체인 보험 기업, 가상자산 거래소, Web3 법률 전문가
9. **모니터링 지표**: DeFi 프로토콜의 긴급 거버넌스 메커니즘 채택 및 설계 변경 추이, 규제 기관의 탈중앙화 프로토콜 긴급 개입 의무화 논의, DeFi 익스플로잇 손실 규모 및 빈도 추이, 블록체인 거버넌스 표준화 논의 진행 상황

---

### 우선순위 13: GigaBrain-0.5M* - 월드 모델 기반 강화학습으로 학습하는 VLA 모델

- **신뢰도**: pSST 84.0/100 (Grade B+)

1. **분류**: 기술(T) - 로보틱스, 비전-언어-행동, 월드 모델
2. **출처**: GigaBrain Team et al. "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning" (arXiv:2602.12099v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12099v1)
3. **핵심 사실**: 웹 규모 비디오 코퍼스에서 사전학습된 비디오 월드 모델의 시공간 추론 능력을 VLA 모델에 통합하는 RAMP(Reinforcement leArning via world Model-conditioned Policy) 프레임워크 발표. 10,000시간 이상의 로봇 조작 데이터로 사전학습된 GigaBrain-0.5 기반으로, 세탁물 접기, 상자 포장, 에스프레소 제조 등 복잡한 과제에서 약 30% 성능 향상 달성.
4. **정량 지표**: 10,000시간 이상 로봇 조작 데이터 사전학습, RoboChallenge 벤치마크 1위 (중간 버전), RECAP 베이스라인 대비 약 30% 성능 향상 (세탁물 접기/상자 포장/에스프레소 제조), 실세계 배포 검증
5. **영향도**: 8/10 - "월드 모델 + 강화학습 + VLA"의 결합이 로봇의 장기 시계열 조작 능력에 획기적 진전을 가져오며, 가정용 로봇의 상용화 가능성을 한 단계 높임
6. **상세 설명**: 현재 VLA 모델은 현재 관찰에서 직접 다단계 행동 청크를 예측하는 방식으로 동작하여, 제한된 장면 이해와 약한 미래 예측 능력이라는 한계를 갖는다. GigaBrain-0.5M*는 웹 규모 비디오로 사전학습된 비디오 월드 모델이 가진 강력한 시공간 추론과 미래 예측 능력을 VLA 학습에 통합한다. RAMP 프레임워크는 월드 모델에 조건화된 정책을 통한 강화학습으로, 안정적인 교차 과제 적응(cross-task adaptation)을 가능하게 한다.
7. **추론**: 이 연구는 "범용 가정 로봇"의 실현에 한 걸음 더 가까워졌음을 시사한다. 세탁물 접기, 상자 포장, 에스프레소 제조 등 일상적이면서도 복잡한 조작 과제에서의 성공은 소비자 및 서비스 로봇 시장에 직접적 시사점을 제공한다. 다만, 10,000시간 규모의 로봇 데이터 수집 비용이 여전히 높은 진입 장벽이므로, 시뮬레이션-실세계 전이(sim-to-real) 기술과의 결합이 핵심 과제가 될 것이다.
8. **이해관계자**: 로봇 스타트업 (Figure AI, 1X, Covariant), 대형 기술 기업 로봇 부서 (Google DeepMind, Tesla), 가전 기업 (Samsung, LG), 물류/유통 기업 (Amazon Robotics, Ocado), 로봇 하드웨어 제조사
9. **모니터링 지표**: GigaBrain 후속 버전 발표 및 벤치마크 성능, 주요 로봇 기업의 월드 모델 기반 VLA 채택 동향, RoboChallenge 벤치마크 순위 변동, 가정용/서비스 로봇 상용화 타임라인 업데이트

---

### 우선순위 14: 볼록 마르코프 게임 이론의 확장 - 내쉬 균형의 새로운 존재 증명과 학습 알고리즘

- **신뢰도**: pSST 84.0/100 (Grade B+)

1. **분류**: 경제(E) - 게임 이론, 다중 에이전트 학습, 경제 모델링
2. **출처**: Barakat, A. et al. "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria" (arXiv:2602.12181v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.12181v1)
3. **핵심 사실**: 볼록 마르코프 게임(cMG)을 에이전트 간 점유 측도 결합을 요구하는 새로운 응용을 포착하는 일반 효용 마르코프 게임(GUMG)으로 확장하고, 내쉬 균형이 투영된 의사 기울기 역학의 고정점과 일치함을 증명. 브라우어 고정점 정리를 통한 내쉬 균형 존재의 간결한 새 증명과 마르코프 완전 균형의 존재를 최초 확립.
4. **정량 지표**: 에이전트별 기울기 지배(gradient domination) 속성 발견, 브라우어 고정점 정리를 통한 내쉬 균형 존재의 간결한 증명, GUMG 정책 기울기 정리 확립, 모델 프리 정책 기울기 알고리즘의 반복 복잡도 보장 도출
5. **영향도**: 7/10 - 다중 에이전트 AI 시스템의 이론적 기반을 확장하며, 경쟁적 AI 에이전트 간 균형 전략 설계의 수학적 기초를 강화
6. **상세 설명**: 볼록 마르코프 게임은 전략적 에이전트가 가산적 보상을 넘어 일반적 효용을 최적화하는 다중 에이전트 학습 문제의 광범위한 클래스이다. 이 연구는 cMG를 에이전트 간 점유 측도의 결합을 허용하는 GUMG로 확장하여, 새로운 응용(에이전트 간 상호 의존적 효용)을 포착한다. 핵심 기여는 내쉬 균형의 새로운 특성화(1차 정상점 일치), 간결한 존재 증명, 마르코프 완전 균형 존재 확립, 정책 기울기 학습 알고리즘의 수렴 보장이다.
7. **추론**: 이 이론적 발전은 AI 에이전트 간 전략적 상호작용이 핵심인 영역 -- 자율 거래 시스템, 경매 설계, 다중 에이전트 로보틱스, 분산 에너지 시장 -- 에서 균형 전략의 존재와 학습 가능성을 수학적으로 보장하는 기반을 제공한다. 특히 "모델 프리" 정책 기울기 알고리즘의 수렴 보장은 실제 배포 환경에서의 적용 가능성을 높인다.
8. **이해관계자**: 다중 에이전트 AI 연구 커뮤니티, 경매/시장 설계 기관, 분산 에너지 시장 운영자, 자율 거래 시스템 개발사, 게임 이론 연구자, AI 경제학 연구 기관
9. **모니터링 지표**: GUMG 프레임워크 인용 및 적용 연구 사례, 다중 에이전트 AI 시스템의 균형 전략 학습 기법 발전, 자율 거래/경매 설계에서의 게임 이론 기반 AI 적용 사례, NeurIPS/ICML 등 주요 학회에서의 관련 논문 발표 추이

---

### 우선순위 15: TAVAE - 적응적 사전 분포가 시각 피질의 맥락적 조절을 설명하는 VAE 모델

- **신뢰도**: pSST 83.0/100 (Grade B+)

1. **분류**: 정신적(s) - 신경과학, 인지 모델링, 시각 인지
2. **출처**: Meszena, B. et al. "TAVAE: A VAE with Adaptable Priors Explains Contextual Modulation in the Visual Cortex" (arXiv:2602.11956v1, 2026-02-12) [링크](https://arxiv.org/abs/2602.11956v1)
3. **핵심 사실**: 과제별 맥락적 사전 분포를 유연하게 학습하는 Task-Amortized VAE(TAVAE)를 개발하고, 마우스 V1 영역 대규모 기록과의 비교를 통해 시각 피질이 과제별 사전 분포를 수요에 따라 학습하고 시각 처리의 최초 단계(V1)에서 이미 배포할 수 있음을 확인.
4. **정량 지표**: 단순 변별 과제 최적화, V1 대규모 뉴런 기록과의 비교, 훈련된 과제 통계 위반 자극에 대한 이중 모드(bimodal) 반응 프로필 확인, 일일 내 집단 반응 업데이트 포착
5. **영향도**: 7/10 - 뇌의 학습 메커니즘에 대한 새로운 이해를 제공하며, "확률적 추론으로서의 인지" 이론을 실증적으로 뒷받침하여 차세대 AI 아키텍처 설계에 영감을 줄 수 있음
6. **상세 설명**: 뇌는 학습된 규칙성을 통해 시각 정보를 해석하며, 이 과정은 확률적 추론(사전 분포 하의 추론)으로 형식화된다. 시각 피질은 이 추론을 위한 사전 분포를 구축하며, 일부는 하향식(top-down) 연결을 통해 고수준 피질에서 저수준 피질로 전달된다. 적응이 자연 이미지 구조를 반영하는 사전 분포로 이어진다는 증거는 있지만, 특정 과제 학습 시 유사한 사전 분포가 유연하게 획득될 수 있는지는 불분명했다. TAVAE는 과제가 이전에 학습된 표현을 재사용하여 효율적으로 획득될 수 있도록 VAE 형식을 확장하며, 학습된 과제별 사전 분포와 감각 증거 간 불일치가 V1 기록의 이중 모드 반응 프로필과 일치하는 불확실성 서명을 생성함을 보여준다.
7. **추론**: 이 연구는 "뇌에서 영감을 받은 AI"의 새로운 방향을 제시한다. 과제별 사전 분포의 유연한 학습이라는 발견은 현재 AI 시스템이 부족한 "맥락 의존적 지각"을 구현하는 데 핵심적 통찰을 제공한다. 특히 TAVAE의 "이전 표현 재사용" 메커니즘은 전이 학습(transfer learning)의 신경과학적 기반을 밝히며, 보다 효율적인 AI 아키텍처 설계에 영감을 줄 수 있다. 인간 인지의 "유연한 적응"을 모방하는 AI의 개발은 인공 일반 지능(AGI) 연구의 핵심 방향 중 하나이다.
8. **이해관계자**: 계산 신경과학 연구 커뮤니티, AI 아키텍처 연구자, 뉴로모픽 컴퓨팅 기업 (Intel Loihi, IBM TrueNorth), 인지 과학 연구 기관, AGI 연구 기관 (DeepMind, OpenAI, Anthropic)
9. **모니터링 지표**: TAVAE 기반 후속 신경과학 연구 발표, 과제별 사전 분포 학습 메커니즘의 AI 아키텍처 적용 사례, 뇌-AI 대응 연구(brain-AI alignment) 동향, 뉴로모픽 컴퓨팅 칩의 적응적 사전 분포 구현 진행 상황

---

## 3. 기존 신호 업데이트

> 활성 추적 스레드: 582개 | 강화: 0개 | 약화: 0개 | 소멸: 0개

### 3.1 강화 추세 (Strengthening)

| 신호 ID | 제목 | 이전 pSST | 현재 pSST | 변화 | 상태 |
|---------|------|-----------|-----------|------|------|
| - | 해당 없음 | - | - | - | - |

이번 스캔에서 기존 신호와의 직접적 반복 등장(recurring) 또는 강화 추세(strengthening)는 탐지되지 않았다. 이는 arXiv 논문의 특성상 동일 논문이 재등장하지 않는 구조적 특성에 기인한다. 다만, 테스트 시점 스케일링(TTS) 주제는 2월 15일 스캔의 "역량 지향 훈련" 주제와 AI 정렬/안전이라는 상위 테마에서 연결되며, 이 테마의 연속적 발현으로 해석할 수 있다.

### 3.2 약화 추세 (Weakening)

| 신호 ID | 제목 | 이전 pSST | 현재 pSST | 변화 | 상태 |
|---------|------|-----------|-----------|------|------|
| - | 해당 없음 | - | - | - | - |

약화 추세 신호는 탐지되지 않았다.

### 3.3 신호 상태 요약

| 상태 | 수 | 비율 |
|------|---|------|
| 신규 | 15 | 100.0% |
| 강화 | 0 | 0.0% |
| 반복 등장 | 0 | 0.0% |
| 약화 | 0 | 0.0% |
| 소멸 | 0 | 0.0% |

arXiv 논문은 고유 ID(arXiv ID)를 가지므로 동일 논문의 반복 등장이 구조적으로 발생하지 않는다. 그러나 **주제 수준의 연속성** 분석에서는 주목할 만한 패턴이 관찰된다. "테스트 시점 스케일링" 주제는 금번 스캔에서 3건(#1 CoVer, #2 UniT, #11 CATTS)이 동시에 등장하였으며, 이는 이 연구 방향이 학술 커뮤니티에서 빠르게 확산 중임을 나타내는 강력한 신호이다. 또한, "AI 안전성 도구의 오픈소스화" 테마는 전일 스캔의 SafeNeuron, 역량 지향 훈련 정렬 위험과 연속선 상에 있다.

---

## 4. 패턴 및 연결고리

### 4.1 신호 간 교차 영향

**패턴 1: 테스트 시점 스케일링(TTS) 생태계의 급속 형성**

- CoVer(#1) ↔ UniT(#2): 로보틱스 VLA 검증 스케일링과 멀티모달 CoT 스케일링이 "추론 시점 연산 증가 = 성능 향상"이라는 동일 원리를 공유하며, 도메인 간 TTS 패러다임의 범용성을 상호 입증
- UniT(#2) ↔ CATTS(#11): 멀티모달 추론 스케일링과 웹 에이전트 적응적 연산 할당이 "균일 스케일링의 수확 체감"이라는 공통 관찰에서 출발하여, 선택적/동적 연산 할당이 핵심임을 교차 검증
- CoVer(#1) ↔ GigaBrain(#13): 검증 기반 VLA 접근법과 월드 모델 기반 VLA가 범용 로봇의 "의도-행동 격차" 해소라는 동일 목표를 다른 경로로 추구하며, 결합 시 시너지 잠재력이 높음

신호 #1(CoVer), #2(UniT), #11(CATTS)은 모두 "추론 시점에 더 많은 연산을 투자하여 성능을 향상시키는" 테스트 시점 스케일링 패러다임에 속한다. 그러나 각각은 서로 다른 도메인(로보틱스, 멀티모달 생성, 웹 브라우징)에 적용되어, TTS가 특정 영역이 아닌 범용적 AI 개선 전략으로 자리잡고 있음을 보여준다. 이 세 논문이 동시에 arXiv에 등장한 것은 2026년 초 AI 연구의 핵심 방향 전환을 나타내는 강력한 수렴 신호이다.

**패턴 2: AI 안전성의 "도구적 민주화"와 "편향 감사" 동시 진행**

- DeepSight(#3) ↔ Crosscoder(#8): 화이트박스 안전 진단 도구와 교차 아키텍처 편향 발견 도구가 결합되면 AI 모델의 안전성과 가치 편향을 통합적으로 감사하는 완전한 파이프라인 구축 가능
- DeepSight(#3) ↔ 에이전틱 사이버보안(#5): AI 안전 평가 도구의 민주화와 AI 기반 보안 시스템의 거버넌스 프레임워크가 결합하여, AI 시스템 자체의 안전성 확보와 AI를 통한 보안 강화라는 양방향 신뢰 구축 생태계 형성

신호 #3(DeepSight)과 #8(Crosscoder)은 AI 안전성 평가를 소수 대형 기업의 전유물에서 광범위한 사용자에게 개방하는 도구를 제공한다. DeepSight는 블랙박스 안전 평가를 화이트박스 진단으로 전환하고, Crosscoder는 서로 다른 아키텍처의 LLM에 내재된 가치 편향을 비지도적으로 발견한다. 이 두 도구의 조합은 규제 기관과 학계가 AI 모델의 안전성과 편향을 독립적으로 검증할 수 있는 역량을 크게 강화한다.

**패턴 3: 인간-AI 상호작용의 이론적 체계화 물결**

- VIRENA(#4) ↔ KPM(#6): 소셜 미디어 환경에서의 인간-AI 실험 인프라와 AI 설득 이론 모델이 결합하면, AI 에이전트의 설득적 행동이 소셜 미디어 역학에 미치는 영향을 실험적으로 검증 가능
- KPM(#6) ↔ 인간-LLM 아키타입(#9): 설득 메커니즘 이론과 역할 분담 분류 체계가 결합하여, 특정 아키타입에서 설득 효과가 어떻게 달라지는지를 구조화된 방식으로 분석 가능

신호 #4(VIRENA), #6(KPM), #9(인간-LLM 아키타입)은 모두 인간과 AI 에이전트의 상호작용을 이론적으로 체계화하려는 시도이다. VIRENA는 실험적 인프라를, KPM은 설득 메커니즘의 이론을, 아키타입 연구는 역할 분담의 분류 체계를 제공한다. 이 세 연구는 AI가 사회에 미치는 영향을 "직관적 우려"에서 "체계적 학문"으로 전환시키는 공동의 흐름을 형성한다.

**패턴 4: 경제-환경 교차점에서의 지속 가능성 모델링**

- InvestESG(#7) ↔ 탄소 인식 AoI(#10): 금융 영역의 ESG 투자 시뮬레이션과 통신 영역의 탄소 인식 네트워크 설계가 "개인 최적화 ≠ 집단 복지"라는 동일한 사회적 딜레마 구조를 공유하며, 시스템 수준 지속 가능성 설계 원칙의 범분야적 적용 가능성을 시사

신호 #7(InvestESG)과 #10(탄소 인식 AoI)은 각각 금융과 통신 영역에서 지속 가능성을 정량적 최적화 문제로 재정의한다. 두 연구 모두 "개인 최적화가 집단 복지를 보장하지 않는다"는 공통 관찰에서 출발하여, 시스템 수준의 지속 가능성을 달성하기 위한 설계 원칙을 제시한다.

### 4.2 떠오르는 테마

**테마 1: "훈련 스케일링에서 추론 스케일링으로" (Training Scaling to Inference Scaling)**

이번 스캔의 가장 강력한 메타 테마이다. AI 모델의 성능 향상 전략이 "더 큰 모델, 더 많은 데이터"에서 "더 스마트한 추론 시점 연산 할당"으로 전환되고 있다. 이는 AI 산업의 비용 구조, 배포 전략, 경쟁 역학에 근본적 변화를 가져올 수 있다. 소규모 모델이 추론 시점 스케일링으로 대규모 모델과 경쟁할 수 있다면, AI 산업의 진입 장벽이 낮아지고 경쟁 구도가 재편될 전망이다.

**테마 2: "AI 거버넌스의 실용적 도구화" (Practical Tooling for AI Governance)**

DeepSight(#3), Crosscoder(#8), VIRENA(#4), KPM(#6) 등 이번 스캔에서 다수의 연구가 AI 거버넌스를 "원칙 선언"에서 "실용적 도구"로 전환하는 데 기여하고 있다. 이는 EU AI Act, 미국 AI 행정명령 등 규제 프레임워크의 실효성 있는 이행을 가능하게 하는 기반이 형성되고 있음을 시사한다.

**테마 3: "범용 로봇의 임계점 접근" (General-Purpose Robotics Approaching Threshold)**

CoVer(#1)와 GigaBrain(#13)은 각각 검증 기반 접근법과 월드 모델 기반 강화학습을 통해 범용 로봇의 과제 수행 능력을 한 단계 끌어올리고 있다. 세탁물 접기, 에스프레소 제조 등 일상적 과제에서의 성공은 가정용/서비스 로봇의 상용화 임계점이 가까워지고 있음을 보여준다.

---

## 5. 전략적 시사점

### 5.1 즉시 조치 필요 (0-6개월)

1. **테스트 시점 스케일링 기술 동향 추적 강화**: CoVer, UniT, CATTS로 대표되는 TTS 패러다임이 AI 산업의 차세대 경쟁 축으로 부상하고 있다. 자사 AI 시스템의 추론 시점 연산 최적화 전략을 점검하고, TTS 기술 도입 로드맵을 수립해야 한다. 특히 에이전트형 AI 서비스를 운영하거나 계획 중인 기업은 CATTS 유사 적응적 연산 할당 기법의 조기 도입을 검토해야 한다.

2. **AI 모델 편향 감사 프로세스 도입 검토**: Crosscoder(#8)가 보여준 교차 아키텍처 모델 비교 기술은 외국산 AI 모델(중국산 Qwen/DeepSeek, 미국산 Llama/GPT) 도입 시 내재 편향을 사전 감사하는 실용적 도구를 제공한다. AI 모델 도입 의사결정에 편향 감사를 필수 프로세스로 내재화하는 것을 권고한다.

3. **DeepSight 활용 AI 안전 평가 역량 구축**: 오픈소스 AI 안전 툴킷 DeepSight(#3)를 활용하여 자사/도입 AI 모델의 안전성을 독립적으로 평가할 수 있는 내부 역량을 구축해야 한다. EU AI Act 준수 준비의 일환으로도 필수적이다.

### 5.2 중기 모니터링 (6-18개월)

1. **AI 설득 에이전트 규제 프레임워크 대비**: KPM(#6)이 제시하는 "동기 부여 vs. 조작" 경계의 학문적 기준이 규제에 반영될 가능성에 대비해야 한다. 마케팅, 고객 서비스, 헬스케어 등 AI 에이전트를 활용하는 모든 영역에서 설득 메커니즘의 윤리적 가이드라인을 선제적으로 수립해야 한다.

2. **ESG 정책 시뮬레이션 도구 동향 추적**: InvestESG(#7) 유형의 다중 에이전트 시뮬레이션이 ESG 규제 설계의 표준 도구로 발전할 가능성이 있다. K-Taxonomy, SFDR 등 ESG 규제 강화 맥락에서 정책 사전 시뮬레이션 역량의 중요성이 증대될 전망이다.

3. **범용 로봇 상용화 타임라인 재평가**: CoVer(#1)와 GigaBrain(#13)의 성과를 고려할 때, 가정용/서비스 로봇의 상용화 타임라인이 기존 예측보다 앞당겨질 가능성이 있다. 로봇 관련 투자/사업 전략의 타임라인 재평가가 필요하다.

### 5.3 모니터링 강화 필요 영역

1. **탈중앙화 거버넌스의 제도적 수용**: Legitimate Overrides(#12)의 정량적 분석이 DeFi 규제 논의에 미치는 영향을 지속 추적해야 한다. 특히 "긴급 개입 메커니즘 의무화" 논의는 가상자산 산업 전반에 구조적 변화를 가져올 수 있다.

2. **탄소 인식 네트워크 설계 표준화**: AoI-CF 트레이드오프(#10) 연구가 3GPP/ETSI 표준 논의에 반영되는 시점과 방식을 추적해야 한다. 5G/6G 네트워크 장비 시장에 직접적 영향을 미칠 수 있다.

3. **뇌-AI 대응 연구(Brain-AI Alignment)**: TAVAE(#15)로 대표되는 신경과학-AI 교차 연구가 차세대 AI 아키텍처에 미치는 영향을 장기적으로 모니터링해야 한다.

---

## 6. Plausible Scenarios(개연성 있는 시나리오)

**시나리오 1: "추론 경제" 시대의 도래 (확률: 높음, 시간 범위: 1-3년)**

테스트 시점 스케일링이 AI 산업의 지배적 전략으로 자리잡으면서, AI 서비스의 가격 구조가 "모델 크기"에서 "추론 연산량"으로 전환된다. 소규모 모델이 정교한 추론 시점 검증으로 대규모 모델과 경쟁하면서 AI 산업의 진입 장벽이 낮아지고, "추론 효율성"이 경쟁의 핵심 축이 된다. NVIDIA의 추론 전용 칩(예: Blackwell 후속) 수요가 급증하고, AI 클라우드 서비스의 가격 모델이 근본적으로 재설계된다.

**시나리오 2: "AI 거버넌스 도구 전쟁" (확률: 중간, 시간 범위: 1-2년)**

DeepSight, Crosscoder 등 오픈소스 AI 안전 도구의 확산으로 규제 기관이 AI 모델의 독립적 감사 역량을 확보하게 된다. 이에 대응하여 AI 기업들은 "투명성 경쟁"에 돌입하고, 모델의 안전성과 편향에 대한 자발적 공개가 경쟁 우위로 작용한다. 반면, 교차 아키텍처 편향 감사가 "AI 지정학"의 새로운 마찰점이 되어, 미중 AI 경쟁에서 모델 편향이 외교적 이슈로 부상할 수 있다.

**시나리오 3: "가정용 로봇 시장의 조기 개화" (확률: 중간-낮음, 시간 범위: 2-5년)**

CoVer의 검증 기반 접근법과 GigaBrain의 월드 모델 기반 학습이 결합되면서, 세탁, 요리, 정리 등 일상 과제를 수행할 수 있는 범용 가정 로봇이 기존 예측(2030년대)보다 빠르게 시장에 진입한다. 초기에는 고가의 프리미엄 시장(10만 달러 이상)에서 시작하지만, 추론 시점 스케일링의 효율성 향상으로 2-3년 내 가격이 급격히 하락한다.

---

## 7. 신뢰도 분석

| 항목 | 값 |
|------|---|
| **데이터 출처** | arXiv (단일 출처, 사전 심사 미완료 프리프린트) |
| **시간적 일관성** | 스캔 윈도우 48시간 (2/13 21:48 ~ 2/15 21:48 UTC), arXiv 주말 동결로 2/12 논문 포함 |
| **총 스캔 논문** | 568개 |
| **선별 비율** | 15/568 = 2.6% |
| **pSST 점수 범위** | 83.0 ~ 90.0 (분산: 4.9) |
| **STEEPs 커버리지** | 6/6 도메인 (T:7, S:3, E:2, E:1, P:1, s:1) |
| **한계** | arXiv 프리프린트 특성상 피어 리뷰 미완료, 재현성 미검증. 주말 게시 동결로 실질적 신규 논문이 아닌 배치 공개 논문 포함. 기술(T) 도메인 편향(7/15)은 arXiv의 CS/AI 중심 특성을 반영. |
| **교차 검증** | 단일 출처(arXiv)이므로 외부 교차 검증 불가. WF1 일반 환경스캔 결과와의 교차 참조를 통합 보고서에서 수행 권장. |

**신뢰도 등급**: B+ (양호) -- arXiv은 최신 학술 연구의 가장 빠른 공개 채널이나, 피어 리뷰 미완료와 단일 출처 한계가 존재. 6개 STEEPs 도메인 전체 커버리지는 긍정적이나, 기술(T) 편향이 뚜렷함.

---

## 8. 부록

### A. 신호 목록 (요약)

| 순위 | ID | 제목 | 도메인 | pSST |
|------|-----|------|--------|------|
| 1 | arxiv-2602.12281v1 | CoVer: VLA 검증 스케일링 | T | 90.0 |
| 2 | arxiv-2602.12279v1 | UniT: 멀티모달 CoT TTS | T | 89.0 |
| 3 | arxiv-2602.12092v1 | DeepSight: LM 안전 툴킷 | T | 88.0 |
| 4 | arxiv-2602.12207v1 | VIRENA: 가상 소셜 미디어 실험 | S | 88.0 |
| 5 | arxiv-2602.11897v1 | 에이전틱 AI 사이버 보안 | T | 87.0 |
| 6 | arxiv-2602.11483v1 | KPM: 지식 기반 설득 모델 | S | 87.0 |
| 7 | arxiv-2602.11829v1 | InvestESG: 지속 가능 투자 정책 | E | 87.0 |
| 8 | arxiv-2602.11729v1 | Crosscoder: 교차 아키텍처 모델 비교 | T | 86.0 |
| 9 | arxiv-2602.11924v1 | 인간-LLM 의사결정 아키타입 | S | 86.0 |
| 10 | arxiv-2602.11946v1 | 탄소 인식 AoI 프레임워크 | E | 86.0 |
| 11 | arxiv-2602.12276v1 | CATTS: 에이전틱 TTS | T | 85.0 |
| 12 | arxiv-2602.12260v1 | 탈중앙화 프로토콜 긴급 거버넌스 | P | 85.0 |
| 13 | arxiv-2602.12099v1 | GigaBrain: 월드 모델 기반 VLA | T | 84.0 |
| 14 | arxiv-2602.12181v1 | GUMG: 볼록 마르코프 게임 확장 | E | 84.0 |
| 15 | arxiv-2602.11956v1 | TAVAE: 시각 피질 맥락적 조절 | s | 83.0 |

### B. STEEPs 분포

| 도메인 | 신호 수 | 비율 |
|--------|---------|------|
| 기술 (T) | 7 | 46.7% |
| 사회 (S) | 3 | 20.0% |
| 경제 (E) | 2 | 13.3% |
| 환경 (E) | 1 | 6.7% |
| 정치 (P) | 1 | 6.7% |
| 정신적 (s) | 1 | 6.7% |

### C. 스캔 매개변수

| 매개변수 | 값 |
|----------|---|
| 워크플로우 | WF2 - arXiv Academic Deep Scanning |
| 스캔 윈도우 | 2026-02-13T21:48 ~ 2026-02-15T21:48 UTC (48시간) |
| 시간적 예외 | arXiv 주말 게시 중단으로 2/12 게시 논문 포함 |
| 회고 기간 | 14일 |
| 카테고리당 최대 결과 | 50건 |
| 쿼리 그룹 | 22개 |
| 카테고리 커버리지 | ~180개 |
| 총 스캔 논문 | 568개 |
| 선별 신호 | 15개 |
| 중복 제거율 | 97.4% |

### D. 방법론 참고

본 보고서는 arXiv 학술 프리프린트를 대상으로 한 심층 환경 스캐닝 결과이다. WISDOM Framework(arXiv:2409.15340v1)의 다출처 스캐닝 방법론, Millennium Project FRM 3.0의 미래 연구 방법론, Cross-Impact Analysis의 교차 영향 분석 기법을 적용하였다. 모든 신호는 pSST(predicted Signal Scanning Trust) 6차원 평가를 거쳐 신뢰도를 정량화하였으며, STEEPs 프레임워크에 따라 분류되었다.
