"""
Unit tests for validate_report.py

Tests validation logic against:
- Synthetic "good" reports (should PASS)
- Synthetic "bad" reports mimicking 2026-02-02 failures (should FAIL)
- Real report files when available (conditional)
"""

import json
import os
import sys
import textwrap
from pathlib import Path

import pytest

# Add scripts to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "env-scanning" / "scripts"))
from validate_report import (
    ValidationReport,
    validate_report,
    _count_words,
    _count_signal_blocks,
    _check_signal_fields,
    _extract_section,
    _count_field_occurrences,
    _extract_steeps_distribution,
    _classify_steeps_field,
    _check_exploration_proof,
    _get_enforcement_level,
    _auto_enforce_exploration,
)


# ---------------------------------------------------------------------------
# Fixtures: Generate synthetic reports
# ---------------------------------------------------------------------------

def _make_signal_block(n: int, full: bool = True) -> str:
    """Generate a single signal block with 9 fields (or partial if full=False)."""
    block = f"### ìš°ì„ ìˆœìœ„ {n}: í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ì œëª© {n}ë²ˆ\n\n"
    block += f"- **ì‹ ë¢°ë„**: pSST ë¯¸ì‚°ì¶œ (ìš°ì„ ìˆœìœ„ ì ìˆ˜ ê¸°ë°˜: {8.0 - n * 0.1:.1f}/10.0)\n\n"
    block += f"1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬\n"
    block += f"2. **ì¶œì²˜**: TestSource, 2026-02-01, ID: test-{n:03d}\n"
    block += f"3. **í•µì‹¬ ì‚¬ì‹¤**: ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {n}ë²ˆì˜ í•µì‹¬ ì‚¬ì‹¤ì…ë‹ˆë‹¤. ì¤‘ìš”í•œ ë°œê²¬ ë‚´ìš©ì„ ê¸°ìˆ í•©ë‹ˆë‹¤.\n"
    block += f"4. **ì •ëŸ‰ ì§€í‘œ**:\n   - ì˜í–¥ë„(Impact): 8.0/10\n   - ë°œìƒí™•ë¥ (Probability): 7.0/10\n"
    block += f"5. **ì˜í–¥ë„**: â­â­â­â­ ({8.0 - n * 0.1:.1f}/10.0) â€” ë†’ìŒ\n"
    if full:
        block += f"6. **ìƒì„¸ ì„¤ëª…**: ì´ê²ƒì€ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {n}ë²ˆì— ëŒ€í•œ ìì„¸í•œ ë¶„ì„ì„ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.\n"
        block += f"7. **ì¶”ë¡ **: ì˜ì‚¬ê²°ì •ìë¥¼ ìœ„í•œ ì „ëµì  í•´ì„ì…ë‹ˆë‹¤. ì´ ì‹ í˜¸ê°€ ë¯¸ë˜ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤.\n"
        block += f"8. **ì´í•´ê´€ê³„ì**: ì •ë¶€ê¸°ê´€, ê¸°ì—…A, ê¸°ì—…B, êµ­ì œê¸°êµ¬, í•™ê³„\n"
        block += f"9. **ëª¨ë‹ˆí„°ë§ ì§€í‘œ**:\n   - ê´€ë ¨ íŠ¹í—ˆ ì¶œì› ê±´ìˆ˜\n   - íˆ¬ì ë™í–¥ ë³€í™”\n"
    block += "\n---\n\n"
    return block


def _make_good_report() -> str:
    """Create a synthetic report that should pass all 15 checks."""
    sections = []

    # Header
    sections.append("# ì¼ì¼ í™˜ê²½ ìŠ¤ìºë‹ ë³´ê³ ì„œ\n\n**ë‚ ì§œ**: 2026ë…„ 2ì›” 1ì¼\n\n---\n\n")

    # Section 1
    sections.append("## 1. ê²½ì˜ì§„ ìš”ì•½\n\n")
    sections.append("### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë°œê²¬ (Top 3 ì‹ í˜¸)\n\n")
    for i in range(1, 4):
        sections.append(f"{i}. **í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i}** (ê¸°ìˆ  ì˜ì—­)\n   - ì¤‘ìš”ë„: â­â­â­â­â­\n   - í•µì‹¬ ë‚´ìš©: í…ŒìŠ¤íŠ¸ ìš”ì•½ {i}\n   - ì „ëµì  ì‹œì‚¬ì : ì „ëµì  ì˜ë¯¸ {i}\n\n")
    sections.append("### ì£¼ìš” ë³€í™” ìš”ì•½\n- ë°œê²¬ëœ ì‹ ê·œ ì‹ í˜¸: 100ê°œ\n- ìš°ì„ ìˆœìœ„ ìƒìœ„ ì‹ í˜¸: 15ê°œ\n- ì£¼ìš” ì˜í–¥ ë„ë©”ì¸: ê¸°ìˆ (40%), ê²½ì œ(30%), ì •ì¹˜(20%), ì‚¬íšŒ(10%)\n\n---\n\n")

    # Section 2
    sections.append("## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\n\n> í†µí•© ìš°ì„ ìˆœìœ„ ê¸°ì¤€ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n")
    for i in range(1, 16):
        sections.append(_make_signal_block(i, full=(i <= 10)))

    # Section 3 (with evolution data)
    sections.append("## 3. ê¸°ì¡´ ì‹ í˜¸ ì—…ë°ì´íŠ¸\n\n")
    sections.append("> í™œì„± ì¶”ì  ìŠ¤ë ˆë“œ: 12ê°œ | ê°•í™”: 3ê°œ | ì•½í™”: 1ê°œ | ì†Œë©¸: 2ê°œ\n\n")
    sections.append("### 3.1 ê°•í™” ì¶”ì„¸ (Strengthening)\n\n")
    sections.append("| ì¶”ì  ìŠ¤ë ˆë“œ | ì¶”ì ì¼ìˆ˜ | pSST ë³€í™” | ì†ë„ | í™•ì¥ë„ |\n|------------|---------|----------|------|-------|\n")
    sections.append("| ì–‘ì ì»´í“¨íŒ… ê¸°ìˆ  ë°œì „ | 10ì¼ | 82â†’88 (+6) | â–² ê°€ì† | 0.67 |\n\n")
    sections.append("- **SIG-001**: ì–‘ì ì»´í“¨íŒ… ê¸°ìˆ  ë°œì „\n  - ë³€í™”: emerging â†’ developing\n  - ì´ìœ : ì¶”ê°€ ì¶œì²˜ í™•ì¸, ì ìˆ˜ ìƒìŠ¹\n\n")
    sections.append("### 3.2 ì•½í™” ì¶”ì„¸ (Weakening)\n\n")
    sections.append("í•´ë‹¹ ì—†ìŒ\n\n")
    sections.append("- **SIG-042**: ë¸”ë¡ì²´ì¸ íˆ¬í‘œ ì‹œìŠ¤í…œ\n  - ë³€í™”: developing â†’ stagnating\n  - ì´ìœ : ê´€ë ¨ ë‰´ìŠ¤ ê°ì†Œ\n\n")
    sections.append("### 3.3 ì‹ í˜¸ ìƒíƒœ ìš”ì•½\n\n")
    sections.append("| ìƒíƒœ | ìˆ˜ | ë¹„ìœ¨ |\n|------|---|------|\n")
    sections.append("| ì‹ ê·œ | 8 | 53% |\n| ê°•í™” | 3 | 20% |\n| ë°˜ë³µ ë“±ì¥ | 2 | 13% |\n| ì•½í™” | 1 | 7% |\n| ì†Œë©¸ | 2 | 13% |\n\n")
    sections.append("---\n\n")

    # Section 4
    sections.append("## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬\n\n")
    sections.append("### 4.1 ì‹ í˜¸ ê°„ êµì°¨ ì˜í–¥\n\n")
    sections.append("- **ì–‘ì ì»´í“¨íŒ… ë°œì „** â†” **ë°˜ë„ì²´ ê³µê¸‰ë§ ë³€í™”**: ì–‘ì ê¸°ìˆ ì´ ê¸°ì¡´ ë°˜ë„ì²´ ìˆ˜ìš” êµ¬ì¡°ë¥¼ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆìŒ (+3)\n")
    sections.append("- **AI ë…¸ë™ ëŒ€ì²´** â†” **êµìœ¡ ì‹œìŠ¤í…œ ê°œí¸**: ìë™í™” ê°€ì†ì´ êµìœ¡ ì¬ì„¤ê³„ ì••ë ¥ì„ ì¦ê°€ì‹œí‚´ (+4)\n")
    sections.append("- **ê¸°í›„ ì •ì±… ë³€í™”** â†” **ì—ë„ˆì§€ ì „í™˜ ê°€ì†**: ë¯¸êµ­ íŒŒë¦¬í˜‘ì • íƒˆí‡´ê°€ EU ê¸°í›„ ë¦¬ë”ì‹­ì„ ê°•í™”í•¨ (+3)\n")
    sections.append("- **ë””ì§€í„¸ í™”í** â†” **ê¸ˆìœµ ê·œì œ**: ì¤‘ì•™ì€í–‰ ë””ì§€í„¸ í™”í ë„ì…ì´ ê·œì œ í”„ë ˆì„ì›Œí¬ ë³€í™”ë¥¼ ì´‰ì§„í•¨ (+2)\n\n")
    sections.append("### 4.2 ë– ì˜¤ë¥´ëŠ” í…Œë§ˆ\n\n")
    sections.append("1. **ê¸°ìˆ  ì£¼ê¶Œ ê²½ìŸ**\n   - ê´€ë ¨ ì‹ í˜¸: 25ê°œ\n   - STEEPs êµì°¨: T, P, E\n   - ì˜ë¯¸: ë°˜ë„ì²´, AI, ì—ë„ˆì§€ ë¶„ì•¼ì—ì„œ êµ­ê°€ ê°„ ê¸°ìˆ  ìë¦½ ê²½ìŸ ì‹¬í™”\n\n")
    sections.append("2. **ë…¸ë™ì‹œì¥ êµ¬ì¡° ì „í™˜**\n   - ê´€ë ¨ ì‹ í˜¸: 18ê°œ\n   - STEEPs êµì°¨: S, T, E\n   - ì˜ë¯¸: AI ìë™í™”ë¡œ ì¸í•œ ì¼ìë¦¬ ë³€ë™ì´ ì‚¬íšŒ ì•ˆì „ë§ ì¬ì„¤ê³„ë¥¼ ìš”êµ¬\n\n---\n\n")

    # Section 5
    sections.append("## 5. ì „ëµì  ì‹œì‚¬ì \n\n")
    sections.append("### 5.1 ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” (0-6ê°œì›”)\n\n")
    sections.append("1. **ê´‘í•™ ì»´í“¨íŒ… ê¸°ìˆ  ë™í–¥ ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•**\n   - ê·¼ê±° ì‹ í˜¸: ìš°ì„ ìˆœìœ„ 1ë²ˆ (ê´‘í•™ ì»´í“¨íŒ…)\n   - ì´ìœ : ê¸°ìˆ  ì„±ìˆ™ë„ê°€ ê¸‰ì†íˆ í–¥ìƒ ì¤‘\n   - ê¶Œê³ : ì „ë‹´ ëª¨ë‹ˆí„°ë§ íŒ€ êµ¬ì„±\n\n")
    sections.append("2. **AI ì¸ë ¥ ì¬êµìœ¡ í”„ë¡œê·¸ë¨ ê¸°íš**\n   - ê·¼ê±° ì‹ í˜¸: ìš°ì„ ìˆœìœ„ 2ë²ˆ (AI ë…¸ë™ ëŒ€ì²´)\n   - ì´ìœ : í™”ì´íŠ¸ì¹¼ë¼ ì§ì¢… ì˜í–¥ ì„ë°•\n   - ê¶Œê³ : ì‚¬ë‚´ ì¬êµìœ¡ ì˜ˆì‚° í™•ë³´\n\n")
    sections.append("### 5.2 ì¤‘ê¸° ëª¨ë‹ˆí„°ë§ (6-18ê°œì›”)\n\n")
    sections.append("1. **ê¸°í›„ ì •ì±… ì§€í˜• ë³€í™” ì¶”ì **\n   - ê·¼ê±° ì‹ í˜¸: ìš°ì„ ìˆœìœ„ 3ë²ˆ (íŒŒë¦¬ê¸°í›„í˜‘ì •)\n   - ê´€ì°° ì§€í‘œ: CBAM ì‹œí–‰ ì¼ì •, EU íƒ„ì†Œ ê°€ê²©\n   - ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸°ì : ë¯¸êµ­ ì¬ê°€ì… ì—¬ë¶€\n\n")
    sections.append("2. **ì–‘ì ì»´í“¨íŒ… ìƒìš©í™” ì¼ì •**\n   - ê·¼ê±° ì‹ í˜¸: ìš°ì„ ìˆœìœ„ 4ë²ˆ\n   - ê´€ì°° ì§€í‘œ: ì˜¤ë¥˜ ì •ì • ê¸°ìˆ  ë°œì „ ì†ë„\n   - ì‹œë‚˜ë¦¬ì˜¤ ë¶„ê¸°ì : 100íë¹— ì˜¤ë¥˜ ì •ì • ë‹¬ì„± ì‹œì \n\n")
    sections.append("### 5.3 ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš” ì˜ì—­\n\n")
    sections.append("- **ìš°ì£¼ ê²½ì œ**: ë¯¼ê°„ ìš°ì£¼ ì‚°ì—… íˆ¬ì ê¸‰ì¦ì— ë”°ë¥¸ ê·œì œ í”„ë ˆì„ì›Œí¬ ë³€í™” ì¶”ì  í•„ìš”\n")
    sections.append("- **í•©ì„± ìƒë¬¼í•™**: ìœ ì „ì í¸ì§‘ ê¸°ìˆ ì˜ ì‚°ì—…ì  ì ìš© í™•ëŒ€ ëª¨ë‹ˆí„°ë§\n\n---\n\n")

    # Section 6 (optional)
    sections.append("## 6. Plausible Scenarios(ê°œì—°ì„± ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤)\n\nê¸ˆì¼ êµì°¨ì˜í–¥ ë³µì¡ë„ ë¯¸ë‹¬ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë¯¸ë°œë™.\n\n---\n\n")

    # Section 7
    sections.append("## 7. ì‹ ë¢°ë„ ë¶„ì„\n\n")
    sections.append("### 7.1 pSST ë“±ê¸‰ ë¶„í¬\n\n")
    sections.append("| ë“±ê¸‰ | ì‹ í˜¸ ìˆ˜ | ë¹„ìœ¨ |\n|------|---------|------|\n")
    sections.append("| ğŸŸ¢ A (â‰¥90) | 10 | 10% |\n| ğŸ”µ B (70-89) | 40 | 40% |\n| ğŸŸ¡ C (50-69) | 30 | 30% |\n| ğŸ”´ D (<50) | 20 | 20% |\n\n")
    sections.append("**í‰ê·  pSST**: 68.5/100\n\n---\n\n")

    # Section 8
    sections.append("## 8. ë¶€ë¡\n\n")
    sections.append("### 8.1 ì „ì²´ ì‹ í˜¸ ëª©ë¡\n\n| # | ì‹ í˜¸ ID | ì œëª© | ë¶„ë¥˜ | ì˜í–¥ë„ |\n|---|---------|------|------|--------|\n")
    for i in range(1, 21):
        sections.append(f"| {i} | SIG-{i:03d} | í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i} | T | {8.0 - i * 0.1:.1f} |\n")
    sections.append("\n### 8.2 ë°©ë²•ë¡ \n\nìë™í™”ëœ í™˜ê²½ ìŠ¤ìºë‹ ì‹œìŠ¤í…œì„ í†µí•´ ìˆ˜ì§‘, ë¶„ë¥˜, ë¶„ì„ëœ ì‹ í˜¸ì…ë‹ˆë‹¤.\n")

    return "".join(sections)


def _make_bad_report_02_02_style() -> str:
    """Create a report mimicking 2026-02-02 failures:
    - Missing ìƒì„¸ ì„¤ëª…, ì¶”ë¡ , ì´í•´ê´€ê³„ì, ëª¨ë‹ˆí„°ë§ ì§€í‘œ fields
    - Missing Section 5, 7, 8
    - Wrong Section 3 subsection names
    - Abbreviated Section 4
    """
    sections = []
    sections.append("# ì¼ì¼ í™˜ê²½ ìŠ¤ìºë‹ ë³´ê³ ì„œ\n\n**ë‚ ì§œ**: 2026ë…„ 2ì›” 2ì¼\n\n---\n\n")

    # Section 1 (present but minimal)
    sections.append("## 1. ê²½ì˜ì§„ ìš”ì•½\n\n### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë°œê²¬\n\n1. ì‹ í˜¸ A\n2. ì‹ í˜¸ B\n3. ì‹ í˜¸ C\n\n### ì£¼ìš” ë³€í™” ìš”ì•½\n- ì‹ ê·œ ì‹ í˜¸ ìˆ˜: 50ê°œ\n\n---\n\n")

    # Section 2 with incomplete signals (only 5 fields)
    sections.append("## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\n\n")
    for i in range(1, 11):
        sections.append(f"### ìš°ì„ ìˆœìœ„ {i}: ê²°í•¨ ì‹ í˜¸ {i}\n\n")
        sections.append(f"1. **ë¶„ë¥˜**: ê¸°ìˆ  (T)\n")
        sections.append(f"2. **ì¶œì²˜**: Source {i}\n")
        sections.append(f"3. **í•µì‹¬ ì‚¬ì‹¤**: í•µì‹¬ ì‚¬ì‹¤ {i}\n")
        sections.append(f"4. **ì •ëŸ‰ ì§€í‘œ**: ë°ì´í„° ì—†ìŒ\n")
        sections.append(f"5. **ì˜í–¥ë„**: â­â­â­ ({6.0 + i * 0.1:.1f}/10)\n")
        # Missing: ìƒì„¸ ì„¤ëª…, ì¶”ë¡ , ì´í•´ê´€ê³„ì, ëª¨ë‹ˆí„°ë§ ì§€í‘œ
        sections.append("\n---\n\n")

    # Section 3 with WRONG subsection names (mimicking 02-02 bug)
    sections.append("## 3. ê¸°ì¡´ ì‹ í˜¸ ì—…ë°ì´íŠ¸\n\n")
    sections.append("### STEEPsë³„ ë¶„ì„\n\nê¸°ì¡´ ì‹ í˜¸ ì—†ìŒ.\n\n---\n\n")

    # Section 4 (abbreviated â€” only 2 lines)
    sections.append("## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬\n\nê¸°ìˆ  ë¶„ì•¼ì™€ ì •ì¹˜ ë¶„ì•¼ì˜ êµì°¨ íŒ¨í„´ì´ ê´€ì°°ë¨.\n\n---\n\n")

    # Section 5 COMPLETELY MISSING
    # Section 7 COMPLETELY MISSING
    # Section 8 COMPLETELY MISSING

    return "".join(sections)


def _make_good_naver_report() -> str:
    """Create a synthetic WF3 naver report that should pass all 18 naver-profile checks.
    Extends the standard report with FSSF table, Three Horizons table,
    Section 4.3-4.6, and Tipping Point alerts."""
    sections = []

    # Header
    sections.append("# ì¼ì¼ ë„¤ì´ë²„ ë‰´ìŠ¤ í™˜ê²½ ìŠ¤ìºë‹ ë³´ê³ ì„œ\n\n")
    sections.append("**ë‚ ì§œ**: 2026ë…„ 2ì›” 10ì¼\n\n")
    sections.append("> **ë³´ê³ ì„œ ìœ í˜•**: WF3 ë„¤ì´ë²„ ë‰´ìŠ¤ í™˜ê²½ìŠ¤ìºë‹\n")
    sections.append("> **ìŠ¤ìº” ì‹œê°„ ë²”ìœ„**: 2026ë…„ 2ì›” 9ì¼ 08:00 ~ 2026ë…„ 2ì›” 10ì¼ 08:00 (24ì‹œê°„)\n")
    sections.append("> **ê¸°ì¤€ ì‹œì  (Tâ‚€)**: 2026-02-10T08:00:00+09:00\n\n---\n\n")

    # Section 1 with FSSF and Three Horizons tables
    sections.append("## 1. ê²½ì˜ì§„ ìš”ì•½\n\n")
    sections.append("### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë°œê²¬ (Top 3 ì‹ í˜¸)\n\n")
    for i in range(1, 4):
        sections.append(f"{i}. **í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i}** (ê¸°ìˆ )\n   - ì¤‘ìš”ë„: â­â­â­â­\n   - FSSF ìœ í˜•: Weak Signal\n   - ì‹œê°„ ì§€í‰: H1\n   - í•µì‹¬ ë‚´ìš©: ìš”ì•½ {i}\n   - ì „ëµì  ì‹œì‚¬ì : ì‹œì‚¬ì  {i}\n\n")
    sections.append("### ì£¼ìš” ë³€í™” ìš”ì•½\n- ë°œê²¬ëœ ì‹ ê·œ ì‹ í˜¸: 80ê°œ\n- ìš°ì„ ìˆœìœ„ ìƒìœ„ ì‹ í˜¸: 15ê°œ\n- ì£¼ìš” ì˜í–¥ ë„ë©”ì¸: ê¸°ìˆ (35%), ê²½ì œ(25%), ì •ì¹˜(20%), ì‚¬íšŒ(20%)\n\n")

    # FSSF classification summary table
    sections.append("### FSSF ë¶„ë¥˜ ìš”ì•½\n\n")
    sections.append("| FSSF ìœ í˜• | ì‹ í˜¸ ìˆ˜ | ë¹„ìœ¨ |\n|-----------|---------|------|\n")
    sections.append("| Weak Signal (ì•½ì‹ í˜¸) | 8 | 10% |\n")
    sections.append("| Emerging Issue (ë¶€ìƒ ì´ìŠˆ) | 12 | 15% |\n")
    sections.append("| Trend (ì¶”ì„¸) | 25 | 31% |\n")
    sections.append("| Megatrend (ë©”ê°€íŠ¸ë Œë“œ) | 10 | 13% |\n")
    sections.append("| Driver (ë™ì¸) | 15 | 19% |\n")
    sections.append("| Wild Card (ì™€ì¼ë“œì¹´ë“œ) | 3 | 4% |\n")
    sections.append("| Discontinuity (ë‹¨ì ˆ) | 2 | 3% |\n")
    sections.append("| Precursor Event (ì „ì¡° ì‚¬ê±´) | 5 | 6% |\n\n")

    # Three Horizons distribution table
    sections.append("### Three Horizons ë¶„í¬\n\n")
    sections.append("| ì‹œê°„ ì§€í‰ | ì‹ í˜¸ ìˆ˜ | ë¹„ìœ¨ | ì„¤ëª… |\n|-----------|---------|------|------|\n")
    sections.append("| H1 (0-2ë…„) | 40 | 50% | í˜„ì¬ ì²´ì œ ë‚´ ë³€í™” |\n")
    sections.append("| H2 (2-7ë…„) | 25 | 31% | ì „í™˜ê¸° ì‹ í˜¸ |\n")
    sections.append("| H3 (7ë…„+) | 15 | 19% | ë¯¸ë˜ ì²´ì œ ë§¹ì•„ |\n\n---\n\n")

    # Section 2 â€” signals
    sections.append("## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\n\n> FSSF ë¶„ë¥˜ ê¸°ë°˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n\n---\n\n")
    for i in range(1, 16):
        sections.append(_make_signal_block(i, full=(i <= 10)))

    # Section 3 (with evolution data)
    sections.append("## 3. ê¸°ì¡´ ì‹ í˜¸ ì—…ë°ì´íŠ¸\n\n")
    sections.append("> í™œì„± ì¶”ì  ìŠ¤ë ˆë“œ: 10ê°œ | ê°•í™”: 2ê°œ | ì•½í™”: 1ê°œ | ì†Œë©¸: 1ê°œ\n\n")
    sections.append("### 3.1 ê°•í™” ì¶”ì„¸ (Strengthening)\n\n")
    sections.append("| ì¶”ì  ìŠ¤ë ˆë“œ | ì¶”ì ì¼ìˆ˜ | pSST ë³€í™” | ì†ë„ | í™•ì¥ë„ |\n|------------|---------|----------|------|-------|\n")
    sections.append("| ë°˜ë„ì²´ ê³µê¸‰ë§ ì¬í¸ | 8ì¼ | 78â†’84 (+6) | â–² ê°€ì† | 0.50 |\n\n")
    sections.append("- **SIG-001**: ë°˜ë„ì²´ ê³µê¸‰ë§ ì¬í¸\n  - ë³€í™”: emerging â†’ developing\n\n")
    sections.append("### 3.2 ì•½í™” ì¶”ì„¸ (Weakening)\n\ní•´ë‹¹ ì—†ìŒ\n\n- **SIG-042**: NFT ì‹œì¥ ì¶•ì†Œ\n  - ë³€í™”: developing â†’ stagnating\n\n")
    sections.append("### 3.3 ì‹ í˜¸ ìƒíƒœ ìš”ì•½\n\n")
    sections.append("| ìƒíƒœ | ìˆ˜ | ë¹„ìœ¨ |\n|------|---|------|\n")
    sections.append("| ì‹ ê·œ | 6 | 40% |\n| ê°•í™” | 2 | 13% |\n| ë°˜ë³µ ë“±ì¥ | 4 | 27% |\n| ì•½í™” | 1 | 7% |\n| ì†Œë©¸ | 1 | 7% |\n\n---\n\n")

    # Section 4 with 4.1-4.6
    sections.append("## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬\n\n")
    sections.append("### 4.1 ì‹ í˜¸ ê°„ êµì°¨ ì˜í–¥\n\n")
    sections.append("- **AI ë°˜ë„ì²´** â†” **ì—ë„ˆì§€ ìˆ˜ìš”**: ê³ ì„±ëŠ¥ ì¹© ìˆ˜ìš” ì¦ê°€ê°€ ì—ë„ˆì§€ ì†Œë¹„ êµ¬ì¡°ë¥¼ ë³€í™” (+3)\n")
    sections.append("- **ê¸°í›„ ì •ì±…** â†” **ì „ê¸°ì°¨ ë³´ê¸‰**: íƒ„ì†Œì„¸ í™•ëŒ€ê°€ ì „ê¸°ì°¨ ì „í™˜ ê°€ì† (+4)\n")
    sections.append("- **ë””ì§€í„¸ í”Œë«í¼** â†” **ë…¸ë™ ì‹œì¥**: í”Œë«í¼ ê²½ì œ í™•ëŒ€ê°€ ë¹„ì •ê·œì§ ì¦ê°€ì— ì˜í–¥ (+3)\n\n")
    sections.append("### 4.2 ë– ì˜¤ë¥´ëŠ” í…Œë§ˆ\n\n1. **AI ì¸í”„ë¼ ê²½ìŸ**\n   - ê´€ë ¨ ì‹ í˜¸: 15ê°œ\n   - STEEPs êµì°¨: T, E, P\n\n")

    # 4.3 FSSF distribution
    sections.append("### 4.3 FSSF ì‹ í˜¸ ë¶„ë¥˜ ë¶„í¬\n\n")
    sections.append("| FSSF ìœ í˜• | ì‹ í˜¸ ìˆ˜ | ëŒ€í‘œ ì‹ í˜¸ | ì£¼ìš” íŠ¹ì§• |\n|-----------|---------|-----------|----------|\n")
    sections.append("| Weak Signal | 8 | AI ì¹© ìê¸‰ë¥  | ì´ˆê¸° ì§•í›„ |\n")
    sections.append("| Emerging Issue | 12 | ë””ì§€í„¸ í™”í | ë¶€ìƒ ì¤‘ |\n")
    sections.append("| Trend | 25 | ì „ê¸°ì°¨ ì „í™˜ | í™•ë¦½ëœ ì¶”ì„¸ |\n")
    sections.append("| Wild Card | 3 | ì–‘ì ì•”í˜¸ í•´ë… | ì˜ˆì¸¡ ë¶ˆê°€ |\n\n")

    # 4.4 Three Horizons
    sections.append("### 4.4 Three Horizons ë¶„í¬\n\n")
    sections.append("| ì‹œê°„ ì§€í‰ | ì‹ í˜¸ ëª©ë¡ | ì£¼ìš” í…Œë§ˆ |\n|-----------|-----------|----------|\n")
    sections.append("| H1 (0-2ë…„) | ë°˜ë„ì²´ ê³µê¸‰, ì „ê¸°ì°¨ | í˜„ì¬ ë³€í™” |\n")
    sections.append("| H2 (2-7ë…„) | ì–‘ì ì»´í“¨íŒ…, AI ë²•ì œí™” | ì „í™˜ê¸° |\n")
    sections.append("| H3 (7ë…„+) | AGI, í•µìœµí•© | ë¯¸ë˜ ì²´ì œ |\n\n")

    # 4.5 Tipping Point
    sections.append("### 4.5 ì „í™˜ì (Tipping Point) ê²½ê³ \n\n")
    sections.append("| ê²½ê³  ë ˆë²¨ | ì‹ í˜¸ | ì§€í‘œ | ê·¼ê±° |\n|-----------|------|------|------|\n")
    sections.append("| YELLOW | AI ë°˜ë„ì²´ ìê¸‰ë¥  | êµ­ì‚°í™”ìœ¨ 15% â†’ 25% | ì •ë¶€ íˆ¬ì í™•ëŒ€ |\n")
    sections.append("| GREEN | ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ | ì¶©ì „ì†Œ 5ë§Œê°œ | ì„¤ì¹˜ ê°€ì† |\n\n")

    # 4.6 Anomaly detection
    sections.append("### 4.6 ì´ìƒ íƒì§€ ê²°ê³¼\n\n")
    sections.append("| ìœ í˜• | ì‹ í˜¸ | ì´ìƒ ì§€í‘œ | ì‹¬ê°ë„ |\n|------|------|-----------|--------|\n")
    sections.append("| ê¸‰ì¦ | ë°”ì´ì˜¤ íŠ¹í—ˆ | ì „ì£¼ ëŒ€ë¹„ +300% | ë†’ìŒ |\n\n---\n\n")

    # Section 5
    sections.append("## 5. ì „ëµì  ì‹œì‚¬ì \n\n")
    sections.append("### 5.1 ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” (0-6ê°œì›”)\n\n1. **AI ë°˜ë„ì²´ ë™í–¥ ëª¨ë‹ˆí„°ë§**\n   - ê·¼ê±°: ìš°ì„ ìˆœìœ„ 1ë²ˆ\n   - ê¶Œê³ : ì „ë‹´íŒ€ êµ¬ì„±\n\n")
    sections.append("### 5.2 ì¤‘ê¸° ëª¨ë‹ˆí„°ë§ (6-18ê°œì›”)\n\n1. **ë””ì§€í„¸ í™”í ì •ì±… ì¶”ì **\n   - ê·¼ê±°: ìš°ì„ ìˆœìœ„ 3ë²ˆ\n   - ê´€ì°° ì§€í‘œ: CBDC ì‹œí–‰ ì¼ì •\n\n")
    sections.append("### 5.3 ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš” ì˜ì—­\n\n- **ìš°ì£¼ ê²½ì œ**: ë¯¼ê°„ íˆ¬ì ê¸‰ì¦\n- **í•©ì„± ìƒë¬¼í•™**: ìœ ì „ì í¸ì§‘ í™•ëŒ€\n\n---\n\n")

    # Section 6
    sections.append("## 6. Plausible Scenarios(ê°œì—°ì„± ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤)\n\nê¸ˆì¼ êµì°¨ì˜í–¥ ë³µì¡ë„ ë¯¸ë‹¬ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë¯¸ë°œë™.\n\n---\n\n")

    # Section 7
    sections.append("## 7. ì‹ ë¢°ë„ ë¶„ì„\n\n### 7.1 pSST ë“±ê¸‰ ë¶„í¬\n\n| ë“±ê¸‰ | ì‹ í˜¸ ìˆ˜ | ë¹„ìœ¨ |\n|------|---------|------|\n")
    sections.append("| ğŸŸ¢ A (â‰¥90) | 5 | 6% |\n| ğŸ”µ B (70-89) | 35 | 44% |\n| ğŸŸ¡ C (50-69) | 25 | 31% |\n| ğŸ”´ D (<50) | 15 | 19% |\n\n**í‰ê·  pSST**: 65.2/100\n\n---\n\n")

    # Section 8
    sections.append("## 8. ë¶€ë¡\n\n### 8.1 í¬ë¡¤ë§ í†µê³„\n\n| í•­ëª© | ê°’ |\n|------|-----|\n| í¬ë¡¤ë§ ì¼ì‹œ | 2026-02-10 08:00 |\n| ì´ ìˆ˜ì§‘ ê¸°ì‚¬ | 500 |\n\n")
    sections.append("### 8.2 FSSF ë¶„ë¥˜ ë°©ë²•ë¡ \n\në¯¸ë˜ì‹ í˜¸íƒìƒ‰í”„ë ˆì„ì›Œí¬(FSSF)ëŠ” 8ê°€ì§€ ë¶„ë¥˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\n")
    sections.append("### 8.3 ì „ì²´ ì‹ í˜¸ ëª©ë¡\n\n| # | ì‹ í˜¸ ID | ì œëª© | ë¶„ë¥˜ | ì˜í–¥ë„ |\n|---|---------|------|------|--------|\n")
    for i in range(1, 16):
        sections.append(f"| {i} | naver-20260210-{i:03d} | í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i} | T | {8.0 - i * 0.1:.1f} |\n")
    sections.append("\n### 8.4 ì¶œì²˜ ëª©ë¡\n\n- ë„¤ì´ë²„ ë‰´ìŠ¤ ì •ì¹˜ ì„¹ì…˜\n- ë„¤ì´ë²„ ë‰´ìŠ¤ ê²½ì œ ì„¹ì…˜\n- ë„¤ì´ë²„ ë‰´ìŠ¤ ITê³¼í•™ ì„¹ì…˜\n")

    return "".join(sections)


@pytest.fixture
def good_report_file(tmp_path):
    f = tmp_path / "good-report.md"
    f.write_text(_make_good_report(), encoding="utf-8")
    return str(f)


@pytest.fixture
def bad_report_file(tmp_path):
    f = tmp_path / "bad-report.md"
    f.write_text(_make_bad_report_02_02_style(), encoding="utf-8")
    return str(f)


@pytest.fixture
def empty_report_file(tmp_path):
    f = tmp_path / "empty-report.md"
    f.write_text("", encoding="utf-8")
    return str(f)


@pytest.fixture
def skeleton_report_file(tmp_path):
    """A report with unfilled placeholders."""
    f = tmp_path / "skeleton-report.md"
    content = _make_good_report().replace("í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ì œëª© 1ë²ˆ", "{{SIGNAL_1_TITLE}}")
    f.write_text(content, encoding="utf-8")
    return str(f)


# ---------------------------------------------------------------------------
# Tests: Good Report (should PASS)
# ---------------------------------------------------------------------------

class TestGoodReport:
    def test_overall_pass_or_warn(self, good_report_file):
        """Good report should PASS or at most WARN (no CRITICAL failures).
        Synthetic fixtures may be slightly under word count threshold."""
        result = validate_report(good_report_file)
        assert result.overall_status in ("PASS", "WARN"), result.human_summary()

    def test_all_17_checks_run(self, good_report_file):
        result = validate_report(good_report_file)
        assert len(result.results) == 17

    def test_no_critical_failures(self, good_report_file):
        result = validate_report(good_report_file)
        assert len(result.critical_failures) == 0, \
            f"Unexpected critical failures: {[r.check_id for r in result.critical_failures]}"

    def test_file_exists_check(self, good_report_file):
        result = validate_report(good_report_file)
        file_check = next(r for r in result.results if r.check_id == "FILE-001")
        assert file_check.passed

    def test_section_headers_check(self, good_report_file):
        result = validate_report(good_report_file)
        sec_check = next(r for r in result.results if r.check_id == "SEC-001")
        assert sec_check.passed

    def test_signal_blocks_check(self, good_report_file):
        result = validate_report(good_report_file)
        sig_check = next(r for r in result.results if r.check_id == "SIG-001")
        assert sig_check.passed

    def test_signal_fields_check(self, good_report_file):
        result = validate_report(good_report_file)
        sig_check = next(r for r in result.results if r.check_id == "SIG-002")
        assert sig_check.passed, f"SIG-002 failed: {sig_check.detail}"

    def test_section5_subsections(self, good_report_file):
        result = validate_report(good_report_file)
        s5_check = next(r for r in result.results if r.check_id == "S5-001")
        assert s5_check.passed

    def test_json_output_structure(self, good_report_file):
        result = validate_report(good_report_file)
        d = result.to_dict()
        assert d["overall_status"] in ("PASS", "WARN")
        assert d["summary"]["total_checks"] == 17
        assert d["summary"]["critical_failures"] == 0


# ---------------------------------------------------------------------------
# Tests: Bad Report (should FAIL â€” mimics 02-02 bugs)
# ---------------------------------------------------------------------------

class TestBadReport0202Style:
    def test_overall_fail(self, bad_report_file):
        result = validate_report(bad_report_file)
        assert result.overall_status == "FAIL", result.human_summary()

    def test_sig002_fails(self, bad_report_file):
        """SIG-002 should fail: signals are missing 4 fields."""
        result = validate_report(bad_report_file)
        sig_check = next(r for r in result.results if r.check_id == "SIG-002")
        assert not sig_check.passed
        # Verify the specific missing fields are detected
        detail = sig_check.detail
        assert "ìƒì„¸ ì„¤ëª…" in detail
        assert "ì¶”ë¡ " in detail
        assert "ì´í•´ê´€ê³„ì" in detail
        assert "ëª¨ë‹ˆí„°ë§ ì§€í‘œ" in detail

    def test_sec001_fails(self, bad_report_file):
        """SEC-001 should fail: missing sections 5, 7, 8."""
        result = validate_report(bad_report_file)
        sec_check = next(r for r in result.results if r.check_id == "SEC-001")
        assert not sec_check.passed
        assert "5. ì „ëµì  ì‹œì‚¬ì " in sec_check.detail
        assert "7. ì‹ ë¢°ë„ ë¶„ì„" in sec_check.detail
        assert "8. ë¶€ë¡" in sec_check.detail

    def test_s5001_fails(self, bad_report_file):
        """S5-001 should fail: Section 5 completely missing."""
        result = validate_report(bad_report_file)
        s5_check = next(r for r in result.results if r.check_id == "S5-001")
        assert not s5_check.passed

    def test_s3001_fails(self, bad_report_file):
        """S3-001 should fail: wrong subsection names in Section 3."""
        result = validate_report(bad_report_file)
        s3_check = next(r for r in result.results if r.check_id == "S3-001")
        assert not s3_check.passed

    def test_s4002_fails(self, bad_report_file):
        """S4-002 should fail: no cross-impact pairs (â†”)."""
        result = validate_report(bad_report_file)
        s4_check = next(r for r in result.results if r.check_id == "S4-002")
        assert not s4_check.passed

    def test_critical_failure_count(self, bad_report_file):
        """Should have multiple CRITICAL failures."""
        result = validate_report(bad_report_file)
        assert len(result.critical_failures) >= 3, \
            f"Expected >= 3 CRITICAL failures, got {len(result.critical_failures)}: " \
            f"{[r.check_id for r in result.critical_failures]}"


# ---------------------------------------------------------------------------
# Tests: Edge cases
# ---------------------------------------------------------------------------

class TestEdgeCases:
    def test_nonexistent_file(self):
        result = validate_report("/nonexistent/report.md")
        assert result.overall_status == "FAIL"
        assert len(result.results) == 17  # All checks present (14 base + STEEPS-001 + TEMP-001 + EVOL-001)
        file_check = next(r for r in result.results if r.check_id == "FILE-001")
        assert not file_check.passed

    def test_empty_file(self, empty_report_file):
        result = validate_report(empty_report_file)
        assert result.overall_status == "FAIL"
        file_size = next(r for r in result.results if r.check_id == "FILE-002")
        assert not file_size.passed

    def test_skeleton_placeholder_detected(self, skeleton_report_file):
        """SKEL-001 should detect unfilled {{PLACEHOLDER}} tokens."""
        result = validate_report(skeleton_report_file)
        skel_check = next(r for r in result.results if r.check_id == "SKEL-001")
        assert not skel_check.passed
        assert "SIGNAL_1_TITLE" in skel_check.detail


# ---------------------------------------------------------------------------
# Tests: Helper functions
# ---------------------------------------------------------------------------

class TestHelpers:
    def test_count_words_korean(self):
        text = "ì´ê²ƒì€ í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤"
        wc = _count_words(text)
        assert wc > 5

    def test_count_words_mixed(self):
        text = "Hello ì„¸ê³„ world í…ŒìŠ¤íŠ¸"
        wc = _count_words(text)
        assert wc >= 4

    def test_count_signal_blocks(self):
        content = "### ìš°ì„ ìˆœìœ„ 1: A\n### ìš°ì„ ìˆœìœ„ 2: B\n### ìš°ì„ ìˆœìœ„ 3: C\n"
        assert _count_signal_blocks(content) == 3

    def test_count_signal_blocks_empty(self):
        assert _count_signal_blocks("no signals here") == 0

    def test_count_signal_blocks_integrated(self):
        """Regex must match 'í†µí•© ìš°ì„ ìˆœìœ„' headers used in integrated reports."""
        content = "### í†µí•© ìš°ì„ ìˆœìœ„ 1: [WF2] Signal A\n### í†µí•© ìš°ì„ ìˆœìœ„ 2: [WF1] Signal B\n"
        assert _count_signal_blocks(content) == 2

    def test_extract_section(self):
        content = "## 1. ê²½ì˜ì§„ ìš”ì•½\nHello\n## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\nWorld\n"
        section = _extract_section(content, "## 1. ê²½ì˜ì§„ ìš”ì•½")
        assert "Hello" in section
        assert "World" not in section

    def test_count_field_occurrences(self):
        content = "**ë¶„ë¥˜**: T\n**ë¶„ë¥˜**: S\n**ë¶„ë¥˜**: E\n"
        assert _count_field_occurrences(content, "ë¶„ë¥˜") == 3

    def test_check_signal_fields_complete(self):
        content = _make_signal_block(1, full=True)
        total, complete, missing = _check_signal_fields(content)
        assert total == 1
        assert complete == 1
        assert len(missing) == 0

    def test_check_signal_fields_incomplete(self):
        content = _make_signal_block(1, full=False)
        total, complete, missing = _check_signal_fields(content)
        assert total == 1
        assert complete == 0
        assert len(missing) == 1
        assert "ìƒì„¸ ì„¤ëª…" in missing[0]["missing_fields"]


# ---------------------------------------------------------------------------
# Tests: Integrated profile (CW-002 with [WF3])
# ---------------------------------------------------------------------------

class TestIntegratedProfile:
    """Test CW-002 source tag validation for integrated profile."""

    def _make_integrated_report(self, include_wf3: bool = True) -> str:
        """Create a synthetic integrated report with [WF1]/[WF2]/[WF3] tags."""
        sections = []
        sections.append("# í†µí•© ì¼ì¼ í™˜ê²½ ìŠ¤ìºë‹ ë³´ê³ ì„œ\n\n**ë‚ ì§œ**: 2026ë…„ 2ì›” 7ì¼\n\n---\n\n")

        # Section 1
        sections.append("## 1. ê²½ì˜ì§„ ìš”ì•½\n\n### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë°œê²¬ (Top 5 ì‹ í˜¸)\n\n")
        for i in range(1, 6):
            if include_wf3:
                tag = "[WF1]" if i % 3 == 1 else ("[WF2]" if i % 3 == 2 else "[WF3]")
            else:
                tag = "[WF1]" if i % 2 == 1 else "[WF2]"
            sections.append(f"{i}. **{tag} í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i}** (ê¸°ìˆ )\n   - ì¤‘ìš”ë„: â­â­â­â­\n   - í•µì‹¬ ë‚´ìš©: ìš”ì•½ {i}\n   - ì „ëµì  ì‹œì‚¬ì : ì‹œì‚¬ì  {i}\n\n")
        if include_wf3:
            sections.append("### ì£¼ìš” ë³€í™” ìš”ì•½\n- **WF1**: 50ê°œ ìˆ˜ì§‘\n- **WF2**: 30ê°œ ìˆ˜ì§‘\n- **WF3**: 40ê°œ ìˆ˜ì§‘\n- í†µí•©: 120ê°œ\n- ìƒìœ„ 20ê°œ ì„ ì •\n- ë„ë©”ì¸: T(40%), E(30%)\n\n")
        else:
            sections.append("### ì£¼ìš” ë³€í™” ìš”ì•½\n- **WF1**: 50ê°œ ìˆ˜ì§‘\n- **WF2**: 30ê°œ ìˆ˜ì§‘\n- í†µí•©: 80ê°œ\n- ìƒìœ„ 20ê°œ ì„ ì •\n- ë„ë©”ì¸: T(40%), E(30%)\n\n")
        sections.append("### ì›Œí¬í”Œë¡œìš° êµì°¨ í•˜ì´ë¼ì´íŠ¸\nêµì°¨ ë¶„ì„ ìš”ì•½\n\n---\n\n")

        # Section 2 with 20 signals
        sections.append("## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\n\n> í†µí•© ë¶„ì„ ê²°ê³¼\n\n---\n\n")
        for i in range(1, 21):
            tag = "[WF1]" if i % 3 == 1 else ("[WF2]" if i % 3 == 2 else "[WF3]")
            if not include_wf3:
                tag = "[WF1]" if i % 2 == 1 else "[WF2]"
            sections.append(_make_signal_block(i, full=True).replace(
                f"### ìš°ì„ ìˆœìœ„ {i}:", f"### í†µí•© ìš°ì„ ìˆœìœ„ {i}: {tag}"))

        # Section 3 (with evolution data)
        sections.append("## 3. ê¸°ì¡´ ì‹ í˜¸ ì—…ë°ì´íŠ¸\n\n")
        sections.append("> í™œì„± ì¶”ì  ìŠ¤ë ˆë“œ: 20ê°œ | ê°•í™”: 5ê°œ | ì•½í™”: 3ê°œ | ì†Œë©¸: 2ê°œ\n\n")
        sections.append("### 3.1 ê°•í™” ì¶”ì„¸\n\n- ê°•í™” ì‹ í˜¸ 5ê°œ\n\n")
        sections.append("### 3.2 ì•½í™” ì¶”ì„¸\n\n- ì•½í™” ì‹ í˜¸ 3ê°œ\n\n")
        sections.append("### 3.3 ì‹ í˜¸ ìƒíƒœ ìš”ì•½\n\n| ìƒíƒœ | ìˆ˜ | ë¹„ìœ¨ |\n|------|---|------|\n| ì‹ ê·œ | 10 | 50% |\n| ê°•í™” | 5 | 25% |\n| ë°˜ë³µ ë“±ì¥ | 3 | 15% |\n| ì•½í™” | 2 | 10% |\n\n---\n\n")

        # Section 4 with 4.3
        sections.append("## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬\n\n")
        sections.append("### 4.1 ì‹ í˜¸ ê°„ êµì°¨ ì˜í–¥\n\n- A â†” B: êµì°¨ (+3)\n- C â†” D: êµì°¨ (+2)\n- E â†” F: êµì°¨ (+4)\n\n")
        sections.append("### 4.2 ë– ì˜¤ë¥´ëŠ” í…Œë§ˆ\n\n1. í…Œë§ˆ A\n\n")
        sections.append("### 4.3 ì›Œí¬í”Œë¡œìš° êµì°¨ ë¶„ì„\n\n")
        sections.append("#### 4.3.1 ìƒí˜¸ ê°•í™” ì‹ í˜¸\n\nêµì°¨ ë¶„ì„ ë‚´ìš©\n\n")
        sections.append("#### 4.3.2 í•™ìˆ  ì„ í–‰ ì‹ í˜¸\n\ní•™ìˆ  ì„ í–‰ ë‚´ìš©\n\n")
        sections.append("#### 4.3.3 ë¯¸ë””ì–´ ì„ í–‰ ì‹ í˜¸\n\në¯¸ë””ì–´ ì„ í–‰ ë‚´ìš©\n\n---\n\n")

        # Section 5
        sections.append("## 5. ì „ëµì  ì‹œì‚¬ì \n\n")
        sections.append("### 5.1 ì¦‰ì‹œ ì¡°ì¹˜\n\n1. ì¡°ì¹˜ A\n\n")
        sections.append("### 5.2 ì¤‘ê¸° ëª¨ë‹ˆí„°ë§\n\n1. ëª¨ë‹ˆí„°ë§ A\n\n")
        sections.append("### 5.3 ê°•í™” í•„ìš”\n\n- ì˜ì—­ A\n\n---\n\n")

        # Section 7
        sections.append("## 7. ì‹ ë¢°ë„ ë¶„ì„\n\npSST ë¶„í¬ ë¶„ì„ ë‚´ìš©\n\n---\n\n")

        # Section 8
        sections.append("## 8. ë¶€ë¡\n\nì „ì²´ ì‹ í˜¸ ëª©ë¡ í…Œì´ë¸”\n\n")

        return "".join(sections)

    def test_integrated_with_wf3_passes_cw002(self, tmp_path):
        """CW-002 should pass when [WF1], [WF2], [WF3] all present."""
        f = tmp_path / "integrated-report.md"
        f.write_text(self._make_integrated_report(include_wf3=True), encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        cw002 = next(r for r in result.results if r.check_id == "CW-002")
        assert cw002.passed, f"CW-002 should pass with all 3 tags: {cw002.detail}"

    def test_integrated_without_wf3_fails_cw002(self, tmp_path):
        """CW-002 should fail when [WF3] is missing in integrated profile."""
        f = tmp_path / "integrated-no-wf3.md"
        f.write_text(self._make_integrated_report(include_wf3=False), encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        cw002 = next(r for r in result.results if r.check_id == "CW-002")
        assert not cw002.passed, "CW-002 should fail without [WF3] in integrated profile"
        assert "[WF3]" in cw002.detail or "WF3" in cw002.detail

    def test_integrated_profile_runs_19_checks(self, tmp_path):
        """Integrated profile should run 19 checks (14 base + STEEPS-001 + CW-001 + CW-002 + TEMP-001 + EVOL-001)."""
        f = tmp_path / "integrated-report.md"
        f.write_text(self._make_integrated_report(include_wf3=True), encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        assert len(result.results) == 19, f"Expected 19 checks, got {len(result.results)}"

    def test_integrated_cw001_passes(self, tmp_path):
        """CW-001 should pass when Section 4.3 exists inside ## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬."""
        f = tmp_path / "integrated-report.md"
        f.write_text(self._make_integrated_report(include_wf3=True), encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        cw001 = next(r for r in result.results if r.check_id == "CW-001")
        assert cw001.passed, f"CW-001 should pass with 4.3 subsection: {cw001.detail}"

    def test_integrated_signal_blocks_counted(self, tmp_path):
        """SIG-001 should find 20 signal blocks with 'í†µí•© ìš°ì„ ìˆœìœ„' headers."""
        f = tmp_path / "integrated-report.md"
        f.write_text(self._make_integrated_report(include_wf3=True), encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        sig001 = next(r for r in result.results if r.check_id == "SIG-001")
        assert sig001.passed, f"SIG-001 should find 20 signals: {sig001.detail}"


# ---------------------------------------------------------------------------
# Tests: Naver profile (WF3 â€” FSSF/Three Horizons/Tipping Point)
# ---------------------------------------------------------------------------

class TestNaverProfile:
    """Test naver profile with WF3-specific checks (FSSF-001, H3HZ-001, TPNT-001)."""

    def test_naver_valid_report_passes(self, tmp_path):
        """All 18 naver-profile checks should pass."""
        f = tmp_path / "naver-report.md"
        f.write_text(_make_good_naver_report(), encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        assert len(result.critical_failures) == 0, \
            f"Unexpected CRITICAL failures: {[(r.check_id, r.detail) for r in result.critical_failures]}"
        assert result.overall_status in ("PASS", "WARN"), result.human_summary()

    def test_naver_runs_20_checks(self, tmp_path):
        """Naver profile should run 20 checks (15 base + STEEPS-001 + FSSF-001 + H3HZ-001 + TPNT-001 + EVOL-001)."""
        f = tmp_path / "naver-report.md"
        f.write_text(_make_good_naver_report(), encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        assert len(result.results) == 20, \
            f"Expected 20 checks, got {len(result.results)}: {[r.check_id for r in result.results]}"

    def test_naver_missing_fssf_table_fails(self, tmp_path):
        """FSSF-001 should fail when FSSF keywords are missing."""
        content = _make_good_naver_report()
        # Remove all FSSF type keywords
        for kw in ["Weak Signal", "Wild Card", "Discontinuity", "Emerging Issue",
                    "Driver", "Precursor Event", "ì•½ì‹ í˜¸", "ì™€ì¼ë“œì¹´ë“œ", "ë‹¨ì ˆ",
                    "ë¶€ìƒ ì´ìŠˆ", "ë™ì¸", "ì „ì¡° ì‚¬ê±´"]:
            content = content.replace(kw, "ì‹ í˜¸ìœ í˜•")
        # Also neutralize Trend/Megatrend (but keep them as "ì¶”ì„¸ìœ í˜•" to avoid breaking other text)
        content = content.replace("Megatrend", "ëŒ€í˜•ì¶”ì„¸ìœ í˜•")
        content = content.replace("ë©”ê°€íŠ¸ë Œë“œ", "ëŒ€í˜•ì¶”ì„¸ìœ í˜•")
        content = content.replace("Trend", "ì¶”ì„¸ìœ í˜•")
        f = tmp_path / "naver-no-fssf.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        fssf = next(r for r in result.results if r.check_id == "FSSF-001")
        assert not fssf.passed, f"FSSF-001 should fail without FSSF keywords: {fssf.detail}"

    def test_naver_missing_three_horizons_fails(self, tmp_path):
        """H3HZ-001 should fail when Three Horizons data is missing."""
        content = _make_good_naver_report()
        # Remove H1/H2/H3 horizon patterns
        content = content.replace("H1 (0-2ë…„)", "ë‹¨ê¸°")
        content = content.replace("H2 (2-7ë…„)", "ì¤‘ê¸°")
        content = content.replace("H3 (7ë…„+)", "ì¥ê¸°")
        f = tmp_path / "naver-no-horizons.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        h3hz = next(r for r in result.results if r.check_id == "H3HZ-001")
        assert not h3hz.passed, f"H3HZ-001 should fail without horizon data: {h3hz.detail}"

    def test_naver_missing_section_4_3_to_4_6_fails(self, tmp_path):
        """S4-001 should fail when Section 4.3-4.6 subsections are missing."""
        content = _make_good_naver_report()
        # Remove 4.3, 4.4, 4.5, 4.6 subsections
        content = content.replace("### 4.3 FSSF", "### ë– ì˜¤ë¥´ëŠ” ë¶„ì„ FSSF")
        content = content.replace("### 4.4 Three", "### ì‹œê°„ ë¶„ì„ Three")
        content = content.replace("### 4.5 ì „í™˜ì ", "### ë³€í™”ì  ì „í™˜ì ")
        content = content.replace("### 4.6 ì´ìƒ", "### ë¹„ì •ìƒ ì´ìƒ")
        f = tmp_path / "naver-no-s4subs.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        s4 = next(r for r in result.results if r.check_id == "S4-001")
        assert not s4.passed, f"S4-001 should fail with missing 4.3-4.6: {s4.detail}"
        # Verify specific missing subs
        for sub in ["4.3", "4.4", "4.5", "4.6"]:
            assert sub in s4.detail, f"Missing subsection {sub} should be in detail"

    def test_naver_missing_tipping_point_warns(self, tmp_path):
        """TPNT-001 should fail as ERROR (not CRITICAL) when tipping point data is missing."""
        content = _make_good_naver_report()
        # Remove tipping point text and alert levels
        content = content.replace("ì „í™˜ì ", "ë³€í™”ì§€ì ")
        content = content.replace("Tipping Point", "Change Point")
        content = content.replace("YELLOW", "ê²½ê³ ì¤‘")
        content = content.replace("GREEN", "ì •ìƒ")
        content = content.replace("ORANGE", "ì£¼ì˜")
        content = content.replace("RED", "ìœ„í—˜")
        f = tmp_path / "naver-no-tp.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        tpnt = next(r for r in result.results if r.check_id == "TPNT-001")
        assert not tpnt.passed, f"TPNT-001 should fail: {tpnt.detail}"
        assert tpnt.level == "ERROR", f"TPNT-001 should be ERROR level, not {tpnt.level}"

    def test_naver_nonexistent_file_runs_20_checks(self):
        """Naver profile with nonexistent file should still report 20 checks."""
        result = validate_report("/nonexistent/naver-report.md", profile="naver")
        assert result.overall_status == "FAIL"
        assert len(result.results) == 20, \
            f"Expected 20 checks, got {len(result.results)}: {[r.check_id for r in result.results]}"

    def test_fssf001_megatrend_only_should_fail(self, tmp_path):
        """FSSF-001 edge case: 'Megatrend' alone should NOT also match 'Trend'.
        With only 1 distinct type, the check must fail (need >= 3)."""
        content = _make_good_naver_report()
        # Remove all FSSF types except Megatrend/ë©”ê°€íŠ¸ë Œë“œ
        for kw in ["Weak Signal", "Wild Card", "Discontinuity", "Emerging Issue",
                    "Driver", "Precursor Event", "ì•½ì‹ í˜¸", "ì™€ì¼ë“œì¹´ë“œ", "ë‹¨ì ˆ",
                    "ë¶€ìƒ ì´ìŠˆ", "ë™ì¸", "ì „ì¡° ì‚¬ê±´"]:
            content = content.replace(kw, "ìœ í˜•X")
        # Replace standalone "Trend" but keep "Megatrend" â€” simulate a report
        # that only discusses megatrends
        import re as _re
        content = _re.sub(r'\bTrend\b', 'ìœ í˜•Y', content)
        content = content.replace("ì¶”ì„¸", "ìœ í˜•Z")
        f = tmp_path / "naver-megatrend-only.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        fssf = next(r for r in result.results if r.check_id == "FSSF-001")
        assert not fssf.passed, \
            f"FSSF-001 should fail with only Megatrend type: {fssf.detail}"

    def test_fssf001_two_types_should_fail(self, tmp_path):
        """FSSF-001 edge case: exactly 2 distinct types should fail (need >= 3)."""
        content = _make_good_naver_report()
        # Keep only Weak Signal + Megatrend, remove all other types
        for kw in ["Wild Card", "Discontinuity", "Emerging Issue",
                    "Driver", "Precursor Event", "ì™€ì¼ë“œì¹´ë“œ", "ë‹¨ì ˆ",
                    "ë¶€ìƒ ì´ìŠˆ", "ë™ì¸", "ì „ì¡° ì‚¬ê±´"]:
            content = content.replace(kw, "ìœ í˜•X")
        import re as _re
        content = _re.sub(r'\bTrend\b', 'ìœ í˜•Y', content)
        content = content.replace("ì¶”ì„¸", "ìœ í˜•Z")
        f = tmp_path / "naver-2types.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        fssf = next(r for r in result.results if r.check_id == "FSSF-001")
        assert not fssf.passed, \
            f"FSSF-001 should fail with only 2 distinct types: {fssf.detail}"

    def test_tpnt001_predicted_not_false_positive(self, tmp_path):
        """TPNT-001 edge case: 'PREDICTED' should NOT match as 'RED' alert.
        A report with 'ì „í™˜ì ' but only 'PREDICTED'/'GREENHOUSE' (no real alerts)
        must fail TPNT-001."""
        content = _make_good_naver_report()
        # Replace actual alert keywords with words containing them as substrings
        content = content.replace("YELLOW", "PREDICTED")
        content = content.replace("GREEN", "GREENHOUSE")
        content = content.replace("ORANGE", "STORED")
        content = content.replace("RED", "CENTERED")
        # Also handle lowercase variants
        content = content.replace("yellow", "predicted")
        content = content.replace("green", "greenhouse")
        f = tmp_path / "naver-false-alerts.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="naver")
        tpnt = next(r for r in result.results if r.check_id == "TPNT-001")
        assert not tpnt.passed, \
            f"TPNT-001 should fail when alerts are only substrings: {tpnt.detail}"


# ---------------------------------------------------------------------------
# Tests: STEEPS-001 (category distribution check)
# ---------------------------------------------------------------------------

class TestSteepsDistribution:
    """Tests for STEEPS-001 check and _extract_steeps_distribution helper."""

    # -- Helper function tests --

    def test_extract_steeps_distribution_basic(self):
        """Basic extraction from standard signal blocks."""
        content = (
            "### ìš°ì„ ìˆœìœ„ 1: AI\n"
            "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” ì¸ê³µì§€ëŠ¥\n"
            "### ìš°ì„ ìˆœìœ„ 2: ì¸êµ¬\n"
            "1. **ë¶„ë¥˜**: ì‚¬íšŒ (S) â€” ì¸êµ¬í†µê³„\n"
            "### ìš°ì„ ìˆœìœ„ 3: íƒ„ì†Œ\n"
            "1. **ë¶„ë¥˜**: í™˜ê²½ (E) â€” ê¸°í›„ë³€í™”\n"
        )
        dist = _extract_steeps_distribution(content)
        assert dist == {"T_Technological": 1, "S_Social": 1, "E_Environmental": 1}

    def test_extract_steeps_distribution_all_six(self):
        """All 6 STEEPs categories detected."""
        content = (
            "1. **ë¶„ë¥˜**: ì‚¬íšŒ (S)\n"
            "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T)\n"
            "1. **ë¶„ë¥˜**: ê²½ì œ (E)\n"
            "1. **ë¶„ë¥˜**: í™˜ê²½ (E)\n"
            "1. **ë¶„ë¥˜**: ì •ì¹˜ (P)\n"
            "1. **ë¶„ë¥˜**: ì •ì‹ ì  (s)\n"
        )
        dist = _extract_steeps_distribution(content)
        assert len(dist) == 6

    def test_extract_steeps_distribution_counts_duplicates(self):
        """Same category appearing multiple times is counted correctly."""
        content = (
            "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” AI\n"
            "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” ì–‘ì\n"
            "1. **ë¶„ë¥˜**: ê²½ì œ (E) â€” ë¬´ì—­\n"
        )
        dist = _extract_steeps_distribution(content)
        assert dist["T_Technological"] == 2
        assert dist["E_Economic"] == 1

    def test_extract_steeps_distribution_empty(self):
        """Empty or no-match content returns empty dict."""
        assert _extract_steeps_distribution("") == {}
        assert _extract_steeps_distribution("no signals here") == {}

    def test_extract_steeps_distribution_boundary_matching(self):
        """Korean boundary matching prevents false substring matches.
        'ê²½ì œì‚¬íšŒì ' should NOT match 'ì‚¬íšŒ' as a standalone category."""
        content = "1. **ë¶„ë¥˜**: ê²½ì œì‚¬íšŒì  ë³€í™”\n"
        dist = _extract_steeps_distribution(content)
        # 'ê²½ì œ' is at start with 'ì‚¬' following â†’ should NOT match as standalone "ê²½ì œ"
        # 'ì‚¬íšŒ' has 'ì œ' before and 'ì ' after â†’ should NOT match as standalone "ì‚¬íšŒ"
        # Neither should match due to Korean boundary regex
        assert "S_Social" not in dist
        assert "E_Economic" not in dist

    def test_extract_steeps_distribution_legitimate_match(self):
        """Normal category format with surrounding non-Korean chars matches correctly."""
        content = "1. **ë¶„ë¥˜**: ì‚¬íšŒ (S) â€” ì¸êµ¬í†µê³„\n"
        dist = _extract_steeps_distribution(content)
        assert dist == {"S_Social": 1}

    # -- STEEPS-001 integration tests --

    def _make_diverse_report(self, categories: list[tuple[str, str]]) -> str:
        """Build a minimal valid report with signals in specified categories.
        categories: list of (korean_name, code) like [("ê¸°ìˆ ", "T"), ("ì‚¬íšŒ", "S")]
        """
        sections = []
        sections.append("# ì¼ì¼ í™˜ê²½ ìŠ¤ìºë‹ ë³´ê³ ì„œ\n\n**ë‚ ì§œ**: 2026ë…„ 2ì›” 1ì¼\n\n---\n\n")

        # Section 1
        sections.append("## 1. ê²½ì˜ì§„ ìš”ì•½\n\n### ì˜¤ëŠ˜ì˜ í•µì‹¬ ë°œê²¬ (Top 3 ì‹ í˜¸)\n\n")
        for i in range(1, 4):
            sections.append(f"{i}. **ì‹ í˜¸ {i}**\n   - ì¤‘ìš”ë„: â­â­â­â­\n   - í•µì‹¬ ë‚´ìš©: ìš”ì•½ {i}\n   - ì „ëµì  ì‹œì‚¬ì : ì‹œì‚¬ì  {i}\n\n")
        sections.append("### ì£¼ìš” ë³€í™” ìš”ì•½\n- ë°œê²¬ëœ ì‹ ê·œ ì‹ í˜¸: 100ê°œ\n- ìš°ì„ ìˆœìœ„: 15ê°œ\n- ë„ë©”ì¸: ê¸°ìˆ  ì‚¬íšŒ ê²½ì œ í™˜ê²½\n\n---\n\n")

        # Section 2 â€” signals with diverse categories
        sections.append("## 2. ì‹ ê·œ íƒì§€ ì‹ í˜¸\n\n---\n\n")
        for i in range(1, 16):
            ko_name, code = categories[i % len(categories)]
            sections.append(f"### ìš°ì„ ìˆœìœ„ {i}: í…ŒìŠ¤íŠ¸ ì‹ í˜¸ {i}ë²ˆ\n\n")
            sections.append(f"- **ì‹ ë¢°ë„**: pSST ë¯¸ì‚°ì¶œ (7.0/10.0)\n\n")
            sections.append(f"1. **ë¶„ë¥˜**: {ko_name} ({code}) â€” í…ŒìŠ¤íŠ¸\n")
            sections.append(f"2. **ì¶œì²˜**: TestSource, 2026-02-01, ID: test-{i:03d}\n")
            sections.append(f"3. **í•µì‹¬ ì‚¬ì‹¤**: í•µì‹¬ ì‚¬ì‹¤ {i}ë²ˆì…ë‹ˆë‹¤ ì¤‘ìš”í•œ ë°œê²¬ì„ ê¸°ìˆ í•©ë‹ˆë‹¤\n")
            sections.append(f"4. **ì •ëŸ‰ ì§€í‘œ**:\n   - ì˜í–¥ë„(Impact): 8.0/10\n   - ë°œìƒí™•ë¥ : 7.0/10\n")
            sections.append(f"5. **ì˜í–¥ë„**: â­â­â­â­ (8.0/10.0) â€” ë†’ìŒ\n")
            sections.append(f"6. **ìƒì„¸ ì„¤ëª…**: ìƒì„¸ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤\n")
            sections.append(f"7. **ì¶”ë¡ **: ì „ëµì  í•´ì„ì…ë‹ˆë‹¤ ë¯¸ë˜ ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤\n")
            sections.append(f"8. **ì´í•´ê´€ê³„ì**: ì •ë¶€ê¸°ê´€, ê¸°ì—…, í•™ê³„\n")
            sections.append(f"9. **ëª¨ë‹ˆí„°ë§ ì§€í‘œ**:\n   - ê´€ë ¨ ì§€í‘œ {i}\n")
            sections.append("\n---\n\n")

        # Section 3
        sections.append("## 3. ê¸°ì¡´ ì‹ í˜¸ ì—…ë°ì´íŠ¸\n\n")
        sections.append("### 3.1 ê°•í™” ì¶”ì„¸ (Strengthening)\n\n- ê°•í™” ì‹ í˜¸ 3ê°œ\n\n")
        sections.append("### 3.2 ì•½í™” ì¶”ì„¸ (Weakening)\n\ní•´ë‹¹ ì—†ìŒ\n\n")
        sections.append("### 3.3 ì‹ í˜¸ ìƒíƒœ ìš”ì•½\n\n| ìƒíƒœ | ìˆ˜ |\n|------|---|\n| ì‹ ê·œ | 8 |\n\n---\n\n")

        # Section 4
        sections.append("## 4. íŒ¨í„´ ë° ì—°ê²°ê³ ë¦¬\n\n")
        sections.append("### 4.1 ì‹ í˜¸ ê°„ êµì°¨ ì˜í–¥\n\n- A â†” B: êµì°¨ (+3)\n- C â†” D: êµì°¨ (+2)\n- E â†” F: êµì°¨ (+4)\n\n")
        sections.append("### 4.2 ë– ì˜¤ë¥´ëŠ” í…Œë§ˆ\n\n1. í…Œë§ˆ A\n\n---\n\n")

        # Section 5
        sections.append("## 5. ì „ëµì  ì‹œì‚¬ì \n\n")
        sections.append("### 5.1 ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”\n\n1. ì¡°ì¹˜ A\n\n")
        sections.append("### 5.2 ì¤‘ê¸° ëª¨ë‹ˆí„°ë§\n\n1. ëª¨ë‹ˆí„°ë§ A\n\n")
        sections.append("### 5.3 ëª¨ë‹ˆí„°ë§ ê°•í™” í•„ìš” ì˜ì—­\n\n- ì˜ì—­ A\n\n---\n\n")

        # Section 7
        sections.append("## 7. ì‹ ë¢°ë„ ë¶„ì„\n\npSST ë¶„í¬ ë¶„ì„\n\n---\n\n")

        # Section 8
        sections.append("## 8. ë¶€ë¡\n\nì „ì²´ ì‹ í˜¸ ëª©ë¡\n\n")

        return "".join(sections)

    def test_steeps_001_pass_diverse_categories(self, tmp_path):
        """STEEPS-001 passes when report has >= 4 distinct categories."""
        content = self._make_diverse_report([
            ("ê¸°ìˆ ", "T"), ("ì‚¬íšŒ", "S"), ("ê²½ì œ", "E"), ("í™˜ê²½", "E"), ("ì •ì¹˜", "P"),
        ])
        f = tmp_path / "diverse-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        assert steeps.passed, f"STEEPS-001 should pass with 5 categories: {steeps.detail}"

    def test_steeps_001_fail_insufficient_categories(self, tmp_path):
        """STEEPS-001 fails when report has < 4 distinct categories (standard)."""
        content = self._make_diverse_report([
            ("ê¸°ìˆ ", "T"), ("ê²½ì œ", "E"),
        ])
        f = tmp_path / "narrow-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        assert not steeps.passed, f"STEEPS-001 should fail with only 2 categories"
        assert "2" in steeps.detail  # "Found 2 categories"
        assert steeps.level == "ERROR"

    def test_steeps_001_fail_detail_shows_missing(self, tmp_path):
        """STEEPS-001 detail includes missing category codes."""
        content = self._make_diverse_report([
            ("ê¸°ìˆ ", "T"),
        ])
        f = tmp_path / "single-cat-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        assert not steeps.passed
        # Missing categories should be listed
        assert "S_Social" in steeps.detail
        assert "E_Economic" in steeps.detail
        assert "E_Environmental" in steeps.detail
        assert "P_Political" in steeps.detail
        assert "s_spiritual" in steeps.detail

    def test_steeps_001_skip_weekly(self, tmp_path):
        """Weekly profile (steeps_min_categories=0) skips STEEPS-001 entirely."""
        # Use a minimal weekly-format report
        f = tmp_path / "weekly-report.md"
        f.write_text("# ì£¼ê°„ report\n" * 100, encoding="utf-8")
        result = validate_report(str(f), profile="weekly")
        steeps_checks = [r for r in result.results if r.check_id == "STEEPS-001"]
        assert len(steeps_checks) == 0, "STEEPS-001 should not appear in weekly profile"

    def test_steeps_001_arxiv_fallback_threshold(self, tmp_path):
        """arxiv_fallback profile has lower threshold (3 categories)."""
        content = self._make_diverse_report([
            ("ê¸°ìˆ ", "T"), ("ê²½ì œ", "E"), ("í™˜ê²½", "E"),
        ])
        f = tmp_path / "arxiv-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="arxiv_fallback")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        assert steeps.passed, f"arxiv_fallback should pass with 3 categories: {steeps.detail}"

    def test_steeps_001_integrated_needs_5(self, tmp_path):
        """Integrated profile requires 5 distinct categories."""
        content = self._make_diverse_report([
            ("ê¸°ìˆ ", "T"), ("ì‚¬íšŒ", "S"), ("ê²½ì œ", "E"), ("í™˜ê²½", "E"),
        ])
        f = tmp_path / "integrated-4cat.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="integrated")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        # 4 categories, but integrated needs 5
        assert not steeps.passed, f"Integrated should fail with only 4 categories"


# ---------------------------------------------------------------------------
# Tests: _classify_steeps_field (3-layer detection, real-world formats)
# ---------------------------------------------------------------------------

class TestClassifySteepsField:
    """Tests for _classify_steeps_field â€” all 7 observed real-world formats."""

    # -- Format A: Korean-first (ìµœì‹  í˜•ì‹) --

    def test_format_a_korean_first(self):
        """Standard Korean-first: ê¸°ìˆ  (T) â€” AI/LLM"""
        assert _classify_steeps_field("ê¸°ìˆ  (T) â€” AI/LLM") == {"T_Technological"}

    def test_format_a_korean_first_no_space(self):
        """Korean-first without space: ê¸°ìˆ (T) - ë¡œë³´í‹±ìŠ¤"""
        assert _classify_steeps_field("ê¸°ìˆ (T) - ë¡œë³´í‹±ìŠ¤") == {"T_Technological"}

    def test_format_a_all_six_categories(self):
        """Each Korean category resolves correctly."""
        assert _classify_steeps_field("ì‚¬íšŒ (S) â€” ì¸êµ¬í†µê³„") == {"S_Social"}
        assert _classify_steeps_field("ê¸°ìˆ  (T) â€” AI") == {"T_Technological"}
        assert _classify_steeps_field("ê²½ì œ (E) â€” ë¬´ì—­") == {"E_Economic"}
        assert _classify_steeps_field("í™˜ê²½ (E_Environmental) â€” ê¸°í›„") == {"E_Environmental"}
        assert _classify_steeps_field("ì •ì¹˜ (P) â€” ê·œì œ") == {"P_Political"}
        assert _classify_steeps_field("ì •ì‹ ì (s) - ì‹ ê²½ê³¼í•™") == {"s_spiritual"}

    # -- Format B: English code-first --

    def test_format_b_english_code_first(self):
        """English code-first: T (Technological) -- AI-ë°”ì´ì˜¤"""
        assert _classify_steeps_field("T (Technological) -- AI-ë°”ì´ì˜¤") == {"T_Technological"}

    def test_format_b_social(self):
        """S (Social) -- ê³µì¤‘ë³´ê±´"""
        assert _classify_steeps_field("S (Social) -- ê³µì¤‘ë³´ê±´") == {"S_Social"}

    def test_format_b_environmental(self):
        """E_Environmental (í™˜ê²½) -- ê¸°í›„ê³¼í•™"""
        result = _classify_steeps_field("E_Environmental (í™˜ê²½) -- ê¸°í›„ê³¼í•™")
        assert "E_Environmental" in result

    # -- Format C: Full-code first --

    def test_format_c_full_code_first(self):
        """Full code: P_Political (ë¹„êµì •ì¹˜)"""
        assert _classify_steeps_field("P_Political (ë¹„êµì •ì¹˜)") == {"P_Political"}

    def test_format_c_spiritual(self):
        """Full code: s_spiritual (ì‹¬ë¦¬/ì²´ì œ ë…¼ë¦¬)"""
        assert _classify_steeps_field("s_spiritual (ì‹¬ë¦¬/ì²´ì œ ë…¼ë¦¬)") == {"s_spiritual"}

    def test_format_c_s_spiritual_with_korean_desc(self):
        """s_spiritual (ì‹¬ë¦¬/ê°€ì¹˜/ì‹ ë¢°)"""
        assert _classify_steeps_field("s_spiritual (ì‹¬ë¦¬/ê°€ì¹˜/ì‹ ë¢°)") == {"s_spiritual"}

    # -- Format D: English name-first (WF3) --

    def test_format_d_english_name_first(self):
        """English name: Political (P) -- ì‚¬ë²•ë¶€ì˜ ê¸°í›„ ì •ì±…"""
        assert _classify_steeps_field("Political (P) -- ì‚¬ë²•ë¶€ì˜ ê¸°í›„ ì •ì±…") == {"P_Political"}

    def test_format_d_technological(self):
        """Technological (T) -- ë©”ëª¨ë¦¬ ë°˜ë„ì²´"""
        assert _classify_steeps_field("Technological (T) -- ë©”ëª¨ë¦¬ ë°˜ë„ì²´") == {"T_Technological"}

    def test_format_d_economic(self):
        """Economic (E) -- AI ë°˜ë„ì²´ ì‹œì¥"""
        assert _classify_steeps_field("Economic (E) -- AI ë°˜ë„ì²´ ì‹œì¥") == {"E_Economic"}

    def test_format_d_environmental(self):
        """Environmental (E_Environmental) -- êµ­ì œ ê¸°í›„"""
        result = _classify_steeps_field("Environmental (E_Environmental) -- êµ­ì œ ê¸°í›„")
        assert "E_Environmental" in result

    def test_format_d_social(self):
        """Social (S) -- ì¸êµ¬ ì†Œë©¸ ìœ„ê¸°"""
        assert _classify_steeps_field("Social (S) -- ì¸êµ¬ ì†Œë©¸ ìœ„ê¸°") == {"S_Social"}

    def test_format_d_spiritual(self):
        """spiritual (s) -- AI ìœ¤ë¦¬ì™€ ê°€ì¹˜ê´€ ë³€í™”"""
        assert _classify_steeps_field("spiritual (s) -- AI ìœ¤ë¦¬ì™€ ê°€ì¹˜ê´€ ë³€í™”") == {"s_spiritual"}

    # -- Format E: "ì˜ì /ìœ¤ë¦¬" variant --

    def test_format_e_yeongjeok(self):
        """ì˜ì /ìœ¤ë¦¬ (s) -- ì‚¬íšŒ ì‹¬ë¦¬/ê°€ì¹˜ê´€"""
        result = _classify_steeps_field("ì˜ì /ìœ¤ë¦¬ (s) -- ì‚¬íšŒ ì‹¬ë¦¬/ê°€ì¹˜ê´€")
        assert "s_spiritual" in result

    def test_format_e_yeongjeok_full_code(self):
        """ì˜ì /ìœ¤ë¦¬ (s_spiritual)"""
        result = _classify_steeps_field("ì˜ì /ìœ¤ë¦¬ (s_spiritual)")
        assert "s_spiritual" in result

    # -- Format F: Multi-category with + --

    def test_format_f_triple_category(self):
        """ê²½ì œ(E) + ì‚¬íšŒ(S) + ì •ì¹˜(P) -- econ.GN"""
        result = _classify_steeps_field("ê²½ì œ(E) + ì‚¬íšŒ(S) + ì •ì¹˜(P) -- econ.GN")
        assert result == {"E_Economic", "S_Social", "P_Political"}

    def test_format_f_dual_with_spiritual(self):
        """ì‚¬íšŒ (S) + ì˜ì  (s) -- cs.CY"""
        result = _classify_steeps_field("ì‚¬íšŒ (S) + ì˜ì  (s) -- cs.CY")
        assert result == {"S_Social", "s_spiritual"}

    # -- Format G: Dual-category with / --

    def test_format_g_dual_slash(self):
        """ê²½ì œ (E) / ì •ì¹˜ (P)"""
        result = _classify_steeps_field("ê²½ì œ (E) / ì •ì¹˜ (P)")
        assert result == {"E_Economic", "P_Political"}

    def test_format_g_tech_env(self):
        """ê¸°ìˆ  (T) / í™˜ê²½ (E_Environmental)"""
        result = _classify_steeps_field("ê¸°ìˆ  (T) / í™˜ê²½ (E_Environmental)")
        assert result == {"T_Technological", "E_Environmental"}

    def test_format_g_tech_spiritual(self):
        """ê¸°ìˆ  (T) / ì˜ì /ìœ¤ë¦¬ (s_spiritual)"""
        result = _classify_steeps_field("ê¸°ìˆ  (T) / ì˜ì /ìœ¤ë¦¬ (s_spiritual)")
        assert result == {"T_Technological", "s_spiritual"}

    def test_format_g_tech_spiritual_code(self):
        """ê¸°ìˆ (T) / ì •ì‹ ì (s) -- AI ì•ˆì „ì„±"""
        result = _classify_steeps_field("ê¸°ìˆ (T) / ì •ì‹ ì (s) -- AI ì•ˆì „ì„±")
        assert result == {"T_Technological", "s_spiritual"}

    # -- Description false-positive prevention --

    def test_description_not_matched(self):
        """Korean keywords in description part must NOT cause false matches.
        ì •ì¹˜ (P) -- í™˜ê²½ ê·œì œ ì •ì±…: 'í™˜ê²½' is in description, not category."""
        result = _classify_steeps_field("ì •ì¹˜ (P) -- í™˜ê²½ ê·œì œ ì •ì±…")
        assert result == {"P_Political"}
        assert "E_Environmental" not in result

    def test_description_social_in_desc(self):
        """ê²½ì œ (E) -- ì‚¬íšŒë³´ì¥ ì •ì±…: 'ì‚¬íšŒ' in description."""
        result = _classify_steeps_field("ê²½ì œ (E) -- ì‚¬íšŒë³´ì¥ ì •ì±…")
        assert result == {"E_Economic"}
        assert "S_Social" not in result

    # -- Edge cases --

    def test_empty_field(self):
        assert _classify_steeps_field("") == set()

    def test_metadata_not_signal(self):
        """Non-signal text like 'STEEPs 6ê°œ ì¹´í…Œê³ ë¦¬' should return empty."""
        assert _classify_steeps_field("STEEPs 6ê°œ ì¹´í…Œê³ ë¦¬") == set()

    def test_placeholder_not_matched(self):
        """Unfilled placeholder should return empty."""
        assert _classify_steeps_field("{{SIGNAL_1_CLASSIFICATION}}") == set()

    def test_s_lowercase_fallback(self):
        """s (spiritual/ethical) -- AI ìœ¤ë¦¬: Layer 3 leading code fallback."""
        result = _classify_steeps_field("s (spiritual/ethical) -- AI ìœ¤ë¦¬")
        assert "s_spiritual" in result

    def test_ambiguous_e_without_korean(self):
        """Economic (E) â€” no Korean 'ê²½ì œ' keyword. Layer 2 skips (E),
        Layer 3 catches 'Economic'."""
        result = _classify_steeps_field("Economic (E) -- ì‹œì¥ ë¶„ì„")
        assert result == {"E_Economic"}

    def test_s_korean_in_parens(self):
        """S (ì‚¬íšŒ) â€” ì˜ë£ŒÂ·êµìœ¡: Korean in parens matches Layer 1."""
        result = _classify_steeps_field("S (ì‚¬íšŒ) â€” ì˜ë£ŒÂ·êµìœ¡ ì •ì±…")
        assert result == {"S_Social"}

    def test_social_korean_in_parens(self):
        """Social (ì‚¬íšŒ) â€” ì˜ë£Œì¸ë ¥: English name + Korean in parens."""
        result = _classify_steeps_field("Social (ì‚¬íšŒ) â€” ì˜ë£Œì¸ë ¥/êµìœ¡ì •ì±…")
        assert result == {"S_Social"}

    # -- Production bug regression: BUG-1 (spiritual/ethical) format --------

    def test_bug1_spiritual_ethical_with_tech(self):
        """BUG-1 regression: (spiritual/ethical) combined with T must detect both."""
        result = _classify_steeps_field(
            "T (Technological) / s (spiritual/ethical) -- AI ì •ë ¬, ìœ¤ë¦¬ì  ì¶”ë¡ "
        )
        assert result == {"T_Technological", "s_spiritual"}

    def test_bug1_spiritual_ethical_with_social(self):
        """BUG-1 regression: (spiritual/ethical) combined with S must detect both."""
        result = _classify_steeps_field(
            "S (Social) / s (spiritual/ethical) -- AI ê³µì •ì„±, êµ¬ì¡°ì  ì°¨ë³„"
        )
        assert result == {"S_Social", "s_spiritual"}

    # -- Production bug regression: BUG-2 CODE / CODE (description) ---------

    def test_bug2_fullcode_dual_tech_spiritual(self):
        """BUG-2 regression: bare full-codes with paren description."""
        result = _classify_steeps_field(
            "T_Technological / s_spiritual (AI ì•ˆì „ì„±, ë‹¤ì¤‘ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ, ì •ë ¬)"
        )
        assert result == {"T_Technological", "s_spiritual"}

    def test_bug2_fullcode_dual_econ_social(self):
        result = _classify_steeps_field(
            "E_Economic / S_Social (í–‰ë™ê²½ì œí•™, AI í¸í–¥, ê¸ˆìœµ ì˜ì‚¬ê²°ì •)"
        )
        assert result == {"E_Economic", "S_Social"}

    def test_bug2_fullcode_dual_econ_political(self):
        result = _classify_steeps_field(
            "E_Economic / P_Political (AI í¸í–¥, ê¸ˆìœµ ì˜ˆì¸¡, ê±°ë²„ë„ŒìŠ¤)"
        )
        assert result == {"E_Economic", "P_Political"}

    def test_bug2_fullcode_dual_political_tech(self):
        result = _classify_steeps_field(
            "P_Political / T_Technological (AI ê±°ë²„ë„ŒìŠ¤, í–‰ì •ë²•, ê·œì œ)"
        )
        assert result == {"P_Political", "T_Technological"}

    def test_bug2_fullcode_dual_tech_political(self):
        result = _classify_steeps_field(
            "T_Technological / P_Political (AI ë³´ì•ˆ, ì—ì´ì „íŠ¸ AI ì•„í‚¤í…ì²˜)"
        )
        assert result == {"T_Technological", "P_Political"}

    def test_bug2_fullcode_dual_econ_social_2(self):
        result = _classify_steeps_field(
            "E_Economic / S_Social (ë²•ë¥  AI, ê³µê³µ ì¸ì‹, ìœ„í—˜ ê´€ë¦¬)"
        )
        assert result == {"E_Economic", "S_Social"}

    def test_bug2_fullcode_dual_tech_social(self):
        result = _classify_steeps_field(
            "T_Technological / S_Social (íœ´ë¨¸ë…¸ì´ë“œ ë¡œë´‡, ì¸ê°„-ë¡œë´‡ ìƒí˜¸ì‘ìš©)"
        )
        assert result == {"T_Technological", "S_Social"}

    def test_bug2_fullcode_dual_social_political(self):
        result = _classify_steeps_field(
            "S_Social / P_Political (AI ê±°ë²„ë„ŒìŠ¤, ì¸ê°„ ê°ë…, ì‚¬íšŒì  ë¶„ê¸°)"
        )
        assert result == {"S_Social", "P_Political"}

    def test_bug2_fullcode_dual_tech_env(self):
        result = _classify_steeps_field(
            "T_Technological / E_Environmental (ìš°ì£¼ë¡ , ì²œì²´ë¬¼ë¦¬í•™, ê¸°ì´ˆê³¼í•™)"
        )
        assert result == {"T_Technological", "E_Environmental"}


# ---------------------------------------------------------------------------
# Tests: Real reports (conditional â€” only run if files exist)
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# Tests: English profiles (_en) â€” bilingual workflow validation
# ---------------------------------------------------------------------------

def _make_en_signal_block(n: int, full: bool = True) -> str:
    """Generate a single English signal block with 9 fields."""
    block = f"### Priority {n}: Test Signal Title {n}\n\n"
    block += f"- **Confidence**: pSST not computed (priority score: {8.0 - n * 0.1:.1f}/10.0)\n\n"
    block += f"1. **Classification**: Technological (T) -- AI/LLM\n"
    block += f"2. **Source**: TestSource, 2026-02-01, ID: test-{n:03d}\n"
    block += f"3. **Key Facts**: This is the key fact for test signal {n}. Important findings.\n"
    block += f"4. **Quantitative Metrics**:\n   - Impact: 8.0/10\n   - Probability: 7.0/10\n"
    block += f"5. **Impact**: â­â­â­â­ ({8.0 - n * 0.1:.1f}/10.0) â€” High\n"
    if full:
        block += f"6. **Detailed Description**: Detailed analysis of test signal {n}. Multi-sentence description.\n"
        block += f"7. **Inference**: Strategic interpretation for decision makers.\n"
        block += f"8. **Stakeholders**: Government, Company A, Company B, Academia\n"
        block += f"9. **Monitoring Indicators**:\n   - Patent filing count\n   - Investment trends\n"
    block += "\n---\n\n"
    return block


def _make_good_en_report() -> str:
    """Create a synthetic English report that should pass standard_en checks."""
    sections = []

    # Header
    sections.append("# Daily Environmental Scanning Report\n\n**Date**: 2026-02-01\n\n")
    sections.append("> **Scan Window**: 2026-01-31 14:00 ~ 2026-02-01 14:00 (24 hours)\n")
    sections.append("> **Anchor Time (Tâ‚€)**: 2026-02-01T14:00:00+09:00\n\n---\n\n")

    # Section 1
    sections.append("## 1. Executive Summary\n\n")
    sections.append("### Today's Key Findings (Top 3 Signals)\n\n")
    for i in range(1, 4):
        sections.append(f"{i}. **Test Signal {i}** (Technology)\n   - Importance: â­â­â­â­â­\n   - Key Content: Summary {i}\n   - Strategic Implications: Implication {i}\n\n")
    sections.append("### Key Changes Summary\n- New signals detected: 100\n- Top priority signals: 15\n- Major impact domains: Technology(40%), Economy(30%)\n\n---\n\n")

    # Section 2
    sections.append("## 2. Newly Detected Signals\n\n> Priority-ranked analysis results.\n\n---\n\n")
    for i in range(1, 16):
        sections.append(_make_en_signal_block(i, full=(i <= 10)))

    # Section 3
    sections.append("## 3. Existing Signal Updates\n\n")
    sections.append("> Active Tracking Threads: 12 | Strengthening: 3 | Weakening: 1 | Faded: 2\n\n")
    sections.append("### 3.1 Strengthening Trends\n\n")
    sections.append("| Tracking Thread | Days Tracked | pSST Change | Velocity | Breadth |\n|-----------------|-------------|-------------|----------|--------|\n")
    sections.append("| Quantum Computing | 10 days | 82â†’88 (+6) | â–² Accelerating | 0.67 |\n\n")
    sections.append("### 3.2 Weakening Trends\n\n")
    sections.append("| New | 8 | 53% |\n| Strengthening | 3 | 20% |\n\n")
    sections.append("### 3.3 Signal Status Summary\n\n")
    sections.append("| Status | Count | Ratio |\n|--------|-------|-------|\n")
    sections.append("| New | 8 | 53% |\n| Strengthening | 3 | 20% |\n\n---\n\n")

    # Section 4
    sections.append("## 4. Patterns and Connections\n\n")
    sections.append("### 4.1 Cross-Impact Between Signals\n\n")
    sections.append("- **Quantum Computing** â†” **Semiconductor Supply Chain**: Impact +3\n")
    sections.append("- **AI Labor Replacement** â†” **Education Reform**: Impact +4\n")
    sections.append("- **Climate Policy** â†” **Energy Transition**: Impact +3\n")
    sections.append("- **Digital Currency** â†” **Financial Regulation**: Impact +2\n\n")
    sections.append("### 4.2 Emerging Themes\n\n")
    sections.append("1. **Technology Sovereignty** â€” Related: 25 signals, STEEPs: T, P, E\n\n---\n\n")

    # Section 5
    sections.append("## 5. Strategic Implications\n\n")
    sections.append("### 5.1 Short-term (0-6 months)\n\nStrategic points here.\n\n")
    sections.append("### 5.2 Mid-term (6-24 months)\n\nMore strategic points.\n\n")
    sections.append("### 5.3 Long-term (2+ years)\n\nLong-term implications.\n\n---\n\n")

    # Section 6
    sections.append("## 6. Plausible Scenarios\n\nScenario analysis here.\n\n---\n\n")

    # Section 7
    sections.append("## 7. Confidence Analysis\n\nConfidence assessment here.\n\n---\n\n")

    # Section 8
    sections.append("## 8. Appendix\n\nAppendix data here.\n\n")

    # Pad to ensure word count (repeat some text)
    padding = "Quantum computing technology development signal detection " * 300
    sections.append(f"\n\n{padding}\n")

    return "".join(sections)


class TestEnProfiles:
    """Tests for English report validation profiles (standard_en, etc.)."""

    def test_standard_en_good_report(self, tmp_path):
        """A well-formed English report should pass standard_en."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        # Check no CRITICAL failures
        crits = [r for r in result.results if not r.passed and r.level == "CRITICAL"]
        assert len(crits) == 0, f"Unexpected CRITICAL failures: {[(r.check_id, r.detail) for r in crits]}"

    def test_standard_en_has_correct_checks(self, tmp_path):
        """standard_en should produce the same check IDs as standard."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        check_ids = {r.check_id for r in result.results}
        assert "FILE-001" in check_ids
        assert "SEC-001" in check_ids
        assert "SIG-001" in check_ids
        assert "SIG-002" in check_ids
        assert "STEEPS-001" in check_ids
        assert "EVOL-001" in check_ids
        assert "TEMP-001" in check_ids

    def test_standard_en_korean_report_fails_sec001(self, tmp_path):
        """A Korean report validated with standard_en should fail SEC-001."""
        content = _make_good_report()
        f = tmp_path / "ko-as-en.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        sec001 = next(r for r in result.results if r.check_id == "SEC-001")
        assert not sec001.passed, "Korean report should fail English section header check"

    def test_standard_en_counts_en_signal_blocks(self, tmp_path):
        """English signal blocks with Priority N: headers should be counted."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        sig001 = next(r for r in result.results if r.check_id == "SIG-001")
        assert sig001.passed, f"SIG-001 should pass: {sig001.detail}"

    def test_standard_en_checks_en_fields(self, tmp_path):
        """SIG-002 should check English field names (**Classification**, etc.)."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        sig002 = next(r for r in result.results if r.check_id == "SIG-002")
        assert sig002.passed, f"SIG-002 should pass with English fields: {sig002.detail}"

    def test_standard_en_korean_ratio_not_required(self, tmp_path):
        """English reports should pass QUAL-002 even with 0% Korean."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        qual002 = next(r for r in result.results if r.check_id == "QUAL-002")
        assert qual002.passed, "QUAL-002 should pass for English report (min_korean_ratio=0)"

    def test_standard_en_detects_steeps(self, tmp_path):
        """STEEPS-001 should detect categories from **Classification** fields."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        steeps = next(r for r in result.results if r.check_id == "STEEPS-001")
        # All signals are T, so only 1 category â€” will fail (need 4)
        # This is expected: validates that STEEPS detection works in EN mode
        assert "T_Technological" in steeps.detail or steeps.passed is False

    def test_standard_en_evol_check(self, tmp_path):
        """EVOL-001 should detect English evolution keywords."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        evol = next(r for r in result.results if r.check_id == "EVOL-001")
        assert evol.passed, f"EVOL-001 should pass with English evolution text: {evol.detail}"

    def test_standard_en_temp_check(self, tmp_path):
        """TEMP-001 should detect Scan Window / Tâ‚€ in English."""
        content = _make_good_en_report()
        f = tmp_path / "en-report.md"
        f.write_text(content, encoding="utf-8")
        result = validate_report(str(f), profile="standard_en")
        temp = next(r for r in result.results if r.check_id == "TEMP-001")
        assert temp.passed, f"TEMP-001 should pass with English temporal text: {temp.detail}"


class TestEnHelperFunctions:
    """Tests for language-aware helper functions."""

    def test_count_signal_blocks_en(self):
        content = "### Priority 1: Signal A\n### Priority 2: Signal B\n"
        assert _count_signal_blocks(content, language="en") == 2

    def test_count_signal_blocks_en_integrated(self):
        content = "### Integrated Priority 1: Signal A\n### Integrated Priority 2: Signal B\n"
        assert _count_signal_blocks(content, language="en") == 2

    def test_count_signal_blocks_en_no_korean(self):
        content = "### ìš°ì„ ìˆœìœ„ 1: ì‹ í˜¸ A\n"
        assert _count_signal_blocks(content, language="en") == 0

    def test_count_signal_blocks_ko_default(self):
        """Default language=ko, backward compatible."""
        content = "### ìš°ì„ ìˆœìœ„ 1: ì‹ í˜¸ A\n### ìš°ì„ ìˆœìœ„ 2: ì‹ í˜¸ B\n"
        assert _count_signal_blocks(content) == 2

    def test_check_signal_fields_en(self):
        block = _make_en_signal_block(1, full=True)
        total, complete, missing = _check_signal_fields(block, max_signals=1, language="en")
        assert total == 1
        assert complete == 1, f"Missing fields: {missing}"

    def test_check_signal_fields_en_incomplete(self):
        block = _make_en_signal_block(1, full=False)
        total, complete, missing = _check_signal_fields(block, max_signals=1, language="en")
        assert total == 1
        assert complete == 0
        assert len(missing) == 1
        assert "Detailed Description" in missing[0]["missing_fields"]

    def test_extract_steeps_en(self):
        content = (
            "### Priority 1: AI\n"
            "1. **Classification**: Technological (T) -- AI research\n"
            "### Priority 2: Trade\n"
            "1. **Classification**: Economic (E) -- trade policy\n"
        )
        dist = _extract_steeps_distribution(content, language="en")
        assert "T_Technological" in dist
        assert "E_Economic" in dist

    def test_extract_steeps_ko_default(self):
        """Default language=ko backward compatible."""
        content = "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” AI\n"
        dist = _extract_steeps_distribution(content)
        assert "T_Technological" in dist

    def test_extract_steeps_en_ignores_ko_field(self):
        """EN mode should NOT match **ë¶„ë¥˜** fields."""
        content = "1. **ë¶„ë¥˜**: ê¸°ìˆ  (T) â€” AI\n"
        dist = _extract_steeps_distribution(content, language="en")
        assert len(dist) == 0


REPORT_DIR = Path(__file__).parent.parent.parent / "env-scanning" / "reports" / "daily"


@pytest.mark.skipif(
    not (REPORT_DIR / "environmental-scan-2026-02-01.md").exists(),
    reason="Real 02-01 report not available",
)
class TestRealReport0201:
    def test_0201_passes_validation(self):
        result = validate_report(str(REPORT_DIR / "environmental-scan-2026-02-01.md"))
        # The 02-01 report is known good â€” should pass or at most WARN
        assert result.overall_status in ("PASS", "WARN"), result.human_summary()

    def test_0201_no_critical_failures(self):
        result = validate_report(str(REPORT_DIR / "environmental-scan-2026-02-01.md"))
        assert len(result.critical_failures) == 0, \
            f"02-01 report CRITICAL failures: {[r.check_id + ': ' + r.detail for r in result.critical_failures]}"


@pytest.mark.skipif(
    not (REPORT_DIR / "environmental-scan-2026-02-02.md").exists(),
    reason="Real 02-02 report not available",
)
class TestRealReport0202:
    """
    02-02 report was regenerated with 4-layer defense (2026-02-02).
    It should now PASS validation, just like 02-01.
    The original defective pattern is covered by TestBadReport0202Style (synthetic).
    """

    def test_0202_passes_validation(self):
        result = validate_report(str(REPORT_DIR / "environmental-scan-2026-02-02.md"))
        assert result.overall_status in ("PASS", "WARN"), \
            f"Expected 02-02 report (regenerated) to PASS but got {result.overall_status}\n{result.human_summary()}"

    def test_0202_no_critical_failures(self):
        result = validate_report(str(REPORT_DIR / "environmental-scan-2026-02-02.md"))
        assert len(result.critical_failures) == 0, \
            f"02-02 report CRITICAL failures: {[r.check_id + ': ' + r.detail for r in result.critical_failures]}"


# ---------------------------------------------------------------------------
# EXPLO-001: Exploration Proof Check (option-based)
# ---------------------------------------------------------------------------

class TestExplorationProofCheck:
    """Tests for EXPLO-001: exploration proof validation (--exploration-proof option)."""

    def test_valid_proof_passes(self, tmp_path):
        """Valid exploration proof file passes EXPLO-001."""
        proof = {
            "gate_id": "exploration_gate.py",
            "gate_decision": "MUST_RUN",
            "execution_status": "executed",
            "date": "2026-02-13",
        }
        proof_file = tmp_path / "proof.json"
        proof_file.write_text(json.dumps(proof))

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(proof_file))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is True

    def test_missing_proof_fails(self, tmp_path):
        """Missing proof file fails EXPLO-001."""
        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(tmp_path / "nonexistent.json"))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is False
        assert "not found" in explo[0].detail

    def test_invalid_json_fails(self, tmp_path):
        """Invalid JSON in proof file fails EXPLO-001."""
        bad_file = tmp_path / "bad-proof.json"
        bad_file.write_text("{invalid json")

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(bad_file))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].passed is False
        assert "Invalid JSON" in explo[0].detail

    def test_missing_fields_fails(self, tmp_path):
        """Proof file missing required fields fails EXPLO-001."""
        incomplete = {"gate_id": "exploration_gate.py"}  # Missing gate_decision, execution_status, date
        proof_file = tmp_path / "incomplete-proof.json"
        proof_file.write_text(json.dumps(incomplete))

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(proof_file))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].passed is False
        assert "missing fields" in explo[0].detail

    def test_skipped_proof_passes(self, tmp_path):
        """Proof with SKIP_DISABLED decision passes (valid format)."""
        proof = {
            "gate_id": "exploration_gate.py",
            "gate_decision": "SKIP_DISABLED",
            "execution_status": "skipped",
            "date": "2026-02-13",
        }
        proof_file = tmp_path / "skip-proof.json"
        proof_file.write_text(json.dumps(proof))

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(proof_file))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].passed is True

    def test_check_level_is_error_by_default(self, tmp_path):
        """EXPLO-001 check level defaults to ERROR."""
        proof_file = tmp_path / "proof.json"
        proof_file.write_text(json.dumps({
            "gate_id": "exploration_gate.py",
            "gate_decision": "MUST_RUN",
            "execution_status": "executed",
            "date": "2026-02-13",
        }))

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(proof_file))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].level == "ERROR"

    def test_check_level_critical_when_passed(self, tmp_path):
        """EXPLO-001 level should be CRITICAL when caller passes level='CRITICAL'."""
        proof_file = tmp_path / "proof.json"
        proof_file.write_text(json.dumps({
            "gate_id": "exploration_gate.py",
            "gate_decision": "MUST_RUN",
            "execution_status": "executed",
            "date": "2026-02-13",
        }))

        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(proof_file), level="CRITICAL")

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].level == "CRITICAL"

    def test_missing_proof_with_critical_level(self, tmp_path):
        """Missing proof + level=CRITICAL â†’ CRITICAL FAIL (not ERROR FAIL)."""
        vr = ValidationReport(report_path="dummy.md")
        _check_exploration_proof(vr, str(tmp_path / "nonexistent.json"), level="CRITICAL")

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert explo[0].passed is False
        assert explo[0].level == "CRITICAL"


# ---------------------------------------------------------------------------
# EXPLO-001 Auto-Enforcement (SOT-driven mandatory enforcement)
# ---------------------------------------------------------------------------

class TestExplorationAutoEnforcement:
    """Tests for _auto_enforce_exploration(): auto-detect SOT enforcement setting
    and apply CRITICAL (mandatory) or ERROR (optional) level to EXPLO-001."""

    def _setup_wf1_project(self, tmp_path, enforcement="mandatory", exploration_enabled=True):
        """Create a minimal project structure with SOT for testing auto-enforcement.
        Returns the report path."""
        # Create directory structure: project_root/env-scanning/wf1-general/reports/daily/
        project_root = tmp_path / "project"
        wf1_reports = project_root / "env-scanning" / "wf1-general" / "reports" / "daily"
        wf1_reports.mkdir(parents=True)
        wf1_exploration = project_root / "env-scanning" / "wf1-general" / "exploration"
        wf1_exploration.mkdir(parents=True)

        # Create minimal SOT
        sot_dir = project_root / "env-scanning" / "config"
        sot_dir.mkdir(parents=True)
        sot_content = {
            "workflows": {
                "wf1-general": {
                    "data_root": "env-scanning/wf1-general",
                    "parameters": {
                        "source_exploration": {
                            "enabled": exploration_enabled,
                            "enforcement": enforcement,
                        }
                    }
                }
            }
        }
        import yaml as _yaml
        with open(sot_dir / "workflow-registry.yaml", "w") as f:
            _yaml.dump(sot_content, f)

        # Create report file
        report_path = wf1_reports / "environmental-scan-2026-02-15.md"
        report_path.write_text("# Test report", encoding="utf-8")

        return str(report_path), project_root, wf1_exploration

    def test_wf1_mandatory_no_proof_critical(self, tmp_path):
        """WF1 + enforcement=mandatory + no proof â†’ CRITICAL FAIL."""
        report_path, _, _ = self._setup_wf1_project(tmp_path, enforcement="mandatory")
        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is False
        assert explo[0].level == "CRITICAL"
        assert "mandatory" in explo[0].detail.lower()

    def test_wf1_mandatory_with_proof_passes(self, tmp_path):
        """WF1 + enforcement=mandatory + valid proof â†’ PASS."""
        report_path, _, exploration_dir = self._setup_wf1_project(
            tmp_path, enforcement="mandatory"
        )
        # Create valid proof file
        proof = {
            "gate_id": "exploration_gate.py",
            "gate_decision": "MUST_RUN",
            "execution_status": "executed",
            "date": "2026-02-15",
        }
        proof_file = exploration_dir / "exploration-proof-2026-02-15.json"
        proof_file.write_text(json.dumps(proof), encoding="utf-8")

        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is True

    def test_wf2_path_skips_exploration(self, tmp_path):
        """WF2 path (not wf1-general) â†’ auto-detection skips entirely."""
        # Create a WF2-like path
        wf2_dir = tmp_path / "project" / "env-scanning" / "wf2-arxiv" / "reports" / "daily"
        wf2_dir.mkdir(parents=True)
        report_path = wf2_dir / "environmental-scan-2026-02-15.md"
        report_path.write_text("# Test", encoding="utf-8")

        vr = ValidationReport(report_path=str(report_path))
        _auto_enforce_exploration(vr, str(report_path))

        # No EXPLO-001 check should be added
        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 0

    def test_non_standard_path_skips(self, tmp_path):
        """Non-standard filename â†’ graceful skip (no EXPLO-001 added)."""
        report_path = tmp_path / "custom-report.md"
        report_path.write_text("# Test", encoding="utf-8")

        vr = ValidationReport(report_path=str(report_path))
        _auto_enforce_exploration(vr, str(report_path))

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 0

    def test_optional_enforcement_stays_error(self, tmp_path):
        """enforcement=optional + no proof â†’ ERROR (not CRITICAL)."""
        report_path, _, _ = self._setup_wf1_project(tmp_path, enforcement="optional")
        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is False
        assert explo[0].level == "ERROR"

    def test_check_level_is_critical_when_mandatory(self, tmp_path):
        """Verify level field is exactly 'CRITICAL' when enforcement=mandatory."""
        report_path, _, exploration_dir = self._setup_wf1_project(
            tmp_path, enforcement="mandatory"
        )
        # Even with a valid proof, verify the level would be CRITICAL
        proof = {
            "gate_id": "exploration_gate.py",
            "gate_decision": "MUST_RUN",
            "execution_status": "executed",
            "date": "2026-02-15",
        }
        proof_file = exploration_dir / "exploration-proof-2026-02-15.json"
        proof_file.write_text(json.dumps(proof), encoding="utf-8")

        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].level == "CRITICAL"

    def test_exploration_disabled_skips(self, tmp_path):
        """exploration.enabled=false â†’ no EXPLO-001 check added."""
        report_path, _, _ = self._setup_wf1_project(
            tmp_path, enforcement="mandatory", exploration_enabled=False
        )
        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 0

    def test_get_enforcement_level_mandatory(self, tmp_path):
        """_get_enforcement_level returns CRITICAL for WF1 mandatory path."""
        report_path, _, _ = self._setup_wf1_project(tmp_path, enforcement="mandatory")
        level = _get_enforcement_level(report_path)
        assert level == "CRITICAL"

    def test_get_enforcement_level_optional(self, tmp_path):
        """_get_enforcement_level returns ERROR for WF1 optional path."""
        report_path, _, _ = self._setup_wf1_project(tmp_path, enforcement="optional")
        level = _get_enforcement_level(report_path)
        assert level == "ERROR"

    def test_get_enforcement_level_non_wf1(self, tmp_path):
        """_get_enforcement_level returns ERROR for non-WF1 paths."""
        wf2_dir = tmp_path / "project" / "env-scanning" / "wf2-arxiv" / "reports" / "daily"
        wf2_dir.mkdir(parents=True)
        report_path = wf2_dir / "environmental-scan-2026-02-15.md"
        report_path.write_text("# Test", encoding="utf-8")
        level = _get_enforcement_level(str(report_path))
        assert level == "ERROR"

    def test_flag_override_respects_mandatory_level(self, tmp_path):
        """When --exploration-proof is passed with mandatory enforcement,
        _check_exploration_proof should use CRITICAL level (not ERROR).
        This tests the CRITICAL-1 fix: flag overrides path, not level."""
        report_path, _, exploration_dir = self._setup_wf1_project(
            tmp_path, enforcement="mandatory"
        )
        # Create invalid proof (missing fields)
        bad_proof = exploration_dir / "bad-proof.json"
        bad_proof.write_text(json.dumps({"gate_id": "test"}), encoding="utf-8")

        # Simulate what main() does: get level from SOT, pass to _check_exploration_proof
        level = _get_enforcement_level(report_path)
        assert level == "CRITICAL"  # Confirms SOT is read correctly

        vr = ValidationReport(report_path=report_path)
        _check_exploration_proof(vr, str(bad_proof), level=level)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1
        assert explo[0].passed is False
        assert explo[0].level == "CRITICAL"  # NOT ERROR â€” CRITICAL-1 fix verified


# ---------------------------------------------------------------------------
# EXPLO-001 Silent Fallback Fix Tests (v2.9.0)
# ---------------------------------------------------------------------------

class TestExplo001SilentFallbackFix:
    """Tests that SOT parsing failures in _auto_enforce_exploration() produce
    visible error/critical results instead of silently returning."""

    def _setup_wf1_project(self, tmp_path, sot_content=None, create_sot=True):
        """Create a WF1 project structure. Returns (report_path, sot_path)."""
        project_root = tmp_path / "project"
        wf1_reports = project_root / "env-scanning" / "wf1-general" / "reports" / "daily"
        wf1_reports.mkdir(parents=True)
        sot_dir = project_root / "env-scanning" / "config"
        sot_dir.mkdir(parents=True)

        sot_path = sot_dir / "workflow-registry.yaml"
        if create_sot and sot_content is not None:
            import yaml as _yaml
            with open(sot_path, "w") as f:
                _yaml.dump(sot_content, f)
        elif create_sot:
            # Create a valid SOT with exploration enabled
            sot = {
                "workflows": {
                    "wf1-general": {
                        "data_root": "env-scanning/wf1-general",
                        "parameters": {
                            "source_exploration": {
                                "enabled": True,
                                "enforcement": "mandatory",
                            }
                        }
                    }
                }
            }
            import yaml as _yaml
            with open(sot_path, "w") as f:
                _yaml.dump(sot, f)

        report_path = wf1_reports / "environmental-scan-2026-02-15.md"
        report_path.write_text("# Test report", encoding="utf-8")

        return str(report_path), sot_path

    def test_sot_parse_failure_produces_critical(self, tmp_path):
        """SOT YAML parse error â†’ CRITICAL EXPLO-001 (not silent skip)."""
        report_path, sot_path = self._setup_wf1_project(tmp_path, create_sot=False)
        # Write invalid YAML
        sot_path.parent.mkdir(parents=True, exist_ok=True)
        sot_path.write_text("{{{invalid yaml content!!!", encoding="utf-8")

        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1, "Expected EXPLO-001 check result on SOT parse failure"
        assert explo[0].passed is False
        assert explo[0].level == "CRITICAL"
        assert "parse" in explo[0].detail.lower() or "sot" in explo[0].detail.lower()

    def test_sot_not_found_produces_error(self, tmp_path):
        """SOT file missing â†’ ERROR EXPLO-001 (not silent skip)."""
        report_path, sot_path = self._setup_wf1_project(tmp_path, create_sot=False)
        # Do NOT create SOT file â€” it should be missing

        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 1, "Expected EXPLO-001 check result when SOT missing"
        assert explo[0].passed is False
        assert explo[0].level == "ERROR"
        assert "not found" in explo[0].detail.lower() or "sot" in explo[0].detail.lower()

    def test_exploration_disabled_still_silent(self, tmp_path):
        """exploration.enabled=false â†’ still produces NO check (legitimate skip)."""
        sot = {
            "workflows": {
                "wf1-general": {
                    "data_root": "env-scanning/wf1-general",
                    "parameters": {
                        "source_exploration": {
                            "enabled": False,
                            "enforcement": "mandatory",
                        }
                    }
                }
            }
        }
        report_path, _ = self._setup_wf1_project(tmp_path, sot_content=sot)

        vr = ValidationReport(report_path=report_path)
        _auto_enforce_exploration(vr, report_path)

        explo = [r for r in vr.results if r.check_id == "EXPLO-001"]
        assert len(explo) == 0, "exploration disabled should not add EXPLO-001"


# ---------------------------------------------------------------------------
# Tests: WF4 multiglobal-news profiles existence and FSSF flags
# ---------------------------------------------------------------------------

class TestMultiglobalNewsProfiles:
    """Tests that multiglobal-news and multiglobal-news_en profiles exist
    in PROFILES and have the expected FSSF-related flags."""

    def test_multiglobal_news_profile_exists(self):
        """multiglobal-news profile must exist in PROFILES dict."""
        from validate_report import PROFILES
        assert "multiglobal-news" in PROFILES, \
            f"multiglobal-news not in PROFILES. Available: {list(PROFILES.keys())}"

    def test_multiglobal_news_en_profile_exists(self):
        """multiglobal-news_en profile must exist in PROFILES dict."""
        from validate_report import PROFILES
        assert "multiglobal-news_en" in PROFILES, \
            f"multiglobal-news_en not in PROFILES. Available: {list(PROFILES.keys())}"

    def test_multiglobal_news_has_fssf_flag(self):
        """multiglobal-news profile must require FSSF table."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news"]
        assert prof.get("require_fssf_table") is True

    def test_multiglobal_news_has_three_horizons_flag(self):
        """multiglobal-news profile must require Three Horizons table."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news"]
        assert prof.get("require_three_horizons_table") is True

    def test_multiglobal_news_has_tipping_point_flag(self):
        """multiglobal-news profile must require tipping point section."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news"]
        assert prof.get("require_tipping_point_section") is True

    def test_multiglobal_news_en_has_fssf_flag(self):
        """multiglobal-news_en profile must require FSSF table."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("require_fssf_table") is True

    def test_multiglobal_news_en_has_three_horizons_flag(self):
        """multiglobal-news_en profile must require Three Horizons table."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("require_three_horizons_table") is True

    def test_multiglobal_news_en_has_tipping_point_flag(self):
        """multiglobal-news_en profile must require tipping point section."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("require_tipping_point_section") is True

    def test_multiglobal_news_has_s4_required_subs(self):
        """multiglobal-news profile must define s4_required_subs for Section 4."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news"]
        subs = prof.get("s4_required_subs")
        assert subs is not None and len(subs) > 0, \
            "multiglobal-news must define s4_required_subs"

    def test_multiglobal_news_en_has_s4_required_subs(self):
        """multiglobal-news_en profile must define s4_required_subs for Section 4."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        subs = prof.get("s4_required_subs")
        assert subs is not None and len(subs) > 0, \
            "multiglobal-news_en must define s4_required_subs"

    def test_multiglobal_news_en_is_english_language(self):
        """multiglobal-news_en must have language='en'."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("language") == "en"

    def test_multiglobal_news_en_zero_korean_ratio(self):
        """multiglobal-news_en must have min_korean_ratio=0.0 (English-only)."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("min_korean_ratio") == 0.0

    def test_multiglobal_news_min_signal_blocks(self):
        """multiglobal-news must require at least 10 signal blocks."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news"]
        assert prof.get("min_signal_blocks", 0) >= 10

    def test_multiglobal_news_en_min_signal_blocks(self):
        """multiglobal-news_en must require at least 10 signal blocks."""
        from validate_report import PROFILES
        prof = PROFILES["multiglobal-news_en"]
        assert prof.get("min_signal_blocks", 0) >= 10


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
